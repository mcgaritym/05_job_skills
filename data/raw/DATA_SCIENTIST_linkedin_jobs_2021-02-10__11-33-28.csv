job_title,company,location,date_posted,applicants,job_text,seniority_level,employment_type,job_function,industries,date_scraped
Data Scientist- Statistician,Harnham,New York City Metropolitan Area,,N/A,"['', 'New York City ', 'HOW TO APPLY:', 'Python and/or R programming skills', 'Create & validate models for causal analysis & outcome prediction', 'THE COMPANY ', 'Utilize a large amount of diverse healthcare data to examine causal relationships between healthcare quality and patient outcomesCreate & validate models for causal analysis & outcome predictionCommunicate results to external & internal stakeholdersPrepare material to be published in scientific journals', 'Previous work experience with generalized linear models, mixed models, & longitudinal data', 'PhD or Masters in statistics, biostatistics, computer science, healthcare economics, applied math, computer science or a related field', 'Communicate results to external & internal stakeholders', 'The successful Data Scientist- Statistician will earn a base salary of $150,000 - $170,000 and a comprehensive benefits package. ', 'DATA SCIENTIST – STATISTICIAN', 'THE ROLE:', 'Utilize a large amount of diverse healthcare data to examine causal relationships between healthcare quality and patient outcomes', 'Please register your interest by sending your CV to Nitasha Khazanchi via the Apply link on this page.', 'An innovative health-tech company is looking for a statistician to aid them in their mission to revolutionize patient care utilizing artificial intelligence & advanced data analytics. ', 'Prepare material to be published in scientific journals', 'You would be working for a well-funded start-up that aims to create a better patient experience utilizing AI and advanced data science technology. In the past year, they have invested millions of dollars in new tech for the Data Science, Computer Vision, and Engineering teams. The culture of the company is centered around solving challenging problems through creativity and collaboration. ', '$150,000 - $170,000 ', 'PhD or Masters in statistics, biostatistics, computer science, healthcare economics, applied math, computer science or a related fieldPrevious work experience with generalized linear models, mixed models, & longitudinal dataExperience in the healthcare sectorPython and/or R programming skills', '\xa0', 'THE BENEFITS:', 'As a Data Scientist- Statistician, you will be part of a multidisciplinary team of engineers, researchers, and other data scientists. Some of the day to day responsibilities include: ', 'YOUR SKILLS AND EXPERIENCE:', 'KEY WORDS: statistician, statistics, data science, artificial intelligence, healthcare technology, biostatistics, python, causal analysis, outcome prediction, clinical data', 'Experience in the healthcare sector']",Mid-Senior level,Full-time,Information Technology,Biotechnology,2021-02-10 11:29:29
Data Scientist - Developer Services,Roblox,"San Mateo, CA",14 hours ago,Be among the first 25 applicants,"['', 'Accelerate product development through your understanding of the underlying data and your ability to partner with product and technical leaders to provide insights that drive growth.', 'Influence how Roblox interacts with its players and its platform developers.', 'An expert transforming data', 'A strong communicator. You understand that analysis must be presented in meaningful ways and engage in spirited discussions about the findings. You have the ability to explain technical concepts to non-technical audiences and discuss appropriate tradeoffs.', '2+ years of experience using big data query/processing languages such as SQL, Hive or Spark to transform/manipulate very large datasets', '1+ years of experience in statistical modeling and machine learning', 'WHY DATA SCIENCE & ANALYTICS?', ' 4+ years of industry experience in analytics 1+ years of experience in statistical modeling and machine learning 2+ years of experience using big data query/processing languages such as SQL, Hive or Spark to transform/manipulate very large datasets 2+ years of experience in one or more scripting languages such as Python or R BA/BS in Computer Science, Applied Math, Physics, Engineering, Statistics, Economics or other technical field ', 'MS or PhD in Computer Science, Applied Math, Physics, Engineering, Statistics, Economics or other technical field', 'BA/BS in Computer Science, Applied Math, Physics, Engineering, Statistics, Economics or other technical field', 'Basic Qualifications', '2+ years of industry experience in analytics focused on enhancing products and discovering opportunities', 'A strong communicator.', 'WHY DEVELOPER SERVICES?', 'Explore and shape a vision for new services to offer developers leading to further success and better content.', 'Understand how existing services are used by successful developers at scale to build deeper engaging and immersive experiences. ', 'You Are', 'Creative thinker able to apply first-principles reasoning to solve complex problems', ' MS or PhD in Computer Science, Applied Math, Physics, Engineering, Statistics, Economics or other technical field 2+ years of industry experience in analytics focused on enhancing products and discovering opportunities 2+ years of experience in fast-paced environment or fast growing company, such as the tech sector Experience working with platforms offering infrastructure-as-a-service Ability to communicate analytics results and data storytelling to influence product teams and leaders Creative thinker able to apply first-principles reasoning to solve complex problems', 'Passionate about data. You have the curiosity and self-drive to continuously learn new techniques and tools to extract value from data. You have a degree in Statistics, Economics, Computer Science or other relevant field.', 'WHY ROBLOX?', ' Understand how existing services are used by successful developers at scale to build deeper engaging and immersive experiences.  Explore and shape a vision for new services to offer developers leading to further success and better content. Accelerate product development through your understanding of the underlying data and your ability to partner with product and technical leaders to provide insights that drive growth. Access raw data, and then transform it, analyze it, and render it in a compelling way--all using a custom analytics tool kit built from state-of-the-art open-source libraries. Build dashboards to understand root causes to changes in metrics. Establish creative experiments to evaluate success of product feature launches. Influence how Roblox interacts with its players and its platform developers. ', 'A capable statistician. You understand the value of characterizing data by its distribution. Covariance, Bias, and Conditional Probability are concepts that you rely on every day.', 'Access raw data, and then transform it, analyze it, and render it in a compelling way--all using a custom analytics tool kit built from state-of-the-art open-source libraries.', 'Experience working with platforms offering infrastructure-as-a-service', 'Experienced in developing models', 'Ability to communicate analytics results and data storytelling to influence product teams and leaders', '4+ years of industry experience in analytics', '2+ years of experience in one or more scripting languages such as Python or R', ' Passionate about data. You have the curiosity and self-drive to continuously learn new techniques and tools to extract value from data. You have a degree in Statistics, Economics, Computer Science or other relevant field. A strong communicator. You understand that analysis must be presented in meaningful ways and engage in spirited discussions about the findings. You have the ability to explain technical concepts to non-technical audiences and discuss appropriate tradeoffs. A capable statistician. You understand the value of characterizing data by its distribution. Covariance, Bias, and Conditional Probability are concepts that you rely on every day. An expert transforming data with SQL and a scripting language such as Python or R. You’re experienced in automating efforts and crunching massive volumes of data using big data frameworks such as Spark, Hadoop or Flink. Experienced in developing models to draw insights from data. You use regression techniques, data mining, and statistical techniques to create new, scalable solutions to solve difficult business problems. You understand when to apply the appropriate methodology to maximize impact in a pragmatic fashion. ', 'Preferred Qualifications', 'A capable statistician.', 'Build dashboards to understand root causes to changes in metrics.', '2+ years of experience in fast-paced environment or fast growing company, such as the tech sector', 'You Will', 'An expert transforming data with SQL and a scripting language such as Python or R. You’re experienced in automating efforts and crunching massive volumes of data using big data frameworks such as Spark, Hadoop or Flink.', 'Passionate about data.', 'Experienced in developing models to draw insights from data. You use regression techniques, data mining, and statistical techniques to create new, scalable solutions to solve difficult business problems. You understand when to apply the appropriate methodology to maximize impact in a pragmatic fashion.', 'Establish creative experiments to evaluate success of product feature launches.']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Data Engineer,"Paradigm Information Services, Inc.","Beaverton, OR",13 hours ago,Be among the first 25 applicants,"['', 'Demonstrated experience with Microsoft SQL Server, including SSAS, SSRS, and SSIS', 'Research and implement tooling to support the build out of intelligence tools', 'Experience analyzing and optimizing SQL performance', ' Bachelor’s degree in Computer Science or equivalent industry experience  5+ years of experience in BI architecture design, data modeling, data warehouse design, ETL, and OLAP structures Demonstrated experience with Microsoft SQL Server, including SSAS, SSRS, and SSIS 5+ years of experience with the Microsoft BI delivery stack, including SharePoint, Power BI, Power View, Power Pivot, Power App, Flow, and Excel Experience working in clout environments likes Azure or AWS Experience with continuous integration/continuous delivery (CI/CD) demonstrated experience work in Python or other object-oriented languages  Experience in multidimensional database design, and SQL Server Tabular Models (Star Schema) Experience analyzing and optimizing SQL performance Must be driven and goal oriented  Must have the ability work in a fast-paced environment with shifting priorities  The ability to communicate with both technical and non-technical stakeholders Experience in Master Data Management preferred Experience in a manufacturing environment a plus Experience with Microsoft Dynamics AX and CRM a plus ', '5+ years of experience in BI architecture design, data modeling, data warehouse design, ETL, and OLAP structures', '5+ years of experience with the Microsoft BI delivery stack, including SharePoint, Power BI, Power View, Power Pivot, Power App, Flow, and Excel', 'Write high-quality code that runs smoothly in production and sets high standard to be met across the team ', 'Experience in Master Data Management preferred', 'Must have the ability work in a fast-paced environment with shifting priorities ', 'As a Senior Data Engineer, you will', 'Type', 'Experience in a manufacturing environment a plus', 'Must be driven and goal oriented ', 'About Us, Paradigm', 'Create a production data platform that supports the business', 'Experience with Microsoft Dynamics AX and CRM a plus', 'Experience working in clout environments likes Azure or AWS', 'Bachelor’s degree in Computer Science or equivalent industry experience ', 'Our skills and experience wish list includes ', 'Location', 'Experience with continuous integration/continuous delivery (CI/CD)', 'Set technical documentation standards such as data dictionaries, business glossaries, metric definitions, and other data resources', 'Create and monitor the metadata management repository and data lineage for source data, intermediate data and target repositories including common information models', 'Requirements', 'demonstrated experience work in Python or other object-oriented languages ', 'The ability to communicate with both technical and non-technical stakeholders', 'Benefits', 'Develop and implement scalable solutions to meet the business requirements ', 'Establish data architectural standards, a process for maintaining the standards and a process of monitoring compliance to those standards across the team', 'Experience in multidimensional database design, and SQL Server Tabular Models (Star Schema)', ' Develop and implement scalable solutions to meet the business requirements  Create a production data platform that supports the business Collaborate across business departments to develop long-term strategic goals for data warehousing  Research and implement tooling to support the build out of intelligence tools Write high-quality code that runs smoothly in production and sets high standard to be met across the team  Establish data architectural standards, a process for maintaining the standards and a process of monitoring compliance to those standards across the team Set technical documentation standards such as data dictionaries, business glossaries, metric definitions, and other data resources Devise a strategy for obtaining data from diverse source systems and moving it into the data ecosystem Create and monitor the metadata management repository and data lineage for source data, intermediate data and target repositories including common information models ', 'Collaborate across business departments to develop long-term strategic goals for data warehousing ', 'Devise a strategy for obtaining data from diverse source systems and moving it into the data ecosystem', 'Pay Rate']",Mid-Senior level,Full-time,Analyst,Electrical/Electronic Manufacturing,2021-02-10 11:29:29
Researcher (Part Time),Stanford Center on Philanthropy and Civil Society (Stanford PACS),"Stanford, CA",15 hours ago,Be among the first 25 applicants,"['·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Other tasks to further the studies', 'Candidates must have the following minimum qualifications:\xa0', '', '\xa0\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Ability to work under\xa0deadlines with general guidance', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Strong organizational\xa0or\xa0project/program management\xa0skills', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Graduate degree in the social sciences, PhD preferred', 'Researcher (part-time),\xa0Effective Philanthropy Learning Initiative\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience conducting qualitative social science\xa0research,\xa0and thorough understanding of scientific theory and methods', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Code and analyze data', 'Apply at:\xa0https://form.jotform.com/91565445022151', 'Apply at:', 'Time\xa0commitment: 20 hours a week (average)', 'Candidate Criteria:\xa0', 'Application\xa0Deadline:\xa0\xa0February 24, 2021', 'About\xa0EPLI\xa0and Stanford PACS:\xa0', 'The EPLI team is seeking an experienced\xa0researcher with excellent analytical and writing capabilities. The\xa0researcher will work alongside the Associate Director of\xa0Research to develop and conduct two studies. The first will examine the ways that professional training and norms influence the experiences and philanthropic behaviors of wealthy individuals. The second will investigate the ways that donors who espouse values related to social justice incorporate those values into their philanthropic practice. Specifically, the\xa0researcher will:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Draft\xa0papers revealing\xa0research\xa0results', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Conduct literature reviews', 'The\xa0Effective Philanthropy Learning Initiative\xa0(EPLI)\xa0at Stanford University’s\xa0Center on Philanthropy and Civil Society (PACS)\xa0is looking for\xa0a\xa0part-time\xa0researcher\xa0to\xa0support our\xa0research agenda, which focuses broadly\xa0on philanthropic trends and donor behavior.\xa0\xa0\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Prepare manuscripts for publication in academic and non-academic publications\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Perform\xa0participant outreach\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A commitment to EPLI’s work\xa0and mission or scholarly interests in philanthropy, wealth, the social sector and/or social inequality', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Strong\xa0writing, communication,\xa0and data analysis skills', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience conducting interviews for qualitative\xa0research projects', 'Available\xa0Position:\xa0Researcher (part-time)\xa0', 'Stanford PACS is a\xa0research center for students, scholars, and practitioners to explore and share ideas that create social change. Its primary\xa0participants are Stanford faculty, visiting scholars, postdoctoral fellows, graduate and undergraduate students, and nonprofit and foundation practitioners. As publisher of Stanford Social Innovation Review (SSIR), Stanford PACS informs policy and social innovation, philanthropic investment and nonprofit practice.\xa0PACS is also home to\xa0thought leaders tackling some of the greatest challenges facing the world today through the Digital Civil Society Lab, the Program on Democracy and the Internet, and the Global Impact Innovation Lab.\xa0', 'To begin:\xa0February or March, 2021\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0General knowledge of IRB protocols', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Assist in the determining methodological approaches to\xa0research questions', 'The\xa0Effective Philanthropy Learning Initiative\xa0(EPLI) at Stanford PACS\xa0is an interdisciplinary\xa0team\xa0working at the intersection of the social and behavioral sciences and strategic philanthropy. The lab conducts\xa0research, develops\xa0resources, and teaches with the aim of increasing donor impact.\xa0\xa0', 'Work period:\xa06-12 months, with the possibility of extension', '\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Conduct interviews', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Excellent organizational skills and demonstrated ability to complete detailed work accurately', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Participate in weekly\xa0research meeting', 'https://form.jotform.com/91565445022151', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Familiarity with qualitative coding software is a plus']",Associate,Part-time,Research,Higher Education,2021-02-10 11:29:29
Data Scientist I,The Bowen Center,"Aliso Viejo, CA",2 hours ago,Be among the first 25 applicants,"['', ' Must have experience working in cross-functional teams and ability to communicate results to non-technical audiences.', ' Familiar with Integration scenarios such as Message Queues, Kafka, File transfer integration, web services', ' Design Data Science projects that address specific business problems determined in consultation with cross-functional business partners.', 'Location ', ' Familiar with DevOPs such as Bitbucket / Bamboo / Jira / Confluence', 'CareerBuilder TIP', ' Piping and processing massive data-streams in distributed computing environments such as Hadoop to facilitate analysis. Implements batch and real-time model scoring to drive actions.', ' Identifies opportunities for continuous improvement of current algorithm solutions.', 'Recommended Skills', 'Recommended Jobs', ' Must have experience in healthcare sector, either for payer, provider, or similar organization', ' Must have experience working with enterprise data warehouses, experience working with Hadoop or other distributed or cloud-based data storage systems strongly preferred', ' Health care domain experience preferred but no mandatory', ' Experience with care and disease management strongly preferred', ' Develop sophisticated visualization of analysis output for business users.', 'Report this Job', 'Requirements', ' Graduate degree preferred', ' Develop proprietary algorithms to build customized solutions that go beyond standard industry tools and lead to innovative solutions.', 'Data Scientist', ' Must have advanced expertise with software such as Python or R as well as expertise with SQL', ' Proactively collaborates with business partners to determine identified population segments and develop actionable plans to enable the identification of patterns related to quality, use, cost and other variables.', ' Provide controllership/evaluation of all output produced to ensure established targets are met both during initial development and on an ongoing basis.', "" Bachelor's degree in Statistics, Computer Science, Mathematics, Machine Learning, Econometrics, Physics, Biostatistics or related Quantitative disciplines and 3 or more years' experience in an enterprise data science organization Graduate degree preferred Must have experience in healthcare sector, either for payer, provider, or similar organization Experience with care and disease management strongly preferred Must have advanced expertise with software such as Python or R as well as expertise with SQL Must have experience working with enterprise data warehouses, experience working with Hadoop or other distributed or cloud-based data storage systems strongly preferred Must have experience working in cross-functional teams and ability to communicate results to non-technical audiences. Familiar with Integration scenarios such as Message Queues, Kafka, File transfer integration, web services Familiar with Interfaces such as REST web services, swagger profiles, JSON payloads Experience with AWS – Develop applications in a cloud-based environment preferably in Amazon Web Services (Knowledge on ECS, Caching, Authentication) Familiar with DevOPs such as Bitbucket / Bamboo / Jira / Confluence Experience with Test driven development Work experience in Agile (Scrum) development teams required Health care domain experience preferred but no mandatory"", 'Responsibilities', "" Bachelor's degree in Statistics, Computer Science, Mathematics, Machine Learning, Econometrics, Physics, Biostatistics or related Quantitative disciplines and 3 or more years' experience in an enterprise data science organization"", ' Familiar with Interfaces such as REST web services, swagger profiles, JSON payloads', ' Work with data-sets of varying degrees of size and complexity including both structured and unstructured data.', ' Design Data Science projects that address specific business problems determined in consultation with cross-functional business partners. Work with data-sets of varying degrees of size and complexity including both structured and unstructured data. Piping and processing massive data-streams in distributed computing environments such as Hadoop to facilitate analysis. Implements batch and real-time model scoring to drive actions. Develop proprietary algorithms to build customized solutions that go beyond standard industry tools and lead to innovative solutions. Develop sophisticated visualization of analysis output for business users. Provide controllership/evaluation of all output produced to ensure established targets are met both during initial development and on an ongoing basis. Identifies opportunities for continuous improvement of current algorithm solutions. Proactively collaborates with business partners to determine identified population segments and develop actionable plans to enable the identification of patterns related to quality, use, cost and other variables.', ' Experience with AWS – Develop applications in a cloud-based environment preferably in Amazon Web Services (Knowledge on ECS, Caching, Authentication)', ' Experience with Test driven development', ' Work experience in Agile (Scrum) development teams required']",Entry level,Full-time,Engineering,Nonprofit Organization Management,2021-02-10 11:29:29
Data Scientist - Washington,"The Maven Group, LLC","Washington, DC",12 hours ago,Be among the first 25 applicants,"['', 'Must be a US Citizen with an active TS clearance with SCI eligibility and willing to submit to a counterintelligence (CI) polygraphBachelor’s degree in applicable field 10+ years of Data Science experience Understanding of open source “big data” analytic methodologies and technologiesProject Management experienceAdvanced use of Python, SQL, R or other statistical software', 'Understanding of open source “big data” analytic methodologies and technologies', '10+ years of Data Science experience ', 'Must be a US Citizen with an active TS clearance with SCI eligibility and willing to submit to a counterintelligence (CI) polygraph', 'Advanced use of Python, SQL, R or other statistical software', 'Project Management experience', 'Skills', 'Bachelor’s degree in applicable field ']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Hybrid Analyst/Data Scientist,ClearedJobs.Net,"Washington, DC",7 hours ago,Be among the first 25 applicants,"['Job Number: R0099025', '', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunkchange the world with the Data Science Bowl—the world’s premier data science for social good competitionparticipate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Experience with manipulating large datasets', 'Knowledge of contemporary data science, coding, and scripting technologies', 'change the world with the Data Science Bowl—the world’s premier data science for social good competition', 'You Have', 'Ability to obtain a security clearance', 'BA or BS degree', 'Ability to develop analytic workflows and tangible results, clearly communicate complex findings, work with diverse users/partners to rapidly solve mission-driven requests', 'Experience with national security, defense, or law enforcement data', 'Knowledge of building scripts in R or Python', 'participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Nice If You Have', 'Build Your Career', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'Experience with national security, defense, or law enforcement dataKnowledge of building scripts in R or Python', 'Experience with manipulating large datasetsKnowledge of contemporary data science, coding, and scripting technologiesAbility to develop analytic workflows and tangible results, clearly communicate complex findings, work with diverse users/partners to rapidly solve mission-driven requestsAbility to obtain a security clearanceBA or BS degree', 'Clearance', 'The Challenge']",Entry level,Temporary,Information Technology,Information Technology and Services,2021-02-10 11:29:29
Senior Design Researcher,Aquent,"Illinois, United States",,N/A,"['', 'are ready to champion those insights', '\uf0b7 Five years + experience using qualitative research methods including observation, interviewing,', '\uf0b7 Plan and facilitate hands-on tool evaluations, team workshops, and analysis sessions. These', 'business through strategic and functional findings. In this role you will be leading the research efforts of', 'use, while inspiring creativity and collaboration within your team.', 'innovation methods and design thinking', '\uf0b7 Analyze and synthesize research findings into key insights that inform opportunities for new', '\uf0b7 You are a team player, focused on bringing the team along on the journey', 'demonstrations.', '(ex: Adobe Creative Suite)', '\uf0b7 You are a strategic thinker who looks not only at the stated problem but at the space around it', 'your process', 'championing Design Research and Design Thinking, and coaching and mentoring', '\uf0b7 You are comfortable working in the ambiguous “fuzzy front end”', 'member of the team you will also provide leadership in developing new methods and approaches,', 'context. Establishing strong relationships with our end users is critical to conducting appropriate', '\uf0b7 Master’s degree preferred', 'with informing the entrepreneurial spirit of the company, influencing and inspiring the direction of the', 'trade. These plans typically include qualitative discovery research on jobsites, primary and', 'Education and Experience Requirements', '\uf0b7 Five years + experience in the fuzzy front end of product development with an understanding of', '\uf0b7 You have strong communication skills and can get your ideas across to engineers, industrial', 'The Design Research team sits within a collaborative user-centered design and', 'inspire and influence key decision makers on new solutions for the construction industry. As a senior', '\uf0b7 You have passion for the importance of user insights in the product development process and', 'highly collaborative and diverse teams of Engineers, Industrial Designers, and Product Managers to', 'Required Skills', '\uf0b7 You are proactive and open to changing research plans on the fly based on new information', 'designers, and marketers alike', 'business. You will need to communicate through well-crafted presentations and events that', '\uf0b7 Champion the importance of User-Centered Design and Design Thinking throughout the', '\uf0b7 Design and conduct multi-faceted research plans to learn about all aspects of the construction', '\uf0b7 You link everything back to our core end user’s activities and needs to provide insight for', '\uf0b7 You are comfortable facilitating conversations with multi-disciplinary teams', 'Desired Skills', '\uf0b7 Master’s or Bachelor’s degree in Psychology, Anthropology, Sociology, Industrial Design, Graphic', 'educate and inspire your team through photos, video, diagrams, storytelling and', 'secondary research exercises to understand the competitive product set, and evaluation of', 'Duties and Responsibilities', 'feature sets, functionalities and business approaches.', '\uf0b7 Mentor and coach junior researchers as appropriate.', '\uf0b7 An appreciation of how quantitative and qualitative research methodologies play best together', '\uf0b7 25-35% overnight domestic travel', 'participatory co-creation sessions result in a common ground of familiarity with a tool and its', '\uf0b7 You are curious, not just about your research topic but also the company, your co-workers, and', 'developing breakthrough products', '\uf0b7 You make non-obvious connections and revel in talking about ideas', 'company.', 'Senior Design Researcher', '\uf0b7 Experiment with new approaches and methodologies to achieve ingenious results. As a', '\uf0b7 You are proficient in Microsoft Office, with some experience with editing video and 2D software', '\uf0b7 Some familiarity with quantitative research methodologies, study design and data analysis', '\uf0b7 Experience within a design consultancy a plus', 'discovery research, co-creating solutions, and eliciting honest feedback.', 'mock-ups and preliminary concept prototypes in field.', 'technology development group focused on the fuzzy front end of product development. We are tasked', '\uf0b7 Build, grow, and maintain a network of users to understand their evolving needs and work', 'and methodologies appropriate to the work we do.', 'Design, Business, or Engineering', 'junior-level researchers as needed.', 'research group we encourage new ways of thinking, and we want you to help us build new tools', '\uf0b7 Present research findings in an engaging and concise manner to key stakeholders across the', '\uf0b7 Upon an interview, must be prepared to present on a project and its methodology', 'and contextual inquiry']",Mid-Senior level,Contract,Design,Staffing and Recruiting,2021-02-10 11:29:29
Senior Data Engineer,Opus Recruitment Solutions,United States,12 minutes ago,Be among the first 25 applicants,"['', 'Proficient in the use of industry standard tooling (i.e. the Atlassian Stack, etc.)', 'This company is a multi-award winner pioneer of hyper-local retailing, combining artificial intelligence (AI), operations research, and human-centred design to help consumer packaged goods (CPG) manufacturers and retailers generate a return on physical space investments. Currently building out a US based Data Engineering team.', 'Solid oral and written communications skills', 'Proficiency in one or more core languages: Golang, Python, SQL, Bash, Perl', 'Familiarity with design patterns and industry best practices', 'Experience with one or alternative database technologies like: ElasticSearch, Apache Cassandra, Mongo DB, Spark', 'Experience with AWS', 'Proficient in the use of databases: query and data definition', 'Proficient in the use of databases: query and data definitionProficiency in one or more core languages: Golang, Python, SQL, Bash, PerlProficient in the use of industry standard tooling (i.e. the Atlassian Stack, etc.)Competent with LinuxSolid oral and written communications skillsFamiliarity with design patterns and industry best practicesExperience with one or alternative database technologies like: ElasticSearch, Apache Cassandra, Mongo DB, SparkExperience with AWS', 'Competent with Linux']",Mid-Senior level,Full-time,Information Technology,Retail,2021-02-10 11:29:29
Machine Learning Engineer - Core Engineering,Goldman Sachs,"New York, NY",4 hours ago,Over 200 applicants,"['', ' OUR IMPACT ', ' Experience working closely with data scientists and appreciation for their unique workflow ', 'Basic Qualifications', ' 2+ years of experience in systems using machine learning and other artificial intelligence techniques ', 'About Goldman Sachs', ' 2+ years of experience in systems using machine learning and other artificial intelligence techniques  Working knowledge of more than one programming language (Python, R, Java, C++ etc.)  Experience building and operating distributed systems on the cloud  Experience working closely with data scientists and appreciation for their unique workflow  Excellent interpersonal, communication and presentation skills, both written and verbal  Ability to stay commercially focused and to always push for quantifiable commercial impact  Ability to collaborate effectively across global teams and communicate complex ideas in a simple manner ', ' GS.com/careers ', ' Excellent interpersonal, communication and presentation skills, both written and verbal ', ' Ability to stay commercially focused and to always push for quantifiable commercial impact ', ' Ability to collaborate effectively across global teams and communicate complex ideas in a simple manner ', 'YOUR IMPACT ', ' ABOUT GOLDMAN SACHS ', ' SKILLS & EXPERIENCE WE’RE LOOKING FOR ', ' Working knowledge of more than one programming language (Python, R, Java, C++ etc.) ', 'Responsibilities And Qualifications', 'How You Will Fulfill Your Potential', ' Experience building and operating distributed systems on the cloud ', ' https:// www.goldmansachs.com/careers/footer/disability-statement.html ']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Principal Data Scientist,athenahealth,"Watertown, MA",13 hours ago,Be among the first 25 applicants,"['', 'Advanced degree required in\u202fa\u202frelevant field\u202fsuch as\u202f(PhD, MS) in computer science, data science,\u202fmath,\u202fstatistics and other related disciplines.\u202f\u202f ', 'Proficiency with data analysis\u202fand modeling\u202ftools, e.g., python,\u202fJupyter, R, RStudio,\u202fand libraries like\u202ftensorflow\u202fand\u202fpyTorch.\u202f\u202f ', 'Our Culture:\u202f\u202fAt athenahealth, our employees (or “athenistas”) are committed to making healthcare smarter. Our success is dependent on the diversity, collective spirit, and contributions of our people, clients and partners. We value teamwork and believe that the strength of our team comes from supporting each other and leveraging our specialized skills. If you are looking for company that will enable you to work outside of your comfort zone to transform the healthcare ecosystem, athenahealth is the place for you.\u202f ', 'Familiarity with Linux/Unix/Shell environments, AWS experience strongly preferred\u202f\u202f\u202f\u202f ', 'Typical Qualifications:\u202f ', 'Our Vision:\u202fTo create a thriving ecosystem that delivers\u202fdelivers\u202faccessible, high-quality, and sustainable healthcare for all.\u202f\u202f', 'Our Location:\u202fThis role is based in Watertown, MA, just a few miles outside of Boston. Watertown is our Global Headquarters and our campus, the Arsenal on the Charles, is home to\u202fa number of\u202frestaurants, a local gym and large outdoor space. This office also has a cafeteria, coffee café and food trucks that rotate every day.\u202f ', 'Proficiency with\u202fPython and/or other\u202fprogramming languages, e.g.,\u202fPerl, C/C++, java, etc.\u202f\u202f ', 'About Athenahealth\u202f', 'Our Perks:\u202fAlong with health & financial benefits, our\u202fathenistas\u202fare offered a variety of perks that promote employee wellbeing such as commuter support (We were named one of the 2018 Best Workplaces for Commuters!), tuition reimbursement, collaborative work spaces and dog-friendly offices - just to name a few.\u202f ', 'Our Vision:\u202fTo create a thriving ecosystem that delivers\u202fdelivers\u202faccessible, high-quality, and sustainable healthcare for all.\u202f\u202fOur Location:\u202fThis role is based in Watertown, MA, just a few miles outside of Boston. Watertown is our Global Headquarters and our campus, the Arsenal on the Charles, is home to\u202fa number of\u202frestaurants, a local gym and large outdoor space. This office also has a cafeteria, coffee café and food trucks that rotate every day.\u202f Our Culture:\u202f\u202fAt athenahealth, our employees (or “athenistas”) are committed to making healthcare smarter. Our success is dependent on the diversity, collective spirit, and contributions of our people, clients and partners. We value teamwork and believe that the strength of our team comes from supporting each other and leveraging our specialized skills. If you are looking for company that will enable you to work outside of your comfort zone to transform the healthcare ecosystem, athenahealth is the place for you.\u202f Our Perks:\u202fAlong with health & financial benefits, our\u202fathenistas\u202fare offered a variety of perks that promote employee wellbeing such as commuter support (We were named one of the 2018 Best Workplaces for Commuters!), tuition reimbursement, collaborative work spaces and dog-friendly offices - just to name a few.\u202f ', 'Advanced degree required in\u202fa\u202frelevant field\u202fsuch as\u202f(PhD, MS) in computer science, data science,\u202fmath,\u202fstatistics and other related disciplines.\u202f\u202f 7+ years of experience including\u202f5+ years of professional experience\u202fin some or all aspects of\u202fdesigning, building, training, deploying and evaluating machine learning models in\u202fproduction software environments at scale\u202f\u202f Expertise in leveraging advanced techniques in areas such as deep learning, NLP, classification, predictive modeling, etc.\u202f\u202f Proficiency with\u202fPython and/or other\u202fprogramming languages, e.g.,\u202fPerl, C/C++, java, etc.\u202f\u202f Proficiency with data analysis\u202fand modeling\u202ftools, e.g., python,\u202fJupyter, R, RStudio,\u202fand libraries like\u202ftensorflow\u202fand\u202fpyTorch.\u202f\u202f Proficiency with relational databases (e.g., SQL,\u202fpostgres, etc.)\u202fand\u202fquery optimization\u202f\u202f Familiarity with Linux/Unix/Shell environments, AWS experience strongly preferred\u202f\u202f\u202f\u202f ', '7+ years of experience including\u202f5+ years of professional experience\u202fin some or all aspects of\u202fdesigning, building, training, deploying and evaluating machine learning models in\u202fproduction software environments at scale\u202f\u202f ', 'Expertise in leveraging advanced techniques in areas such as deep learning, NLP, classification, predictive modeling, etc.\u202f\u202f ', 'Proficiency with relational databases (e.g., SQL,\u202fpostgres, etc.)\u202fand\u202fquery optimization\u202f\u202f ', 'The Team:']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Geospatial Data Scientist,"BigBear, LLC.","Washington, DC",17 hours ago,Be among the first 25 applicants,"['', 'BigBear is an Equal Employment Opportunity Employer/Veterans/Disabled', 'Conduct research and analysis of data to produce patterns of life and other derivative data to ease the workload of analysts.Review ingest and output data for anomalies in support of QA/QC activities and continued evolution of the analytics.Coordinate derivative data requirements with analysts and other team members to ensure it meets their evolving needs.Automated population of databases with findings so that the work is discoverable by those who need it.', 'AWS', 'PythonPostgreSQLElasticsearchAWSGit', ' Education Assistance', 'Minimum Requirements', 'Our Company', ' 6 WEEKS of Paid Time Off (PTO) on top of 11 Paid Holidays!', 'Strong decision-making skills and ability to think outside of established policies to produce customer satisfaction.', 'Bachelor’s or Master’s degree in Computer Science, Engineering, a related field, or equivalent work experience', 'Git', 'Professional and applied use of Python to include Requests, SciKit Learn, Pandas, or Jupyter Notebooks.', ' Flexible Hours', 'PostgreSQL', 'Technology We Use', 'Geospatial Data Scientist', 'Review ingest and output data for anomalies in support of QA/QC activities and continued evolution of the analytics.', 'Work with large geospatial datasets to facilitate complex analytics generating actionable location intelligence.', ' 100% employer-paid for Medical, Dental, and Vision insurance (PPO)', ' Pre-paid Legal & Identity Theft Protection - optional', 'Ability to interrogate large sets of data to identify new intelligence and insights.', ' 401(k) with dollar-for-dollar match up to 6%', 'Bachelor’s or Master’s degree in Computer Science, Engineering, a related field, or equivalent work experienceAbility to interrogate large sets of data to identify new intelligence and insights.Work with large geospatial datasets to facilitate complex analytics generating actionable location intelligence.Professional and applied use of Python to include Requests, SciKit Learn, Pandas, or Jupyter Notebooks.Strong decision-making skills and ability to think outside of established policies to produce customer satisfaction.', 'Python', ' A competitive salary based on experience 401(k) with dollar-for-dollar match up to 6% 100% employer-paid for Medical, Dental, and Vision insurance (PPO) Life and Disability Insurance 100% paid for by the company 6 WEEKS of Paid Time Off (PTO) on top of 11 Paid Holidays! Education Assistance Gym Reimbursement Flexible Hours Flexible Spending Account (FSA) - optional 529 College Savings Plan - optional Pre-paid Legal & Identity Theft Protection - optional Pet Insurance - optional', 'Elasticsearch', ' Gym Reimbursement', ' Flexible Spending Account (FSA) - optional', 'Conduct research and analysis of data to produce patterns of life and other derivative data to ease the workload of analysts.', ' 529 College Savings Plan - optional', ' Pet Insurance - optional', 'Perks/Benefits', ' A competitive salary based on experience', 'Responsibilities', ' Life and Disability Insurance 100% paid for by the company', 'Job Description', 'Coordinate derivative data requirements with analysts and other team members to ensure it meets their evolving needs.', 'Automated population of databases with findings so that the work is discoverable by those who need it.', 'By submitting your interest in this job, you agree to receive text notifications with additional steps to complete your job application. You will receive up to 6 messages from the number ""63879"". Message & data rates may apply. Please refer to our privacy policy for more information.', 'Our Team']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Data Scientist,The Chemours Company,"Wilmington, DE",32 minutes ago,Be among the first 25 applicants,"['', 'OUR CULTURE', 'Tuition Reimbursement', '401(k) Match', 'PhD in computer science, math, statistics, engineering or related field', 'Chemours is an E-Verify employer', '“Great Place to Work-Certified Company”', 'In order to be qualified for this role, you must possess the following:', 'Working collaboratively across one or more agile project teams', 'Learning and Development Opportunities', 'Commuter Benefits', ' PLEASE USE A WEB BROWSER OTHER THAN INTERNET EXPLORER IF YOU ENCOUNTER ISSUES (CHROME, FIREFOX, SAFARI, ETC.)', 'We’re Chemours. a Different Kind Of Chemistry Company.', 'Evaluating new technologies that may bring additional automation and capability to machine learning pipelines', '4 years of experience with SQL and Linux', 'Organizing and leading discussions to review and compare statistical modeling / machine learning approaches, aspects of the underlying algorithms and their results', 'The responsibilities of the position include, but are not limited to, the following:', 'Employee Stock Purchase Program', ' PhD in computer science, math, statistics, engineering or related field 4 years of experience with SQL and Linux Ability to create clear and concise presentation material that drives home key points to an audience Experience with process optimization and predictive maintenance using high-fidelity, time-series, process manufacturing data ', 'Ability to speak clearly and concisely, share knowledge, and make key decisions', 'Writing data preparation and analysis routines in Python using the pandas and scikit-learn packages', '2+ years of experience in data science', 'Comprehensive Benefits Packages', 'Experience with process optimization and predictive maintenance using high-fidelity, time-series, process manufacturing data', ' Master’s degree (in computer science, math, statistics, engineering or related field) or Bachelor’s degree 2+ years of experience in data science 2+ years of experience with Python and the data science ecosystem (pandas, numpy, scikit-learn, matplotlib, etc.) Ability to speak clearly and concisely, share knowledge, and make key decisions ', 'Master’s degree (in computer science, math, statistics, engineering or related field) or Bachelor’s degree', 'Ability to create clear and concise presentation material that drives home key points to an audience', 'Chemours is an equal opportunity employer', 'Immigration sponsorship (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status) is not currently available for this position', 'Competitive Compensation', 'Providing critical input to data set design and feature engineering discussions', 'Understanding business objectives and mapping specific prediction capabilities to support desired outcomes', ' Competitive Compensation Comprehensive Benefits Packages 401(k) Match Employee Stock Purchase Program Tuition Reimbursement Commuter Benefits Learning and Development Opportunities Strong Inclusion and Diversity Initiatives Company-paid Volunteer Days ', ' Evaluating new technologies that may bring additional automation and capability to machine learning pipelines Understanding business objectives and mapping specific prediction capabilities to support desired outcomes Providing critical input to data set design and feature engineering discussions Organizing and leading discussions to review and compare statistical modeling / machine learning approaches, aspects of the underlying algorithms and their results Writing data preparation and analysis routines in Python using the pandas and scikit-learn packages Developing data products using various technologies including Docker and the Microsoft Azure ecosystem Deploying, monitoring, and maintaining data products in Kubernetes Working collaboratively across one or more agile project teams ', 'Deploying, monitoring, and maintaining data products in Kubernetes', 'Data Scientist', 'The following skill sets are preferred by the business unit', 'Strong Inclusion and Diversity Initiatives', 'Benefits', 'Candidates must be able to perform all duties listed with or without accommodation', 'Company-paid Volunteer Days', 'OUR APPROACH', 'must possess', 'Developing data products using various technologies including Docker and the Microsoft Azure ecosystem', '2+ years of experience with Python and the data science ecosystem (pandas, numpy, scikit-learn, matplotlib, etc.)', 'preferred']",Not Applicable,Full-time,Engineering,Chemicals,2021-02-10 11:29:29
Data Scientist - Load Forecasting,ISO New England Inc.,"Holyoke, MA",2 hours ago,Be among the first 25 applicants,"['', ' Lead the development of novel data pipelines, reusable software packages and visualization tools ', ' High proficiency in at least one advanced programming language (e.g., Python, R, MATLAB, SAS); familiarity with MATLAB is a plus ', ""ISO New England reserves the right to review the candidate's postings on any social networking site accessible in the public domain as part of the candidate assessment process. "", ' Passionate and innovative thinker who is excited about the latest scientific programming and machine learning trends ', ' Present complex and technical content to a diverse audience through written reports and presentations ', '  Master’s degree in Mathematics, Engineering, Computer Science, Information Systems, Business Administration or other applicable discipline   3 – 5 years of project development experience in the design, development, testing, and implementation of software solutions   High proficiency in at least one advanced programming language (e.g., Python, R, MATLAB, SAS); familiarity with MATLAB is a plus   Passionate and innovative thinker who is excited about the latest scientific programming and machine learning trends   Proficiency with peer code review, coding standards and version control practices   A self-motivated, detail-oriented, analytical problem solver   Ability to work in a team and individually  ', ' We maintain a drug-free workplace and perform pre-employment substance abuse testing. ', ' Drug Free Environment ', ' Master’s degree in Mathematics, Engineering, Computer Science, Information Systems, Business Administration or other applicable discipline ', '  Work closely with the forecasting team and other departments to facilitate the streamlining and enhancement of existing forecasting applications   Lead the development of novel data pipelines, reusable software packages and visualization tools   Research advances in machine learning tools and practices and help ensure the forecasting group remains at the forefront of emerging information technology   Present complex and technical content to a diverse audience through written reports and presentations  ', 'How You Will Make An Impact', ' Work closely with the forecasting team and other departments to facilitate the streamlining and enhancement of existing forecasting applications ', ' We are proud to be an EEO/AA employer. Applicants for employment are considered without regard to race, creed, color, citizenship, religion, sex, sexual orientation, marital status, national origin, age, disability, status as a veteran, Vietnam Era Veteran, or being a member of the Reserves or National Guard. ', 'What We Are Looking For', ' Equal Opportunity ', ' A self-motivated, detail-oriented, analytical problem solver ', ' 3 – 5 years of project development experience in the design, development, testing, and implementation of software solutions ', ' Social Networking Notice ', ' Proficiency with peer code review, coding standards and version control practices ', ' Ability to work in a team and individually ', ' Research advances in machine learning tools and practices and help ensure the forecasting group remains at the forefront of emerging information technology ']",Entry level,Full-time,Engineering,Utilities,2021-02-10 11:29:29
Aure Data Engineer,"Next Level Business Services, Inc.","Shelton, CT",2 hours ago,Be among the first 25 applicants,"['', '• Evaluate and define functional requirements for BI and DW solutions', '• 2-3 years of experience working on JAVA or other object oriented programming (Preferred).', '• 2-3 years of experience working on Power BI, Azure Analysis Services and leading other Busines Analytics tools', '• Good understanding of data oriented projects for integration and analytics is must.', '• Extensive experience working on Big data technologies such has Hive, Pig and Map Reduce are preferred.', '• Identify avenues on cost savings either by using in-house Cognizant accelerators or by building re-usable frameworks across the projects.', '• 2-3 Experience on understanding the frameworks & the data pipelines. (Mandatory)', '• Provide Business Intelligence and Data Warehousing solutions and support by leveraging project standards and leading analytics platform.', '• Analyze the data quality, data governance, compliance and other legal requirements on data storage; address all the required non-business but operational requirements during the design and build of data pipelines.', '• Build conceptual and logical models based on the functional flow of business in a scalable mode.', 'Qualifications', '• 2-3 years of experience working on Python or R. (Mandatory)', 'Job Descriptions', '• Work directly with Business leadership and Application SMEs to understand the requirement and analyzing the source to fulfill the requirement.', '• Must have experience working with Onshore / Offshore model. (Mandatory)', '• 2-3 years of experience on requirement gathering, designing dashboards, analytical use cases, reports, personalization models etc., on Azure.', '• Experience work with structured and unstructured data are must.', '• Must have experience on reading the data streams between Event Hub and Azure Service Bus with other integration systems such as Azure Data Factory etc., (Mandatory)', '• Domain: Retail/Supply chain/Pharmacy (Preferred)', '• Interpret data by building the models, charts and tables on reporting platform towards business intelligence requirements.', '• Propose and develop data solutions to enable effective decision-making, driving business objects or addressing the enterprise integration requirements.', '• 2-3 years of experience working on Spark SQL, Hive SQL, USQL. (Mandatory).', '• Expert and Key point of contact between the data analyst, data scientists, and the business/application teams.']",Mid-Senior level,Full-time,Engineering,Telecommunications,2021-02-10 11:29:29
Senior Data Engineer,meshify,"Austin, Texas Metropolitan Area",16 hours ago,66 applicants,"['', 'Expert in SQL\xa0', 'The Senior Data Engineer will be responsible for the following: ', 'Data reporting ', 'BS Computer Science or equivalent experience ', ' ', 'Preferred experience with NoSQL (Cassandra) ', 'PostgreSQL database administration Data reporting Aurora / RDS / AWS infrastructure Data pipelines and ETLs Preferred experience with NoSQL (Cassandra) ', 'The Senior Data Engineer will be held accountable for overall coordination, status, reporting and stability of Meshify data efforts of various sizes and complexity to support the software groups. Works closely with developers, DBAs, and data analysts to drive business value through a deeper understanding of data and optimizations. Utilizes accepted database processes and methodologies to ensure minimal downtime, high availability, and timely reporting of data assets. Partners with technology groups to ensure ongoing operational support for business applications. Additional responsibilities include maintaining known SQL libraries, working with business units to determine and document data decisions, and reporting and analyzing data. ', 'Educaction: ', 'Experience: ', 'Data pipelines and ETLs ', 'PostgreSQL database administration ', '5-10 years experience with PostgreSQL or similar RDMS ', 'Aurora / RDS / AWS infrastructure ', '5-10 years experience with PostgreSQL or similar RDMS Expert in SQL\xa0']",Mid-Senior level,Full-time,Engineering,Computer Software,2021-02-10 11:29:29
Data Scientist,thredUP,"Remote, OR",3 hours ago,Be among the first 25 applicants,"['', 'Create mathematical representations of the flow of items into and out of our marketplace', 'Uncover insights in our vast repository of raw data, and provide tactical guidance on how to achieve an assortment that maximizes growth and value for all marketplace participants', ""What You'll Do"", 'About ThredUP', 'Implement algorithmic solutions to drive decisions around item acceptance, item pricing, and discounting and clearance strategies for 3.5M unique items in inventory and 1.5M new items every month', '3 years of full time, professional experience', 'Well-rounded skill set in statistics, machine learning, software development, and project management', 'Advanced knowledge of SQL and Python, and experience writing code in a collaborative environment', ' The opportunity to make a massive impact & influence outcomes for our business and customers alongside passionate coworkers', 'Requirements', ' Autonomy. The ability to make, own, and carry out decisions', 'Prior experience working with marketplaces and/or a relevant background in economics or operations research is a plus', 'Innate curiosity and drive to find insights that unlock new growth or efficiency - you can’t help but dig in and seek the truth', 'We believe diversity, inclusion and belonging is key for our team.', 'Drive the strategy for promotions, merchandising campaigns, and sales, and investigate their effect on inventory and buyer mix', 'Implement algorithmic solutions to drive decisions around item acceptance, item pricing, and discounting and clearance strategies for 3.5M unique items in inventory and 1.5M new items every monthUncover insights in our vast repository of raw data, and provide tactical guidance on how to achieve an assortment that maximizes growth and value for all marketplace participantsDevelop the algorithms and data strategy that power search and discovery, allowing buyers to seamlessly find items they love in our vast assortmentDevelop rigorous forecasting systems to bring predictability to our planning around inventory growth and economicsCreate mathematical representations of the flow of items into and out of our marketplaceDrive the strategy for promotions, merchandising campaigns, and sales, and investigate their effect on inventory and buyer mixParticipate in our knowledge-sharing culture by spreading best practices and learnings from prior experiences, helping the entire team level up', 'At least 3 years of full time, professional experience in data analytics, data science, or software engineering roles', 'What We Offer', ' Flexible PTO', ' Competitive salary, equity and full benefits (health/dental/vision insurance & 401k)', 'Develop rigorous forecasting systems to bring predictability to our planning around inventory growth and economics', 'Ability to effectively work with business leads; strong cross-functional communication skills that help push projects forward and encourage the development of new collaborations', 'At least 3 years of full time, professional experience in data analytics, data science, or software engineering rolesAbility to effectively work with business leads; strong cross-functional communication skills that help push projects forward and encourage the development of new collaborationsInnate curiosity and drive to find insights that unlock new growth or efficiency - you can’t help but dig in and seek the truthWell-rounded skill set in statistics, machine learning, software development, and project managementAdvanced knowledge of SQL and Python, and experience writing code in a collaborative environmentPrior experience working with marketplaces and/or a relevant background in economics or operations research is a plus', 'Participate in our knowledge-sharing culture by spreading best practices and learnings from prior experiences, helping the entire team level up', 'Develop the algorithms and data strategy that power search and discovery, allowing buyers to seamlessly find items they love in our vast assortment']",Entry level,Full-time,Engineering,Marketing and Advertising,2021-02-10 11:29:29
Sr Data Engineer (201707),Bull City Talent Group,"Memphis, TN",,N/A,"['Strong programming skills in R / Python or equivalent tools for exploratory and predictive analytics', 'The Senior Data Engineer will create and implement strategies directed at acquiring data from new and existing sources, build a modern data platform and promote the development of insights and data driven decisions using our Operational, Sales and Marketing data to improve Business Process efficiency and Product quality. Must have Oracle DW, Teradata, and/or Netezza experience and migrated to redshift or snowflake.', 'Ability to devise and deliver persuasive presentations, based on data-driven insights and facts, to gain support for business strategies and/or initiatives', 'Design and implement predictive & prescriptive data models', 'Applicants must be authorized to work in the United States on a full-time basis', 'Solution-oriented with an ability to identify and assess risk and prioritize competing demands', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing data infrastructure for greater scalability', ""Bachelor's degree from an accredited four-year college or university in related field4+ years working on Data Platforms2+ years on a Modern Data Platform. (AWS, Azure, Snowflake etc.)Experience in evaluating, designing, and implementing data platforms and data pipelines to scale and automate extraction of data from multiple internal and external sourcesExperience articulating business questions and using quantitative techniques and driving insights for businessSolution-oriented with an ability to identify and assess risk and prioritize competing demandsStrong storytelling skills to help decision-makers see the big picture and act on the results of analysisAbility to devise and deliver persuasive presentations, based on data-driven insights and facts, to gain support for business strategies and/or initiativesCurious, independent mindset and attitude – you explore new technological & methodical options independentlyKnowledge of professional software engineering practices and best practices for the full software development life cycle (Waterfall and Agile), including coding standards, code reviews, source control management, build processes, testing, and operationsStrong programming skills in R / Python or equivalent tools for exploratory and predictive analyticsProficiency in data transformations, handling missing data, feature engineering, regression, classification, and clustering analysisDeep technical understanding of machine learning (linear models, decision trees, boosting, random forest, k-means, ensemble models etc.)Experience in relational databases such as Oracle and proficiency with SQLExperience working with structured, semi structured (JSON, XML) & unstructured data types (text, files etc.)Familiarity with Git, NoSql databases, Spark, TensorFlowApplicants must be authorized to work in the United States on a full-time basis"", 'Troubleshoot data quality issues - identifying root cause/system & documentation/communication of resolution', 'Strong storytelling skills to help decision-makers see the big picture and act on the results of analysis', 'BCTG’s direct client is looking for a permanent Senior Data Engineer. This position can be in Memphis, TN, Chambersburg, PA, Bend Or, New York, NY, Marlborough, MA, Irvine, CA , or El Paso, TX. Client will sponsor for the right candidate.', 'Build strong relationships with the different departments, teams, and support functions to understand the business needs.', 'Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies.', 'Develops and implements effective/strategic business solutions through research and analysis of data and business processes', ""Bachelor's degree from an accredited four-year college or university in related field"", 'Collaborate and knowledge share with internal stakeholders to ensure single source of truth for all data', 'Explore/Analyze Company’s Operational data and find correlation between different business process to improve and/or recommend changes to Business Processes', 'Experience in evaluating, designing, and implementing data platforms and data pipelines to scale and automate extraction of data from multiple internal and external sources', 'Deep technical understanding of machine learning (linear models, decision trees, boosting, random forest, k-means, ensemble models etc.)', 'Deliver value-add solutions at the speed of business', 'Familiarity with Git, NoSql databases, Spark, TensorFlow', ' Responsibilities ', 'requirements for consideration', 'Ensure the effective collection, organization and distribution of data, from a variety of data sources', 'Experience articulating business questions and using quantitative techniques and driving insights for business', 'Create and maintain excellent data documentation that allows the data to be understood (Metadata) and leveraged for additional use.', 'Knowledge of professional software engineering practices and best practices for the full software development life cycle (Waterfall and Agile), including coding standards, code reviews, source control management, build processes, testing, and operations', 'Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions.', 'Determines business information needs, identifies system requirements, KPIs, and methods for the data warehouse to assist with operational and strategic planning.', 'Gather business needs and translating into analytical problems', '2+ years on a Modern Data Platform. (AWS, Azure, Snowflake etc.)', 'Design and Develop Data platforms and pipelinesEvaluate gaps in existing data platform and aid the implementation of a modern data platformIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing data infrastructure for greater scalabilityEnsure the effective collection, organization and distribution of data, from a variety of data sourcesBuild processes supporting data transformation, data structures, metadata, dependency and workload managementGather business needs and translating into analytical problemsTranslate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies.Create and maintain excellent data documentation that allows the data to be understood (Metadata) and leveraged for additional use.Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions.Design and implement predictive & prescriptive data modelsAnalyze data to find actionable insights and “tell the story” of our business as well as help deliver solutions to any business needs using machine learning, text-mining/NLP to extract insights from structured and unstructured data to assist in new product development, improving the quality of the products, improving customer service experienceExplore/Analyze Company’s Operational data and find correlation between different business process to improve and/or recommend changes to Business ProcessesDevelop programs to assist business in improving Marketing strategy, Product Pricing and customer retentionCreate and implement customer centric solutionsBuild strong relationships with the different departments, teams, and support functions to understand the business needs.Collaborate and knowledge share with internal stakeholders to ensure single source of truth for all dataConduct written and verbal presentations to share insights and recommendations to audiences of varying levels of technical sophisticationDetermines business information needs, identifies system requirements, KPIs, and methods for the data warehouse to assist with operational and strategic planning.Develops and implements effective/strategic business solutions through research and analysis of data and business processesTroubleshoot data quality issues - identifying root cause/system & documentation/communication of resolutionDeliver value-add solutions at the speed of business', 'Develop programs to assist business in improving Marketing strategy, Product Pricing and customer retention', '4+ years working on Data Platforms', 'Experience working with structured, semi structured (JSON, XML) & unstructured data types (text, files etc.)', 'Curious, independent mindset and attitude – you explore new technological & methodical options independently', 'Experience in relational databases such as Oracle and proficiency with SQL', '*This position is temporarily eligible for Work from Home until our offices reopen. Once offices reopen, this position is not eligible to be Work from Home, and you will be required to report to the office Monday-Friday.', 'Proficiency in data transformations, handling missing data, feature engineering, regression, classification, and clustering analysis', 'Design and Develop Data platforms and pipelines', 'Create and implement customer centric solutions', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'Analyze data to find actionable insights and “tell the story” of our business as well as help deliver solutions to any business needs using machine learning, text-mining/NLP to extract insights from structured and unstructured data to assist in new product development, improving the quality of the products, improving customer service experience', 'Conduct written and verbal presentations to share insights and recommendations to audiences of varying levels of technical sophistication', 'Evaluate gaps in existing data platform and aid the implementation of a modern data platform']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2021-02-10 11:29:29
Data Scientist I,Levi Strauss & Co.,"San Francisco, CA",3 hours ago,Over 200 applicants,"['', 'Required Technical Skills', ' EOE M/F/Disability/Vets ', ' 401K match : $1.25 for every $1.00 you contribute up to the first 6% of pay you save.', 'Current LS&Co Employees, apply via your Workday account.', ' 2+ years of experience with data visualization tools (D3.js, R Shiny, Looker, Tableau or similar).', ' 3+ years of experience deploying Machine Learning algorithms in a production environment.', '2+ years of SQL development skills writing complex queries.', ' 2+ years of prior experience in a business-focused Data Scientist role', 'Assess the potential usefulness and validity of new ML and DL approaches and data sources.', 'Experience in Reinforcement Machine Learning is a huge plus.', 'Experience working with Linux/UNIX shell virtual machines.', ' Actively and continuously contribute to our data science culture and strategy.', 'Partner with stakeholders across the organization to identify opportunities to use our data to serve our disruptive planning strategy.Build complex predictive models using Machine Learning and Deep Learning algorithms to substantially improve our planning process and contribute to business growth.Assess the potential usefulness and validity of new ML and DL approaches and data sources.Manipulate large databases with structured and unstructured (text, images, videos..) data from our sources.develop proof-of-concept prototypes to prove out hypotheses.Manage experience with data, including complex queries, exploratory data analysis, data visualization, advanced modeling and communication of applicable insights to audiences at varying levels of technical sophistication. Actively and continuously contribute to our data science culture and strategy.', ' 3+ years of experience with Python, R, Java, C++, Julia, or another widely used open-source programming language.', ' Experience in Data Engineering and DevOps would be a nice to have. ', 'Manipulate large databases with structured and unstructured (text, images, videos..) data from our sources.', ' 401K match : $1.25 for every $1.00 you contribute up to the first 6% of pay you save.Five hours of paid volunteer time per month with nonprofit organizationsProduct discount of 50% off regular-price merchandise', 'LOCATION', 'Experience working with cloud environments: AWS and/or Azure and/or GCP cloud platforms.', ' 2+ years of hands-on experience analyzing data, drawing conclusions, defining recommended actions, building predictive models, and visualizing results.', 'Master’s/ PhD degree (computer science, applied mathematics, applied statistics, data science, or similar)', 'Partner with stakeholders across the organization to identify opportunities to use our data to serve our disruptive planning strategy.', 'Experience using data access tools and building web application and simple UI solutions.', 'develop proof-of-concept prototypes to prove out hypotheses.', 'FULL TIME/PART TIME', ' 2+ years’ experience in experience in Deep Learning engineering.', 'Familiarity with distributed systems (Docker, Kubernetes, Kafka , Spark …)', ' 2+ years of prior experience in a business-focused Data Scientist role 2+ years of hands-on experience analyzing data, drawing conclusions, defining recommended actions, building predictive models, and visualizing results.2+ years of SQL development skills writing complex queries. 3+ years of experience with Python, R, Java, C++, Julia, or another widely used open-source programming language. 3+ years of experience deploying Machine Learning algorithms in a production environment. 2+ years’ experience in experience in Deep Learning engineering.Experience in Reinforcement Machine Learning is a huge plus. 2+ years’ experience with big data processing tools such as MapReduce, PIG, and HIVE, Hadoop, with considerable experience working with Spark. 2+ years of experience working with SQL and Non-SQL databases. 2+ years of experience with data visualization tools (D3.js, R Shiny, Looker, Tableau or similar).Experience working with cloud environments: AWS and/or Azure and/or GCP cloud platforms.Experience working with Linux/UNIX shell virtual machines.Familiarity with distributed systems (Docker, Kubernetes, Kafka , Spark …)Experience using data access tools and building web application and simple UI solutions. Experience in Data Engineering and DevOps would be a nice to have. ', ' 2+ years of experience working with SQL and Non-SQL databases.', 'Build complex predictive models using Machine Learning and Deep Learning algorithms to substantially improve our planning process and contribute to business growth.', 'Manage experience with data, including complex queries, exploratory data analysis, data visualization, advanced modeling and communication of applicable insights to audiences at varying levels of technical sophistication.', 'Product discount of 50% off regular-price merchandise', ' Current LS&Co Employees, apply via your Workday account.', 'Master’s/ PhD degree (computer science, applied mathematics, applied statistics, data science, or similar)Overall 2+ years (with Bachelor’s or Master’s) or 1+ years (for PhDs) relevant (hands-on) professional experience in data science, and applied statistics, and computer science, and machine learning engineering in the field of consumer goods and tech industry and retail industry.', 'Five hours of paid volunteer time per month with nonprofit organizations', 'Job Description', 'Overall 2+ years (with Bachelor’s or Master’s) or 1+ years (for PhDs) relevant (hands-on) professional experience in data science, and applied statistics, and computer science, and machine learning engineering in the field of consumer goods and tech industry and retail industry.', ' 2+ years’ experience with big data processing tools such as MapReduce, PIG, and HIVE, Hadoop, with considerable experience working with Spark.', ""Here's a Small Snapshot""]",Not Applicable,Full-time,Engineering,Apparel & Fashion,2021-02-10 11:29:29
Senior Research Scientist,Pelichem Associates,"Addison, TX",12 hours ago,Be among the first 25 applicants,[''],Associate,Full-time,Other,Automotive,2021-02-10 11:29:29
Data Scientist,Booz Allen Hamilton,"Alexandria, VA",10 hours ago,Be among the first 25 applicants,"['', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunkchange the world with the Data Science Bowl—the world’s premier data science for social good competitionparticipate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Experience with programming languages such as Python or Java', 'Experience with data visualization and knowledge object creation a plus', 'Experience with data gathering and analysis of large data sets', 'Experience with Data Science in R or Python', 'change the world with the Data Science Bowl—the world’s premier data science for social good competition', 'Experience with Big Data programming technologies, including Hadoop, Spark, MongoDB, MapReduce, Accumulo, Cassandra, HBase, Mahout, Pig, and Hive-BA', 'Experience with Data Science in R or PythonExperience with Machine Learning libraries, such as Caffe, Keras, MxNet, PyTorch, or TensorFlowExperience with Cloud Computing services, including Amazon AWS, Google Cloud, Microsoft Azure, or equivalentExperience with Big Data programming technologies, including Hadoop, Spark, MongoDB, MapReduce, Accumulo, Cassandra, HBase, Mahout, Pig, and Hive-BAExperience with data visualization and knowledge object creation a plusExperience with GEOINT data, formats, structures, and standardsPossession of excellent oral and written communication skillsBS degree in Statistics, Mathematics, Physics or Computer Science preferred', 'Experience with Cloud Computing services, including Amazon AWS, Google Cloud, Microsoft Azure, or equivalent', 'Active TS/SCI clearance', 'You Have', 'BA or BS degree', 'Experience in an analytics field, including data analytics, data science, advanced mathematics or statisticsExperience with data gathering and analysis of large data setsExperience with programming languages such as Python or JavaAbility to exhibit flexibility, initiative, and innovation in dealing with ambiguous, fast-paced situationsActive TS/SCI clearanceBA or BS degree', 'Job Number: R0083390', 'Experience with Machine Learning libraries, such as Caffe, Keras, MxNet, PyTorch, or TensorFlow', 'Experience in an analytics field, including data analytics, data science, advanced mathematics or statistics', 'participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Possession of excellent oral and written communication skills', 'Nice If You Have', 'Build Your Career', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'Ability to exhibit flexibility, initiative, and innovation in dealing with ambiguous, fast-paced situations', 'Experience with GEOINT data, formats, structures, and standards', 'Clearance', 'BS degree in Statistics, Mathematics, Physics or Computer Science preferred', 'The Challenge']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Principal Data Scientist (Clinical Data Management),Premier Research,"Nashville, TN",6 hours ago,Be among the first 25 applicants,"['', ""Minimum of a Bachelor's Degree, preferably in Science, Engineering, or Math, or RN, RPh, or LPN certification preferred along with a minimum of 8 years of mastery in data management/science/analytics/informatics and at least 3 years leading studiesProven expertise in ICH/GCP and/or ISO14155 requirements; knowledge of site and institution specific contract requirements; clinical trials support or pharmaceutical industry experience; working knowledge of medical terminology and experience with clinical research; working knowledge of FDA Guidance Documents and clinical monitoring procedures; proficient in the development and review of Informed Consent Form templatesUnderstanding and experience at least one Database Management System (e.g., Medidata Rave, DataLabs EDC, Oracle RDC or Inform, etc.); knowledge of web based communication tools for conferencesKnown for being customer-focused in approach to work and communications with the ability to professionally Interact with site, clients, vendors and other functional areas; strong verbal and written communication and negotiation skillsMaintains a positive, results-oriented work environment; excellent team player, collaborative and able to build an effective team.Excellent organizational and time-management skills, able to prioritize work to meet deadlines; ability to multitask and work effectively in a fast-paced environment with changing priorities; accountable, dependable and strongly commited."", 'Oversee the preparation of data management plans, data entry guidelines, data management reports and other documents required for preparing and completing databasesReview draft protocols and CRFs for potential data collection and representation, database structure or data entry problems, and provides feedback to the project team; Reviews CRFs, data listings, and database to ensure all captured data follow the rules outlined by the protocol and data management plan; track CRFs as they are processed through the Data Management departmentGenerate queries to appropriate internal or external personnel (investigational sites, vendors, Clinical Research Associates, client representatives) to resolve problematic data identified during every aspect of the data management processReview responses to queries for appropriateness, resolves any discrepancies and modifies the database accordinglyMentor Data Coordinators and junior LeadsSupport new business opportunities, including contribution to study budgets, proposals, and bid defense meetings', 'Understanding and experience at least one Database Management System (e.g., Medidata Rave, DataLabs EDC, Oracle RDC or Inform, etc.); knowledge of web based communication tools for conferences', 'Support new business opportunities, including contribution to study budgets, proposals, and bid defense meetings', 'Excellent organizational and time-management skills, able to prioritize work to meet deadlines; ability to multitask and work effectively in a fast-paced environment with changing priorities; accountable, dependable and strongly commited.', 'You’ll Need This To Be Considered', 'Generate queries to appropriate internal or external personnel (investigational sites, vendors, Clinical Research Associates, client representatives) to resolve problematic data identified during every aspect of the data management process', 'Oversee the preparation of data management plans, data entry guidelines, data management reports and other documents required for preparing and completing databases', 'Maintains a positive, results-oriented work environment; excellent team player, collaborative and able to build an effective team.', 'Known for being customer-focused in approach to work and communications with the ability to professionally Interact with site, clients, vendors and other functional areas; strong verbal and written communication and negotiation skills', 'Mentor Data Coordinators and junior Leads', ""Minimum of a Bachelor's Degree, preferably in Science, Engineering, or Math, or RN, RPh, or LPN certification preferred along with a minimum of 8 years of mastery in data management/science/analytics/informatics and at least 3 years leading studies"", 'Proven expertise in ICH/GCP and/or ISO14155 requirements; knowledge of site and institution specific contract requirements; clinical trials support or pharmaceutical industry experience; working knowledge of medical terminology and experience with clinical research; working knowledge of FDA Guidance Documents and clinical monitoring procedures; proficient in the development and review of Informed Consent Form templates', 'What You’ll Be Doing', 'Description', 'Review responses to queries for appropriateness, resolves any discrepancies and modifies the database accordingly', 'Principal Data Scientist', 'Review draft protocols and CRFs for potential data collection and representation, database structure or data entry problems, and provides feedback to the project team; Reviews CRFs, data listings, and database to ensure all captured data follow the rules outlined by the protocol and data management plan; track CRFs as they are processed through the Data Management department', 'Position at Premier Research Group Limited']",Entry level,Full-time,Engineering,Biotechnology,2021-02-10 11:29:29
"Data Scientist, Marketing Analytics",Creative Business Resources (CBR),"New York, NY",13 hours ago,Be among the first 25 applicants,"['', 'Media Strategy Optimization, A/B Testing', 'Experience in deploying analytics projects in a cloud environment (GCP, AWS, Azure)', 'dbt and/or Airflow experience', 'Basic understanding of deep learning techniques', 'Dog friendly office', 'Proficient in SQL and Python/R', 'Linear TV attribution modeling experience', ' Base salary DOE Unlimited vacation policy Bonus opportunities Monthly Phone Stipend Comprehensive Medical, Dental, and Vision insurance options Dog friendly office Full Time Remote Work options', ' Marketing Mix Modeling Multi-channel Attribution (Linear TV, OTT, etc.) Media Strategy Optimization, A/B Testing Customer Lifetime Value (CLV/LTV)  ', 'Working knowledge of Tableau, Data Studio or other visualization software', 'We offer a competitive salary and benefits based on ability level including ', 'Strong marketing analytics foundation (Marketing Mix Modeling, Customer Lifetime Value, Attribution)', 'About You', 'Monthly Phone Stipend', 'Experience with data pipelining, from data preparation to analysis to deployment', 'Comprehensive Medical, Dental, and Vision insurance options', 'About Us ', 'Requirements', 'Unlimited vacation policy', 'Benefits', ' Strong marketing analytics foundation (Marketing Mix Modeling, Customer Lifetime Value, Attribution) Proficient in SQL and Python/R Experience with data pipelining, from data preparation to analysis to deployment Advanced knowledge of machine learning techniques (supervised and unsupervised) Basic understanding of deep learning techniques Strong attention to detail and ability to adapt to team norms Excellent verbal and written communication  ', 'Customer Lifetime Value (CLV/LTV) ', 'Responsibilities', 'Marketing Mix Modeling', 'Multi-channel Attribution (Linear TV, OTT, etc.)', 'Excellent verbal and written communication ', 'Bonus opportunities', 'Base salary DOE', 'Strong attention to detail and ability to adapt to team norms', 'Advanced knowledge of machine learning techniques (supervised and unsupervised)', 'Full Time Remote Work options', ' Linear TV attribution modeling experience Working knowledge of Tableau, Data Studio or other visualization software Experience in deploying analytics projects in a cloud environment (GCP, AWS, Azure) dbt and/or Airflow experience ']",Associate,Full-time,Analyst,Marketing and Advertising,2021-02-10 11:29:29
Data Engineer,Spotify,"New York, NY",6 hours ago,Over 200 applicants,"['', 'You know how to work with high volume heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, and CassandraYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, or something we didn’t list- but not just Pig/Hive/BigQuery/other SQL-like abstractionsYou are knowledgeable about data modeling, data access, and data storage techniquesYou understand the value of teamwork within teams, are excellent communicators, and can build relationships with a diverse set of partnersMachine Learning experience is a plusExperience with data ingestion via API and/or web scraping/crawling (e.g. Selenium, BeautifulSoup) at scale preferredExperience with Google Cloud Platform', 'You are knowledgeable about data modeling, data access, and data storage techniques', 'Experience with Google Cloud Platform', 'Machine Learning experience is a plus', 'Demonstrate standard methodologies in continuous integration and delivery', 'Ingest and aggregate data from both internal and external data sources to build our extraordinary datasetsBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Storm, or Spark on the Google Cloud PlatformDemonstrate standard methodologies in continuous integration and deliveryHelp drive optimization, testing, and tooling to improve data qualityCollaborate with other engineers, ML specialists, and partners, taking learning and leadership opportunities that will arise every dayWork in cross functional agile teams to continuously experiment, iterate, and deliver on new product objectives.Work from our offices in New York, with some travel to other Spotify office locations', 'Work in cross functional agile teams to continuously experiment, iterate, and deliver on new product objectives.', 'Work from our offices in New York, with some travel to other Spotify office locations', 'Help drive optimization, testing, and tooling to improve data quality', 'You know how to work with high volume heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, and Cassandra', 'Collaborate with other engineers, ML specialists, and partners, taking learning and leadership opportunities that will arise every day', 'Who You Are', 'You have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, or something we didn’t list- but not just Pig/Hive/BigQuery/other SQL-like abstractions', 'What You Will Do', 'Build large-scale batch and real-time data pipelines with data processing frameworks like Scio, Storm, or Spark on the Google Cloud Platform', 'Ingest and aggregate data from both internal and external data sources to build our extraordinary datasets', 'Experience with data ingestion via API and/or web scraping/crawling (e.g. Selenium, BeautifulSoup) at scale preferred', 'You understand the value of teamwork within teams, are excellent communicators, and can build relationships with a diverse set of partners']",Not Applicable,Full-time,Information Technology,Marketing and Advertising,2021-02-10 11:29:29
Data Scientist,Known,"Boston, MA",15 hours ago,35 applicants,"['', 'Self-motivated and exhibits initiative', 'Paid parental leave', 'Superb written and verbal communication and presentation skills', 'Collaborative attitude', 'Experience using Machine Learning', ' Responsible for the day-to-day management of the media spend you’re responsible for, including ideation on quantitative approaches for driving value, monitoring metrics, and troubleshooting issues Design and execute every technical aspect of an engagement, including machine learning, analytics, and visualization  Develop new techniques (e.g., ML models, optimization algorithms, and automation) to optimize KPIs and improve Known IP Discuss and defend your analyses and ensure that it directly meets the client’s needs.  ', ' Unlimited paid time off Equity plan with profit sharing Annual bonuses Vacation and birthday cash bonuses Generous medical plan Paid parental leave Company-paid cell phone service In-house barista plus cold brew on tap! Fully stocked kitchen Weekly company lunches', 'Key Responsibilities', 'Experience utilizing Python (or similar language) and SQL', 'Ability to articulate clearly and communicate a “data story”', 'Experience multi-tasking in a fast-paced environment', 'Company-paid cell phone service', ' A Masters or PhD from a well-regarded college or university. STEM degrees are preferred  5+ years of hands-on experience doing quantitative analysis, predictive modeling, optimization and/or statistics Some professional experience in marketing, advertising or media is a plus ', 'An ability to translate business challenges into quantitative problems, and solve them by whatever means necessary, which may not always be strict machine learning', 'A desire to work on advertising challenges that require flexibility in approach -- everything from on-the-fly analytics to statistics, big data, machine learning, and mathematical algorithms ', ' Productionalize workflows and contributing code to our Known repos (I don’t know what this means) Operate existing software infrastructure to traffic, evaluate performance, and analyze media May mentor others ', 'Annual bonuses', 'Ability to build a presentation deck', 'Equity plan with profit sharing', 'Unlimited paid time off', 'A Masters or PhD from a well-regarded college or university. STEM degrees are preferred ', 'Operate existing software infrastructure to traffic, evaluate performance, and analyze media', 'Some professional experience in marketing, advertising or media is a plus', 'Weekly company lunches', 'Ability to think strategically, analytically, and proactively about diverse business problems', 'A commitment to managing the quality & accuracy of analytics, ensuring high standards with your and others’ work', 'Desire to mentor and teach others', 'Generous medical plan', 'Responsible for the day-to-day management of the media spend you’re responsible for, including ideation on quantitative approaches for driving value, monitoring metrics, and troubleshooting issues', 'Productionalize workflows and contributing code to our Known repos (I don’t know what this means)', ' Experience utilizing Python (or similar language) and SQL Experience using Machine Learning Understanding of statistics/science/evidence/experimentation Proficient with Microsoft office suite of products (Excel, Word, PowerPoint) Ability to build and maintain external relationships (clients, vendors, etc.) Superb written and verbal communication and presentation skills Ability to articulate clearly and communicate a “data story” Ability to build a presentation deck A desire to work on advertising challenges that require flexibility in approach -- everything from on-the-fly analytics to statistics, big data, machine learning, and mathematical algorithms  An ability to translate business challenges into quantitative problems, and solve them by whatever means necessary, which may not always be strict machine learning A willingness to learn foundational knowledge and skills rapidly An ability to think strategically, analytically, and proactively about diverse business problems A commitment to managing the quality & accuracy of analytics, ensuring high standards with your and others’ work Experience multi-tasking in a fast-paced environment ', 'The Opportunity', ' Build presentations and present work to clients with the ability to articulate results ', 'A willingness to learn foundational knowledge and skills rapidly', 'Here Are Just Some Examples Of What We Offer', 'Develop new techniques (e.g., ML models, optimization algorithms, and automation) to optimize KPIs and improve Known IP', 'May mentor others', 'Discuss and defend your analyses and ensure that it directly meets the client’s needs. ', 'Willing & able to learn quickly', 'Fully stocked kitchen', 'Ability to prioritize time, work and effort while multitasking on multiple projects', 'Understanding of statistics/science/evidence/experimentation', 'An ability to think strategically, analytically, and proactively about diverse business problems', ' Ability to prioritize time, work and effort while multitasking on multiple projects Desire to mentor and teach others Ability to think strategically, analytically, and proactively about diverse business problems Collaborative attitude Self-motivated and exhibits initiative Willing & able to learn quickly Abundant intellectual curiosity and integrity Collaborative attitude ', 'Ability to build and maintain external relationships (clients, vendors, etc.)', 'Design and execute every technical aspect of an engagement, including machine learning, analytics, and visualization ', 'In-house barista plus cold brew on tap!', 'Who You Are And What You Have', 'Vacation and birthday cash bonuses', '5+ years of hands-on experience doing quantitative analysis, predictive modeling, optimization and/or statistics', 'Abundant intellectual curiosity and integrity', 'About Known', 'Competencies', 'Skills, Abilities, And Knowledge', 'Proficient with Microsoft office suite of products (Excel, Word, PowerPoint)', 'Build presentations and present work to clients with the ability to articulate results']",Entry level,Full-time,Engineering,Marketing and Advertising,2021-02-10 11:29:29
Data Engineer II - Wild Rift,Riot Games,"Los Angeles, CA",29 minutes ago,41 applicants,"['', ' You will transform raw data to datasets that end-users can easily query.', ""It’s our policy to provide equal employment opportunity for all applicants and members of Riot Games, Inc. Riot Games makes reasonable accommodations for handicapped and disabled Rioters and does not unlawfully discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, handicap, veteran status, marital status, criminal history, or any other category protected by applicable federal and state law, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance relating to an applicant's criminal history (LAMC 189.00)."", '  You will partner with researchers, analysts, and advisers to ensure the time they spend transforming data to answer their questions are minimal.  You will transform raw data to datasets that end-users can easily query.  You will work with the data scientists and engineers on your team to ship data powered products to players.  You will advocate for best practices and identify opportunities for the team to improve the sustainability of our portfolio. ', ' Experience with Databricks, Spark, Airflow, Terraform, or Ansible.', 'Desired Qualifications', ' 1+ years of experience working directly with end data users and meeting their requirements.', ' Proficiency in data structures and algorithms.', ' 3+ years of programming experience in SQL and Python or Java.', ' You will advocate for best practices and identify opportunities for the team to improve the sustainability of our portfolio.', 'Our Perks', ' You will partner with researchers, analysts, and advisers to ensure the time they spend transforming data to answer their questions are minimal.', ' Experience mentoring others.', ' 1+ years of experience leading the technical direction of your projects.', ' You will work with the data scientists and engineers on your team to ship data powered products to players.', '  Experience developing an enterprise data warehouse spanning across multiple teams.  Experience working collaboratively in a team environment.  Experience mentoring others.  Experience with Databricks, Spark, Airflow, Terraform, or Ansible.  Fluency in Mandarin. ', ' 1+ years of experience with cloud service providers (AWS, GCP).', ' 3+ years of experience developing data pipelines and data modeling.', 'Responsibilities', 'Required Qualifications', ' Experience working collaboratively in a team environment.', '  3+ years of programming experience in SQL and Python or Java.  3+ years of experience developing data pipelines and data modeling.  1+ years of experience with cloud service providers (AWS, GCP).  1+ years of experience working directly with end data users and meeting their requirements.  1+ years of experience leading the technical direction of your projects.  Proficiency in data structures and algorithms. ', ' Experience developing an enterprise data warehouse spanning across multiple teams.', ' Fluency in Mandarin.']",Not Applicable,Full-time,Information Technology,Computer Games,2021-02-10 11:29:29
Senior Researcher,N/A,"Milford, MI",22 hours ago,Be among the first 25 applicants,[''],Associate,Full-time,Research,N/A,2021-02-10 11:29:29
Researcher in Physiological Modeling and Closed-Loop Medical Systems (Biomedical/Electrical/Mechanical Engineer),FDA,"Montgomery County, MD",1 hour ago,Be among the first 25 applicants,"['', 'The candidate will join a research team studying science questions to advance new patient monitoring and physiological closed-loop controlled medical devices. The candidate will work closely with other team members on a project to study and determine best practices in the design, evaluation, and use of patient-specific models (e.g., models of heart rate variability) for medical device testing. Candidates will be involved with and learn about developing computational modeling and simulation methods for testing physiological closed-loop controlled medical devices, writing and maintaining software documentation, developing scientific manuscripts, and contributing to future research study design. Strong communication and writing skills are required.', 'Desired Skills & Experience', 'Strong technical background and experience in signal processing, system identification, control system design and analysis, stochastic control of physiological variables, computational modeling and simulations of physiological and/or medical device systems;', 'PhD or MS degree in biomedical engineering, electrical engineering, mechanical engineering, or a related field with a strong interest in a biomedical research career;', 'An ORISE Research Fellow position for a biomedical / electrical / mechanical engineer is available in\xa0the Division of Biomedical Physics, Office of Science and Engineering Laboratories at the U.S. Food and Drug Administration, located in Silver Spring. MD. Funding is currently available for up to 1 year with the possibility of extension. The candidate must have received his / her most recent degree within 5 years of the start date and be eligible to work in the U.S. All candidates must meet applicable security requirements which include a background check and a minimum of 3 out of the past 5 years’ residency status in the US.', 'Job Description', 'Computational analysis of physiologic signals (e.g., ECG);', 'PhD or MS degree in biomedical engineering, electrical engineering, mechanical engineering, or a related field with a strong interest in a biomedical research career;Strong technical background and experience in signal processing, system identification, control system design and analysis, stochastic control of physiological variables, computational modeling and simulations of physiological and/or medical device systems;Experience in one or more of the following:Designing, testing and using automated measurement testing platforms including instrumentation control and data acquisition;Designing, evaluating, and implementing simulations of computational physiologic systems models;Computational analysis of physiologic signals (e.g., ECG);Excellent programming skills in high level languages (e.g., Python / Matlab) and software for system modeling, simulation, and testing (e.g., Simulink / LabView);Background or research experience in cardiovascular physiology and neural engineering.', 'Designing, evaluating, and implementing simulations of computational physiologic systems models;', 'Background or research experience in cardiovascular physiology and neural engineering.', 'Designing, testing and using automated measurement testing platforms including instrumentation control and data acquisition;', 'Experience in one or more of the following:', 'Excellent programming skills in high level languages (e.g., Python / Matlab) and software for system modeling, simulation, and testing (e.g., Simulink / LabView);']",Associate,Full-time,Research,Government Administration,2021-02-10 11:29:29
Researcher (Part Time),Stanford Center on Philanthropy and Civil Society (Stanford PACS),"Stanford, CA",15 hours ago,Be among the first 25 applicants,"['·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Other tasks to further the studies', 'Candidates must have the following minimum qualifications:\xa0', '', '\xa0\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Ability to work under\xa0deadlines with general guidance', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Strong organizational\xa0or\xa0project/program management\xa0skills', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Graduate degree in the social sciences, PhD preferred', 'Researcher (part-time),\xa0Effective Philanthropy Learning Initiative\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience conducting qualitative social science\xa0research,\xa0and thorough understanding of scientific theory and methods', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Code and analyze data', 'Apply at:\xa0https://form.jotform.com/91565445022151', 'Apply at:', 'Time\xa0commitment: 20 hours a week (average)', 'Candidate Criteria:\xa0', 'Application\xa0Deadline:\xa0\xa0February 24, 2021', 'About\xa0EPLI\xa0and Stanford PACS:\xa0', 'The EPLI team is seeking an experienced\xa0researcher with excellent analytical and writing capabilities. The\xa0researcher will work alongside the Associate Director of\xa0Research to develop and conduct two studies. The first will examine the ways that professional training and norms influence the experiences and philanthropic behaviors of wealthy individuals. The second will investigate the ways that donors who espouse values related to social justice incorporate those values into their philanthropic practice. Specifically, the\xa0researcher will:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Draft\xa0papers revealing\xa0research\xa0results', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Conduct literature reviews', 'The\xa0Effective Philanthropy Learning Initiative\xa0(EPLI)\xa0at Stanford University’s\xa0Center on Philanthropy and Civil Society (PACS)\xa0is looking for\xa0a\xa0part-time\xa0researcher\xa0to\xa0support our\xa0research agenda, which focuses broadly\xa0on philanthropic trends and donor behavior.\xa0\xa0\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Prepare manuscripts for publication in academic and non-academic publications\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Perform\xa0participant outreach\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A commitment to EPLI’s work\xa0and mission or scholarly interests in philanthropy, wealth, the social sector and/or social inequality', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Strong\xa0writing, communication,\xa0and data analysis skills', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience conducting interviews for qualitative\xa0research projects', 'Available\xa0Position:\xa0Researcher (part-time)\xa0', 'Stanford PACS is a\xa0research center for students, scholars, and practitioners to explore and share ideas that create social change. Its primary\xa0participants are Stanford faculty, visiting scholars, postdoctoral fellows, graduate and undergraduate students, and nonprofit and foundation practitioners. As publisher of Stanford Social Innovation Review (SSIR), Stanford PACS informs policy and social innovation, philanthropic investment and nonprofit practice.\xa0PACS is also home to\xa0thought leaders tackling some of the greatest challenges facing the world today through the Digital Civil Society Lab, the Program on Democracy and the Internet, and the Global Impact Innovation Lab.\xa0', 'To begin:\xa0February or March, 2021\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0General knowledge of IRB protocols', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Assist in the determining methodological approaches to\xa0research questions', 'The\xa0Effective Philanthropy Learning Initiative\xa0(EPLI) at Stanford PACS\xa0is an interdisciplinary\xa0team\xa0working at the intersection of the social and behavioral sciences and strategic philanthropy. The lab conducts\xa0research, develops\xa0resources, and teaches with the aim of increasing donor impact.\xa0\xa0', 'Work period:\xa06-12 months, with the possibility of extension', '\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Conduct interviews', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Excellent organizational skills and demonstrated ability to complete detailed work accurately', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Participate in weekly\xa0research meeting', 'https://form.jotform.com/91565445022151', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Familiarity with qualitative coding software is a plus']",Associate,Part-time,Research,Higher Education,2021-02-10 11:29:29
Data Engineer,JBT Corporation,United States,18 minutes ago,61 applicants,"['', 'Data Engineering', 'Bachelor’s degree in Computer Science or related field', '\ufeffYou will be part of multiple teams tasked with multiple projects, designing and building strategic data solutions supporting analytical and reporting needs of the Organization. This opportunity has a global scope, collaborating with all levels of leadership within various businesses within the organization. Senior Data Engineer will support the creation and execution of data strategy at the corporate, business unit and site levels.\xa0\xa0\xa0', 'Be an evangelist to promote understanding and usage of enterprise data to fully leverage the power of data and automation', 'Load', 'Write optimized, secure and scalable code', 'Excellent interpersonal skills, relationship building, and project management skills.', 'Positions in this sub-functional area of Data, Analytics & Business Intelligence Organization are responsible for performing complex data processing, manipulating and integrating internal and external data sources. Through an Extract, Transform, and Load strategy resulting in aggregating data for insights and self-service analytics, achieving highest data quality and efficiency.', 'This area is responsible for creating a data driven culture, through the development and execution of our organizational data analytics strategy, combing people, process, and technology to deliver value from data to the organization.\xa0Enabling self-service analytics while focusing on innovations, automation, efficiency gains, promoting agility and organizational growth.', 'An understanding of coding using Python or Scala or anther high-level programming language, with an aptitude to become proficient in the near future', 'Experienced in working with ETL application, data pipelines, and Big Data', 'Write optimized, secure and scalable codeExecute a design of data ETL process (including, documentation and flow charts)Come up with creative solutions to solve technical and analytical challengesSupport efforts to develop enterprise data model and data cataloging to promote consistency and efficiencyDevelop and support needed data pipelinesPartner closely with teams across the globe to gain a full understanding of analytical and/or reporting objective to provide respective data aggregationBe comfortable communicating with non-technical audienceBe an evangelist to promote understanding and usage of enterprise data to fully leverage the power of data and automationExpected to keep up with emerging trends & technologies in big data and analytics and keep abreast of latest related researchMentor and train junior engineers and other team membersReport and monitor progress towards Data & Analytics Organizational goalsOn daily basis monitor current data extraction processes in place and address any issues that might occur', 'Support efforts to develop enterprise data model and data cataloging to promote consistency and efficiency', 'Knowledge of Hadoop related technology such as Impala, Yarn, Hive, HDFS, Oozie etc.', 'Extract', 'Knowledge of Azure Data Factory', 'Be comfortable communicating with non-technical audience', 'Data, Analytics & Business Intelligence Organization', 'This position reports to the Global Senior Manager of Data and BI Analytics.', 'Qualification:', 'Experienced in using data integrations tools, SQL and BI Tools, Tableau experience preferred', 'Partner closely with teams across the globe to gain a full understanding of analytical and/or reporting objective to provide respective data aggregation', 'Execute a design of data ETL process (including, documentation and flow charts)', '\ufeff', 'Come up with creative solutions to solve technical and analytical challenges', 'Ability to work various hours to support global organization with business hours in multiple time zones', 'Experienced in data quality issue tracking and resolution activities, end to end (impact analysis, root causes analysis, implications to reporting and data analytics, etc.)', 'As a Senior Data Engineer, you will be part of the Data, Analytics & Business Intelligence Team, working with and mentoring colleagues who will help, support, and challenge you every day.\xa0Data testing, code reviewing, creative solutions related to challenging data problems, regular check-ins with leadership, business and IT partners, for continuous integration is just a part of your day.\xa0\xa0We expect our engineers to do more than just write code, your responsibilities will include but are not limited to:', 'Report and monitor progress towards Data & Analytics Organizational goals', 'Mentor and train junior engineers and other team members', 'Develop and support needed data pipelines', '\xa0', ' Transform,', 'An understanding of Spark, experience using Spark is a plus', 'High attention to details,', 'On daily basis monitor current data extraction processes in place and address any issues that might occur', 'Expected to keep up with emerging trends & technologies in big data and analytics and keep abreast of latest related research', '5+ years of relevant experience', 'Experienced with creating data cataloging, data certifications, and full documentation spectrum related to data strategy and/or pipeline', 'Experienced in leading and coordinating multifunctional activities to support data needs between various business units across the organization', 'Bachelor’s degree in Computer Science or related field5+ years of relevant experienceExperienced in using data integrations tools, SQL and BI Tools, Tableau experience preferredExperienced in working with ETL application, data pipelines, and Big DataExperienced in data quality issue tracking and resolution activities, end to end (impact analysis, root causes analysis, implications to reporting and data analytics, etc.)Experienced working with structured and unstructured data, dispersed data with various formats, size and/or locationsExperienced in leading and coordinating multifunctional activities to support data needs between various business units across the organizationExperienced with creating data cataloging, data certifications, and full documentation spectrum related to data strategy and/or pipelineAn understanding of coding using Python or Scala or anther high-level programming language, with an aptitude to become proficient in the near futureAn understanding of Spark, experience using Spark is a plusKnowledge of Hadoop related technology such as Impala, Yarn, Hive, HDFS, Oozie etc.Knowledge of Azure Data FactoryExcellent interpersonal skills, relationship building, and project management skills.High attention to details,Ability to work various hours to support global organization with business hours in multiple time zones', 'Experienced working with structured and unstructured data, dispersed data with various formats, size and/or locations']",Mid-Senior level,Full-time,Information Technology,Business Supplies and Equipment,2021-02-10 11:29:29
Data Engineer,Strategic Staffing Solutions,"Detroit, MI",16 hours ago,Be among the first 25 applicants,"['', 'Hands-on experience as a Data Engineer/ETL Developer in a data warehousing environment', 'Understanding of data integration, business intelligence and data warehousing concepts', 'Experience working with cloud infrastructure such as Microsoft Azure or AWS', 'We have the following opening.\xa0If you are interested and qualified, please submit a word resume and I will contact you.', 'Must sit in Detroit', 'Ability to connect data warehouse solutions through API or similar connectivity ', 'Knowledge of one or more BI reporting tools such as PowerBI a plus', 'Experience with cloud-based integration platforms ', 'Long term contract', 'Data Engineer']",Associate,Contract,Information Technology,Information Technology and Services,2021-02-10 11:29:29
Data Engineer - Platform Mission,Spotify,"New York, NY",6 hours ago,Over 200 applicants,"['', 'You are experienced with JVM-based data processing frameworks such as Beam, Spark or FlinkHave experience crafting and building maintainable backend services in JavaAre able to work across tech stacks, implementing features end-to-endKnowledgeable about data modeling, data access, and data storage techniques.Know and care about sound engineering practices like continuous delivery, defensive programming and automated testingYou care about agile software processes, data-driven development, reliability, and responsible experimentation.You are comfortable working both independently and collaboratively (pairing and mobbing)', 'Know and care about sound engineering practices like continuous delivery, defensive programming and automated testing', 'Work in agile teams to continuously experiment, iterate and deliver on new product objectives.', 'Craft and build the infrastructure in support of our data quality objectives, including but not restricted to large-scale batch and real-time data pipelines, backend services, libraries, UIs and other tools that enable testing, monitoring, validation, sampling, outlier detection and other techniques that help assess and monitor the quality of data', 'You are comfortable working both independently and collaboratively (pairing and mobbing)', 'Who You Are', 'Craft and build the infrastructure in support of our data quality objectives, including but not restricted to large-scale batch and real-time data pipelines, backend services, libraries, UIs and other tools that enable testing, monitoring, validation, sampling, outlier detection and other techniques that help assess and monitor the quality of dataUse standard methodologies in continuous integration and deliveryTake an active part in the operational responsibilities for our own infrastructureWork in agile teams to continuously experiment, iterate and deliver on new product objectives.', 'Take an active part in the operational responsibilities for our own infrastructure', 'You care about agile software processes, data-driven development, reliability, and responsible experimentation.', 'Knowledgeable about data modeling, data access, and data storage techniques.', 'Are able to work across tech stacks, implementing features end-to-end', 'Have experience crafting and building maintainable backend services in Java', 'Use standard methodologies in continuous integration and delivery', ""What You'll Do"", 'You are experienced with JVM-based data processing frameworks such as Beam, Spark or Flink']",Not Applicable,Full-time,Information Technology,Marketing and Advertising,2021-02-10 11:29:29
Data Engineer ,Johnson & Johnson,"Spring House, PA",18 hours ago,Be among the first 25 applicants,"['', 'Performs miscellaneous programming tasks to support in-house data tools, platforms, pipelines and workflows. ', 'Key Responsibilities', 'Proficiency in a general-purpose programming language such as Python, C, C++, Java, Scala, Go or similar is required.', ' Implements and supports data management solutions (storage and integration of molecular, clinical, and technical data and analysis outputs) and best practices in partnership with data scientists, IT partners and other key stakeholders.  Engineers infrastructure components and operational workflows for data access and integration. Performs miscellaneous programming tasks to support in-house data tools, platforms, pipelines and workflows.  Performs data curation and quality control as required. ', 'Implements and supports data management solutions (storage and integration of molecular, clinical, and technical data and analysis outputs) and best practices in partnership with data scientists, IT partners and other key stakeholders. ', 'Familiarity with standard bioinformatics workflows and approaches is preferred. ', 'Familiarity with a statistical programming language (R or SAS) is preferred. ', 'Performs data curation and quality control as required.', 'Familiarity with Amazon Web Services is required. ', 'Database management and programming (SQL, NoSQL) experience is required. ', 'Familiarity with high-performance computing environments is preferred.', 'Qualifications', 'Develops, documents, and supports standard procedures and best practices for data organization and exchange.', 'Strong oral and written communication skills are required.', ' A Ph.D. OR a Master’s degree with at least 2 years of relevant experience OR a bachelor’s degree with at least 8 years of experience in computer science, mathematics, bioinformatics, computational biology, physics, engineering or information technology is required.  Proficiency in a general-purpose programming language such as Python, C, C++, Java, Scala, Go or similar is required. Database management and programming (SQL, NoSQL) experience is required.  Familiarity with Amazon Web Services is required.  Experience with processing omics (transcriptomics, proteomics, genotypes etc.) or other high-dimensional data is required. Strong oral and written communication skills are required. Familiarity with high-performance computing environments is preferred. Demonstrated ability to work in diverse, interdisciplinary teams is required.  Familiarity with a statistical programming language (R or SAS) is preferred.  A working knowledge of web application design and programming is preferred.  Familiarity with standard bioinformatics workflows and approaches is preferred.  Familiarity with basics of biology or medicine is preferred. Prior experience in the pharmaceutical industry or a related field is preferred.', 'Engineers infrastructure components and operational workflows for data access and integration.', 'Description', 'A working knowledge of web application design and programming is preferred. ', ' Develops, documents, and supports standard procedures and best practices for data organization and exchange. ', 'Job Description', 'A Ph.D. OR a Master’s degree with at least 2 years of relevant experience OR a bachelor’s degree with at least 8 years of experience in computer science, mathematics, bioinformatics, computational biology, physics, engineering or information technology is required. ', 'Experience with processing omics (transcriptomics, proteomics, genotypes etc.) or other high-dimensional data is required.', 'Familiarity with basics of biology or medicine is preferred. Prior experience in the pharmaceutical industry or a related field is preferred.', 'Demonstrated ability to work in diverse, interdisciplinary teams is required. ']",Not Applicable,Full-time,Information Technology,Hospital & Health Care,2021-02-10 11:29:29
Data Scientist,Amazon,"Sunnyvale, CA",2 hours ago,Be among the first 25 applicants,"['', "" Bachelor's Degree"", ' Experience with statistical modeling / machine learning and parameters that affect their performance', ' Basic knowledge in Automatic Speech Recognition', 'Key Responsibilities', ' Apply or design highly innovative models for predictive learning, content ranking, and anomaly detection', ' Utilize code (Python, R, Scala, etc.) for analyzing data and building statistical models to solve specific business problems', ' 2 years working as a Data Scientist', ' Analyze key metrics to uncover trends and root causes of issues', ' 3+ years experience with dashboard and data visualization by Excel, Tableau, Quicksight or other similar tool', ' Analyze and extract relevant information from large amounts of historical data to help automate and optimize key processes', "" Master's Degree or PhD in a relevant field Track record of diving into data to discover hidden patterns and of conducting error/deviation analysis Ability to develop experimental and analytic plans for data modeling processes, ability to accurately determine cause and effect relations Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. Proven ability to meet tight deadlines, multi-task, and prioritize workload Track record for being detail-oriented with a demonstrated ability to self-motivate and follow-through on projects A desire to work in a collaborative, intellectually curious environment"", 'Basic Qualifications', ' Communicate verbally and in writing to business customers and leadership team with various levels of technical knowledge, and share insights and recommendations', ' Track record for being detail-oriented with a demonstrated ability to self-motivate and follow-through on projects', ' 3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)', ' Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams', ' 3+ years experience as a data scientist, data engineer or similar job function with a technology company', ' 2+ years of coding experience in at least one modern programming language (R, Python, Ruby, Scala, Java, Spark etc.)', ' Ability to develop experimental and analytic plans for data modeling processes, ability to accurately determine cause and effect relations', ' Adopt best practices and implement strategies for data audit, data integrity, and validation Utilize code (Python, R, Scala, etc.) for analyzing data and building statistical models to solve specific business problems Execute end to end insights projects include data collecting, data cleaning, exploratory analysis, model selection, model evaluation, and interpreting results Apply or design highly innovative models for predictive learning, content ranking, and anomaly detection Analyze and extract relevant information from large amounts of historical data to help automate and optimize key processes Analyze key metrics to uncover trends and root causes of issues Communicate verbally and in writing to business customers and leadership team with various levels of technical knowledge, and share insights and recommendations', ' Proven ability to meet tight deadlines, multi-task, and prioritize workload', 'Description', ' Track record of diving into data to discover hidden patterns and of conducting error/deviation analysis', 'Preferred Qualifications', ' A desire to work in a collaborative, intellectually curious environment', "" Master's degree in Computer Science, Engineering, Mathematics, or a related field"", "" Master's Degree or PhD in a relevant field"", "" Bachelor's Degree 3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab) 2 years working as a Data Scientist Master's degree in Computer Science, Engineering, Mathematics, or a related field Basic knowledge in Automatic Speech Recognition 3+ years experience as a data scientist, data engineer or similar job function with a technology company 3+ years experience with dashboard and data visualization by Excel, Tableau, Quicksight or other similar tool 2+ years of coding experience in at least one modern programming language (R, Python, Ruby, Scala, Java, Spark etc.) Experience with statistical modeling / machine learning and parameters that affect their performance Excellent communication (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams"", ' Execute end to end insights projects include data collecting, data cleaning, exploratory analysis, model selection, model evaluation, and interpreting results', ' Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc.', ' Adopt best practices and implement strategies for data audit, data integrity, and validation', 'Company']",Not Applicable,Full-time,Engineering,Computer Software,2021-02-10 11:29:29
"Data Scientist, Marketing Analytics",Creative Business Resources (CBR),"New York, NY",13 hours ago,Be among the first 25 applicants,"['', 'Media Strategy Optimization, A/B Testing', 'Experience in deploying analytics projects in a cloud environment (GCP, AWS, Azure)', 'dbt and/or Airflow experience', 'Basic understanding of deep learning techniques', 'Dog friendly office', 'Proficient in SQL and Python/R', 'Linear TV attribution modeling experience', ' Base salary DOE Unlimited vacation policy Bonus opportunities Monthly Phone Stipend Comprehensive Medical, Dental, and Vision insurance options Dog friendly office Full Time Remote Work options', ' Marketing Mix Modeling Multi-channel Attribution (Linear TV, OTT, etc.) Media Strategy Optimization, A/B Testing Customer Lifetime Value (CLV/LTV)  ', 'Working knowledge of Tableau, Data Studio or other visualization software', 'We offer a competitive salary and benefits based on ability level including ', 'Strong marketing analytics foundation (Marketing Mix Modeling, Customer Lifetime Value, Attribution)', 'About You', 'Monthly Phone Stipend', 'Experience with data pipelining, from data preparation to analysis to deployment', 'Comprehensive Medical, Dental, and Vision insurance options', 'About Us ', 'Requirements', 'Unlimited vacation policy', 'Benefits', ' Strong marketing analytics foundation (Marketing Mix Modeling, Customer Lifetime Value, Attribution) Proficient in SQL and Python/R Experience with data pipelining, from data preparation to analysis to deployment Advanced knowledge of machine learning techniques (supervised and unsupervised) Basic understanding of deep learning techniques Strong attention to detail and ability to adapt to team norms Excellent verbal and written communication  ', 'Customer Lifetime Value (CLV/LTV) ', 'Responsibilities', 'Marketing Mix Modeling', 'Multi-channel Attribution (Linear TV, OTT, etc.)', 'Excellent verbal and written communication ', 'Bonus opportunities', 'Base salary DOE', 'Strong attention to detail and ability to adapt to team norms', 'Advanced knowledge of machine learning techniques (supervised and unsupervised)', 'Full Time Remote Work options', ' Linear TV attribution modeling experience Working knowledge of Tableau, Data Studio or other visualization software Experience in deploying analytics projects in a cloud environment (GCP, AWS, Azure) dbt and/or Airflow experience ']",Associate,Full-time,Analyst,Marketing and Advertising,2021-02-10 11:29:29
"Data Engineer( Spark, Scala exp)",Diligente Technologies,San Francisco Bay Area,32 minutes ago,Over 200 applicants,"['', 'Description:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0', 'Hands-on development experience using open source big data components such as Hadoop, Hive, Pig, Spark, HBase, Hawk, Oozie, Mahout, Flume, Kafka, ZooKeeper, Sqoop etc. preferably with Hortonworks distro', '8-10 years of software development and deployment experience with at least 5 years of hands-on experience with Hadoop applications (e.g. administration, configuration management, monitoring, debugging, and performance tuning)Strong experience building data ingestion pipelines (simulating Extract, Transform, Load workload), data warehouse or database architectureHands-on development experience using open source big data components such as Hadoop, Hive, Pig, Spark, HBase, Hawk, Oozie, Mahout, Flume, Kafka, ZooKeeper, Sqoop etc. preferably with Hortonworks distroStrong experience with data modeling, design patterns, building highly scalable Big Data Solutions and distributed applications', 'Location: San Francisco, CA', '8-10 years of software development and deployment experience with at least 5 years of hands-on experience with Hadoop applications (e.g. administration, configuration management, monitoring, debugging, and performance tuning)', 'Strong experience on Spark, Scala and create streaming data pipelines', ' Long Term Contract', 'Strong experience with data modeling, design patterns, building highly scalable Big Data Solutions and distributed applications', 'Title: Data Engineer', 'Strong experience building data ingestion pipelines (simulating Extract, Transform, Load workload), data warehouse or database architecture']",Mid-Senior level,Contract,Engineering,Accounting,2021-02-10 11:29:29
Senior Data Engineer,DataKitchen,"Boston, MA",17 hours ago,196 applicants,"['', 'Do you want to be part of the next big thing and have fun doing it? DataKitchen has an excellent opportunity for a Data Engineer or Customer Success professional to be part of an exciting, growing company delivering a cloud-based DataOps Solution! We are leading the DataOps movement, making it possible for enterprise data teams to turn data into true business value. DataKitchen was honored as 2019 Gartner Cool Vendor and a CRN Big Data “Start-Up to Watch” in 2020. Our company is profitable, rapidly growing and stock will be part of the package.', 'DataKitchen is located in the heart of Kendall Square at the Cambridge Innovation Center (CIC). The CIC provides a great collaborative working environment, with plenty of free food and perks (e.g, Massage Mondays and beer on Fridays). DataKitchen also offers an extremely competitive salary, stock options, and benefits, with a flexible work environment, where you are trusted to get the work done, wherever that may be.\xa0\xa0\xa0', 'We follow agile development practices while embracing our errors and falling forward. We hire the best and brightest and give everyone the opportunity to contribute to the growth of the company.', 'Desired Tools and Experience', 'Run with open-ended requirements to mockup features for clients and then iterate and improve them over time', 'Day to Day:', 'Write Amazon Redshift SQL and leverage other AWS products (S3, Lambda, Glacier) and technologies to transform raw data into analytic assets\xa0', 'Develop and maintain data pipelines utilizing our DataOps software', 'DataKitchen has a culture of trust and transparency. As a Data Engineer at DataKitchen, you will own and take responsibility for the work you do. We pride ourselves on being collaborative amongst the team and with our customers. We are always asking “Is there a better way we can do this?”, refactoring and building on what we have done as a team.', 'Work in an agile working environment: weekly sprints, daily scrums', 'Self-manage and lead client projects', 'Why You Should Work at DataKitchen', 'MS in a quantitative field (Computer Science, preferred)', 'Knowledge of Commercial Pharmaceutical / Life Sciences data sets (NPP, DDD, Xponent, Plantrak, SPP, Symphony, IQVIA)', '5+ years of hands-on data engineering experience', 'Advanced knowledge of cloud database design, warehousing (AWS, Snowflake, Google Cloud, etc.)', 'Background:', '5+ years of hands-on data engineering experienceMS in a quantitative field (Computer Science, preferred)Advanced knowledge of cloud database design, warehousing (AWS, Snowflake, Google Cloud, etc.)Solid experience with at least one object-oriented programming language, preferably PythonStrength communicating technical details, at both a high level and very detailedKnowledge of Commercial Pharmaceutical / Life Sciences data sets (NPP, DDD, Xponent, Plantrak, SPP, Symphony, IQVIA)', 'Strength communicating technical details, at both a high level and very detailed', 'Solid experience with at least one object-oriented programming language, preferably Python', 'Communicate directly with customers; maintain transparency through Jira ticketing and Confluence documentation', 'Develop and maintain data pipelines utilizing our DataOps softwareWrite Amazon Redshift SQL and leverage other AWS products (S3, Lambda, Glacier) and technologies to transform raw data into analytic assets\xa0Self-manage and lead client projectsRun with open-ended requirements to mockup features for clients and then iterate and improve them over timeCommunicate directly with customers; maintain transparency through Jira ticketing and Confluence documentationWork in an agile working environment: weekly sprints, daily scrums']",Mid-Senior level,Full-time,Engineering,Computer Software,2021-02-10 11:29:29
"Researcher II, North America",Riot Games,"Los Angeles, CA",33 minutes ago,53 applicants,"['', 'Advise regional leadership on market research spend/best practices, and need for scope of current tools and future tools to be developed', 'Create studies and surveys designed to answer business, development, and usability questions and work with central research team to lead focus groups and share your results with other Rioters and leaders', 'Hypothesis-driven experimentation skills with emphasis on qual/quant user research techniques and playtesting/labs. Familiarity with helping a team test, learn, and iterate', 'Desired Qualifications', 'Experience in the tech, gaming, consumer products or media/entertainment industry', 'Our Perks', ' BA or BS in Psychology, Anthropology, Human-Computer Interaction, or a related social science discipline 4+ years of experience in user experience research, behavioral or cognitive research, or quantitative market research Proficient in many research methodologies, such as surveys, focus groups, ethnography, and labs, and apply research methodologies with a minimal amount of craft guidance Expertise in at least one quantitative method for understanding sentiment, needs, and survey preferences Hypothesis-driven experimentation skills with emphasis on qual/quant user research techniques and playtesting/labs. Familiarity with helping a team test, learn, and iterate Create applicable recommendations for brand/growth strategy Experience creating presentations and convey complex or nuanced topics to creative audiences ', 'Proficient in many research methodologies, such as surveys, focus groups, ethnography, and labs, and apply research methodologies with a minimal amount of craft guidance', 'BA or BS in Psychology, Anthropology, Human-Computer Interaction, or a related social science discipline', 'Create/socialize backlog for regional market research to understand gamer & esports fan preferences', ' Develop projects that improve our understanding of the gamer and Esports audience to both grow the audience and increase audience investment in our multiple IP Create/socialize backlog for regional market research to understand gamer & esports fan preferences Advise regional leadership on market research spend/best practices, and need for scope of current tools and future tools to be developed Scope, support and socialize regional audience profiling, purchase/trial research, or additional company-wide research efforts Framework for understanding the interaction effects between player hours in games and player engagement in non-game experiences (Esports, IP/C products) Create studies and surveys designed to answer business, development, and usability questions and work with central research team to lead focus groups and share your results with other Rioters and leaders Develop relationships with product and regional insights teams ', ""It's our policy to provide equal employment opportunity for all applicants and members of Riot Games, Inc. Riot Games makes reasonable accommodations for handicapped and disabled Rioters and does not unlawfully discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, handicap, veteran status, marital status, criminal history, or any other category protected by applicable federal and state law, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance relating to an applicant's criminal history (LAMC 189.00)."", '4+ years of experience in user experience research, behavioral or cognitive research, or quantitative market research', ' Advanced degree Experience in the tech, gaming, consumer products or media/entertainment industry ', 'Framework for understanding the interaction effects between player hours in games and player engagement in non-game experiences (Esports, IP/C products)', 'Develop relationships with product and regional insights teams', 'Expertise in at least one quantitative method for understanding sentiment, needs, and survey preferences', 'Create applicable recommendations for brand/growth strategy', 'Researcher on the North America Regional & Oceania team', 'Responsibilities', 'Required Qualifications', 'Develop projects that improve our understanding of the gamer and Esports audience to both grow the audience and increase audience investment in our multiple IP', 'Experience creating presentations and convey complex or nuanced topics to creative audiences', 'Scope, support and socialize regional audience profiling, purchase/trial research, or additional company-wide research efforts', 'Advanced degree']",Not Applicable,Full-time,Research,Computer Games,2021-02-10 11:29:29
Senior Data Scientist-Consumer Safety ,Johnson & Johnson,"Fort Washington, PA",9 hours ago,Be among the first 25 applicants,"['', 'Manage relationships across IT, QA and finance functional areas; balance between business needs and IT/QA standards and strategies to guide well-informed designs and decisions.', 'Lead the safety science eﬀort to build applications and tools by applying advanced scientific algorithms and methods and translating the strategic vision of safety science into solutions and insights.', 'Willingness to work in an exploratory environment, handling non-standard tasks with minimal supervision', 'The Senior Data Scientist Will', 'Apply and leverage technology-driven analytics (e.g., natural language processing, artificial intelligence/machine learning) in advancing safety science practice.', 'Lead as a Business Analyst for moderate to large projects, programs, or initiatives of varying complexity', 'Be a member of the Safety Science and Analytics group within the Oﬀice of Consumer Medical Safety (OCMS).', 'Prior training/experience building natural language processing and machine learning solutions using common machine learning and deep learning frameworks', 'Should be passionate about working on developing cutting edge analytics/informatics solutions in the field of safety analytics and surveillance.', 'Master’s degree required in Applied Mathematics, Computer Science/Informatics, Epidemiology, Statistics or related discipline, plus 5 years of overall experience; or a PhD in the same disciplines plus 3 years of overall experience', ' Master’s degree required in Applied Mathematics, Computer Science/Informatics, Epidemiology, Statistics or related discipline, plus 5 years of overall experience; or a PhD in the same disciplines plus 3 years of overall experience Strong competency in at least one programming language commonly used in developing analytics solutions, such as R, Python, or Julia Experience with technologies used to build analytics dashboards/applications, such as RShiny, Dash, and Streamlit Working knowledge of how to build custom web applications using modern web frameworks (e.g., AngularJS, React, etc.) Experience with relational database technologies (e.g., Oracle, MySQL, PostgreSQL) Excellent written and communications skills and the ability to articulate findings in a clear, structured, and concise manner Willingness to work in an exploratory environment, handling non-standard tasks with minimal supervision ', 'Qualifications', 'Work closely with customers and stakeholders to turn data into critical information and knowledge that can be used to make evidence-based decisions.', ' Prior training/experience building natural language processing and machine learning solutions using common machine learning and deep learning frameworks Experience with spontaneous adverse events and working knowledge of safety surveillance', 'Experience with relational database technologies (e.g., Oracle, MySQL, PostgreSQL)', 'Be responsible for translating the strategic vision of safety science into solutions and insights through development of innovative methodology and applications.', 'Preferred', ' Be a member of the Safety Science and Analytics group within the Oﬀice of Consumer Medical Safety (OCMS). Be responsible for translating the strategic vision of safety science into solutions and insights through development of innovative methodology and applications. Should be passionate about working on developing cutting edge analytics/informatics solutions in the field of safety analytics and surveillance. Lead the safety science eﬀort to build applications and tools by applying advanced scientific algorithms and methods and translating the strategic vision of safety science into solutions and insights. Work closely with customers and stakeholders to turn data into critical information and knowledge that can be used to make evidence-based decisions. Manage relationships across IT, QA and finance functional areas; balance between business needs and IT/QA standards and strategies to guide well-informed designs and decisions. Apply compliance/validation requirements related to GxP-regulated applications, provides documentation as necessary, and participate in compliance/validation activities as required. Work eﬀectively as part of a team and solve complex or unusual problems in consideration of the potential impact. Lead as a Business Analyst for moderate to large projects, programs, or initiatives of varying complexity Apply and leverage technology-driven analytics (e.g., natural language processing, artificial intelligence/machine learning) in advancing safety science practice. ', 'Excellent written and communications skills and the ability to articulate findings in a clear, structured, and concise manner', 'Experience with spontaneous adverse events and working knowledge of safety surveillance', 'Working knowledge of how to build custom web applications using modern web frameworks (e.g., AngularJS, React, etc.)', 'Apply compliance/validation requirements related to GxP-regulated applications, provides documentation as necessary, and participate in compliance/validation activities as required.', 'Experience with technologies used to build analytics dashboards/applications, such as RShiny, Dash, and Streamlit', 'Work eﬀectively as part of a team and solve complex or unusual problems in consideration of the potential impact.', 'Job Description', 'Strong competency in at least one programming language commonly used in developing analytics solutions, such as R, Python, or Julia']",Not Applicable,Full-time,Other,Hospital & Health Care,2021-02-10 11:29:29
Data Scientist,Hireology,"Chicago, IL",11 hours ago,Be among the first 25 applicants,"['', 'Project Managing and Executing quantitative analyses that translate data into actionable insights that lead to innovation', 'Metrics Driven: There are a myriad of signals you’ll learn to understand and manage, ensuring our customers are happy, engaged and informed. We’re passionate about data and trends and managing to key performance indicators and you will be as passionate about our bottoms-up approach to providing insights to our clients.', 'Knowledge of programming languages like SQL, Python, R, and Scala', 'Strong mathematics skills (e.g., statistics, algebra)', 'Candidates must be authorized to work in the US.', 'Correlating similar data to find actionable results', 'Work Independently and with a Team: Some people work best individually and some as part of a team. The ideal candidate is a chameleon who can succeed both on their own and work within a team-oriented, collaborative environment.', 'Utilizing Looker or other similar tools to fulfill transactional reporting, and ad hoc analyses ', 'Metrics Driven: There are a myriad of signals you’ll learn to understand and manage, ensuring our customers are happy, engaged and informed. We’re passionate about data and trends and managing to key performance indicators and you will be as passionate about our bottoms-up approach to providing insights to our clients.Possess Integrity: Not negotiable in this or any role at Hireology. You have the highest level of integrity and discretion.Work Independently and with a Team: Some people work best individually and some as part of a team. The ideal candidate is a chameleon who can succeed both on their own and work within a team-oriented, collaborative environment.', 'Speak with a member of our senior leadership team. If you have made it this far, just be yourself, and everything will be fine.', 'Take a brief true/false survey. Be sure to check your email after you apply.', 'Work with clients and internal stakeholders to develop advanced analyses that help them solve challenging business problems ', 'We are an equal opportunity employer and prohibit discrimination/harassment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.', 'Previous exposure to ETL, data model design, and data warehouse concepts is a plus', 'Ability to communicate complex data in a simple, actionable way', 'GLM, SVM and tree-based models (e.g. Boosting, Random Forest) ', 'Previous exposure to ETL, data model design, and data warehouse concepts ', 'Have a phone conversation with someone on our Recruiting team. This is a high-level conversation about you, but also a good opportunity for you to learn more about us.', 'Regression models GLM, SVM and tree-based models (e.g. Boosting, Random Forest) NLP (Natural Language Processing)Neural Networks', ""You'll have the opportunity to show off your modeling skills and how you solve business cases. This will also be an opportunity for us to get an idea of how you got to where you are, and if where you want to go lines up with where we are going."", 'Creating reports and presentations for business uses', 'Experience with common data science toolkit', 'Master’s degree or Ph.D. in a quantitative field or 2+ years professional experience working in an analytics-focused role', 'Proficiency in SQL and databases (most notably PostgreSQL) is required', 'Creating new, experimental frameworks to collect data', 'Familiarity with business intelligence tools (e.g., Tableau, Looker)', 'Possess Integrity: ', 'Metrics Driven:', 'Made a high-quality data science project available in a public forum like GitHub, Kaggle, or an analytics blog', 'Transferring data into a new format to make it more appropriate for analysisCreating new, experimental frameworks to collect dataBuilding tools to automate data collectionCreating reports and presentations for business usesCorrelating similar data to find actionable resultsUtilizing Looker or other similar tools to fulfill transactional reporting, and ad hoc analyses Works cross-functionally to define problem statements, collect data, build models, translate data to solve complex business problems and make recommendationsWorking directly with Revenue, Marketing, Engineering, Product and other business units to understand and satisfy stakeholders’ needs, while communicating and coordinating closely with business partners and leadershipProject Managing and Executing quantitative analyses that translate data into actionable insights that lead to innovationWork with clients and internal stakeholders to develop advanced analyses that help them solve challenging business problems ', 'Working directly with Revenue, Marketing, Engineering, Product and other business units to understand and satisfy stakeholders’ needs, while communicating and coordinating closely with business partners and leadership', 'NLP (Natural Language Processing)', 'Neural Networks', 'Ability to work independently and with team members from different backgrounds', 'As a Data Scientist, You’ll Be Responsible For', 'Work Independently and with a Team: ', 'Building tools to automate data collection', ""Take a brief true/false survey. Be sure to check your email after you apply.Have a phone conversation with someone on our Recruiting team. This is a high-level conversation about you, but also a good opportunity for you to learn more about us.Meet with our Revenue Operations team to talk about how you approach work technically with examples of how you have done it in the past. You'll have the opportunity to show off your modeling skills and how you solve business cases. This will also be an opportunity for us to get an idea of how you got to where you are, and if where you want to go lines up with where we are going.Provide us some references. We use our automated reference check system for this, so you just give us some names, they fill out a survey, and we are all set.Speak with a member of our senior leadership team. If you have made it this far, just be yourself, and everything will be fine."", 'Regression models ', 'Advanced ability to perform exploratory data analysis', 'Transferring data into a new format to make it more appropriate for analysis', 'Candidates must be authorized to work in the US.Master’s degree or Ph.D. in a quantitative field or 2+ years professional experience working in an analytics-focused roleAbility to write sophisticated machine learning and data analysis code in R, Matlab, or Python. This includes but is not limited to:Regression models GLM, SVM and tree-based models (e.g. Boosting, Random Forest) NLP (Natural Language Processing)Neural NetworksMade a high-quality data science project available in a public forum like GitHub, Kaggle, or an analytics blogProficiency in SQL and databases (most notably PostgreSQL) is requiredPrevious exposure to ETL, data model design, and data warehouse concepts is a plusExpertise in creating publication-quality visualizations and white papers.Knowledge of programming languages like SQL, Python, R, and ScalaPrevious exposure to ETL, data model design, and data warehouse concepts Familiarity with business intelligence tools (e.g., Tableau, Looker)Strong mathematics skills (e.g., statistics, algebra)Advanced ability to perform exploratory data analysisExperience with common data science toolkitAbility to communicate complex data in a simple, actionable wayAbility to visualize data in the most effective way possible for a given project or studyAbility to work independently and with team members from different backgrounds', 'Ability to visualize data in the most effective way possible for a given project or study', 'Meet with our Revenue Operations team to talk about how you approach work technically with examples of how you have done it in the past. ', 'Ability to write sophisticated machine learning and data analysis code in R, Matlab, or Python. This includes but is not limited to:Regression models GLM, SVM and tree-based models (e.g. Boosting, Random Forest) NLP (Natural Language Processing)Neural Networks', 'Role', 'Provide us some references. We use our automated reference check system for this, so you just give us some names, they fill out a survey, and we are all set.', 'Works cross-functionally to define problem statements, collect data, build models, translate data to solve complex business problems and make recommendations', 'Possess Integrity: Not negotiable in this or any role at Hireology. You have the highest level of integrity and discretion.', 'Expertise in creating publication-quality visualizations and white papers.']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Principal Data Scientist (Marketing Personalization Algorithms),Udemy,"San Francisco, CA",2 hours ago,Be among the first 25 applicants,"['', 'Udemy in the News', 'Strong knowledge of statistics, machine learning, and reinforcement learning', '7+ years of hands-on data science experience building complex data productsStrong knowledge of statistics, machine learning, and reinforcement learningProficiency with SQL and 1+ programming languages (e.g., Python)Experience with the design and development of large-scale machine learning applicationsAbility to communicate effectively with non-technical stakeholdersExcellent written and oral communication skillsSelf-driven, highly motivated, and able to learn quickly', 'Self-driven, highly motivated, and able to learn quickly', 'We’re Excited About You Because You Have', 'Provide technical mentorship for other team members', 'Collaborate with product managers, marketing experts, data scientists, and engineers to scope and build data products with a focus on personalization.Perform statistical analysis, feature engineering, and model development for ML-based data products.Develop production-grade applications at scaleDesign and analyze experiments to measure the performance of data products in offline and online settings. Proactively influence product prioritization through data-driven insightsLead complex cross-organizational initiativesMaintain high-quality standards, effective team processes, and best practices.Provide technical mentorship for other team membersBuild Udemy’s technical brand through talks, blog posts, and publications', 'Great If You Have But Not Required', 'Build Udemy’s technical brand through talks, blog posts, and publications', 'Experience with the design and development of large-scale machine learning applications', '7+ years of hands-on data science experience building complex data products', 'Ability to communicate effectively with non-technical stakeholders', 'Perform statistical analysis, feature engineering, and model development for ML-based data products.', 'Maintain high-quality standards, effective team processes, and best practices.', 'Design and analyze experiments to measure the performance of data products in offline and online settings. ', 'Proactively influence product prioritization through data-driven insights', 'Collaborate with product managers, marketing experts, data scientists, and engineers to scope and build data products with a focus on personalization.', 'Excellent written and oral communication skills', 'Proficiency with SQL and 1+ programming languages (e.g., Python)', 'Here’s What You’ll Be Doing', 'Lead complex cross-organizational initiatives', 'About Udemy', 'Experience using big data technologies (e.g., Hadoop, Spark)Familiarity with software development practices', 'Familiarity with software development practices', 'Experience using big data technologies (e.g., Hadoop, Spark)', 'Develop production-grade applications at scale']",Not Applicable,Full-time,Engineering,Marketing and Advertising,2021-02-10 11:29:29
"Data Scientist, Junior",ClearedJobs.Net,"Fort Meade, MD",10 hours ago,Be among the first 25 applicants,"['', 'Job Number: R0101062', 'Nice If You Have', 'access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'MA or MS degree preferred', 'Build Your Career', 'Experience with building data products using open source programming languages, including Python, R, or JavaScript', 'a chance to change the world with the Data Science Bowl—the world’s premier data science for social good competition', 'Experience with applying advanced statistics, including natural language processing and machine learning', '2+ years of experience with applying advanced statistics, including natural language processing and machine learning preferred', 'participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'You Have', 'Experience with scaling data products across distributed computer environments, including Hadoop', 'TS/SCI clearance with a polygraph', 'Clearance', 'The Challenge', 'BA or BS degree', 'access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunka chance to change the world with the Data Science Bowl—the world’s premier data science for social good competitionparticipation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Data Scientist-Senior,The Bowen Center,"Washington, DC",4 hours ago,Be among the first 25 applicants,"['', 'About Perspecta', 'Full-stack development experience.', 'Thorough/Working knowledge of research designs.', ' Thorough/Working knowledge of Python and some of the following software/tools: SQL, R, Hadoop, Spark, Java, C/C++, Git Bash, Tableau, ArcGIS, Unix commands. Thorough/Working knowledge of research designs. Thorough/Working knowledge of collection methods, capabilities and tasking process. Familiarity with project management concepts and principles. Intellectual curiosity; creativity and innovation to go beyond current tools to deliver the best solution to complex problems. Strong analytical and critical thinking skills ', 'CareerBuilder TIP', 'Desired Qualifications', 'Familiarity with project management concepts and principles.', 'Current TS/SCI clearance', 'Thorough/Working knowledge of Python and some of the following software/tools: SQL, R, Hadoop, Spark, Java, C/C++, Git Bash, Tableau, ArcGIS, Unix commands.', 'Recommended Skills', 'Recommended Jobs', 'Knowledge of database tools and current data science processes.', 'Business Group Highlights ', ' Strong understanding of data engineering, structure, formatting, conditioning and analysis. Knowledge of database tools and current data science processes. Full-stack development experience. ', 'Thorough/Working knowledge of collection methods, capabilities and tasking process.', 'Qualifications', 'Report this Job', 'Intellectual curiosity; creativity and innovation to go beyond current tools to deliver the best solution to complex problems.', 'Desired Skills', 'Strong understanding of data engineering, structure, formatting, conditioning and analysis.', 'Strong analytical and critical thinking skills', 'Responsibilities', 'Pay Transparency Nondiscrimination Provision', 'Defense']",Associate,Full-time,Other,Nonprofit Organization Management,2021-02-10 11:29:29
Senior Big Data Engineer,Grid Dynamics,"Cupertino, CA",1 hour ago,Be among the first 25 applicants,"['Understanding how to run Spark on KubernetesExperience working with scheduling technologies - Airflow, AzkabanExperience with JVM build systems (SBT, Maven, Gradle)', 'Code, develop and design a data platform to support big data pipeline and infrastructure for 100s of engineersDrive development end-to-end for specific componentsContribute to project discussions, collaborate directly with lead architects and present results to key stakeholdersWrite detailed design documentation, present decisions and motivate theseDesign, build, support and continuously enhance the project code baseWork inside a team of industry experts on the cutting edge Big Data technologies to develop solutions for deployment at massive scale', 'Corporate social events', 'What will be a big plus:', 'Medical insurance', 'About us:', 'Work inside a team of industry experts on the cutting edge Big Data technologies to develop solutions for deployment at massive scale', 'Strong understanding of the challenges of synching many disjunct big data technologies', 'Worked with HDFS', '+3 years of experience working with event-messaging systems - Kafka in particular', 'We offer:', ""We are looking for a Senior Big Data Engineer/Senior Spark Platform that can take the lead on a critical new project to design and build a big data platform, which will be a key component for all our data pipelines, running daily with petabytes of data under high performance requirements, utilizing bleeding-edge technologies. Our customer is one of the world's largest technology companies based in Silicon Valley with operations all over the world. The ideal candidate is a driven, enthusiastic and technology-proficient Spark Software/Big Data Engineer, who is eager and able to develop projects from scratch interconnecting up to +15 teams and several hundreds of engineers."", 'Design, build, support and continuously enhance the project code base', 'Contribute to project discussions, collaborate directly with lead architects and present results to key stakeholders', 'Experience with JVM build systems (SBT, Maven, Gradle)', 'Code, develop and design a data platform to support big data pipeline and infrastructure for 100s of engineers', 'NB:', 'At this moment, we are not able to process H1B transfers.About us:', 'Strong communication skills', '+8 years experience working with Big Data - Spark and Hadoop for a minimum of 4 years+3 years of experience working with event-messaging systems - Kafka in particularStrong knowledge of Scala and coding skills - alternatively very strong Java with 1-2 year of Scala Strong understanding of the challenges of building end-to-end big data pipelines for a large variety of use-cases at scaleStrong understanding of the challenges of synching many disjunct big data technologiesStrong communication skillsWorked with/understanding of streaming processes and technologies - Cassandra, Spark StreamingWorked with big data pipelines at terabyte/petabyte scaleWorked with HDFS', 'Strong understanding of the challenges of building end-to-end big data pipelines for a large variety of use-cases at scale', 'Worked with/understanding of streaming processes and technologies - Cassandra, Spark Streaming', 'Strong knowledge of Scala and coding skills - alternatively very strong Java with 1-2 year of Scala ', 'Placement and Staffing Agencies need not apply. We do not work with C2C at this time.', 'Drive development end-to-end for specific components', 'Understanding how to run Spark on Kubernetes', 'Competitive salary', 'Write detailed design documentation, present decisions and motivate these', 'Responsibilities:', 'Worked with big data pipelines at terabyte/petabyte scale', 'Benefits program', 'Opportunity to work on bleeding-edge projects', 'Opportunity to work on bleeding-edge projectsWork with a highly motivated and dedicated teamCompetitive salaryFlexible scheduleMedical insuranceBenefits programCorporate social events', 'Grid Dynamics is the engineering services company known for transformative, mission-critical cloud solutions for retail, finance and technology sectors. We architected some of the busiest e-commerce services on the Internet and have never had an outage during the peak season. Founded in 2006 and headquartered in San Ramon, California with offices throughout the US and Eastern Europe, we focus on big data analytics, scalable omnichannel services, DevOps, and cloud enablement.', 'Experience working with scheduling technologies - Airflow, Azkaban', 'Work with a highly motivated and dedicated team', 'Flexible schedule', '+8 years experience working with Big Data - Spark and Hadoop for a minimum of 4 years', 'Requirements:']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2021-02-10 11:29:29
Data Scientist,Booz Allen Hamilton,"Chantilly, VA",10 hours ago,Be among the first 25 applicants,"['', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunkchange the world with the Data Science Bowl—the world’s premier data science for social good competitionparticipate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Experience with programming languages such as Python or Java', 'Experience with data visualization and knowledge object creation a plus', 'Experience with data gathering and analysis of large data sets', 'Experience with Data Science in R or Python', 'change the world with the Data Science Bowl—the world’s premier data science for social good competition', 'Experience with Big Data programming technologies, including Hadoop, Spark, MongoDB, MapReduce, Accumulo, Cassandra, HBase, Mahout, Pig, and Hive-BA', 'Experience with Data Science in R or PythonExperience with Machine Learning libraries, such as Caffe, Keras, MxNet, PyTorch, or TensorFlowExperience with Cloud Computing services, including Amazon AWS, Google Cloud, Microsoft Azure, or equivalentExperience with Big Data programming technologies, including Hadoop, Spark, MongoDB, MapReduce, Accumulo, Cassandra, HBase, Mahout, Pig, and Hive-BAExperience with data visualization and knowledge object creation a plusExperience with GEOINT data, formats, structures, and standardsPossession of excellent oral and written communication skillsBS degree in Statistics, Mathematics, Physics or Computer Science preferred', 'Experience with Cloud Computing services, including Amazon AWS, Google Cloud, Microsoft Azure, or equivalent', 'Active TS/SCI clearance', 'You Have', 'BA or BS degree', 'Experience in an analytics field, including data analytics, data science, advanced mathematics or statisticsExperience with data gathering and analysis of large data setsExperience with programming languages such as Python or JavaAbility to exhibit flexibility, initiative, and innovation in dealing with ambiguous, fast-paced situationsActive TS/SCI clearanceBA or BS degree', 'Job Number: R0083390', 'Experience with Machine Learning libraries, such as Caffe, Keras, MxNet, PyTorch, or TensorFlow', 'Experience in an analytics field, including data analytics, data science, advanced mathematics or statistics', 'participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Possession of excellent oral and written communication skills', 'Nice If You Have', 'Build Your Career', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'Ability to exhibit flexibility, initiative, and innovation in dealing with ambiguous, fast-paced situations', 'Experience with GEOINT data, formats, structures, and standards', 'Clearance', 'BS degree in Statistics, Mathematics, Physics or Computer Science preferred', 'The Challenge']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Senior Data Engineer,Opus Recruitment Solutions,United States,15 minutes ago,Be among the first 25 applicants,"['', 'Proficient in the use of industry standard tooling (i.e. the Atlassian Stack, etc.)', 'This company is a multi-award winner pioneer of hyper-local retailing, combining artificial intelligence (AI), operations research, and human-centred design to help consumer packaged goods (CPG) manufacturers and retailers generate a return on physical space investments. Currently building out a US based Data Engineering team.', 'Solid oral and written communications skills', 'Proficiency in one or more core languages: Golang, Python, SQL, Bash, Perl', 'Familiarity with design patterns and industry best practices', 'Experience with one or alternative database technologies like: ElasticSearch, Apache Cassandra, Mongo DB, Spark', 'Experience with AWS', 'Proficient in the use of databases: query and data definition', 'Proficient in the use of databases: query and data definitionProficiency in one or more core languages: Golang, Python, SQL, Bash, PerlProficient in the use of industry standard tooling (i.e. the Atlassian Stack, etc.)Competent with LinuxSolid oral and written communications skillsFamiliarity with design patterns and industry best practicesExperience with one or alternative database technologies like: ElasticSearch, Apache Cassandra, Mongo DB, SparkExperience with AWS', 'Competent with Linux']",Mid-Senior level,Full-time,Information Technology,Retail,2021-02-10 11:29:29
Data Engineer,Confidential,"Austin, Texas Metropolitan Area",16 hours ago,26 applicants,"['Benefits\xa0', 'Take total ownership results of design, solution, or ways to solve measurable problems.\xa0', 'Company is an equal opportunity employer that hires based on stellar qualifications, positive attitude, and exemplary work ethic rather than factors like age, gender identity, race, nationality, religion, or sexuality.\xa0', 'Unit Appreciation Rights: Up to 5% of yearly salary; based upon company and team performance.\xa0', 'Life at Company\xa0', ""Unit Appreciation Rights: Up to 5% of yearly salary; based upon company and team performance.\xa0Company Bonus: Up to 5% of yearly salary; based upon company and team performance.\xa0Health Insurance: Company offers two plans:\xa0o\xa0Aetna PPO: Company covers 100% of premiums for employees and 50% for your spouse and dependents included on the plan.\xa0Aetna HDHP HSA Plan: Company will contribute $500 to an HSA for an employee-only plan or $1000 for your spouse and dependents included on the plan.\xa0Dental Insurance: Company will pay half of the dental coverage for you/spouse/family plans.\xa0401k: Company partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan options.\xa0Paid Time Off: untracked time off.\xa0Wedding Week: Enjoy an additional 5 paid days off before or after your wedding.\xa0Creating a Home: After 2 years of employment, Company will give you $5,000 when you buy a home.\xa0Year 3 Vacation: After 3 years of employment, you will be eligible for an all-inclusive vacation.\xa0Year 5 Sabbatical: After 5 years of employment, you will be eligible for a 2-week paid sabbatical.\xa0Donation Matching: Company will match your donation dollar for dollar, up to $250 a year and up to $1,000 if you've been here for 5 years.\xa0Community Involvement: Company encourages employees to take time off for volunteer opportunities throughout the year, including a semi-annual volunteer week in every community we serve.\xa0Product Discount: Enjoy a 20% discount on the products we sell.\xa0"", 'Year 3 Vacation: After 3 years of employment, you will be eligible for an all-inclusive vacation.\xa0', 'Experienced with data presentation tools (Power BI, Tableau, QlikView, etc.).\xa0', 'Working at Company is a once-in-a-lifetime opportunity to help build one of the fastest-growing ecommerce companies in history. We take on challenges that others would call impossible because we have a team of amazing, talented people who collaborate and think bigger together. At Company, you’ll create deep, personal connections and challenge yourself to achieve your most ambitious goals.\xa0', 'Company Bonus: Up to 5% of yearly salary; based upon company and team performance.\xa0', 'Year 5 Sabbatical: After 5 years of employment, you will be eligible for a 2-week paid sabbatical.\xa0', 'Develop, build, and cultivate strong relationships with all stakeholders that are built on trust and respect.\xa0', 'Company is an ecommerce company that connects brands with customers wherever they love to shop online. We delight our customers every day by putting our technology, marketing, and supply chain to work for them behind the scenes. Company has grown into offices and fulfillment centers in 8 cities across 6 states.\xa0', 'Bring energy on a daily basis.\xa0', '2+ years of experience in data warehouse modeling, design, and development.\xa0', 'Dental Insurance: Company will pay half of the dental coverage for you/spouse/family plans.\xa0', 'Product Discount: Enjoy a 20% discount on the products we sell.\xa0', 'Gain a deep understanding of Company’s data and how source system changes affect the data warehouse.\xa0Develop systems and processes to be fast, efficient, and scale to increasing business demands.\xa0Build excellent relationships with team mates and stakeholders that enable you to build the best solutions.\xa0Develop, build, and cultivate strong relationships with all stakeholders that are built on trust and respect.\xa0Collect and analyze system data to guide decisions for feature prioritization, scope, and design.\xa0Take total ownership results of design, solution, or ways to solve measurable problems.\xa0Bring energy on a daily basis.\xa0', 'Creating a Home: After 2 years of employment, Company will give you $5,000 when you buy a home.\xa0', 'Paid Time Off: untracked time off.\xa0', '2+ years of experience in ETL tools (SSIS, DataStage, Informatica, etc.) and OLAP tools.\xa0', 'Develop systems and processes to be fast, efficient, and scale to increasing business demands.\xa0', 'Gain a deep understanding of Company’s data and how source system changes affect the data warehouse.\xa0', 'As a Data Platform Engineer, you will:\xa0', 'Very strong with SQL development skills (stored procedures, views, functions, etc.).\xa0', '401k: Company partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan options.\xa0', 'Who you are:\xa0', 'Collect and analyze system data to guide decisions for feature prioritization, scope, and design.\xa0', 'Quick to learn and adapt to new technologies.\xa0', 'Experienced with on-premises, hybrid, and cloud-based analytical solutions.\xa0', 'Community Involvement: Company encourages employees to take time off for volunteer opportunities throughout the year, including a semi-annual volunteer week in every community we serve.\xa0', 'Experienced with end-user data integration tools (Power Query, Alteryx, etc.).\xa0', '2+ years of experience in data warehouse modeling, design, and development.\xa02+ years of experience in ETL tools (SSIS, DataStage, Informatica, etc.) and OLAP tools.\xa0Very strong with SQL development skills (stored procedures, views, functions, etc.).\xa0Experienced with on-premises, hybrid, and cloud-based analytical solutions.\xa0Quick to learn and adapt to new technologies.\xa0Experienced with end-user data integration tools (Power Query, Alteryx, etc.).\xa0Experienced with data presentation tools (Power BI, Tableau, QlikView, etc.).\xa0', ""Donation Matching: Company will match your donation dollar for dollar, up to $250 a year and up to $1,000 if you've been here for 5 years.\xa0"", '\xa0', 'Aetna HDHP HSA Plan: Company will contribute $500 to an HSA for an employee-only plan or $1000 for your spouse and dependents included on the plan.\xa0', 'Health Insurance: Company offers two plans:\xa0o\xa0Aetna PPO: Company covers 100% of premiums for employees and 50% for your spouse and dependents included on the plan.\xa0', 'Wedding Week: Enjoy an additional 5 paid days off before or after your wedding.\xa0', 'Build excellent relationships with team mates and stakeholders that enable you to build the best solutions.\xa0', 'Equal Opportunity Employer\xa0']",Associate,Full-time,Engineering,Consumer Goods,2021-02-10 11:29:29
Mission Data Scientist,Booz Allen Hamilton,"Alexandria, VA",10 hours ago,Be among the first 25 applicants,"['', 'Meaningful work', '. ', 'Experience as a data scientist supporting intelligence missions', 'Experience with advanced analytic techniques, including data mining, regression analysis, predictive modeling, natural language processing, or machine learning', 'Knowledge of cloud computing, including AWS, solutions architecting, or elastic computing concepts and technologies', 'Experience as a data scientist supporting intelligence missionsExperience with all-source and operational intelligence, including work across the US Intelligence Community or DoDExperience with integrating modeling and automation methods or technology into national or operational intelligence workflowsExperience with advanced analytic techniques, including data mining, regression analysis, predictive modeling, natural language processing, or machine learningExperience with programming languages, including Python, SQL, or RExperience with data visualization technologies, including Tableau or KibanaExperience with system integration for multi-INT operations, including databases and tasking systems for GEOINT, SIGINT, HUMINT, MASINT, or OSINTTS/SCI clearanceHS diploma or GED and 15+ years of experience with supporting intelligence missions or BA or BS degree and 10+ years of experience with supporting intelligence missions', 'HS diploma or GED and 15+ years of experience with supporting intelligence missions or BA or BS degree and 10+ years of experience with supporting intelligence missions', 'Knowledge of artificial intelligence, machine learning, or deep learning concepts and technologies', 'Experience with working in multi-agency or deployed operational environments', 'Experience with working in multi-agency or deployed operational environmentsExperience with working in hybrid teams of analysts and technologists to solve mission-critical intelligence challengesExperience with leveraging new or emerging intelligence capabilitiesKnowledge of cloud computing, including AWS, solutions architecting, or elastic computing concepts and technologiesKnowledge of artificial intelligence, machine learning, or deep learning concepts and technologiesAbility to manage dynamic queries and data integration from national, operational, and tactical intelligence databases, tools, and servicesAbility to create custom automated functions in integrated development environments, visual programming environments, or scripting notebooksMA or MS degree in CS, Engineering, Data Analytics, or a related field', 'Experience with all-source and operational intelligence, including work across the US Intelligence Community or DoD', 'State-of-the-art technology', 'Challenging projects', 'New skills', 'Experience with system integration for multi-INT operations, including databases and tasking systems for GEOINT, SIGINT, HUMINT, MASINT, or OSINT', 'You Have', 'Ability to create custom automated functions in integrated development environments, visual programming environments, or scripting notebooks', 'Job Number: R0081823', 'MA or MS degree in CS, Engineering, Data Analytics, or a related field', 'Experience with integrating modeling and automation methods or technology into national or operational intelligence workflows', 'Experience with programming languages, including Python, SQL, or R', 'Experience with leveraging new or emerging intelligence capabilities', 'TS/SCI clearance', 'Experience with working in hybrid teams of analysts and technologists to solve mission-critical intelligence challenges', 'Nice If You Have', 'Experience with data visualization technologies, including Tableau or Kibana', 'Build Your Career', 'Clearance', 'Ability to manage dynamic queries and data integration from national, operational, and tactical intelligence databases, tools, and services', 'The Challenge', 'Room to grow']",Entry level,Full-time,Engineering,Information Technology and Services,2021-02-10 11:29:29
Data Scientist,thredUP,"Remote, OR",3 hours ago,Be among the first 25 applicants,"['', 'Create mathematical representations of the flow of items into and out of our marketplace', 'Uncover insights in our vast repository of raw data, and provide tactical guidance on how to achieve an assortment that maximizes growth and value for all marketplace participants', ""What You'll Do"", 'About ThredUP', 'Implement algorithmic solutions to drive decisions around item acceptance, item pricing, and discounting and clearance strategies for 3.5M unique items in inventory and 1.5M new items every month', '3 years of full time, professional experience', 'Well-rounded skill set in statistics, machine learning, software development, and project management', 'Advanced knowledge of SQL and Python, and experience writing code in a collaborative environment', ' The opportunity to make a massive impact & influence outcomes for our business and customers alongside passionate coworkers', 'Requirements', ' Autonomy. The ability to make, own, and carry out decisions', 'Prior experience working with marketplaces and/or a relevant background in economics or operations research is a plus', 'Innate curiosity and drive to find insights that unlock new growth or efficiency - you can’t help but dig in and seek the truth', 'We believe diversity, inclusion and belonging is key for our team.', 'Drive the strategy for promotions, merchandising campaigns, and sales, and investigate their effect on inventory and buyer mix', 'Implement algorithmic solutions to drive decisions around item acceptance, item pricing, and discounting and clearance strategies for 3.5M unique items in inventory and 1.5M new items every monthUncover insights in our vast repository of raw data, and provide tactical guidance on how to achieve an assortment that maximizes growth and value for all marketplace participantsDevelop the algorithms and data strategy that power search and discovery, allowing buyers to seamlessly find items they love in our vast assortmentDevelop rigorous forecasting systems to bring predictability to our planning around inventory growth and economicsCreate mathematical representations of the flow of items into and out of our marketplaceDrive the strategy for promotions, merchandising campaigns, and sales, and investigate their effect on inventory and buyer mixParticipate in our knowledge-sharing culture by spreading best practices and learnings from prior experiences, helping the entire team level up', 'At least 3 years of full time, professional experience in data analytics, data science, or software engineering roles', 'What We Offer', ' Flexible PTO', ' Competitive salary, equity and full benefits (health/dental/vision insurance & 401k)', 'Develop rigorous forecasting systems to bring predictability to our planning around inventory growth and economics', 'Ability to effectively work with business leads; strong cross-functional communication skills that help push projects forward and encourage the development of new collaborations', 'At least 3 years of full time, professional experience in data analytics, data science, or software engineering rolesAbility to effectively work with business leads; strong cross-functional communication skills that help push projects forward and encourage the development of new collaborationsInnate curiosity and drive to find insights that unlock new growth or efficiency - you can’t help but dig in and seek the truthWell-rounded skill set in statistics, machine learning, software development, and project managementAdvanced knowledge of SQL and Python, and experience writing code in a collaborative environmentPrior experience working with marketplaces and/or a relevant background in economics or operations research is a plus', 'Participate in our knowledge-sharing culture by spreading best practices and learnings from prior experiences, helping the entire team level up', 'Develop the algorithms and data strategy that power search and discovery, allowing buyers to seamlessly find items they love in our vast assortment']",Entry level,Full-time,Engineering,Marketing and Advertising,2021-02-10 11:29:29
Data Scientist,2U,"Denver, CO",12 hours ago,Be among the first 25 applicants,"['', ' Medical, dental, and vision coverage Life insurance, disability and 401(k) Unlimited snacks and drinks Tuition reimbursement program Generous paid leave policies including unlimited PTO Additional time off benefits include: volunteer days, parental leave, and a company-wide winter break from Christmas through New Years! ', 'Improve defect and outlier detection reporting for data workflows to ensure ML systems are fully operational and accurate', 'Familiarity with AWS and GCP platforms', 'Use PySpark and MLlib to build machine learning models through all phases of development, from design, through training, evaluation, validation, and implementation', 'Unlimited snacks and drinks', '3+ years of experience writing OOP Python code', 'Advanced working SQL knowledge and experience with relational databases', 'Utilize best practices for software development of high performance systems around design, coding, maintenance, and deployment', 'Experience in a data scientist role with a track record of building production ML systems', 'Data exploration and analysis of novel data sources to identify and create new features for predictive models', ' Use PySpark and MLlib to build machine learning models through all phases of development, from design, through training, evaluation, validation, and implementation Data exploration and analysis of novel data sources to identify and create new features for predictive models Utilize best practices for software development of high performance systems around design, coding, maintenance, and deployment Improve defect and outlier detection reporting for data workflows to ensure ML systems are fully operational and accurate Ad hoc analysis and reporting as needed ', 'Experience building ML Pipelines in PySpark/MLlib', 'Life insurance, disability and 401(k)', 'Medical, dental, and vision coverage', '2U Offers a Comprehensive Benefits Package', ' Degree in statistics, mathematics, computer science, economics, or other quantitative field required; Graduate degree preferred 3+ years of experience writing OOP Python code Experience in a data scientist role with a track record of building production ML systems Experience building ML Pipelines in PySpark/MLlib Experience working with GPUs/multithreading to develop models Familiarity with AWS and GCP platforms Advanced working SQL knowledge and experience with relational databases ', 'Responsibilities Include, But Are Not Limited To', 'Ad hoc analysis and reporting as needed', 'Additional time off benefits include: volunteer days, parental leave, and a company-wide winter break from Christmas through New Years!', 'Benefits & Culture', 'Generous paid leave policies including unlimited PTO', 'About 2U Inc. (NASDAQ: TWOU)', '2U Diversity and Inclusion Statement', 'Things That Should Be In Your Background', ""What We're Looking For"", 'Degree in statistics, mathematics, computer science, economics, or other quantitative field required; Graduate degree preferred', 'Experience working with GPUs/multithreading to develop models', 'Tuition reimbursement program']",Entry level,Full-time,Engineering,Marketing and Advertising,2021-02-10 11:29:29
