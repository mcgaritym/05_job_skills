job_title,company,company_rating,location,job_text,date
Data Collection Engineer,"Epiq Systems, Inc.",N/A,"Collegeville, PA 19426","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Computer forensics: 1 year (Preferred)"", 'At least 4-5 years of experience in the electronic discovery industry, IT industry, and/or computer forensic industry and digital forensic data collections', 'Strong technical understanding of Windows, iOS, mobile devices, networks, and computer technologies', 'Experience with e-Discovery data harvesting processes and evidence handling', 'Experience with Robocopy (Robust File Copy), FTK, and other data collection toolsets', 'Strong verbal and written communication skills', 'Available to work evenings and/or weekends if required', 'Experience with Exchange, Office 365, Discovery Accelerator', 'Microsoft Access experience (Preferred, but not required)', 'Responsible for daily electronic data discovery collection efforts including digital forensic data collections', 'Email collection experience using email archiving software such as Veritas Enterprise Vault', 'Responsible for executing project requirements and providing daily status updates', 'Effectively works within a variety of hardware and software technologies', 'Works collaboratively with a team of e-Discovery digital forensic data collection', 'Communicates with Senior Project Manager to resolve issues and provide daily updates', 'Performs quality checks on work related to e-discovery collection requests', ""Follows electronic discovery industry's best practices to ensure work is completed to client satisfaction"", '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Computer forensics: 1 year (Preferred)', 'One location']",2020-12-30 21:49:28
Data Engineer,Applied Information Sciences,4.2 out of 5 from 19 employee ratings,"Chevy Chase, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work in a team using cutting edge technologies to solve challenging business problems and build solutions', 'Interact directly with our client(s) to understand their needs and meet, or exceed their expectations by meeting delivery deadlines', 'Work in an agile environment with participation in daily stand-ups/scrum', 'Design, write, test, troubleshoot, and document data transformations', 'Learn new technologies and be aware of industry standards, best practices, and trends.', '3+ years of experience working with Scala', 'Hands on Programming experience in Scala with Spark for ETL', 'Advanced SQL skills', 'Possess Hive skills with HiveQL.', 'Experience in designing efficient and robust ETL/ELT workflows, schedulers using Oozie, and event-based triggers', 'Big Data Experience - Experience with Ab Initio, MDM, Microstrategy, Cassandra, Hadoop, Spring Cloud', 'Data Operations and Security - experience with tools like Collibra, able to establish data standards and policies', 'Proven ability to work with clients to understand requirements and envision data ingestion solutions', 'Experience with Snowflake', 'Experience with the Azure storage technologies (Azure Data Lake, Azure SQL Data Warehouse, Azure SQL Database)', 'Knowledge of Azure data movement and transformation capabilities (Azure Data Factory, Data Lake Analytics, Data Bricks, Stream Analytics)', 'Knowledge of Talend ETL', 'Microsoft related certifications such as the MCSD/MCSE', 'Smart people with a passion for technology', 'Strong technical capabilities with a consultancy mindset', 'Close involvement with local technical communities', 'A willingness to think outside of the box to provide innovative solutions to clients', 'Ability to solve challenging technical business problems', 'Self-directed professionals', 'Client Success', 'Continued Learning and Technical Excellence', 'Strong Client Relationships', 'Citizenship and Community']",2020-12-30 21:49:28
Data Engineer,Virtusa,3.7 out of 5 from 727 employee ratings,"Buffalo, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 21:49:28
Data Engineer,Rangam Consultants Inc,3.9 out of 5 from 40 employee ratings,"Baltimore, MD 21231","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Python/Scala/SQL programming language, 2 years (Preferred)DevOps, 3 years (Preferred)Data Engineer, 5 years (Preferred)ETL, 2 years (Preferred)', 'Location:Baltimore, MD 21231 (Preferred)', 'The Data Engineer will report to the Sr Manager, Strategic Development and will focus on supporting AI Labs technology stack.', 'The role will heavily leverage DevOps and Agile development practices, as the position further refines and integrates best practices across the client cloud-based AI platform.', 'The Data Engineer will make heavy use of ETL methods to “clean” messy data with machine learning in mind.', 'The role heavily uses Apache Spark to prepare and clean large data sets to solve AI Lab’s most exciting and difficult data challenges.', 'The Data Engineer will work in closely with Data scientists to create data synergy across all domains to ensure clean and reliable delivery of data on the AI Labs platform.', 'Experience in building/operating/maintaining fault tolerant and scalable data processing integrations using Azure', '2+ years’ experience in Python/Scala/SQL programming language', 'Strong problem-solving skills with emphasis on optimization data pipelines', 'Excellent written and verbal communication skills for coordinating across teams', 'A drive to learn and master new technologies and techniques', 'Experience using Docker or Kubernetes is a plus', 'Demonstrated capabilities with cloud infrastructures and multi-cloud environments such as Azure, AWS, IBM cloud', 'Experienced in DevOps and Agile environments and using CI/CD pipelines.', 'Experienced using Databricks & Apache Spark', 'Experienced using Azure Data Factory', 'Health insurance', '8 hour shift', 'Python/Scala/SQL programming language: 2 years (Preferred)', 'DevOps: 3 years (Preferred)', 'Data Engineer: 5 years (Preferred)', 'ETL: 2 years (Preferred)', 'Baltimore, MD 21231 (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 21:49:28
Data Engineer,iknowvate technologies,N/A,"Basking Ridge, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 21:49:28
Big Data Engineer,"Vertex, Inc.",3.8 out of 5 from 65 employee ratings,"King of Prussia, PA 19406","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Provide engineering leadership in all architecture decisions.', 'Provide technical leadership to build and implement data and big data solutions', 'Articulate pros and cons of various technologies, platforms and tools.', 'Define and lead the frameworks for compliance with data management standards for emerging technologies (streaming platforms, cloud integration, etc.)', 'Be part of a core team leading migration to new data technologies for unstructured, streaming and high-volume data.', 'Overall accountability of your work and adopt established data management frameworks to prevent data lakes from becoming data swamps.', 'Provide senior level technical consulting to application development teams during application design and development for highly complex or critical projects.', 'Participate in other projects or duties.', 'Occasional travel required.', 'Expert with Big Data technologies like Hadoop, Hive, HBase, Spark, and various AWS technologies (EMR, Redshift, Athena, Glue)', 'Ability to listen and understand information and communicate the same.', 'Must possess good organizational skills.', 'Must be results oriented, customer focused, and exhibit good interpersonal skills.', 'Demonstrated hands-on experience with at-least one of the major Hadoop distributions (Preferably Cloudera / Hortonworks).', 'Demonstrated work experience with distributed, scalable Big Data programming model and technologies such as Hadoop, Hive, Pig, etc.', 'Deep technical Expertise in Hadoop eco system components.', 'Experience designing, developing and implementing online-machine learning libraries', 'Ability to apply broad expertise or knowledge to contribute to development of company objectives and principles to resolve complex issues in creative ways.', 'Ability to work without supervision. Wide latitude for decision making.', 'Ability to create formal networks involving coordination among groups.', 'Ability to listen and understand information and communicate the same', 'Must possess strong interpersonal, organizational, presentation and facilitation skills.', 'Must be results oriented and customer focused.', 'Proficiency in Microsoft Office packages.', 'Sufficient knowledge of business communication, including telephone, voicemail, and e-mail and operations of office machines, such as photocopier, scanner, and fax.', 'Eight (8) years of experience in dimensional data modeling, ETL development, and Data Warehousing.', 'Five (5) years of experience in Business Consulting-ETL Processes.', 'Three (3) years of experience using BIG Data (BD)-Apache Hadoop (HDFS) Base/Hive/Pig/Mahout/Flume/Scoop/MapReduce/Yarn.', 'One (1) year experience in Cloud Dev and Migration-AWS-Analytics/DW/Redshift.', 'Builds Relationships: Fosters open dialogue and obtains shared commitment to proposals; shared ideas and information to promote mutual understanding, respect, and effective decision-making.', 'Drives for Results: Acts to create opportunities for Vertex or to avoid future problems; has the courage to act with incomplete information rather than simply thinking about it; maintains a focused commitment to achieving enterprise objectives', 'Knows the Business: Understands and applies knowledge of Vertex’s business and processes to accomplish goals.', 'Anticipates Customer Needs (internal and external): Establishes and maintains productive relationships with customers and partners, anticipating their needs.', 'Learns Continuously: Expands own knowledge base to enhance performance; seeks development to increase strengths for current and future needs.']",2020-12-30 21:49:28
Data Engineer and Integration Developer,PCS Global Tech,N/A,"Wayne, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)Data Warehouse: 1 year (Preferred)US work authorization (Preferred)"", 'Help write and optimize in-application SQL statements.', 'Ensure performance, security, and availability of databases.', 'Prepare documentations and specifications.', 'Handle common database procedures such as upgrade, backup, recovery, migration, etc.', 'Write TSQL scripts and objects such as stored procedures, user-defined functions, views, indexes per business requirements.', 'Create ETL SSIS packages to migrate data from OLTP sources to OLAP destinations through available tasks and transformations in SSIS.', 'Design and create user interactive reports in SSRS, Power BI and Tableau.', 'Profile server resource usage, and optimize and tweak as necessary.', 'Collaborate with other team members and stakeholders.', 'BS or MS of degree in Computer Science, Information Technology, Engineering or related field is required', 'Proficiency with SQL and its variation among popular databases', 'Skilled at optimizing large complicated SQL statements', 'Capable of configuring popular database engines and orchestrating clusters as necessary', 'Ability to plan resource requirements from high level specifications', 'Good communication skills', 'Maintain, support, and enhance the business intelligence data backend, including data warehouses and data lakes.', 'Build interfaces between the business intelligence systems and other college information systems to maintain a timely and accurate integration of data.', 'Collaborate and work with data analysts in various departments to ensure that data meets their reporting and analysis needs.', 'Provide technical guidance for design and implementation of data governance systems and policy.', 'Work extensively towards SQL Server development in writing core TSQL scripts to implement complex business logics.', 'Develop SSIS packages to implement complex ETL strategies as a part of business requirements for population of dimensional data structures.', 'Work on creating SSAS cubes and various cube objects such as KPIs (Key Performance Indicators), calculated members, attributes hierarchies and perspectives.', 'Design eye-catching reports with data from OLTP database, dimensional data structure and OLAP cubes for business reporting purposes.', 'Keep abreast of new business intelligence technologies', 'BS or MS of degree in Computer Science, Information Technology, Engineering or related field is required', 'At least 1 year of experience using Microsoft SQL Server Database, SSIS, SSRS, SSAS is required', 'Experience with other relational databases, BI reporting and data discovery tools is preferred', 'Provides plan with data, reporting and analyses that enable data driven decision making.', 'Provides summary analyses in written and oral presentation settings.', 'Builds database from scratch. And prepares complex presentations.', 'Develops system test cases and documents results, researches system issues and documents findings.', 'Bachelor’s degree in Science, Technology, Engineering or Mathematics', 'Ability to translate business requirements into non-technical, lay terms', 'Understanding of addressing and metadata standards', 'High-level written and verbal communication skills', 'Managing master data, including creation, updates, and deletion.', 'Managing users and user roles.', 'Provide quality assurance of imported data, working with quality assurance analyst if necessary.', 'Commissioning and decommissioning of data sets.', 'Processing confidential data and information according to guidelines.', 'Helping develop reports and analysis.', 'Managing and designing the reporting environment, including data sources, security, and metadata.', 'Supporting the data warehouse in identifying and revising reporting requirements.', 'Supporting initiatives for data integrity and normalization.', 'Assessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems.', 'Generating reports from single or multiple systems.', 'Troubleshooting the reporting database environment and reports.', 'Evaluating changes and updates to source production systems.', 'Training end users on new reports and dashboards.', 'Providing technical expertise on data storage structures, data mining, and data cleansing.', 'Bachelor’s degree in Science, Technology, Engineering or Mathematics', '1-3 years of work experience as a data analyst or in related field is preferred', 'Ability to work with stakeholders to assess potential risks.', 'Ability to analyze existing tools and databases and provide software solution recommendations.', 'Ability to translate business requirements into non-technical, lay terms.', 'High-level experience in methodologies and processes for managing large scale databases.', 'Demonstrated experience in handling large data sets and relational databases.', 'Understanding of addressing and metadata standards.', 'High-level written and verbal communication skills.', 'Dental insurance', 'Health insurance', 'Life insurance', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Wayne, PA (Preferred)', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)', 'Data Warehouse: 1 year (Preferred)', '100% (Preferred)', 'Pay', 'Yes: H-1B work authorization']",2020-12-30 21:49:28
Data Engineer,Rackspace,3.8 out of 5 from 366 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build complex ETL code', 'Work on Data and Analytics Tools in the Cloud', 'Develop code using Python, Scala, R languages', 'Work with technologies such as Spark, Hadoop, Kafka, etc.', 'Build complex Data Engineering workflows', 'Create complex data solutions and build data pipelines', 'Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates', 'Capture and share industry best practices amongst the community', 'Attend and present valuable information at Industry Events', 'Drive the engagements with customers from the architectural pillar, from design to delivery, create runbooks etc.', '15+ Years of Data-warehouse and Analytic system development and deployment experience', '10+ years of experience in database architectures and data pipeline development', '8+ years of experience in modern data ware housing platform using cloud native technologies', '5+ years of experience in delivering Azure/GCP/AWS Data Solutions.', 'Demonstrated knowledge of software development tools and methodologies', 'Presentation skills with a high degree of comfort speaking with executives, IT management, and developers', 'Excellent communication skills with an ability to right level conversations', 'Demonstrated ability to adapt to new technologies and learn quickly', 'Experience with Google Cloud Services such as Streaming + Batch, BigQuery, BigTable, DataStudio, DataPrep, Pub/Sub , Cloud Storage, Cloud Dataflow, Data Proc, DataFlow, DFunc, Big Query & Big Table', 'knowledge and proven use of contemporary data mining, cloud computing and data management tools including but not limited to Microsoft Azure, AWS Cloud, Google Cloud, hadoop, HDFS, MapR and spark.', 'Design and configuration of data movement, streaming and transformation (ETL) technologies such as Informatica, Nifi, Kafka, Storm, Sqoop, SSIS, Alteryx, Pentaho, Alooma, Airflow.', 'Creation of descriptive, predictive and prescriptive analytics solutions using Azure Stream Analytics, Azure Analysis Services, Data Lake Analytics, HDInsight, HDP, Spark, Databricks, MapReduce, Pig, Hive, Tez, SSAS.', 'Design and configuration of data movement, streaming and transformation (ETL) technologies such as Azure Data Factory, HDF, Nifi, Kafka, Storm, Sqoop, SSIS, LogicApps, Signiant, Aspera, Alteryx, Pentaho, Alooma, Airflow.', 'Large scale design, implementation and operations of OLTP, OLAP, DW and NoSQL data storage technologies such as SQL Server, Azure SQL, Azure SQL DW, PostgreSQL, CosmosDB, RedisCache, Azure Data Lake Store, Hadoop, Hive, MySQL, Neo4j, Cassandra, HBase', 'Experience working within an agile development process (Scrum, Kanban, etc)', 'Expertise in data estate workloads like HDInsight, Hadoop, Cloudera, Spark, Python.', 'Familiarity with CI/CD concepts', 'Strong verbal and written communications skills are a must, as well as the ability to work effectively across internal and external organizations and virtual teams.', 'Knowledge or hands-on experience with data visualization and/or data sciences.', 'Hands on experience with Azure/GCP projects.', 'Cloud certifications such as GCP Professional Data Engineer or Microsoft Data / AI certifications.', 'Technical degree required; Computer Science or Math background desired', 'This is a virtual role', 'The candidate needs to be based in US or Canada', 'This role would require 25 - 30% travel']",2020-12-30 21:49:28
DATA ENGINEER,OnPoint,3.6 out of 5 from 45 employee ratings,"New York, NY 10118","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Wrangle large and messy datasets to profiling the data, identify patterns, and enable advance analytics', 'Create and manage batch and streaming data pipelines', 'Collaborate with teams to identify opportunities to design and implement data informed solutions', 'Build data expertise and own data quality for allocated areas of ownership', 'Design, build and launch new data extraction, transformation and loading processes', 'Working with OnPoint’s delivery team to solve problems and establish data pipelines', '2+ years professional experience working with SQL and database programming', '2+ years of experience using a scripting language (Python, R etc.) for data preparation, cleaning, and analysis', ""Bachelor's degree in Computer Science, Computer Engineering, Management Information Systems or related field from an accredited institution OR High School Diploma and 4+ cumulative years of relevant work experience"", 'Proficiency in transforming and storing large, distributed datasets (e.g. Hadoop, Redshift, Apache Spark, AWS Athena)', 'Proficiency in designing efficient and robust ETL workflows and integration with data technologies with cloud platforms like AWS/GCP/Azure', 'Proficiency in data streaming technologies like Apache Kafka, Amazon Kinesis, and Apache Spark', 'Experience with Industrial historian like OSIsoft Pi, Aspen 21, or Honeywell PHD etc performing data extraction.', 'Previous experience in the large industrial sector']",2020-12-30 21:49:28
ETL Data Engineer,Integress Inc.,N/A,"Conshohocken, PA 19428","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL: 5 years (Preferred)Enterprise Data Warehouse: 3 years (Preferred)', 'Building scalable Cloud data solutions using MPP Data Warehouses (Snowflake, Redshift, or Azure Data Warehouse/Synapse), data storage (S3 or Azure Blob Storage) and analytics platforms (i.e. Spark, Databricks, etc.)', 'Creation of data pipelines and transformations (ELT – Matillion, FiveTran, DBT, etc. and/or ETL – Informatica, Talend, etc.)', 'Creating data integrations with scripting languages such as Lambda, Python, etc.', 'Writing complex SQL queries, stored procedures, etc.', 'Bachelor’s degree, or equivalent experience, in Computer Science, Engineering, Mathematics or a related field. Commensurate work experience will be considered in lieu of degree', 'Experience building scalable Cloud data solutions using MPP Data Warehouses (Snowflake, Redshift, or Azure Data Warehouse/Synapse), data storage (S3 or Azure Blob Storage) and analytics platforms (i.e. Spark, Databricks, etc.)', '5+ years with complex SQL queries and scripting', '3+ years’ experience with AWS and/or Azure Cloud', '3+ years developing, and deploying scalable enterprise data solutions (Enterprise Data Warehouses, Data Marts, ETL/ELT workloads, etc.)', '3+ years of supporting business intelligence and analytic projects', 'Good understanding of code repositories such as GIT', 'Excellent written and oral communication skills', 'Experience with Kafka, RabbitMQ, SSIS', 'Experience working at a consulting company', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Paid time off', 'Referral program', 'Retirement plan', 'Monday to Friday', 'Bonus pay', 'SQL: 5 years (Preferred)', 'Data Movement: 3 years (Preferred)', 'Enterprise Data Warehouse: 3 years (Preferred)', 'More than 1 year', 'One location', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Aggressive -- competitive and growth-oriented', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.integress.com', 'Temporarily due to COVID-19', 'Remote interview process', 'Personal protective equipment provided or required', 'Temperature screenings', 'Social distancing guidelines in place', 'Virtual meetings', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 21:49:28
Data Engineer,PowerInbox,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build and maintain data services to provide data to analytics users and machine learning systems', 'Build and maintain a reporting service to deliver analytics on a configurable schedule', 'Provide data analytics support for business insights and machine learning optimizations', 'Perform manual and develop automated QA to verify data quality and integrity', 'Maintain data dictionary documentation and encourage the generalization of data solutions', 'Respond to ad-hoc requests for information', 'Experience with Python', 'Three or more years working with distributed big data systems (e.g. Hadoop, Redshift)', 'Professional experience building data science systems with experience building out data pipelines and ETL processes for machine learning', 'Experience working remotely', 'Knowledge in the digital and AdTech landscape']",2020-12-30 21:49:28
Entry level Data Engineer,Cognizant Technology Solutions,"3.9 out of 5 from 13,859 employee ratings","Wilmington, DE 19801","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Scala, Scala and AWS technologies.']",2020-12-30 21:49:28
"Entry-Level Data Positions (Data Engineer, Machine Learning & Visualization)",Citi,"3.9 out of 5 from 17,932 employee ratings","Jacksonville, FL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Data Engineer: Hadoop/Big Data Technologies, Spark, Google or AWS Cloud Development Data Solutions, Scala, Python, SQL. In this role, you will build/manage our Big Data pipelines and manage data migrations.', 'Machine Learning Engineer: Data Engineer skillset plus experience with Machine Learning concepts, frameworks and infrastructure. Here, you will scale our data science models into production-level applications.', 'Visualization Engineer: Angular/React, Java, Tableau. Create customized dashboards for reporting or forecasting models. This can be through full-stack web applications, Tableau or a combination of the two.', 'Degree, certification or commensurate skills in Computer Science, Computer Engineering, Statistics, Mathematics or a related field.', 'Hands-on experience with one or more of Hadoop/Big Data Technologies, Spark, Google or AWS Cloud Development Data Solutions, Scala, Python, Machine Learning concepts/frameworks/infrastructure, Angular/React, Java, Tableau, or SQL.', 'Ability to pass technical interviews consisting of basic algorithmic programming exercises.', 'Must be collaborative and adaptable, with good communication skills.', 'Experience designing and interacting with databases.', 'Knowledge of the principles of software engineering and data analytics.', 'System level understanding - Data structures, algorithms, distributed storage & compute.', 'Experience with containerization and related technologies (e.g. Docker, Kubernetes) is a plus.', 'Knowledge of agile(scrum) development methodology is a plus.', 'Knowledge of SAS is a plus.', 'Experience in the Financial industry is a plus.']",2020-12-30 21:49:28
Data Engineer - Remote,Octane,3.5 out of 5 from 15 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 21:49:28
Data Engineer I,"DUFF AND PHELPS, LLC",3.4 out of 5 from 86 employee ratings,"Pomona, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and build organizational data infrastructure and architecture', 'Choosing the best tools/services/resources to build robust data pipelines for data ingestion, connection, transformation, and distribution', 'Design, develop and manage ETL processes', 'Transform data and engineer new features for machine learning models', 'Versioning data', 'Assist with deploying models to production', 'Working with global teams to deliver models', 'Project or personnel management experience', 'Experience with Azure', 'Experience with Python', 'Experience in dealing with different kind of databases, data sources and formats', 'Experience writing ETL jobs', 'Experience with big data tools like data lakes, Spark, Hadoop, etc.', 'Ability to work with an international team', 'Strong cloud architecture principles: compute, storage, networks, security, cost savings, etc.', 'Experience with NLP tools like spaCy or NLTK preferred', 'Experience with machine learning tools like Tensorflow, PyTorch or Keras preferred', 'Experience with real-time data pipelines', 'Excellent written and verbal communication skills that help represent diverse communities', 'Experience working with diverse teams']",2020-12-30 21:49:28
Data Engineer,TRM Labs,N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)creating ETL Pipelines: 2 years (Preferred)"", 'Building highly reliable data services to integrate with dozens of blockchains', 'Creating ETL pipelines that transform and process petabytes of structured and unstructured data in real-time, ultimately helping financial institutions and governments fight fraud and criminal activity', 'Designing data models for optimal storage and retrieval to support sub-second latency for querying blockchain data', 'Deploying and monitor large database clusters that are performant and highly-available', 'Working cross-functionally with data scientists, backend engineers, and product managers to design and implement, and new data models to support the product', 'Developing your skills through exceptional training as well as frequent coaching and mentoring from colleagues', ""Bachelor's degree (or equivalent) in Computer Science or related field"", '3+ years of experience building real-time and distributed system architecture, from whiteboard to production', 'Strong programming skills in Node, Python, and SQL.', 'Versatility. Experience across the entire spectrum of data engineering, including:', 'Data stores (e.g., ClickHouse, ElasticSearch, PostGres, MongoDB, Redis, and Neo4j)', 'Data pipeline and workflow orchestration tools (e.g., Azkaban, Luigi, Airflow, Storm)', 'Data processing technologies (e.g., Spark)', 'Deployment and monitoring large data base clusters in public cloud platforms (e.g., Docker, Terraform, Datadog)', 'Adaptable. Goals can change fast. You anticipate and react quickly.', 'Autonomous. You own what you work on. You move fast and get things done.', 'Excellent communication. You will need communicate complex ideas effectively to both technical and non-technical audiences, and both verbally and in writing', 'Collaborative. You must work collaboratively in a cross-functional team and with people at all levels in an organization', 'Industry experience building and productionizing innovative end-to-end Machine Learning systems is a plus.', 'Relevant experience in crypto/blockchain is a plus', 'Stock', '$2,000 yearly coupon for books, conferences, and professional coaching', 'Competitive salary: 160K - 250k + Equity', 'Paid time off', 'Volunteer time off', 'Parental leave', 'Medical, dental, & vision insurance', 'Life & disability coverage', '401K', 'Apple equipment', 'Daily lunch and dinner', '401(k)', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Parental leave', 'Vision insurance', '8 hour shift', ""Bachelor's (Preferred)"", 'creating ETL Pipelines: 2 years (Preferred)', 'Fully Remote', 'No: Not providing sponsorship for this job', 'Remote interview process', 'Virtual meetings']",2020-12-30 21:51:11
Oops! That page can’t be found.,TRM Labs,N/A,"San Francisco, CA","['Indeed Jobs', '404', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Facebook', 'Twitter', 'instagram', 'Youtube', 'Soundcloud']",2020-12-30 21:51:11
Jr. Data Software Engineer,Choice Hotels,3.7 out of 5 from 408 employee ratings,"Phoenix, AZ 85054","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Under the direction of senior engineering staff, codes and implements object-oriented component designs. Documents, programs and debugs the specific coding changes necessary to satisfy the component’s functional and technical requirements. Provides development status updates to the senior development and project management, as needed.', 'Prepare the development version of software components for QA testing. Builds the associated release files, unit tests the coding changes and sets up the testing environment for QA. Assists with the development of automated test scripts and pre-production release testing. Supports both the manual and automated testing efforts.', 'Assist with the authoring and analysis of business use case and functional requirements for software component implementations.', 'Support the Productions release of system components and assists with any post-Production issue analysis and problem resolution. Assists with the post-Release audit to identify process improvements.', 'Keep up on industry trends and current technological standards, languages, coding techniques, utilities and operational considerations. Makes suggestions for process, coding, implementation, and performance improvements.', 'Bachelor’s Degree in Computer Science, or related field, from a four-year college or university, or one to two years related experience and/or training; or equivalent combination of education and experience.', 'A minimum of 1-year relevant experience in software development, information systems, or equivalent technical environment. Previous experience in the development of highly transactional, mission critical applications in heterogeneous environments/architectures for multi-user systems is preferred.', 'Demonstrated knowledge of all aspects of the software development lifecycle: design, functional and technical requirements, coding, debugging, testing, release, and operational support.', 'Demonstrated knowledge of agile software development methodologies, Service Oriented Architecture and object-oriented programming methodologies.', 'Demonstrated knowledge of software development best practices, including coding standards, code reviews, source control management, build processes, testing, and operations.', 'Demonstrated knowledge of relational database management system technologies and tools.', 'Proficient with the following technologies:', 'Java', 'Unix/Linux', 'XML, XSLT, DTD or Schema modeling, DOM/XPath/SAX parsing', 'Service oriented designs and technologies (AJAX, XML/JSON)', 'Web service protocols, such as SOAP', 'REST APIs', 'SQL', 'Software development tool kits, such as Subversion and Hudson.', 'Proficient in the use of MS Office applications, such as Outlook, Word, PowerPoint and Excel', 'HTML, CSS and JavaScript (jQuery), AngularJS.', 'Java Server Pages (JSP), XML and XSL.', 'Spring or similar MVC framework for navigating web-based applications.', 'XML transformations to HTML, PDF, or other file formats utilizing XSLT or JavaServer Pages (JSP).', 'Emerging web standards, such as HTML5.', 'Web analytics tools (Omniture, WebTrends, Google Analytics)', 'Adobe Photoshop, Adobe Illustrator, or equivalent tools used for the creation and management of web-', 'based graphics and other content is preferred.', 'Proficient with the following technologies:', 'Java or Objective-C or Swift', 'Android SDK or iOS SDK frameworks', 'For iOS, thorough understanding of memory management in iOS environments', 'Emerging web standards, such as HTML5', 'Web analytics tools (Omniture, WebTrends, Google Analytics)']",2020-12-30 21:51:11
Data Engineer(cosmos & Kusto),Lenora systems,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)"", 'Data Engineering', 'ETL processes', 'Data transformation concepts', 'Open Source', 'PowerBI', 'Python', 'Entry Level Data Science', 'Spark', 'R', 'Monday to Friday', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)', 'Fully Remote', 'Temporarily due to COVID-19']",2020-12-30 21:51:11
Lead Data Engineer,Digital Dhara,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:AWS, 10 years (Required)EMR, 10 years (Required)Scala, 10 years (Required)Spark, 10 years (Required)No-SQL/Dynamo DB , 10 years (Required)', ""Education:Bachelor's (Preferred)"", '8 hour shift', 'AWS: 10 years (Required)', 'EMR: 10 years (Required)', 'Scala: 10 years (Required)', 'Spark: 10 years (Required)', 'No-SQL/Dynamo DB : 10 years (Required)', ""Bachelor's (Preferred)""]",2020-12-30 21:51:11
Data Engineer,Govini,2.5 out of 5 from 4 employee ratings,"Pittsburgh, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Define and lead Govini's data lifecycle strategy across data acquisition, data ingestion, data cleansing, normalization and linkage"", 'Identify data sources, assess their value and quality and estimate the level of effort required to integrate into existing data model, infrastructure and products.', 'Ensure key entities within datasets are identified, resolved and linked to existing entities within the current master data repository.', 'Apply various techniques to produce solutions to large-scale optimization problems, including data pre-processing, indexing, blocking, field and record comparison and classification.', 'Develop, refine and oversee master data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions. Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practices.', 'Improve data sharing, increase data repurposing and improve cost efficiency associated with data management efforts.', 'Build best practices that help with chain of custody of data so it can be easily traced back to the source for accuracy and consistency.', 'Work across functional teams to understand advanced statistical, machine learning, and text processing models. Incorporate them into Govini’s existing data engineering infrastructure.', 'Perform exploratory data analyses, generate and test working hypotheses, prepare and analyze historical data and identify patterns.', 'Work directly with users as well as SMEs to establish, create and populate optimal data architectures and structures, as well as articulate techniques and results using non-technical language.', 'US Citizenship is Required', ""Bachelor's degree in Computer Science, Mathematics or related technical field"", 'Minimum of 3 years direct experience creating sustainable, automated processes for data discovery, curation and synthesis', '3-5 years experience with programmatically manipulating data Experience with PostgreSQL or similar RDBMS', 'Expert at advanced SQL programming', 'Experience utilizing open-source technologies such as Linux, PostgreSQL', 'Proficient usage of common data formats such as CSV, XML, and JSON', 'Requires strong analytical ability and attention to detailAbility to work independently with little supervision', 'A burning desire to tackle hard problems and create sustainable solutions', 'Experience using Amazon Web Services', 'Experience in or exposure to the nuances of a startup or other entrepreneurial environment', 'Strong expertise with scripting languages such as Python, Ruby, Perl', '3-5 years Master Data Management experience including data consolidation, linkage, federation and dissemination']",2020-12-30 21:51:11
Associate Systems Engineer - Data Science,Unisys,"3.7 out of 5 from 2,405 employee ratings","Blue Bell, PA 19422","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Working with a dedicated Artificial Intelligence and Machine Learning team, learning the process for developing high-quality solutions', 'Learn the process and performing data structuring, cleansing, visualization, etc.', 'Learn how to implement and validate predictive models as well as create and maintain statistical models', 'Share your knowledge with the team', 'Work to develop AI/ML Proof of Concepts (PoCs) and deploy models into production for our product offerings', 'Learn about and work on a team to build and deploy MLOps pipelines for existing and new product offerings', 'Tools and Technologies, you will use: Hadoop, Spark, H2O.ai, Cloud AI platforms, containerization; Data visualization tools (Tableau, R Shiny, Plotly, Grafana, etc.)', 'Learn to work in a team environment – This is a global cross-functional team including data analysts, scientists, and engineers', 'Develop and grow skills by delivering high-quality code, data analysis, and data visualization', 'A bachelor’s degree in Computer Science, Math, or related field', 'A hunger to learn and work with emerging and cutting-edge technologies in areas of Data Analytics, Artificial Intelligence, and Machine Learning', 'Key Skills:Strong analytic and algorithmic skillsStrong communication skills to include presenting quantitative concepts in easy to understand formats', 'Technical experience such as:Basic understanding of machine learning and statistical algorithms and techniques.Experience in developing clean, efficient code in languages like R, Python, SQL, etc.Experience working with Cloud-base tooling like AWS and/or Azure preferred.']",2020-12-30 21:51:11
"Data Engineer, Tesla Product Engineering",Tesla,"3.5 out of 5 from 4,571 employee ratings","Palo Alto, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, build and deploy efficient & reliable data pipelines to move and transform data (ETL)', 'Build data pipelines to allow design and service engineers to gain insights into product’s field performance', 'Collaborate with stakeholders in design and engineering team for requirements on different data pipelines', 'Build data pipelines and integrations to auto detect different fault conditions and create notifications for customers or field technicians or remote support engineers', 'Optimize existing pipelines and maintain all domain-related data pipelines', 'BS or higher in computer science/engineering, software engineering, physics, math, electrical engineering or proof of exceptional skills in related fields, with practical engineering experience', 'Hands-on experience using SQL to build and deploy production-quality ETL pipelines', 'Experience writing and deploying Python/Scala + SQL code', 'Hands-on experience using Hadoop, Hive or another MPP database system like AWS Redshift', 'Hands-on experience using SPARK (Pyspark) in production environment', 'Strong aptitude to collaborate with different internal stakeholders to understand requirements and developing systems and tools to meet them', 'Excellent oral and written communication skills', 'As a full time Tesla employee you will receive full benefits from day 1 for you and your dependents.', 'Kaiser and UnitedHealthcare PPO and HSA plans (including infertility coverage)', '3 medical plan choices with $0 paycheck contribution', 'Vision & dental plans (including orthodontic coverage)', 'Company paid Life, AD&D, short-term and long-term disability', '401(k), Employee Stock Purchase Plans, and other financial benefits', 'Employee Assistance Program, Paid Time Off, and Paid Holidays', 'Back-up childcare and employee discounts']",2020-12-30 21:51:11
Data Engineer,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Newark, DE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'BS/BA degree or equivalent experience', 'Advanced knowledge of application, data, and infrastructure architecture disciplines', 'Understanding of software skills such as business analysis, development, maintenance, and software improvement', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', ""Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies."", 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', ""Experience building and optimizing 'big data' data pipelines, architectures and data sets."", 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', ""Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores."", 'Strong project management and organizational skills.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.']",2020-12-30 21:51:11
Data Engineer I,"AbleTo, Inc.",3.9 out of 5 from 58 employee ratings,"New York, NY 10018","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Build and maintain batch and real-time ETL pipelines in a Google Cloud Platform architecture (BigQuery, Dataproc, Firestore, etc.)', 'Identify code quality issues and implement tests to improve future processes.', 'Implement data integrity tests to ensure we are ingesting accurate data.', 'Translate business requirements into actionable data tasks.', 'Partner with business users to understand their needs, come up with end to end solutions, and communicate the results back to the users.', 'Implement high-quality test-driven code.', 'Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.', '1+ years experience coding in Python.', 'Experience working with structured and NOSQL databases.', 'Familiarity with structuring and writing ETLs.', 'Experience working with Airflow and Bigquery is a big plus.', 'Experience working with a multitude of stakeholders is a big plus.']",2020-12-30 21:51:11
Data Engineer,The New York Times,4 out of 5 from 258 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Run and support a production enterprise data platform', 'Design and develop data models', 'Work with languages like Java, Python, Go, Bash, and SQL', 'Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub', 'Develop processes for automating, testing, and deploying your work', 'Make an impact by supporting our original, independent and deeply reported journalism.', 'We provide competitive health, dental, vision and life insurance for employees and their families', 'We support responsible retirement planning with a generous 401(k) company match.', 'We offer a generous parental-leave policy, which we recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid; non gestational parents receive 10 weeks, also fully paid.', 'We are committed to career development, supported by a formal mentoring program and $8,000 annual tuition reimbursement.', 'We have frequent panel discussions and talks by a wide variety of news makers and industry leaders.', 'Join a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups.']",2020-12-30 21:51:11
Data Engineer (recent grad),Experian,"3.8 out of 5 from 1,493 employee ratings","San Diego, CA 92130","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyzing, processing, evaluating and documenting large data sets', 'Researching and implementing conversational AI technology and applications', 'Implementing and experimenting various language models (transformer, BERT, GPT, etc.)', 'Identify/develop appropriate machine learning/deep learning/data mining/text mining techniques to uncover the value of the data', 'Designing data structure and data storage schemes for efficient data manipulation and information retrieval', 'Developing tools for data processing and information retrieval', 'Developing data driven models to quantify the value of a given data set', 'Applying, modifying and inventing algorithms to solve challenging business problems', 'Validating score performance', 'Conducting ROI and benefit analysis', 'Documenting and presenting model process and model performance', 'Degree in Machine Learning, Computer Science, Electrical Engineering, Physics, Statistics, Applied Math or other quantitative fields', '0-2 years of working experience in deep learning and machine learning', 'Ability to independently support existing products', 'Proven track record in modifying and applying advanced algorithms to address practical problems', 'Experience with Natural Language Processing, Natural Language Understanding, and the relevant open-source tools', 'Proficient with advanced deep learning technology and open source tools such as pytorch or tensorflow', 'Experience with regression, Neural Network, SVM, and/or ensemble methods', 'Experience with generative modeling techniques such as GAN', 'Experience in developing, modifying and experimenting advanced language models', 'Experience in developing/applying/evaluating conversational AI technology', 'Proven ability to work independently on development of complex models with extremely large and complex data structures', 'Proficient in more than one of Python, R, Java, C++, or C', 'Robust knowledge and experience with statistical methods', 'Extensive knowledge of SQL', 'Experience with Hadoop and NoSQL related technologies such as Map Reduce, Spark, Hive, HBase, mongoDB, Cassandra, etc.', 'Experience with online, mobile marketing analytics', 'Experience with GPU programming', 'Solid knowledge of Bayesian statistical inference and related machine learning methods.', 'Experience with Agile methods for software development']",2020-12-30 21:51:11
Looker Data Engineer/Developer (Contractor),"Traxion Group, Inc",N/A,"New York, NY 10018","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Requirements Gathering - produce business requirements and process documentation. Will require facing off with multiple business lines and regions. Candidate must possess ability to synthesize user requirements, break them into logical phases and identify key dependencies required for success (e.g. business processes and standards)', 'Design - assist project team with designing functional specifications to meet the business requirements', 'Testing - assist in the creation of system and user acceptance test plans, execution of the testing plans, and coordination of testing execution', 'Training - Coordination and support of training program - work with business areas and training department to develop and/or deploy multi-channel training as needed', 'Ingestion of data from multiple sources using Looker', 'Migrating legacy visualizations to Looker Looks and Dashboards', 'Implementing Looker Best Practices', 'Designing Looker based solutions for both external and internal stakeholders', '2+ years of relevant professional experience', 'Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle, Snowflake)', 'Good understanding of SQL Engine and able to conduct query performance tuning', 'Experience with at least one of the following Visualization Tools (PowerBI, Microstrategy, or Tableau) and Looker', 'Implementation of a Looker Environment', 'Business Analysis Skills']",2020-12-30 21:51:11
Senior Data Engineer,GITSUS,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift', 'Yes']",2020-12-30 21:51:11
Data Engineer,EnergyHub,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '', 'Improve reliability, recovery, and integrity of our data ingestion pipeline', 'Develop reporting tools to help our in-house experts and utility clients understand the impact of our services', 'Work with our in-house Advanced Grid Services/Analytics team to productionize exciting new services for utilities', 'Experience developing automated ETL pipelines with high reliability requirements', 'At least 2 of years of experience working on a professional web development team', 'Demonstrated expertise with at least one RDBMS', 'Demonstrated expertise with MongoDB, DynamoDB or similar document-oriented data store', 'Dealing with streaming ingestion', 'Improving reliability of ETL pipelines', 'Improving data recovery processes', 'Improving tooling for data correctness', 'Python or Java experience', 'Collaborate with outstanding people: Our employees work hard, do great work, and enjoy collaborating and learning from each other.', 'Make an immediate impact: New employees can expect to be given real responsibility for bringing new technologies to the marketplace. You are empowered to perform as soon as you join the team!', 'Gain well rounded experience: EnergyHub offers a diverse and dynamic environment where you will get the chance to work directly with executives and develop expertise across multiple areas of the business.', ""Work with the latest technologies: You'll gain exposure to a broad spectrum of IoT, SaaS and machine learning challenges, including distributed fault-tolerance, device control optimization, and process modeling to support scalable interaction with disparate downstream APIs."", 'Be part of something important: Help create the future of how energy is produced and consumed. Make a positive impact on our climate.', ""Focus on fun: EnergyHub places high value on our team culture. Happy hours and holiday parties are important to us, but what's also important is how our employees feel every single day.""]",2020-12-30 21:51:11
Data Engineer - Remote,Analysts International,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Familiarity with spark programming paradigms (batch and stream-processing)', 'Understanding of different data abstraction objects used in spark for different use cases, use of optimal data format and other optimization techniques', 'Strong programming skills in at least one of the following languages: Java, Scala. Familiarity with a scripting language like Python as well as Unix/Linux shells', 'Strong knowledge of writing optimized Spark & Hive sql and experience to tune poor performing queries', 'Outstanding programming and debugging skills', 'Strong knowledge of common algorithms and data structures', 'Good understanding of job scheduling and workflow orchestration through enterprise scheduling tools preferably CA-Automic or Control-M', 'Strong experience with SQL and relational databases like PostgreSQL, MySQL, Teradata, SQL Server Familiarity with one or more stream processing / queuing technologies like Spark Streaming, Kafka, Kinesis, Flink, etc. preferred.', 'Familiarity and prior experience with Agile / Scrum development methodologies', 'Prior Experience deploying to cloud platforms, preferably Azure or AWS Cloud', 'Familiarity with any Object-Oriented Programming language', 'Prior experience in Continuous Integration/Continuous Delivery tools and pipelines such as Jenkins, Maven, Gradle, etc.']",2020-12-30 21:52:55
Data Engineer,HASH,2.5 out of 5 from 6 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 21:52:55
Big Data Engineer,Vanguard,"3.8 out of 5 from 1,026 employee ratings","Malvern, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Undergraduate degree in computer science or analytically oriented subject', 'Minimum 3 years of developer or software engineering experience', 'Expertise in Python, Spark, AWS, SQL, Hive, Presto or other data analysis, data mining and programming tools is essential', 'Experience with business intelligence tools such as Tableau, Power BI or equivalent preferred', 'Exceptional organizational and interpersonal skills required']",2020-12-30 21:52:55
Data Engineer,"Trobus Technologies,LLC",N/A,"Cockeysville, MD 21030","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 5 years (Preferred)"", '8 hour shift', ""Bachelor's (Preferred)"", 'SQL: 5 years (Preferred)', 'One location', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'www.trobustech.com', 'Remote interview process']",2020-12-30 21:52:55
AWS Data Engineer,VTS Technologies LLC,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:AWS Glue, 2 years (Required)Hive, 3 years (Required)PySpark, 3 years (Required)Big Data, 5 years (Required)', ""Education:Bachelor's (Required)"", 'Position that is responsible for the design, development, testing, and support of the Big Data Analytics solutions on cloud (AWS) in collaboration with cross functional teams.', 'Collaborate with key stake holders and translate business requirements to technical requirements and implement solutions under the guidance of technical leads.', 'Dive into large, noisy, and complex real-world customer TV and Digital Ad viewing data to do pre-campaign planning and post campaigns performance measurement using Big data Platform (DataBricks, Pyspark, Glue, EMR).', 'Responsible for building automated data pipelines to ingest data, integrate data from multiple data sources (On-Premise & Cloud) and create aggregated data sets for reporting needs.', 'Strong understanding of database structures, query languages (e.g. SQL), fundamentals of mathematics, distributed systems (Hadoop), data science, and statistical concepts.', 'Experience consolidating and integrating data from multiple sources (On-Premise & Cloud).', 'Ability to analyze, transform and aggregate large data sets (Big Data) using BI tools (Hive QL, Pyspark, Jupyter Notebooks, AWS Athena, AWS Glue).', 'Ability to automate PySpark Jobs using Lambda/Glue/EMR/Python and fine tune for performance.', 'Ability to Architect and Design Big Data Analytics solutions on cloud (AWS).', 'Knowledge of Media/Advertising industry.', '5+ years of Hands-on experience in Big Data Analytics geared towards BI insights.', '3+ years of Hands-on experience working on data pipelines, automation of jobs using big data technologies (Spark, Python, Pyspark, Glue).', '3+ years of experience working with Linux, DataBricks, and Azkaban or similar tools.', 'Strong knowledge of SQL, Python and relational databases.', 'Knowledge of AWS services such as Glue, Athena, Lambda, EC2, IAM, CloudWatch, EMR, S3 and Big data Query engines like Hive, Presto, Spark.', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', '8 hour shift', 'AWS Glue: 2 years (Required)', 'Hive: 3 years (Required)', 'PySpark: 3 years (Required)', 'Big Data: 5 years (Required)', ""Bachelor's (Required)"", 'Yes', 'Remote interview process']",2020-12-30 21:52:55
Data Engineer,Starry,3.6 out of 5 from 20 employee ratings,Massachusetts,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with stakeholders to build data pipelines and tooling for their work', 'Become a domain expert for certain datasets within Starry', 'Build tools to monitor the flow and quality of data moving through our data pipelines', 'Lead by example with best practices in coding and automation', 'Work on an evolving data infrastructure platform at a fast growing company', 'Participate in code reviews and design meetings', 'Learn new tools and concepts on the job', 'Communicate with analytics and engineering stakeholders to help you get the job done', 'Participate in a positive work environment', '3+ years data engineering experience', 'Python and SQL fluency', 'Experience with relational databases like PostgreSQL', 'Experience with batch ETL', 'Experience with Git and CI/CD within the context of data engineering', 'GIS data experience', 'Spark experience', 'Serverless experience', 'AWS ecosystem experience', 'Streaming data experience with Kafka or Kinesis', 'Orchestration experience with frameworks like Airflow', 'Front end experience', 'Container experience with frameworks like Docker', '100% employer paid low deductible health plan, dental plan, vision plan, AD&D and life insurance', '401(k) retirement plan and stock options', '12 weeks of 100% paid parental leave for new mothers and fathers after one year of employment', 'Professional development assistance after six months of employment', 'Catered meals on a weekly basis for employees working in the office', 'Casual dress, community clubs, annual fitness reimbursement, stocked kitchen and other perks and discounts']",2020-12-30 21:52:55
Data Engineer,USA for UNHCR,3.5 out of 5 from 16 employee ratings,"New York, NY 10001","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Write code to build ETL processes to integrate information from various enterprise IT systems.', 'Ability to perform API integrations on platforms such as Salesforce Marketing Cloud. We use Postgres SQL for our data stores and AWS for hosting.', 'Design new data structures, add to and optimize existing data schemas.', 'Ability to analyze upstream and downstream effects of a change in existing data structures and planning for change management.', 'Understand key strategies and business processes of internal clients across the organization in order to provide the best solution to achieve their outcomes.', 'Conduct analyses of business or technical user needs, document requirements and design tailored data solutions.', 'Monitor performance of ETL processes and build in redundancies to avoid risk of an information outage.', 'Provide support and troubleshoot questions arising from report developers and business users of these data solutions.', 'Well versed in specific industry best practices, and an ability to adapt them to U4U’s environment.', 'Ability to work effectively across multiple complex projects.', 'Research and recommend innovative and automated approaches.', 'Bachelor’s degree in computer science, information systems or related field required and/or combined equivalent of education and experience. Master’s degree preferred.', 'At least 6 years of experience as a business or technical professional in business intelligence, data modeling or related field.', 'Experience with data integration, building database objects using SQL, optimizing queries and writing stored procedures. (> 5 years.)', 'Experience in writing SQL queries, coding in Python, and creating systems in the Cloud Computing Space, preferably Amazon Web Services Redshift and/or Salesforce Nonprofit Success Pack (Salesforce NPSP.)', 'Experience in Extracting, Transforming and Loading (ETL) tools from various platforms, database management systems, disparate data sources, and APIs.', 'Experience in defining and documenting complex systems requirements.', 'Strong ability to work in multi-disciplinary teams to analyze business requirements and recommend solutions.', 'Strong communication skills translating technical to non0technical audiences.', 'Experience with CRM’s, preferably Salesforce.', 'Experience with working on different file types for both structured and unstructured data.', 'Must be self-sufficient and self-motivated', 'Basic knowledge and experience in machine learning to support data science solutions.', 'Demonstrates sound judgement and strong decision-making skills', 'Demonstrates emotional intelligence when interacting with employees, peers and vendors', 'Demonstrates passion for U4U’s mission']",2020-12-30 21:52:55
Big Data Engineer (Remote)- Contract,Glow Networks,3.5 out of 5 from 46 employee ratings,"Budd Lake, NJ 07828","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 21:52:55
Data Engineer,myAgro Farms,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data architecture: Working collaboratively with the team, design how we will build myAgro’s data systems, applications, and pipelines so it can scale to support 1 million farmers and the related team.', 'Data tools development: Build data pipelines, data processing tools, and other software development work to support the building and rollout of the data roadmap.', 'Data processes and standards: Oversee the data pipeline process, providing support and training on techniques for working with data and create processes and standards to use within myAgro for future team growth.', 'Support: Collaboratively troubleshoot, fix bugs and be responsive to myAgro’s ticketing platform. Solve problems quickly and communicate with related teams as needed', 'Data reporting: Understand user needs, and build reports and dashboards to help users directly interact with data and gain insight into what is happening. Analyze data (past and current) to show trends, spotlight problems or bright lights to help reach enrollment, payment and impact targets', 'Proven, strong communication skills and ability to work cross culturally', 'Experience working with Python', 'Experience building data processing pipelines', 'Proven record of being a self-starter and delivering on projects.', 'A passion for the mission, vision and values of myAgro', 'Familiarity with using common development tools (ticketing, version control)', 'Knowledge of databases.', 'Experience driving data initiatives and/or data quality programs.', 'Experience working with Tableau or similar tool is a plus, but not required', 'French proficiency a plus but not required. The tech team primarily works in English']",2020-12-30 21:52:55
Data Warehouse Engineer,i3infotek,N/A,"West Chester, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL', 'Data Warehouse', 'SSIS', 'Dimensional Model Experience', 'SSAS', 'Azure Lake experience a plus', 'Azure Data Factory a plus', 'Azure Data Warehouse a plus.', 'Tableau a plus']",2020-12-30 21:52:55
"Data Engineer, Pax River",LOCKHEED MARTIN CORPORATION,"4 out of 5 from 8,473 employee ratings","Patuxent River, MD 20670","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Basic understanding of data gathering processes.', 'Must be proficient in the use of large data servers and computer peripherals for the purposes of data downloading, processing, managing, backup and recovery.', 'Knowledge of instrumentation devices to develop, test, and troubleshoot data processing algorithms for aircraft data.', 'Demonstrate strong analytical and troubleshooting skills;', 'Demonstrate ability to work independently.', 'Experience in computer programming and windows servers.', 'Must be able to work effectively across several different disciplines in a collaborative environment', 'Must be able to communicate effectively (both orally and written)', 'Must be well-organized and able to handle multiple assignments', 'Must be a US citizen.', 'Must currently have and/or be capable of obtaining a security clearance.', 'Must currently have or be capable of successfully completing an NCIC criminal background check to access Pax NAS.', 'Must currently have or be capable of obtaining full unescorted access Pax NAS.', ""Must have a valid photo ID (driver's license + social security card or birth certificate OR US passport)."", ""Must have valid driver's license/vehicle insurance to drive on base at Pax NAS."", 'Experience in installation, testing, operating, troubleshooting, and maintenance of hardware and software systems', 'Experience in monitoring and maintaining computer system or network hardware or software applications', 'Experience in data processing']",2020-12-30 21:52:55
Data Engineer,TCS,3.8 out of 5 from 199 employee ratings,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience in Data ingestion tools like Azure data factory and Talend', 'Good understanding of Azure Databricks and the Spark eco-system', 'Experience of data analysis and transformation using Python (Pyspark)', 'Experience of setting up Azure data bricks and ingesting data from varied sources.', 'Experience in creation of jobs, clusters and setting up security in Azure data bricks', 'Experience of using custom libraries in Azure databricks', 'Comfortable coding using Python(Scala is added advantage)', 'Experience years of design and implementation experience in Big Data technologies', 'Experienced with performance tuning, troubleshooting, and debugging in Azure databricks', 'Familiarity with database and analytics technologies in the industry including Data Warehousing/ETL, Relational Databases', 'Ability to manage and work with multiple stakeholders like customer Tech team, Business, Data Scientist', '']",2020-12-30 21:52:55
Data Engineer,Quick Quack Car Wash,4.2 out of 5 from 195 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL databases: 1 year (Preferred)Big Data Kafka/Druid/Hadoop: 1 year (Preferred)Python: 1 year (Preferred)"", '401(k)', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'SQL databases: 1 year (Preferred)', 'Big Data Kafka/Druid/Hadoop: 1 year (Preferred)', 'Python: 1 year (Preferred)', 'Fully Remote', 'www.dontdrivedirty.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19', 'Remote interview process']",2020-12-30 21:52:55
Data Engineer,Amazon.com Services LLC,"3.6 out of 5 from 67,873 employee ratings","Arlington, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'BA/BS in Computer Science, Information Systems, Engineering, or related technical field.', '4+ years of relevant work experience in a role requiring application of analytic skills to develop data pipelines to support downstream reporting.', 'Experience building/operating distributed systems of data extraction, ingestion, and processing of large data sets from multiple sources.', 'Knowledge of data warehousing fundamentals, ETL development, and data storage principles.', 'Advanced SQL and query performance tuning skills.', 'Coding proficiency using Python, R, Scala, or other scripting languages.', 'Own development, design, and maintenance of big data architectures to support querying of diverse datasets to be queried for legal and regulatory bulk data requests.', 'Translate ambiguous business problem statements into data warehousing requirements. Work with internal customers to define best output based on expressed stakeholder needs.', 'Produce scalable mechanisms to validate, monitor, and troubleshoot operational or data issues in data pipelines.', 'Learn and navigate compliance related requirements for storing and using bulk data.', 'MBA or Master’s degree in Computer Science, Information Systems, Engineering, or related technical field.', 'Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies.', 'Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams.', '5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets.', 'Linux/UNIX experience, including to process large data sets.']",2020-12-30 21:52:55
Data Engineer,Teton Outfitters,N/A,"Spokane Valley, WA 99216","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'A Bachelor’s degree or higher in an analytics field such as statistics, mathematics, economics, or related field, or equivalent experience', '3+ years experience in data engineering or similar field', 'Demonstrated ability to effectively define and deliver innovative data pipelines, providing actionable data-driven insights to the team', 'Strong understanding of database development and structure, along with manipulation and management of existing datasets', 'Mine, retrieve, and manipulate high-volume, high-dimensionality data from varying sources to enable the highlighting of patterns, anomalies, relationships, and trends', 'Work with your team to develop and deliver presentations succinctly and effectively, communicating technical ideas to non-technical audiences', 'Proactively identify and develop expertise in new technologies, methodologies, and techniques', 'Lead cross-functional projects from ideation/conception through implementation', 'Ensure data integrity; collaborate with internal stakeholders and business partners to identify rules, procedures, and policy; work with other staff in data gathering and reporting.', 'Strong experience building and working with data warehouses and ETL flows', 'Advanced SQL knowledge, in depth experience with, Snowflake, Matillion, Netsuite, Power BI, Excel, Python, R, Stitch or related software', 'Experience with HTML, CSS, Ruby*, JS, and other client-side languages a plus', 'A curious and proactive mentality, with a “see it, own it, do it” approach', 'Entrepreneurial spirit and creative approach to problem solving', 'Demonstrated strong verbal and written communications skills', 'Strong interpersonal skills with ability to relate at all levels.', 'Strong analytical skills', 'Ability to effectively work with cross-functional teams to achieve results', 'Interpret and/or discuss information with others, which involves terminology or concepts not familiar to many people. (We’re a bunch of outdoor thrill seekers, afterall)', 'Strong ability to provide advice and recommend actions involving complex and cross-functional issues. May resolve problems within established practices.']",2020-12-30 21:52:55
Data Engineer,Amazon.com Services LLC,"3.6 out of 5 from 67,873 employee ratings","Arlington, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'BA/BS in Computer Science, Information Systems, Engineering, or related technical field.', '4+ years of relevant work experience in a role requiring application of analytic skills to develop data pipelines to support downstream reporting.', 'Experience building/operating distributed systems of data extraction, ingestion, and processing of large data sets from multiple sources.', 'Knowledge of data warehousing fundamentals, ETL development, and data storage principles.', 'Advanced SQL and query performance tuning skills.', 'Coding proficiency using Python, R, Scala, or other scripting languages.', 'Own development, design, and maintenance of big data architectures to support querying of diverse datasets to be queried for legal and regulatory bulk data requests.', 'Translate ambiguous business problem statements into data warehousing requirements. Work with internal customers to define best output based on expressed stakeholder needs.', 'Produce scalable mechanisms to validate, monitor, and troubleshoot operational or data issues in data pipelines.', 'Learn and navigate compliance related requirements for storing and using bulk data.', 'MBA or Master’s degree in Computer Science, Information Systems, Engineering, or related technical field.', 'Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies.', 'Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams.', '5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets.', 'Linux/UNIX experience, including to process large data sets.']",2020-12-30 21:54:36
Data & Analytics Intern,Perchwell,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Currently pursuing, or have completed a bachelor's degree in a relevant analytics field. This can range from a degree in finance or economics to something along the lines of political science."", 'Applicable coursework having to do with analysis and critical thinking to effectively interpret data', 'Strong skills using data processing software (Microsoft Excel, Tableau, etc.)', 'Be able to work independently as well as collaborate with others. Making sure you can own and understand trends to make our platform more effective is critical.', 'Demonstrated interest in real estate', 'Desire to be a part of a small but rapidly growing company that requires employees to be multi faceted and adaptable.', 'Work alongside web developers to implement beneficial changes to the platform', 'Daily data review and clean up as data comes in through various sources. This involves constantly looking for trends and patterns to better the process and become more efficient.', 'Provide quarterly data and analyses to clients in order to support market updates and insights into general market trends.', 'Think about the data creatively to reduce time spent processing individual nodes', 'Drive the backend of the software platform and strive to build a more comprehensive database', 'Perform ad-hoc analysis to review and check data as new features, markets and initiatives are rolled out.', 'Collaborate with engineers, product and customer success teams to identify existing or new problems and come up with solutions to address and fix them.', 'Identify projects and initiatives to improve data and be more efficient when expanding to new markets.', 'Contribute to the development of something new in the real estate field', 'Quarterly market reports for major real estate brokerages', 'Designing a new interface for defining and documenting incorrect unit floor numbers in buildings', 'Creating a system to designate private outdoor space for individual units', 'Research and compile NYC neighborhood boundaries for different clients', 'Competitive compensation']",2020-12-30 21:54:36
Data Engineer,"Trobus Technologies,LLC",N/A,"Cockeysville, MD 21030","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 5 years (Preferred)"", '8 hour shift', ""Bachelor's (Preferred)"", 'SQL: 5 years (Preferred)', 'One location', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'www.trobustech.com', 'Remote interview process']",2020-12-30 21:54:36
Data Engineer,Divi Technologies,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Python: 4 years (Required)Bachelor's (Preferred)"", 'Work closely with software engineers and architects to extract, transform, and standardize data to prepare for ingest into target sources', 'Design and develop data services and/or pipelines as part of an Agile/Scrum team', 'Support continuous process automation for data ingest', 'Work with program management and engineers to implement and document complex and evolving requirements', 'Perform multiple tasks simultaneously and successful perform under changing requirements and deadlines', 'Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork.', 'Must be a US Citizen', 'Must be able to obtain a Public Trust Clearance', 'BS degree in Computer Science or related IT field/equivalent experience', '5+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.', 'Experience handling multiple tasks, changing priorities, and timely action;', 'Experience with developing data pipelines from many sources for structure and unstructured data sets in a variety of formats', 'Proficiency developing data extraction, transformation, and loading (ETL) processes, and performing test and validation steps', 'Proficiency with Python, R, and SQL languages, as well as various command line interfaces (Linux, AWS, Git Bash, etc.)', 'Proficiency with R Studio', 'Technical proficiency with various database architectures, designs, and modeling', 'Familiarity with Hive, Hadoop, Kylin, and other big data analytic tools', 'Excellent communication, and presentation skills with the demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences with an impeccable attention to detail', 'Experience with DHS and knowledge of DHS standards a plus', 'Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions', 'Mid-level expertise in developing and managing data technologies, technical operations, reusable data services, and related tools and technologies', 'Demonstrated ability to adequately plan and meet delivery objectives and maintain adequate service levels in a highly dynamic, complex environments', '8 hour shift', ""Bachelor's (Preferred)"", 'R Studio: 3 years (Preferred)', 'Python: 4 years (Required)', 'Remote interview process']",2020-12-30 21:54:36
Data Engineer,"FYI-For Your Information, Inc.",N/A,"Washington, DC 20036","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Opportunity to work remotely (per contract requirements).', 'A knowledgeable, high-achieving, experienced, and fun team.', 'A diverse work atmosphere.', 'The chance to be part of a rapidly growing company and the next success story.', 'Team building and innovation.', 'A competitive base salary with a loaded benefits package plus 401K.', 'Personal computer device allowance.', 'Pet Insurance.', 'Oversee the buildout of the enterprise Data Warehouse/API strategy', 'Work with the analytics teams to prioritize data assets', 'Manage contractors and oversee solution delivery', 'Optimizing data ingest and ETL processes to ensure our products have maximum performance', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Navigate conflicting priorities and provide recommendations to the CDO when necessary', ""Experience building and optimizing 'big data' data pipelines, architectures and data sets."", 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Work with the Enterprise Architect to establish modeling standards, data quality standards, data integration patterns or transactional and analytical systems.', 'Prepare polished technical and non-technical status reports and presentations for senior management.', '12+ years of experience in data management or data architecture', 'Experience managing vendors/contractors', 'Experience with feature/product ownership', 'Experience with Agile Scrum methodology', 'Experience writing clear and effective proposals, policies, research summaries, etc.', 'Development experience with MuleSoft and Informatica preferred; MicroStrategy a plus', ""Bachelor's degree or equivalent coursework in data management/computer science""]",2020-12-30 21:54:36
Madewell Data Engineer,Madewell,4.1 out of 5 from 159 employee ratings,"Long Island City, NY 11101","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Get us – a passion for the brand that shows up in everything you do, everyday.', 'Be a strategic thinker – spend time and energy on what drives the greatest results.', 'Look under rocks, be curious, ask questions and use your smarts to think boldly and do the right thing.', 'Be a team player – cultivate productive relationships with cross-functional business partners.', 'Communicate consistently, with purpose and an understanding of your audience.', 'Be a multi-task master – make quick decisions under tight timelines.', 'Be nimble and comfortable with change.', 'Work independently and take the lead, even when all of the pieces are not in place.', 'Articulate your point of view and have the courage and conviction to stand up for your beliefs.', 'Have a great fashion esthetic and be all over what’s happening in the industry.', 'Always be on, up for anything and ready to have fun along the way.', 'Translate business requirements into effective and resilient data pipelines and data models', 'Implement best practices to ensure data quality throughout our data pipelines and integrations', 'Recommend improvements and modifications to existing data integrations and ETL/ELT', 'Handle various data formats including structured (databases) and semi-structured (XML, JSON, csv)', 'Design and develop scalable, high performing data models for a wide range of business groups, including Store Operations, Financial Planning, Allocation, Merchandising, Web and Marketing', 'Forge a strong partnership with our business stakeholders to ensure success of data initiatives', 'Evangelize a data-driven culture and processes using modern tools and methodologies', 'Administer Snowflake database and data orchestration tools', 'Strive to implement data governance throughout the enterprise', 'Identify operational data issues and recommend strategies to resolve data problems.', 'Resolve critical data issues as they arise', 'Have experience designing and developing enterprise data warehouses', 'Be able to work with minimum supervision and proactively prioritize tasks', 'Have a bachelor’s degree. Preferred bachelor’s degree in a Technical Field;', '4+ years of experience in the data warehouse space in hands-on roles', '4+ years of experience in writing complex SQL and ETL/ELT processes, preferably in a retail, brand manufacturing or consumer-facing company', '4+ years of experience with schema design and dimensional data modeling', '1+ years of experience with object-oriented programming languages, like Java or Python', 'Preferred experience in a retail, CPG or e-commerce company']",2020-12-30 21:54:36
Jr. Data Engineer- Data Engineering Development Program,MassMutual,"3.7 out of 5 from 1,262 employee ratings","Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build conceptual and logical data architecture design', 'Develop, monitor, and manage data systems across our platform', 'Process disparate data sources and form a high integrity, high quality, clean data asset', 'Contribute to batch pipelines, data modeling, and data mart solutions', 'Work on collaborative project teams working to implement robust data collection and processing pipelines', 'Work across departments to understand data patterns', 'Data structures and databases', 'Designing data processing systemsÂ', 'Data Warehousing', 'Data Mining', 'Comprehension of distributed systems', 'Comprehension of Software Development Principles', 'Algorithms Design', 'Machine learning', 'Designing for reliability, security and compliance', 'Americas Best Employer for Diversity Forbes (2019)', 'Score of 100 on the Human Rights Campaign Corporate Equality Index (2019)', 'National Association for Female Executives Top Company for Executive Women (2018)', 'Disability Equality Index (DEI) Best Place to Work for Disability Inclusion (2019)', 'Diversity Best Practices Inclusion Index Company (2018)', 'Solid computational and technical proficiency', ""Bachelor's Degree in computer science or a related discipline"", 'Working proficiency in at least one programming language such as R, Python, or SQL', 'Demonstrated 6 month work experience through part time employment or other endeavors including internships', 'Commitment to data integrity', 'Ability to take graduate courses concurrent with a full-time work schedule', 'Ability to function well in unstructured environments, working with challenging problems', 'Self-motivated, enthusiastic learner', 'Authorized to work in the United States, with or without requiring sponsorship both now and in the future']",2020-12-30 21:54:36
Summer 2021 Data Engineering Intern,The New York Times,4 out of 5 from 258 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Run and support a production enterprise data platform', 'Design and develop data models', 'Work with languages like Java, Python, Go, Bash, and SQL', 'Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub', 'Develop processes for automating, testing, and deploying your work', 'Our internships are paid', 'It is 10 weeks long', 'You will work remotely during the summer.', 'Interning at The New York Times is a unique opportunity to work at a historic and innovative global media organization dedicated to enhancing society by creating, collecting and distributing high-quality news and information', 'You will be helping to power, distribute and expand what is possible for our award-winning journalism', 'We run a week-long maker event during the summer, where Design, Product, Project, Marketing and Technology come together', 'to work on creative, cross-functional projects', 'We have frequent panel discussions and talks by a wide variety of news makers and industry leaders', 'NYT interns benefit from competitive pay, great perks and influential networking']",2020-12-30 21:54:36
Data Engineer,Seven Gomax Consulting,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'BS or MS degree in Mathematics, Computer Science, Statistics.', '5+ years of Hands-on experience in Big Data Analytics geared towards BI insights.', '3+ years of Hands-on experience working on data pipelines, automation of jobs using big data technologies (Spark, Python, Pyspark, Glue).', '3+ years of experience working with Linux, DataBricks, and Azkaban or similar tools.', 'Strong knowledge of SQL, Python and relational databases.', 'Knowledge of AWS services such as Glue, Athena, Lambda, EC2, IAM, CloudWatch, EMR, S3 and Big data Query engines like Hive, Presto, Spark.', 'Hands-on experience working with Big Data and building Data Analytics solutions on Cloud (AWS).', '8 hour shift']",2020-12-30 21:54:36
Data Engineer,Pixelberry Studios,5 out of 5 from 2 employee ratings,"Mountain View, CA 94043","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with leadership, engineers, program managers and data scientists to understand data needs.', 'Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms', 'Educate your partners: Use your data and analytics experience to ‘see what’s missing’, identifying and addressing gaps in their existing logging and processes.', 'Leverage data and business principles to solve large scale web, mobile and data infrastructure problems.', 'Build data expertise and own data quality for your areas.', '3+ years of python development experience', '3+ years of database experience and strong SQL knowledge', '2+ years of experience in cloud infrastructure and Microservices', '2+ years of big data experience and knowledge of data warehouse architecture', 'Strong understanding of Architecture, Design Patterns and Software Principles', 'Computer Science degree, or equivalent work experience', 'Good communication skills', 'Custom real-time ETL design experience', 'Redshift experience', 'Experience with the AWS stack (S3, EC2, ECS, Lambda, Step Functions, etc)', 'Experience of providing SQL debugging and support to analysts/BI', 'Handling data from multiple sources with different formats', 'Knowledge of mobile gaming metric', 'Competitive salary.', 'High level of autonomy and freedom.', 'Work from home Tuesdays and Thursdays (Pre-Covid)', 'Full benefits package (PTO, 401k, Medical, Dental, Vision).', 'Free food and snacks, movie nights, and field trips (Pre-Covid)', 'Feel good about what you do.', 'Great environment to grow and makes a difference', 'Learn about the business side of mobile games. Our team is very good at what we do.', 'Good work/life balance. We are family-friendly and look at things in the long term.']",2020-12-30 21:54:36
Data Engineer,Airspace Technologies,3.9 out of 5 from 20 employee ratings,"Carlsbad, CA 92011","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work as part of the data engineering team to define and develop data ingestion, validation, transformation and loading code', 'Maintain and improve existing data pipelines', 'Collaborate with leadership and project leads to ensure the data, reporting, analytics, and automation needs of the business are met', 'Provide technical guidance for design and implementation of data storage and governance systems', 'Work closely with Analytics and Data Science teams to design informative user metrics and models', '2+ years experience building and optimizing data pipelines, warehouses and data sets', 'Proficient with Python', 'Advanced knowledge of SQL (CTEs, window functions, querying semi-structured data) and relational databases (Postgres, Snowflake, Redshift, BigQuery)', 'Experience developing ETL applications that move data to and from various platforms including REST APIs, SQL/Cloud DBs, and Cloud File Storage (such as S3)', 'Familiarity with AWS/GCP cloud computing tools', 'Knowledge and use of a source control system, such as Git', 'Knowledge of data warehousing best practices and data quality management', 'Experience with data pipeline and workflow management tools (Airflow, Luigi) a huge plus']",2020-12-30 21:54:36
Data Engineer,LiveBy,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL: 5 years (Required)Back-end development: 5 years (Required)Data modeling: 5 years (Required)Data science: 3 years (Preferred)', 'Collaborate with stakeholders, project managers, business analysts, and product developers to define and document data requirements for products and services', 'Work with data processing systems to efficiently intake, transform, and store massive data sets', 'Design data models that support product and business needs', 'Build datasets for use in internal and external APIs and data products', 'Implement and schedule the export and delivery of data products', 'Implement test cases to validate data quality, availability, and reliability', 'Experience using and administering SQL and NoSQL databases', 'Experience building data pipelines using external data sources', 'Experience using and authoring Web APIs and services', 'Experience working on an Agile team', 'Experience owning mission critical services', 'Proficiency in JavaScript or Python', 'Spatial databases, such as PostGIS or MongoDB', 'Statistical mathematics and linear mathematics', 'Bash/Terminal scripting', 'Using and configuring cloud services, such as AWS', 'QGIS, ArcGIS or equivalent', 'RETS Feeds and RESO APIs', 'Dental insurance', 'Health insurance', 'Paid time off', 'Monday to Friday', 'SQL: 5 years (Required)', 'Back-end development: 5 years (Required)', 'Data science: 3 years (Preferred)', 'Data modeling: 5 years (Required)', 'Fully Remote', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Team-oriented -- cooperative and collaborative', 'https://liveby.com', 'Yes', 'Remote interview process', 'Virtual meetings']",2020-12-30 21:54:36
Junior Data Engineer,York Telecom Corporation,2.9 out of 5 from 16 employee ratings,"Eatontown, NJ 07724","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Proven experience in utilizing enterprise data model, data warehouse, and business analytics in delivering reporting capability to users', 'Experience with ETL tools and methods in transforming data into target models while maintaining data lineage documentation', 'Ability to utilize best practices for report development, data management and data quality monitoring.', 'Hands on experience with relational database design, SQL, database management, and reporting services', 'Knowledge of best practices in dashboard design and layout for most usability and functionality', 'Knowledge of Microsoft BI technology components: SSRS, Power BI, SSIS, DAX and SQL Server, Azure Analysis services, Azure Data Factors', 'Understanding of data integration patterns between distributed systems and challenges when working with data from heterogenious sources', 'Hands on experience and knowledge of Microsoft Business Intelligence related roadmaps, tool sets, and data visualization applications', 'Familiar with software development lifecycle and its applicability to report and data analytics development and maintenance.', 'Familiar with best practices for ensuring data security and privacy.', 'Familiarity with data concepts related to ERP systems', 'Prioritize between daily support requests and overall project development to balance the expectation between supporting requesters and the timeline to accomplish functional data analytics objectives', 'Identify business process practices that impact existing and new reporting solutions, analytics and legacy reporting capabilities', 'Investigate issues holistically to assess the requirements impacting the data model and data dictionary.', 'Balance between support of existing reporting capabilities, meeting business priorities and following standard and practices established by the Business Intelligence Team, Working Groups and Enterprise Data Architect', 'Respond to request for data from senior leaders while taking considerations of developed standards and best practices.', 'Have a great communication skill both verbal and writing to communicate both to the team members and users involved in the report and data analytics development activities.', 'Consolidate feedback from the team and users to make informed decision to execute the project and refine existing reporting and data analytics capabilities.', 'Be proponent and educate broader organization to take advantage of standard report and data analytics capabilities within their business process whenever possible.', 'Lead migration of legacy reporting capabilities to be aligned with the corporate direction of reporting capabilities.', 'Identify business process areas that have tangible impact data quality needed to support business metrics and propose ideas and metrics that describe monitor the data quality impact.', 'To understand the goals and directions from the Enterprise Data Architect and Information Management Leadership to utilize and configure the enterprise data reporting and data analytics infrastructure that can support the identified standards and objectives', 'Provide support to objectives set by Information Management Leadership, stakeholders from internal organization and from partners organizations.', 'Ensure that reporting capabilities delivered are utilizing optimal software and hardware components to minimize cost and risk to the organization', 'Escalate issues to Enterprise Data Architect, Information Management Leadership or CIO if direction or support required to resolve issues', 'To learn standard corporate data models utilized in corporate standard report and leverage and enhance these models whenever possible when working on daily user requests for information', 'To build ETL processes that collect data from multiple data sources, transform into target tabular data model and deploy the model in Azure Analysis Services', 'Troubleshoot in depth any data accuracy issues in support of reporting and business analysis using SQL Queries and Power BI reports', 'Work with Business Stakeholders to understand business objectives of requested capabilities and map the capability to data elements', 'Understand and able to answer questions on the company data models maintained across organization business units and how the data models support various business processes', 'Document data model elements for consumption by the report developer community', 'To utilize Power BI, SSRS and Data Factory and SQL Server to build ETL processes and configure reports and dashboards that meet both user requirements as well as comply with the standards established by Enterprise Data Architect', 'Assist in maintaining Vision BI platform by identifying data model issues and researching data scenarios that lead to the problems', 'Develop and maintain knowledge of the main platform features of Power BI, SSRS and Azure Analysis Services', 'To answer inquiries and to resolve issues related to data related issues within analytics and reporting components', 'Operational support of the existing processes and components that are part of the BI Platform', 'High levels of Professionalism and Integrity', 'High ability to work with peers', 'Exceptional written, verbal and interpersonal skills.', 'Excellent problem-solving skills', 'Maintain a professional attitude and appearance at all times', 'Extensive use of business computer systems including Microsoft Office applications such as MS Word, Excel, Outlook and MS Project.', 'May require occasional lifting (up to 50 lbs.)', 'Requires extensive sitting, standing and walking', 'Domestic travel requiring multi-night stays within and at times outside US.', 'Require working during off hours or weekend occasionally.', 'Valid passport; International travel required', 'Valid U.S. driver’s license', 'Must be willing to complete background checks and drug tests as required by current or future contracts']",2020-12-30 21:54:36
Data Engineer,kraken,3.9 out of 5 from 25 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build scalable and reliable data pipeline that collects, transforms, loads and curates data from internal systems', 'Augment data platform with data pipelines from select external systems', 'Ensure high data quality for pipelines you build and make them auditable', 'Drive data systems to be as near real-time as possible', 'Support design and deployment of distributed data store that will be central source of truth across the organization', ""Build data connections to company's internal IT systems"", 'Develop, customize, configure self service tools that help our data consumers to extract and analyze data from our massive internal data store', 'Evaluate new technologies and build prototypes for continuous improvements in data engineering', '5+ years of work experience in relevant field (Data Engineer, DW Engineer, Software Engineer, etc)', 'Experience with data warehouse technologies and relevant data modeling best practices (Spark, Presto, Druid, etc)', 'Experience building data pipelines/ETL and familiarity with design principles', 'Excellent SQL skills', 'Proficiency in a major programming language (e.g. Java, C++, etc) and/or a scripting language (Javascript, Python, etc)', 'Experience with business requirements gathering for data sourcing']",2020-12-30 21:54:36
Data Engineer,Axios,3.9 out of 5 from 13 employee ratings,Virginia,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop and maintain developer tooling to support pyspark data pipelines', 'Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it', 'Develop and maintain data platform components including: data producers and consumers, pipeline architecture, data lake, data warehouse, and Business Intelligence tooling', 'Collaborate closely with fellow data team members as well as tech and product teams and company leaders', 'Support continuing increases in data velocity, volume, and complexity', 'Write unit/integration tests and document work', 'Perform data analysis required to troubleshoot data related issues and assist in the resolution of data issues', 'Experience with or knowledge of Agile Software Development methodologies', 'Excellent problem solving and troubleshooting skills', 'Strong SQL and Python development experience', 'Proven experience with schema design and dimensional data modeling', 'Practical experience with SQL and NoSQL databases', 'Practical experience supporting Business Intelligence tooling and third-party systems', 'Experience designing, building, and maintaining data processing systems', 'Experience working with MapReduce and Spark clusters', 'Experience detecting and reporting data quality issues', 'Familiarity with Docker, CI/CD (such as Jenkins/Circle), AWS', 'Experience building data visualizations and dashboards is preferred', 'Competitive salary', 'Health insurance (100% paid for individuals, 75% for families)', 'Primary caregiver 12-week paid leave', '401K', 'Generous vacation policy, plus company holidays', 'Company equity', 'Commuter and cell phone benefit', 'A commitment to an open, inclusive, and diverse work culture', 'Annual learning and development stipend', 'One mental health day per quarter', '$100 monthly work-from-home stipend', 'Tele-mental health services', 'OneMedical membership, including tele-health services', 'Increased work flexibility for parents and caretakers', 'Access to the Axios ""Family Fund"", which was created to allow employees to request financial support when facing financial hardship or emergencies', 'Weekly company-sponsored exercise and meditation classes', 'Virtual company-sponsored social events']",2020-12-30 21:54:36
Big Data Engineer,BTree Solutions Inc,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Cleanse, manipulate and analyze large datasets (Structured and Unstructured data – XMLs, JSONs, PDFs) using Hadoop platform.', 'Develop Python, PySpark, Spark scripts to filter/cleanse/map/aggregate data.', 'Manage and implement data processes (Data Quality reports)', 'Develop data profiling, deduping logic, matching logic for analysis', 'Programming Languages experience in Python, PySpark and Spark for data ingestion', 'Programming experience in BigData platform using Hadoop platform', 'Present ideas and recommendations on Hadoop and other technologies best use to management', '5+ years of experience in processing large volumes and variety of data (Structured and unstructured data, writing code for parallel processing, XMLS, JSONs, PDFs)', '3+ years of programming experience in Hadoop, Spark, Python for data processing and analysis.', 'Strong SQL experience is a must', '3+ years of experience – using Hadoop platform and performing analysis. Familiarity with Hadoop cluster environment and configurations for resource management for analysis work', 'Detail oriented. Excellent communication skills (verbal and written)', 'Must be able to manage multiple priorities and meet deadlines', 'Degree in Statistics, Economics, Business, Mathematics, Computer Science or related field']",2020-12-30 21:56:17
Data Engineer,Unite Us,5 out of 5 from 2 employee ratings,North Carolina,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Execute a data architecture and infrastructure to meet business objectives', 'Work closely with Solutions Architects and Product Managers to make sure that the technical infrastructure can support client requirements', 'Develop ETL and data pipeline solutions to load data warehouse', 'Test internal data pipelines for reliability and performance', 'Experience as a Data Engineer in which you set up data pipelines', 'Experience using and building solutions to support various reporting and data user tools (Chartio, Tableau, Looker, etc)', 'Experience with Spark using Scala and Python.', 'Experience working with data warehouses, data lakes and ETL pipelines (Snowflake, Infomatica, Redshift, Postgres, SQL, etc)', 'Experience setting up an maintaining databases within AWS', 'Experience working on applications serving large enterprise clients', 'Experience working on healthcare and/or social determinants of health data products', 'A focus on building performant systems', 'Ability to think forward and build a scalable solution that satisfies various needs of enterprise clients with dedicated data teams', 'This position is remote']",2020-12-30 21:56:17
Mid-Level Data Engineer,LOCKHEED MARTIN CORPORATION,"4 out of 5 from 8,473 employee ratings","Herndon, VA 20171","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Test-driven development in using the appropriate data storage and access solutions, using the most efficient languages for the task, e.g. Java, Python and/or SQL', 'Implementing multi-processing algorithms to parallelize ingest operations.', 'Execute operating system level scripts for production data load routines.', 'Analyze new large volume data collections looking for opportunities to optimize the data ingest processes.', 'Develop software tools that efficiently preprocess, modify, aggregate, load, index, and archive large data collections.', 'Generate metrics that track data ingest statistics to ensure data integrity and pedigrees are maintained.', 'Proficiency with languages/tools such as SQL, Python, R, and Git.', 'Experience with cleaning, management, optimizing performance and processing large volumes of data.', 'Familiarity with industry best-practices for software-hardware optimization when processing large sets of data.', 'Experience with storage/computing processes such as Hadoop, Spark', 'Experience with machine learning, with statistical modeling and time-series forecasting', 'Thorough/Working knowledge of research designs.', 'Thorough/Working knowledge of collection methods, capabilities and tasking process.', 'Familiarity with project management concepts and principles.', 'Intellectual curiosity; creativity and innovation to go beyond current tools to deliver the best solution to complex problems.', 'Strong analytical and critical thinking skills.']",2020-12-30 21:56:17
Sr. Data Engineer,Excella,4.4 out of 5 from 11 employee ratings,"Arlington, VA 22201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""US work authorization (Required)Bachelor's (Preferred)Python: 2 years (Preferred)"", ""You'll work with great people who love what they do: our team includes published authors, certified trainers, and internationally renowned speakers."", 'We have a ""bring your own device"" workplace and will share the cost of a new computer of your choice -- Mac or PC. It\'s up to you.', ""We'll invest in your career by providing 3 days of paid professional development every year, including travel and registration fees to attend classes and conferences, in addition to tuition assistance for degrees and certifications."", 'Starting day one, every employee is bonus eligible and receives 15 days of paid vacation, 6 federal holidays, and 4 floating holidays.', 'You can bike, drive, or metro to work -- our commute reimbursement plan has you covered.', ""You'll have fun! We hold monthly social events all year long, including a summer event for you and your family."", 'Developing and managing data processes to ensure that data is available and usable', 'Creation and automation of data pipelines and platforms', 'Managing and monitoring data quality via automated testing frameworks (Data Driven Testing, TDD, etc.)', 'Working closely with Architects, Data Scientists, and DevOps to design, build, test, deliver, and maintain sustainable and highly scalable data solutions', 'Researching data acquisition and evaluating suitability', 'Integration of data management solutions into client environment', 'Actively managing risks to data and ensuring there is a data recovery plan', 'Building data repositories such as: data warehouses, data lakes, and operational data stores, etc.', '3+ years relevant professional work experience.', 'Experience and expertise in the following:', 'Creating robust and extensible data pipelines for production systems', 'Use of cloud platforms, preferably AWS', 'Creating secure, performant, and well-modeled data stores', 'Common analytical platform architectural patterns (Star Schema, data integration patterns, ABAC, data quality frameworks etc.)', 'Data lake design patterns and technology options (schema on read, metadata capture, search framework)', 'Use of scripting languages, preferably Python', 'Familiarity with NoSQL databases', 'Source code version control management using git', 'Project experience using the Scrum or Kanban framework.', 'Professionalism; to include written and oral communication – the ability to communicate collaboratively in front of a whiteboard. An ability to understand your audience and adjust your communication style to fit', 'Aptitude and desire for learning new technologies.', 'Technically savvy, entrepreneurial spirit who thrives in environments that reward self-initiative and resourcefulness.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'Data Engineering: 3 years (Required)', 'Python: 2 years (Preferred)', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Team-oriented -- cooperative and collaborative', 'www.excella.com', 'Yes', 'Remote interview process', 'Virtual meetings']",2020-12-30 21:56:17
Data Engineer,ProVantage Corporate Solutions,3.2 out of 5 from 103 employee ratings,"Raleigh, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Someone self-motivated and able to thrive in a fast-paced, results-driven environment', 'Someone enthusiastic about the optimal performance of databases', 'Someone with proven expertise writing advanced SQL queries and triggers, design and code complex stored procedures, and maintain/performance tune existing databases in a mixed usage environment', 'Someone with product development experience in cloud and application services', 'Someone with experience in Machine Learning and Artificial Intelligence', 'Design and consult on a big data project for our new product', 'Performance monitoring', 'Query Tuning', 'Index Optimization', 'Data Management', 'Monitor and troubleshoot database performance', 'Monitor Disaster recovery readiness', 'ETL operations', 'Automating routine maintenance tasks', 'Environment upgrade and migration', 'Audit and enhance security measures', '3-5 years of related experience', 'Implemented ETL and Big Data Solutions in the past', 'Legally authorized to work in the United States', 'Effective Communicator', 'Mindful of details', 'Takes ownership of deliverables', 'Strong analytical and problem-solving skills', 'College degree in related field preferred', 'The machine learning experience is a huge bonus', 'Spirit of Excellence', 'Doing the Right Thing', 'We Before Me', 'Grace Through Generosity', 'Innovate to Elevate']",2020-12-30 21:56:17
BIG DATA ENGINEER,Tabiya Technology,N/A,"Chevy Chase, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Minimum Requirements 3 years of hands-on experience in the Hadoop ecosystem (HDFS, YARN, MapReduce, Oozie, AND Hive)', '1 year of hands-on experience in Spark core AND Spark SQL', '5 years of hands-on programming experience in either core Java OR Spark', '3 years of hands-on experience in Data Warehousing AND Data Marts AND Data/Dimensional Modeling AND ETL', '1 years of hands-on experience in HBase OR Cassandra OR any other NoSQL DB', 'Understanding of Distributed computing design patterns AND algorithms AND data structures AND security protocols', 'How many years of Data Warehousing and Big Data Marts and Data/Dimensional experience do you have?', 'How many years of Hadaoop (HDFS, YARN, MapReduce, Oozie, and Hive) experience do you have?', 'How many years of HBase or Cassandra or any other NoSQL DB experience do you have?', 'How many years of Java and or Spark experience do you have?', 'How many years of Spark core and Spark SQL experience do you have?', ""Have you completed the following level of education: Bachelor's?"", 'Are you in Chevy Chase, MD?', 'Are you authorized to work in the following country: United States?', 'Do you have the following license or certification: read that as certifications - HortonWorks or Coludera?']",2020-12-30 21:56:17
Data Engineer,Bloomberg,3.9 out of 5 from 822 employee ratings,"Princeton, NJ 08540","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Apply your coding skills: Automate the influx of data and build flexible solutions for data acquisition, ETL and machine learning pipelines, and human-in-the-loop data processing to drive successful product adoption', 'Inspire and impact our business: Act as an internal consultant to influence and implement more efficient products through analysis, dashboards, web apps, and user documentation', 'Develop your career: sharpen your technical skills and strengthen relationships through project management, partnering with stakeholders across the firm, and establishing scalable architecture', 'Champion improvements: identify strategic technical gaps in our ecosystem and advocate for solutions over workarounds', 'Grow our business: Approach each day knowing this role is mission-critical to the success of the firm. We will rely on your expertise, and our flat structure allows for you to make real impact, real quick', 'A BA/BS degree or higher in Computer Science, Mathematics, or relevant data technology field, or equivalent professional work experience in software development, data engineering, data science or information technology', '2+ years of Python programming and scripting in a production environment', '2+ years of experience working with restful APIs and data modeling within SQL and NoSQL databases', 'Deep understanding of large-scale, distributed systems', 'Legal authorization to work full-time in the United States without requiring visa sponsorship']",2020-12-30 21:56:17
Data Engineer,Kani Solutions,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Walmart, 1 year (Required)big data, 3 years (Required)', 'Work on highly scalable services to process millions of requests/events per day.  * Work with open source tools for optimizing and testing code using automation scripts  * Maintain active relationships with project stakeholders to understand business requirements, leads requirements gathering meetings and reviews designs with the product owner  * Implement solutions developed in java to meet business and IT needs, ensuring technical viability of new projects and successful deployments  * Integrating multiple technologies and data sources  * Working within Agile development teams  * Troubleshoots business and production issues by gathering information  * Performing root cause analysis to reduce future issues  * Ensure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deployment  * Identify and implement best practices and coach the stakeholders as needed  * Create technical documentation and maintain the knowledge repositories  * Adjust quickly to changing priorities and make quick decisions with limited information  * Collaborate with Architects, Technical experts and application SMEs in implementing complex end-to-end enterprise solutions', '8 hour shift', 'Walmart: 1 year (Required)', 'big data: 3 years (Required)', 'Yes']",2020-12-30 21:56:17
Data Engineer,Piper Companies,4.5 out of 5 from 12 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop and maintain scalable data pipelines to orchestrate the movement, transformation, validation and loading of data from source to destination', 'Assemble large, complex data sets that meet functional/non-functional business requirements', 'Architect, design, build and maintain modern, scalable data architectures on AWS', 'Design and evaluate open source and vendor tools for data lineage', '5+ years of professional software engineering experience', 'Experience AWS cloud services: Lambda, SQS, Elasticsearch service, RDS, CloudFront or Dynamo DB', 'Knowledge of programming languages and tools such as Python, Amazon web services (AWS), Linux and Spark', 'Experience with databases such as PostgreSQL', 'Bachelor’s Degree in Computer Science or a related field', 'Excellent written and verbal communication', 'Salary Range: $120,000-$145,000', 'Benefits: Unlimited PTO, stock options, and competitive health benefits']",2020-12-30 21:56:17
Data Engineer,Voloridge Investment Management,N/A,"Jupiter, FL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate effectively with Stakeholders, Project Managers, Software Engineers, Data Architects, Data Analysts, QA Analysts, DBAs and other Data Engineers', 'Build and maintain data pipelines based on functional and architectural specifications', 'Ensure that data pipelines incorporate best practices related to high performance, fault tolerance, instrumentation, logging and data driven functionality', 'Ensure that data pipelines are scalable, maintainable and not overly engineered', 'Produce and maintain engineering and operational documentation', 'Analyze complex data problems and engineer elegant solutions', 'Stay abreast of emerging technologies and make relevant recommendations', 'Transition existing data warehouses and pipelines to newer technologies where appropriate', 'Work in an Agile environment', 'Participate in engineering standards evolution', 'Participate in an on-call rotation with other Data Engineers', 'Lead investigations to troubleshoot data issues that arise along the data pipelines', 'Ability to work daily onsite in our Jupiter, FL office', '5+ years’ experience building ETL/ELT pipelines using both transactional databases and data warehouses with large data volumes', 'Strong initiative, collaboration, accountability, impartiality and communication', 'Strong analytical skills, real passion for working with data and strong interest in solving data problems', 'Proficient understanding of traditional Agile SDLC best practices', 'Experience building ETL/ELT pipelines against data warehouse entities such as SCD’s and Facts', 'Experience in performance tuning TSQL and SSIS, execution plan analysis, blocking / deadlock analysis and index optimization', 'Experience with SQL Server 2016+', 'Experience using Visual Studio to create and maintain SSIS packages', 'Experience using SSMS to create and maintain SQL Server tables, views, functions, stored procedures', 'Experience writing PowerShell', 'Experience building data pipelines using external data sources', 'Experience working on an Agile team', 'Experience owning mission critical service(s)', 'Bachelor’s degree in Computer Science, Information Systems, related disciplines or equivalent experience', 'C# / .Net and Python programming', 'Python programming using libraries such as Pandas, Numpy, csv, TraceBack, JSON, PyODBC, Math', 'Skilled in developing automated testing, code quality, and engineering best practices for data services', 'Experience working within segregated Development, QA, UAT and Production SDLC stages', 'Experience with AWS', 'Experience working with trading / financial / investment / accounting data', 'Experience with tools such as Red Gate, Grafana, OpsGenie and AirFlow', 'Experience with Big Data technology and MPP databases like Matrix/Paracel, Vertica, Netezza, PDW, Greenplum', 'MS/PhD in Computer Science, Information Systems or related disciplines', 'Relocation assistance available for the right candidate', 'Highly competitive base salary', 'Profit sharing bonus', 'Health, dental, vision, life, and disability insurance', '401K']",2020-12-30 21:56:17
2021 Software Engineer Program - Summer Internship Opportunity,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Begin with an induction covering our tech strategies, products and systems, as well as an overview of our technology community.', 'Dive head-first and gain hands-on experience creating innovative solutions that make a difference for our customers, clients and employees.', 'Work on agile teams with peers and experienced software engineers to grow your skills, share ideas and innovate with our technology community all over the world.', 'Gain deeper insight into what it means to work here through networking events, senior speaker sessions and peer-mentorship programs.', 'Chicago, IL', 'Columbus, OH', 'Wilmington, DE', 'New York Metro, NY', 'Plano, TX', 'San Francisco, CA', 'Seattle, WA', 'Tampa, FL', 'Computer Science and/or Engineering majors are preferred, while other majors may be considered', 'Pursuing a B.A., B.S. or 5th year M.A. or M.S. with expected graduation of August 2021 through June 2023 or participating in a JPMorgan Chase-sponsored training program', 'A well-rounded academic background with a preferred minimum cumulative GPA of 3.2 (or prior participation in a JPMorgan Chase-sponsored training program', 'Foundational knowledge of programming languages (e.g., Python, Javascript, Java, C++, C#), databases, data structures, and algorithms', 'Strong interpersonal and communication skills', 'Ability to thrive in a fast-paced, collaborative environment', 'Relevant internship experience and/or leadership in school or community organizations']",2020-12-30 21:56:17
Data Engineer,CBL SOLUTIONS INC,N/A,"Glen Allen, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift', 'Day shift', 'Monday to Friday', 'No']",2020-12-30 21:56:17
"Engineer, Data",Presidio,3.3 out of 5 from 170 employee ratings,"Reston, VA 20190","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participate as an engineer on projects and assist in communication/collaboration sessions with clients', 'Assist project team with oversight of junior team members: task delegation; technical assistance; oversight and QA', 'Collaborate as assist with solution design', 'Identify, build, and implement optimal Data Platform', 'Identify, build, and implement highly scalable Data pipeline with automation', 'Build out ETL jobs per architectural guidelines which integrates within the data pipeline', 'Work with stakeholders including executive and data teams to troubleshoot and identify issues within the Data Platform', 'Suggest and implement optimization patterns for an existing or new Data Platform', 'Identify and implement BI tools per architectural guidelines', 'Ability to proactively identify performance gaps in a solution and provide guidance for improvements', 'Ability to work independently with minimal supervision', 'Ability to articulate a problem and find solutions in a timely manner', 'Ability to travel up to 30% to customer sites', '2+ years of data engineering experience', 'Bachelor’s degree in computer science, mathematics, statistics or a similar quantitative field', 'Core understanding of Big Data principles and architectural patterns', 'Deep understanding of Batch and streaming data pipelines', 'Have proven experience in building out Data Lakes using AWS services and other CSPs', 'Deep understanding of AWS Data & Analytics services (Kinesis, S3, EMR, Athena, Redshift, etc.)', 'Proven experience building or administering BI tools such as Tableau, Domo, Lookr, etc.', 'Be able to build data pipelines and platforms using proven development tools and languages such as Eclipse, IntelliJ, Python, Scala, Spark, PySpark, AWS Glue', 'Experience implementing Machine Learning solutions and services on AWS or GCP', 'Experience with GCP or Azure cloud solution', 'Experience with Qubole Data Platform']",2020-12-30 21:56:17
Data Engineer,Cognizant Technology Solutions,"3.9 out of 5 from 13,859 employee ratings","Alpharetta, GA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'This role is not able to']",2020-12-30 21:56:17
Data Engineer,AGM Tech Solutions,N/A,"Irvine, CA 92602","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participate in the design and development of data management, business intelligence and analytics projects to drive strategic decisions through data driven actionable metrics and insights.', 'Assist in evaluating and selecting the best technologies and tools to support the data mission.', 'Support development and production issues impacting our clients and operations.', 'Monitor and improve data and BI processes to meet firm SLAs and increase efficiency.', 'Help define user stories as a part of the BI scrum team by analyzing business requirements, defining technical specifications and sizing the development effort.', 'Leverage technology capabilities and standards while working with technology system owners to identify appropriate data sources, define and build required data transformation logic.', 'Perform detailed data analysis to derive insights and deliver operational mechanism such as dashboards or ad-hoc reports.', 'Minimum of 5 years of hands-on experience with SQL Server, Oracle and SSIS', 'Minimum of 3 years of hands-on experience with data engineering including ETL and data warehousing', 'Minimum of 1 year of hands-on experience with building semantic-layer business intelligence solutions including metrics, dashboards and data visualization', ""Bachelor's Degree or equivalent in Computer Science or Information Management"", 'Monday to Friday', 'No', 'One location']",2020-12-30 21:56:17
Data Engineer,AGM Tech Solutions,N/A,"Irvine, CA 92602","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participate in the design and development of data management, business intelligence and analytics projects to drive strategic decisions through data driven actionable metrics and insights.', 'Assist in evaluating and selecting the best technologies and tools to support the data mission.', 'Support development and production issues impacting our clients and operations.', 'Monitor and improve data and BI processes to meet firm SLAs and increase efficiency.', 'Help define user stories as a part of the BI scrum team by analyzing business requirements, defining technical specifications and sizing the development effort.', 'Leverage technology capabilities and standards while working with technology system owners to identify appropriate data sources, define and build required data transformation logic.', 'Perform detailed data analysis to derive insights and deliver operational mechanism such as dashboards or ad-hoc reports.', 'Minimum of 5 years of hands-on experience with SQL Server, Oracle and SSIS', 'Minimum of 3 years of hands-on experience with data engineering including ETL and data warehousing', 'Minimum of 1 year of hands-on experience with building semantic-layer business intelligence solutions including metrics, dashboards and data visualization', ""Bachelor's Degree or equivalent in Computer Science or Information Management"", 'Monday to Friday', 'No', 'One location']",2020-12-30 21:57:59
Data Analyst Engineer,Breakthrough PT Marketing,N/A,"Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and build centralized reporting data warehouse, following best practices to ensure data transformations and computations are accurate and efficient', 'Build out and maintain our data pipeline architecture, and optimize data flow and collection for cross functional teams.', 'Identify, implement and own business intelligence software to provide business insights cross-functionally.', 'Provide insights to team members and lead cross-functional teams to address business issues', 'Produce datasets and reports for analysis using system reporting tools', 'BS or MS Degree in Computer Science, Mathematics, Statistics or a related technical field.', '3+ years experience with SQL and ETL optimization techniques', '2+ years of experience with Business Intelligence tools', 'Experience developing and launching out a data warehouse', 'Experience with data pipeline management', 'A high degree of motivation to be proactive and go above and beyond the task at hand', 'Completely virtual. We don’t have an office (and never have). We care about your results and impact on the business and want our team to live and work wherever they want.', 'We have an amazing team of incredibly driven people who are constantly learning, growing, and encouraging one another.', 'Amazing benefits, including healthcare, matching 401K, and shares in our employee stock ownership trust.', 'Work life balance environment - we care that you are personally and professionally taken care of.']",2020-12-30 21:57:59
Senior Data Engineer,Vanguard,"3.8 out of 5 from 1,026 employee ratings","Malvern, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Writes ETL (Extract / Transform / Load) processes, designs database systems and, develops tools for real-time and offline analytic processing.', 'Troubleshoots software and processes for data consistency and integrity. Integrates complex and large scale data from a variety of sources for business partners to generate insight and make decisions.', 'Translates business specifications into design specifications and code. Responsible for writing complex programs, ad hoc queries, and reports. Ensures that all code is well structured, includes sufficient documentation, and is easy to maintain and reuse.', 'Partners with internal clients to gain an expert understanding of business functions and informational needs. Works closely with other technical and data analytics experts across the business to implement data solutions.', 'Leads all phases of solution development. Explains technical considerations at related meetings, including those with internal clients and less experienced team members.', 'Assesses data quality and tests code thoroughly for accuracy of intended purpose. Provides data analysis guidance and serves as a technical consultant for the client.', 'Educates and develops junior data engineers on the team while applying quality control to their work. Develops data engineering standards and contributes expertise to other data expert teams across Vanguard.', 'Tests and implements new software releases through regression testing. Identifies issues and engages with vendors to resolve and elevate software into production.', 'Participates in special projects and performs other duties as assigned.', 'Minimum of eight years data analytics, programming, database administration, or data management experience.', 'Undergraduate degree or equivalent combination of training and experience. Graduate degree preferred.']",2020-12-30 21:57:59
Cyber Associate Data Engineer,New York City Department: Citywide Cybersecurity | Location: MANHATTAN | Business Unit: DEPT OF INFO TECH & TELECOMM | Posted Date: 09/22/2020,N/A,"Manhattan, NY 10005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Developing and maintaining our data pipeline using Apache Beam, Java, Python and other data processing technologies;', 'Identifying and implementing performance improvements across all pipelines;', 'Engaging with data consumers and producers in order to design appropriate models to suit all needs;', 'Maintaining information exchanges through publish, subscribe, and alert functions that enable users to send and receive critical information as required;', 'Supporting incident management, service-level management, change management, release management, continuity management, and availability management for databases and data management systems;', 'Administering databases and/or data management systems that allow for the secure storage, query, protection, and utilization of data.', 'A bachelor’s degree in computer science or information systems with a specialization in mathematics, number; theory, applied cryptography, or statistics or relevant experience;', 'Experience with the Agile Development Methodology;', 'Expert knowledge in both Java and Python;', 'Familiarity with Unix scripting, Web development, and automated testing;', 'Familiarity with machine learning techniques and machine learning toolkits such as R, scikit-learn, etc;', 'Experience working with Terraform;', 'Familiarity with the CI/CD process,', 'At least one year professional, academic, or personal experience with software development or data engineering experience (includes internship experience);', 'At least 1 year professional, academic, or personal experience with object-oriented/object function scripting languages; preferably java or python;', 'Familiarity with or exposure to cloud application development;', 'Familiarity with distributed data processing frameworks.', 'Interested applicants with other civil service titles who meet the preferred requirements should also submit a resume for consideration']",2020-12-30 21:57:59
Data Engineer,The Washington Post,4 out of 5 from 206 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company']",2020-12-30 21:57:59
Data Engineer,Airspace Technologies,3.9 out of 5 from 20 employee ratings,"Carlsbad, CA 92011","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work as part of the data engineering team to define and develop data ingestion, validation, transformation and loading code', 'Maintain and improve existing data pipelines', 'Collaborate with leadership and project leads to ensure the data, reporting, analytics, and automation needs of the business are met', 'Provide technical guidance for design and implementation of data storage and governance systems', 'Work closely with Analytics and Data Science teams to design informative user metrics and models', '2+ years experience building and optimizing data pipelines, warehouses and data sets', 'Proficient with Python', 'Advanced knowledge of SQL (CTEs, window functions, querying semi-structured data) and relational databases (Postgres, Snowflake, Redshift, BigQuery)', 'Experience developing ETL applications that move data to and from various platforms including REST APIs, SQL/Cloud DBs, and Cloud File Storage (such as S3)', 'Familiarity with AWS/GCP cloud computing tools', 'Knowledge and use of a source control system, such as Git', 'Knowledge of data warehousing best practices and data quality management', 'Experience with data pipeline and workflow management tools (Airflow, Luigi) a huge plus']",2020-12-30 21:57:59
Data Warehouse Engineer,intellectt,N/A,"West Chester, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL', 'Data Warehouse', 'SSIS', 'Dimensional Model Experience', 'SSAS']",2020-12-30 21:57:59
Big Data Machine Learning Engineer,Nespon IT Services,N/A,"Rockville, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Information Technology, 8 years (Preferred)Big Data Software Development, 8 years (Preferred)Machine Learning, 5 years (Preferred)DB2, Oracle, Teradata, MySQL, PostgreSQL, 5 years (Preferred)Python, R or Scala Programming, 5 years (Preferred)', ""Education:Bachelor's (Preferred)"", ""Bachelor's degree in computer science, electrical/electronic engineering or other engineering or technical discipline is required."", 'Minimum of 8 years of experience in IT and Big data software development is required', 'Minimum 3+ Predictive Analytics model implementation experience in production environments using ML/DL libraries like TensorFlow, H20, Pytorch, Sci-kit Learn.', 'Experience in using NLP, Bi/Visual analytics, Graph Databases like Neo4j/Tiger Graph is preferred,', 'Experiences in designing, developing, optimizing and troubleshooting complex data analytic pipelines and ML model applications using Spark, HDFS and other big data related technologies', 'Programming in Python, R or Scala using distributed frameworks like PySpark, Spark, SparkR', 'Working Knowledge in IDE environment/Tools like Jupyter, R Studio, GitHub, Docker, Jenkins', 'Solid knowledge of data warehousing such as Hadoop, MapReduce, HIVE, Apache Spark, as well as cloud base data storage: Google Cloud Storage with various formats (Parquet, JSON, ORC, Avro, delimited)', 'Solid understanding of databases such as DB2, Oracle, Teradata, MySQL, PostgreSQL', 'Extensive Experience with R and Python including language-specific and data science-oriented packages required.', 'Experience with Hadoop and Spark cluster, SparkSQL, Spark ML, and other third-party machine learning algorithms using Scala, PySpark and/or SparkR', 'Experience with Linux/Unix required', '8 hour shift', 'Monday to Friday', 'Information Technology: 8 years (Preferred)', 'Big Data Software Development: 8 years (Preferred)', 'Machine Learning: 5 years (Preferred)', 'DB2, Oracle, Teradata, MySQL, PostgreSQL: 5 years (Preferred)', 'Python, R or Scala Programming: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'Temporarily due to COVID-19']",2020-12-30 21:57:59
Data Engineer,Slalom Consulting,3.7 out of 5 from 105 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You have passion for data!', 'You’re a smart, collaborative person who is excited about technology and driven to get things done.', 'You’re not afraid to be bring your authentic self to work.', 'You embrace a continuous learner mentality.', 'We are engineers, makers, planners, architects, and designers.', 'We choose to imagine things made better, and then set out on a journey to realize what’s possible.', 'We’ll never trade the upside of wonder for the comfort of the familiar or the safety of convention.', 'Expert knowledge of SQL', 'Programming skills in languages like Python or Scala', 'Experience with big data frameworks like Apache Spark or Apache Flink', 'Experience with version control tools (e.g. Git, SVN)', 'Experience with workflow orchestration platforms such as Airflow', 'Experience with one of the major cloud providers (AWS, Azure, GCP)', 'Understanding of different types of storage (filesystem, relational database, MPP, NoSQL) and working with various kinds of data (structured, unstructured)', 'Understanding of data architecture concepts such as data modeling, metadata management, workflow management, ETL/ELT, real-time streaming.)', 'Understanding of agile project approaches and methodologies', 'Strong aptitude for learning new technologies and analytics techniques', 'Strong analytical problem-solving ability', 'Self-starter with the ability to work independently or as part of a project team', 'Capability to conduct performance analysis, troubleshooting and remediation']",2020-12-30 21:57:59
Data Engineer,Owens & Minor,3.1 out of 5 from 855 employee ratings,"Mechanicsville, VA 23116","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Medical, dental, and vision insurance, available on first working day', '401(k), eligibility after 30 days of employment', 'Employee stock purchase plan', 'Tuition reimbursement', 'Development opportunities to grow your career with a global company', 'Provide Business Intelligence (BI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms while evaluating and defining functional requirements for BI and DW solutions', 'The ability to understand the business problem and determine what aspects of it require optimization; define and build data integration processes to be used across the organization and articulate those aspects in a clear and concise manner', 'The ability to build conceptual, define logical data models and analyze models that predict the probability of an outcome. Offers improvements to the way in which analytics service the entire function while validating data accuracy of report results', 'Work directly with management to understand requirements; Communicating and owning the process in manipulating and merging large datasets, and propose and develop best business solution that enables effective decision-making, and drive business objectives', 'Recognizes potential issues and risks during the analytics project implementation and can suggest realistic mitigation strategies; uses statistical practices to analyze current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events', 'Coaches and mentors project team members in carrying out analytics project implementation activities', 'Leads the preparation of high quality project deliverables that are valued by the business and presents them in such a manner that they are easily understood by project stakeholders', 'Interpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision making with the ability to view and understand other project or functional areas in order to consolidate analytical needs and processes', 'Being a key point of contact between the data analyst/data scientist and the project/functional analytics leads', ""5 years' experience working on a data team (preferably ETL/Database team)"", 'Experience working with large datasets', 'Programming experience in Java, Python or SQL', 'An advanced degree may count towards experience', 'Experience with Snowflake and/or Hadoop', 'Experience in Automation of ETL data pipelines will be a huge plus', 'Experience with SQL and RDBMS (Oracle, Postgres, MySQL)', 'Understanding of Dimensional data modeling (Star Schema )', 'Knowledge of NoSQL databases (DynamoDB, MongoDB ) is a plus', 'Familiarity with cloud stacks (Azure)', 'Code Debugging and Performance troubleshooting skills', 'Experience preferred in languages like Python/Java/R and Shell Scripting', 'Experience with Source code management systems like Git, SVN etc.']",2020-12-30 21:57:59
Data Engineer,Technodeed Inc,N/A,"Minneapolis, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 21:57:59
Freelance Data Engineer,AKQA,3.4 out of 5 from 33 employee ratings,"New York, NY 10014","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Developing and deploying machine learning environments', 'Guiding the team with Machine Learning ops practices and assist with challenges such as: ETL operations, performance tracking of models, and continuous deployment', 'Experiences with Kubernetes / Docker', 'Experience with PyTorch / Tensorflow or similar frameworks', 'Experience with platforms like MLFlow, Neptue or Polyaxon', 'An understanding of Python', 'Experience with various ETL frameworks and solutions']",2020-12-30 21:57:59
Data Engineer,Evolytics,N/A,"Kansas City, MO 64152","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create, prepare, and maintain databases and tables to power reports, dashboards, predictive models, and downstream analysis.', 'Plan, create, and fine-tune data pipelines and automation workflows.', 'Design and build data infrastructure that enables actionable insights used to optimize digital marketing performance such as online advertising, social media marketing, websites, and mobile experiences.', 'Develop processes and procedures for ingesting data from disparate sources.', 'Build and maintain database architecture, including fine tuning and optimizing queries, data pipelines, and automation workflows.', 'Create and maintain customized SQL queries to build reporting data structures.', 'Develop and implement data models necessary to build analytic solutions as defined by stakeholder requirements.', 'Validate data to determine and document any gaps between available data and requirements for reporting outputs and downstream analysis.', 'Manage multiple client requests and detailed project activities at any one time to ensure accurate, timely and efficient reporting and analysis deliverables.', 'SQL skills are critical for this Data Engineer role. Consideration will be given to qualified candidates with varying levels of experience, with compensation commensurate with experience.', 'Working knowledge in at least one of the following scripting languages: Python, Bash, Java, Scala, R, Perl, Node.js', 'Linux command line', 'Advanced SQL', 'Working with a leading analytics or relational database system, such as Redshift, Vertica, BigQuery, PostgreSQL, or MySQL', 'Developing cloud-based data solutions on Snowflake, AWS, Azure, or Google Cloud', 'Working in big data solutions such as Hadoop, Hive, or Spark', 'Using change release processes and tools such as git', 'Developing and implementing data transformation via ETL processes and data pipelines', 'Legally authorized to work in the United States without company sponsorship now or in the future', 'Minimum of a Bachelor’s degree in Computer Science, Information Systems, Business, Marketing, or a related discipline', 'Working knowledge in any of the following database systems will be a plus: NoSQL, Mongo DB, Couch DB', 'Working with clickstream web analytics tools such as Adobe Analytics (Omniture SiteCatalyst), Google Analytics, or working knowledge of the field of web analytics', 'Knowledge of commonly-used digital metrics, analytic concepts, and online marketing channel best practices', 'Working with data analysis tools such as SAS, Tableau, Google Data Studio, or Power BI', 'Knowledge of business intelligence methodologies and tools', 'Proficiency in spreadsheet and presentation technologies such as Excel, PowerPoint, or Google Docs', 'Creating and preparing databases and tables for predictive modeling and data science applications', 'Relaxed work environment: casual dress code, pool/ping pong table, treadmill desks', 'Collaboration-oriented office space with plenty of room for working sessions or potlucks', 'Awesome team building events like a day at the Royals game or mini-golf with margaritas', 'Food…weekly lunches, daily snacks, fruits, beverages, unlimited coffee', 'Learning opportunities: company-provided training, conferences and super-smart co-workers', 'Competitive Benefits Package including Health, Dental, Vision, and Life Insurance', 'Great Compensation Package with Paid Time Off, Performance Bonuses and IRA Matching Contributions', 'Opportunity to work alongside amazingly fun people who are passionate about delivering awesome in everything they do.', 'Fortune’s Best Small and Medium Workplaces in 2020: #25 in US', 'Honored for Best Places to Work in 2020 by the Kansas City Business Journal', 'Recognized as a Great Place to Work in 2020', 'Voted Coolest Office Space (Small Business) by the Kansas City Business Journal', 'Named Top Analytics Agency by the Digital Analytics Association in 2018 and again in 2020']",2020-12-30 21:57:59
Data Engineer,First Stop Health,3 out of 5 from 3 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Architect data structures; set and monitor standards.', 'Great time management and self-direction and able to work independently while contributing on team efforts with clear communication', 'Can scope, estimate, develop, document, and test data/database/dataset functionality', 'Incorporate disparate data sources into a database/data lake for consumption via analytics tools such as Tableau or Looker', 'Ability to work with technical team to resolve data discrepancies, and work within project management tool like Jira to track work items and defects', 'Design, create, modify and review database objects (tables, views, indexes, keys, stored procedures, functions, DB links, etc.) to support development projects.', 'Troubleshoot production issues related to data and SQL code', 'Coordinate with VP of technology to manage projects/priorities', '3+ years of practical experience building and supporting Postgres databases', 'Expert understanding of SQL including stored procedures and functions, permissions, bulk load/export', 'Insistence on DRY methodology', 'Understanding of normalization and its tradeoffs', 'Documentation experience for both engineering and cross functional documentation', 'Ability to manage, describe maintain and document disparate data flows and sources', 'Experience automating and routine tasks and processes', 'Familiarity with HIPAA compliance requirements', 'Coding and scripting experience using Python', 'Experience using an ORM such as Django ORM or SqlAlchemy', 'Experience with data operations tools (Keboola and Snowflake)']",2020-12-30 21:57:59
Azure Data Engineer (Remote Project),Golden Technology Inc,N/A,"Cincinnati, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'In depth understanding and proficiency automation of cloud platforms and data platforms.', 'Expertise in on-prem and cloud database automation and platform automation. Azure experience', 'Proficiency with cloud automation tooling such as Ansible and Terraform etc.', 'Proficiency with DevOps and CI/CD methodologies and tools for automated infrastructure code', 'Proficiency with Languages such as Ruby, bash, Python or Go.', 'Proficiency with any one of the cloud provider AWS, Azure or GCP.', 'Experience with Software Development and automation methodologies', 'Experience with data security best practices.', 'Strong problem-solving skills.', 'Strong collaboration skills and excellent verbal and written communication skills.', 'Health insurance', 'Life insurance', 'Vision insurance', '8 hour shift', 'Temporarily due to COVID-19']",2020-12-30 21:57:59
Data Engineer,"Liferay, Inc.",3 out of 5 from 4 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Maintain data that helps our internal teams to gain insights on how to best serve our customers.', 'Bring in new data sets that help drive analytics across the organization.', 'Maintain critical data systems from ETL/ELT, Data Warehouse, BI Tools, and everything in between.', 'Build and maintain systems that will help Data Analysts with advanced analytics.', 'Help grow and champion the use of data driven decision making with the Liferay organization.', 'Analyze requirements from Data Analysts and provide solutions or guidance for solutions.', 'Assist departments without Data Analysts with reports or analysis with a priority on Human Resources and Marketing.', '2+ years of relevant experience with a BS/BA in Computer Science/Information Systems or 4+ years of relevant experience.', 'Proficient in Python, Java or similar languages.', 'Proficient at writing SQL for MySQL, Google BigQuery or similar database.', 'Proficient with ELT/ETL and Data Warehousing development.', 'Proficient in Tableau or similar Business Intelligence tools.', 'Strong communication skills.', 'Experience with Google Cloud Platform, Google BigQuery and Matillion.', 'Experience with Git or similar VCS.', 'Experience working within the Scrum framework.', 'Competitive salary & benefits package according to qualifications and experience', 'Opportunities to take responsibility and grow professionally. We like to Stay Nerdy!', 'A positive and collaborative work culture', 'Working at a leading open source company']",2020-12-30 21:59:41
Data Engineer,Northwestern Medicine,"4 out of 5 from 1,272 employee ratings","Chicago, IL 60611","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'The Data Engineer is responsible for delivering data warehouse and analytic solutions by ingesting, integrating, and curating data, building analytical solutions, and administering systems to deliver information to the health system.', 'Serves as a functional and content expert of the data warehouse to synthesize raw data into actionable information to be used in analytical solutions.', 'Applies knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored procedures.', 'Collaborates with the Architecture team in the design and execution of solutions.', 'Ensures that new and existing data models and databases are consistent with approved data architecture standards.', 'Provide facilitation, analysis, design, and execution of architecture solutions and ensure solutions are leveraged. Create, document, and communicate the integration approach of all the components of the solution.', 'Define key solutions and ensure they are managed for consumption by users and across teams. Research, analyze, determine capabilities and propose solution alternatives to address specific business needs and product/service strategies.', 'Maintain knowledge of current trends and development in the field. Actively explores emerging technologies.', 'Independently work with business users to gather and scope requirements and recommend analytical solutions to meet business needs.', 'Assists with ETL design and development including data analysis, source-target mapping, quality profiling, change data capture, code performance.', 'Evaluate data quality and interpret results in a clear, concise manner.', 'Document all programming changes and design, system modifications and their associated maintenance.', 'Own analytics projects and be accountable for collaborating with the business to gather requirements, execute to provide analytical solutions, which exceed customer expectations.', 'Work collaboratively with and support multi-departments efforts and projects.', 'Mentor staff by sharing skills, experience, knowledge, and expertise on analytic tools and solutions.', 'Serve as subject matter expert within the department.', 'Provide training and support through the organization on the use of analytics tools.', 'Performs other duties and functions as assigned.', 'Bachelor’s degree or equivalent experience in relevant field', 'Five or more years of experience in a role querying, analyzing data, and/or data modeling/architecture', 'Experience working with a variety of data warehousing models and design fundamentals (e.g. Inmom Kimball)', 'Experience with developing and maintaining ETL / data pipeline (e.g. Microsoft SSIS, Azure Data Factory)', 'Experience with OLAP or Tabular cube software', 'Experience using SQL for data extraction, manipulation, and reporting', 'Previous experience working in an Agile environment', 'Strong knowledge of relational database skills including advanced SQL knowledge and the ability to create complex queries and stored procedures', 'Experience with report writing and data visualization tools such as: Microsoft Power BI, Tableau, Crystal Reports, SSRS, etc.', 'Experience developing, designing and supporting applications and relational databases', 'Experience using a software package for statistical analysis (R, Python, etc)', 'Previous experience working with Epic Clarity data', 'Previous healthcare experience, ideally with a health system']",2020-12-30 21:59:41
Big Data Engineer,Nespon IT Services,N/A,"Rockville, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:AWS , 2 years (Required)Hive, 5 years (Required)Scala, 5 years (Preferred)Machine Learning, 3 years (Preferred)spark, 5 years (Preferred)Java, 5 years (Preferred)Hadoop, 5 years (Required)Big Data, 5 years (Required)Python, 5 years (Required)', 'Analyze system requirements and design responsive algorithms and solutions', 'Use big data and cloud technologies to produce production quality code', 'Engage in performance tuning and scalability engineering', 'Work with team, peers and management to identify objectives and set priorities', 'Perform related SDLC engineering activities like sprint planning and estimation', 'Work effectively in small agile teams', 'Provide creative solutions to problems', 'Identify opportunities for improvement and execute', 'Experience with cloud based Big Data technologies', 'Proficiency in Hive / Spark SQL', 'Experience with Spark', 'Experience with one or more programming languages like Scala, Python, and/or Java', 'Ability to push the frontier of technology and independently pursue better alternatives', '8 hour shift', 'Monday to Friday', 'AWS : 2 years (Required)', 'Hive: 5 years (Required)', 'Scala: 5 years (Preferred)', 'Machine Learning: 3 years (Preferred)', 'spark: 5 years (Preferred)', 'Java: 5 years (Preferred)', 'Hadoop: 5 years (Required)', 'Big Data: 5 years (Required)', 'Python: 5 years (Required)', 'Temporarily due to COVID-19']",2020-12-30 21:59:41
Data Operations Engineer,HealthVerity,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyze all vendor data assets and correct complex data anomalies', 'Monitor Airflow and other internal tools to ensure data processing and ingestion is not interrupted', 'Source and oversee the lifecycle of reference data sources specified by the Data Architecture team', 'Provide guidance and support during the vendor on-boarding process which includes data ingestion, normalization, and QC activities', 'Develop repeatable testing routines to expedite QA that can also be used to closely monitor the recurring ingestion for ongoing QC', 'Develop and maintain trend analysis for longer term, historical quality control', 'Perform analytics against healthcare data using SQL based programming tools', 'A data geek with enviable SQL skills and a passionate sense of ownership', 'A self-starter who enjoys working in a small, rapidly changing, fast-paced environment', 'A person with good written/ verbal communication skills', 'Confident enough to course correct a process or team when required', 'Dedicated to ensuring our customers get uninterrupted service', 'Methodical, executing through several approaches to determine the best fit', 'Energized by learning even if outside the scope of day-to-day responsibilities', 'Comfortable working on several different tasks throughout your workday', 'BS degree in MIS, Math/statistics/analytics, computer engineering', 'Proficient in programming against large data assets with a working knowledge of SQL, preferably also knowledgeable in Python', 'Proven analytical, evaluative, and problem-solving abilities', 'Extensive experience working in a team-oriented, collaborative environment', 'Organized and time conscious', 'Capable of working independently', 'Empowering clients with highly rewarding data discovery and licensing tools', 'Ingesting and managing billions of healthcare records from a wide variety of partners', 'Standardizing on common data models across data types', 'Orchestrating an industry-leading HIPAA privacy layer', 'Innovating our proprietary de-identification and data science algorithms', 'Building a culture that supports rapid iteration and new possibilities']",2020-12-30 21:59:41
Data Engineering,SHGT,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience: Palantir Cloud Foundry OR Clinical Trial Data Model , 4 years (Preferred)', 'Responsible for Data Engineering, Foundry Data Pipeline Creation, Foundry Analysis & Reporting, Slate Application development, re-usable code development & management and Integrating Internal or External System with Foundry for data ingestion with high quality.', 'Have good understanding on Foundry Platform landscape and it’s capabilities', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Defines company data assets (data models), Pyspark, spark SQL, jobs to populate data models.', 'Designs data integrations and data quality framework.', 'Design & Implement integration with Internal, External Systems, F1 AWS platform using Foundry Data Connector or Magritte Agent', 'Collaboration with data scientists, data analyst and technology teams to document and leverage their understanding of the Foundry integration with different data sources - Actively participate in agile work practices', 'Coordinating with Quality Engineer to ensure the all quality controls, naming convention & best practices have been followed', 'Strong data engineering background', 'Experience with Clinical Data Model is preferred', 'Experience in', 'SQL Server ,Postgres, Cassandra, Hadoop, and Spark for distributed data storage and parallel computing', 'Java and Groovy for our back-end applications and data integration tools', 'Python for data processing and analysis', 'Cloud infrastructure based on AWS EC2 and S3', '7+ years IT experience, 2+ years’ experience in Palantir Foundry Platform, 4+ years’ experience in Big Data platform', '5+ years of Python and Pyspark development experience', 'Strong troubleshooting and problem solving skills', ""BTech or master's degree in computer science or a related technical field"", 'Experience designing, building, and maintaining big data pipelines systems', 'Hands-on experience on Palantir Foundry Platform and Foundry custom Apps development', 'Able to design and implement data integration between Palantir Foundry and external Apps based on Foundry data connector framework', 'Hands-on in programming languages primarily Python, R, Java, Unix shell scripts', 'Hand-on experience in AWS / Azure cloud platform and stack', 'Strong in API based architecture and concept, able to do quick PoC using API integration and development', 'Knowledge of machine learning and AI', 'Skill and comfort working in a rapidly changing environment with dynamic objectives and iteration with users.', 'Demonstrated ability to continuously learn, work independently, and make decisions with minimal supervision.', '8 hour shift', 'Palantir Cloud Foundry OR Clinical Trial Data Model : 4 years (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 21:59:41
Data Engineer,Dashlane,4 out of 5 from 4 employee ratings,"New York, NY 10010","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build data pipelines and python-based ETL tools for acquiring, processing, and delivering data', 'Develop data models and schemas in our data warehouse that enable performant, intuitive analysis', 'Handle the challenges that come with managing terabytes of data', 'Collaborate with business leaders and analysts to define key metrics and build reporting to monitor and understand company performance', 'Develop the server applications and APIs that are used by our Data Team', 'You have 3+ years of experience as a data engineer, business intelligence analyst, or in a highly analytical role', 'You have 3+ years of experience with a scripting language (preferably Python) for data processing and analysis', 'You have experience designing SQL tables, choosing indexes, tuning queries, and optimizations across different functional environments.', 'You have experience writing complex SQL queries and using a BI tool', 'You have a passion for sharing the value of data and communicating insights to a broad audience with varying levels of technical expertise', 'You have experience with data lakes and designing and maintaining data solutions using Spark and AWS serverless services such as Kinesis, Lambda, or SQS', 'You have experience administrating, ingesting, and monitoring data in data warehouses such as Amazon Redshift or Microsoft SQL Server', 'You are a self-starter that can work in a fast-paced, distributed environment, as you will be collaborating with our Paris and Lisbon teams']",2020-12-30 21:59:41
Junior Data Engineer,Yorktel,3.9 out of 5 from 27 employee ratings,"Eatontown, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Proven experience in utilizing enterprise data model, data warehouse, and business analytics in delivering reporting capability to users', 'Experience with ETL tools and methods in transforming data into target models while maintaining data lineage documentation', 'Ability to utilize best practices for report development, data management and data quality monitoring.', 'Hands on experience with relational database design, SQL, database management, and reporting services', 'Knowledge of best practices in dashboard design and layout for most usability and functionality', 'Knowledge of Microsoft BI technology components: SSRS, Power BI, SSIS, DAX and SQL Server, Azure Analysis services, Azure Data Factors', 'Understanding of data integration patterns between distributed systems and challenges when working with data from heterogenious sources', 'Hands on experience and knowledge of Microsoft Business Intelligence related roadmaps, tool sets, and data visualization applications', 'Familiar with software development lifecycle and its applicability to report and data analytics development and maintenance.', 'Familiar with best practices for ensuring data security and privacy.', 'Familiarity with data concepts related to ERP systems', 'Prioritize between daily support requests and overall project development to balance the expectation between supporting requesters and the timeline to accomplish functional data analytics objectives', 'Identify business process practices that impact existing and new reporting solutions, analytics and legacy reporting capabilities', 'Investigate issues holistically to assess the requirements impacting the data model and data dictionary.', 'Balance between support of existing reporting capabilities, meeting business priorities and following standard and practices established by the Business Intelligence Team, Working Groups and Enterprise Data Architect', 'Respond to request for data from senior leaders while taking considerations of developed standards and best practices.', 'Have a great communication skill both verbal and writing to communicate both to the team members and users involved in the report and data analytics development activities.', 'Consolidate feedback from the team and users to make informed decision to execute the project and refine existing reporting and data analytics capabilities.', 'Be proponent and educate broader organization to take advantage of standard report and data analytics capabilities within their business process whenever possible.', 'Lead migration of legacy reporting capabilities to be aligned with the corporate direction of reporting capabilities.', 'Identify business process areas that have tangible impact data quality needed to support business metrics and propose ideas and metrics that describe monitor the data quality impact.', 'To understand the goals and directions from the Enterprise Data Architect and Information Management Leadership to utilize and configure the enterprise data reporting and data analytics infrastructure that can support the identified standards and objectives', 'Provide support to objectives set by Information Management Leadership, stakeholders from internal organization and from partners organizations.', 'Ensure that reporting capabilities delivered are utilizing optimal software and hardware components to minimize cost and risk to the organization', 'Escalate issues to Enterprise Data Architect, Information Management Leadership or CIO if direction or support required to resolve issues', 'To learn standard corporate data models utilized in corporate standard report and leverage and enhance these models whenever possible when working on daily user requests for information', 'To build ETL processes that collect data from multiple data sources, transform into target tabular data model and deploy the model in Azure Analysis Services', 'Troubleshoot in depth any data accuracy issues in support of reporting and business analysis using SQL Queries and Power BI reports', 'Work with Business Stakeholders to understand business objectives of requested capabilities and map the capability to data elements', 'Understand and able to answer questions on the company data models maintained across organization business units and how the data models support various business processes', 'Document data model elements for consumption by the report developer community', 'To utilize Power BI, SSRS and Data Factory and SQL Server to build ETL processes and configure reports and dashboards that meet both user requirements as well as comply with the standards established by Enterprise Data Architect', 'Assist in maintaining Vision BI platform by identifying data model issues and researching data scenarios that lead to the problems', 'Develop and maintain knowledge of the main platform features of Power BI, SSRS and Azure Analysis Services', 'To answer inquiries and to resolve issues related to data related issues within analytics and reporting components', 'Operational support of the existing processes and components that are part of the BI Platform', 'High levels of Professionalism and Integrity', 'High ability to work with peers', 'Exceptional written, verbal and interpersonal skills.', 'Excellent problem-solving skills', 'Maintain a professional attitude and appearance at all times', 'Extensive use of business computer systems including Microsoft Office applications such as MS Word, Excel, Outlook and MS Project.', 'May require occasional lifting (up to 50 lbs.)', 'Requires extensive sitting, standing and walking', 'Domestic travel requiring multi-night stays within and at times outside US.', 'Require working during off hours or weekend occasionally.', 'Valid passport; International travel required', 'Valid U.S. driver’s license', 'Must be willing to complete background checks and drug tests as required by current or future contracts']",2020-12-30 21:59:41
Data Engineer (Remote),vidIQ,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Building efficient, critical data pipelines, including ETL, partitioning data, data compaction, and AWS optimization', 'Collaborate closely with data scientists, product analysts to create the data sets that power vidIQ’s algorithms', 'Be an advocate for data quality, acquisition of new data sources, and data infrastructure tooling', 'Work closely with cross-functional teammates, including product managers, designers, product analysts, and data scientists, to deliver the highest impact to our users', 'You have experience using Python for internal data pipelines (moving data inside AWS account), including numpy and pandas, additionally you have experience DynamoDB, Lambda, Redshift, and S3', 'Hands-on experience with data workflow orchestration', 'Proven track record of working with cross-functional teams in an agile-like environment', 'Ability to communicate data concepts, requirements, and risks clearly to cross-functional team members, especially product analysts, data scientists, and product managers', 'Preferably, you have experience developing ML-based products & services and/or working with Spark']",2020-12-30 21:59:41
"Customer Engineer, Data & AI",Microsoft,"4.2 out of 5 from 7,020 employee ratings",United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participate in proactive account management, spot performance issues, analyze problems, develop solutions to meet customer needs, represent them.', 'Provides the most effective method of service delivery by analyzing trends and common themes across customers.', 'Create deliverables to address common customer needs & support mobile-first, cloud-first strategy, share intellectual property with others.', 'Engages in strategic service delivery planning, in partnership with the virtual account team (VAT), to strengthen targeted customer relationships.', 'Gathers customer impressions of products and services and integrates this feedback into decision making.', 'Seeks information about the underlying needs of customers.', 'Allocates and aligns resources to optimize the customer experience.', 'Develops and communicates realistic performance goals and standards.', 'Builds plans that consider potential obstacles and immediate and long-term consequences.', 'Demonstrates expertise in a specific solution, or several products, feature functions, or services.', 'Provides stakeholder assistance throughout deployment to avoid/resolve technical issues.', 'Seeks opportunities to drive Customer Success business results by collaborating with multiple team members.', 'Identifies opportunities to articulate business value and grow customer/partner relationships in alignment with Customer Success business priorities and stakeholder management principles.', 'Provides and drives actionable feedback across groups about the customer/partner experience and competitor threats.', 'Modifies existing intellectual property (IP) or, where applicable, creates new content.', 'Seeks opportunities to drive Customer Success business results by collaborating with multiple team members.', 'Consistently apply ""lessons learned"", model personal accountability & teamwork.', 'Demonstrates an understanding of his or her role and contribution to customer/partner change management and adoption initiatives.', 'Understands customer/partner requirements and can map the adoption and optimization of Microsoft technology solutions accordingly.', 'Drives and Supports innovation focusing on industry solutions and customer business outcomes on the Microsoft platform.', 'Contribute & participate with meetings to articulate Premier offerings to all customers; share knowledge thru communities, adapt for customers.', 'Cultivates relationships, credibility, and loyalty with customers and partners intentionally by sharing relevant business expertise.', 'Demonstrated Self Learner', 'Analytical Problem Solving', 'Building Customer/Partner Relationships', 'Product & Technology Expertise', 'Leadership', 'Value Selling', 'Years’ Experience: 3 in systems development, network operations, software support, IT consulting', 'Bachelor’s Degree (B.S./B.A.) or equivalent', 'At least 2 years of experience working with Enterprise customers in any of the following: providing customer technical readiness, delivery support services, on premise and remote technical support, solution development, account management; technical requirements gathering; broad evangelism through events (presentation skills) or related.', 'At least 3 years of experience utilizing SQL Server ( combined experience in any of the following versions of SQL Server 2019, 20v16, 2014, 2012, 2008 R2 and SQL Server 2005) in any two of the following technical focus areas:', 'Deep technical or architectural knowledge is preferred', 'Experience delivering and/or authoring technical training', 'Ability to communicate with a variety of different audiences and strong presentation skills', 'Ability to match technical solutions with customer business requirements', 'Ability to lead and motivate technical communities', 'Ability to effectively recognize and adapt to change']",2020-12-30 21:59:41
Data Engineer,Tanu infotech services,N/A,"Manhattan, NY 10001","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-12-30 21:59:41
Junior Data Engineer,"Horizon Media, Inc.",3.8 out of 5 from 84 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '30% - Build and maintain data pipelines using Python code base', '25% - Troubleshoot data quality issues and perform the necessary fixes/backfills', '20% - Collaborate with data scientists and BI analysts to understand data models and data ingestion requirements', '20% - Enhance Engineering codebase to fix bugs, and add and document features', '5% - Participate in planning meetings', 'Methodical developers who are obsessed with attention to the smallest details.', 'Accomplished go-getters who balance their need for flawless execution with the need to meet client deadlines.', 'Team players who enjoy working with others to design and implement robust solutions for challenging real-world problems.', 'Passionate coders who enjoy devising the most efficient ways to tackle business problems through algorithms and coding best practices', 'Critical thinkers who thrive when working with a variety of coding and programming languages across multiple systems.', 'Ingenious architects whose understanding of data engineering fundamentals enables them to conceptualize manual processes, generate coding and create systems to reduce human dependency.', 'A supporter of and advocate for diversity, equity and inclusion', 'Bachelor’s degree in technical field, computer science/engineering, or mathematics', 'Exposure to cloud services like Google Cloud Platform, Azure or AWS – AWS highly preferred (S3, Redshift, EC2, and etc.)', 'Understanding of object-oriented programming – classes, methods, inheritance, method overriding, etc.', '2+ years of experience using Python and knowledge of a second object-oriented programming language', '2+ years of experience using SQL for data warehousing and ETL development', 'High level knowledge of designing/building/deploying production-level data pipelines on scalable, distributed systems or multi-node database paradigms', 'Working knowledge of Linux environments, Git, and Shell scripting – must be able to perform simple navigation of Unix-like operating systems (manipulating files, logging on to other systems using terminal, etc.)', 'Excellent written and verbal communication with both technical and non-technical audiences', 'Must have a good balance of resourcefulness - If you don’t know how to do something new, figure it out, but if you’re stuck, don’t spend too much time on it before asking for help']",2020-12-30 21:59:41
"Data Engineer, Datasets Team",Earnest Research,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Creative problem solving', 'A high level of enthusiasm and proactivity', 'Attention to detail', 'The ability to succinctly communicate ideas', 'The ability to produce high-quality work under tight timelines', 'A willingness to take ownership of work', 'The ability to work as part of a team and effectively with others', 'Extract and process raw data at scale (including writing scripts, calling APIs, writing SQL/Spark, etc.)', 'Process unstructured data into a form suitable for analysis', 'Work closely with product owners and data analysts to gather and understand requirements', 'Interface with Data Platform engineers and give valuable feedback that guides tooling', 'Participate in code reviews and design discussions, give and receive constructive feedback', ""Create, extend and own data pipelines that power the company's products"", 'Ensure high Data Quality and pipeline stability', 'Experience processing large amounts of structured and semi-structured data', 'Programming experience in Python, SQL and Bash', '2+ years writing and maintaining ETL at a terabyte level scale', '1+ years experience working with Hadoop applications (Spark)', 'Experience with version control systems (Git)', 'Code-based data orchestrator such as Apache Airflow, Dagster, Luigi', 'Knowledge of aws, emr, redshift/snowflake', 'Spark-Scala / PySpark Experience', 'Experience with Docker containerization', 'Strong knowledge of and experience with statistics', 'Enthusiasm for Open Source', 'Data Warehouse modeling experience', 'Experience with or willingness to learn functional programming (Haskell)', 'Experience using Data Build Tool (DBT)', 'Experience automating Data Quality checks either through DBT, Great Expectations or company tooling', '100% company paid medical plan options (additional medical, dental and vision plans available too!)', '401K retirement plans', 'Flexible and generous time off', 'Generous Parental Leave Policies', 'Pre-tax savings plans for public transportation and parking expenses', 'Regular company happy hours, lunches & events']",2020-12-30 21:59:41
Data Engineer (U.S. Citizens ONLY),TAA Solutions LLC,N/A,"Linthicum Heights, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Java: 4 years (Preferred)Python: 4 years (Preferred)ETL: 4 years (Preferred)various log formats such as JSON, XML, and others.: 3 years (Preferred)Secret (Preferred)"", 'Must be able to obtain a security clearance (Secret level or higher), and therefore all candidates must be U.S. citizens. Will also consider candidates that have a current clearance.', 'B.S. degree in Computer Science, Information Technology, Electrical Engineering, Statistics, or equivalent fields. Educational requirements may be adjusted for applicable work experience. Work experience may be adjusted for highly specialized knowledge or uniquely applicable experience.', '5+ years of experience as a developer, analyst, or engineer.', 'Experience with programming languages such as Python and Java.', 'Proficiency with acquisition and understanding of network data and the associated metadata.', 'Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics.', 'Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions).', 'Familiarity with various log formats such as JSON, XML, and others.', 'Ability to decompose technical problems and troubleshoot system and dataflow issues.', 'Experience with NoSQL databases such as Accumulo desired', 'Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer.', 'Experience with Kibana and Elasticsearch.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee discount', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Referral program', 'Relocation assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'Commission pay', 'Signing bonus', 'Tips', ""Bachelor's (Preferred)"", 'developer, analyst, or engineering: 5 years (Preferred)', 'Java: 4 years (Preferred)', 'Python: 4 years (Preferred)', 'ETL: 4 years (Preferred)', 'data flow, management, and storage solutions: 3 years (Preferred)', 'various log formats such as JSON, XML, and others.: 3 years (Preferred)', 'Secret (Preferred)', 'More than 1 year', 'Varies', 'Likely', 'Yes', 'Multiple locations', 'www.taasolutions.net', 'Remote interview process']",2020-12-30 21:59:41
ETL Developer/Data Ingestion Engineer,Varen Technologies,4.3 out of 5 from 6 employee ratings,"Reston, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '2+ years of experience with Java', '1+ years of experience with a streaming data framework, including Apache Kafka', '1+ years of experience with web-based architecture, including HTML and JavaScript', '1+ years of experience with ETL development and processes from diverse data sources', '1+ years of experience with the development, maintenance, and enhancement of data mappings, work-flows, and processes', '1+ years of experience in working with Relational Databases', 'Experience with a variety of data feed types, including RSS, SOAP, and REST', 'Experience with data modeling concepts', 'Experience with XML, JSON, and TXT transformations, including writing and applying XSLT to transform data', 'Experience with any of the following technologies: Apache Kafka, NiFi, Airflow, PostgreSQL, Pentaho Data Integration, Accumulo, Solr, Elastic Stack, Firefox, Chromium, or Kubernetes', 'Experience with DoD or IC clients', 'Experience as a database administrator', 'Experience with web scraping, including Document Object Model (DOM) exploration', 'Knowledge of the Agile software development process, including Scrum and Kanban', 'Ability to map and document needed data elements in multiple databases to aggregate them under one schema', 'BA or BS degree preferred', 'Database Administration, ETL, or Business Intelligence-related Certifications preferred', 'DoD 8570 Compliance Certification, including Security+']",2020-12-30 21:59:41
Data Engineer,IntegriChain,2.8 out of 5 from 8 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop, support, and refine new data pipelines, data models, business logic, data schemas as code, and analytics to product specifications.', 'Prototype and optimize data type checks to ensure data uniformity prior to load.', 'Develop, and refine both streaming and batch processing data pipeline frameworks.', 'Maintain, improve, and develop expertise in existing production data, models, and algorithms.', 'Learn and utilize business data domain knowledge and its correlation to underlying data sources.', 'Define, document, and maintain a data dictionary including: data definitions, data sources, business meaning and usage of information.', 'Identify and validate opportunities to reuse existing data and algorithms.', 'Works with stakeholders to gather requirements on merging, de-duplicating, standardizing data.', 'Collaborate on design and implementation of data standardization procedures.', 'Share team responsibilities; such as contributing to development of data warehouses and productizing algorithms created by Data Science team members.', ""Bachelor's Degree in technical background or equivalent work experience."", '2 - 3+ years of experience building data pipelines and using ETL tools. Prefer python programming experience.', '3+ years of experience in at least one basic relational database platform (sql server, oracle, postgres, mysql) and languages (PL/SQL, SQL).', '1+ years experience developing modern, industry standard big data frameworks with AWS or other cloud services.', 'Experience with common GitHub developer practices and paradigms.', 'Experience working with agile methodologies and cross-functional teams.', 'Knowledge of redshift or any other columnar database is prefered.', 'Knowledge of aws services and airflow is a plus.', 'Experience in building AWS data pipelines using python, S3 data lake is a plus.', 'Knowledge of speciality pharmaceutical and retail pharmacy is a plus.']",2020-12-30 21:59:41
ETL Developer/Data Ingestion Engineer,Varen Technologies,4.3 out of 5 from 6 employee ratings,"Reston, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '2+ years of experience with Java', '1+ years of experience with a streaming data framework, including Apache Kafka', '1+ years of experience with web-based architecture, including HTML and JavaScript', '1+ years of experience with ETL development and processes from diverse data sources', '1+ years of experience with the development, maintenance, and enhancement of data mappings, work-flows, and processes', '1+ years of experience in working with Relational Databases', 'Experience with a variety of data feed types, including RSS, SOAP, and REST', 'Experience with data modeling concepts', 'Experience with XML, JSON, and TXT transformations, including writing and applying XSLT to transform data', 'Experience with any of the following technologies: Apache Kafka, NiFi, Airflow, PostgreSQL, Pentaho Data Integration, Accumulo, Solr, Elastic Stack, Firefox, Chromium, or Kubernetes', 'Experience with DoD or IC clients', 'Experience as a database administrator', 'Experience with web scraping, including Document Object Model (DOM) exploration', 'Knowledge of the Agile software development process, including Scrum and Kanban', 'Ability to map and document needed data elements in multiple databases to aggregate them under one schema', 'BA or BS degree preferred', 'Database Administration, ETL, or Business Intelligence-related Certifications preferred', 'DoD 8570 Compliance Certification, including Security+']",2020-12-30 22:01:22
Data Engineer,IntegriChain,2.8 out of 5 from 8 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop, support, and refine new data pipelines, data models, business logic, data schemas as code, and analytics to product specifications.', 'Prototype and optimize data type checks to ensure data uniformity prior to load.', 'Develop, and refine both streaming and batch processing data pipeline frameworks.', 'Maintain, improve, and develop expertise in existing production data, models, and algorithms.', 'Learn and utilize business data domain knowledge and its correlation to underlying data sources.', 'Define, document, and maintain a data dictionary including: data definitions, data sources, business meaning and usage of information.', 'Identify and validate opportunities to reuse existing data and algorithms.', 'Works with stakeholders to gather requirements on merging, de-duplicating, standardizing data.', 'Collaborate on design and implementation of data standardization procedures.', 'Share team responsibilities; such as contributing to development of data warehouses and productizing algorithms created by Data Science team members.', ""Bachelor's Degree in technical background or equivalent work experience."", '2 - 3+ years of experience building data pipelines and using ETL tools. Prefer python programming experience.', '3+ years of experience in at least one basic relational database platform (sql server, oracle, postgres, mysql) and languages (PL/SQL, SQL).', '1+ years experience developing modern, industry standard big data frameworks with AWS or other cloud services.', 'Experience with common GitHub developer practices and paradigms.', 'Experience working with agile methodologies and cross-functional teams.', 'Knowledge of redshift or any other columnar database is prefered.', 'Knowledge of aws services and airflow is a plus.', 'Experience in building AWS data pipelines using python, S3 data lake is a plus.', 'Knowledge of speciality pharmaceutical and retail pharmacy is a plus.']",2020-12-30 22:01:22
Software Development Engineer I (Front-End & Data Engineering),Fred Hutchinson Cancer Research Center,4.2 out of 5 from 163 employee ratings,"Seattle, WA 98109","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Maintain, modify and develop software features in JavaScript, R, and SQL, such as updating React.js components, refactoring an R package, or creating custom SQL queries.', 'Contribute to the automated testing framework for both the web-based database portal and the R API client', 'Write and maintain user-facing and internal documentation.', 'Participate in feature requirements gathering, design and tasking for new development or refactoring.', 'Engage in code discussions and reviews to ensure all team-members are cross-trained on all parts of the larger codebase.', 'Bachelor’s Degree or equivalent experience', '0-2 years professional experience in software development', 'Experience with modern front-end JavaScript frameworks (e.g. React or Angular) and libraries (e.g. Bootstrap) and interest in learning data engineering with R', 'Detail oriented including the following: Ability to understand a system of complex interactions and explain this understanding to technical and non-technical collaborators', 'Capable of deep troubleshooting to discover the root causes of problems', 'Has well-commented code and documentation', 'Positive attitude, willingness to ask questions and learn independently', 'Working knowledge of version control systems (e.g. git)', 'Experience cleaning and reorganizing data in a common data science language (e.g. R, Python, MatLab)', 'Conceptual understanding of automated testing and experience writing simple unit tests', 'Comfortable in UNIX systems and working at the command line', 'Experience in custom SQL query development', 'Experience with cloud infrastructure (e.g. AWS / Azure) or containerization (Docker)']",2020-12-30 22:01:22
"Java Software Engineer, Big Data","JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Wilmington, DE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Part of a scrum team to deliver high quality software to the business', ""Working closely with our Card Pricing product partners to help estimate and prioritize the team's backlog and define stories needed to deliver the solution"", 'Able to understand production issues and resolving defects.', 'Deliver the defined solutions for the projects thru the Agile process', ""Bachelor's degree in Computer Science, Engineering or related technical field"", '3 - 5 years of progressive, post-baccalaureate work experience in job offered or three years of progressive, post-baccalaureate work experience in a software engineering-related occupation', ""3 - 5 years' experience with full development lifecycle from inception through implementation"", ""2+ years' experience with building large scale big data applications"", 'Extensive experience & demonstrated proficiency in Core Java and Spark (or other Big Data technology).', 'Demonstrable experience of successfully delivering big data projects using Kafka, Spark and related stack on premise or cloud', 'Hands-on experience in HDFS, MapReduce, Yarn & Hive', 'Working experience as Agile developer and good understanding of SDLC methodologies/guidelines', 'Hands on experience with building CI/CD', 'Experience in developing software solutions leveraging Test Driven Development (TDD)', 'Able to tune big data solutions to improve performance', 'Experience with ETL tools such as Ab Initio']",2020-12-30 22:01:22
Data Engineer,Facebook,4.2 out of 5 from 602 employee ratings,"Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with leadership, engineers, program managers and data scientists to understand data needs.', 'Apply proven expertise and build high-performance scalable data warehouses.', 'Design, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts).', 'Securely source external data from numerous partners.', 'Intelligently design data models for optimal storage and retrieval.', 'Deploy inclusive data quality checks to ensure high quality of data.', 'Optimize existing pipelines and maintain of all domain-related data pipelines.', 'Ownership of the end-to-end data engineering component of the solution.', 'Support on-call shift as needed to support the team.', 'Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data.', 'BS/MS in Computer Science or a related technical field.', '5+ years of Python or other modern programming language development experience.', '5+ years of SQL and relational databases experience.', '5+ years experience in custom ETL design, implementation and maintenance.', '3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).', '3+ years experience with Data Modeling.', 'Experience working with cloud or on-prem Big Data/MPP analytics platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).', '2+ years experience working with enterprise DE tools and experience learning in-house DE tools.']",2020-12-30 22:01:22
100% Remote Data Engineer,"Attain, LLC",3.6 out of 5 from 36 employee ratings,"McLean, VA 22102","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work authorization:United States (Required)', 'Passion Seekers. You genuinely care about the work that you do and its impact on society.', 'Self-Starters. You’re a go-getter who isn’t afraid to step up and disrupt the status quo.', 'Entrepreneurs. You bring fresh ideas to the table, work hard, develop business and consistently seek new challenges.', 'Collaborators. You’re a great contributor to a high performing team that accomplishes great feats for our clients.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Establish performance monitoring of databases and create data pipeline architecture', 'Manage data life cycle from transactions to reporting to archival of data', ""Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies"", 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', '5 years of proven expertise in relational and dimensional data modelling', '5 years in modern data development, upgrading, support and design.', 'Proven experience in leading data teams on data migration and transformation', 'Experience in establishing performance and statistical monitoring of enterprise databases to include, but not limited to; wellness checks, data integrity, privacy and security scans.', 'Experience in supporting cloud database environments, specifically AWS (i.e., EC2, S3, Neptune or Redshift) to include backup and archiving of data.', 'Good to have experience with data lakes implementations', 'Should be able to work early morning hours i.e. 6 am to 2 pm (US Eastern Time) for atleast 2-3 days a week', 'Experience with Apache NiFi is desired', 'Experience with OpenText Captiva is desired.', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'United States (Required)', 'Fully Remote']",2020-12-30 22:01:22
Data Engineer - Top Secret w/ SCI Eligibility - Multiple Locations,Logistics Management Institute,3.9 out of 5 from 66 employee ratings,"Schofield Barracks, HI 96857","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Also looking for candidates in these locations: Charlottesville, Fort Bragg (NC), Fort Gordon (GA), Ft. Meade, Hawaii, San Antonio, Germany, Italy, South Korea', '5+ years performing data acquisition, identify relevant data sources and sets and shall provide data system enhancements as required, including but not limited to product reformatting and data quality assessments to support the acquisition of new datasets.', 'Design, develop, test and manage the overall architecture that helps analyze and process data in the way the organization needs it.', 'Integrate external or new datasets into existing data pipelines.', 'Process, clean, and verify the integrity, accuracy, completeness, and uniformity.', 'Assess the effectiveness and accuracy of new data sources and data gathering techniques and perform all network administration and data system operations (e.g., computer and peripheral device operations, system backups) and any related operations associated with data acquisition, data maintenance, maintaining and updating metadata, and other data and information services for stakeholders.', 'Develop, construct, test and maintain databases.', 'Build data and analytics tools that will offer deeper insight into the pipeline, allowing for critical discoveries surrounding key performance indicators and customer activity.', 'Give recommendations and implement ways to improve data reliability, efficiency, and quality: evaluate, compare and improve the different approaches including design patterns innovation, data lifecycle design, data ontology alignment, annotated datasets, and elastic search approaches.', 'Act as the lead data strategist, identifying and integrating new datasets that can be leveraged.', 'Document all processes, models and activities.', 'Research and keep up-to-date with latest tradecraft and technology.', 'Collaborate with systems architects, data scientists, and analysts to direct and optimize the flow of data within the pipeline and ensure consistency of data delivery and utilization across multiple projects.', 'Curate and collect the data from a variety of traditional and non-traditional sources: extract data from sources, transform and integrate data in line with existing data, and load data into data stores for access by others.', 'Data pipeline/workflow management tools such as Azkaban and Airflow AWS cloud services such as EC2, EMR, RDS and Redshift.', 'Know basics of algorithms and data structures, distributed computing, Hadoop cluster management, HDFS, MapReduce, stream-processing solutions such as Storm or Spark, big data querying tools, frameworks, messaging systems, and big data toolkits.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Knowledge of ETL tools, data APIs, data modeling, and data warehousing solutions.', 'R, Python, Ruby, C++, Perl, Java, SAS, SPSS, and Matlab.', 'Demonstrated ability to work with enterprises to develop processes that support data transformation, data structures, metadata, dependency and workload management.', 'Comfort working in a dynamic environment with several ongoing concurrent projects; able to multitask, prioritize, and manage time effectively.', 'Creative problem solver who thrives when presented with a challenge; able to analyze problems and strategize for better solutions; strong problem solving skills with an emphasis on production for re-use.', 'Active TS/SCI clearance', 'MS in Computer Science, Information Systems or equivalent field and 5+ years of experience in a similar data engineer role; BS in Computer Science, Information Systems or equivalent field and 7 + years of experience in a similar data engineer role; or AA in Computer Science Information Systems or equivalent field and 10+ years of experience in a similar data engineer role', '3 years of experience handling databases and software develop is preferred.', 'Experience working with AWS cloud services such as EC2, EMR, RDS and Redshift', 'R, Python, Ruby, C++, Perl, Java, SAS, SPSS, and Matlab skills desired', 'Advanced data engineering experience required', 'Significant experience with databases', 'Experience and familiarity with Agile-Scrum software development', 'Experience gathering and decomposing requirements', 'Proven record of solution development and deployment', 'Familiarity with web based application development', 'Experience with testing, use case, and user stories', 'Outstanding communication skills, written and verbal', 'Highly-organized and able to manage multiple projects simultaneously', 'Team-player mentality with a positive attitude', 'Keen attention to detail and solid analytical skills', 'Able to articulate complex, abstract concepts concisely and effectively']",2020-12-30 22:01:22
Cloud Data Engineer,CACI,"3.8 out of 5 from 1,949 employee ratings","Reston, VA 20190","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with the product owners to understand business/functional requirements and roadmap/timeline for delivery.', 'Participate in design reviews and brainstorming sessions', 'Take requirements and transfer into fast developed prototypes and working solutions.', 'Develop and maintain detailed data mapping and end-to-end process flows', 'Analyze data flows, data relationships, data quality and data usage to define report performance-optimized data models', 'Developed highly optimized and scalable ETL processes that will extract, cleanse, consolidate and transform large structured and unstructured data from multiple sources and load them into a data warehouse, data marts, and/or data lake in AWS S3, Redshift, etc.', ""Minimum of Bachelor's Degree, preferred in related fields (ex: Computer Science, Analytics or Statistics)."", '5+ years ETL development and testing experience', '3+ years experience designing and developing applications using cloud services in AWS such as Redshift/Spectrum, EMR, AWS Glue, DynamoDB and other ETL tools such as Informatica, Mulesoft, etc.', 'Data modeling experience.', 'Advanced programming skills using SQL, Unix scripting, Python, .Net (C#), Java, etc.', 'Experience with and/or certification in BI/Visualization tools such as Tableau, Qlik Sense or PowerBI is a plus.', 'Familiarity with automated testing tools is a plus.', 'Experience with the Agile/Scrum methodology.', 'Excellent interpersonal, team cooperation and communication skills.', 'AWS certification is a plus.', 'Ability to obtain Public Trust clearance.', 'We’ve been named a Best Place to Work by the Washington Post.', 'Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.', 'We offer competitive benefits and learning and development opportunities.', 'We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.', 'For over 55 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.']",2020-12-30 22:01:22
Senior Data Engineer,Glow Networks,3.5 out of 5 from 46 employee ratings,"Budd Lake, NJ 07828","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:01:22
Data Engineer - 3277,ProFocus,N/A,"Beaverton, OR 97005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'ProFocus is searching for Data Engineers for a W-2 contract with competitive benefits with our client in Beaverton, Oregon.', 'Please email us your resume so we can discuss.', '5+ years in software and data engineering within an Agile environment', 'Strong experience in Python', 'Successful experience building RESTful APIs and building on AWS Cloud', 'Strong verbal and written communication skills with the ability to navigate ambiguity', 'Experience working with high volume of data sets', 'Authorization to work in the US is a precondition of employment. We do not sponsor work visas.', 'Our client is a Fortune 100 company with a passion for pushing the boundaries.', 'Candidates come first. ProFocus recently earned the Best in Staffing Award for Talent Satisfaction due to our World-Class service to our amazing candidates.', 'Quality process. We invest the time to learn about your skills, experience, and career goals in detail so we can find you a position that is a great fit.', 'Access to hiring managers. We have close relationships with some of the most respected companies in Portland. Due to those relationships, we can provide direct access to managers and positions that may not be available anywhere else.', 'Excellent benefits. We offer medical, dental, vision, 401k, education reimbursement, sick leave, and employer-paid short-term disability and life insurance.']",2020-12-30 22:01:22
Data Engineer,Capital Group,3.9 out of 5 from 392 employee ratings,"Irvine, CA 92618","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Enjoy generous time-away and health benefits from day one, with the opportunity for flexible work options', 'Receive 2-for-1 matching gifts for your charitable contributions and the opportunity to secure annual grants for the organizations you love', 'Access on-demand professional development resources that allow you to hone existing skills and learn new ones', 'You are excited by the meaning, structure, and content of data, in addition to building the mechanisms to make it available throughout the organization', ""You have a bachelor's degree in Computer Science, Engineering or a related technical field, and/or at least 5 years relevant work experience in analytics, data engineering, complex ETL, BI or related field."", 'You write and optimize advanced SQL queries with large-scale, complex datasets', 'You have technical knowledge of ETL/ELT technologies and a proven implementation track record leveraging complex SQL, ETL tools, API/file-based end points', 'You have experience modeling data for data warehousing and data lakes', 'You have an understanding of Big Data technology stack, including Hive, Hbase, Oozie, Airflow, MapReduce, and Spark, along with coding proficiency in at least one modern language such as: Python, R, Java', 'You have strengths in leadership, interpersonal, and problem-solving skills with the ability to continually learn new concepts and technologies and effectively apply them', 'You coordinate technical efforts using incremental mindset/agile methodology', 'You have some experience in cloud-first design, preferably AWS or Azure and corresponding services and components (data lake, MPP databases, autoscaling, container orchestration, etc.)', 'Your background includes 2-3 years’ experience in implementing big data solutions and automating enterprise scale data pipelines leveraging Hadoop, Apache Spark, etc.', 'You’ve implemented big data processing technology like Hadoop, AWS Redshift, Microsoft MPP (SQL DW/Synapse), and Snowflake.']",2020-12-30 22:01:22
Data Engineer,ShopKeep,3.1 out of 5 from 17 employee ratings,"New York, NY 10016","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You are passionate about working with data to solve business problems and will build and maintain the infrastructure to answer questions with data.', ""We have a big data warehouse with data ranging from merchant transactions to Zuora billing to Product usage. You'll model new constructs and improve existing ones."", 'Help streamline our data science workflows, adding value to our product offering and building out our customer life cycle and retention models.', ""All of our teams are hungry for insights. You'll work with stakeholders across the company, fielding abstract requests. This may involve pointing someone to the answer, teaching them how to fish, or ticketing a large project for later."", 'SQL (3 or more years of experience)', 'Python (3 or more years of experience)', 'Data visualization / exploration tools (1 or more years of experience)', 'Communications skills, especially of technical concepts to non-technical business leaders', 'Familiarity with the AWS ecosystem specifically RedShift and RDS', 'Attention to detail', 'Looker experience', 'Building or maintaining ETL processes', 'Ability to juggle multiple projects', 'Experience with Git', 'Medical, Dental, and Vision Insurance', 'Flexible Paid Time Off (PTO)', 'Commuter Benefits', '401k Match', 'Lively and enriching Engineering culture', 'Regularly scheduled hackathons, meetups and Tech Talks', 'Opportunity to attend Engineering Conferences, thanks to our generous company conference budget', 'Newsletters produced by Engineering teams', 'Cross-office collaboration between our NYC and Belfast teams with the opportunity to travel to our different offices', 'Regular team events, including Happy Hours and Game Nights', 'Catered lunches', 'Break area to play and relax', 'Standing desks', 'Meditation Sessions', 'And more to come as we work on ideas to help us keep the community feel connected while working remote']",2020-12-30 22:01:22
Data Engineer,Stanza Soft Inc,N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Evangelize and advocate for bringing in new data technologies for solving complex problems in data domain', 'Design and develop scalable data stores and frameworks with sub-second query latency on highly multi-dimensional data.', 'Engineering solutions to aggregate and automate large scale data flows from varying sources', 'Build real-time streaming pipelines that deliver data with measurable quality under the SLA', 'Ability to effectively communicate ideas to peers and distributed teams', 'Delivering products with top-notch quality in a fast-paced environment', 'Contributing to building a system with a test-driven development / agile approach', 'Collaborate with other team members in breaking down tasks and implementation of the initiatives all the way to release.', 'Works on complex issues where analyzing situations or data require an in-depth evaluation of variables. Exercises judgment in selecting methods, techniques, and evaluation criteria to obtain results.', ""Bachelor's degree in Computer Science/Engineering with 10+ years of experience or Master’s degree with 8+ years directly related experience."", 'Experience with large-scale distributed systems as pertains to data storage and computing', 'Experience building and architecting data lakes and distributed storage on AWS', 'Knowledge of batch and streaming data architectures', 'Extensive experience with Amazon AWS technologies S3, EMR and Redshift', 'Strong development skills in Java, Scala, and/or PySpark', 'Experience with caching technologies using Redis, Memcached.', 'Knowledge of various databases/database technologies - Oracle, Postgres, Cassandra (NoSQL), Vertica, or other columnar databases.', 'Advanced disciplinary knowledge in data technologies like SQL, Python, Airflow, Spark, Java, AWS and strong CS Fundamentals', 'Exposure to statistical data structures such as HyperLogLog, MinHash, etc', 'Demonstrated strength in data modeling, ETL development, and data warehousing', 'Experience providing technical leadership and mentoring other engineers for best practices in data engineering', '8 hour shift', 'No: Not providing sponsorship for this job', 'https://stanzasoft.com/', 'Remote interview process']",2020-12-30 22:01:22
Data Engineer / Data Scientist,AptoNet Inc,3 out of 5 from 2 employee ratings,"Woonsocket, RI 02895","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Required:', 'Strong in SQL and Python', 'Experience building automated data pipelines', 'Experience performing data analysis and data exploration', 'Experience working in an Agile delivery environment', 'Strong critical thinking, communication, and problem solving skills', 'Preferred:', 'Experience with big data frameworks (i.e. Hadoop and Spark)', 'Experience with cloud based platforms (i.e. Azure, GPC, AWS)', 'Experience working in multi-developer environment, using version control (i.e. Git)', 'Experience with orchestrating pipelines using tools (i.e. Airflow, Azure Data Factory)', 'Bonus:', 'Exposure/understanding DevOps best practice and CICD (i.e. Jenkins)', 'Exposure/understanding of containerization (i.e. Kubernetes, Docker)', 'Experience with real-time and streaming technology (i.e. Azure Event Hubs, Azure Functions Kafka, Spark Streaming)', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)""]",2020-12-30 22:01:22
Azure Data Engineer (100% Remote),Denken Solutions Inc,4.8 out of 5 from 5 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'In depth understanding and proficiency automation of cloud platforms and data platforms.', 'Expertise in on-prem and cloud database automation and platform automation. Azure experience preferred.', 'Proficiency with cloud automation tooling such as Ansible and Terraform etc.', 'Proficiency with DevOps and CI/CD methodologies and tools for automated infrastructure code test, integration, deployment, and assurance.', 'Proficiency with Languages such as Ruby, bash, Python or Go.', 'Proficiency with any one of the cloud provider AWS, Azure or Google Cloud Platform.', 'Experience with Software Development and automation methodologies', 'Experience with data security best practices.', 'Strong problem-solving skills.', 'Strong collaboration skills and excellent verbal and written communication skills.', 'Automation of data platform in cloud environment with CI/CD processes.Partner with architecture, security, infrastructure, and application teams to design and implement automation data and database platforms and tools.', 'Design, implement, and maintain automation platform and tools, including Ansible Tower, Azure, ARM, Terraform Enterprise, Azure DevOps and GitHub Actions.', 'Partner with outside teams to design, educate, and implement automation solutions for cloud, server, network, storage, middleware, database and security.', 'Design, implement and maintain Continuous Integration and Delivery environments for automated provisioning and deployments', 'Assist with problem resolution for cloud automation issues.', 'Create and update automation to eliminate routine management processes.', 'Maintain appropriate controls and documentation to ensure compliance of audit requirements and qualifications.', 'Articulate the need for scalability and understand the importance of improving quality through testing.', 'Perform cost, capacity and performance management analysis.']",2020-12-30 22:01:22
Data Engineer,Spruce,3.7 out of 5 from 18 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work closely with Product, Engineering, and Operations as part of a team building the industry’s first automated title search platform', 'Use Python to collect and parse real estate records from 3rd party data sources', 'Using this data, train and implement predictive underwriting models', 'Convert existing offline prototype models to fully automated, high performance production systems', '1-2 years working experience as a data scientist or data engineer', 'Experience with Python and SQL in a work setting', 'Working knowledge of web-scraping packages such as Selenium', 'Advanced degree in a quantitative field or equivalent', 'Experience developing and implementing statistical models, especially in the ML / AI family']",2020-12-30 22:03:02
Data Engineer L2,Capgemini,"3.8 out of 5 from 8,123 employee ratings","Wayne, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SRE/ Site Reliability Engineer - Advanced proficiency with at least three of the following, Java Server Pages (JSPs), JAX-RS / Jersey APIs, Python, Machine Learning, AI agents, Spring Framework experience', 'Subversion and Git', 'Basic SQL competency is expected', 'Hands on experience with cloud ecosystem such as AWS/PCF/Google Cloud/Azure Experience with Big Data platforms such as building out a data lake APM and distributed tracing solutions such as Dynatrace/AppDynamics/Jaeger/Zipkin', 'Experience with Distributed Tracing implementation (opentracing Experience with circuit breakers or developing circuit breaker logic)', 'Experience with structured and unstructured logging frameworks', 'Experience with resiliency patterns toggling, redundancy, autoscaling, idepotent methods etc']",2020-12-30 22:03:02
Data Engineer,JLL,"3.8 out of 5 from 2,763 employee ratings","Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company']",2020-12-30 22:03:02
Big Data Engineer,Wells Fargo,"3.7 out of 5 from 39,976 employee ratings","Summit, NJ 07901","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Standing up cutting-edge analytical capabilities, leveraging automation, cognitive and science-based techniques to manage data and models, and drive operational efficiency by offering continuous insights and improvements.', 'Help in design and implementation of algorithms and tools for analytics and data scientist teams.', 'Use a variety of languages, tools and frameworks to marry data and systems together.', 'Collaborate with modelers, developers, DevOps and project managers on meeting project goals.', '5+ years of software engineering experience', '5+ years of experience in software delivery in a large matrixed organization or on a complex system such as AKA, Development, DEVOPS, or QA', '4+ years of experience delivering ETL, data warehouse and data analytics capabilities on big-data architecture such as Hadoop', '5+ years of JDBC experience', '5+ years of JIRA experience', '5+ years of Linux experience', '5+ years of log4j experience', '5+ years of Middleware experience', '5+ years of Open Source experience', '5+ years of Oracle experience', '5+ years of Python experience', '5+ years of Cache experience', '5+ years of Multi-Threading Experience', '5+ years of Tomcat development or implementation experience', '5+ years of experience delivering complex enterprise wide information technology solutions', '5+ years of experience testing web-based applications developed in Java or .NET framework', '5+ years of experience supporting an Active Directory', '5+ years of Red Hat Linux or UNIX experience', '5+ years of application development experience', '5+ years of Windows or Linux scripting experience', '5+ years of server side coding experience', '5+ years of development experience with languages such as Python, Java, Scala, or R', '5+ years of experience with Big Data or Hadoop tools such as Spark, Hive, Kafka and Map', '5+ years of experience with Cloud technologies', '5+ years of Jira project design experience', '5+ years of JavaScript experience or 5+ years of PowerShell experience', '5+ years of experience with SonarQube', '5+ years of Kafka Platform experience, Confluent Platform experience, or a combination of both', '1+ year of API Gateway engineering experience such as DataPower, Apigee, MuleSoft', '3+ years of experience with machine learning tools', '2+ years of experience with one or a combination of the following: RESTful, JSON or XML web-based services', 'A BS/BA degree or higher', 'An industry-standard technology certification', 'Strong verbal, written, and interpersonal communication skills', 'SAS programming experience in model implementation, reporting, and complex data manipulations', 'Strong organizational, multi-tasking, and prioritizing skills', 'Strong collaboration and partnering skills', 'Strong technical and quantitative skills', 'Ability to travel up to 10% of the time']",2020-12-30 22:03:02
Cloud Data Engineer,Opinior,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Google Cloud Platform: 1 year (Required)US work authorization (Required)Bachelor's (Preferred)"", 'Experience in building solution architecture, provision infrastructure, secure and reliable data-centric services and application in GCP or Azure or AWS or on one of the prominent cloud platforms', 'Work with data team to efficiently use Hadoop/Cloud infrastructure to analyze data, build models, and generate reports/visualizations', 'Integrate massive datasets from multiple data sources for data modelling', 'Implement methods for automation of all parts of the predictive pipeline to minimize labor in development and production', 'Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management', 'Knowledge in machine learning algorithms especially in recommender systems', 'Extracting, Loading, Transforming, cleaning, and validating data', 'Designing pipelines and architectures for data processing', 'Creating and maintaining machine learning and statistical models', 'Querying datasets, visualizing query results and creating reports', 'Minimum 3 year of designing, building and operationalizing large-scale enterprise data solutions and applications using one or more of GCP data and analytics services in combination with 3rd parties - Spark, Cloud DataProc, Cloud Dataflow, Apache Beam, BigTable, Cloud BigQuery, Cloud PubSub, Cloud Functions, etc.', 'Minimum 1 year of hands-on experience analyzing, re-architecting and re-platforming on-premise data warehouses to data platforms on cloud using 3rd party services', 'Minimum 1 year of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java, Python, Scala etc.', 'Minimum 1 year of designing and implementing data engineering, ingestion and curation functions on cloud using native or custom programming', 'Minimum 1 year of experience in performing detail assessments of current state data platforms and creating an appropriate transition path to cloud', 'Hands-on Cloud experience with a minimum of 1 solution designed and implemented at production scale', ""Bachelor's degree or equivalent (minimum 12 years) work experience. If Associate Degree, must have minimum 6 years work experience"", 'Minimum 1 year of architecting and implementing next generation data and analytics platforms on GCP cloud', 'Minimum 1 year of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders', '1 year of hands-on experience designing and implementing data ingestion solutions on GCP using GCP native services or with 3rd parties such as Talend, Informatica', '1 year of hands-on experience architecting and designing data lakes on GCP cloud serving analytics and BI application integrations', 'Minimum 1 year of experience in designing and optimizing data models on GCP cloud using GCP data stores such as BigQuery, BigTable', 'Minimum 1 year of experience integrating GCP or 3rd party KMS, HSM with GCP data services for building secure data solutions', 'Minimum 1 year of experience introducing and operationalizing self-service data preparation tools (e.g. Trifacta, Paxata) on GCP', 'Minimum 1 year of architecting and operating large production Hadoop/NoSQL clusters on premise or using Cloud services', 'Minimum 1 year of architecting and implementing metadata management on GCP', 'Architecting and implementing data governance and security for data platforms on GCP', 'Designing operations architecture and conducting performance engineering for large scale data lakes a production environment', 'Craft and lead client design workshops and provide tradeoffs and recommendations towards building solutions', '2+ years of experience writing complex SQL queries, stored procedures, etc', 'Google Cloud Platform certification is a plus', 'Excellent communication (written and oral) and interpersonal skills', 'Proven ability to work creatively and analytically in a problem-solving environment', 'GC holder/Citizens only', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', ""Bachelor's (Preferred)"", 'Google Cloud Platform: 1 year (Required)', 'Google Cloud Certification (Required)', 'Fully Remote', 'A “Fair Chance” job (you or the employer follow Fair Chance hiring practices when performing background checks)', 'Waiting period may apply', 'Only full-time employees eligible', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:03:02
Data Engineer,GSK,"4.2 out of 5 from 4,430 employee ratings","Collegeville, PA 19426","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with data teams to implement pipeline designs to support R&D strategy and conceptual data flows', 'Partner with the metadata leads to translate conceptual data models into physical database/tables optimized for data analytics in RDIP using established environments and tools', 'Assist the design, build, test and maintenance of data acquisition and processing pipelines including but not limited to the creation/maintenance of appropriate artifacts', 'Ensure the preservation of data integrity from source to target state including but not limited to the acquisition of appropriate metadata and the incorporation of appropriate QC checks into the pipelines', 'Support the use and growth of the Data Engineering DataOps environment, influence strategy and roadmap for the curation toolset, work with R&D and Tech to prioritize enhancements', 'Provide Tier 3 support for production pipelines', 'Support DCS and broader R&D in self-service/exploratory efforts', 'Influence vendor roadmaps, work with R&D and Tech to prioritize DataOps enhancements, and onboard these tools or enhancements', 'Ensure the quality consistency and availability of guidance documentation of end users of the tools to support high quality outputs', 'Extend current pipelines to support clinical biomarkers', 'Assess GxP readiness as it related to the upstream data pipelines and develop a plan for addressing any gaps', 'Provide Tier 3 support/administration of DNA Nexus bioinformatics system', 'This position requires a Computer Science, Bioinformatics, or related degree; 5+ years’ experience in data movement, data wrangling and delivery of data or analytics pipelines', 'Experience implementing and maintaining, data or analytic pipelines.', 'Experience with Big Data technologies, Cloud-based offerings (Microsoft Azure, GCP, AWS, etc), and corresponding tools.', 'Experience with open source software, bioinformatics tools and languages such as SQL, R, Perl, Python, Java, and ETL tools.', 'Experience with data movement and management in the Pharmaceutical industry or related scientific fields.', 'Experience with the core components of the Hadoop stack including HDFS and Apache Spark, ideally a Cloudera based stack', 'Background and experience in LIMS systems, Next Generation Sequencing (NGS) workflows, Cloud computing and HPC systems.', 'Understanding of diverse ‘omic data types including RNA-Seq, DNA-Seq, Chip-Seq, WES, WGS, ATAC-seq, microbiome, proteomic, metabolomic data etc. from different sources.', 'Familiarity with data mining, machine learning and artificial intelligence techniques', 'Proven ability to contribute to development projects.', 'Strong interpersonal skills and effective communication of complex concepts to stake holders with wide range of expertise.', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.', 'Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.', 'Continuously looking for opportunities to learn, build skills and share learning.', 'Sustaining energy and well-being.', 'Building strong relationships and collaboration, honest and open conversations.', 'Budgeting and cost-consciousness', 'LI-GSK']",2020-12-30 22:03:02
Data Engineer/Data Scientist,Crossmedia,4.3 out of 5 from 10 employee ratings,"New York, NY 10001","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help set the vision of the Rebox data science and engineering team, grow our capabilities, and build innovative new data products.', 'Find new and innovative ways to apply data to marketing and media decision making.', 'Be a subject matter expert for clients and coworkers within Crossmedia. Have a strong point of view on data science and engineering topics that you are happy to share.', 'Build, utilize, and support tools that enable us to become even more data-driven than we already are.', 'Drive quality into our data pipeline and ultimately data, be it through good standards, in-depth and helpful reviews, data validation methods, anomaly detection and alerting, multivariate experiments with proper control groups, partnering with engineering on data storage and logging, well-thought out ETL, and clearly and succinctly documenting where and how 3rd party data becomes our clean, gold-standard set.', 'Explore data from all sides of the business and drive insights through modeling (Marketing attribution models, churn prediction, account health)', 'Facilitate decisions on standard, frameworks & tools, build vs use, and best practices. We try and keep our data and tools simple, clean, readable, and consistent to maximize our time.', 'Learn, teach, & share. With your fellow teammates and the world (blogs, open source, etc). It’s good for you, good for Crossmedia, and good for the world.', 'A champion of quality, ensuring accuracy and reliability of data.', '3-5 years of experience', 'A problem solver, not afraid to dive into a problem to understand root-causes.', 'Communicative & empathetic. You are happy when helping others succeed.', 'A confident communicator and someone who is able to manage client calls', 'Constantly looking to learn and improve how you work.', 'Very high standards but practical, you know that perfect is the enemy of good.', '3- 5 years of experience in a data science, data engineering, or software engineering role.', 'Domain Knowledge of Media Agencies and Marketing', 'Experience with some of our tools: SQL, DBT, Python, Snowflake, AWS, R, Shiny', 'Experience with statistics, modeling, data visualizations', 'Help set the vision of the Redbox data science and engineering team, grow our capabilities, and build innovative new data products.', 'Find new and innovative ways to apply data to marketing and media decision making.', 'Be a subject matter expert for clients and coworkers within Crossmedia. Have a strong point of view on data science and engineering topics that you are happy to share.', 'Build, utilize, and support tools that enable us to become even more data-driven than we already are.', 'Drive quality into our data pipeline and ultimately data, be it through good standards, in-depth and helpful reviews, data validation methods, anomaly detection and alerting, multivariate experiments with proper control groups, partnering with engineering on data storage and logging, well-thought out ETL, and clearly and succinctly documenting where and how 3rd party data becomes our clean, gold-standard set.', 'Explore data from all sides of the business and drive insights through modeling (Marketing attribution models, churn prediction, account health)', 'Facilitate decisions on standards, frameworks & tools, build vs use, and best practices. We try and keep our data and tools simple, clean, readable, and consistent to maximize our time.', 'Learn, teach, & share. With your fellow teammates and the world (blogs, open source, etc). It’s good for you, good for Crossmedia, and good for the world.', 'A champion of quality, ensuring accuracy and reliability of data.', 'A problem solver, not afraid to dive into a problem to understand root-causes.', 'Communicative & empathetic. You are happy when helping others succeed.', 'A confident communicator and someone who is able to manage client calls', 'Constantly looking to learn and improve how you work.', 'Very high standards but practical, you know that perfect is the enemy of good.', 'Several years of experience in a data science, data engineering, or software engineering role.', 'Domain Knowledge of Media Agencies and Marketing', 'Experience with some of our tools: SQL, DBT, Python, Snowflake, AWS, R, Shiny', 'Experience with statistics, modeling, data visualizations']",2020-12-30 22:03:02
Data Engineer / Analytics engineer,Systechcorp Inc,N/A,"Charlotte, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)R & Python: 4 years (Preferred)"", 'Health insurance', '8 hour shift', 'Day shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Data Engineer: 6 years (Preferred)', 'Capital Market & Finance: 4 years (Preferred)', 'R & Python: 4 years (Preferred)', '5 - 6 months', 'One location', 'Temporarily due to COVID-19']",2020-12-30 22:03:02
Oops! That page can’t be found.,Systechcorp Inc,N/A,"Charlotte, NC","['Indeed Jobs', '404', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Facebook', 'Twitter', 'instagram', 'Youtube', 'Soundcloud']",2020-12-30 22:03:02
Data Engineer,LOCKHEED MARTIN CORPORATION,"4 out of 5 from 8,473 employee ratings","Sunnyvale, CA 94089","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work across the Space Data Governance team and SAP team leadership to recommend and develop data strategies to align vision and strategy roadmaps', 'Work with Space data and SAP teams as well as the corporate Data Analytics COE to support data mining and analysis of best practices', 'Collaborate with internal customers (functional/subject matter experts and/or end users) across various business units to build knowledge regarding their specific business area, unique processes, and operational data needed to support business objectives', 'Provide input to business cases and drive business value into existing processes by defining and delivering data driven process improvements', 'Minimum 8-10 years of related experience within a corporate environment required; experience must include successful track record with data modeling, ETL processing, data architecture, understanding of reporting platforms, and machine learning and predictive analytic solutions', 'Experience leading practices and SAP S/4 solution capabilities for the in-scope business analytics, including finance, procurement, supply chain management, manufacturing, quality management, logistics and order to cash', 'Strong experience working with HANA studio, HANA calculation views/ CDS and BOBJ (WEBI, Lumira) Demonstrated success working in cross-functional teams with both business and technical resources', 'Ability to adapt to change quickly (high flexibility)', 'Excellent written and oral communication skills', 'Experience using Tableau, Brainspace, or other data visualization tools', ""Bachelor's degree in Information Technology, Data Engineering, Data Science or a related field, required"", 'Broad experience and expertise working with various technologies such as Python, SQL, R, SAS, Apache Spark, Google AI, TensorFlow, and other frameworks and libraries for AI', 'Knowledge of information access and delivery methods, analytics applications and tool portfolio, data sourcing and integration methods such as OLAP / ROLAP / HOLAP and an understanding of data warehousing/mining, ETL, EII, data cleansing, and architecture']",2020-12-30 22:03:02
Data Engineer - Need only on W2,Simplex Info,N/A,"Springfield, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience: Cloudformation, 2 years (Required)Hadoop/Spark , 1 year (Required)AWS Cloud (Athena, Redshift, EMR preferred), 3 years (Required)SQL, 1 year (Required)Python, 3 years (Required)Any data science background, 3 years (Required)', '8 hour shift', 'Monday to Friday', 'Cloudformation: 2 years (Required)', 'Hadoop/Spark : 1 year (Required)', 'AWS Cloud (Athena, Redshift, EMR preferred): 3 years (Required)', 'SQL: 1 year (Required)', 'Python: 3 years (Required)', 'Any data science background: 3 years (Required)', 'One location', 'Temporarily due to COVID-19']",2020-12-30 22:03:02
"Customer Engineer, Data & AI Solutions",Microsoft,"4.2 out of 5 from 7,020 employee ratings",United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Demonstrates expertise in a specific solution, or several products, feature functions, or services.', 'Participate in proactive account management, spot performance issues, analyze problems, develop solutions to meet customer needs, represent them.', 'Deliver effective service by analyzing trends and common themes across customers.', 'Create deliverables to address common customer needs & support mobile-first, cloud-first strategy, share intellectual property with others.', 'Gather customer feedback on products and services.', 'Model personal accountability and teamwork.', 'Seek opportunities to drive business growth by collaborating with multiple team members.', 'Partner with stakeholders to provide and drive actionable feedback cross broader Customer Success Unit (CSU), Product and Engineering team and Microsoft Services.', 'Reuse and update existing intellectual property (IP) or, where applicable, create new content.', 'Seek opportunities to drive business growth by understanding customer and partner requirements then mapping the adoption and optimization of Microsoft technology solutions accordingly.', 'Drive and Support innovation by focusing on industry solutions and customer business outcomes on the Microsoft platform.', 'Share knowledge through communities.', 'Intentionally cultivate relationships, credibility, and loyalty with customers and partners.', 'At least 4 years of experience with any of the following: Advanced Analytics - Azure SQL DB, Cloud native Apps with CosmosDB, PostgreSQL, AI (Cognitive Services with focus on Azure Search), ML (Azure Machine Learning, Databricks); Business Intelligence – Azure Synapse, DW migration from Teradata and Netezza; Database administration (preferably with SQL, including Azure SQL) – SQL migration (IaaS and PaaS), MySQL Migration, Oracle RDBMS to PostgreSQL Migration or related', 'At least 4 years of experience working with Enterprise customers in any of the following: providing customer technical readiness, delivery support services, on premise and remote technical support, solution development, account management; technical requirements gathering; broad evangelism through events (presentation skills) or related.', 'At least 5 years of experience in software support, secure infrastructure, IT consulting, or related.', 'Proven track record in successful consultative/complex technical and deployment projects, architecture, design, implementation, and/or support of highly distributed applications.', 'Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solutions/projects.', 'Broad business acumen, across various industries, to enable relevant discussions with business decision makers.', 'Experience utilizing cloud technologies to resolve in-depth customer issues, across organizational / regional boundaries.', 'Exceptional verbal and written communication skills to orchestrate, lead, and influence virtual teams and ensure successful implementation of customer projects.', 'Professional presentation skills experienced with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist).', 'International experience and ability to communicate in multiple languages is preferred.', 'Prior work experience in a Customer Engineer/Consulting/Architecture position within an IT Solution Provider and/or services company such as Amazon, VMware, Google, IBM, Oracle is preferred.', 'Advanced Analytics – Modernize apps with Azure SQL DB, Cloud native Apps with CosmosDB, PostgreSQL, AI (Cognitive Services with focus on Azure Search), ML (Azure Machine Learning, Databricks). Experience designing and building solutions using technologies such as Azure Synapse, Azure Data Factory, Azure Data Lake, HD Insights, SQL DWH, stream analytics, machine learning, R server highly valued.', 'Business Intelligence – Azure Synapse, DW migration from Teradata and Netezza. Knowledge of SSIS/SSRS/Power BI technologies with a deep understanding of data structure / data models to design, develop, and tune BI solutions and reports preferred.', 'Database administration (preferably with SQL, including Azure SQL) – SQL migration (IaaS and PaaS), MySQL Migration, Oracle RDBMS to PostgreSQL Migration, with additional experience with performance tuning, trouble-shooting, high availability / disaster recovery, security (mandatory), migrations (on-prem to cloud, oracle to SQL and etc..) desired.', ""Bachelor's degree in Computer Science, Information Technology, Engineering, or related field is preferred.""]",2020-12-30 22:03:02
Data Cloud Engineer,"C2 Technology Solutions, Inc.",N/A,"Columbia, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Five (5) years experience with Linux and Windows system administration', 'Two (2) years experience with Python or two other scripting languages', 'Two (2) years experience configuring system monitoring tools', 'Two (2) years experience standing up new Linux servers', 'Experience with Cloud architectures (AWS, Azure), automation, microservices architectures, k8s', 'API Front end development experience', 'Experience with Elasticsearch and object storage']",2020-12-30 22:03:02
Associate Support Engineer,SAP,"4.3 out of 5 from 2,496 employee ratings","Newtown Square, PA 19073","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participate in initial training program (bootcamp) to learn targeted SAP technologies and methodologies.', 'Ability to manage multiple tasks, work in a team environment, understand and be responsive to project and customer needs.', 'Ability to adapt and function effectively in a fast-paced, changing environment while working under deadlines.', 'A record of taking initiative (self-starter), driving results and accepting increasing levels of responsibility.', 'Must be able to problem solver, learn quickly and apply knowledge effectively', 'Recent graduate of an accredited university with a Bachelor’s or Master’s degree in: Computer Science, Engineering, Information Systems, or similar degree.', 'Strong preference for completion of SAP course work at an SAP University Alliance School.', 'Must be able to work as a team player yet have the ability to work independently.', 'Analytical, results-driven and have a solution-oriented approach.', 'Possess exceptional interpersonal and communication skills including verbal, written presentation and listening.', 'Must be open to travel.', 'Must be willing to relocate to Newtown Square, PA', 'Development experience in one or more programming/scripting languages like Java, ABAP, C/C++, C#, ASP, .NET, and PHP. 3+ university courses or class project experience in C++ or JAVA preferred.', 'Technical skills in SQL, Database (SQL) knowledge, database management, business intelligence, enterprise performance management, data mining, systems administration.', '6 months to 2 years of relevant work experience in a corporate environment through internships or recent work experience is a plus']",2020-12-30 22:03:02
Data Engineer,Apex Global Solutions,2.5 out of 5 from 6 employee ratings,"Suffern, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Multiple locations', 'No: Not providing sponsorship for this job', 'ApexGlobalUs.Com', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-12-30 22:03:02
Data Engineer,Inspire,3.4 out of 5 from 39 employee ratings,"Philadelphia, PA 19103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data querying and processing in SQL', 'Data processing and task management in Python', 'Communication skills, and ability to translate between the domains of business problems and technical implementations', 'Team-oriented development: building modular & re-usable tools, writing maintainable code, owning technical and business documentation', 'Refactor operating model code into scalable, transparent processes leveraging Airflow and DBT as core frameworks', ""Expand the capabilities of Inspire's core data platform to support incremental product lines and product features"", 'Partner with Analytics to systematize and scale high-integrity value-oriented analysis', 'Partner with Sales, Operations, and other business stakeholders to design and deliver new data-driven integrations', 'Partner with other engineering teams to guide refactors of existing data infrastructure to improve data quality and features.', ""Cultivated familiarity with Inspire's frameworks & operating model"", 'Delivery of high-quality pull requests in DBT and Airflow, evidencing strong code standards & testing practices', 'Comfort with self-directed project management: requires minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.', 'Positive interactions with department stakeholders: can offer guidance and input that creates business value for non-technical personnel.', 'Technical competency - comfort on a command line, a good grasp on the fundamentals of programming, a general understanding of Git/source control, and a willingness to read the docs, search stack overflow, and test it until it works', ""Problem-Solving Mentality - gets excited about digging into complexity, wants to ask questions and learn more, and isn't put off by problems they've never been explicitly told how to solve. Especially troubleshooting: ability to break down a chain of steps to narrow and locate a problem."", 'Number Sense - Strong background in mathematics or physics, comfort with quantitative measurement and estimation. Ability to work in establishing boundaries and orders-of-magnitude to make informed judgements without fussing over exactitude.', 'Big-picture awareness - Understanding of the importance of context, and willingness to understand the business problem in addition to the technical one. Focus on people & impact.', 'Must Have1 or more years in a data analytics, engineering or science roleStrong SQL experience working with large datasets, ideally in cloud-based data warehousesSoftware development in Python3Experience automating data processing, cleaning and/or preparationSoftware development lifecycle familiarity in GitHub (ie environment management, testing, deployment)', 'Nice to HaveExperience with key frameworks: Snowflake, Apache Airflow, dbt, AWS services, Docker, KubernetesExperience at a similar scale of data processing (Multi-TB/billions of rows)Work with real-time event stream dataContextual work in the energy industryData consultancy experience a plusProven ability to break down a chain of steps to narrow and locate a problemStrategic approach to problem solving and understand the why behind a problem']",2020-12-30 22:04:45
Big Data Engineer / Modeler,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Jersey City, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Engage with business stakeholders to understand required capabilities, converting business ask into scalable data analytics solutions', 'Design and develop logical & Physical data models for the AWM data platforms, comprising relational & non-relational platforms', 'Ability to quickly comprehend the functions and capabilities of existing, new and emerging solutions that enable and drive new business designs and models', 'Develop and maintain standards, and guidelines to ensure that a consistent data solutions framework is applied across the platform', 'Work with Application development teams to implement data strategies, build data flows and data models', 'Support multiple teams with planning, scoping and creation of the solutions for the new product capabilities, through to continuous delivery to production', 'Document data models and maintain related metadata repositories', 'BS/BA degree or equivalent experience', 'Advanced knowledge of application, data, and infrastructure architecture disciplines', 'Understanding of architecture and design across all systems', 'Working proficiency in developmental toolsets', 'Knowledge of industry-wide technology trends and best practices', 'Ability to work in large, collaborative teams to achieve organizational goals', 'Passionate about building an innovative culture', 'Proficiency in one or more modern programming languages', 'Understanding of software skills such as business analysis, development, maintenance, and software improvement', 'Demonstrated experience as an Analytics / Reporting modeler', 'Experience with modeling for Hadoop, RedShift, GreenPlum or similar platforms', 'Strong SQL skills and hands on experience with JSON', 'Experience with migrations from relational to big data implementations', 'Work experience in Financial Services industry and knowledge of Financial Instruments and trade life cycles', 'Knowledge of architectural design frameworks, integration frameworks, and patterns', 'Experience with Metadata Management Tools (Collibra preferred)']",2020-12-30 22:04:45
Data Engineer,BankMobile,3.4 out of 5 from 7 employee ratings,"Radnor, PA 19087","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Cloud data pipelines are developed and supported in an efficient fashion to ensure large, complex data sets are effectively maintained and continuously augmented', 'Manual processes around data delivery are identified so that automation can be designed and implemented for greater scalability and organizational efficiency', 'Infrastructure is configured for optimal extraction, transform and loading of data from a wide variety of external sources', 'Cloud-based analytics tools will make extensive use of our highly reliable data infrastructure to provide actionable insights into customer acquisition, product performance, fraud detection and other key business performance metrics', 'Knowledge sharing is performed across all technology teams to increase business alignment, quality and efficiency', 'Partners are satisfied with our level of professionalism and technical expertise', 'This is a hands-on systems engineering role that focuses on building and deploying data pipelines within our Azure environment with the express purpose of organizing our complex data effectively while ensuring data integrity and security', 'Develop and maintain ETL workflows for both SQL Server and Azure Data Explorer systems while exhibiting leadership around integrating other potential technology solutions', 'Partner with the Data Architect to meet the functional needs of business operations, business product management, and disparate technical teams by delivering best-in-class data solutions', 'Collaborate with business units to help define our data analytics strategy with the goal of building and driving adoption of a new unified business intelligence platform', 'Continuously monitor our business for new opportunities to automate inefficient internal processes around data acquisition and availability', 'Identify, assess, track and mitigate issues and risks at multiple levels within the organization', 'Foster teamwork, communication, collaboration while managing competing priorities', 'Must have 5+ years of experience building and optimizing big data data pipelines, architectures and data sets within a cloud computing environment', 'Must have advanced working SQL knowledge and experience working with both relational databases in a query authoring capacity as well as big data technologies such as No SQL and unstructured data store', 'Must have expertise in DataOps techniques and modern cloud computing technologies, most importantly deep familiarity with the Azure stack', 'Must have previously built processes supporting data transformation, data structures, metadata, dependency and workload management', 'Previous work experience partnering with data analytics teams to increase the effectiveness of internal business intelligence systems preferred', 'Comfortable working with Python 3.x', 'Strong attention to detail including precise and effective customer communications and proven ability to manage multiple, competing priorities simultaneously', 'Superior verbal and written communications skills and history of excellent team collaboration', 'B.S. in Computer Science, Statistics, Informatics, Information Systems or other quantitative field']",2020-12-30 22:04:45
Software and Data Engineer Intern,ViaSat,3.8 out of 5 from 270 employee ratings,"Germantown, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data analytics & cloud application engineering', 'System infrastructure development; scripting, automation, data visualization & dashboarding', 'Network function virtualization, orchestration', 'Virtualized networking and service chaining', 'Distributed enterprise software applications', 'Cybersecurity software & systems engineering', 'Web & mobile application engineering', ""Bachelor's degree in Computer Science, Computer Engineering, Electrical Engineering, Physics, Mathematics, and/or a related field"", 'Exposure or desire to work with Cloud Technology, Automation, Machine Learning, Big Data, Full-Stack, Embedded, Apps, or Front-End', 'Previous internship experience in software development and/or test related areas', 'Knowledge of TCP/IP network fundamentals', 'Previous experience coding in Go, Java, Python, JavaScript, Hadoop, Spark, SQL, Postrgres, and/or C/C++']",2020-12-30 22:04:45
Data Engineer,"Amplify Education, Inc.",4.1 out of 5 from 8 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Impress the toughest customers around – students – by:helping teams create fun, compelling apps by leveraging millions of data points', 'Make life better for passionate teachers by:helping teachers understand their students by building reusable data pipelines', 'Make life better for passionate, Marketing and Sales teams by:using REST APIs for sourcing/sending data to SaaS like Salesforce and HubSpot', 'Help school administrators build great schools by:respecting privacy and ensuring security while offering useful insights by making smart choices in tech stack, database design, and encryptionhelping school principals understand how teachers are teaching and how students are learning by architecting data warehouse schemas and SQL transforms with just the right CTEs, window functions, and pivotsanalyzing performance and squashing tricky bugs using tools like Snowflake, Matillion, SQL, Python, Looker, and Datadog', 'Learn every day by:immersing oneself in agile rituals and leveraging our infrastructureleading collaboration, pull request-ing, and mentoring on a cross-functional teamparticipating in cross-team share-outs, brownbags, and workshop seriesbecoming an expert in the data models and standards within Amplify and the educational industry in order to deliver quality and consistent solutions', 'Building well-tested and optimized ETL data pipelines for both full and delta extraction', 'Collaborating with data scientists to store, aggregate, and calculate captured students’ work', 'Contributing to leading industry data standards, such as Caliper Analytics or xAPI', 'Improving our deployment and testing automation data pipelines', 'BS in Computer Science, Data Science, or equivalent', '2+ years of professional software development or data engineering experience', 'Strong CS and data engineering fundamentals', 'Proven fluency in SQL and a development language such as Python', 'Understanding of ETL/ELT pipelines and Data Warehousing design, tooling, and support', 'Understanding of different data formatting (JSON, CSV, XML) and data storage techniques (3NF, EAV Model, Star Schema, Data Lake)', 'Strong communication skills in writing, conversation, and maybe silly gifs', 'Experience with tools we use every day:', 'Storage: Snowflake, AWS Storage Services (S3, RDS, Glacier, DynamoDB)ETL/BI: Matillion, LookerCloud Infrastructure: AWS Kinesis, Lambda, API Gateway, Terraform', 'Experience with tools we don’t use', 'Proven passion and talent for teaching fellow engineers and non-engineers', 'Proven passion for building and learning: open source contributions, pet projects, self-education, Stack Overflow', 'Experience in education or ed-tech']",2020-12-30 22:04:45
Data Engineer,Oshkosh Corporation,3.8 out of 5 from 141 employee ratings,"Hagerstown, MD 21740","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Create and maintain optimal data pipeline architecture: A scalable ETL solution that delivers data from source systems (telematics devices & APIs) to analytics platforms', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs', 'Collaborate, coordinate, and communicate across disciplines, departments, and segments', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Responsible for testing and validation to support the accuracy of data transformations', 'Work with data and analytics experts to strive for greater functionality in our data systems', 'Create and update data pipeline documentation for the purposes of architectural governance and support', 'Assist in educating others on best practices surrounding data work (i.e. data modeling, database design, ETL design, job scheduling and monitoring, etc.)', '2-5 years of experience in a Data Engineering role', 'Bachelor’s degree (minimum) in Computer Science, Statistics, Informatics, Mathematics, Information Systems, or another quantitative field', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Strong analytic skills related to working with structured and unstructured datasets', 'Build processes supporting data transformation, data structures, metadata, dependency, and workload management', 'A successful history of manipulating, processing, and extracting value from large disconnected datasets', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Experience with big data tools: Hadoop, Spark, Kafka, etc', 'Experience with relational SQL and NoSQL databases', 'Experience with data pipeline and workflow management tools: Oozie, Airflow, etc', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc', '2-5 years of experience in a Data Engineering role', 'Bachelor’s degree (minimum) in Computer Science, Statistics, Informatics, Mathematics, Information Systems, or another quantitative field']",2020-12-30 22:04:45
Data Engineer,IDC,N/A,"Redmond, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Power BI, 2 years (Preferred)Elasticsearch, 2 years (Preferred)C# / SQL, 2 years (Preferred)data engineer , 4 years (Preferred)', 'Power BI: 2 years (Preferred)', 'Elasticsearch: 2 years (Preferred)', 'C# / SQL: 2 years (Preferred)', 'data engineer : 4 years (Preferred)']",2020-12-30 22:04:45
Data Center Operations Engineer,Equinix,3.8 out of 5 from 259 employee ratings,"Secaucus, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Structured cabling of power, copper, and fiber network connections', 'Configure and test all hardware for deployment to local and remote sites', 'Prepare pallets and supporting documentation (including waybill and export paperwork) for international shipment', 'Work with our data center providers and internal engineering teams to optimize for creating as quick and efficient of a turn-up process as possible; maintain a positive overall relationship with our global vendors. Ideally this would also include a basic proficiency in coding/scripting to develop tools to help with our daily workflow', 'Work with our network and systems engineering teams around turning up new data center locations and incremental rack-level infrastructure, as well as troubleshooting physical server hardware and network devices', 'Ability to lift IT equipment, some of which may exceed (40) lbs per unit', 'Data center, Computer Science, or Information Technology education or background required. We are looking for an individual with basic subject-matter experience, though we will provide extensive training around the Equinix Metal hardware platform and specific areas of responsibility', 'Linux systems administration and scripting experience is a plus', 'Optical network troubleshooting (e.g. use of a light meter and OTDR/OSA) and termination experience is a plus', 'Familiarity with data center industry, and interacting with remote site technicians, is a plus', ""We are hiring for a full-time (40 hours) position, with an ability to work nights and weekends as required. We will work with the candidate to build an optimal schedule based on his/her working preferences, as well as Equinix Metal's needs to maximize around 24x7 global coverage."", 'Demonstrate humility', 'Possess endless curiosity', 'Listening to understand', 'Open Your Heart, Open Your Mind', 'Put We Before Me', 'Speak Up, Step Up', 'Keep Your Promises', 'Be an Energy Supplier', 'Find a Better Way', 'Serve Others', 'Keep Growing']",2020-12-30 22:04:45
Data Engineer,Pie Insurance,N/A,"Denver, CO 80202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 3 years (Preferred)"", '3-5 years working in data as an engineer. Building data solutions for a company who uses data as a primary part of their business.', 'Experience in data warehouse and/or data analytics. Qualified candidates may also come from a strong database skill-set involved in analytics architecture.', 'Strong experience in writing complex SQL queries.', 'Strong experience in ETL/ELT platforms is strongly preferred.', 'Exposure to one major SQL RDBMS or analytics database. (Snowflake, Redshift, MySQL, Postgres, Oracle, SQL Server, etc.)', 'Big Data and Business Intelligence exposure would help in the success of this role.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Referral program', 'Relocation assistance', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'SQL: 3 years (Preferred)', 'One location', 'Pieinsurance.com', 'https://www.facebook.com/PieInsurance/', 'Yes']",2020-12-30 22:04:45
Data Cleansing Engineer,Cloud and Things Inc,5 out of 5 from 2 employee ratings,"Albany, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Quality Assessment', 'Data Cleansing Experience', 'Informatica Data Quality', 'PL/SQL', 'Oracle DB', 'Perform system data analysis and data documentation', 'Provide technical Subject Matter support in system data analysis', 'Assist team in defining data profile and data cleansing rules', 'Document To-Be Target Model data requirements for system based on business requirements', 'Collect and document data synchronization/bridging requirements between As-Is and To-Be systems', 'Assist team with data management, data quality assurance testing, data cleansing, and data mapping.', 'Minimum 2 years’ experience working on State Government Projects.', 'More than 5 years working on data conversion projects including tasks such as:', 'o Source system metadata analysis, documentation, and validation', 'o Source to Target system data mapping', 'o Data profiling and data cleansing rules', 'o To-Be system data requirements gathering, analysis, documentation, and validation', 'o Data synchronization and Bridging requirements gathering, analysis, documentation, and validation', 'o Data conversion quality assurance', 'Experience with Data Quality processes, approaches, measurement techniques and business cases for data profiling, data cleansing, standardization, match and merge functionality using Informatica Data Quality', 'Experience working in Human Service domain', 'Experience writing PL/SQL statements and queries against RDBMS such as Oracle.', '8 hour shift', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-12-30 22:04:45
Environmental Scientist/Engineer – Data Analytics,Integral Consulting Inc.,N/A,"Annapolis, MD 21401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with multidisciplinary teams (data managers, engineers, environmental scientists, toxicologists) to develop and implement data analysis plans to support environmental investigations', 'Lead data and statistical analysis tasks with minimal supervision, applying appropriate statistical methods and visualization techniques', 'Perform quality assurance reviews of technical analyses and results', 'Develop R Shiny web applications to present data to clients and stakeholders', 'Prepare technical reports summarizing analytical methods and results in a clear, concise manner', 'Track new technologies and trends in data analytics and statistics and their applications to the environmental industry', 'Train and mentor other data analysts.', 'Bachelor’s degree in an environmental field, including environmental science/engineering, computational biology, geochemistry, hydrogeology, ecology, toxicology, or related quantitative field with a strong interest in environmental applications; Master’s degree is a plus', 'Strong knowledge of environmental science and chemistry', '3+ years of demonstrated experience using R statistical programming language, including the use of one or more of the following packages: tidyverse (specifically, dplyr and/or ggplot2), plotly (R), and leaflet (R), or equivalent experience using Python, including the use of one or more of the following packages: NumPy, pandas, Matplotlib, plotly (Python), and folium', 'Proficiency with code versioning tools, such as Git', 'Experience using relational database management systems and SQL', 'Strong background in applied statistics', 'Ability to independently manage and perform multiple tasks with competing deadlines', 'Excellent interpersonal/teamwork skills', 'A desire to grow intellectually and professionally in the discipline of environmental data science.', '3+ years working as an environmental consultant in a data analyst role', 'Experience with or desire/aptitude to learn machine learning methods', 'Experience with development, deployment, and maintenance of R Shiny web applications', 'Experience using Markdown to create formatted documents', 'Experience with other visualization tools such as D3', 'Working knowledge of JavaScript, HTML, and GIS.']",2020-12-30 22:04:45
Data Engineer,Benefits Data Trust,3.2 out of 5 from 23 employee ratings,Pennsylvania,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build out our new GCP data platform and collaborate on architectural patterns for it with the Data Engineering team', 'Support the development of machine learning models with productionizing, monitoring and alerting tools', 'Write, update, and maintain ETL jobs across our data pipelines (mostly in Airflow)', 'Implement continuous improvements using our existing tools/technologies, which include SQL, Airflow, Python, Docker/Kubernetes, and others such as Terraform and Apache Beam. May also be expected to research and select other tools when the situation demands', 'Collaborate with internal customers to identify ongoing platform improvements (teams including Analytics, Projects, Policy, Software Engineering, and others throughout the organization)', ""Consult to software engineers on data-related changes to BDT's suite of software applications, including schema/model design, table structure, and data collection"", 'Engage with colleagues and collaborators using curiosity, critical thinking, a drive to completion, empathy, and a focus on impact', 'Follow existing data access and performance design standards for the data platform, software engineering, and all products and services accessing BDT information', 'Communication and Relationship-building – with technical peers and some stakeholders', 'Cloud-based Solution Implementation, of data platforms and infrastructure, including event-driven architectures, microservices and pattern design, supporting compliance and regulated environments (including PII and PHI)', 'Workflow and pipeline development to ensure reliability, availability, and consistency', 'Systems Engineering – on-system service management, typically in *nix environments', 'Data Modeling and Warehousing – proficient understanding of relational data structures and schemas; some familiarity with semi-structured, unstructured (big data) schemas', 'Automation, monitoring, and alerting – creating these tools based on existing designs and frameworks; resolving bugs and issues', 'Cloud engineering – working towards certification on any of the major hyperscale cloud platforms', 'Data Encapsulation & Transfer methodologies – understands standards for file formats and transfer methods', 'Also interested in relevant experience including:', 'o Experience with BI implementations/uplifts (we currently use Looker) and/or Data Governance models and methods', 'o Machine learning techniques, productionizing machine learning models, and/or creating models']",2020-12-30 22:04:45
Data Engineer,"Attain, Inc.",3.1 out of 5 from 51 employee ratings,"McLean, VA 22101","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)AWS Cloud: 3 years (Preferred)"", 'Passion Seekers. You genuinely care about the work that you do and its impact on society.', 'Self-Starters. You’re a go-getter who isn’t afraid to step up and disrupt the status quo.', 'Entrepreneurs. You bring fresh ideas to the table, work hard, develop business and consistently seek new challenges.', 'Collaborators. You’re a great contributor to a high performing team that accomplishes great feats for our clients.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Establish performance monitoring of databases and create data pipeline architecture', 'Manage data life cycle from transactions to reporting to archival of data', ""Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies"", 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', '5 years of proven expertise in relational and dimensional data modelling', '5 years in modern data development, upgrading, support and design.', 'Proven experience in leading data teams on data migration and transformation', 'Experience in establishing performance and statistical monitoring of enterprise databases to include, but not limited to; wellness checks, data integrity, privacy and security scans.', 'Experience in supporting cloud database environments, specifically AWS (i.e., EC2, S3, Neptune or Redshift) to include backup and archiving of data.', 'Good to have experience with data lakes implementations', 'Should be able to work early morning hours i.e. 6 am to 2 pm (US Eastern Time) for at least 2-3 days a week', 'Experience with Apache NiFi is desired', 'Experience with OpenText Captiva is desired.', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'AWS Cloud: 3 years (Preferred)', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'https://www.attain.com/about-attain', 'Yes']",2020-12-30 22:04:45
Jr. Data Engineer,Dash Technologies Inc,N/A,"Texas City, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture,', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Monday to Friday', 'Only full-time employees eligible']",2020-12-30 22:04:45
Data Engineer,PDI,N/A,"Dallas, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Onboard new customers' data into the PDI data warehouse and platform, writing and installing the required ETL’s"", 'Optimize and manage existing clients’ data pipelines', 'Monitor, maintain, and, if needed rectify, various clients’ data integrity', 'Develop and/or enhance automated processes to proactively identify any data related issues and/or simplify process', 'Gather technical requirements from multiple sources for new data-oriented features, integrating new solutions within a developed Java solution base', 'Participate as a key member of our agile development team', 'Collaborate with team members to automate queries as needed', ""Bachelor's degree in Math, Statistics, Computer Science or equivalent technical field."", 'Working and practical knowledge of programming principles, techniques, standards and analytical ability', 'Strong proficiency in Java', 'Proven experience with complex SQL query design and optimization', 'Experience with Bash scripting', 'Experience in data cleansing, curation, parsing, integration, semantic mapping, or editing', 'Experience with analytics systems (data warehouses, dimensional models, etc.)', 'Organizational skills and ability to balance multiple priorities in a dynamic and fast-paced environment', 'Strong team player with a passion for data and problem solving', 'Excellent oral and written communication skills', 'Degree in Computer Science, Computer Engineering, Management Information Systems or related field', '1-3 years of applied data engineering-related experience', 'Strong competence in Python', 'Experience with Google Cloud', 'Experience with Linux/Unix']",2020-12-30 22:04:45
Data Engineer,Autodesk,4.1 out of 5 from 472 employee ratings,"Denver, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Maintain/ develop a scalable database/ data warehouse through connecting disparate data housed across numerous organizational systems and different business lines', 'Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies', 'Optimize/ maintain workflows/ scripts on present data warehouses and present ETL', 'Maintain data sources and workflows/ data pipelines across different systems', 'Maintain different data/ analytics outlets including SFDC, Domo, Power BI, etc to ensure data delivery to team members and ad-hoc reporting requirements', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', ""Bachelor's degree computer science, information systems, applied mathematics or a related discipline"", '5+ years of experience', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience of manipulating, processing and extracting value from large disconnected datasets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'Experience with salesforce administration', 'Experience with BI tools such as Domo, Looker, PowerBI and/ or other tools', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Expertise in gathering data through multiple sources through API calls and scripting languages']",2020-12-30 22:06:25
Biological Researcher,Teva Pharmaceuticals,"3.7 out of 5 from 1,264 employee ratings","West Chester, PA 19380","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's degree in Cell Biology, Biotechnology, Biochemistry or related field of study – Master’s degree preferred."", 'Minimum 1 year of experience in cell culture, conducting cell based assays and ELISA.', 'Your ability to work in a team environment.']",2020-12-30 22:06:25
Data Engineer,"eClinical Solutions, LLC",2.5 out of 5 from 4 employee ratings,"Mansfield, MA 02048","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop, test and deploy highly efficient SQL code and data mapping code according to specifications', 'Design and develop ETL code in support of analytic software applications and related analysis projects', 'Work with Analytics developers, other team members and clients to review the business requirements and translate them into database objects', 'Research and utilize new technologies', 'Collaborate with the Quality Assurance team to test the applications functionality', 'Provide technical guidance, training and support to other team members', 'Ensure compliance with eClinical Solutions/industry quality standards, regulations, guidelines and procedures', 'Manage multiple timelines and deliverable (for single or multiple clients) and managing client communications as assigned', 'Provide programming solutions and support using elluminate Clinical Data Platform', 'Configuration, migration and support of the elluminate platform', 'Knowledge of clinical trial data is a plus - CDISC SDTM, or ADAM standards', 'Other duties as assigned', 'Basic Science/Bachelor of Science or Master of Science degree in Computer Science and/or equivalent work experience', 'Excellent knowledge of English', 'Minimum of 7 years in database design and development experience', 'Thorough experience in data warehouse architecture, design and development.', 'Thorough understanding of database design principles and best practices', 'Excellent experience in designing scalable, modular SQL code and ETL procedures using MS-SQL Server', 'Strong Software Development Lifecycle experience (Agile methodology experience is a plus)', 'Excellent understanding of relational database concepts, data modeling and design', 'Strong technical project management experience and team leadership skills including scope management, work planning and work delegation', 'Strong troubleshooting skills and use of defect/feature management systems', 'Proven ability to work independently and with technical team members (Startup environment experience is preferred', 'Experience in the Biotechnology, Pharmaceutical, or Life Sciences industries ( Clinical Research Organization - CRO or Clinical Trial regulated environment preferred)', 'Excellent verbal and written communication skills', '7+ years with SQL Server, ETL and Data Warehousing', '5+ years with ETL architecture and design', '5+ years with Data modeling (physical & logical)', 'Experience with Performance tuning and management of SQL Server', 'Experience with Dimensional modeling', 'Experience with any BI tools(e.g. Qlik, MicroStrategy, etc)', 'Knowledge of clinical trial data is a plus']",2020-12-30 22:06:25
Data Engineer,"AmTote International, Inc.",N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate and participate in the design and implementation of robust and scalable databases ensuring all systems meet the business/company requirements as well as industry practices', 'Document technology specifications and ensure any new technology solutions are optimal for meeting needs; leverage existing technologies when possible', 'Translate business requirements into data models that are easy to understand and used by different disciplines across the company', 'Work collaboratively with analysis and development teams to create standards and best practices for BI (Business Intelligence) and data science solutions', 'Partner with domain business experts, data analysts, and engineering teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enables self-service', 'Continually work to improve data reliability and quality and supports ongoing incorporation of new data sources', 'Develop quality framework to ensure delivery of high-quality data and analyses to stakeholders', 'Identifie, document, and promote best practices', 'Troubleshoot and solve production Database issues', 'Perform other duties as assigned', 'Bachelor’s degree in Computer Science, Software Engineering, Data Science or related field; or 7 years of related experience in lieu of degree.', '3+ years of experience in a technical role supporting BI and data science efforts. This should include application of knowledge in statistics, data wrangling, data visualization, and communication', '3+ years of experience in database development and tools. Ideally, this includes: ETL, data modeling, complex queries, performance tuning, and stored procedures/functions', '3+ years of programming experience using one or more of Python, Java or Scala, C#.net', '2+ years working with Cloud technologies related to Data Science.', 'Prior experience with using a typical set of tools for building data pipelines: streaming, ingestion, and processing pipelines', 'Contributed to a nascent data ecosystem and building a strong data foundation for the company', 'A proven track record of successfully delivering large data-centric projects', 'A broad, enterprise-wide view of the business with the understanding of the roles of strategy, processes, and capabilities, enabling technologies and governance', 'Strong skills in design and implementation of logical and physical approaches to managing and analyzing large volumes of data with knowledge of best practices', 'An understanding of Agile/Scrum development environment', 'Strong relationship management skills; able to interface effectively with all organizational levels: users, team members, and management', 'The ability to produce high-quality documentation of business and system requirements, system design, data architecture, and training materials', 'Experience with data visualization tools such as Periscope is a plus.', 'Experience managing multiple projects simultaneously with a team spanning various geographical locations and outsourcing', 'Experience in leading and/or collaborating with teams spanning multiple geographical locations and outsourcing', 'A openness to learn about and understand the ‘niche’ industry', 'Effective, consistent, and impeccable communication, interpersonal, leadership, organizational, people management, presentation, project management, teamwork, and training skills', 'Exhibited the behaviors of a self-starter, self-motivator, detail-oriented, and are a highly organized professional', 'Structured problem solving and expert prioritization skills', 'Demonstrated and maintained flexibility and can adapt to changes within industry and company', 'Master’s degree in Computer Science, Engineering or related field', 'Wagering/gaming industry experience', 'Knowledge of horse racing, pari-mutuel wagering, gaming, sports wagering and/or social marketplace industries', 'Compensation is commensurate with experience and includes a competitive base salary and benefits', 'Base Work Location – Position based in, Hunt Valley, MD with remote work consideration available.', 'Note: Due to pandemic and based on business direction, positions are remote work full time until otherwise notified.']",2020-12-30 22:06:25
Data Engineer,bp,"3.9 out of 5 from 4,015 employee ratings","Denver, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Health, vision and dental insurance', 'Spending accounts', 'Flexible working schedule', 'A paid time off policy that considers experience', 'Other time off programs to help with personal matters (sick leave, bereavement, etc.)', 'Disability coverage (short and long-term)', 'Discretionary annual bonus program', 'Long-term incentive program', 'Paid parental leave', 'Generous 401K matching program through our Employee Savings Plan', 'Group Universal Life', 'Occupational Accidental Death', 'Basic life/accidental death and dismemberment', 'bp Care (Employee Assistance Program)']",2020-12-30 22:06:25
Data Engineer,Panalgo,N/A,"Boston, MA 02110","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Provide custom coding and data manipulation for Data Integration team', 'Integrate new healthcare data sources into our state-of-the-art application', 'Build and optimizing pipelines for ETL processes', 'Build new features/tools to improve our big data and distributed computing infrastructure', 'Become a subject matter expert in the structure and contents of various healthcare databases', 'Run ETL scripts and perform quality control tasks', 'Maintain and ensure databases are delivered on-time to our customers', 'Configure our software platform to use data sets and ensure ETL instructions and documentation are up-to-date', 'Bachelor’s degree in Mathematics, Statistics, Computer Science, or other technical/quantitative degree', '1-3 years of related work experience', 'Proficient in object oriented and functional programming skills such as Java, C++, Ruby or Python', 'Skilled at analyzing data (SQL, Python, R)', 'Experience working in a Linux command line environment and scripting', 'Eager to learn new systems and technologies', 'Exceptional attention to detail and critical-thinking skills', 'Experience working with NoSQL databases (MongoDB. Cassandra, etc.)', 'Familiarity with distributed file systems', 'Apache Spark experience', 'Leading healthcare data analytics/big data company', 'Work on a team of talented and pragmatic engineers/researchers', 'Great mentorship and growth opportunities']",2020-12-30 22:06:25
Data Engineer,STRIVE HEALTH,4.5 out of 5 from 2 employee ratings,"Denver, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'have a working knowledge with structured and unstructured data', 'have an experience with processing HL7 messages, CCD documents, and EDI X12 Claims files.', 'have a familiarity with development methodologies, including the AGILE development approaches', 'are able to code and comprehend code around technologies that deal with acquiring data', 'have an experience working with Hadoop and other Big Data Technologies', 'have exposure to programming languages such as Python, C#, or Java', 'have 5+ years’ experience in healthcare/technology related field', 'have a working knowledge of database principles, processes, technologies and tools', 'have exposure to Extract, Transform and Load (ETL) concepts and processes', 'have experience working with EMR\\EHR systems and an understanding of the healthcare clinical domain', 'are an expert in Structured Query Language (SQL)']",2020-12-30 22:06:25
Data Engineer,Ryzen Solutions,N/A,"Cupertino, CA 95014","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""MySQL: 1 year (Required)Python: 1 year (Required)Spark: 1 year (Required)Bachelor's (Preferred)"", '401(k)', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'MySQL: 1 year (Required)', 'Python: 1 year (Required)', 'Spark: 1 year (Required)', 'airflow: 1 year (Required)', 'Yes', 'Temporarily due to COVID-19', 'Remote interview process', 'Plastic shield at work stations', 'Temperature screenings', 'Social distancing guidelines in place', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 22:06:25
Data Analyst - All Levels,FedEx Services,3.9 out of 5 from 93 employee ratings,"Pittsburgh, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Associate Data Analyst (Sponsorship is not available for this position)', 'Data Analyst (Sponsorship is not available for this position)', 'Sr. Data Analyst', 'Data Analyst Advisor', 'Data Science / Engineer expertise as a thought leader and practitioner', 'Experience analyzing large-scale structured and unstructured data using Scala, Python, R', 'Experience working in Big Data technologies like Hadoop, Spark, Hive, Kafka, etc., with understanding of best practices used throughout industry', 'Development experience within Cloud technologies like Microsoft Azure or Google Cloud Platform', 'Experience in mathematical modeling of large-scale, real-world optimization problems and design of algorithms that obtain implementable cost-efficient solutions', 'Experience using object-oriented programming languages such as Java and C++', 'Experience using CPLEX, Gurobi, or similar optimization modeling packages', 'Process improvement experience and training/application of quality management processes and principles, e.g. QDM expert, Six Sigma, and Lean', 'Experience in the transportation industry and understanding of evolving technology', 'Use of data visualization tools such as Power BI, Spotfire, Tableau to communicate results', 'Experimental design experience', ""Associate Data Analyst - Bachelor's degree in information systems, computer science, or a quantitative discipline such as mathematics, engineering, operations research, economics or Finance. Demonstrated knowledge gained through course work or work experience in measurement and analysis, quantitative business problem solving, operations analysis, marketing analysis, simulation development and/or predictive analytics. Proficient in analytics software and applications. Good Interpersonal skills. Good written and oral communication skills."", ""Data Analyst - Bachelor's degree in information systems, computer science, or a quantitative discipline such as mathematics, engineering, operations research, economics or Finance. Two (2) years work experience in measurement and analysis, quantitative business problem solving, operations analysis,marketing analysis, simulation development and/or predictive analytics. Proficient in analytics software and applications. Good interpersonal skills. Good written and oral communication skills."", ""Sr. Data Analyst - Bachelor's degree in information systems, computer science, or a quantitative discipline such as mathematics, engineering, operations research, economics or Finance. Five (5) years work experience in measurement and analysis,quantitative business problem solving, operations analysis,marketing analysis, simulation development and/or predictive analytics. Proficient in analytics software and applications. Good interpersonal skills. Good written and oral communication skills."", ""Data Analyst Advisor - Bachelor's degree in information systems, computer science, or a quantitative discipline such as mathematics, engineering, operations research, economics or finance. Seven (7) years equivalent work experience in measurement and analysis, quantitative business problem solving, operations analysis, marketing analysis, simulation development and/or predictive analytics. Superior analytical skills with diverse analytics and statistical software and applications. Excellent interpersonal skills, written and oral communication Skills. Proven leadership skills."", 'The position(s) can be domiciled anywhere in the United States', 'Remote work is available', 'Relocation assistance may be available based on business need.']",2020-12-30 22:06:25
"Data Engineer (GCP, SQL & Python must )","Conquest Tech Solutions, Inc",N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'GCP: 1 year (Preferred)', 'GCP: 1 year (Preferred)']",2020-12-30 22:06:25
Data Engineer,Optimize.Health,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, construct, install, test, and maintain our growing data platform.', 'Ensure that all systems meet the business/company requirements as well as industry practices.', 'Integrate up-and-coming data management and software engineering technologies into existing data structures.', 'Develop set processes for data procurement, mining, modeling and data visualization tools.', 'Research new uses for existing data.', 'Employ an array of technological languages and tools to connect systems', 'Recommend different ways to constantly improve data reliability and quality.', 'Collaborate with our team to build the best RPM system in the industry', 'Bachelors degree in computer science or similar field OR equivalent work experience in place of a degree', '4+ years of experience in a data engineering role, working with large datasets', 'Demonstrated experience with scripting and coding as it pertains to data engineering (Python, etc.) and SQL', 'Ability to communicate and establish best practices regarding data management', 'Experience working in data cloud-based environments including Tableau, Snowflake, Azure SQL, AWS RDS', 'Demonstrable experience in data modeling, ETL development, and data warehousing, or similar skills. Nice to have streaming and any contemporary AI/ML languages.', ""A generous cash compensation package (money isn't everything, but it helps!)"", 'Stock Options', '100% employer paid health, dental, and vision premiums for our employees', '$3,000 yearly HSA contribution', 'Work-From-Home stipend to set up an office that works for you!', 'Culture that fosters inclusion, collaboration, and growth']",2020-12-30 22:06:25
"Data Engineer, Analytics",Facebook,4.2 out of 5 from 602 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Inform, influence, support, and execute our product decisions and product launches', 'Manage data warehouse plans for a product or a group of products.', 'Interface with engineers, product managers and product analysts to understand data needs.', 'Partner with Product and Engineering teams to solve problems and identify trends and opportunities.', 'Build data expertise and own data quality for allocated areas of ownership.', 'Design, build and launch new data extraction, transformation and loading processes in production.', 'Support existing processes running in production.', 'Define and manage SLA for all data sets in allocated areas of ownership.', 'Work with data infrastructure to triage infra issues and drive to resolution.', 'BS/BA in Technical Field, Computer Science or Mathematics.', '4+ years experience in the data warehouse space.', '4+ years experience in custom ETL design, implementation and maintenance.', '4+ years experience working with either a Map Reduce or an MPP system.', '4+ years experience with schema design and dimensional data modeling.', '4+ years experience in writing SQL statements.', 'Ability to analyze data to identify deliverables, gaps and inconsistencies.', 'Communication skills including the ability to identify and communicate data driven insights.', 'Ability in managing and communicating data warehouse plans to internal clients.']",2020-12-30 22:06:25
Data Science Intern (Summer 2021),Reddit,4 out of 5 from 2 employee ratings,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Graduating between December 2021 - Summer 2022', 'A desire to work at Reddit HQ in San Francisco over Summer 2021 (Subject to change pending safety guidelines due to pandemic)', ""Working towards a Bachelor's degree in Data Science, Statistics, Mathematics, Physics, Biology, Computer Science or a related field"", 'Authorization to work in the United States', ""You're over the age of 18""]",2020-12-30 22:06:25
Data Engineer,"Trusted Concepts, Inc",N/A,"Herndon, VA 20170","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:06:25
Data Engineer,MTK Technologies,N/A,"Irving, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Analytics/Engineering: 6 years (Required)Python: 5 years (Required)SQL /Business Intelligence/Data science: 5 years (Required)Linux/Bash scripting: 4 years (Preferred)', '8 hour shift', 'Data Analytics/Engineering: 6 years (Required)', 'Python: 5 years (Required)', 'SQL /Business Intelligence/Data science: 5 years (Required)', 'Linux/Bash scripting: 4 years (Preferred)']",2020-12-30 22:06:25
Data Engineer,"Trusted Concepts, Inc",N/A,"Herndon, VA 20170","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:08:06
Data Engineer,MTK Technologies,N/A,"Irving, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Analytics/Engineering: 6 years (Required)Python: 5 years (Required)SQL /Business Intelligence/Data science: 5 years (Required)Linux/Bash scripting: 4 years (Preferred)', '8 hour shift', 'Data Analytics/Engineering: 6 years (Required)', 'Python: 5 years (Required)', 'SQL /Business Intelligence/Data science: 5 years (Required)', 'Linux/Bash scripting: 4 years (Preferred)']",2020-12-30 22:08:06
Data Engineer - CIMD Technology,Goldman Sachs,"4 out of 5 from 1,813 employee ratings","Wilmington, DE 19801","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You will be part of the technology function for Marcus, focusing on building a business intelligence and Analytics platform that enables the business to operate efficiently.', 'You should be able to quickly build visualizations and semantic layers on top of AWS / Hadoop / Sybase / Oracle data to meet business needs, as well as be the thought leader to influence functional heads on new and innovate ways to visualize and report data that will help drive business value.', 'You will help design data models to support new and existing Lines of business(s) to enable business teams make accurate, timely and reliable decisions.', 'You will participate in data architecture decisions and partner with technology teams to implement data products in production systems.', ""You will work closely with business partners and technology leaders to evaluate new BI tools that can further enhance the business' ability to analyze data."", 'You should be able to commercialize data products and influence leadership on the value of these products.', 'Advanced degree in Engineering, Computer Science or related disciplines.', 'Hands-on experience with one or more mainstream programming languages (Python, Java, C, Scala, C++, etc.).', 'Hands-on experience with one or more relational database systems (Sybase, Snowflake, Oracle).', 'Experience in building data products from ideation to implementation.', 'At least 2 years’ experience in a visualization tool such as Tableau/QlikView/Spotfire/Power BI.', 'At least 3 years’ experience dealing with data (structured or unstructured).', 'Ability to explain data analysis to drive business ideas.', 'Strong project management skills.', 'Experience working in a start-up business or a new business line within a larger organization is preferred.']",2020-12-30 22:08:06
Data Engineer 100% remote,Ksquareinc,N/A,"Dallas, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Required:', '10+ years of IT experience', 'Strong in SQL and Python, 2+ years with both (preferably)', 'Experience building automated data pipelines', 'Experience performing data analysis and data exploration', 'Experience working in an agile delivery environment', 'Strong critical thinking, communication, and problem solving skills', 'Preferred:', 'Experience with big data frameworks (i.e. Hadoop and Spark)', 'Experience with cloud based platforms (i.e. Azure, GPC, AWS)', 'Experience working in multi-developer environment, using version control (i.e. Git)', 'Experience with orchestrating pipelines using tools (i.e. Airflow, Azure Data Factory)', 'Bonus:', 'Exposure/understanding of DevOps best practice and CICD (i.e. Jenkins)', 'Exposure/understanding of containerization (i.e. Kubernetes, Docker)', '8 hour shift', 'Yes']",2020-12-30 22:08:06
Data Engineer,Coalition,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Implement risk models for various insurance products', 'Evaluate, recommend, and implement data pipelines for a variety of data sources used at Coalition', 'Deliver production-quality software implementations for ETL and streaming pipelines', 'Explore new data sources and develop insights into existing data sources that improve business efficiency', '3+ years working with large disparate data sets', 'Deep understanding of ETL pipelines, statistical modeling, data analytics, and large scale data streaming', 'Expert-level knowledge of SQL, Python, R, or similar language used for data engineering', 'A proven track record of successfully automating business value from data insights', 'Experience with at least one big data search tool, such as Elastic', 'Excellent oral and written communications skills at all levels', 'Bachelor’s degree in Computer Science or a related field preferred', 'Prior experience with insurance or network security technologies', 'In-depth knowledge of AWS or other cloud-hosted platforms relevant to data engineering', 'Experience with data visualization technologies', 'Enjoy a highly fulfilling, mission-driven culture', 'Health, dental, and vision benefits for you and your family', 'Life insurance and disability benefits', 'Paid Parental Leave', '401(k) plan', 'Wellness and commuter benefits', 'Flexible working hours', 'Open vacation days', 'We embrace distributed work; some benefits will vary by location', 'You are an owner! We offer stock options to each of our employees', 'More details at https://www.coalitioninc.com/careers']",2020-12-30 22:08:06
Data Engineer,Zip,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You believe and want to participate in a blameless culture which focuses on process and technology', ""You don't sleep well at night when you leave work with a question unanswered"", 'You feel accountable for everything you do and that sense of urgency has been driving you your entire life', 'You like to have a good time while getting things done', 'When we say a team player we mean it - you have a crisp high-five and funny stories to tell', 'You have your teams back. And the team has yours', 'Sense of humor is hugely preferred', ""An interesting life story/a cool hobby/a diverse background has proven to bring more to the table in terms of perspective, what's yours?"", 'Database concepts – indexes, execution engines, etc', 'Database Administration experience (Azure DWH, SqlServer, Postgresql)', 'You understand that databases are an integral part of being a Data Engineer', 'You get the Cloud – we use Azure', 'You understands complex data and the challenges of accessing it', 'Traditional/relational databases, Lakes, or Pub/Subs make no difference to you', 'A real bottom-line person, not someone who throws terms like “big data” around because it’s popular', 'You like to ask questions and devise a complete solution', 'You want to understand the data (not only the pipes) and you can definitely perform some analytics and build dashboards because you like it', ""Finance industry /Credit / Risk experience is helpful for our domain's big picture"", 'You know that you don’t know enough, and it bothers you that there isn’t enough time in the day to learn about the next topic', 'You’re up-to-date on new trends in data – you know who’s using what to solve various problems and are excited for the next release of your favorite tool', 'If you like being thrown in the deep end of the pool, this team’s for you', 'Flexible working culture', 'Share incentive programs', 'Generous paid parental leave', '100% employer covered insurance', 'Fun team with high-growth hustle', 'Beautiful NYC office with a casual dress code', 'Fully stocked kitchen with snacks and coffee', 'Company-sponsored 401k program', 'Commuter benefits program']",2020-12-30 22:08:06
Data Engineer,Massachusetts General Hospital(MGH),"4.3 out of 5 from 1,108 employee ratings","Charlestown, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Achieving an extremely detailed understanding of our current data ecosystem, including its structure, meaning, history, transformation, flow, and challenges', 'Utilizing, improving, and constructing ETL toolsRunning current SQL, Python, PHP, and/or Tableau Prep ETL scriptsUsing various monitoring and evaluation methods to validate that data flowing through these pipelines is accurate and troubleshooting/addressing issues when they are discoveredImproving and further integrating these scripts (ETL and validation) further into various data pipelines to achieve greater efficiency, reliability, and functionality.Constructing new ETL tools as necessary/able, including a major rewrite of a family of old PHP pipelines in Python', 'Data CleaningWriting queries and scripts to identify data quality problemsInvestigating the root cause of data quality problemsWorking with appropriate team members to determine appropriate data remediation and process improvement plansDeveloping queries and scripts as needed to repair data in bulkBuilding out a dashboard to automatically monitor for certain critical data quality problems in production, independent of ETL processes', 'Additional ResponsibilitiesSupport the team as needed with data querying, processing, analysis and reporting for both regular and ad-hoc requests from clinical, executive, and external audiencesResearch potential new data engineering solutions, analyze feasibility, and assist technical leadership in road-mapping the evolution of our data infrastructureCreate and maintain documentation across our data ecosystem', 'BackgroundGraduate degree in Health Informatics, Computer Science, Statistics, Mathematics, Engineering, or a similar fieldFamiliarity with behavioral health clinical practice and/or research preferred', 'TechnicalProcedural programming aptitude and experience with Python, NumPy, and PandasPHP, Java, or other languages are a plus', 'Knowledge of relational database platforms and data modeling', 'Comfortable extracting data from and loading data into sources ranging from an Enterprise Data Warehouse to an Excel or text file, using built-in tools or custom-written ETL scripts', 'Knowledge of data aggregation and transformation processes (e.g. pivot, merge, union, hierarchical grouping, aggregation functions)', 'Above average SQL skills (e.g. familiar with subqueries, multiple joins, and grouping), specifically MySQL. SQL Server experience a plus', 'Comfortable with complex multi-stage, multi-technology ETL pipelines', 'Comfortable using APIs to transmit data in both an ad-hoc and automated manner', 'Familiar with concepts/tools of Data Quality Management as well as Data Governance practices', 'ProfessionalAbility to interpret and follow-through on data requirements and with strong attention to detail', 'Strength in independently validating and debugging code and analyses, including consulting documentation, Stack Exchange, etc.', 'Demonstrates personal initiative and time management skills, as well as the ability to work effectively and kindly as part of a team', 'Excellent verbal and written communication skills', 'Familiar with agile software development methodologies', 'Interest in identifying process improvement opportunities is a plus', 'Required: Graduate degree in Health Informatics, Computer Science, Statistics, Mathematics, Engineering, or a related subject.', 'Intermediate Databases and SQL', 'Intermediate Programming', 'Data Structures', '(Data) Quality Management', 'Data Flow and Automation']",2020-12-30 22:08:06
Data Engineer,Trane Technologies,3.4 out of 5 from 57 employee ratings,"Galway, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Responsible for the data pipeline architechture and its operation', 'Discover and implement new process improvements and automation methods to optimise workflow for development and deployment', 'Degree/Masters in Data Science, Mathermatics, Physics', 'Strong Alalytical skills relating to unstructures data sets', 'Strong experience modelling machine behavioural data', 'Proficient with machine learing techniques', 'Experience with a wide variety of statistical languages and data mining tools', 'Breath and depth of knowledge in statistical computing languages and tools, conventional langiuages (Java, C, ython, SQL)', 'Hands on experience with cloud based architectures and softwate stacks', 'Deep understanding of large always-on enterprise system architecture', 'Algorithim optimisation proficiency']",2020-12-30 22:08:06
Data Engineer,Federal Reserve Bank of Boston,4.2 out of 5 from 14 employee ratings,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Understands key business drivers and can translate into data requirements to provide insight and solutions', 'Works with stakeholders - both business and IT partners - to develop and analyze business intelligence needs', 'Designs and develops reports, dashboards, and other data visualization solutions to meet business needs', 'Analyzes program needs and translates them into data warehousing and data mart requirements', 'Integrates data from one or more source systems into data repositories that are optimized for reporting and analytics', 'Constructs, implements and operational data stores, data lakes, and data marts', 'Recognizes and resolves conflicts between data models, ensuring consistency and compliance with enterprise standards', 'Translates business requirements and problems into conceptual, logical, and physical data models', 'Monitors data transmissions, provides production support 24 hrs x 7 days a week', 'Performs other related duties as assigned.']",2020-12-30 22:08:06
Collateral and Derivatives Management Engineer,Vanguard,"3.8 out of 5 from 1,026 employee ratings","Malvern, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Lead the integration of a leading collateral and derivative vendor solution with the other applications that provide OTC Derivative Middle Office Services for Vanguard’s Investor Services Clients', 'Act as Liaison for the Collateral and Derivative vendor based product.', 'Manage the book of work for the integration of the vendor product while working closely with the application development team.', 'As an application owner, be accountable for application stability, system uptime, escalation point for Production incidents', 'Create clear and transparent technology solutions that are scalable, communicating the need to avoid customized logic in favor of generic functions.', 'Ensure Vanguard’s design and control standards are adhered to and managing any open design issues to resolution.', 'Deep and differentiating understanding of Derivatives and Collateral subject matter', 'Proficient in development and production support objectives within leading Derivatives and Collateral management platforms', 'Proficient in strategic development within Derivatives and Collateral', 'Extensive experience in Calypso or other modelling and implementing OTC products from a fund administration/middle office servicing perspective', 'Vendor relationship management', 'Should have understanding for APIs required to extend or add data to the vendor system, and to build interfaces between product and external systems (data uploader framework)', 'Experience designing / building front-to-back trade capture and work flow processing systems will be especially valuable', 'Self-starter with the ability to lead strategic application objectives', 'Strength in working in an highly collaborative team environment']",2020-12-30 22:08:06
Data Engineer,illumis,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Write, maintain, and improve Python code for collecting and processing data from thousands of different third-party sources', 'Analyze new data sources to understand how to best acquire and model/catalogue the data', 'Develop a strong understanding of the ways our users use our products to help inform how we can best present records and data to meet their needs', 'Work with many different kinds of data, both public and proprietary, in many different structured and unstructured formats, ingested from sources such as APIs, databases, websites, files, cloud storage, etc.', 'Curate and monitor existing source integrations to ensure data in our platform is accurate, consistent, available', 'Analyze our data to deliver insights that improve our platform and power new features and products', 'You LOVE (or are at least intensely interested by) data and the idea of collecting, organizing, and making it more accessible and usable', 'You have worked programmatically with data in a role such as a software engineer, data analyst, digital archivist, scientist, researcher, or data programmer', 'You can quickly profile and understand a data set and implement an appropriate process in code for working with it', 'You’re experienced and proficient with Python, and have a strong working knowledge of web technologies such as HTTP, HTML, and JSON', 'You have experience ingesting data from varied and complex real-world sources including websites, files in multiple formats, databases, and APIs', 'You have a strong understanding of data types, schemas, and normalization and how to work with “dirty” data', 'You are a fast, motivated learner and are willing to pick up new tools and technologies on the fly to solve a problem', 'You’re excited by open-ended problems and are comfortable owning and delivering a solution from start-to-finish', 'You have a VERY strong attention to detail and documentation', 'You enjoy working collaboratively and really care about the work you do, the people you do it with, and the customers who ultimately use the product', 'Python, ElasticSearch, Postgres, Redis, Linux, Celery, Docker, GCP']",2020-12-30 22:08:06
Data Engineer,"Integrated Technology Strategies, Inc.",N/A,"Allentown, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Bachelor’s degree in engineering or a bachelor’s degree in technology from a recognized university', 'Candidate should have recent work experience with US-based customers', 'Minimum 10 years of relevant experience is required', '5+ years of experience working in data engineering or architecture role', 'Expertise in SQL and data analysis and experience with at least one programming language (Python/PySpark or Scala preferred)', 'Experience developing and maintaining data warehouses in big data solutions', 'Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)', 'Database development experience using Hadoop or BigQuery and experience with a variety of relational, NoSQL, and cloud data lake technologies', 'Worked with BI tools such as Tableau, Power BI, Looker, Shiny', 'Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data.', 'Big Data Development experience using Hive, Impala, Spark and familiarity with Kafka (Preferred)', 'Familiarity with the Linux operating system (Preferred)', 'Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics']",2020-12-30 22:08:06
Data Scientist / Software Engineer,Matrix Transport Service LLC,N/A,"Bayonne, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with our service organization to prioritize high-value issues', 'Design and build your machine learning pipeline end to endWork with service engineers and firmware engineers to understand what features could help predict issuesBuild efficient and reproducible data pipelines to produce your features, consuming petabytes of time series data using cutting-edge open source technologiesBuild machine learning models to predict failures, and anything you need to iterate over your model (feature selection, hyper parameter tuning, validation, etc)Evaluate, justify and communicate model performanceSchedule and operate your model in a production data pipeline', 'Build user interfaces to bring humans in the loop when necessary, to further increase the quality of your predictions', 'Write clean and tested code that can be maintained and extended by other software engineers', 'Keep up to date on relevant technologies and frameworks, and propose new ones that the team could leverage', 'Identify trends, invent new ways of looking at data, and get creative in order to drive improvements in both existing and future products', 'Give talks, contribute to open source projects, and advance data science on a global scale', 'Strong proficiency in Python', 'Strong foundation in machine learning', 'Strong foundation in software engineering', 'Experience building multiple machine learning models that provided company value', 'Experience with data science tools such as Pandas, Numpy, R, Matlab, Octave', 'Strong verbal and written communication skills', 'Smart but humble, with a bias for action']",2020-12-30 22:08:06
Systems/Data Engineer,Tesla,"3.5 out of 5 from 4,572 employee ratings","Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyze and interpret high volume manufacturing data from various sources and assembly operations to extract useful statistics and insights about the operation', 'Support engineering staff and management in investigations of failures, containment activities, continuous improvement initiatives, etc, in order to drive meaningful improvements to production quality and output', 'Work effectively with engineers and conduct end-to-end analyses, from data requirement gathering, to data processing and modeling', 'Interpret data, analyze results using statistical techniques and provide ongoing reports', 'Monitor key product metrics, understanding root causes of changes in metrics', 'Identify, analyze, and interpret trends or patterns in complex data sets and depict the story via dashboards and reports', 'Create and maintain standardized reporting tools for the operation, providing results on the health of the business for various audiences, including senior management', 'Maintain existing data visualizations, data pipelines and dashboard enhancement requests', 'Acquire data from primary or secondary data sources and maintain databases/data systems to empower operational and exploratory analysis', 'Automate analyses and authoring pipelines via SQL, Python, Tableau, and similar', 'Drive underlying data systems improvement by working with key cross-functional stakeholders', 'Perform data quality validations to ensure data creation', 'Proactively identify improvement opportunities (potential gaps between process and system) across all business functions, developing tools that allow for visibility into process bottlenecks and inconsistencies', 'Work closely with controls, process, and quality engineers to develop and improve data collection activities and reporting tools within a high volume manufacturing environment', 'Work with management to prioritize business and information needs', 'B.S. degree or higher in quantitative discipline (e.g. Computer Science, Mathematics, Physics, Electrical Engineering, Statistics, Industrial Engineering) or the equivalent in experience and evidence of exceptional ability', '3+ years of work experience in data engineering and platform engineering', 'Extensive experience developing software', 'Works well under pressure while collaborating and managing competing demands with tight deadlines', 'A passion and curiosity for data and data-driven decision making', 'Drive to introduce predictive models that can be used for production decision making assistance', 'Possess a high level of attention to detail and professionalism in report creation', 'Be a team player and have the ability to collaborate well across diverse functional groups', 'Strong verbal and written communication skills to manage and communicate the health and integrity of the data and systems', 'Experience in high volume manufacturing is a plus where automated assembly is performed and data collected via Manufacturing Execution Systems', 'Understanding of software and database design in order to work closely with a development team to translate business needs into software solutions', 'Data mining and database (e.g. MySQL) experience', 'Data visualization experience (e.g Tableau)']",2020-12-30 22:08:06
Data Engineer - Houston,Octane,3.5 out of 5 from 15 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:08:06
Data Engineer - Houston,Octane,3.5 out of 5 from 15 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:09:47
Data Engineer,SFL Scientific,N/A,"Quincy, MA 02169","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)US work authorization (Preferred)"", 'Never ask you to engage in conversations that are not over the phone, email, or LinkedIn.', 'Only use @sflscienific.com email accounts.', 'Never ask you about your gender identity, race, color, religion.', 'Never ask you to submit over email any identifying information including social security numbers, drivers license, passport numbers or credit card numbers', 'Never send a contract or job offer without first having an interview with our teams.', '401(k)', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Quincy, MA 02169 (Preferred)', ""Bachelor's (Preferred)"", 'One location', 'Temporarily due to COVID-19', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:09:47
Data Engineer / Analytics engineer,Moxieit Cloud,N/A,"Charlotte, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'ETL and DBs: 5 years (Preferred)', 'Prior proficient experience in Capital markets, finance , Banking and investment portfolio.', 'Extensive work experience in executing analytics with Portfolio and market data.', 'Should be able to understand the use cases and assist business users / leaders in generating / enhancing the analytics that helps in business decisions', 'Knowledge of end to end business process cycle of handling the financial assets data.', 'Flexible to adapt new technologies and inherit the established analytics.', 'Goo communication skills, both written and verbal, with the ability to interact with business users and key stakeholders in the line of business.', 'Self-directed, highly motivated and able to work independently.', 'Expert in understanding the analytical and reporting requirements, backtracking the data to data mart till source systems by understanding the end to end data flows', 'Strong querying experience in data marts for what if analysis, Data quality checks and building data sets for adhoc analytics / Reporting', 'Develop the consolidated data mart from multiple source systems - DBs and ETL tools', 'Work experience in developing the adhoc & standard analytics and reporting needs for finance teams.', 'Building the reusable analytics across applications and reduce TAT.', 'Effective knowledge in improving the performance with huge volumes of data analytics.', 'Tools & Technologies: Polypaths (analytics tool) / others, Reporting skills (MicroStrategy/others), ETL skills (SSIS/Others), Data bases (Oracle/Exadata/SQL server)', 'R & Python skills for forecasting the analytics data would be preferable.', 'Monday to Friday', 'Capital Markets: 5 years (Preferred)', 'polypath(analytical tools): 5 years (Preferred)', 'ETL and DBs: 5 years (Preferred)', '5 - 6 months', 'Likely']",2020-12-30 22:09:47
Entry Level Data Analyst and Data Visualization (STEM),PCS Global Tech,N/A,"California City, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:SQL, 1 year (Preferred)Data Modeling, 1 year (Preferred)T-SQL, 1 year (Preferred)', 'Help write and optimize in-application SQL statements.', 'Ensure performance, security, and availability of databases.', 'Prepare documentation and specifications.', 'Handle common database procedures such as upgrade, backup, recovery, migration, etc.', 'Write TSQL scripts and objects such as stored procedures, user-defined functions, views, indexes per business requirements.', 'Create ETL SSIS packages to migrate data from OLTP sources to OLAP destinations through available tasks and transformations in SSIS.', 'Design and create user-interactive reports in SSRS, Power BI, and Tableau.', 'Profile server resource usage, and optimize and tweak as necessary.', 'Collaborate with other team members and stakeholders.', 'BS or MS of a degree in Computer Science, Information Technology, Engineering or a related field is required', 'Proficiency with SQL and its variation among popular databases', 'Skilled at optimizing large complicated SQL statements', 'Capable of configuring popular database engines and orchestrating clusters as necessary', 'Ability to plan resource requirements from high-level specifications', 'Good communication skills', 'Maintain, support, and enhance the business intelligence data backend, including data warehouses and data lakes.', ""Build interfaces between the business intelligence systems and other colleges' information systems to maintain a timely and accurate integration of data."", 'Collaborate and work with data analysts in various departments to ensure that data meets their reporting and analysis need.', 'Provide technical guidance for design and implementation of data governance systems and policy.', 'Work extensively towards SQL Server development in writing core TSQL scripts to implement complex business logic.', 'Develop SSIS packages to implement complex ETL strategies as a part of business requirements for the population of dimensional data structures.', 'Work on creating SSAS cubes and various cube objects such as KPIs (Key Performance Indicators), calculated members, attribute hierarchies, and perspectives.', 'Design eye-catching reports with data from OLTP database, dimensional data structure and OLAP cubes for business reporting purposes.', 'Keep abreast of new business intelligence technologies', 'BS or MS of a degree in Computer Science, Information Technology, Engineering or a related field is required', 'At least 1 year of experience using Microsoft SQL Server Database, SSIS, SSRS, SSAS is required', 'Experience with other relational databases, BI reporting and data discovery tools are preferred', 'Provides plan with data, reporting, and analyses that enable data driven decision making.', 'Provides summary analyses in written and oral presentation settings.', 'Builds database from scratch. And prepares complex presentations.', 'Develops system test cases and documents results, researches system issues, and documents findings.', 'Bachelor’s degree in Science, Technology, Engineering or Mathematics', 'Ability to translate business requirements into non-technical, lay terms', 'Understanding of addressing and metadata standards', 'High-level written and verbal communication skills', 'Managing master data, including creation, updates, and deletion.', 'Managing users and user roles.', 'Provide quality assurance of imported data, working with quality assurance analyst if necessary.', 'Commissioning and decommissioning of data sets.', 'Processing confidential data and information according to guidelines.', 'Helping develop reports and analyses.', 'Managing and designing the reporting environment, including data sources, security, and metadata.', 'Supporting the data warehouse in identifying and revising reporting requirements.', 'Supporting initiatives for data integrity and normalization.', 'Assessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems.', 'Generating reports from single or multiple systems.', 'Troubleshooting the reporting database environment and reports.', 'Evaluating changes and updates to source production systems.', 'Training end-users on new reports and dashboards.', 'Providing technical expertise in data storage structures, data mining, and data cleansing.', 'Bachelor’s degree in Science, Technology, Engineering or Mathematics', '1-3 years of work experience as a data analyst or in a related field is preferred', 'Ability to work with stakeholders to assess potential risks.', 'Ability to analyze existing tools and databases and provide a software solution recommendations.', 'Ability to translate business requirements into non-technical, lay terms.', 'High-level experience in methodologies and processes for managing large scale databases.', 'Demonstrated experience in handling large data sets and relational databases.', 'Understanding of addressing and metadata standards.', 'High-level written and verbal communication skills.', 'Dental insurance', 'Health insurance', 'Life insurance', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'SQL: 1 year (Preferred)', 'Data Modeling: 1 year (Preferred)', 'T-SQL: 1 year (Preferred)', 'Multiple locations', 'Pay']",2020-12-30 22:09:47
Big Data Engineer - Python + Spark,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Westerville, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Several years of experience working on software development projects.', 'In-depth Python experience.', 'Expertise in Spark with Python/ PySpark.', 'Advanced knowledge of application, data and infrastructure architecture disciplines.', ""Multiple years' experience with building large scale big data applications."", 'Prefered experience with AWS Cloud, working with EMR, S3, CI/CD pipelines.', 'Experience in Agile SDLC and working proficiency in developmental toolsets.', 'Understanding of architecture and design across all systems.', 'Knowledge of various financial instruments is desirable.', 'Successful track record on several major technology implementation projects.', 'Excellent team spirit and ability to work in collaborative environment.', 'Ability to working under own initiative.', 'Working proficiency in developmental toolsets.', 'Knowledge of industry wide technology trends and best practices.', 'Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture.', 'Understanding of software skills such as business analysis, development, maintenance and software improvement.']",2020-12-30 22:09:47
Data Engineer,PHILAINQ,N/A,Pennsylvania,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop, test and maintain data architecture.', 'Design and implement secure data pipelines to prepare, process, ingest and organize data into data data lake / data warehouse from disparate on-premise and cloud data sources.', 'QA and troubleshoot performance of data pipelines and queries accessing data warehouse', 'Clean, transform and model data to power our analytics and user facing products', 'Ensure proper data governance and privacy practices', 'Partner with Analytics team on buildout of advanced data products', 'Assist with automation and orchestration', 'Capable coder with Python, Scala, and R', 'Familiar with modern, cloud-native, scalable ETL solutions/tools, ex: Informatica, Stitch/Talend, Mulesoft/Salesforce, etc…', 'Experience with workflow orchestration principles & platforms (DAGs, Airflow, DBT, Luigi, Dagster, Prefect, etc…)', 'Prefer experience with Google Cloud Platform(Bigquery, Dataproc, Dataflow, Pub/Sub, etc…). Experience with AWS (DynamoDb, Kinesis Stream, etc…) is a plus', 'Building an analytic engine, segmentation and grouping data', 'Experience writing scripts to automate the provisioning and maintenance of systems in a distributed, virtualized infrastructure', 'Familiarity with managed cloud-based options for building machine learning models', 'RDBMS database development using SQL queries and stored procedures', 'Nice to have experience with ElasticSearch, DataDog, Serverless microservices', 'Pay Type Salary']",2020-12-30 22:09:47
Data Engineer,Tempest,3.3 out of 5 from 17 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with various stakeholders within the organization including marketing, product, finance, engineering , and executive leadership to define data requirements for specific business functions', 'Design and architect the data infrastructure (table design, data flows etc.)Partner with product teams to enable data capture on digital products and business processes', 'Develop data pipes across various sources to collect and stage data for operational and analytical consumption', 'Document data objects to produce technical metadata, and business data dictionaries', 'Manage data loads, data quality checks and defect resolution', 'Develop data visualization and reporting views over base tables', 'Work with Product Managers to own all aspects of web tagging and clickstream data collection', 'Manage and maintain all aspects of Google Tag Manager inclusive of tagging documentation, tool configuration and user administration', 'Develop event architecture for Tempest’s web data and work to integrate into 3rd party platforms (marketing / advertising, email systems, CRM systems, etc)', 'Collaborate with other engineering teams to ensure quality, accessibility, and consistency of collected data across web and native platforms', '5+ years experience in full-stack engineering with a focus on backend and clickstream data development', 'RDBMS and SQL skills are a must', 'PostGres experience preferred', 'Experience with Tag Management systems like Google Tag Manager Applied data warehousing techniques and architecture approach', 'Collaborative team player and self-starter with an ability to prioritize competing priorities', 'Experience with JavaScript, especially as it relates to 3rd party tagging', 'Ability to translate business problems into actionable metrics and technical measurement requirements', 'Ability to translate complicated methods and results into plain language, both in speaking and writing']",2020-12-30 22:09:47
Data Engineer Internship - Summer 2021 (US),Amazon.com Services LLC,"3.6 out of 5 from 67,873 employee ratings","Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Currently enrolled in or will receive a Bachelor’s or Master’s Degree in math/statistics/engineering or other equivalent quantitative discipline with a conferral date after September 2021', 'Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)', 'Experience with one or more scripting language (e.g., Python, KornShell)', 'Experience with data mining, data warehouse solutions, and ETL', 'Design, implement, and automate deployment of our distributed system for collecting and processing log events from multiple sources', 'Design data schema and operate internal data warehouses and SQL/NoSQL database systems', 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions', 'Monitor and troubleshoot operational or data issues in the data pipelines', 'Drive architectural plans and implementation for future data storage, reporting, and analytic solutions', 'Work collaboratively with Business Analysts, Data Scientists, and other internal partners to identify opportunities/problems', 'Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem', 'Master’s or advance technical degree', 'Proficient in at least one or more query language, schema definition language, and scripting language', 'Knowledge of writing and optimizing SQL queries in a business environment with large-scale, complex datasets', 'Experience with data visualization software (e.g., AWS QuickSight or Tableau) or open-source project', 'Experience with big data processing technology (e.g., Hadoop or ApacheSpark), data warehouse technical architecture, infrastructure components, ETL, and reporting/analytic tools and environments', 'Ability to deal with ambiguity in a fast-paced environment']",2020-12-30 22:09:47
Data Pipeline Engineer,Rockerbox,N/A,"New York, NY 10013","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Expertise in big data technologies, e.g. Elasticsearch, SMACK stack (Spark, Mesos, Akka, Cassandra/Scylla, Kafka)', 'Experience with functional programming in Scala, Python, Go', 'Deep knowledge of containerization and service orchestration technologies (Docker, Mesos, DC/OS, Kubernetes) and web servers technologies (OpenResty, Nginx, Lua)', 'Familiarity with monitoring tools like Grafana, Graphite, Prometheus', 'Know your way around tech stacks for big data ingestion, storage, processing', 'Understand the lifecycle of developing and shipping applications and databases from staging to production', 'Have a track record of experimenting with bleeding-edge technology and frameworks', 'Can comfortably transfer ad-hoc analysis to a production environment', 'Get joy out of setting stuff up and making it run smoothly', 'Work in a small, dynamic team', 'Healthcare Insurance: health, dental, vision', 'Paid time off: choose your own schedule!', 'Competitive salaries', 'Opportunities to give back to the open-source developer community']",2020-12-30 22:09:47
Data Software Engineer,General Dynamics Information Technology,"3.8 out of 5 from 7,499 employee ratings","Rockville, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop Oracle database scripts to maintain data and database in all environments, Dev, Test, Preprod, and Prod', 'Work closely with the tech lead and team lead to solve various database related problems including data model, data quality, db performance, etc.', 'Submit a change request and coordinate to deploy any database changes to all environments', 'Provide data and database support for application development and test activities', 'Maintain all database scripts for both scheduled and unscheduled releases', 'Document database changes for both scheduled and unscheduled releases', 'Attend various meetings to accurately report about database related', 'Bachelor’s Degree in relevant field', '2 + years knowledge and hands-on experience with:Oracle SQL and PL/SQLVarious Oracle database objects development', 'Minimum of 1 year of Oracle database system administration', 'Knowledge and hands on experienceOracle data model designUnix scriptingJava/C#/Python programmingHands-on InformaticaOracle ADF and WeblogicNon-Oracle database like MySQL, SQL Server, etcKnowledge or Hands-on experience with AWS or Azure', 'Excellent verbal and written communication skills']",2020-12-30 22:09:47
Data Engineer,BAE Systems,"3.8 out of 5 from 4,092 employee ratings","Washington, DC 20032","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Identify workflow improvements systems in order to reduce analytic fatigue and administrative burden', 'Document the desired master and reference standards of specific data fields to ensure interoperability', 'Identify a system that can store an interoperable database with appropriate security protocolsHave each system identify the parameters for sending output to a centralized DB per agreed upon standardsSet guidelines and policy for access to business data (primary and integrated forms)', 'Design and define highly performant data ingestion pipelines from multiple sources using scripting language such as python and/or open source such as nifi', 'Architect and build security compliant user management framework for multi-tenant big data platform', 'Integrate the end to end data pipeline to take data from source systems to target data repositories ensuring the quality and consistency of data is maintained at all times', 'Implementing high performant data ingestion pipelines', 'Document the common master and reference data services needed', 'Determine the governance process to manage the lifecycle of each service, to include creating new data, changing existing data, and archiving data.', 'Build data dictionary to document shared understanding of key data (master/reference)', 'Experience /knowledge of AWS Cloud', 'Maintains metadata layer, database ontology, monitors overall database standards and procedure, and integrates systems through database design', 'Strong understanding of the Software Development Lifecycle and experience integrating Data Architecture and Data Governance into that lifecycle to steer towards desirable outcomes.', 'Experience with analyzing current state and conceiving desired future state, and identifying projects required to evolve.', 'Ability to estimate work effort for project sub-plans or small projects and ensure the project is successfully completed', 'Knowledge of non-relational (NoSQL) databases such as MongoDB, Redis, Accumulo or similar technologies and relational databases like Oracle, PostgreSQL and MySQL.', 'COMPTia Security+ Certification', 'Experience with structured, semi-structured, and unstructured data sets, using XSLT, XML and scripting languages for data transformation.', 'High degree of analytical and critical thinking skills.']",2020-12-30 22:09:47
DATA ENGINEER,Bangura Solutions,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop a Data Migration Strategy and document, which covers business/data quality requirements, sources of data from the legacy systems.', 'Manage the data cleansing and migration work-stream.', 'Oversee the implementation of interfaces.', 'Lead the data work-stream in developing various mappings and process flows using SQL and other business intelligence tools to migrate data from the Legacy systems.', 'Develop Test plans, scripts an execution test cases for Systems End to End testing and UAT.', 'Housing', 'Data Cleansing', 'Data Migration', 'Interfaces', 'Full data lifecycle of project.', 'Excel for data cleansing and migration', 'Experience of data migration from Northgate OHMS', 'Experience of Housing, Local Council, Repairs, Asset Management interfaces', 'Experience of Oracle and SQL Server', 'Experience of managing Junior Staff', 'Full understanding of data protection practice and GDPR', 'Database administration experience and understanding of data management']",2020-12-30 22:09:47
Engineer - Data,SafeGraph,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Have attention to detail and bias for action, are a prolific communicator, and thrive in uncertainty.', 'Are passionate about big data, looking to work in a fast-paced environment, focusing on hard problems where the solutions are often not predefined.', 'Authorized to work within North America and are comfortable working remotely.', 'Minimum 3+ years of backend engineering work experience.', 'Proficiency writing production-quality code, preferably in Scala, Java, or Python.', 'Familiarity with all things building data products - schema design, modeling, optimization, scalability.', 'Deep understanding of Apache Spark and distributed data systems - that allows you to solve production-scale problems.', 'Excellent communication skills.', 'Experience and passion for functional programming in solving data problems (Scala).', 'Experience with AWS.', 'Experience working with huge data sets.', 'Experience with building ML models from the ground up.', 'Experience with open source development.', 'Our goal is to be the dominant place to get any data on a physical Place. We sell our product - our datasets - to data scientists and machine learning engineers at companies of all sizes.', 'At SafeGraph, we’ve taken a measured approach to building a long term company. We were profitable in 2019, have hired experienced leadership from the start and care deeply about democratizing access to data to everyone.', 'We currently have ~50 employees and are growing quickly. We raised a $20 million Series A, and the CEO was previously the founder and CEO of LiveRamp (NYSE:RAMP).', ""While SafeGraph was started in San Francisco, we've been distributed across North America since 2019, and currently have small offices (in non-pandemic times) in SF, NYC & Denver. We get the entire company together in the same place as often as possible, and cannot wait to do this again soon!"", 'We offer our employees a robust set of benefits, including health, dental & vision insurance coverage, a 401k, work-from-home stipend, mental health benefits, and much more.']",2020-12-30 22:09:47
Federal - Big Data Engineer,Accenture,"4 out of 5 from 20,306 employee ratings","Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience with Data Engineering or Big Data Technologies, or Data Transformation, and modeling', 'Experience in architecting and building scalable data platforms', 'Experience with Cloud Technologies (Data Lake, Azure, Google, AWS etc.) or experience with open source technologies (Spark, Kafka, Presto, Hive, Cassandra etc.)', 'Experience with SQL and/or NOSQL databases', 'Must be a US Citizen; no dual citizens', 'Production implementation experience for all qualifications listed', 'Production experience in building real-time analytics applications', 'Experience in both batch and stream processing technologies', 'Experience with 2 of 3 - Java, Scala, and Python programming languages', 'Machine learning experience with Spark or similar', 'Ability to manage numerous requests concurrently and be able to prioritize and deliver', 'Good communication skills', 'Dynamic team player', 'Bachelor’s Degree']",2020-12-30 22:09:47
Oops! That page can’t be found.,Accenture,N/A,"Washington, DC","['Indeed Jobs', '404', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Facebook', 'Twitter', 'instagram', 'Youtube', 'Soundcloud']",2020-12-30 22:09:47
Data Engineer,Steampunk,4.5 out of 5 from 2 employee ratings,"McLean, VA 22102","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Profile and analyze source system data to determine data relationships, keys, conformed dimensions, and necessary transformations', 'Identify data quality issues', ""Ensure data structures are designed for flexibility to support clients' business needs"", 'Develop strategy and repeatable process for maintaining Enterprise Data Models', 'Design & test integrations to/from data modeling tools', 'Work with developers to create an API access layer for the data', 'Reverse engineer complex, new datasets, and map these new datasets to the existing model.', 'Provide documentation and instruction to data modelers and developers', 'Constantly interact with both ETL developers and end users data analysts to share knowledge, collect feedback, and provide additional implementation requirements.', 'Develop, maintain, and review data processes and architecture for both on-premise and cloud-based data systems', 'You will contribute to the growth of our Data Exploitation Practice.', 'Who wants to do something different......', 'US Citizen Only', 'Ability to hold a position of public trust with the US government.', '5+ years industry experience coding commercial software and a passion for solving complex problems.', '5+ years direct experience in Data Engineering with experience in tools such as:', 'Advanced working SQL knowledge and experience working with relational databases, query authoring and optimization (SQL) as well as working familiarity with a variety of databases.', 'Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience manipulating, processing and extracting value from large, disconnected datasets.', 'Experience manipulating structured and unstructured data for analysis', 'Experience constructing complex queries to analyze results using databases or in a data processing development environment', 'Experience with data modeling tools and process', 'Experience architecting data systems (transactional and warehouses)', 'Experience aggregating results and/or compiling information for reporting from multiple datasets', 'Experience working in an Agile environment', 'Experience supporting project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models']",2020-12-30 22:11:28
Cyber Associate Data Engineer,NYC Cyber Command,N/A,"New York, NY 10005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Developing and maintaining our data pipeline using Apache Beam, Java, Python and other data processing technologies;', 'Identifying and implementing performance improvements across all pipelines;', 'Engaging with data consumers and producers in order to design appropriate models to suit all needs;', 'Maintaining information exchanges through publish, subscribe, and alert functions that enable users to send and receive critical information as required;', 'Supporting incident management, service-level management, change management, release management, continuity management, and availability management for databases and data management systems;', 'Administering databases and/or data management systems that allow for the secure storage, query, protection, and utilization of data.', 'A bachelor’s degree in computer science or information systems with a specialization in mathematics, number; theory, applied cryptography, or statistics or relevant experience;', 'Experience with the Agile Development Methodology;', 'Expert knowledge in both Java and Python;', 'Familiarity with Unix scripting, Web development, and automated testing;', 'Familiarity with machine learning techniques and machine learning toolkits such as R, scikit-learn, etc;', 'Experience working with Terraform;', 'Familiarity with the CI/CD process,', 'At least one year professional, academic, or personal experience with software development or data engineering experience (includes internship experience);', 'At least 1 year professional, academic, or personal experience with object-oriented/object function scripting languages; preferably java or python;', 'Familiarity with or exposure to cloud application development;', 'Familiarity with distributed data processing frameworks.', 'Interested applicants with other civil service titles who meet the preferred requirements should also submit a resume for consideration']",2020-12-30 22:11:28
Software Engineer,Dell Technologies,"4 out of 5 from 10,284 employee ratings","New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop, test and integrate code for new or existing software while following source code revision control', 'Troubleshoot software reliability and performance issues', 'Review requirements, specifications and designs, developing and implementing tests for product quality and performance assurance', 'Assist with the development and review of (technical) end user documentation', 'Drive idea generation for new software products or for the next version of an existing product', 'Entry level position requiring basic knowledge of programming languages, operating systems and databases', 'Debugging skills for simple programs using either written or verbal design specifications', 'A good understanding of hardware and software interactions', 'First-hand experience with server, storage, networking and client technologies', 'Insight into software architectures and applications', 'First-hand experience gathered during an internship, student job or related professional role']",2020-12-30 22:11:28
"Big Data Engineer, AVP",Citi,"3.9 out of 5 from 17,932 employee ratings","New Castle, DE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Oversee process for technical issue escalation and prioritize technical issue resolution', 'Leverage skills across Applications Development area to provide technical oversight across systems and applications', 'Communicate internal and external departmental interdependence as well as cross product and cross project', 'Resolve issues using in-depth knowledge of concepts and procedures within applications development', 'Utilize in-depth specialty knowledge of applications development to analyze complex problems/issues, provide evaluation of business processes, system processes, and industry standards, and make evaluative judgement', 'Contribute to planning, budget management, formulation of procedures, and resource planning negotiating with external parties when necessary', ""Appropriately assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing and reporting control issues with transparency, as well as effectively supervise the activity of others and create accountability with those who fail to maintain these standards."", 'Hands on experience on Big Data EAP platform technologies on Hadoop like Hive, HDFS, Data Bridge, Unix, Shell scripting, Autowatch, File watcher, Autosys.', 'Java/Oracle experience will be preferable.', '5-8 years of relevant experience', 'Hands on experience on Big Data EAP platform technologies on Hadoop like Hive, HDFS, Data Bridge, Unix, Shell scripting, Autowatch, File watcher, Autosys.', 'Java/Oracle experience will be preferable.', 'Experience in resolving issues in the Big Data environment', 'Experience in managing and implementing successful projects', 'Ability to take ownership and make technical decisions on software development projects', 'Experience with dependency management, change management, continuous integration testing tools, and audit/compliance requirements', 'Extensive knowledge of software engineering and object-oriented design', 'Demonstrated leadership and management skills', 'Consistently demonstrates clear and concise written and verbal communication', 'Bachelor’s degree/University degree or equivalent experience']",2020-12-30 22:11:28
Data Engineer,Screen Actors Guild- Producers Pension & Health Plans,3.2 out of 5 from 10 employee ratings,"Burbank, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Posted: December 17, 2020', 'Full-Time', 'LocationsShowing 1 locationBurbank, CA, USA', 'Engage business teams to understand requirements, document them and deliver robust and scalable solutions in the form of data models that can be leveraged for self-service analytics.', 'Explore ways of modeling the Plans unstructured voice and text data into frameworks fit for analysis.', 'Design conceptual, logical and physical data models, maintain data dictionary and capture metadata.', 'Perform gap analysis as needed for purposes of maintaining, continuously enhancing data models and integrating KPI’s into the analytics platform as and when new KPI and business metrics are adapted by the organization.', 'Work closely with data experts to build and maintain KPI data dictionary, metadata, data standards, and ensure adherence to the Plans Analytics Method and data standards.', 'Work with application development team to deploy analytics data products through such ways as embedding analysis models into business applications and mobile solutions.', 'Establish and maintain provenance, integrity and security of data used for self-service reporting, ad-hoc analysis or other levels of analysis.', 'Utilize ETL tools and other data pipeline automation techniques to develop and maintain source to target mapping that includes extract requirements, derived field logic, domain values and data lineage.', 'Ensure developed data models are easy to use and efficient to access data thus enable transparency of data lineage to business teams and all stakeholders.', 'Bachelor’s Degree in Computer Science, Information Systems, or other related field as well as equivalent work experience.', 'Minimum 5 years of data engineering, data modeling or data architecture experience with a focus on multidimensional data modeling for both structured and unstructured data.', 'Experience designing conceptual, logical and physical data models and maintaining data dictionary and capturing metadata.', 'Experience creating and maintaining automated data pipelines, data standards, and best practices to maintain integrity and security of the data; ensure adherence to developed standards.', 'Experience in developing and maintaining source to target mapping that includes extract requirements, derived field logic, domain values and data lineage.', 'Experience in relevant technical languages and tools such as SQL, Python, NoSQL, Airflow, Quartz, ERWIN or equivalent.', 'Previous work experience in the Healthcare industry preferred.', 'Customer focus - Gains insight into customer needs; identifies opportunities that benefit the customer; builds and delivers solutions that meet customer expectations; establishes and maintains effective customer relationships.', 'Decision quality – Makes sound decisions, even in the absence of complete information; relies on a mixture of analysis, wisdom, experience, and judgment when making decisions; considers all relevant factors and uses appropriate decision-making criteria and principles; recognizes when a quick 80% solution will suffice.', 'Communicates effectively – Is effective in a variety of communication settings: one-on-one, small and large groups, or among diverse styles and position levels; attentively listens to others; adjusts to fit the audience and the message; provides timely and helpful information to others across the organization; encourages the open expression of diverse ideas and opinions.', 'Ensures accountability – follows through on commitments and makes sure others do the same; acts with a clear sense of ownership; takes personal responsibility for decisions, actions, and failures; establishes clear responsibilities and processes for monitoring work and measuring results; designs feedback loops into work.', 'Instills trust – follows through on commitments; is seen as direct and truthful; keeps confidences; practices what he/she preaches; shows consistency between words and actions.', 'Manages Ambiguity- Operating effectively, even when things are not certain or the way forward is not clear.', 'Proficient in leading business and internal team discussions to gather requirements, brain-storm and propose robust and scalable solutions; leverage business partner/unit input to enhance data models.', 'Expert knowledge of relational DBMS, specifically Oracle .', 'Expert knowledge in areas of advanced data techniques including unstructured and spatial data.']",2020-12-30 22:11:28
Big Data Engineer(spark/scala),Volto Consulting,N/A,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Hadoop: 6 years (Required)Apache Spark, Scala: 3 years (Required)Bachelor's (Preferred)"", '6+ years development experience with BigData and Hadoop Ecosystems', 'Experience with Apache Spark, Scala is must', 'Develop code to ingest, transform and analyze Oracle and SQL data', 'Knowledge Experience in Agile Development methodologies Excellent communication skills', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Hadoop: 6 years (Required)', 'Apache Spark, Scala: 3 years (Required)', 'Fully Remote']",2020-12-30 22:11:28
"Data Engineer - Sqoop, Cloud, strong in SQL queries",Springhead Technologies,N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL: 10 years (Required)Python: 3 years (Required)', '8 hour shift', 'SQL: 10 years (Required)', 'Python: 3 years (Required)', 'Sqoop: 1 year (Required)', 'No', 'Yes', 'Remote interview process']",2020-12-30 22:11:28
"Associate, Big Data Engineer",KPMG,"4 out of 5 from 6,759 employee ratings","New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Work in cross-disciplinary teams with KPMG industry specialists, data scientists, and software engineers to gauge client needs for consuming analytics, understanding user profiles, competencies, and priorities', 'Utilize technical and industry knowledge to identify complex client issues and build long-term business relationships with key executives through engagement delivery and networking in professional organizations', 'Utilize analytics to explore data, and identify key trends and insights from multi-faceted, and high-dimensional data, and work with data scientists to create diagnostic, predictive, and prescriptive insights', 'Implement visualizations that meet client visualization needs, considering composition, color, texture, and optimizing the depth and information density for the target user', 'Explore a variety of visualization methodologies from Data Discovery (such as Tableau, Qlikview)', 'A minimum of one year of experience in Informatics, Data Science, Computer Science, Business Intelligence or a similar field, with a minimum of one year of professional experience', 'Fluency in several programming languages such as Python, C#, Ruby, Java, or Javascript, with the ability to pick up new languages and technologies quickly', 'Ability to perform data tasks, working with a variety of SQL, NoSQL, and HDFS data stores, and preparing data for visualization', 'Experience with one or more of the following: data discovery software (such as Tableau or Qlikview), cluster computing framework (Hadoop- Pig/Hive/Sqoop or Spark ), or SQL Database management (MySQL, PostgreSQL)', 'Solid understanding of visual composition and visualizations; familiarity with ethnographic research preferred', 'Travel may be up to 80-100%', 'Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future']",2020-12-30 22:11:28
Data Engineer,"Parallax Volatility Advisers, LP",N/A,"Jersey City, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SqlServer TSQL advanced query semantics', 'SqlServer TSQL limited writing of stored procedures, functions, table and index definitions.', 'Powershell and Python scripting, ability to troubleshoot, create, and maintain scripts.', 'SqlServer Integration Services data feed package troubleshooting', 'Unix shell scripting', 'Source code management with Subversion and Git', 'Basic Sqlagent and Bamboo job management', ""Bachelor's Degree in Computer Science, Data Science, Science."", ""Minimum of 3 years' experience in relevant field to Data Quality Management; preferably within a hedge fund or related firm"", 'Must be a U.S citizen or authorized to work in the U.S on a permanent basis', 'SQL Server', 'Suberversion/GIT', 'Bamboo', 'Powershell', 'Python', 'Knowledge of hedge fund data operations and hedge fund trading products (options, futures, stocks, swaps)', 'Clear and effective written and spoken communications', 'External vendor and support channel handling', 'Ability to operate and prioritize own assignments', 'Ability to respond to operational interruptions']",2020-12-30 22:11:28
Data Analytic Engineer,FacilityConneX,N/A,"Nashua, NH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:11:28
Data Engineer,The Knot Worldwide,3.3 out of 5 from 7 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Extract, load and transform data from The Knot Worldwide and other sources to our DataWarehouse for the consumption of our end users.', 'Design and develop solutions for integration between disparate systems which include cloud-based sources such as Salesforce and Salesforce Marketing Cloud.', 'Maintaining current ETL processes and resolve daily ETL job failures as they arise.', 'Resolve Ad-hoc data questions from the organization in a timely and accurate manner.', 'Continuous improvement on current ETL processes to ensure accuracy, timeliness and scalability as data volumes grow.', 'Document built processes and data content and publish needed information to our data dictionary', ""A Bachelor's Degree in Computer Science, Information Systems, or a related field is preferred. An advanced degree or professional licensing is a plus."", 'Programming experience and a demonstrated interest in statistical analysis, informatics, analytics, or business intelligence', 'Minimum of 5+ years experience with SQL and Data Warehouse development and ETL', 'Hands-on experience with at least one of the following Databases (MYSQL, PostgreSQL, Snowflake, MSSQL, Redshift)', 'Scripting skills using shell, python or ruby', 'Experience with standard warehousing concepts like Data Marts and Dimensional Modeling', 'Excellent communication skills, both verbal and written.', 'Present ideas, expectations and information in a concise, well-organized way.', 'Conduct research and make recommendations on BI requirements, products, and services.', 'Manage time well, correctly prioritizing tasks.', 'Knowledge of data warehouse schema design and architecture.', 'Experience with at least one Business Intelligence tool such as Qlik and Metabase', 'Experience with Big Data Solutions such as Snowflake, Redshift, Google BigQuery or Hadoop.', 'Experience with ETL tools such as Matillion, Boomi, Informatica, SSIS,, etc.', 'Programming experience with Ruby, Python, Shell Scripting.', 'You Dream Big. You iterate and experiment to drive innovation.', 'You Love Our Users. You keep our global community at the center of everything you do.', 'You Do the Right Thing. You strengthen your team through respect, fairness, and inclusion.', 'You Hustle Every Day. You favor urgency and own your outcomes.', 'You Win Together. People are at the heart of our success and you play as a team.']",2020-12-30 22:11:28
New Graduate Roles,Lynk,5 out of 5 from 4 employee ratings,"Falls Church, VA 22041","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Completed at least a bachelor's degree (or better) in a STEM- related"", 'Strong interpersonal skills and ability to work effectively in a team environment, accomplishing tasks with limited resources at a rapid', 'Proficiency skill level using Windows and Linux OS, and proficiency with some other technical software package or programming', 'Hands-on experience with lab research, engineering project teams, or prior relevant internship or work']",2020-12-30 22:11:28
Full Time Opportunities for Students and Recent Graduates - Software Engineer,Microsoft,"4.2 out of 5 from 7,020 employee ratings","Redmond, WA 98052","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""A bachelor's or master's degree in engineering, computer science or related field 12 months of graduation or graduated within the last 12 months."", 'A year or two of experience programming in C++, Java or other computer programming languages preferred.', 'Ability to demonstrate understanding of algorithms, data structures and other systems architecture factors that affect code quality, performance and customer experience', 'Some experience building software outside of the classroom environment like an internship, hackathon, research project or related experience preferred', 'Demonstrated skill in time management and completing software projects in a cooperative team environment']",2020-12-30 22:11:28
Data Engineer,Arcadia,3.8 out of 5 from 175 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Manage data pipelines from disparate sources, standardizing and feeding them into our centralized data warehouse', 'Work with both the Engineering and Analytics & Data Science teams to optimize data flow and queries for large data sets to improve scalability', 'Sync data across internal and external systems, such as marketing and sales automation tools, to enable key stakeholders to build best-in-class experiences', 'Support ongoing efforts to establish and enforce best practices on data quality, use, and security across the company', '3+ years combined programming and/or DevOps experience', ""Significant experience with and a strong understanding of languages/tools relevant to engineering & data teams' work"", 'Experience in one or more of the following languages: Python, Java, Ruby, Javascript', 'Advanced knowledge of algorithms, data structures, and relational algebra', 'Database management experience with PostgreSQL, RDS, or Redshift', 'Data extraction experience with a strong understanding of thread-based and event-based paradigms', 'Extensive experience in managing data pipelines, schemas, and storage for multiple systems for multiple teams', 'Strong communication skills', 'Undergraduate and/or graduate degree in math, statistics, engineering, computer science, or related technical field', 'Experience in predictive modeling and statistical analysis', 'Experience with enterprise database interfaces and messaging APIs', 'Experience with Amazon Web Services (AWS) or other cloud infrastructure platforms', 'Experience with entity resolution at scale', 'Experience in the energy sector', 'Market-based compensation (salary + equity)', 'Healthcare, dental, vision, 401(k) and commuter benefits', 'Paid Time Off (holidays, vacation, professional development, volunteer, parental leave)', 'A supportive engineering culture that values diversity, empathy, teamwork, trust, and efficiency', 'Professional development opportunities', 'All-company lunches', 'Free clean energy', 'A chance to decarbonize and disrupt the energy sector']",2020-12-30 22:11:28
Data Engineer,Prutech Solutions,3.8 out of 5 from 11 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:o\tAdvanced reporting in SSRS and Power BI, 6 years (Preferred)Development and administration of SQL , 6 years (Preferred)o\tC# programming and debugging , 6 years (Preferred)', ""Education:Bachelor's (Preferred)"", 'Work authorization:United States (Preferred)', ""Bachelor's degree in Computer Science, Information Systems, or related fields."", '5+ years of development and administration experience, including advanced TSQL, Stored Procedure, complex queries built from scratch, experience with very large databases and data warehousing/data lakes; performance tuning and query optimization. Must be aware of modern SQL techniques.', 'Writing advanced SQL queries to generate reports, maintain data warehouse, and performing data analysis.', 'Advanced reporting in SSRS and Power BI, including charts, drill through and sub- reports.', 'Advanced data warehousing techniques using DAX.', 'Experience with SQL Server encryption is a plus.', 'Deep understanding of Microsoft Dynamics CRM modules and underlying data model.', 'Experience in designing custom workflow activities using the Dynamics CRM SDK.', 'C# programming and debugging skills are a plus.', 'Python, PowerShell and UiPath to write ETL processes and automate repetitively tasks.', 'Pulling data from various vendor applications and feeding into the data warehouse.', 'Create front-end applications/workflows to solve immediate as well as long-term requirements.', 'Deep knowledge of API (REST, SOAP), API management, and microservices.', 'Experience with developing user authentication and knowledge of security compliance is a plus.', 'Strong analytical and problem-solving skills.', 'Ability to work creatively in a problem-solving environment.', 'Ability to articulate technical issues to a non-technical audience.', 'Ability to present effectively to an audience of individuals both up and down the organization structure.', 'Participate in code reviews, developer meetings, stand-up meetings, and relevant technology business partner meetings.', 'Provide second level IT support to the user community for various custom and vendor applications.', 'Provide technical assistance to the Helpdesk team in analyzing, troubleshooting, and correcting issues affecting the customer experience or business operations.', 'Recommend and implement code changes that improve stability, performance, and support the scalability necessary to support future business growth. Work closely with team members to test and launch new features.', 'Responsible for installing, customizing, upgrading, testing, and deploying third-party vendor applications.', 'Stay abreast of data privacy & security regulations and ensure compliance with PII, HIPAA, GDPR, PCI, and regulations governing patient confidentiality and data security.', 'Willing to work outside of normal business hours when necessary.', 'Information Security minded.', 'Ability to conduct research into a wide range of issues as required.', 'Ability to absorb and retain information quickly.', 'Exceptional written and oral communication skills.', 'Ability to present ideas in user-friendly language.', 'Exceptional interpersonal skills, with a focus on rapport-building, listening, and questioning skills.', 'Highly self-motivated and detail-oriented.', 'Proven analytical and problem-solving abilities.', 'Ability to effectively prioritize and execute tasks in a high-pressure environment.', 'Experience working in a team-oriented, collaborative environment.', 'Shows initiative and follow-up to ensure successful results.', '401(k)', '8 hour shift', 'Monday to Friday', 'o Advanced reporting in SSRS and Power BI: 6 years (Preferred)', 'Development and administration of SQL : 6 years (Preferred)', 'o C# programming and debugging : 6 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Preferred)', 'Are you available for W2 hiring?']",2020-12-30 22:11:28
Senior Software Engineer - Data (Remote),PlaceIQ,3.9 out of 5 from 11 employee ratings,"New York, NY 10011","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, and develop data-products, with adjoining data-pipelines, engineered to high standards of performance, efficiency, and reliability', 'Generate and implement Machine-Learning algorithms, with Data-Scientists', 'Formulate data-management strategy and data-warehouse architecture to provide single source-of-truth datasets for internal and external clients', 'Ensure data quality, with testing on a product and pipeline level', 'Implement automation of the data pipelines & software releases', 'Collaborate with internal teams to gather requirements for data-products', 'Mentor data engineers to provide technical guidance', 'Provide some ongoing support, monitoring, and maintenance of deployed products', 'Professional development experience with Apache Spark in a Hadoop Ecosystem, preferably with Scala.', 'Strong experience in building ETL/Data-pipelines.', 'Background with Data-Modeling, Data-Access and Data-Warehouse technologies.', 'Understanding of Machine-Learning algorithms, and computational modeling', 'Experience with distributed databases e.g.: Hbase, Cassandra, MongoDB with streaming platforms e.g.: Kafka, RabbitMQ, and good-old RDBMS e.g.: PostgreSQL.', 'Experience in UNIX/Linux environments with Bash/Python scripting.', 'Production Continuous-Integration experience with Jenkins, and building with Maven / Ant / SBT.', 'Exposure to InfluxDB, visualization with Grafana, and with schedulers e.g., Azkaban, Oozie and Airflow is a Plus.', 'Experience in an Agile Scrum software development environment.', 'BA/BS/MS in Computer Science/Engineering or related technical field.']",2020-12-30 22:13:14
Data Engineer,Benefits Data Trust,3.2 out of 5 from 23 employee ratings,Pennsylvania,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build out our new GCP data platform and collaborate on architectural patterns for it with the Data Engineering team', 'Support the development of machine learning models with productionizing, monitoring and alerting tools', 'Write, update, and maintain ETL jobs across our data pipelines (mostly in Airflow)', 'Implement continuous improvements using our existing tools/technologies, which include SQL, Airflow, Python, Docker/Kubernetes, and others such as Terraform and Apache Beam. May also be expected to research and select other tools when the situation demands', 'Collaborate with internal customers to identify ongoing platform improvements (teams including Analytics, Projects, Policy, Software Engineering, and others throughout the organization)', ""Consult to software engineers on data-related changes to BDT's suite of software applications, including schema/model design, table structure, and data collection"", 'Engage with colleagues and collaborators using curiosity, critical thinking, a drive to completion, empathy, and a focus on impact', 'Follow existing data access and performance design standards for the data platform, software engineering, and all products and services accessing BDT information', 'Communication and Relationship-building – with technical peers and some stakeholders', 'Cloud-based Solution Implementation, of data platforms and infrastructure, including event-driven architectures, microservices and pattern design, supporting compliance and regulated environments (including PII and PHI)', 'Workflow and pipeline development to ensure reliability, availability, and consistency', 'Systems Engineering – on-system service management, typically in *nix environments', 'Data Modeling and Warehousing – proficient understanding of relational data structures and schemas; some familiarity with semi-structured, unstructured (big data) schemas', 'Automation, monitoring, and alerting – creating these tools based on existing designs and frameworks; resolving bugs and issues', 'Cloud engineering – working towards certification on any of the major hyperscale cloud platforms', 'Data Encapsulation & Transfer methodologies – understands standards for file formats and transfer methods', 'Also interested in relevant experience including:', 'o Experience with BI implementations/uplifts (we currently use Looker) and/or Data Governance models and methods', 'o Machine learning techniques, productionizing machine learning models, and/or creating models']",2020-12-30 22:13:14
Data Engineer,BRAZE,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Own and audit the technical implementation of Braze @ Braze, our instance of the Braze software which runs on our own tool.', 'Build, enhance, and maintain data pipelines which ensure synchronicity between Braze @ Braze, Salesforce, the Braze backend, and other tools like Demandbase, Marketo, etc.', 'Partner with the Customer Marketing team to drive adoption of advanced technical marketing techniques like using AMP for Email, or building API endpoints which can furnish personalized content in real-time to our customers via Connected Content.', 'Collaborate with Product, Customer Marketing, and Product Marketing to instrument new events and attributes in Braze @ Braze in a consistent, documented, and reliable manner.', '3+ years of engineering experience with a strong track record of success.', 'Pride yourself on writing elegant, maintainable code.', 'Comfortable working in a large code-base with many stakeholders across multiple departments and functions.', 'Able to learn new technologies quickly and act independently', 'Have a user-centric attitude and care deeply about CX (Customer Experience)', 'Familiarity with the following technologies is a strong plus (Braze, JS, Ruby, Rails, MongoDB, React, HTML, CSS)', 'Degree in computer science or equivalent experience.', 'Competitive compensation that includes equity', 'Flexible time off policy to balance your work and life, including paid parental leave', 'Free daily lunch in the office, including snacks and beverages', 'Competitive medical, dental, and vision coverage for you and your dependents', 'Collaborative, transparent, and fun loving office culture']",2020-12-30 22:13:14
Software and Data Engineer Intern,ViaSat,3.8 out of 5 from 270 employee ratings,"Germantown, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data analytics & cloud application engineering', 'System infrastructure development; scripting, automation, data visualization & dashboarding', 'Network function virtualization, orchestration', 'Virtualized networking and service chaining', 'Distributed enterprise software applications', 'Cybersecurity software & systems engineering', 'Web & mobile application engineering', ""Bachelor's degree in Computer Science, Computer Engineering, Electrical Engineering, Physics, Mathematics, and/or a related field"", 'Exposure or desire to work with Cloud Technology, Automation, Machine Learning, Big Data, Full-Stack, Embedded, Apps, or Front-End', 'Previous internship experience in software development and/or test related areas', 'Knowledge of TCP/IP network fundamentals', 'Previous experience coding in Go, Java, Python, JavaScript, Hadoop, Spark, SQL, Postrgres, and/or C/C++']",2020-12-30 22:13:14
Python Developer Intern,OXO Solutions,N/A,"Ruby, SC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:13:14
Data Scientist,Ampcontrol.io,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'High school or equivalent (Preferred)Python: 2 years (Preferred)', ""You'll be responsible for building, maintaining and improving our optimization algorithms, models, and simulation tools"", 'Develop our ML-algorithms in Python, with an eye on performance and scalability', 'Work with software engineers to build a stable and powerful ML-applications for real-time optimization', 'Use our own simulation tools build, test and use new algorithms', 'Monitor and evaluate the performance of algorithms', 'Write clean and easily maintainable code for our optimization engine', 'Work very closely with the team on product planning', 'Contribute to the improvement of our software architecture and development process', 'More than 2 years of professional experience in Machine Learning and Data Science', 'Experience with deploying algorithms in production systems', 'Experience in data science tools such as NumPy, Pandas, TensorFlow, Gekko, and similar', 'Working knowledge of advanced optimization algorithms and simulation approaches', 'A good understanding in energy technologies and markets is a plus', 'Fluency in English for verbal and written communication is required', 'Comfortable working remotely', 'Motivation to work on electric vehicles and sustainability', 'The electric vehicle charging domain', 'Time-series databases', 'Upcoming technologies, software libraries and cloud solutions and be eager to offer new solutions', 'Working with software developers who need to translate your algorithms to production-ready, thoroughly tested and monitored solutions', 'What surprising thing have you learned in the last few months?', ""What is a project you're most proud of and why?"", 'What is your favorite Data Science book or online resource?', 'Monday to Friday', 'High school or equivalent (Preferred)', 'applied mathematics: 2 years (Preferred)', 'Python: 2 years (Preferred)', 'Fully Remote', 'Dependable -- more reliable than spontaneous', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'High stress tolerance -- thrives in a high-pressure environment', 'https://www.ampcontrol.io/', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:13:14
Data Engineer,GSK,"4.2 out of 5 from 4,430 employee ratings","Collegeville, PA 19426","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with data teams to implement pipeline designs to support R&D strategy and conceptual data flows', 'Partner with the metadata leads to translate conceptual data models into physical database/tables optimized for data analytics in RDIP using established environments and tools', 'Assist the design, build, test and maintenance of data acquisition and processing pipelines including but not limited to the creation/maintenance of appropriate artifacts', 'Ensure the preservation of data integrity from source to target state including but not limited to the acquisition of appropriate metadata and the incorporation of appropriate QC checks into the pipelines', 'Support the use and growth of the Data Engineering DataOps environment, influence strategy and roadmap for the curation toolset, work with R&D and Tech to prioritize enhancements', 'Provide Tier 3 support for production pipelines', 'Support DCS and broader R&D in self-service/exploratory efforts', 'Influence vendor roadmaps, work with R&D and Tech to prioritize DataOps enhancements, and onboard these tools or enhancements', 'Ensure the quality consistency and availability of guidance documentation of end users of the tools to support high quality outputs', 'Extend current pipelines to support clinical biomarkers', 'Assess GxP readiness as it related to the upstream data pipelines and develop a plan for addressing any gaps', 'Provide Tier 3 support/administration of DNA Nexus bioinformatics system', 'This position requires a Computer Science, Bioinformatics, or related degree; 5+ years’ experience in data movement, data wrangling and delivery of data or analytics pipelines', 'Experience implementing and maintaining, data or analytic pipelines.', 'Experience with Big Data technologies, Cloud-based offerings (Microsoft Azure, GCP, AWS, etc), and corresponding tools.', 'Experience with open source software, bioinformatics tools and languages such as SQL, R, Perl, Python, Java, and ETL tools.', 'Experience with data movement and management in the Pharmaceutical industry or related scientific fields.', 'Experience with the core components of the Hadoop stack including HDFS and Apache Spark, ideally a Cloudera based stack', 'Background and experience in LIMS systems, Next Generation Sequencing (NGS) workflows, Cloud computing and HPC systems.', 'Understanding of diverse ‘omic data types including RNA-Seq, DNA-Seq, Chip-Seq, WES, WGS, ATAC-seq, microbiome, proteomic, metabolomic data etc. from different sources.', 'Familiarity with data mining, machine learning and artificial intelligence techniques', 'Proven ability to contribute to development projects.', 'Strong interpersonal skills and effective communication of complex concepts to stake holders with wide range of expertise.', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.', 'Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.', 'Continuously looking for opportunities to learn, build skills and share learning.', 'Sustaining energy and well-being.', 'Building strong relationships and collaboration, honest and open conversations.', 'Budgeting and cost-consciousness', 'LI-GSK']",2020-12-30 22:13:14
Data Engineer,Luxoft,4.4 out of 5 from 212 employee ratings,"New York, NY 10006","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:13:14
Bioinformatics Data Engineer / Programmer (Contract),"GRAIL, Inc.",N/A,"Menlo Park, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Contribute to derived clinical feature workflows for clinical study data, working from raw data extracts, through data dissemination with a strong focus on automation and data QC.', 'Assist in developing and managing interactive data visualization and analytics tools for reporting.', 'Play a key role in understanding user requirements, implementing systems and authoring procedures related to system use.', 'Maintain data integrity and quality throughout the data lifecycle, including ensuring clinical study-related blinding where appropriate.', 'BS or MS in quantitative scientific fields (computer science, engineering, mathematics, statistics, bioinformatics, etc.).', 'Experience with R or Python programming.', 'Experience with CDISC data models is a plus.', 'Experience with Amazon Web Services is a plus.', 'Experience with cross-functional collaboration while ensuring data quality and commitment to analysis reproducibility.', 'Experience with data visualization and analytics tools.', 'Excellent interpersonal communication (written and verbal) and organizational skills.', 'Excellent team player with a demonstrated track record of success in a cross-functional team environment.', 'Consistent commitment to delivering on team goals with a sense of shared urgency.']",2020-12-30 22:13:14
Data Engineer,Baer Group,N/A,"Irvine, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Candidates should be well versed in technologies like Python code, JSON, Azure Data Factory, SQL, etc and others. From a SQL perspective, they will need to be able to generate queries.', 'Strong communication skills and collaboration skills required.', 'The ability to be flexible and work within a team is important.']",2020-12-30 22:13:14
Data Engineer,Inspire,3.4 out of 5 from 39 employee ratings,"Philadelphia, PA 19103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data querying and processing in SQL', 'Data processing and task management in Python', 'Communication skills, and ability to translate between the domains of business problems and technical implementations', 'Team-oriented development: building modular & re-usable tools, writing maintainable code, owning technical and business documentation', 'Refactor operating model code into scalable, transparent processes leveraging Airflow and DBT as core frameworks', ""Expand the capabilities of Inspire's core data platform to support incremental product lines and product features"", 'Partner with Analytics to systematize and scale high-integrity value-oriented analysis', 'Partner with Sales, Operations, and other business stakeholders to design and deliver new data-driven integrations', 'Partner with other engineering teams to guide refactors of existing data infrastructure to improve data quality and features.', ""Cultivated familiarity with Inspire's frameworks & operating model"", 'Delivery of high-quality pull requests in DBT and Airflow, evidencing strong code standards & testing practices', 'Comfort with self-directed project management: requires minimal oversight to assess a problem, formulate a solution, deliver code, and document changes.', 'Positive interactions with department stakeholders: can offer guidance and input that creates business value for non-technical personnel.', 'Technical competency - comfort on a command line, a good grasp on the fundamentals of programming, a general understanding of Git/source control, and a willingness to read the docs, search stack overflow, and test it until it works', ""Problem-Solving Mentality - gets excited about digging into complexity, wants to ask questions and learn more, and isn't put off by problems they've never been explicitly told how to solve. Especially troubleshooting: ability to break down a chain of steps to narrow and locate a problem."", 'Number Sense - Strong background in mathematics or physics, comfort with quantitative measurement and estimation. Ability to work in establishing boundaries and orders-of-magnitude to make informed judgements without fussing over exactitude.', 'Big-picture awareness - Understanding of the importance of context, and willingness to understand the business problem in addition to the technical one. Focus on people & impact.', 'Must Have1 or more years in a data analytics, engineering or science roleStrong SQL experience working with large datasets, ideally in cloud-based data warehousesSoftware development in Python3Experience automating data processing, cleaning and/or preparationSoftware development lifecycle familiarity in GitHub (ie environment management, testing, deployment)', 'Nice to HaveExperience with key frameworks: Snowflake, Apache Airflow, dbt, AWS services, Docker, KubernetesExperience at a similar scale of data processing (Multi-TB/billions of rows)Work with real-time event stream dataContextual work in the energy industryData consultancy experience a plusProven ability to break down a chain of steps to narrow and locate a problemStrategic approach to problem solving and understand the why behind a problem']",2020-12-30 22:13:14
Data Engineer,Prutech Solutions,3.8 out of 5 from 11 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:o\tAdvanced reporting in SSRS and Power BI, 6 years (Preferred)Development and administration of SQL , 6 years (Preferred)o\tC# programming and debugging , 6 years (Preferred)', ""Education:Bachelor's (Preferred)"", 'Work authorization:United States (Preferred)', ""Bachelor's degree in Computer Science, Information Systems, or related fields."", '5+ years of development and administration experience, including advanced TSQL, Stored Procedure, complex queries built from scratch, experience with very large databases and data warehousing/data lakes; performance tuning and query optimization. Must be aware of modern SQL techniques.', 'Writing advanced SQL queries to generate reports, maintain data warehouse, and performing data analysis.', 'Advanced reporting in SSRS and Power BI, including charts, drill through and sub- reports.', 'Advanced data warehousing techniques using DAX.', 'Experience with SQL Server encryption is a plus.', 'Deep understanding of Microsoft Dynamics CRM modules and underlying data model.', 'Experience in designing custom workflow activities using the Dynamics CRM SDK.', 'C# programming and debugging skills are a plus.', 'Python, PowerShell and UiPath to write ETL processes and automate repetitively tasks.', 'Pulling data from various vendor applications and feeding into the data warehouse.', 'Create front-end applications/workflows to solve immediate as well as long-term requirements.', 'Deep knowledge of API (REST, SOAP), API management, and microservices.', 'Experience with developing user authentication and knowledge of security compliance is a plus.', 'Strong analytical and problem-solving skills.', 'Ability to work creatively in a problem-solving environment.', 'Ability to articulate technical issues to a non-technical audience.', 'Ability to present effectively to an audience of individuals both up and down the organization structure.', 'Participate in code reviews, developer meetings, stand-up meetings, and relevant technology business partner meetings.', 'Provide second level IT support to the user community for various custom and vendor applications.', 'Provide technical assistance to the Helpdesk team in analyzing, troubleshooting, and correcting issues affecting the customer experience or business operations.', 'Recommend and implement code changes that improve stability, performance, and support the scalability necessary to support future business growth. Work closely with team members to test and launch new features.', 'Responsible for installing, customizing, upgrading, testing, and deploying third-party vendor applications.', 'Stay abreast of data privacy & security regulations and ensure compliance with PII, HIPAA, GDPR, PCI, and regulations governing patient confidentiality and data security.', 'Willing to work outside of normal business hours when necessary.', 'Information Security minded.', 'Ability to conduct research into a wide range of issues as required.', 'Ability to absorb and retain information quickly.', 'Exceptional written and oral communication skills.', 'Ability to present ideas in user-friendly language.', 'Exceptional interpersonal skills, with a focus on rapport-building, listening, and questioning skills.', 'Highly self-motivated and detail-oriented.', 'Proven analytical and problem-solving abilities.', 'Ability to effectively prioritize and execute tasks in a high-pressure environment.', 'Experience working in a team-oriented, collaborative environment.', 'Shows initiative and follow-up to ensure successful results.', '401(k)', '8 hour shift', 'Monday to Friday', 'o Advanced reporting in SSRS and Power BI: 6 years (Preferred)', 'Development and administration of SQL : 6 years (Preferred)', 'o C# programming and debugging : 6 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Preferred)', 'Are you available for W2 hiring?']",2020-12-30 22:13:14
Software Engineer: Distributed Data Systems,Pinecone,3 out of 5 from 3 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'At least 4 years of experience as a Software Engineer', 'Extensive experience in database internals', 'Experience in building web-scale services and distributed systems', 'Proficiency in at least one scripting language, such as Python', 'Proficiency in at least one compiled language, such as C++', 'Some experience with Information Retrieval and Search']",2020-12-30 22:13:14
Data Scientist Intern (Summer 2021),BCG Digital Ventures,4.3 out of 5 from 10 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Demonstrate and communicate a passion about building the data foundation, products and capabilities that drive business growth', 'Build innovative data products: e.g., real-time services, such as personalization; customer segmentation; unified profile; commerce graph; as well as a big data platforms on Hadoop and Spark with real-time data streaming (e.g. Kinesis) and analysis', 'Conceptualize, define, and oversee regular updates around key product and business metrics as the company’s challenges and data evolve', 'Execute descriptive analyses, ranging from identifying product opportunities to understanding user behavior', 'Cultivate strong collaborations with product, engineering and senior stakeholders', 'Share your technical solutions and product ideas with the BCG DV team through design reviews, pair programming, code reviews, and tech talks', 'Balance competing priorities while adhering to deadlines and aligning resources with value demands', 'Active enrollment in a BS, MS or PhD program in Computer Science, Engineering or a related subject from an accredited University', '3.5 GPA or higher', 'Ability to plan, prioritize and organize work effectively and efficiently within a team', 'Experience with statistical methods such as multivariate analysis, linear models, quantitative approaches, and sampling methods', 'Experience with a programming language like Python, Java, R and C++', 'Ability to translate data insights into product decisions', 'Enthusiasm for learning new concepts and diving deep into data analysis', 'Workflow flexibility and strong teamwork skills']",2020-12-30 22:13:14
Data Engineer,Evolytics,N/A,"Kansas City, MO 64152","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create, prepare, and maintain databases and tables to power reports, dashboards, predictive models, and downstream analysis.', 'Plan, create, and fine-tune data pipelines and automation workflows.', 'Design and build data infrastructure that enables actionable insights used to optimize digital marketing performance such as online advertising, social media marketing, websites, and mobile experiences.', 'Develop processes and procedures for ingesting data from disparate sources.', 'Build and maintain database architecture, including fine tuning and optimizing queries, data pipelines, and automation workflows.', 'Create and maintain customized SQL queries to build reporting data structures.', 'Develop and implement data models necessary to build analytic solutions as defined by stakeholder requirements.', 'Validate data to determine and document any gaps between available data and requirements for reporting outputs and downstream analysis.', 'Manage multiple client requests and detailed project activities at any one time to ensure accurate, timely and efficient reporting and analysis deliverables.', 'SQL skills are critical for this Data Engineer role. Consideration will be given to qualified candidates with varying levels of experience, with compensation commensurate with experience.', 'Working knowledge in at least one of the following scripting languages: Python, Bash, Java, Scala, R, Perl, Node.js', 'Linux command line', 'Advanced SQL', 'Working with a leading analytics or relational database system, such as Redshift, Vertica, BigQuery, PostgreSQL, or MySQL', 'Developing cloud-based data solutions on Snowflake, AWS, Azure, or Google Cloud', 'Working in big data solutions such as Hadoop, Hive, or Spark', 'Using change release processes and tools such as git', 'Developing and implementing data transformation via ETL processes and data pipelines', 'Legally authorized to work in the United States without company sponsorship now or in the future', 'Minimum of a Bachelor’s degree in Computer Science, Information Systems, Business, Marketing, or a related discipline', 'Working knowledge in any of the following database systems will be a plus: NoSQL, Mongo DB, Couch DB', 'Working with clickstream web analytics tools such as Adobe Analytics (Omniture SiteCatalyst), Google Analytics, or working knowledge of the field of web analytics', 'Knowledge of commonly-used digital metrics, analytic concepts, and online marketing channel best practices', 'Working with data analysis tools such as SAS, Tableau, Google Data Studio, or Power BI', 'Knowledge of business intelligence methodologies and tools', 'Proficiency in spreadsheet and presentation technologies such as Excel, PowerPoint, or Google Docs', 'Creating and preparing databases and tables for predictive modeling and data science applications', 'Relaxed work environment: casual dress code, pool/ping pong table, treadmill desks', 'Collaboration-oriented office space with plenty of room for working sessions or potlucks', 'Awesome team building events like a day at the Royals game or mini-golf with margaritas', 'Food…weekly lunches, daily snacks, fruits, beverages, unlimited coffee', 'Learning opportunities: company-provided training, conferences and super-smart co-workers', 'Competitive Benefits Package including Health, Dental, Vision, and Life Insurance', 'Great Compensation Package with Paid Time Off, Performance Bonuses and IRA Matching Contributions', 'Opportunity to work alongside amazingly fun people who are passionate about delivering awesome in everything they do.', 'Fortune’s Best Small and Medium Workplaces in 2020: #25 in US', 'Honored for Best Places to Work in 2020 by the Kansas City Business Journal', 'Recognized as a Great Place to Work in 2020', 'Voted Coolest Office Space (Small Business) by the Kansas City Business Journal', 'Named Top Analytics Agency by the Digital Analytics Association in 2018 and again in 2020']",2020-12-30 22:13:14
Data Analyst (1-2),Function of Beauty,2.2 out of 5 from 22 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with complex datasets across our rich and varied platforms to perform analysis and design predictive models.', 'Use data to discover business insights, uncover new opportunities, provide recommendations and influence decisions.', 'Deepen our understanding of pattern/trends in customer behavior, support customer experience optimization and improve both acquisition and retention.', 'Work cross-functionally to ensure access to useful data and drive value creation.', 'Promote a data-driven organization and empower teams with actionable data and with automated and intuitive KPI dashboards.', 'Support our A/B testing activities in conjunction with the Engineering team.', 'Constantly look for improvements in tools, data sources, data quality, and analytic techniques; build structure and process around data science initiatives and requests.', ""You have a bachelor's degree in a quantitative field (math, data science, computer science, economics). Graduate degree is a plus."", 'You are an expert with MySQL and have experience with industry leading business intelligence tools, such as Mode, Periscope, Tableau, or Looker. Knowledge of Python is a plus.', 'You have experience with creating and managing data warehouses, as well as the ETL/ELT work flow.', 'You have 1 to 2 years of experience in solving business problems by leveraging large datasets. Direct to Consumer start-up experience a plus.', 'You have proven ability to think creatively, solve strategic problems, learn quickly, work independently, handle ambiguity and clearly communicate results in a business-oriented manner.', 'Full Time, Exempt']",2020-12-30 22:14:55
Data Entry Clerk 1,TriOpz,N/A,"Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Candidate have to come to the office to get their computer and for some training when they start. Then the position will be remote until the team returns to the office post COVID. Then the candidate will be required to work from the office when everyone returns. LOCAL CANDIDATES ONLY.']",2020-12-30 22:14:55
Data Engineer,Kharon,N/A,"Los Angeles, CA 90067","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create secure, resilient, integrated software, working with a variety of data sources and consumers in a complex, distributed environment', 'Integrate and extend data sets in multiple formats and environments', 'Integrate and produce data tracking and event metrics', 'Collaborate with Operational Engineers, Data Engineers, Search Engineers and', 'Data Scientists, as well as Product and Research teams', '4+ years experience as a professional software engineer', 'BS/MS in Computer Science or equivalent experience in completed online coursework', 'Strong skills in Python, Java or Go', 'Experience in multiple languages and stacks, using Procedural and Functional programming', 'Experience implementing best practices in use of data structures and design patterns', 'Understanding of algorithmic complexity analysis', 'Deploying and troubleshooting code in a distributed cloud environment', 'API development and integration', 'Familiarity with GraphQL', 'SQL querying and optimization using DDL and DML', 'Experience with at least one NoSQL database', 'Schema design and mapping', 'Development of data pipelines using event or message driven architecture on Kinesis, SQS, Kafka, RabbitMQ or similar', 'Experience with one or more of the following technologies:', 'Neo4j', 'Kubernetes', 'Elasticsearch', 'Spark', 'Ontological graph composition and transformation']",2020-12-30 22:14:55
Big Data Engineer,AGM Tech Solutions,N/A,"Pasadena, CA 91101","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""SQL: 5 years (Required)ETL: 3 years (Required)US work authorization (Required)Bachelor's (Preferred)"", 'Participate in the design and development of data management, business intelligence and analytics projects to drive strategic decisions through data driven actionable metrics and insights.', 'Assist in evaluating and selecting the best technologies and tools to support the data mission.', 'Support development and production issues impacting our clients and operations.', 'Monitor and improve data and BI processes to meet firm SLAs and increase efficiency.', 'Help define user stories as a part of the BI scrum team by analyzing business requirements, defining technical specifications and sizing the development effort.', 'Leverage technology capabilities and standards while working with technology system owners to identify appropriate data sources, define and build required data transformation logic.', 'Perform detailed data analysis to derive insights and deliver operational mechanism such as dashboards or ad-hoc reports.', 'Minimum of 5 years of hands-on experience with SQL Server, Oracle and SSIS', 'Minimum of 3 years of hands-on experience with data engineering including ETL and data warehousing', 'Minimum of 1 year of hands-on experience with building semantic-layer business intelligence solutions including metrics, dashboards and data visualization', ""Bachelor's Degree or equivalent in Computer Science or Information Management"", 'Working experience with Tableau, Power BI and Alteryx', 'Working experience in the HCM or financial industry', 'Working experience with large or medium size companies', 'Expert problem solving skills to rapidly create ad-hoc queries to answer complex business questions or debug data issues', 'Experience developing complex queries against normalized and dimensional data models', 'Ability to work cooperatively as part of a team, as well as independently', 'Excellent verbal and written communication skills', 'Dental insurance', 'Health insurance', '8 hour shift', 'Monday to Friday', 'Pasadena, CA 91101 (Required)', ""Bachelor's (Preferred)"", 'SQL: 5 years (Required)', 'ETL: 3 years (Required)', '5 - 6 months', 'Likely', 'Temporarily due to COVID-19', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:14:55
Data Engineer,FlairTech Solutions LLC,N/A,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Hadoop: 5 years (Preferred)Microsoft SQL Server: 4 years (Preferred)Data warehouse: 5 years (Preferred)Big data: 5 years (Preferred)', 'Good experience in AWS Analytics stack in Spark/Databricks, Kubernetes,', 'Using data engineering tools, languages, frameworks to mine, cleanse and explore data.', 'Fluent in NoSQL & relational based systems.', 'Strong analytical and problem-solving skills.', 'Strong understanding of database technologies and management systems.', 'Strong understanding of cloud-based systems/services.', 'Excellent analytical and problem-solving skills.', 'Aware of the Agile methodologies', 'Ability to work on collaboration with local and external teams', 'Good Verbal and Written Communication skills', 'Monday to Friday', 'Hadoop: 5 years (Preferred)', 'Microsoft SQL Server: 4 years (Preferred)', 'Data warehouse: 5 years (Preferred)', 'Big data: 5 years (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 22:14:55
Software Engineer (New Graduate Summer 2021),Teachable,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Hold a 4 year CS degree and have a strong grasp of CS fundamentals or have graduated from bootcamp', 'Are comfortable with at least one mainstream object-oriented compiled or script language (C++, C#, Java, Ruby, Python, Javascript, etc)', 'Experience with Ruby or React is a plus but not required.', 'Have a foundational understanding of good coding practices that account for readability, testability, and edge cases.', 'Have a foundational understanding of quality and of practices that ensure quality like unit, integration, functional testing, and manual testing or analogous techniques.', 'Value working as part of a team collaborating with other team members', 'Asks clear questions and communicates effectively.', 'Active listener and participant in discussions and contribute ideas to the team.', 'Focus on growth and incorporating feedback from others in order to self-improve.', 'Previous internship experiences in Technology are always a plus.']",2020-12-30 22:14:55
Associate Data Platform Engineer,Madison Square Garden Entertainment,4 out of 5 from 533 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, build, maintain, and optimize components of MSG enterprise data architecture required to meet the analytics and production data needs of the business using a range of tools including Python, Amazon Redshift, Amazon Athena, among others', 'Partner with business stakeholders and Business Intelligence (BI) developers to define data requirements and ensure accuracy of all metrics and master data', 'Develop, implement, and maintain enhancements to core data warehouse applications as requested by our business partners', 'Design, develop, and maintain ETL required to populate dimensional data models', 'Research and respond to complex data inquiries and adhoc data analysis as requested', ""Evaluate and inform selection of technologies to build and optimize MSG's data solutions"", ""Triage and resolve issues across all areas of MSG's data solutions"", '1-2 years data platform development experience', 'Bachelor’s degree in Computer Science, Engineering or related field', 'Experience with ETL, SQL coding plus working knowledge of Big Data solutions and noSQL databases', 'Experience with scripting languages (Python, Perl, Shell)', 'Experience with MPP data warehouse platforms (Redshift, Netezza, Teradata, Greenplum)', 'Experience working in cloud-based environment (AWS, Azure, Google)', 'Experience working with ETL tools & IDE a plus (SAP Data Services, Informatica, Talend, Pentaho, Eclipse)', 'Strong problem solving and analytical skills', 'High level of enthusiasm for building innovative data solutions']",2020-12-30 22:14:55
Data Engineer,MX Technologies Inc.,4.6 out of 5 from 7 employee ratings,"Lehi, UT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Evaluate data pipeline and machine learning pipeline technologies', 'Implement platforms that will simplify and improve the work of data analysts and scientists.', 'Build tools to allow Data Scientists to own machine learning models for the entire life cycle.', 'Be a bridge between Data Scientists and Engineers while effectively communicating business needs.', 'Fundamental understanding of various machine learning techniques.', 'Foundational knowledge in Event Source design and Stream Processing architecture', 'Foundational knowledge in MLOps.', 'Experience in deploying machine learning models to production.', '3 years of professional Python or R experience.', '3 years of professional SQL experience.', 'Strong mathematical background including Statistics.', 'Experience working with non-relational data.', '(Optional) Experience with MLFlow, Ruby/Rails, Postgres, Large data structures (Vertica, Clickhouse, Redshift, ElasticSearch, Hadoop or similar).', 'Thinking like an owner', 'Balancing independent problem solving with collaboration', 'Not being afraid to make mistakes and learn from them', 'Communicating with honesty, candor, and respect', 'Being bold and resourceful', 'Being a passionate and empathetic team member', 'You will build and share products that are making a difference in the lives of others', 'You will collaborate with other brilliant minds', 'You will be rewarded and recognized for your high-caliber work', 'You will enjoy autonomy', 'You will build products that outshine all of our competitors', 'You will be working with established design standards and libraries', 'You will work with a deeply technical engineering team']",2020-12-30 22:14:55
Data Pipeline Engineer,Capgemini,"3.8 out of 5 from 8,123 employee ratings","Oaks, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience in design, perform POC where needed and develop enterprise’s Apache Kafka Distributed Messaging and Integration .', 'Experience in Confluent kafka environment (Kafka Cluster, Apache ZooKeeper) to provide inputs in designing.', 'Experience in to transform data into topics, streaming processors in Kafka.', 'Experience in Confluent tools (Control center, data balancer, replicator, security control REST Proxy ,MQTT proxy etc.)', 'Setup best practices, Standards, Patterns Development and automate process for onboarding.', 'Developed playbooks for troubleshooting and support teams', 'Develop monitoring strategies for Kafka infrastructure in Confluent Center and applications aligning with enterprise strategy and overall industry trends.', 'Designed monitoring solutions and baseline statistics reporting to support the implementation', 'Experience with stream processing using Kafka', 'Experience with Kafka Connect and Informatica Powercenter and SQL Server will be a plus', 'Language : Java', '5-10 years of experience developing data platform', '2+ years of experience implementing Kafka']",2020-12-30 22:14:55
"Data Engineer, Mid",Booz Allen Hamilton,"3.9 out of 5 from 2,200 employee ratings","Arlington, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience as a database developer or ETL developer', 'Experience with migrating data into an enterprise data lake', 'Experience with Apache Nifi, Oracle, and MySQL', 'Ability to obtain a security clearance', 'BA or BS degree', 'Experience with Agile software development', 'Experience with using Lucene-based search engines, including ElasticSearch or Solr', 'Experience with Big Data ETL tools, including StreamSets and NiFi', 'Experience with Big Data systems, including Hadoop, HDFS, Hive, or Cloudera', 'Experience in working with enterprise and production systems', 'Ability to display a positive, can-do attitude to solve the challenges of tomorrow', 'Ability to learn technical concepts and communicate with multiple functional groups', 'Possession of excellent oral and written communication skills', 'Hortonworks, Cloudera, or Big data Certification']",2020-12-30 22:14:55
Software Engineer- Big Data,Data Bridge,N/A,"Alexandria, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Hadoop, 1 year (Preferred)Big Data, 1 year (Preferred)', ""Education:Bachelor's (Preferred)"", 'Software engineer/developer supporting Scrum Teams', 'Performs test-driven software engineering and development activities associated with designing, developing, maintaining, and enhancing the Big Data analytic system using an Agile DevSecOps model.', 'Designs and develops reusable services that support capabilities such as data discovery and query, analytic visualizations, link-node analysis, AI/ML big data analytics, and object production and relationships', 'Develops services using modern techniques such as REST, Java, JSON, Spring, Python, Javascript frameworks (e.g., JQuery, Angular, React), and Docker', 'Identifies and integrates applicable DIA and IC shared services (e.g., IC PKI and IAA)', 'Uses processes and tools that support the DevSecOps pipeline including JIRA, Git, Junit, Jenkins, SonarQube, Fortify, and Artifactory', 'Measures and optimizes service execution using tools such as AppDynamics, CloudWatch, and Splunk.', 'Develops or provides input to engineering artifacts including Weekly Status Reports, Development Sprint Plans, System Design Documents, Database Design Documents, Bill of Materials, User Training Plans, Release Plans, Requirements Traceability Matrices, and Sprint Summary Reports.', '9+ years of software engineering and development; designing, developing, maintaining, and enhancing Big Data analytic systems', 'Tools: Agile, AWS, Java, Python, JSON, Spring, Spring Boot, Docker, JIRA, Git, Junit, RDBMS technology, Elasticsearch and/or SOLR, NoSQL technology (Hadoop and/or EMR, Web UI Javascript frameworks (e.g. JQuery, Angular, React)', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Paid time off', 'Monday to Friday', 'Bonus pay', 'Commission pay', 'Signing bonus', 'Tips', 'Hadoop: 1 year (Preferred)', 'Big Data: 1 year (Preferred)', ""Bachelor's (Preferred)"", 'Temporarily due to COVID-19']",2020-12-30 22:14:55
Data Engineer,Walker Edison Furniture Company LLC,3.4 out of 5 from 19 employee ratings,"Salt Lake City, UT 84120","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work closely with Analyst to provide the data and support they need.', 'Modify, build, and maintain data warehouse tables and pipelines through various tools like SQL, python, and AWS stack.', 'Wrangling data from disparate systems and sources such as RDBMS, flat files, and API connections.', 'Optimization of existing SQL queries to improve reliability and performance.', 'Lead the way in data warehouse documentation such as data pipelines, definitions, and warehouse change impacts.', 'Can work remotely and independently under minimal supervision to achieve objectives.', 'Bachelor’s degree in information systems, data analytics, or related field.', '2+ years SQL experience using CTE, window functions, and complex joins.', 'Experience with ETL processes and good data warehouse principles.', 'Basic understanding of Datawarehouse models like Kimbal and Inmon.', 'Should be familiar with terms like primary key, granularity, index, additive attributes, views.', 'RDBMS: Redshift, Postgres.', 'Experience with visualization tools such as Tableau, Looker, and DOMO.', 'Coding experience with Python, R, and other languages.', 'Experience with web scraping.', 'Familiar with Apache Airflow, DOMO, various AWS cloud platform tools.']",2020-12-30 22:14:55
Data Platform Engineer - Remote within US,Human Capital Resource,5 out of 5 from 2 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Ruby: 4 years (Preferred)Java: 4 years (Preferred)Machine Learning: 4 years (Preferred)AWS or Other Cloud Service: 4 years (Preferred)Go, Elixir, or Scala: 4 years (Preferred)"", 'Design and develop data pipelines, ETL, storage solutions, and workflows that are optimized for speed, fault-tolerance, and scalability', 'Work with Application, Machine Learning, and Site Reliability/DevOps engineers to create systems that support their varied data needs while allowing for independent manipulation and iteration of data', 'Define robust data schemas for the rapid intake and processing of customer data with diverse structures', 'Support product-focused engineering teams with data infrastructure, APIs, and scalable deployments', 'Architect and author internal libraries for use by fellow engineers', 'Help create data analytics tools for software telemetry and business intelligence purposes', 'Cultivate a better understanding of data handling best practices across engineering teams', 'Collaborate on security efforts for customer data', '4+ years of experience writing code in one of: Ruby, Go, Python, Scala, Elixir, Java, or similar languages at a SaaS company', 'Strong understanding of relational and non-relational databases such as PostgreSQL, ElasticSearch, and Redis', 'Ability to organize and model data to support varied use cases', 'Experience creating and deploying container-based software', 'Familiarity with asynchronous data processing patterns with an added focus on monitoring and logging', 'Prior experience working with AWS or a similar cloud provider', 'A BS/MS in computer science or related field of study, or equivalent experience', 'Ability to communicate ideas to technical and non-technical colleagues', 'Experience designing, building, and maintaining highly distributed or event-driven systems', 'Experience supporting Machine Learning engineers with data preparation, validation, annotation, and model evaluation', 'Previous work with workflow management and/or task scheduling systems', 'Prior use of Terraform/Ansible/Infrastructure as Code tools', 'You have strong opinions about technology and the facts to back it up', 'You welcome healthy but respectful debate', 'You know the differences between: data warehouses and data lakes, schema-on-read and schema-on-write, relational and non-relational databases, batch and stream processing', 'The thought of code sitting undeployed for more than a week sends shivers up your spine', 'You want to be go-to subject matter expert for data-related questions', '401(k)', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', '8 hour shift', 'Monday to Friday', 'Signing bonus', ""Bachelor's (Preferred)"", 'Ruby: 4 years (Preferred)', 'Java: 4 years (Preferred)', 'Machine Learning: 4 years (Preferred)', 'Startup: 4 years (Preferred)', 'AWS or Other Cloud Service: 4 years (Preferred)', 'Go, Elixir, or Scala: 4 years (Preferred)', 'Fully Remote', 'https://www.hc-resource.com/', 'https://www.facebook.com/HumanCapResource/', 'Yes']",2020-12-30 22:14:55
Junior Research Engineer/Data Scientist,Technica Corporation,3.5 out of 5 from 24 employee ratings,"Dulles, VA 20166","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Support a team of Developers and Data Scientists working on a variety of research and development projects as well as customer projects', 'Research and analyze cutting edge algorithms and technologies with a focus on Natural Language Processing and data visualization techniques', 'Effectively communicate results of research and analysis with teammates and senior management in the form of essays, whitepapers, and PowerPoint presentations', 'Design, Develop and Deploy:', 'Automated analytic software, techniques, and algorithms', 'Data-driven analytics; event-driven analytics', 'Bachelor’s in Computer Science, Mathematics, or relevant technical field', 'Experience with web frameworks (React, Flask, NodeJS)', 'Experience with Python', 'Able to obtain clearance', 'Experience using Linux as a development operating system', 'Experience with Docker and Singularity container platforms', 'Experience with Machine Learning toolkits such as Tensorflow, Pytorch', 'Experience with data visualization']",2020-12-30 22:14:55
Data Engineer,Super Systems Inc,4.7 out of 5 from 6 employee ratings,"Chantilly, VA 20151","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Science or Data Engineering: 2 years (Required)Secret (Required)', '2+ years of experience with machine learning, data science, or data engineering', 'Experience with the design, implementation and ETL process for databases', 'Experience with creating data pipelines', 'Experience with building machine learning models and predictive analytics', 'Experience with common programming languages, including SQL, Python, or R', 'Ability to articulate workflows and explain technical concepts to non-technical audiences', 'Ability to interact with multidisciplinary teams including data scientists and technical consultants in project- based areas', 'BA or BS degree', 'Experience with Big Data technologies, including HDFS, Impala, AWS, Glue, Azure, Cloudera, Hadoop, or Spark', 'Experience with data science frameworks including DataBricks, Data Robot, or Cloudera', 'Experience with distributed computing and optimizing pipelines', 'Experience with parsing a variety of data sources including Oracle, XML, JSON, or parquet', 'Experience with data visualization development and role of data integration', 'Secret', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Chantilly, VA 20151 (Required)', 'Data Science or Data Engineering: 2 years (Required)', 'Secret (Required)', 'One location']",2020-12-30 22:14:55
Data/Analytics Engineer,SmartAsset,4.1 out of 5 from 17 employee ratings,"New York, NY 10012","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's Degree in a hard science, mathematics, or engineering"", '2+ years of development experience with exposure to Data Science', 'Solid Python and SQL skills', 'Good knowledge of pandas with hands on data wrangling experience', 'Comfortable in the Linux environment', 'Solid math skills - Probability/statistics/calculus', 'PhD/MSc', 'ETL/data pipelining experience', 'Experience with AWS services/EC2 and cloud storage', 'Data Science experience']",2020-12-30 22:16:36
Data Engineer,ZILLIZ,N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Location:San Francisco, CA (Required)', 'Language:English (Required)', 'Work authorization:United States (Required)', 'Proficiency in Python, one-year development experience.', 'Familiar with common databases, such as MySQL, Postgres, MongoDB, etc., have actual development experience', 'Understand the data science ecosystem and related deep learning technologies, such as Hadoop, Elasticsearch, Cassandra, Rapids, TensorFlow, pytorch, Sklearn, BigDL, Caffee, Spark, etc.', 'Can use Linux operating system for development and maintenance', 'San Francisco, CA (Required)', 'English (Required)', 'United States (Required)', 'Temporarily due to COVID-19']",2020-12-30 22:16:36
"Intern, Clinical Analytics Data Engineer","Accolade, Inc.",3.2 out of 5 from 106 employee ratings,"Seattle, WA 98101","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build patient identification algorithms using medical claims and pharmacy claims data to power Accolade clinical programs', 'Create clinically meaningful characteristics for display in downstream nurse care management application', 'Integrate and work with modern data services to make algorithm results and clinical characteristics available to the rest of the data platform', 'Analyze algorithms to build a business case, and work with multidisciplinary stakeholders to improve performance based on clinical program objectives', 'Collaborate with data scientists and subject matter experts to incorporate novel techniques in model building and tuning', 'Relevant experience with Python', 'Experience writing and optimizing SQL queries', 'Experience in data science python libraries (pandas, numpy, etc)', 'Skill or interest in healthcare data, experience working with medical or pharmacy insurance claims data', 'Knowledge of healthcare data coding systems (ICD10, CPT, NDC/GPI)', 'Statistics coursework or training']",2020-12-30 22:16:36
Data Engineer,NewWave HQ,N/A,"Woodlawn, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop, and deploy infrastructure to support the overall data environment, including database administration, data pipeline & warehousing solutions.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Design, maintenance, patch management, and configuration of Oracle databases.', 'Experience supporting and working with cross-functional teams in a dynamic environment to support Installation and maintaining Oracle database.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Build processes supporting data transformation, data structures, metadata, dependency, and workload management.', '10+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems, or another quantitative field. They should also have experience using the following software/tools:Experience with Oracle, PL/SQL, SAS, Informatica, Unix Shell Scripting', ""Serve as technical resource responsible for Oracle SQL development, writing complex queries using advanced PLSQL concepts and, review table structures, apply indexes were needed, performance tune SQL's."", 'Authorized to work in the United States.', 'Experience with related technologies including SQL Developer and TOAD.', 'Experience with MicroStrategy Reporting or Business Intelligence environment.', 'Experience with continuous integration and continuous delivery.', 'Exempt', 'Excellent interpersonal, verbal and written communication, and organizational skills - must be able to communicate fluently in English both verbally and in writing', 'Should be extremely facts and data oriented.', 'Should be deadline and closure oriented.', 'Strong persuasion, facilitation and influencing skills.', 'Should be self-driven.', 'Strong analytical, organizational and project management skills.', 'Demonstrated ability to lead and work with cross functional teams including senior level individuals.', 'Must be able to thrive in a fast-paced, rapidly evolving environment with varying priorities, based on a team building culture.']",2020-12-30 22:16:36
ML / Data Engineer,Mobiveil Technologies Inc.,N/A,"Longmont, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data analysis: 3 years (Preferred)', '5+ years of experience', 'Strong machine learning background with deep understanding of different types of machine learning algorithms like CNN, RNN, LSTM and Reinforcement learning . Should have completed a few projects from data preparation, training, inference and data analysis.', 'Must have experience working with multi input and output, different type of features', 'Very familiar using frameworks like keras, tensorflow or pytorch or any other deep learning frameworks', 'Proficient with Python development using packages like numpy, panda, scipy, sklearn etc', 'Very proficient in Python, using linux. C++/CUDA is a plus', 'Familiar with Statistics, Linear Algebra, Optimization techniques as applicable to machine learning', 'Familiar training using GPU based frameworks on-prem and in cloud', 'Good problem solving and communication skills', 'Understands data structures, data modelling and software engineering', 'Health insurance', 'Paid time off', '8 hour shift', 'ML algorithms (CNN, RNN, LSTM): 3 years (Preferred)', 'Data analysis: 3 years (Preferred)', 'Likely', 'No', 'Varies']",2020-12-30 22:16:36
Data Engineer II,Expedia.com,3.9 out of 5 from 927 employee ratings,"Seattle, WA 98119","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, architect, implement, and support key datasets that provide structured and timely access to actionable business information with the needs of the end customer always in view', 'Retrieve and analyze data using SQ and other data management systems', 'Create ETLs/ELTs to take data from various operational systems and craft a unified dimensional or star schema data model for analytics and reporting', 'Develop a deep understanding of vast data sources (existing on the cloud) and know exactly how, when, and which data to use to solve particular business problems', 'Experience developing and operating large scale analytical databases/platforms/data warehouses and performing ETL across multiple operating systems (Microsoft and Linux)', 'Experience in working with Cloud BI Production implementation', 'Experience with Agile, DevOps, CICD frameworks', 'Experience working with multi-terabyte data sets using relational databases (RDBMS) and SQL', 'Experience using Agile/Scrum methodologies to iterate quickly on product changes, developing user stories and working through backlogs.', '5+ years of experience with detailed knowledge of data warehouse technical architectures, ETL/ ELT, reporting/analytic tools, and data security', '3+ years of experience in designing data warehouse solutions and integrating technical components', '2+ yrs of experience with any scripting language (Ruby, python, etc.)', '2+ yrs of experience leading data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies', '1+ yr of experience with production BI implementation in the Cloud', 'Exposure in at least one reporting tool like Qlikview, Tableau, Power BI etc.', 'Capable of investigating, familiarizing and mastering new data sets quickly', 'Experience with building data platform on cloud (AWS)', 'Good familiarity with Linux/Unix scripting', 'Experience with Snowflake Computing, Kafka, or Kinesis are a huge plus', 'LI-ES1']",2020-12-30 22:16:36
Research Engineer,TieSet,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Doctorate (Preferred)Machine Learning: 1 year (Preferred)', 'Salary range varies from $1,000 up to $5,500', 'Stock Options (We prefer to work with people who are more interested in stock options rather than just getting paid with salaries)', 'System integration and software development', 'Software documentation', 'Resposible for Proof of Concept (POC) projects with customers', 'Strong implementation skills in Python and/or JavaScript', 'Understanding of fundamental Machine Learning concepts', 'Experience in large scale software implementation', 'Knowledge of development version control tools (like Git), Linux, Machine Learning library (PyTorch and/or TensorFlow), and Google Cloud Platform (GCP)', 'Communication skills to work with R&D teams and international customers', ""[preferred] Master's or PhD degree in Computer Science, Software Engineering, or a related field"", 'Flexible schedule', '8 hour shift', 'Bonus pay', 'Doctorate (Preferred)', 'Machine Learning: 1 year (Preferred)', '3 - 4 months', 'Fully Remote', '20-29', '9AM', '5PM', 'Pay', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'www.tie-set.com', 'Temporarily due to COVID-19', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:16:36
Data Engineer,Vivint Smart Home,"3.4 out of 5 from 1,074 employee ratings","Lehi, UT 84043","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Must have a passion for data and helping the business turn data into information and action', '1+ years of data engineering experience', '1+ years of ETL & data pipeline development experience', 'Ability to initiate, drive, and manage projects with competing priorities', 'Ability to communicate effectively with business leaders, IT leadership, and engineers', 'Expert in SQL, databases, and ETL development processes & tools (Cloud MPP like Snowflake or Redshift)', 'Proficiency in the python scripting language. Preference given to knowledge of more (Perl, .net, etc.)', 'Familiarity with one or more web technologies (Angular, React, PHP, ASP.net, etc.)', 'Experience with big data technologies (HDFS, Hadoop, Spark, Elastic Search, Redshift, Snowflake, etc...)', 'Experience with Tableau or similar data visualization tool', 'Experience with AWS or Azure data product offerings and platform', 'Experience with machine learning technologies (R, SparkML, AzureML, etc.)', 'Paid holidays and flexible paid time away', 'Your choice between Mac or PC', 'Employee pricing on smart home products', 'Casual dress code', 'Onsite gym, gaming tables across our campus', 'Onsite health clinic', 'Medical/dental/vision/life coverage', 'Must have a passion for data and helping the business turn data into information and action', '1+ years of data engineering experience', '1+ years of ETL & data pipeline development experience', 'Ability to initiate, drive, and manage projects with competing priorities', 'Ability to communicate effectively with business leaders, IT leadership, and engineers', 'Expert in SQL, databases, and ETL development processes & tools (Cloud MPP like Snowflake or Redshift)', 'Proficiency in the python scripting language. Preference given to knowledge of more (Perl, .net, etc.)', 'Familiarity with one or more web technologies (Angular, React, PHP, ASP.net, etc.)', 'Experience with big data technologies (HDFS, Hadoop, Spark, Elastic Search, Redshift, Snowflake, etc...)', 'Experience with Tableau or similar data visualization tool', 'Experience with AWS or Azure data product offerings and platform', 'Experience with machine learning technologies (R, SparkML, AzureML, etc.)', 'Paid holidays and flexible paid time away', 'Your choice between Mac or PC', 'Employee pricing on smart home products', 'Casual dress code', 'Onsite gym, gaming tables across our campus', 'Onsite health clinic', 'Medical/dental/vision/life coverage']",2020-12-30 22:16:36
Data Analyst,"Turn5, Inc.",2.9 out of 5 from 62 employee ratings,"Paoli, PA 19301","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'The role will be key in uncovering positive and negative anomalies in business/marketing performance. Acting as the first line of defense that highlights causes and drives next steps.', 'Assisting and leading next steps on complex analysis regarding Customer Lifecycles which will include Lifetime Value.', 'In depth analysis on New customer and retention of repeat customers.', 'Support Marketing Director in Quarterly Marketing Business review by analyzing previous quarters results and adding insight or new visualizations into what drove growth or decline.', ""Discovering opportunities for improvement and provide recommendations for improvement within Turn5's Web strategy to drive incremental success"", 'Working with team of Data Engineers to ensure performance reliability of dashboards and visualizations available via Tableau Server', 'Using custom SQL to improve data structure, optimize/automate data flow, and build custom reports', ""Collaborating with representatives from across Turn5's departments to contribute to analytics and data integration projects"", 'Performing ad-hoc reporting analysis for Marketing/Web functions to help highlight performance/opportunities to assist in future decisions', 'Being presented with business/marketing problems and doing any required aspects (data identification, data cleansing, data movement, analysis, etc.) to figure out the cause and how to improve performance', 'Create and optimize data sources combining web & customer data for unique insight.', 'Developing and confidently presenting data directly to C-level executives.', 'BA/BS in IT, marketing, e-commerce, economics, mathematics, or other related degrees & at minimum 1-2 years of experience working in a similar capacity', 'Excellent analytical skills: including being able to quality-assure, clean, and analyze large data sets to draw conclusions and propose recommendations', 'Google Analytics experience is not required but a huge plus', '6 months - 2 years of experience with MS SQL Server 2012+', '6 months - 2 years of experience working in/moving data from Tableau, Google Analytics, or any other analytics platforms', 'Data centric experience working with various applications (OMS, WMS, etc.) implemented within an eCommerce setting would be a plus', 'Proficiency in Excel']",2020-12-30 22:16:36
Client & Data Test Engineer,Apple,"4.2 out of 5 from 9,978 employee ratings","Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Comfortable and adaptable in a fast-paced environment.', 'Strong analytical, problem solving and creative thinking skills.', 'Excellent verbal and written communication.', 'Strong commitment to technical quality assurance as a key part of the software development cycle. Willingness to work cross-functionally.', 'Results-oriented, persistent, and meticulous.', 'Experience writing automation using Python, JavaScript scripting and user-level automation for iOS.', 'Experience with Spark, Hadoop, Kafka or other distributed systems is a plus.', 'Experience in developing and verifying Spark/Map Reduce jobs is a plus.', 'Familiarity with Objective-C or Swift is a plus.', 'Knowledge in SQL, CSS, HTML, JSON a plus.']",2020-12-30 22:16:36
Data Discovery Engineer,M&T Bank,"3.6 out of 5 from 1,507 employee ratings","Cheektowaga, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL', 'Python', ""Combined minimum of 6 years' combined higher education and/or operational/business analytics/systems development experience"", 'Strong verbal and written communication skills', 'Experience with Agile Methodology', 'Strong collaboration with technology partners and customers', 'A team player mindset with an ability to thrive and effectively communicate in a fast-paced, constantly evolving environment']",2020-12-30 22:16:36
DIGIT Program - Remote Database/Data Engineer,NCI Information Systems Inc.,3.7 out of 5 from 400 employee ratings,"Reston, VA 20190","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'IT service desk and on-site support.', 'End-user device management.', 'Conference and collaboration support.', 'Network and telecommunications support.', 'Unified communications.', 'Compute/storage and cloud management.', 'Identity, credential, and access management.', 'Be part of the Transition-in Team to transition operations from incumbent to NCI and then fulfill duties as the Database Architect on the program.', 'Lead development of material management database, migrating from an Oracle instance into a modern cloud DB solutions.', 'Provide database server administration support and incident management and service request responses', 'Meet both technical and consumer needs.', 'Manage and implement database technology transition, including the sunset of older database technologies.', 'Execute disaster recovery and continuity of operations support.', 'Be available for off-hours support as needed.', 'Work across development and operational environments.', 'Stay abreast of database technologies and best practices.', 'Skillful of multitasking and managing multiple simultaneous high priorities a must.', 'Other duties as assigned', 'Required Clearance is US Public Trust.', 'Bachelor’s degree in Computer Science or Engineering discipline.', '4-9 years of database development in Defense or secured Government Installations.', 'Familiar with leading data migrations from Oracle Databases.', 'Working experience architecting, designing, and implementing databases as well as implementing and executing ETL tools.', 'Experience transforming large, government programs to the cloud.', 'Strong written and oral communication skills.', 'Google Cloud Professional Collaboration Engineer Experience or Certification', 'Recent experience with leading successful improvement projects in an agile environment for organizations similar in size to GSA.', 'Minimum of three years of experience analyzing customer requirements and providing assistance with requirements development similar in size, scope, and complexity.', 'Recent experience delivering emergent technologies to complex business solutions for stakeholders from multiple disciplines.', 'Experience with Oracle DBA, MS SQL MSCA, or MSCE, Enterprise DB (EDB) preferred.', 'Knowledge in Database development and administration in cloud solutions preferred.', 'Experience with NAVSEA financial systems, such as CSAS, or MSE PROD is preferred.', 'Sitting for long periods', 'Standing for long periods', 'Ambulate throughout an office', 'Ambulate between several buildings']",2020-12-30 22:16:36
Data Engineer,Built Technologies,2.5 out of 5 from 2 employee ratings,"Nashville, TN 37211","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help build the foundation for the future of reporting at Built', 'Ship features that enable clients and internal stakeholders to get the most out of their data', 'Provide data that helps drive product decisions', 'Participate in design and architectural conversations around data warehousing and report generation/building', 'Encourage and build up your teammates', 'Delivering the right solution at the right time with integrity', 'Participating in driving our data warehousing and report generation architecture forward', 'Communicating and collaborating with both technical and non-technical team members to arrive at negotiated decisions.', 'Working across languages, environments, and teams to create the best solution from the information currently available', 'MySQL', 'Python (3.6+), JavaScript, and/or PHP', 'ETL processes', 'Looker or similar Business Intelligence platform (Power BI, Tableau, etc)', 'Rundeck', 'GoCD', 'Be a good communicator', 'Possess a strong focus on customers, both internal and external', 'Be able to work across teams to accomplish goals', 'Have a dedication to the quality and ownership of your work product', 'Have empathy and support for your teammates']",2020-12-30 22:16:36
GCP Data Engineer,CBL SOLUTIONS INC,N/A,"United, WV","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Strong with Core Java', '3+ years with GCP Data stack( Dataflow, BQ, pipeline, Dataproc…)', 'Strong experience with writing pipelines', 'Strong experience with Data migration to GCP', 'GCP Data engineer certification', 'Any past PSO experience is a plus', '8 hour shift', 'Day shift', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-12-30 22:16:36
Software Engineer,Moody's Corporation,3.7 out of 5 from 458 employee ratings,"West Chester, PA 19380","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Front-end and back-end web development', 'Support and improve existing codebase', 'Debug user-reported issues', 'Architect new products and upgrade existing features', 'Work collaboratively with team members and other stakeholders to ensure successful delivery and implementation of assigned tasks', 'Participate in several aspects of the software development life cycle (SDLC)', '3+ years’ experience in the following areas:', 'Solid understanding of web technologies', 'Programming (C#, JavaScript, Typescript, Node, React, etc.)', 'Databases (Microsoft SQL, MongoDb, Redis, MySQL, etc.)', 'Source code management tools (Subversion, Git, VSS, etc.)', 'Cloud (Amazon Web Services, Microsoft Azure, Google) services', 'BS in Computer Science (or equivalent)', 'Knowledge of the software development life cycle (SDLC) including Agile Development Methodology', 'Strong analytical, problem-solving, and troubleshooting skills', 'Ability to stay current on trends within functional area of expertise and the industry', 'Excellent time management and organizational skills', 'Strong written, verbal, and interpersonal communication skills', 'Demonstrated team player', 'Willingness to learn, a can-do attitude, and motivated to succeed and grow']",2020-12-30 22:16:36
"Junior Data Engineer, Part-time",Suddath,3.6 out of 5 from 250 employee ratings,"Jacksonville, FL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Support the Suddath Data and Analytics Team in developing data solutions in a cloud environment (Azure).', 'Be part of a team that builds transformation processes (ETL) to reshape data for user consumption.', 'Build solutions around data quality testing and reporting on quality metrics.', 'Create insightful, informative, and actionable data dashboards and reports that are easily accessible by stakeholders and clients.', 'Understand key business drivers and data capture methods.', 'Handle confidential information appropriately.', 'Strong SQL skills.', 'Strong computational and analytical skills.', 'Strong foundation in data engineering, data modeling and software design.', 'Experience in software development using Python or C# programming, design and analysis.', 'Strong verbal and written communication skills, and be able to work with others at all levels; effective at working with geographically remote and culturally diverse teams.', 'Possess the drive and passion for quality with the ability to inspire, excite and motivate other team members.', 'Experience with data visualization tools (e.g. Microsoft Power BI).', 'Creative problem solver.', 'Detail oriented.', 'Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.']",2020-12-30 22:18:17
Software Engineer- Big Data,Data Bridge,N/A,"Alexandria, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Hadoop, 1 year (Preferred)Big Data, 1 year (Preferred)', ""Education:Bachelor's (Preferred)"", 'Software engineer/developer supporting Scrum Teams', 'Performs test-driven software engineering and development activities associated with designing, developing, maintaining, and enhancing the Big Data analytic system using an Agile DevSecOps model.', 'Designs and develops reusable services that support capabilities such as data discovery and query, analytic visualizations, link-node analysis, AI/ML big data analytics, and object production and relationships', 'Develops services using modern techniques such as REST, Java, JSON, Spring, Python, Javascript frameworks (e.g., JQuery, Angular, React), and Docker', 'Identifies and integrates applicable DIA and IC shared services (e.g., IC PKI and IAA)', 'Uses processes and tools that support the DevSecOps pipeline including JIRA, Git, Junit, Jenkins, SonarQube, Fortify, and Artifactory', 'Measures and optimizes service execution using tools such as AppDynamics, CloudWatch, and Splunk.', 'Develops or provides input to engineering artifacts including Weekly Status Reports, Development Sprint Plans, System Design Documents, Database Design Documents, Bill of Materials, User Training Plans, Release Plans, Requirements Traceability Matrices, and Sprint Summary Reports.', '9+ years of software engineering and development; designing, developing, maintaining, and enhancing Big Data analytic systems', 'Tools: Agile, AWS, Java, Python, JSON, Spring, Spring Boot, Docker, JIRA, Git, Junit, RDBMS technology, Elasticsearch and/or SOLR, NoSQL technology (Hadoop and/or EMR, Web UI Javascript frameworks (e.g. JQuery, Angular, React)', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Paid time off', 'Monday to Friday', 'Bonus pay', 'Commission pay', 'Signing bonus', 'Tips', 'Hadoop: 1 year (Preferred)', 'Big Data: 1 year (Preferred)', ""Bachelor's (Preferred)"", 'Temporarily due to COVID-19']",2020-12-30 22:18:17
Data Engineer,Hudson River Trading,3.5 out of 5 from 2 employee ratings,"New York, NY 10005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Strong programming experience in Python', 'Proficient in a strongly-typed language like Java, C, or C++', 'Demonstrated ability to work with data', ""Data infrastructure experience - you know how to really store data; and no, we don't mean saving an Excel file on your desktop (everyone knows that's messy and it should be in a nicely named folder)"", 'Track record of working successfully in a collaborative environment', 'Top-notch communication skills', 'You have a minimum of 2-3 years of experience working in data infrastructure', ""Bachelor's degree in computer science, math or a related field"", ""You enjoy being part of an amazing team but don't mind working alone on a difficult problem"", 'You can analyze and fix problems quickly', 'You really like to work with people who motivate you and make you better', 'In your spare time you: code, tinker, read, explore, break things, and have an insatiable curiosity for all things computer related']",2020-12-30 22:18:17
Architecture and Data Engineer,ThinkInTree Inc,N/A,"Redmond, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift']",2020-12-30 22:18:17
Data Engineer,Built Technologies,2.5 out of 5 from 2 employee ratings,"Nashville, TN 37211","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help build the foundation for the future of reporting at Built', 'Ship features that enable clients and internal stakeholders to get the most out of their data', 'Provide data that helps drive product decisions', 'Participate in design and architectural conversations around data warehousing and report generation/building', 'Encourage and build up your teammates', 'Delivering the right solution at the right time with integrity', 'Participating in driving our data warehousing and report generation architecture forward', 'Communicating and collaborating with both technical and non-technical team members to arrive at negotiated decisions.', 'Working across languages, environments, and teams to create the best solution from the information currently available', 'MySQL', 'Python (3.6+), JavaScript, and/or PHP', 'ETL processes', 'Looker or similar Business Intelligence platform (Power BI, Tableau, etc)', 'Rundeck', 'GoCD', 'Be a good communicator', 'Possess a strong focus on customers, both internal and external', 'Be able to work across teams to accomplish goals', 'Have a dedication to the quality and ownership of your work product', 'Have empathy and support for your teammates']",2020-12-30 22:18:17
Data Engineer,Tesla,"3.5 out of 5 from 4,572 employee ratings","Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:18:17
Data Engineer,MX Technologies Inc.,4.6 out of 5 from 7 employee ratings,"Lehi, UT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Evaluate data pipeline and machine learning pipeline technologies', 'Implement platforms that will simplify and improve the work of data analysts and scientists.', 'Build tools to allow Data Scientists to own machine learning models for the entire life cycle.', 'Be a bridge between Data Scientists and Engineers while effectively communicating business needs.', 'Fundamental understanding of various machine learning techniques.', 'Foundational knowledge in Event Source design and Stream Processing architecture', 'Foundational knowledge in MLOps.', 'Experience in deploying machine learning models to production.', '3 years of professional Python or R experience.', '3 years of professional SQL experience.', 'Strong mathematical background including Statistics.', 'Experience working with non-relational data.', '(Optional) Experience with MLFlow, Ruby/Rails, Postgres, Large data structures (Vertica, Clickhouse, Redshift, ElasticSearch, Hadoop or similar).', 'Thinking like an owner', 'Balancing independent problem solving with collaboration', 'Not being afraid to make mistakes and learn from them', 'Communicating with honesty, candor, and respect', 'Being bold and resourceful', 'Being a passionate and empathetic team member', 'You will build and share products that are making a difference in the lives of others', 'You will collaborate with other brilliant minds', 'You will be rewarded and recognized for your high-caliber work', 'You will enjoy autonomy', 'You will build products that outshine all of our competitors', 'You will be working with established design standards and libraries', 'You will work with a deeply technical engineering team']",2020-12-30 22:18:17
Data Engineer - AADS,Eli Lilly,"4.2 out of 5 from 1,732 employee ratings","Indianapolis, IN","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with key business partners and work within team to identify, scope, and execute analytic efforts that leverage data to answer business questions, solve business needs, and add business value', 'Maintain a broad understanding of the pharmaceutical industry (from discovery to commercialization) and be fully engaged with teams, bringing an objective voice to the table, and facilitating decisions grounded in data', 'Collaborate with other analytics team members to review and provide feedback on the analytics work being done, and be willing to seek feedback from other team members about your own work', 'Streamline and prepare data for analysis through understanding of data flow and integration', 'Creating and driving standards for data capture, storage, and transformation.', 'Master in Statistics, Computer Science, Biostatistics, Operations Research, MIS or related areas', 'OR a Bachelors in Statistics, Computer Science, Biostatistics, Operations Research, MIS, or related areas with at least 2 years of related working experience', 'Proficiency with one or more relevant programming languages such as R, SQL, Python, C++', 'Deep knowledge of database structures', 'Strong communication skills', 'Bring an insatiable desire to learn, to innovate, and to challenge yourself for the benefit of patients.']",2020-12-30 22:18:17
Data Engineer,FlairTech Solutions LLC,N/A,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Hadoop: 5 years (Preferred)Microsoft SQL Server: 4 years (Preferred)Data warehouse: 5 years (Preferred)Big data: 5 years (Preferred)', 'Good experience in AWS Analytics stack in Spark/Databricks, Kubernetes,', 'Using data engineering tools, languages, frameworks to mine, cleanse and explore data.', 'Fluent in NoSQL & relational based systems.', 'Strong analytical and problem-solving skills.', 'Strong understanding of database technologies and management systems.', 'Strong understanding of cloud-based systems/services.', 'Excellent analytical and problem-solving skills.', 'Aware of the Agile methodologies', 'Ability to work on collaboration with local and external teams', 'Good Verbal and Written Communication skills', 'Monday to Friday', 'Hadoop: 5 years (Preferred)', 'Microsoft SQL Server: 4 years (Preferred)', 'Data warehouse: 5 years (Preferred)', 'Big data: 5 years (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 22:18:17
Data Entry Clerk 1,TriOpz,N/A,"Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Candidate have to come to the office to get their computer and for some training when they start. Then the position will be remote until the team returns to the office post COVID. Then the candidate will be required to work from the office when everyone returns. LOCAL CANDIDATES ONLY.']",2020-12-30 22:18:17
Azure Data Engineer,Tech Golden,N/A,"Cincinnati, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Leverages enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses', 'Guides high level data architecture design (functional, non-functional) and ensures teams adhere to data architecture standards', 'Develops information processes for data acquisition, data transformation, data migration, data verification, data modeling, and data mining', 'Accountable for cost viability and technical estimation of data platform usage', 'Designs data solutions for data distributions and partitions, scalability, disaster recovery and high availability', 'Designs security for data policies and standards', 'Monitors and optimizes data solutions', 'Actively governs and automates standard data architecture patterns and blueprints', 'Partners with architecture, security, infrastructure, and application teams to design and implement the automation of data, data platforms, and tools', 'Creates and updates automation to eliminate routine management processes', 'Articulates the need for scalability and understand the importance of improving quality through testing', '5+ years of hands-on experience with data platforms', 'Experience in designing data solutions in Azure including data distributions and partitions, scalability, disaster recovery and high availability', 'Experience in monitoring and optimizing data solutions in Azure including using Azure Monitor', 'Experience in implementing data solutions in Azure including Azure SQL, Azure Synapse, Cosmos DB, Databricks, ADLS, Blob Storage, ADF, Azure Stream Analytics', 'Experience in designing security for data policies and standards', 'In depth understanding and proficiency in automation of cloud platforms and data platforms', 'Expertise in on-prem and cloud database automation and platform automation with Azure', 'Proficiency with cloud automation tooling such as Ansible and Terraform', 'Proficiency with DevOps and CI/CD methodologies and tools for automated infrastructure code test, integration, deployment, and assurance', 'Proficiency with Languages such as Ruby, bash, Python or Go', 'Experience with Software Development and automation methodologies', 'Experience with data security best practices', 'Strong problem-solving skills', 'Strong collaboration skills and excellent verbal and written communication skills', '8 hour shift', 'Temporarily due to COVID-19']",2020-12-30 22:18:17
Data Engineer,VTS3,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Will be required to help with the discovery of existing .NET applications', 'Will help building any conversion programs and integrations from Cloud to on-premise as needed to support the Oracle HCM Cloud/OAC implementation', 'Will be required to support and make enhancements to existing systems if needed', 'Would be required to perform analysis of business and system requirements and system design for the development', 'Should be able to start working on the system from day one with minimal hands holding. (Must be experienced)', 'Would have to design, build, unit test, and deploy changes to existing applications based on requirements', 'Would have to work closely with other Developers, DBAs, and Business/Functional users', 'Will have to maintain technical and standard documentation for program development activity in a timely and high-quality manner', 'Strong experience in Transact-SQL', 'Strong experience in MS SQL Server Integration Services', 'Strong experience in Database Design & Analysis', 'Experience in ASP.NET (VB, C#)', 'Experience in JavaScript', 'Experience in VBScript', 'Experience in HTML and CSSExperience working with Webservices and APIs', 'Experience in Visual Studio 2010 and higher', 'Ability to establish and meet target dates', 'Ability to handle multiple projects at the same time', 'Excellent communications skills (written and verbal)', 'BA/BS in Computer Science to Information Technology', 'Experience working with Oracle database and PL/SQL', 'The referral must be made by using the ""Refer a friend"" button on this page', 'The person you refer must be placed within 90 days of being referred', 'The person you refer must complete 480 billable hours', 'Cannot be someone we already have on our team or are currently working with']",2020-12-30 22:18:17
Data Engineer,at HomeLight,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Optimize and execute on requests to pull, analyze, interpret and visualize data', 'Partner with team leaders across the organization to build out and iterate on team, and individual performance metrics', 'Optimize our data release processes, and partner with team leads to iterate on and improve existing data pipelines.', 'Design and develop systems that ingest and transform our data streams using the latest tools.', 'Design, build, and integrate new cutting edge databases and data warehouses, develop new data schemas and figure out new innovative ways of storing and representing our data.', 'Research, architect, build, and test robust, highly available and massively scalable systems, software, and services.', '3+ years of Python and ETL experience, preferably Airflow', 'Experience writing and executing complex SQL queries', 'Experience building data pipelines and ETL design (implementation and maintenance)', 'Scrum/Agile software development process.', 'Expertise with Ruby on Rails.', 'Familiarity with AWS, Elasticsearch, Ruby/Rails, Django, Heroku', 'Experience setting up and managing internal API services.', 'Experience working on a small team, ideally at a startup.', 'Familiarity with the Amazon AWS ecosystem']",2020-12-30 22:18:17
"Mechanical Engineer, Data Center Design",Facebook,4.2 out of 5 from 602 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with internal stakeholders to define project design criteria and develop Basis of Design', 'Manage consultants to implement the project through schematic design, design development, to construction documents', 'Manage the design build contractor to ensure the project meet the business and technical needs defined in the BOD', 'Provide construction administrative support to the project manager during construction with tasks including, but not limited to, responding to RFI’s, issuance of technical bulletins, review submittals and shop-drawings, and conducting source inspections at vendor factories', 'Review consultants’ engineering calculations, run independent engineering and cost analysis', 'Research new designs, materials, and construction methods for data center HVAC equipment and related components', 'Travel to datacenter sites for engineering studies, mechanical systems audits, startup testing, and full commissioning, as required', 'Provide instructions to design consultants, installation contractors, and validate quality of installed works', 'Take ownership and work to achieve the goal with good team spirit', 'Provide solutions to projects under pressure', 'Respond on an as-needed basis to emergencies', 'BS in Mechanical Engineering, or other technical discipline', 'Knowledge of HVAC systems including Direct Evaporative Systems, Chilled Water Systems, Condenser Water Systems, Pump Controls, Glycool/Glycol, AHU units (DX, split, RTU, CRAC, etc.), CRAH Units, Raised Floor Systems, Hot/Cold aisle containment, Air Filtration, and Building Management System/Controls Automation', 'Knowledge of Plumbing systems including Electric Water Heaters, Water Treatment, Booster Pumps, Distribution, Sanitary/Waste Systems, and Storm Drainage Systems', 'Knowledge of industry standards, building codes and safety standards including UMC, NFPA, ASHRAE, UBC, IMC and LEED', 'Trouble shooting and analytical experience making data driven decisions', 'Experience with construction process and cost estimating process', 'Fluent in English']",2020-12-30 22:18:17
Data Engineer,Dow Jones,3.9 out of 5 from 222 employee ratings,"New York, NY 10176","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Strong familiarity and experience with ingestion, streaming and batch processing, data infrastructure design, and data analytics.', 'Top-notch understanding of basic statistics and issues surrounding data quality', 'Experience building infrastructure required for optimal extraction, transformation and loading of data from diverse data resources', 'Experience running and supporting production of enterprise data platforms.', 'Experience with relational and non-relational databases.', 'Experience building data pipelines in AWS (preferred) or GCP.', 'Proficiency in Scala, Python, Bash, Git, Spark, and SQL.', '2 or more years of data engineering experience', 'Excellent written and verbal communication skills, as well as top organizational, time management, and documentation skills.', 'Experience working with digital media content tracking across websites and mobile applications.', 'Exposure to, or direct experience with, implementing machine learning driven product features or tools.', 'You will report to the Chief of Data Science, who leads our News Insights team.', 'LI-JA1-WSJ']",2020-12-30 22:18:17
Data Engineer,HealthVerity,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Work with the team to load data into HealthVerity's data warehouse"", 'Troubleshoot and resolve issues relating to data integrity', 'Help establish procedures and best practices for transforming and storing data', 'Lead requirements gathering around data pipeline automation improvements', 'Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin', 'Leverage distributed computing and serverless architecture such as AWS EMR & AWS Lambda, to develop pipelines for transforming data', 'Marvel at the speed with which your creation makes it into production', 'Research and implement new technologies with a team of developers to execute strategies and implement solutions', 'Produce peer reviewed quality software', 'Solve complex problems related to the real-time discovery of large data', 'Experienced in writing scalable applications on distributed architectures', 'Data driven, testing and measuring as much as you can', 'Eager to both review peer code and have your code reviewed', 'Comfortable on the command line and consider it an essential tool', 'Confident in SQL, you know it, write smart queries, it’s no big deal', '3+ years of work experience', '3+ years of experience with Python', '3+ years of experience with PySpark and Spark-SQL (writing, testing, debugging spark routines)', '1+ years of experience with AWS EMR, AWS S3 service.', 'Comfortable using AWS CLI and boto3', 'Comfortable using *nix command line (shell scripting, AWK, SED)', 'Experience with MySQL and Postgres', 'Experience with Apache Airflow', 'Experience with Apache Zeppelin', 'Experience with healthcare data', 'Empowering clients with highly rewarding data discovery and licensing tools', 'Ingesting and managing billions of healthcare records from a wide variety of partners', 'Standardizing on common data models across data types', 'Orchestrating an industry-leading HIPAA privacy layer', 'Innovating our proprietary de-identification and data science algorithms', 'Building a culture that supports rapid iteration and new possibilities']",2020-12-30 22:19:57
Data Engineer,Public Health Institute,4.1 out of 5 from 44 employee ratings,"Washington, DC 20024","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Lead the technical solution implementation for core Extract-Transform-Load (ETL) processes associated with USAID/OHA systems primarily the Development Data Commons (DDC).', 'Develop, maintain, test, evaluate, and document data ingestion processes and data pipelines.', 'Implement data models and database schemas aligned with existing and emerging data sources to be analyzed within USAID/OHA systems.', 'Lead transformation analysis and design, analysis of data systems, developing ingestion routines, and pre-ingestion data management.', 'Ensure quality of data ingestion processes meet business and solution needs.', 'Prepare and review project artifacts describing and documenting pipeline processing, data flows, table structures, and data dictionaries as needed.', 'Participates in and presents at technical meetings, seminars and conferences for HIS.', 'International and domestic travel up to 10%.', 'More fully understand the key characteristics of PEPFAR and other HIV and public health data sources for analytic use.', 'Increased knowledge of tools, techniques and frameworks for data ingestion, management, visualization, predictive analytics and machine learning.', 'Deepen knowledge of current literature, research, policies and programmatic experiences related to the HIV response.', 'Participate in professional meetings as appropriate to the position description.', 'Participate in professional continuing education, skills training and professional meetings to enhance relevant technical skills and career development.', 'Complete and execute and Individual Learning and Training Plan and Annual Work Plan.', 'Minimum of a Master’s degree in computer science, public health, health informatics, other relevant discipline is required and 7 years of relevant experience or the equivalent combination of education and experience; or alternatively, must have a Bachelor’s degree in relevant field and 9 years of relevant professional experience.', 'At least 5 years of professional experience with two or more technical disciplines such as (data science, research, database management etc); job duties/responsibilities specifically related to PD requirements.', 'Demonstrated Data Engineering and Data Management experience.', 'Hands-on experience with traditional and/or modern ETL tools (e.g. Trifacta, Alteryx, Informatica, etc.) and big-data processing (e.g. Spark).', 'Hands-on experience with traditional and modern databases such as SQL (e.g. PostgreSQL, MySQL, MS SQL Server, Oracle, etc.) and NoSQL (e.g. Cassandra, MongoDB).', 'Familiarity with Jupyter Notebooks and working knowledge of programming in Python and R.', 'Excellent oral, written, and presentation communication skills. Strong negotiation and group facilitation skills; ability to move a process forward, while meeting the needs of a variety of stakeholders.', 'Experience in developing and delivering end-user training materials highly desired.', 'Demonstrated ability to facilitate complex, mission critical projects and to participate in multi-disciplinary work teams and the ability to quickly understand business processes and translate into data requirements.', 'Ability to adhere to task timelines and deliverable schedules and share concerns about deliverables, timelines, and issues with stakeholders.', 'Strong teamwork, multi-stakeholder collaboration and management skills.', 'Ability to be effective in high-pressure situations, juggle multiple tasks simultaneously, problem solve in a fast-paced environment and set priorities.', 'Ability to travel internationally if necessary up to 10%.', 'S. citizenship or US permanent residence with the ability to obtain and maintain a facility access clearance is required.', 'Facility Access Clearance is required']",2020-12-30 22:19:57
Data Engineer,DeveloperTown,4.5 out of 5 from 2 employee ratings,"Indianapolis, IN 46220","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'High school or equivalent (Required)Data warehouse: 4 years (Required)', 'The Data Engineer will assist DeveloperTown to establish thought leadership in the big data industry', 'Interface with business professionals, application developers and technical staff working in an agile process and environment', 'Develop technical standards, procedures, and guidelines used to govern data models', 'Document success criteria and monitor solution effectiveness, including system performance, adoption and other key metrics', 'Working knowledge of Data Warehousing tools and methodology, reporting tools and ETL tools', 'Create and maintain technical documentation, architecture designs and data flow diagrams', 'Help to lead technology initiatives related to data and analytic solutions for the Marketing and Sales organizations within Global Investment Management', 'Guide development team and business partners in applying data modeling techniques', 'Designing and developing code, scripts and data pipelines that leverage structured and unstructured data integrated from multiple sources', 'Provide technical leadership to clients in a team that designs and develops pathbreaking large-scale cluster data processing systems', 'Providing accurate estimates for project development and implementation. Work with management to meet those estimates', 'Ability to work independently, manage small engagements or parts of large engagements.', 'Work with developers to make sure that all data solutions are consistent', 'The individual will participate in development efforts using Agile development frameworks such as Scrum or Kanban', 'Work collaboratively with Product Management, Technical Marketing and Engineering during the development, launch and continuing refinement of pivotal products', 'Drive development of tools, reporting improvements, and automation, and create new innovative and insightful reports', ""Bachelor's degree in applied mathematics, statistics, computer science, data science, electrical engineering, physics, or closely related field. Masters degree or higher is a plus"", 'Experience implementing predictive and prescriptive models in production systems', 'Experience managing data science projects and mentoring data scientists / analysts', '2+ full cycle product experiences (prototype to production) deploying software utilizing AI/ML technologies', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Demonstrable professional experience with data mining, analysis, modeling, of large scale, complex data sets and driving actionable recommendations', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Retirement plan', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'High school or equivalent (Required)', 'Data warehouse: 4 years (Required)', 'www.developertown.com', 'https://www.facebook.com/developertown', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-12-30 22:19:57
Data Discovery Engineer,M&T Bank,"3.6 out of 5 from 1,507 employee ratings","Cheektowaga, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL', 'Python', ""Combined minimum of 6 years' combined higher education and/or operational/business analytics/systems development experience"", 'Strong verbal and written communication skills', 'Experience with Agile Methodology', 'Strong collaboration with technology partners and customers', 'A team player mindset with an ability to thrive and effectively communicate in a fast-paced, constantly evolving environment']",2020-12-30 22:19:57
Data Engineer,Pinnacle Alliances,N/A,"Roanoke, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Bachelor’s Degree in computer science, information systems, health care business, or equivalent experience required; Master’s Degree preferred', 'Minimum 6+ years of relevant experience required', 'Minimum 3-5 years working with enterprise data sources and ETL tools such as IBM DataStage or Informatica', 'Financial and healthcare knowledge', 'Experience supporting technical service delivery relationships', 'Experience translating business needs into designs and specifications', 'Experience managing projects, testing, and quality control', 'Experience with metadata management', 'Experience with data profiling and data quality analysis', 'Experience working with a coordinated data management environment (CDME) preferred', 'Experience facilitating requirements definition meetings/sessions using structured approaches such as Joint Application Development (JAD)', 'Experience with IBM Infosphere and IBM data models a plus', 'Proficient with dimensional databases, cubes, and columnar data structures', 'Proficient with Microsoft Office applications such as Office, Project, Visio, SharePoint', 'Maintain application vendor certifications as needed', 'Valid VA driver’s license', 'Preferred certifications: ITIL V3, CBAP, CBIP, CDMP, DGSP, PMP', 'Strong listening skills', 'Strong verbal and written communication skills, demonstrating proper business use of grammar and punctuation', 'Strong presentation skills, clearly conveying information, ideas, concepts, and instructions to a variety of audiences', 'Meeting management skills, including agendas, facilitation, minutes, and time management', 'Negotiation skills to resolve conflict and build cooperation', '8 hour shift']",2020-12-30 22:19:57
ML / Data Engineer,Mobiveil Technologies Inc.,N/A,"Longmont, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data analysis: 3 years (Preferred)', '5+ years of experience', 'Strong machine learning background with deep understanding of different types of machine learning algorithms like CNN, RNN, LSTM and Reinforcement learning . Should have completed a few projects from data preparation, training, inference and data analysis.', 'Must have experience working with multi input and output, different type of features', 'Very familiar using frameworks like keras, tensorflow or pytorch or any other deep learning frameworks', 'Proficient with Python development using packages like numpy, panda, scipy, sklearn etc', 'Very proficient in Python, using linux. C++/CUDA is a plus', 'Familiar with Statistics, Linear Algebra, Optimization techniques as applicable to machine learning', 'Familiar training using GPU based frameworks on-prem and in cloud', 'Good problem solving and communication skills', 'Understands data structures, data modelling and software engineering', 'Health insurance', 'Paid time off', '8 hour shift', 'ML algorithms (CNN, RNN, LSTM): 3 years (Preferred)', 'Data analysis: 3 years (Preferred)', 'Likely', 'No', 'Varies']",2020-12-30 22:19:57
Big Data Engineer,Dun & Bradstreet,3.7 out of 5 from 737 employee ratings,"Short Hills, NJ 07078","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'This role can located 100% remote (east coast time zone only).', 'Develop Data pipelines/Ingestion/Engineering and Analytic Application processes to business specification and technology standards that leverage/extend existing Data Analytics platforms.', 'Work with technologies like Cloudera Hadoop, Apache Spark/Spark (DataBricks), Amazon Elastic Map Reduce (EMR), Amazon Athena, AWS Glue, and other related services.', 'Collaborate with project teams (solution architects, business, QA and project management) to ensure solutions meet business objectives and fall within timelines and acceptance criteria', 'Participate in testing of prototypes & validate test procedures to ensure that they are applicable to the design', 'Perform root-cause analysis (RCA) of complex issues ranging from hardware, operating system, application, network, and information security platforms while working closely with various infrastructure teams and business users to quickly arrive at creative, tactical and long-term solutions.', 'Bachelor’s degree in computer science, information systems, or other related field or equivalent work experience', '3-5+ years of high-tech industry and/or IT work experience in Big Data project hands on development and solution engineering roles', 'Experience with AWS ecosystem (Redshift, RDS, EMR, Kinesis, S3, Data pipeline, Glue, Athena, EC2, Lambda, etc.) is required', 'Experience with working on projects in multiple technological and business environments simultaneously', 'A thirst for knowledge, learning, and problem solving', 'Experience in Hadoop, Pig, Hive, Impala (Cloudera a plus)', 'Understanding of micro-services, web-based applications and REST APIs', 'Strong organization skills with high attention to detail', 'Able to work independently with minimal supervision', 'Excellent communication skills – written, verbal, presentation and interpersonal', 'Willing to learn new skills and implement new technologies']",2020-12-30 22:19:57
Data Engineer - Minecraft,Microsoft,"4.2 out of 5 from 7,020 employee ratings","Redmond, WA 98052","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with Project Management, data scientists and business stakeholders to understand requirements and translate to technical requirements.', 'Design, architect and support high quality data frameworks that will provide actionable information to various teams across the studio.', 'Experiment with and recommend new technologies that improve the team’s ability to innovate.', 'Collaborate and communicate with engineers, data scientists and analysts to optimize data flows, tools, operational costs and reporting infrastructures.', 'Use best engineering practices to ensure security and privacy compliance across all development projects.', 'Build data marts for different use cases across the business, using Microsoft and other big data technologies including Azure Synapse.', 'Facilitate ingestion of raw telemetry, and perform cooking, joining, and aggregation to facilitate consumption downstream.', 'Bachelor’s degree in computer science or engineering, database systems, mathematics, or 5+ years of industry experience in a data engineering role.', 'Advanced hands on experience with Azure Cloud Services (Data Factory, Data Explorer, HDInsight. Cosmos DB, SQL) or equivalent', 'Experience with Data Lake infrastructures (Cosmos, Hadoop)', 'Experience with data warehouse technical architectures, ETL/ELT, and reporting/analytic tools', 'Experience optimizing code for hardened, efficient deployments', 'Experience designing and building data warehouse solutions', 'Experience building and maintaining data pipelines', 'Experience with production BI implementations in the Cloud', 'Experience with Machine Learning Model deployment', 'Experience building Power BI, Excel, and Reporting Services dashboards and reports', 'Exceptional problem solving, technical and data analysis skills', 'Great written and verbal communication and presentation skills', 'Be self-driven, and show ability to deliver on ambiguous projects with incomplete or dirty data', 'Ability to work in a team environment that promotes collaboration']",2020-12-30 22:19:57
Infrastructure Engineer,Chester County Intermediate Unit,4.2 out of 5 from 65 employee ratings,"Downingtown, PA 19335","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Bachelor’s Degree in Computer Science (or 4 years’ equivalent field experience), combined with 4+ years of relevant Infrastructure experience.', 'Competent with Windows and OS X server and client computing environments.', 'Competent with routers, switches, firewalls, wireless access points, server hardware, tape backup systems, SAN, NAS, PBX/VoIP, surveillance, door access control, and all other related technologies.', 'Ability to transport between central office and various locations throughout the county and state as required by the position.', 'Current police, child abuse, and FBI Fingerprint clearances required.', 'Install, configure, troubleshoot and maintain intermediate level server hardware and software across the entire organization.', 'Troubleshoot, monitor and maintain advanced configurations for wired and wireless ethernet data networks and associated hardware including routers, switches, and firewalls.', 'Competent in project management, including overseeing external contractors and internal Infrastructure Administrator staff.', 'Assist senior technical staff with system lifecycle planning.', 'Provide staff training on important topics such as “best security practices”.', 'Develop and implement penetration testing to continually harden existing infrastructure systems.', 'Install, troubleshoot, and maintain remote location services such as internet and telephone, and advanced services such as SD-WAN or VPN Tunnels.', 'Provide on-call 24x7x365 response to all infrastructure outages.', 'Evaluate and recommend potential upgrades to equipment, components, and software.', 'Develop and implement appropriate data recovery plans for every critical function and ensure the disaster recovery backup systems are operating properly.', 'Develop and implement advanced call flow or other basic configuration changes for VoIP systems.', 'Any other related duties as required by the Director of External Technology or Director of Innovative Educational Services.', 'Competent with installing, configuring and troubleshooting network devices such as switches, routers, wireless access points, firewalls, tape backup systems, and servers/clients of varying operating systems.', 'Competent with installing, configuring, and troubleshooting various telecommunications systems including PBX/VoIP hardware and cell phones.', 'Competent with installing, configuring, and troubleshooting various security access/surveillance systems.', 'Competent with installing, terminating, and troubleshooting various types of copper and fiber optic cabling used in network environments, maintaining an expertise in complex diagnostic tools such as TDRs, OTDRs, inductive-amplifiers, tone generators, RF spectrum analyzers, multi-meters, and network packet analyzers.', 'Excellent medical, prescription, vision and dental coverage at minimal cost to employee', 'If medical, prescription, vision and dental coverage is not needed, up to $10,391 in opt-out payments available', '1.5% of annual salary flexible benefit cash payment', 'Life insurance in amount of 2.5x annual salary paid by CCIU', 'Long-term disability insurance effective 31st day of illness/injury', ""Retirement through PSERS, PA's Public School Employees Retirement System"", ""Worker's Compensentation"", 'New employees start with 10 vacation days, 12 sick days, and 2 personal days annually; unlimited accumulation on vacation and sick days', 'Tuition reimbursement - 100% of 15 credits per year', '2020-2021 Project Benefit Summary.pdf']",2020-12-30 22:19:57
Data Engineer,Flashpoint,N/A,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help build and maintain our data infrastructure.', 'Become an expert in Apache Beam.', 'Create observability tooling to help other teams debug, understand, and tune their big data jobs and pipelines.', 'Assist and mentor other teams with building and managing their data pipelines.', 'Write tools to automate data processes and deployments.', 'Create maintainable, scalable code to address data needs', 'Write empathetic documentation and runbooks to enable your team to be force multipliers for each other.', 'Help bring in new technologies and develop innovative approaches to the data challenges we face.', 'Apply your honesty, strong sense of morals and ethics, and sense of responsibility towards making Flashpoint and those around you smarter, stronger, and kinder.', 'Identify opportunities for automation and drive process improvements.', '1 - 5 years experience contributing to production systems or other relevant experience.', 'Experience with big data infrastructure.', 'Proficient with Java or Scala.', 'Solid foundation in computer science fundamentals from data structures and algorithms to high level design patterns.', 'Excellent analytical, problem solving and technical skills.', 'Demonstrated ability to learn and leverage new technologies.', 'Experience with SQL schema design and data warehousing.', 'Experience working with queuing systems and stream processing patterns.', 'Basic understanding of privacy and security.', 'An organized work ethic.', 'A humble attitude and persistence to learn and to Get Stuff Done Right.', ""Experience with public cloud data services, particularly Google Cloud Platform's."", 'Experience with Spark, Hive, and/or Hadoop.', 'Experience working with data science teams.', 'Experience with automating infrastructure using leading cloud providers.', 'Proficiency with Python.', 'Diversity. Flashpoint is committed to fostering, cultivating and preserving a culture of diversity, inclusion, belonging, and equity. We recognize that diversity is key to achieving our vision. We believe that every person and their experiences contribute to building a work environment and a product that will change the world.', ""Culture and Belonging. Our company's culture isn't something you join, it's something you build and shape, and each person's unique backgrounds and experiences contribute to who Flashpoint is and will become. You will have ample opportunities to connect with coworkers through various communication channels and company-funded events: dietary & allergy conscious catered lunches, book clubs, happy hours, committees and much more."", 'Benefits. We offer a competitive salary and benefits package, including unlimited PTO, 401(K), mental health and wellness benefits, commuter benefits, and generous parental leave policies.', ""Perks. Flashpoint understands that personal wellness is one of the keys to a happy, healthy and productive work environment. That's why we also prioritize health and wellness perks like gym reimbursements and daily meditation, well-stocked kitchens, cool cultural initiatives and inclusive employee events."", 'Career Growth. Flashpoint is invested in the growth of our team members and understands that frequent, two-way feedback is critical to that growth. We encourage regular one-on-ones with your manager, a regular schedule of performance reviews, learning and development opportunities, and guidance through formalized career paths; whether that be towards being a great manager, being a great individual contributor, or a lateral move to gain breadth of knowledge and experience.', 'A Great Place to Work. Literally. According to the 99% of employees surveyed, Flashpoint earned designation as a Great Place to Work-Certified™ Company for 2021. 100% of employees agree that new hires are made to feel welcome and appreciated. If you are interested in learning more, please check out our Certified Profile.']",2020-12-30 22:19:57
CAD Drafter,Aegion Corporation,3.2 out of 5 from 32 employee ratings,"Malvern, PA 19355","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Interpret engineering and construction sketches and mock-ups for graphical intent', 'Implement consistent style in preparing plan, section, elevation, and detail drawings', 'Update standard details as directed by supervisor or engineering manager', 'Complete all drawings using high professional standards for clarity and neatness', 'Review blueprints, sketches, and specifications related to drafting requirements', 'Exercise judgment to determine essential information', 'Scale drawings for accurate proportion and relationship among components', 'Prepare CAD drawings to represent physical features of client facilities', 'Annotate cathodic protection components to client facility drawings as designed or as installed', 'Measure and record field data as directed by project engineers or project managers', 'Analyze and tabulate data for customer reports', 'Associates of Arts degree with a concentration in Computer Aided Drafting or related field or equivalent required', 'Experience with AutoCAD 14.0 required', 'Persist at difficult tasks despite unexpected obstacles']",2020-12-30 22:19:57
"Data Science & Analytics, Lifestyle Brands Internship- Summer 2021",Discovery Communications,4.1 out of 5 from 392 employee ratings,"Bellevue, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Must be currently enrolled as a student (proof of enrollment will be required if selected for an', 'Must be a rising Junior, Senior, or Graduate student', 'Must have at least a 3.0 GPA', 'Must have the legal right to work in the United States.', 'Our internships are paid opportunities. Credit is not required; however, we will provide documentation if necessary.', 'The application deadline is November 6th. After this date, we cannot guarantee your application will be reviewed for the position.', 'We do not require a cover letter. Please demonstrate your passion for the position through your resume.']",2020-12-30 22:19:57
Data engineer,DiamondPick,N/A,"Dallas, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4+ years of experience in IT industry', 'Expertise in Python and Pyspark', '2+ years of experience using Apache spark', 'Good working experience on Delta Lake and ETL processing', 'Proficiency in SQL queries', 'Prior experience of working in a Unix environment', 'Experience building data platforms using Azure stack', 'Experience in harmonizing raw data into a consumer-friendly format using Azure Databricks', 'Experience extracting/querying/joining large data sets at scale', 'Experience building data ingestion pipelines using Azure Data Factory to ingest structured and unstructured data', 'Experience in data wrangling, advanced analytic modeling is preferred', 'Exposure to Java is a plus', 'Strong communication and organizational skills', '8 hour shift', 'One location', 'Yes: Other non-immigrant work authorization (e.g. L-1, TN, E-3, O-1, etc.)', 'No: Not providing sponsorship for this job', 'Temporarily due to COVID-19']",2020-12-30 22:19:57
Data Engineer,Beyond Finance,3.2 out of 5 from 42 employee ratings,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Own small to medium sized projects independently', 'Work with the latest cutting edge technologies which include AWS, Snowflake, Airflow and Terraform', 'Integrate all our data sources under one data warehouse which will allow our business to examine what is going on in endless ways.', 'Be a team player in contributing your thoughts and ideas to the overall goals of the team', 'Work closely with the Business Intelligence team to deliver them the data they need to answer business questions.', 'Design and build data pipelines while thinking of creating standards and common tools to be as productive as possible', 'Learn how to take deep dives into technologies and troubleshoot issues to understand the root cause', 'Think about how to handle security issues surrounding access, PII, and business-sensitive data.', ""Design for scalability and robustness of availability ensuring the data pipelines work or provide a clear error when they can't proceed."", ""Bachelor's degree in Computer Science or other technical field or equivalent work experience"", '2-5 years of experience working on building services or data integrations; Airflow experience is a plus', 'Solid Python coding and scripting experience', 'Good knowledge of a relational database platform such as MySQL, Postgres, Redshift, Snowflake, Oracle or SQL Server; any cloud database technologies is a plus', 'Experience working with cloud platforms such as AWS, Azure and GCP', 'Exposure in developing batch systems and real time streaming platforms and a sense of the benefits of each approach.', 'Excellent SQL experience working through complex queries', 'Experience in setting up configuration-as-code tools such as Ansible, Terraform, or Chef.', 'Ability to work in a fast-paced environment where continuous innovation is desired, and ambiguity is the norm', 'Experience with agile or Kanban development methodologies']",2020-12-30 22:19:57
Federal - Data Engineer,Accenture,"4 out of 5 from 20,306 employee ratings","Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Architect, design, and implement updates and enhancements to data repositories and indices to support data ingest, enrichment, analysis, visualization, and dissemination', 'Perform database engineering and management activities associated with designing, developing, maintaining, and enhancing data analytic systems from multiple data models using an Agile DevSecOps model', 'Integrate data from multiple sources in batches and real time', 'Review, design, and develop data quality management processes and automated procedures intended to produce high levels of data integrity', 'Research and recommend solutions to complex problems', 'Oversee code reviews and delivering feedback regarding designs/code', 'Perform research and development and provide technical support to identify and integrate new and emerging technologies into the data environment', 'Design and implement storage and indexing strategies to provide efficient storage and retrieval to support visualizations such as graph-based and geospatial indices', 'Support design and development of data access APIs that allow enterprise access (as appropriate) to data', 'Develop or provide input to engineering artifacts associated with the data repositories', 'Experience with SQL / NOSQL databases, and/or Graph Databases (Neo4J)', 'Experience with scripting using (Python, Java, Perl, or PL/SQL)', 'Exposure to Cloud Data Services (AWS)', 'Experience with Architecting and building', 'Experience with Data Engineering and Data transformation', 'Familiarity with no-SQL databases like Neo4j, ElasticSearch, or Cassandra', 'Familiarity with SQL query engines, preferably PrestoDB or SparkSQL', 'Familiarity with distributed platforms (i.e. HBase, Kafka, Spark, NiFi) and the cloud (i.e. AWS, GCP, Azure), preferably Amazon Web Services', 'Experience integrating open API based data access and processing']",2020-12-30 22:19:57
Data Engineer,Flashpoint,N/A,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help build and maintain our data infrastructure.', 'Become an expert in Apache Beam.', 'Create observability tooling to help other teams debug, understand, and tune their big data jobs and pipelines.', 'Assist and mentor other teams with building and managing their data pipelines.', 'Write tools to automate data processes and deployments.', 'Create maintainable, scalable code to address data needs', 'Write empathetic documentation and runbooks to enable your team to be force multipliers for each other.', 'Help bring in new technologies and develop innovative approaches to the data challenges we face.', 'Apply your honesty, strong sense of morals and ethics, and sense of responsibility towards making Flashpoint and those around you smarter, stronger, and kinder.', 'Identify opportunities for automation and drive process improvements.', '1 - 5 years experience contributing to production systems or other relevant experience.', 'Experience with big data infrastructure.', 'Proficient with Java or Scala.', 'Solid foundation in computer science fundamentals from data structures and algorithms to high level design patterns.', 'Excellent analytical, problem solving and technical skills.', 'Demonstrated ability to learn and leverage new technologies.', 'Experience with SQL schema design and data warehousing.', 'Experience working with queuing systems and stream processing patterns.', 'Basic understanding of privacy and security.', 'An organized work ethic.', 'A humble attitude and persistence to learn and to Get Stuff Done Right.', ""Experience with public cloud data services, particularly Google Cloud Platform's."", 'Experience with Spark, Hive, and/or Hadoop.', 'Experience working with data science teams.', 'Experience with automating infrastructure using leading cloud providers.', 'Proficiency with Python.', 'Diversity. Flashpoint is committed to fostering, cultivating and preserving a culture of diversity, inclusion, belonging, and equity. We recognize that diversity is key to achieving our vision. We believe that every person and their experiences contribute to building a work environment and a product that will change the world.', ""Culture and Belonging. Our company's culture isn't something you join, it's something you build and shape, and each person's unique backgrounds and experiences contribute to who Flashpoint is and will become. You will have ample opportunities to connect with coworkers through various communication channels and company-funded events: dietary & allergy conscious catered lunches, book clubs, happy hours, committees and much more."", 'Benefits. We offer a competitive salary and benefits package, including unlimited PTO, 401(K), mental health and wellness benefits, commuter benefits, and generous parental leave policies.', ""Perks. Flashpoint understands that personal wellness is one of the keys to a happy, healthy and productive work environment. That's why we also prioritize health and wellness perks like gym reimbursements and daily meditation, well-stocked kitchens, cool cultural initiatives and inclusive employee events."", 'Career Growth. Flashpoint is invested in the growth of our team members and understands that frequent, two-way feedback is critical to that growth. We encourage regular one-on-ones with your manager, a regular schedule of performance reviews, learning and development opportunities, and guidance through formalized career paths; whether that be towards being a great manager, being a great individual contributor, or a lateral move to gain breadth of knowledge and experience.', 'A Great Place to Work. Literally. According to the 99% of employees surveyed, Flashpoint earned designation as a Great Place to Work-Certified™ Company for 2021. 100% of employees agree that new hires are made to feel welcome and appreciated. If you are interested in learning more, please check out our Certified Profile.']",2020-12-30 22:21:37
CAD Drafter,Aegion Corporation,3.2 out of 5 from 32 employee ratings,"Malvern, PA 19355","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Interpret engineering and construction sketches and mock-ups for graphical intent', 'Implement consistent style in preparing plan, section, elevation, and detail drawings', 'Update standard details as directed by supervisor or engineering manager', 'Complete all drawings using high professional standards for clarity and neatness', 'Review blueprints, sketches, and specifications related to drafting requirements', 'Exercise judgment to determine essential information', 'Scale drawings for accurate proportion and relationship among components', 'Prepare CAD drawings to represent physical features of client facilities', 'Annotate cathodic protection components to client facility drawings as designed or as installed', 'Measure and record field data as directed by project engineers or project managers', 'Analyze and tabulate data for customer reports', 'Associates of Arts degree with a concentration in Computer Aided Drafting or related field or equivalent required', 'Experience with AutoCAD 14.0 required', 'Persist at difficult tasks despite unexpected obstacles']",2020-12-30 22:21:37
"Data Science & Analytics, Lifestyle Brands Internship- Summer 2021",Discovery Communications,4.1 out of 5 from 392 employee ratings,"Bellevue, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Must be currently enrolled as a student (proof of enrollment will be required if selected for an', 'Must be a rising Junior, Senior, or Graduate student', 'Must have at least a 3.0 GPA', 'Must have the legal right to work in the United States.', 'Our internships are paid opportunities. Credit is not required; however, we will provide documentation if necessary.', 'The application deadline is November 6th. After this date, we cannot guarantee your application will be reviewed for the position.', 'We do not require a cover letter. Please demonstrate your passion for the position through your resume.']",2020-12-30 22:21:37
Data engineer,DiamondPick,N/A,"Dallas, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4+ years of experience in IT industry', 'Expertise in Python and Pyspark', '2+ years of experience using Apache spark', 'Good working experience on Delta Lake and ETL processing', 'Proficiency in SQL queries', 'Prior experience of working in a Unix environment', 'Experience building data platforms using Azure stack', 'Experience in harmonizing raw data into a consumer-friendly format using Azure Databricks', 'Experience extracting/querying/joining large data sets at scale', 'Experience building data ingestion pipelines using Azure Data Factory to ingest structured and unstructured data', 'Experience in data wrangling, advanced analytic modeling is preferred', 'Exposure to Java is a plus', 'Strong communication and organizational skills', '8 hour shift', 'One location', 'Yes: Other non-immigrant work authorization (e.g. L-1, TN, E-3, O-1, etc.)', 'No: Not providing sponsorship for this job', 'Temporarily due to COVID-19']",2020-12-30 22:21:37
Data Engineer,Beyond Finance,3.2 out of 5 from 42 employee ratings,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Own small to medium sized projects independently', 'Work with the latest cutting edge technologies which include AWS, Snowflake, Airflow and Terraform', 'Integrate all our data sources under one data warehouse which will allow our business to examine what is going on in endless ways.', 'Be a team player in contributing your thoughts and ideas to the overall goals of the team', 'Work closely with the Business Intelligence team to deliver them the data they need to answer business questions.', 'Design and build data pipelines while thinking of creating standards and common tools to be as productive as possible', 'Learn how to take deep dives into technologies and troubleshoot issues to understand the root cause', 'Think about how to handle security issues surrounding access, PII, and business-sensitive data.', ""Design for scalability and robustness of availability ensuring the data pipelines work or provide a clear error when they can't proceed."", ""Bachelor's degree in Computer Science or other technical field or equivalent work experience"", '2-5 years of experience working on building services or data integrations; Airflow experience is a plus', 'Solid Python coding and scripting experience', 'Good knowledge of a relational database platform such as MySQL, Postgres, Redshift, Snowflake, Oracle or SQL Server; any cloud database technologies is a plus', 'Experience working with cloud platforms such as AWS, Azure and GCP', 'Exposure in developing batch systems and real time streaming platforms and a sense of the benefits of each approach.', 'Excellent SQL experience working through complex queries', 'Experience in setting up configuration-as-code tools such as Ansible, Terraform, or Chef.', 'Ability to work in a fast-paced environment where continuous innovation is desired, and ambiguity is the norm', 'Experience with agile or Kanban development methodologies']",2020-12-30 22:21:37
Federal - Data Engineer,Accenture,"4 out of 5 from 20,306 employee ratings","Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Architect, design, and implement updates and enhancements to data repositories and indices to support data ingest, enrichment, analysis, visualization, and dissemination', 'Perform database engineering and management activities associated with designing, developing, maintaining, and enhancing data analytic systems from multiple data models using an Agile DevSecOps model', 'Integrate data from multiple sources in batches and real time', 'Review, design, and develop data quality management processes and automated procedures intended to produce high levels of data integrity', 'Research and recommend solutions to complex problems', 'Oversee code reviews and delivering feedback regarding designs/code', 'Perform research and development and provide technical support to identify and integrate new and emerging technologies into the data environment', 'Design and implement storage and indexing strategies to provide efficient storage and retrieval to support visualizations such as graph-based and geospatial indices', 'Support design and development of data access APIs that allow enterprise access (as appropriate) to data', 'Develop or provide input to engineering artifacts associated with the data repositories', 'Experience with SQL / NOSQL databases, and/or Graph Databases (Neo4J)', 'Experience with scripting using (Python, Java, Perl, or PL/SQL)', 'Exposure to Cloud Data Services (AWS)', 'Experience with Architecting and building', 'Experience with Data Engineering and Data transformation', 'Familiarity with no-SQL databases like Neo4j, ElasticSearch, or Cassandra', 'Familiarity with SQL query engines, preferably PrestoDB or SparkSQL', 'Familiarity with distributed platforms (i.e. HBase, Kafka, Spark, NiFi) and the cloud (i.e. AWS, GCP, Azure), preferably Amazon Web Services', 'Experience integrating open API based data access and processing']",2020-12-30 22:21:37
Data Engineer,"Adswerve, Inc.",N/A,"Denver, CO 80202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop applications (visualization, routing data, cleaning data, access to data, interacting with data) for analytics pipelines', 'Develop various Big Data capabilities in the cloud for our clients, aligning them with business strategies and requirements', 'Build data pipelines from leading digital marketing platforms including Google Marketing Platform (GMP), Facebook and Instagram to data warehouses', 'Create data warehouses including determining what datasets to include, the right architecture and tools for the job, while also implementing the architecture, automating pipelines, reporting on results, demonstrating and training clients on value of data warehouses for analysis and how to utilize them', 'Support digital analytics implementations with broad understanding of tag management, HTML and JavaScript on websites, as well as installing advanced JavaScript data analytics tools', 'Work with teams of Google Engineers (Googlers) to architect solutions for massive scale, resiliency and maintainability, leveraging various cloud providers which meet technical, security, and business needs for applications and workloads', 'Work with teams including Google Engineers (Googlers) to develop and lead best-in-class engineering practices to help Clients define and set up frameworks for utilizing Big Data in the cloud', 'Work closely with Data Scientists to execute strategic engineering proof of concepts and contribute to technology strategy and engineering roadmaps', 'Develop monitoring strategies for infrastructure, platforms and applications aligning with enterprise strategy and overall industry trends', 'Translate solutions and complicated concepts to all audiences, from executive level members to marketing teams', 'Other duties as assigned', 'College degree in Computer Science, Information Science or related field preferred - OR - successful completion of code school program combined with experience in data engineering', 'Skilled with SQL (for pulling data), Python (for writing pipelines) and JavaScript (for accessing data from websites)', 'Experience with Google BigQuery or Google Cloud Platform (GCP), AWS or Azure tools as they relate to big data', 'Familiarity with HTML, CSS and JavaScript / Modern JavaScript Frameworks (React)', 'Proven ability to solve complex problems with on-time delivery, the highest quality, and creativity in the approach', 'Ability to listen and understand business needs and creatively develop solutions', 'Ability to work on a team and manage and prioritize individual workloads', 'Strong desire to become a proficient Data Engineer for a fast paced company']",2020-12-30 22:21:37
Data Visualization Engineer,AgileOC,N/A,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)Tableau: 1 year (Required)SAP Business Objects (Crystal, Webi, others): 1 year (Required)SQL: 1 year (Required)US work authorization (Preferred)"", 'Help business and other users by developing data visualization dashboards/reports in Business Objects and/or Tableau', 'Access various business systems and cleans data as required', 'Five plus years of data visualization experience', 'One year of experience in SAP BusinessObjects', 'One year of experience in Tableau', 'Strong SQL skills', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Chicago, IL (Required)', ""Bachelor's (Required)"", 'Tableau: 1 year (Required)', 'SAP Business Objects (Crystal, Webi, others): 1 year (Required)', 'SQL: 1 year (Required)', 'Information Technology: 5 years (Required)', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Only full-time employees eligible', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:21:37
"Data Engineer (Remote, United States)",Slync.io,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, build and integrate new cutting edge databases and data warehouses, develop new data schemas and figure out new innovative ways of storing, integrating, and representing our data.', 'Research, architect, build and test robust, highly available, and massively scalable systems, software, and services.', 'Contribute to the AI/Machine Learning integration process and platform.', 'Contribute to the core design of data architecture, data models and schemas, and implementation plan.', 'Optimize and execute requests to pull, analyze, interpret, and visualize data.', 'Design and develop a new framework and automation tools to enable teams to consume and understand data faster.', 'Write well-tested, production-ready code.', 'Improve the efficiency, reliability, and latency of our data system.', 'Create automated, highly reliable data pipelines.', 'Test all code written and ensure production readiness before shipping.', 'You have a high sense of urgency to deliver projects as well as troubleshoot and fix data queries/ issues.', 'You are always on the lookout to automate and improve existing data processes for quicker turnaround and high productivity.', 'Will run ETL processes on a large scale sensitive datasets.', 'B.S. or above in Computer Science or a related field with 3+ years of experience in data-driven technology.', 'Experience with building scalable and reliable data pipelines using Big Data engine technologies.', 'Development experience on GCP platform/ tools and/ or alternate cloud platforms like AWS is highly desirable.', '3+ years writing complicated database SQL queries (Oracle, PostgresQL, Hive, etc).', '3+ years of programming experience is necessary; Java experience highly desirable.', 'Working experience in Big data/ Hadoop Ecosystem of Tools (Spark, Hive, Pig, MapReduce).', 'Proficient in data modeling and data warehouse concepts.', 'Experience building/ maintaining data pipelines in a data warehouse, data lake environment preferably on a cloud platform.', 'Experience implementing operational best practices such as monitoring, alerting, metadata management.', 'Experience using ETL or Data Virtualization for scalable data integration.']",2020-12-30 22:21:37
Scrum Master (Data Warehouse),Piper Companies,4.5 out of 5 from 12 employee ratings,"Conshohocken, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with key stakeholders across 4,000 person organization to develop a new data warehouse', 'Manage project plans/deliverable within prescribed timelines', 'Participate in the adoption of Agile principles', '7+ years of Project Management experience, with 3+ years of Scrum master experience', 'Expertise in managing large scale data projects - data warehouse, Big Data, Data Lakes, etc', 'Heavy focus on data warehousing projects using : AWS (Redshift, Snow Flake), SQL Server, MySQL, NoSQL', 'Experience with Microstrategy - a plus', 'Scrum expert - adept at building user stories, grooming backlog, running Scrum teams, etc.', 'Sound documentation, organization, and attention to details', 'Excellent presentation and interpersonal skills', '$60 - 70/hr W2 (16 month contract with possible hire)', 'Comprehensive benefit package; Medical, Dental, Vision, 401k, PTO']",2020-12-30 22:21:37
Data Engineer,Airvet,N/A,"Irvine, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '3+ years experience with Python', 'Must be very proficient with SQL', 'Must have experience with Airflow', 'Must have experience with Looker / LookML', 'AWS knowledge of EC2 & Redshift', 'Stripe experience', 'Salesforce experience', 'Quickbooks experience', 'Amplitude analytics experience or similar', 'Design, build, and maintain ETL pipelines', 'Work with stakeholders to define end-to-end analytics', 'You have an insatiable need to learn & use new languages and tools.', ""It's not your first rodeo. You thrive in a fast-paced environment with changing priorities."", ""You understand the customer and the business. You know who you are building for, and the benefits you're providing the end user."", 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Fully Remote', 'No: Not providing sponsorship for this job', 'https://airvet.com', 'Only full-time employees eligible']",2020-12-30 22:21:37
Data Engineer,Fabuwood Cabinetry Corp,3.5 out of 5 from 33 employee ratings,"Newark, NJ 07105","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'MUST have strong programming skills in two(!) out of the following languages/tools: Python (familiarity with Jupyter Notebooks is a plus), SQL, R', 'Experience working in a cloud environment (Azure is a plus)', 'An ability to learn and acquire new skills quickly', 'Familiarity with data quality, governance and science approaches', 'Thinking creatively outside the box about data, analytics and problem solving', 'At least five years of data science / predictive analytics experience or more in a commercial setting', 'Experience implementing data collection, analytics and visualization projects', 'Experience implementing modeling and advanced analytics in a commercial and/or production setting', 'Command of data mining and predictive analytics', 'MS degree or an equivalent level of experience in a quantitative field', 'An active blog, publications or GitHub (or similar) repository demonstrating a portfolio of code and projects', 'Demonstrated Python, Data modeling and/or SQL expertise (based on a coding test during the interview process)', '401(k)', 'Dental insurance', 'Health insurance', 'Hospital Insurance', 'Long Term Disability', 'FSA/ Commuters Benefits', 'Paid time off', 'Vision insurance']",2020-12-30 22:21:37
Data Analyst,Optimove,N/A,"New York, NY 10011","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Conducting consumer data research and analytics', 'Working with customer-centric algorithm models and tailoring them to each customer as required', 'Presenting complexed analysis to clients', 'Extracting actionable insights from large databases', 'B.Sc in Engineering, Computer Science, Data Science, or similar major', 'Experience or undergraduate courses focused on SQL and Excel', 'Exceptional work ethic with outstanding technical skills', 'Ability to manage multiple projects simultaneously', 'Strong communication skills', 'Please note that we are unable to provide sponsorship for this position']",2020-12-30 22:21:37
Data Engineer,Visual Concepts,4.2 out of 5 from 13 employee ratings,"Agoura Hills, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create statistical models that can predict and analyze player behavior, optimize engagement, and inform post-launch feature creation.', 'Using created statistical models and analyses, interpret the underlying story to answer business and game design questions.', 'Develop code to facilitate statistical queries and implement hooks to improve data gathering techniques.', 'Work closely with development teams to provide insights into game quality, difficulty, and fun.', 'Establish and distribute regular performance reports based on telemetry and advanced models.', 'Collaborate with other departments to determine project needs and analytics requirements.', 'Maintain data integrity and resolve issues found with incorrect or incomplete datasets.', 'Minimum of 2 years of experience in data mining & analytics, building models with very large, complex and multi-dimensional data sets.', 'Minimum of 1 year of basic programming experience with C++, and able to demonstrate C++ coding proficiency.', 'Expert in relational databases and SQL data carpentry.', 'Experience with varied data modeling approaches.', 'Expert communication, facilitation, and collaboration skills to effectively present, explain, influence, and advise within cross-functional teams.', 'Video games industry experience and/or gaming familiarity.', 'WWE knowledge and familiarity a plus.', 'Experience with JIRA, DeltaDNA, Perforce, and Confluence.', 'Experience with predictive modeling techniques and accomplished in use of R or Python machine learning and related modules.']",2020-12-30 22:21:37
Data Engineer,Empower Retirement,3.1 out of 5 from 94 employee ratings,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', '5+ years of post degree professional experience', '4+ years development experience building and maintaining ETL pipelines', '3+ years of STRONG Python development experience', 'Experience with AWS integrations such as Kinesis, Firehose, Aurora Unload, Redshift, Spectrum, Elastic Mapreduce, SageMaker and Lambda', 'Experience in mentoring junior team members through code reviews and recommending adherence to best practices', 'Deep understanding of writing test cases to ensure data quality, reliability and high level of confidence', 'Track record of advancing new technologies to improve data quality and reliability', 'Continuously improve quality, efficiency, and scalability of data pipelines', 'Expert skills working with SQL queries, including performance tuning, utilizing indexes, and materialized views to improve query performance', 'Advanced knowledge of both OLTP and OLAP environments with successful implementation of efficient design concepts', 'Proficiency with the design and execution of NoSQL database to optimize BigData storage and retrieval', 'Experience with API code integrations with external vendors to push/pull data between organizations', 'Familiarity with data orchestration pipeline using Argo or Airflow', 'Knowledge of analytic tools such as R, Tableau, Plotly, Python Pandas', 'Financial services industry experience is a plus', 'Bachelor of Science degree in Computer Science or equivalent.', 'Medical, dental, vision and life insurance', 'Retirement savings – 401(k) plan with generous company matching contributions (up to 5), financial advisory services, potential company discretionary contribution, and a broad investment lineup', 'Tuition reimbursement up to $5,250/year', 'Business-casual environment that includes the option to wear jeans', 'Generous paid time off upon hire – including a paid time off program plus nine paid company holidays and three floating holidays each calendar year', 'Paid volunteer time — 16 hours per calendar year', 'Leave of absence programs – including paid parental leave, paid short- and long-term disability, and Family and Medical Leave (FMLA)', 'Business Resource Groups (BRGs) - internal networks that rally around common interest, experiences and identities such as race, ethnicity, gender, ability, military status and sexual orientation. BRGs play a vital role in educating and engaging our people and advancing our business priorities.']",2020-12-30 22:21:37
Data Engineer,PHILAINQ,N/A,Pennsylvania,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop, test and maintain data architecture.', 'Design and implement secure data pipelines to prepare, process, ingest and organize data into data data lake / data warehouse from disparate on-premise and cloud data sources.', 'QA and troubleshoot performance of data pipelines and queries accessing data warehouse', 'Clean, transform and model data to power our analytics and user facing products', 'Ensure proper data governance and privacy practices', 'Partner with Analytics team on buildout of advanced data products', 'Assist with automation and orchestration', 'Capable coder with Python, Scala, and R', 'Familiar with modern, cloud-native, scalable ETL solutions/tools, ex: Informatica, Stitch/Talend, Mulesoft/Salesforce, etc…', 'Experience with workflow orchestration principles & platforms (DAGs, Airflow, DBT, Luigi, Dagster, Prefect, etc…)', 'Prefer experience with Google Cloud Platform(Bigquery, Dataproc, Dataflow, Pub/Sub, etc…). Experience with AWS (DynamoDb, Kinesis Stream, etc…) is a plus', 'Building an analytic engine, segmentation and grouping data', 'Experience writing scripts to automate the provisioning and maintenance of systems in a distributed, virtualized infrastructure', 'Familiarity with managed cloud-based options for building machine learning models', 'RDBMS database development using SQL queries and stored procedures', 'Nice to have experience with ElasticSearch, DataDog, Serverless microservices', 'Pay Type Salary']",2020-12-30 22:23:17
Clinical Data Engineer,Healthjump,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Use of data mining, statistical modeling, algorithmic, and visualization techniques.', 'Collaborating effectively with internal stakeholders and cross-functional teams.', 'Application of a breadth of tools, data sources, and analytical techniques to answer a wide range of high-impact clinical questions and present the insights in a concise and effective manner.', 'Design and develop high-performance data architectures, which support data warehousing, real-time ETL, and batch big-data processing', 'Solve analytical problems and effectively communicate methodologies and results', 'Draw inferences and conclusions', 'Create dashboards and visualizations of processed data, identify trends, anomalies', 'Translate project needs and goals into a data-driven analytical approach', 'Be accountable for the successful implementation and support of data analysis, data investigation for health economics and outcomes projects', 'Be accountable for the assessment of technical risks around data', 'Understand the context of big data and its implications around privacy', 'Work autonomously in a fast-paced environment', 'Work with a broad range of technologists and support personnel both within and outside of Healthjump', 'Possess analytical skills with a solid foundation in programming (primarily SQL and Python) as well as data/database design', 'Minimum 3 years experience as a Python or PHP developer', 'Strong working knowledge of SQL, specifically the T-SQL language', 'Experience with Linux based operating systems', 'Experience using APIs to perform actions on 3rd party services', 'Experience working with RESTful APIs and WebSockets', 'Experience using Git version control software', 'In-depth understanding of data models used in relational databases', 'Experience with software testing suites (unit testing, functional testing)', 'BS in Computer Science', 'Experience working with EHR/EMR (Electronic Health Records) data', 'Experience with Amazon Web Services', 'Self-motivated', 'Works well in a team environment', 'Strong communication skills', 'Able to understand non-technical business needs and then translate into an intuitive application', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Fully Remote', 'Waiting period may apply', 'Only full-time employees eligible']",2020-12-30 22:23:17
Data Engineer Internship - Summer 2021 (US),Amazon.com Services LLC,"3.6 out of 5 from 67,873 employee ratings","Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Currently enrolled in or will receive a Bachelor’s or Master’s Degree in math/statistics/engineering or other equivalent quantitative discipline with a conferral date after September 2021', 'Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)', 'Experience with one or more scripting language (e.g., Python, KornShell)', 'Experience with data mining, data warehouse solutions, and ETL', 'Design, implement, and automate deployment of our distributed system for collecting and processing log events from multiple sources', 'Design data schema and operate internal data warehouses and SQL/NoSQL database systems', 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions', 'Monitor and troubleshoot operational or data issues in the data pipelines', 'Drive architectural plans and implementation for future data storage, reporting, and analytic solutions', 'Work collaboratively with Business Analysts, Data Scientists, and other internal partners to identify opportunities/problems', 'Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem', 'Master’s or advance technical degree', 'Proficient in at least one or more query language, schema definition language, and scripting language', 'Knowledge of writing and optimizing SQL queries in a business environment with large-scale, complex datasets', 'Experience with data visualization software (e.g., AWS QuickSight or Tableau) or open-source project', 'Experience with big data processing technology (e.g., Hadoop or ApacheSpark), data warehouse technical architecture, infrastructure components, ETL, and reporting/analytic tools and environments', 'Ability to deal with ambiguity in a fast-paced environment']",2020-12-30 22:23:17
Data Engineer,Kharon,N/A,"Los Angeles, CA 90067","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create secure, resilient, integrated software, working with a variety of data sources and consumers in a complex, distributed environment', 'Integrate and extend data sets in multiple formats and environments', 'Integrate and produce data tracking and event metrics', 'Collaborate with Operational Engineers, Data Engineers, Search Engineers and', 'Data Scientists, as well as Product and Research teams', '4+ years experience as a professional software engineer', 'BS/MS in Computer Science or equivalent experience in completed online coursework', 'Strong skills in Python, Java or Go', 'Experience in multiple languages and stacks, using Procedural and Functional programming', 'Experience implementing best practices in use of data structures and design patterns', 'Understanding of algorithmic complexity analysis', 'Deploying and troubleshooting code in a distributed cloud environment', 'API development and integration', 'Familiarity with GraphQL', 'SQL querying and optimization using DDL and DML', 'Experience with at least one NoSQL database', 'Schema design and mapping', 'Development of data pipelines using event or message driven architecture on Kinesis, SQS, Kafka, RabbitMQ or similar', 'Experience with one or more of the following technologies:', 'Neo4j', 'Kubernetes', 'Elasticsearch', 'Spark', 'Ontological graph composition and transformation']",2020-12-30 22:23:17
Data Engineer / Analytics engineer,Moxieit Cloud,N/A,"Charlotte, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'ETL and DBs: 5 years (Preferred)', 'Prior proficient experience in Capital markets, finance , Banking and investment portfolio.', 'Extensive work experience in executing analytics with Portfolio and market data.', 'Should be able to understand the use cases and assist business users / leaders in generating / enhancing the analytics that helps in business decisions', 'Knowledge of end to end business process cycle of handling the financial assets data.', 'Flexible to adapt new technologies and inherit the established analytics.', 'Goo communication skills, both written and verbal, with the ability to interact with business users and key stakeholders in the line of business.', 'Self-directed, highly motivated and able to work independently.', 'Expert in understanding the analytical and reporting requirements, backtracking the data to data mart till source systems by understanding the end to end data flows', 'Strong querying experience in data marts for what if analysis, Data quality checks and building data sets for adhoc analytics / Reporting', 'Develop the consolidated data mart from multiple source systems - DBs and ETL tools', 'Work experience in developing the adhoc & standard analytics and reporting needs for finance teams.', 'Building the reusable analytics across applications and reduce TAT.', 'Effective knowledge in improving the performance with huge volumes of data analytics.', 'Tools & Technologies: Polypaths (analytics tool) / others, Reporting skills (MicroStrategy/others), ETL skills (SSIS/Others), Data bases (Oracle/Exadata/SQL server)', 'R & Python skills for forecasting the analytics data would be preferable.', 'Monday to Friday', 'Capital Markets: 5 years (Preferred)', 'polypath(analytical tools): 5 years (Preferred)', 'ETL and DBs: 5 years (Preferred)', '5 - 6 months', 'Likely']",2020-12-30 22:23:17
Data Engineer,Walker Edison Furniture Company LLC,3.4 out of 5 from 19 employee ratings,"Salt Lake City, UT 84120","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work closely with Analyst to provide the data and support they need.', 'Modify, build, and maintain data warehouse tables and pipelines through various tools like SQL, python, and AWS stack.', 'Wrangling data from disparate systems and sources such as RDBMS, flat files, and API connections.', 'Optimization of existing SQL queries to improve reliability and performance.', 'Lead the way in data warehouse documentation such as data pipelines, definitions, and warehouse change impacts.', 'Can work remotely and independently under minimal supervision to achieve objectives.', 'Bachelor’s degree in information systems, data analytics, or related field.', '2+ years SQL experience using CTE, window functions, and complex joins.', 'Experience with ETL processes and good data warehouse principles.', 'Basic understanding of Datawarehouse models like Kimbal and Inmon.', 'Should be familiar with terms like primary key, granularity, index, additive attributes, views.', 'RDBMS: Redshift, Postgres.', 'Experience with visualization tools such as Tableau, Looker, and DOMO.', 'Coding experience with Python, R, and other languages.', 'Experience with web scraping.', 'Familiar with Apache Airflow, DOMO, various AWS cloud platform tools.']",2020-12-30 22:23:17
Oops! That page can’t be found.,Walker Edison Furniture Company LLC,N/A,"Salt Lake City, UT 84120","['Indeed Jobs', '404', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Facebook', 'Twitter', 'instagram', 'Youtube', 'Soundcloud']",2020-12-30 22:23:17
Data Engineer (10+ years Required),RISE IT SOLUTIONS,N/A,"East Hanover, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift']",2020-12-30 22:23:17
Data Science Engineer,Triangulate Labs,N/A,"Cincinnati, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Strong probability and statistics background', 'Proficient in predictive analytics', 'Proficient with Python and/or R and current high-performance machine learning libraries', 'Degree in Computer Science, Engineering, Mathematics, or similar field– Advanced degree is a plus', 'Collaborative attitude', 'Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future', 'This is a full-time position based in Cincinnati, Ohio. Telecommuting may be considered for experienced candidates.']",2020-12-30 22:23:17
Federal - Big Data Engineer,Accenture,"4 out of 5 from 20,306 employee ratings","Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience with Data Engineering or Big Data Technologies, or Data Transformation, and modeling', 'Experience in architecting and building scalable data platforms', 'Experience with Cloud Technologies (Data Lake, Azure, Google, AWS etc.) or experience with open source technologies (Spark, Kafka, Presto, Hive, Cassandra etc.)', 'Experience with SQL and/or NOSQL databases', 'Must be a US Citizen; no dual citizens', 'Production implementation experience for all qualifications listed', 'Production experience in building real-time analytics applications', 'Experience in both batch and stream processing technologies', 'Experience with 2 of 3 - Java, Scala, and Python programming languages', 'Machine learning experience with Spark or similar', 'Ability to manage numerous requests concurrently and be able to prioritize and deliver', 'Good communication skills', 'Dynamic team player', 'Bachelor’s Degree']",2020-12-30 22:23:17
Process Engineer - Non Wovens,Jacob Holm Industries,2.8 out of 5 from 23 employee ratings,"Candler, NC 28715","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Process Engineering, 4 years (Preferred)', ""Education:Bachelor's (Preferred)"", 'Responsible for monitoring modifications and upgrades and troubleshooting existing processes.', 'Maintains reliable and safe manufacturing systems while improving production rates, efficiencies, yields, costs and changeovers.', 'Participates in designing, installing and commissioning new production units.', 'Develops innovative solutions and implements systems that optimize all phases of production process.', 'Provides suggestions during incident investigations (Quality, Production, Safety) and advises on corrective actions. Coordinates problem resolution.', 'Partners with Production, Quality, Engineering and Maintenance to develop a cost-effective and working production process.', 'Operates according to established company objectives and specific work programs. Manages the cost and time constraints of their specific projects.', 'Researches and purchases new manufacturing technology.', 'Realizes continuous improvements through eliminating root causes of production efficiency losses, quality improvements, and modeling process and products.', 'Maintains technical expertise.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Relocation assistance', 'Retirement plan', 'Vision insurance', '10 hour shift', '12 hour shift', '8 hour shift', 'Day shift', 'Holidays', 'Monday to Friday', 'Night shift', 'On call', 'Overtime', 'Weekends', 'Bonus pay', 'Process Engineering: 4 years (Preferred)', ""Bachelor's (Preferred)"", 'No']",2020-12-30 22:23:17
SCADA Engineer,Charter Next Generation,3.3 out of 5 from 111 employee ratings,"Lexington, OH 44904","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Use Ignition to develop a standard tag structure, and integrate all lines at the Lexington site.', 'Implement and maintain a wide variety of monitoring and interface applications, including:', 'Live Data Displays', 'Downtime tracking & reasoning', 'Automated EOS reports', 'Order change verification', 'Quality control data interface', 'Order monitoring interface for quality and rate', 'E-mail and hard alarming', 'Install and program data collection PLCs', 'Work with vendors to identify data that can be collected', 'Must have 3+ years of industrial SCADA programming', '4 year degree in Information Technology or Electrical Engineering', 'Experience with SQL server queries and language', 'Must have 1 year of data historian programming', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Health insurance', 'Life insurance', 'Professional development assistance', 'Referral program', 'Vision insurance', '8 hour shift', 'Bonus pay', 'Signing bonus', 'One location', 'http://www.cnginc.com']",2020-12-30 22:23:17
Senior Civil Engineer,"Geotemps, Inc.",4 out of 5 from 36 employee ratings,"Elko, NV 89801","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:civil, geotechnical, or water resources, 2 years (Required)AutoCAD, 2 years (Preferred)', ""Education:Bachelor's (Preferred)"", 'Develop field investigation and laboratory testing programs, evaluate laboratory data to determine inputs for design.', 'Perform engineering analyses such as slope stability, deformation, seepage analyses, bearing capacity, etc. up to and including engineering designs.', 'Create and manage styles, templates, training methods and other aspects of the drafting department.', 'Conduct extensive grading tasks for pond, pipeline, and drainage design.', 'Prepare complete sets of complex civil engineering land development drawings which include multiple views, detail drawings, and assembly drawings.', 'Design land development drawings including complex design features which require considerable drafting skill to visualize and portray.', 'Complete assignments which regularly require the use of mathematical formulas to draw land contours or to compute dimensions, quantities of materials, etc.', 'Work from sketches, models, and verbal information supplied by an engineer, architect, or designer to determine the most appropriate views, detail drawings, and supplementary information needed to complete assignments.', 'Bachelor’s degree in Civil or Geotechnical Engineering', 'Minimum of two (2) to seven (7) years’ industry related land development CAD drafting experience or equivalent education training or experience.', 'Experience using AutoCAD, Land Desktop, or Civil 3D software.', 'Expertise in creating and editing Annotative Civil Styles (surface, point, alignment, label, etc.), Annotative and Non-Annotative AutoCAD Styles (text, leader, dimension, etc.), Civil Templates, Sheet Set Templates, Drawing Templates, View Frames, and Plot Styles.', 'Proficiency in grading and surface management (creating and modifications of grading objects, feature lines, TIN clean-up, analysis and volumetric operations).', 'Proficiency in creating and editing Alignments, Profiles, Sections.', 'Proficiency in creating Corridors (Assemblies and Sub-assemblies using Tool Palettes as well as creating them from scratch, basic Intersections).', 'Proficiency in use of Sheet Set Manager and displaying final presentation graphics (basic rendering skills).', 'Efficient External Reference and Data Shortcut management.', 'Basic GIS and Mapping knowledge (coordinate systems, topology, implementing GIS data).', 'Experience with Microsoft Office Suite and Adobe Acrobat.', 'Possess a Valid driver’s license', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'civil, geotechnical, or water resources: 2 years (Required)', 'AutoCAD: 2 years (Preferred)', ""Bachelor's (Preferred)"", 'Dependable -- more reliable than spontaneous', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'www.geotemps.com', 'No']",2020-12-30 22:23:17
Data Engineer,Capital One,"3.9 out of 5 from 9,133 employee ratings","New York, NY 10012","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-12-30 22:23:17
Cryptologic Technician (Full Time),U.S. Navy,"4.3 out of 5 from 33,101 employee ratings",United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company']",2020-12-30 22:23:17
Systems Engineer - Immediate Opening,"Deep South Data, LLC",N/A,"Covington, LA 70433","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Microsoft Windows Server: 1 year (Preferred)', 'Setting up and troubleshooting computers, servers, and network equipment.', 'Administering school systems.', 'Troubleshooting network issues.', 'Assisting teachers and students with using technology.', 'Oversee and assist two other employees in the I.T. department.', 'At least 3 years experience working with Microsoft Windows servers.', 'Experience with Active Directory, Hyper-V, Windows Server 2012, 2016, 2019, and Windows 10.', 'Experience with iPads and MacBooks.', 'Azure experience a plus.', 'Advanced certifications preferred.', 'School experience a plus.', 'Must be organized and punctual.', 'Must have a reliable vehicle with insurance.', 'Able to multitask in a fast-paced environment.', 'Professional appearance.', 'Excellent written and verbal communication skills.', 'Pass a background check and drug test.', 'Ability to keep all information confidential.', 'Occasional evening/weekend work, as needed.', 'Continuing education and certifications', 'Open-ended career growth', 'Medical and dental after 90 days', 'Paid vacation after 1 year', 'Enjoyable work environment', 'Dental insurance', 'Health insurance', '8 hour shift', 'On call', 'Microsoft Windows Server: 1 year (Preferred)', 'I.T. industry: 1 year (Preferred)', 'One location', 'No', 'Personal protective equipment provided or required', 'Social distancing guidelines in place', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 22:23:17
Senior Data Scientist,Fracta,N/A,"Redwood City, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Strong knowledge and experience in implementing machine learning in real-world applications – minimum 3 years of experience. Experience with structured data.', 'Knowledge and ability to deal with challenging data problems such as data mining, feature definition and ML-based data cleaning.', 'Demonstrated ability to work with highly imbalanced data sets', 'Experience working with data in a cloud-based application (AWS, GCP, Azure)', 'Knowledge of Python required, PyTorch and SQL (BigQuery) preferred', 'Team player: able to solve problems as part of a team and coach junior engineers', 'Desire and ability to work in a fast-paced, results-oriented start-up']",2020-12-30 22:23:17
Data Collection Engineer,"Epiq Systems, Inc.",N/A,"Collegeville, PA 19426","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Computer forensics: 1 year (Preferred)"", 'At least 4-5 years of experience in the electronic discovery industry, IT industry, and/or computer forensic industry and digital forensic data collections', 'Strong technical understanding of Windows, iOS, mobile devices, networks, and computer technologies', 'Experience with e-Discovery data harvesting processes and evidence handling', 'Experience with Robocopy (Robust File Copy), FTK, and other data collection toolsets', 'Strong verbal and written communication skills', 'Available to work evenings and/or weekends if required', 'Experience with Exchange, Office 365, Discovery Accelerator', 'Microsoft Access experience (Preferred, but not required)', 'Responsible for daily electronic data discovery collection efforts including digital forensic data collections', 'Email collection experience using email archiving software such as Veritas Enterprise Vault', 'Responsible for executing project requirements and providing daily status updates', 'Effectively works within a variety of hardware and software technologies', 'Works collaboratively with a team of e-Discovery digital forensic data collection', 'Communicates with Senior Project Manager to resolve issues and provide daily updates', 'Performs quality checks on work related to e-discovery collection requests', ""Follows electronic discovery industry's best practices to ensure work is completed to client satisfaction"", '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Computer forensics: 1 year (Preferred)', 'One location']",2020-12-30 22:23:17
Data Engineer,Apex Global Solutions,2.5 out of 5 from 6 employee ratings,"Suffern, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Multiple locations', 'No: Not providing sponsorship for this job', 'ApexGlobalUs.Com', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-12-30 22:25:14
Data Science and Database Engineer,SPN Solutions Inc.,3.3 out of 5 from 10 employee ratings,"Rosslyn, VA 22209","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)CompTIA Security+ certification (Preferred)US work authorization (Preferred)Confidential (Preferred)"", 'CompTIA Security+ certification (or obtain within 6 months of starting).', 'Expertise exploring and examining healthcare data sets from multiple sources.', 'Experience refactoring database schemas to support evolutionary development, database performance tuning, and design/structural fixes. Includes a solid understanding of data architecture, (i.e., tables, views, definitions, columns, stored procedures, triggers, data quality, and referential integrity).', 'Proven experience in data rewriting, refactoring, architecture, and scaling; to include query refactoring and index optimization.', 'Able to evaluate data architecture for legacy systems, and lead database refactoring efforts by applying enterprise application design patterns.', 'A solid understanding of architectural refactoring (i.e., changes which improve how external programs interact with databases from official data sources); to include CRUD, migrate, and replace methods.', 'Knowledge of statistical modeling techniques and advanced data analytics.', 'Ability developing data set processes for data discovery, modeling, mining, and production.', 'Experience with system comparability using sample data, and regression models.', 'An understanding of data presentation and experimentation design.', 'Superior verbal, written communication, presentation, and customer service skills.', 'DoD experience a plus', 'Knowledge of Agile and DevSecOps testing best practices', 'VPC computing environments (e.g., milCloud 2.0)', 'Knowledge of Roles of Care in Theater (Continuity of Care)', 'Operational Healthcare Functions (Patient Movement, Health Care Delivery to include Dental, MedSA, Med C2, MedLOG to include Theater Blood)', 'Familiarity with:', 'Operations Research/Systems Analyst (ORSA) Handbook.', 'Military Operations Research Society (MORS) -- preferably with published papers and/or books on analytics and experimentation.', 'Virginia Modeling, Analysis & Simulation Center (VMASC).', 'Desired Certifications –', 'Support complex and diverse IT Research and Development (R&D) and data engineering efforts for emerging technology DoD projects.', 'Explore and examine Healthcare data sets from multiple sources or interfaces.', 'Refactor database schemas to support evolutionary development, database performance tuning, and design/structural fixes. Includes a solid understanding of data architecture, (i.e., tables, views, definitions, columns, stored procedures, triggers, data quality, and referential integrity)', 'Perform data rewriting, refactoring, architecture, and scaling; to include query refactoring and index optimization.', 'Evaluate data architecture for legacy systems, and lead database refactoring efforts by applying enterprise application design patterns.', 'Perform refactoring (i.e., changes which improve how external programs interact with databases from official data sources); to include CRUD, migrate, and replace methods.', 'Leverage statistical modeling techniques and advanced data analytics.', 'Develop data set processes for data discovery, modeling, mining, and production.', 'Perform system comparability using sample data, and regression models.', 'An understanding of data presentation and experimentation design.', 'Perform Database refactoring (improving design while retaining informational semantics)', 'Design highly scalable data management systems, and integrating/preparing large, complex data sets that meet functional/non-functional mission requirements, data analysis, movement of data, extracting, transforming, and loading operations of big data sets.', 'Design and sustain data Extract, Transform, and Load (ETL) system, workflow, mapplets.', 'Development and management of Data Lake and Data Warehouse Infrastructures, Data Pipelining and storage.', 'Utilize a variety of tools (scripting languages) to pull data from different source systems critical for data ingestion, refactoring, and optimization of existing data models, to meet functional and performance needs.', 'Comprehensive Health, Dental, and Vision plans available for you and your family', 'Premier 401k retirement plan with corporate matching', 'Generous vacation and sick leave plan', 'Parental leave plan', 'Company paid Life and AD&D Insurance', 'Tuition reimbursement for continuing education', 'Free gourmet coffee, tea, fresh fruits and healthy snacking alternatives', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', ""Bachelor's (Preferred)"", 'CompTIA Security+ certification (Preferred)', 'DASCA (Preferred)', 'SAS Certified AI & Machine Learning Professional (Preferred)', 'CAP (Preferred)', 'Confidential (Preferred)']",2020-12-30 22:25:14
"Data Engineer (Spark, Python)",Capital One,"3.9 out of 5 from 9,133 employee ratings","Plano, TX 75023","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-12-30 22:25:14
Senior Electrical Engineer / FPGA Designer,Klein Marine Systems,N/A,"Salem, NH 03079","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'US work authorization (Required)', 'Mixed signal design', 'FPGA coding (Verilog / System Verilog)', 'Verification testing', 'Collaboration with software and mechanical engineering', 'BS Electrical Engineering (Masters Preferred) – Or similar experience', 'Minimum 5 years designing electronics, FPGA or embedded microprocessor systems', 'Design FPGAs from specifications using Verilog HDL. (Xilinx, Vivado experience a plus )', 'Use Verilog test benches to verify FPGA compliance to specifications.', 'Apply suitable timing constraints to guarantee reliable operation.', 'Familiarity with digital filters in FPGA - low-pass, pulse-compression, FFT.', 'Ability and willingness to reverse-engineer and improve existing FPGA designs.', 'Design digital PCB circuitry for data I/O, computer interface. (OrCAD experience a plus)', 'Guide PCB layout to achieve signal integrity in digital circuitry. (PADs experience a plus)', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Relocation assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'One location', 'http://kleinmarinesystems.com/', 'Waiting period may apply', 'No']",2020-12-30 22:25:14
Data Engineer,Steampunk,4.5 out of 5 from 2 employee ratings,"McLean, VA 22102","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Profile and analyze source system data to determine data relationships, keys, conformed dimensions, and necessary transformations', 'Identify data quality issues', ""Ensure data structures are designed for flexibility to support clients' business needs"", 'Develop strategy and repeatable process for maintaining Enterprise Data Models', 'Design & test integrations to/from data modeling tools', 'Work with developers to create an API access layer for the data', 'Reverse engineer complex, new datasets, and map these new datasets to the existing model.', 'Provide documentation and instruction to data modelers and developers', 'Constantly interact with both ETL developers and end users data analysts to share knowledge, collect feedback, and provide additional implementation requirements.', 'Develop, maintain, and review data processes and architecture for both on-premise and cloud-based data systems', 'You will contribute to the growth of our Data Exploitation Practice.', 'Who wants to do something different......', 'US Citizen Only', 'Ability to hold a position of public trust with the US government.', '5+ years industry experience coding commercial software and a passion for solving complex problems.', '5+ years direct experience in Data Engineering with experience in tools such as:', 'Advanced working SQL knowledge and experience working with relational databases, query authoring and optimization (SQL) as well as working familiarity with a variety of databases.', 'Experience with message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience manipulating, processing and extracting value from large, disconnected datasets.', 'Experience manipulating structured and unstructured data for analysis', 'Experience constructing complex queries to analyze results using databases or in a data processing development environment', 'Experience with data modeling tools and process', 'Experience architecting data systems (transactional and warehouses)', 'Experience aggregating results and/or compiling information for reporting from multiple datasets', 'Experience working in an Agile environment', 'Experience supporting project teams of developers and data scientists who build web-based interfaces, dashboards, reports, and analytics/machine learning models']",2020-12-30 22:25:14
Data Engineer,"Parallax Volatility Advisers, LP",N/A,"Jersey City, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SqlServer TSQL advanced query semantics', 'SqlServer TSQL limited writing of stored procedures, functions, table and index definitions.', 'Powershell and Python scripting, ability to troubleshoot, create, and maintain scripts.', 'SqlServer Integration Services data feed package troubleshooting', 'Unix shell scripting', 'Source code management with Subversion and Git', 'Basic Sqlagent and Bamboo job management', ""Bachelor's Degree in Computer Science, Data Science, Science."", ""Minimum of 3 years' experience in relevant field to Data Quality Management; preferably within a hedge fund or related firm"", 'Must be a U.S citizen or authorized to work in the U.S on a permanent basis', 'SQL Server', 'Suberversion/GIT', 'Bamboo', 'Powershell', 'Python', 'Knowledge of hedge fund data operations and hedge fund trading products (options, futures, stocks, swaps)', 'Clear and effective written and spoken communications', 'External vendor and support channel handling', 'Ability to operate and prioritize own assignments', 'Ability to respond to operational interruptions']",2020-12-30 22:25:14
Client & Data Test Engineer,Apple,"4.2 out of 5 from 9,978 employee ratings","Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Comfortable and adaptable in a fast-paced environment.', 'Strong analytical, problem solving and creative thinking skills.', 'Excellent verbal and written communication.', 'Strong commitment to technical quality assurance as a key part of the software development cycle. Willingness to work cross-functionally.', 'Results-oriented, persistent, and meticulous.', 'Experience writing automation using Python, JavaScript scripting and user-level automation for iOS.', 'Experience with Spark, Hadoop, Kafka or other distributed systems is a plus.', 'Experience in developing and verifying Spark/Map Reduce jobs is a plus.', 'Familiarity with Objective-C or Swift is a plus.', 'Knowledge in SQL, CSS, HTML, JSON a plus.']",2020-12-30 22:25:14
Data Software Engineer,General Dynamics Information Technology,"3.8 out of 5 from 7,499 employee ratings","Rockville, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop Oracle database scripts to maintain data and database in all environments, Dev, Test, Preprod, and Prod', 'Work closely with the tech lead and team lead to solve various database related problems including data model, data quality, db performance, etc.', 'Submit a change request and coordinate to deploy any database changes to all environments', 'Provide data and database support for application development and test activities', 'Maintain all database scripts for both scheduled and unscheduled releases', 'Document database changes for both scheduled and unscheduled releases', 'Attend various meetings to accurately report about database related', 'Bachelor’s Degree in relevant field', '2 + years knowledge and hands-on experience with:Oracle SQL and PL/SQLVarious Oracle database objects development', 'Minimum of 1 year of Oracle database system administration', 'Knowledge and hands on experienceOracle data model designUnix scriptingJava/C#/Python programmingHands-on InformaticaOracle ADF and WeblogicNon-Oracle database like MySQL, SQL Server, etcKnowledge or Hands-on experience with AWS or Azure', 'Excellent verbal and written communication skills']",2020-12-30 22:25:14
Data/Analytics Engineer,SmartAsset,4.1 out of 5 from 17 employee ratings,"New York, NY 10012","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's Degree in a hard science, mathematics, or engineering"", '2+ years of development experience with exposure to Data Science', 'Solid Python and SQL skills', 'Good knowledge of pandas with hands on data wrangling experience', 'Comfortable in the Linux environment', 'Solid math skills - Probability/statistics/calculus', 'PhD/MSc', 'ETL/data pipelining experience', 'Experience with AWS services/EC2 and cloud storage', 'Data Science experience']",2020-12-30 22:25:14
Systems/Data Engineer,Tesla,"3.5 out of 5 from 4,572 employee ratings","Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyze and interpret high volume manufacturing data from various sources and assembly operations to extract useful statistics and insights about the operation', 'Support engineering staff and management in investigations of failures, containment activities, continuous improvement initiatives, etc, in order to drive meaningful improvements to production quality and output', 'Work effectively with engineers and conduct end-to-end analyses, from data requirement gathering, to data processing and modeling', 'Interpret data, analyze results using statistical techniques and provide ongoing reports', 'Monitor key product metrics, understanding root causes of changes in metrics', 'Identify, analyze, and interpret trends or patterns in complex data sets and depict the story via dashboards and reports', 'Create and maintain standardized reporting tools for the operation, providing results on the health of the business for various audiences, including senior management', 'Maintain existing data visualizations, data pipelines and dashboard enhancement requests', 'Acquire data from primary or secondary data sources and maintain databases/data systems to empower operational and exploratory analysis', 'Automate analyses and authoring pipelines via SQL, Python, Tableau, and similar', 'Drive underlying data systems improvement by working with key cross-functional stakeholders', 'Perform data quality validations to ensure data creation', 'Proactively identify improvement opportunities (potential gaps between process and system) across all business functions, developing tools that allow for visibility into process bottlenecks and inconsistencies', 'Work closely with controls, process, and quality engineers to develop and improve data collection activities and reporting tools within a high volume manufacturing environment', 'Work with management to prioritize business and information needs', 'B.S. degree or higher in quantitative discipline (e.g. Computer Science, Mathematics, Physics, Electrical Engineering, Statistics, Industrial Engineering) or the equivalent in experience and evidence of exceptional ability', '3+ years of work experience in data engineering and platform engineering', 'Extensive experience developing software', 'Works well under pressure while collaborating and managing competing demands with tight deadlines', 'A passion and curiosity for data and data-driven decision making', 'Drive to introduce predictive models that can be used for production decision making assistance', 'Possess a high level of attention to detail and professionalism in report creation', 'Be a team player and have the ability to collaborate well across diverse functional groups', 'Strong verbal and written communication skills to manage and communicate the health and integrity of the data and systems', 'Experience in high volume manufacturing is a plus where automated assembly is performed and data collected via Manufacturing Execution Systems', 'Understanding of software and database design in order to work closely with a development team to translate business needs into software solutions', 'Data mining and database (e.g. MySQL) experience', 'Data visualization experience (e.g Tableau)']",2020-12-30 22:25:14
Data Engineer II,TheLadders,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participate in the architecture and development of our cloud-based data pipeline', 'Practice and promote craftsmanship in data infrastructure components (monitoring, testing, code reviews, documentation, scalability, performance, etc.)', 'Own long-term impacts of key design decisions and balance technical debt with business needs', 'Break down requirements, estimate tasks, and assist in planning roadmap accurately', 'Help users get value from analytic data', 'Grow engineering teams through mentorship, recruiting, and interviewing', 'Focus on team over individual achievements', 'Lead definition of team objectives and drive team towards them', 'Previous success in a Data Engineering role, working knowledge of data concepts (optimization, integrity, policies, etc.)', 'Strong SQL and Relational Skills', 'Working knowledge of Cloud Data Platforms (RedShift, BigQuery)', 'Ability to collaborate cross functionally with other engineering and non-engineering departments', 'Architected non-trivial solutions for a company at scale', 'Curious, self-motivated, and an empathetic drive to solve problems', 'Project/Product management experience', 'Application development experience', 'Previous experience working in a startup environment']",2020-12-30 22:25:14
Data Engineer,Tempest,3.3 out of 5 from 17 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with various stakeholders within the organization including marketing, product, finance, engineering , and executive leadership to define data requirements for specific business functions', 'Design and architect the data infrastructure (table design, data flows etc.)Partner with product teams to enable data capture on digital products and business processes', 'Develop data pipes across various sources to collect and stage data for operational and analytical consumption', 'Document data objects to produce technical metadata, and business data dictionaries', 'Manage data loads, data quality checks and defect resolution', 'Develop data visualization and reporting views over base tables', 'Work with Product Managers to own all aspects of web tagging and clickstream data collection', 'Manage and maintain all aspects of Google Tag Manager inclusive of tagging documentation, tool configuration and user administration', 'Develop event architecture for Tempest’s web data and work to integrate into 3rd party platforms (marketing / advertising, email systems, CRM systems, etc)', 'Collaborate with other engineering teams to ensure quality, accessibility, and consistency of collected data across web and native platforms', '5+ years experience in full-stack engineering with a focus on backend and clickstream data development', 'RDBMS and SQL skills are a must', 'PostGres experience preferred', 'Experience with Tag Management systems like Google Tag Manager Applied data warehousing techniques and architecture approach', 'Collaborative team player and self-starter with an ability to prioritize competing priorities', 'Experience with JavaScript, especially as it relates to 3rd party tagging', 'Ability to translate business problems into actionable metrics and technical measurement requirements', 'Ability to translate complicated methods and results into plain language, both in speaking and writing']",2020-12-30 22:25:14
DATA ENGINEER,Bangura Solutions,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop a Data Migration Strategy and document, which covers business/data quality requirements, sources of data from the legacy systems.', 'Manage the data cleansing and migration work-stream.', 'Oversee the implementation of interfaces.', 'Lead the data work-stream in developing various mappings and process flows using SQL and other business intelligence tools to migrate data from the Legacy systems.', 'Develop Test plans, scripts an execution test cases for Systems End to End testing and UAT.', 'Housing', 'Data Cleansing', 'Data Migration', 'Interfaces', 'Full data lifecycle of project.', 'Excel for data cleansing and migration', 'Experience of data migration from Northgate OHMS', 'Experience of Housing, Local Council, Repairs, Asset Management interfaces', 'Experience of Oracle and SQL Server', 'Experience of managing Junior Staff', 'Full understanding of data protection practice and GDPR', 'Database administration experience and understanding of data management']",2020-12-30 22:25:14
Data Analyst (1-2),Function of Beauty,2.2 out of 5 from 22 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with complex datasets across our rich and varied platforms to perform analysis and design predictive models.', 'Use data to discover business insights, uncover new opportunities, provide recommendations and influence decisions.', 'Deepen our understanding of pattern/trends in customer behavior, support customer experience optimization and improve both acquisition and retention.', 'Work cross-functionally to ensure access to useful data and drive value creation.', 'Promote a data-driven organization and empower teams with actionable data and with automated and intuitive KPI dashboards.', 'Support our A/B testing activities in conjunction with the Engineering team.', 'Constantly look for improvements in tools, data sources, data quality, and analytic techniques; build structure and process around data science initiatives and requests.', ""You have a bachelor's degree in a quantitative field (math, data science, computer science, economics). Graduate degree is a plus."", 'You are an expert with MySQL and have experience with industry leading business intelligence tools, such as Mode, Periscope, Tableau, or Looker. Knowledge of Python is a plus.', 'You have experience with creating and managing data warehouses, as well as the ETL/ELT work flow.', 'You have 1 to 2 years of experience in solving business problems by leveraging large datasets. Direct to Consumer start-up experience a plus.', 'You have proven ability to think creatively, solve strategic problems, learn quickly, work independently, handle ambiguity and clearly communicate results in a business-oriented manner.', 'Full Time, Exempt']",2020-12-30 22:25:14
Senior Industrial Engineer - Distribution,TZA,2.3 out of 5 from 9 employee ratings,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'One location', 'No']",2020-12-30 22:25:14
Data Engineer,Capital One,"3.9 out of 5 from 9,133 employee ratings","Chicago, IL 60695","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-12-30 22:25:14
Data Engineer,Entera,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Use Python, SQL, and R to improve upon a best-in-class data pipeline and develop our workflows', 'Contribute to cloud-first services that improve our reporting, analysis, and metrics collection efforts', 'Use agile software development processes to iteratively make improvements to our back-end systems', 'Mold front-end and back-end data sources to help draw a more comprehensive picture of user flows throughout our system', 'Deliver on detailed specifications for business intelligence and reporting needs', 'Contribute and further develop our data-driven culture', 'Work with product and engineering in cross-functional teams to deliver on improvements to our systems', 'MS or PhD in Computer Science, Mathematics, Statistics, Physics, Economics, or similar hard-science', '3+ years hands-on experience in Data + Analytics at growing product-driven tech companies', 'Proficiency in cloud services and modern ETL workflows', 'Advanced capabilities across Python, R, and SQL', 'Understanding of Spark', 'Strong analytical and problem solving skills', 'Working knowledge of Python web frameworks like Flask', 'Software development background']",2020-12-30 22:27:00
Data Engineer,BambooHR,3.9 out of 5 from 15 employee ratings,"Lindon, UT 84042","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build and maintain core data model schemas for BambooHR’s data warehouse', 'Write code, scripts, and metadata in tools such as SQL, dbt, Python, and Airflow, to transform incoming data from product databases and third-party systems to formats and structures in reusable data views', 'Collaborate with data analysts, data scientists, AI software engineers, and stakeholders to make effective use of core data assets', 'Monitor and improve the health of our data pipeline and the quality of data delivered', 'Contribute to the evolution of tools, systems, and methods for harnessing data', 'Help ensure appropriate data privacy and security', 'Data querying and manipulation with SQL, dbt, Python, and the like', 'Data exploration and visualization a la Tableau', 'Cloud-based computing environments like AWS and GCP', 'Distributed data infrastructure such as Kafka, Spark, or Hadoop', 'Message queues and event-oriented architectures', 'Git-based team coding workflows', 'Clear communicators with team members and stakeholders', 'Analytical and perceptive of patterns', 'Creative in modeling and coding', 'Detail-oriented and persistent', 'Productive in a dynamic setting', 'Great Company Culture. We’ve been recognized by multiple organizations like Inc, Salt Lake Tribune, Glassdoor, & Comparably for our great workplace culture.', 'Work that Stays at Work. Genuine work/life balance served here!', 'Rest and Relaxation. 4 weeks paid time off, 11 paid holidays, and you’ll never work on your birthday!', 'Health Benefits. Medical with HSA and FSA options, dental, and vision.', 'Prepare for the Future. 401(k) with a generous company match, access to a personal financial planner, and both legal and life insurance.', 'Financial Peace University. We pay for the class and you walk away with financial savvy and a bonus.', 'Give back. Get paid to give your time to the community: ask us about this!']",2020-12-30 22:27:00
Data Engineer,Pantheon,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create an automated, state of the art, data platform for various job types and sizes', 'Help stabilize a standard deployment pattern that will enable us to grow our data platform service capabilities for the company', 'Close collaboration with the wider engineering team to both deliver platform improvements and provide subject-matter-expertise for other technology initiatives', 'Continuous improvements to our standard of engineering excellence by implementing best practices for coding, testing, deploying and communication', 'Knowledge of large-scale platforms and the design of scalable, robust services in the real world, especially for data transfers and manipulations (both streaming and batch)', 'Experience with a variety of data store types, tech stacks, and the tradeoffs between them.', 'Experience with scripting the creation of dynamic platform infrastructures hosted by one or more cloud providers such as Google or AWS.', 'Desire to work on a new project and participate in the design and documentation activities related to the creation of new infrastructure.', 'Strong experience in Python', 'Automating infrastructure with kubernetes', 'Scheduling ETLs using Airflow', 'Exposure to frameworks such as Django', 'Experience working on new “greenfield” projects', 'Experience supporting data scientists and analysts through PaaS', 'Industry competitive compensation', 'Stock options', 'Vacation days and time off', 'Full medical coverage (medical, dental, vision)', 'top-of-line equipment', 'Fun at Drupal community events', 'Discounts on custom bicycles - the founders of Pantheon also Founded Mission Bicycle', 'Training stipend to attend industry conferences']",2020-12-30 22:27:00
"Data Engineer, System Software",Tesla,"3.5 out of 5 from 4,572 employee ratings","Palo Alto, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Perform complex data analysis from raw data to meaningful insights using Splunk, Spark, and Python', 'Develop, maintain, and improve CI/CD pipelines to support Extract, Transform, and Load (ETL) applications', 'Support application level development, monitoring, support, and debugging', 'BS or higher in computer science/engineering, software engineering, physics, math, electrical engineering or proof of exceptional skills in related fields, with practical engineering experience', '3+ years of experience working with advanced data analysis tools', '1+ years of experience with Python, Splunk, Spark, and SQL; advanced Spark API experience preferred', 'Experience with Kubernetes, Docker, and CI/CD methods', 'Strong aptitude to collaborate with different internal stakeholders to understand requirements and developing systems and tools to meet them', 'Excellent oral and written communication skills', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'A passion and curiosity for data and data-driven decision making', 'As a full time Tesla employee you will receive full benefits from day 1 for you and your dependents.', 'Kaiser and UnitedHealthcare PPO and HSA plans (including infertility coverage)', '3 medical plan choices with $0 paycheck contribution', 'Vision & dental plans (including orthodontic coverage)', 'Company paid Life, AD&D, short-term and long-term disability', '401(k), Employee Stock Purchase Plans, and other financial benefits', 'Employee Assistance Program, Paid Time Off, and Paid Holidays', 'Back-up childcare and employee discounts']",2020-12-30 22:27:00
Data Engineer,thomasarts,N/A,"Farmington, UT 84025","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)experiencing coding REST and APIs using Python: 2 years (Preferred)understanding of API development: 2 years (Preferred)relational MySQL databases: 2 years (Preferred)Python (object-oriented/object function): 2 years (Preferred)AWS Cloud services: EC2, RDS: 2 years (Preferred)REST API calls and best practices: 2 years (Preferred)performing root cause analysis (internal/external): 2 years (Preferred)"", 'Architect API and integration strategy across different applications, including Salesforce Marketing Cloud.', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies.', 'Interface with Clients in order to learn and understand business requirements.', 'Use Client information to assemble large, complex data sets that meet functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using MySQL and Python technologies.', 'Access data through API’s, FTP file drops and email attachments in order to stage data for reporting and analysis.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Other duties as assigned.', 'Working MySQL knowledge and experience working with relational databases, query authoring as well as working familiarity with a variety of databases.', 'Working Python language knowledge and experience with core programming basics including:', 'Objects, Definitions, Variables Loops and if-statements.', 'Strong understanding of API development and functionality.', 'Minimum of 2 years of experience coding REST services and APIs using Python', 'Experience building new database tables and stored procedures with MySQL or similar database architecture.', 'Ability to document architecture, structure and implementation details for your projects.', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'We are looking for a candidate with 3+ years of experience in a data or analytics role, who has attained a Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using some combination of the following software/tools:', 'Experience with relational MySQL databases.', 'Experience with using Python in an object-oriented/object function way.', 'Experience with AWS cloud services: EC2, RDS.', 'Experience with REST API calls and best practices.', 'Other duties assigned', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'On call', 'Weekends', ""Bachelor's (Preferred)"", 'experiencing coding REST and APIs using Python: 2 years (Preferred)', 'understanding of API development: 2 years (Preferred)', 'relational MySQL databases: 2 years (Preferred)', 'Python (object-oriented/object function): 2 years (Preferred)', 'AWS Cloud services: EC2, RDS: 2 years (Preferred)', 'REST API calls and best practices: 2 years (Preferred)', 'building database tables & stored procedures: 2 years (Preferred)', 'performing root cause analysis (internal/external): 2 years (Preferred)', 'One location', 'thomasarts.com', 'Temporarily due to COVID-19', 'Remote interview process', 'Personal protective equipment provided or required', 'Temperature screenings', 'Social distancing guidelines in place', 'Virtual meetings', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 22:27:00
Software Engineer Intern,PayPal,"3.9 out of 5 from 1,386 employee ratings","New York, NY 10018","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Code high-volume and scalable software', 'Create web applications using React/Node and other technologies', 'Create back end services using Java, SQL, ReST', 'Build and develop new user facing experiences', 'Partner closely with cross functional teams in design, product and other business units', 'Must be pursuing a Bachelor’s or Master’s degree in Computer Science or related field from an accredited college or university', 'Strong applied experience. You’ve built, broken, and rebuilt software applications. We’re looking for creative thinkers who also know how to create real-world products', 'Working knowledge of web technologies (such as HTTP, HTML/DOM, JavaScript, CSS, AJAX) will be beneficial', 'Familiarity with Node.js applications', 'Familiarity with Java, C++ and/or Python', 'Understanding around concepts like Web Services, SOA, REST APIs', 'A constant desire to grow, learn, and explore new things']",2020-12-30 22:27:00
Summer 2021 Data Engineer Intern,CBS Interactive,3.5 out of 5 from 87 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Participate in design discussions', 'Collaborate with other engineers within the team', 'Develop data pipelines with acceptable data quality', ""This is a paid internship and can also be for university credit if it meets your university's guidelines"", 'Experience with Google Cloud', 'Experience with Microservices', 'Intern must be a student currently enrolled in an accredited college, university or bootcamp', 'Must be at least 18 years old']",2020-12-30 22:27:00
Software Engineer,Moody's Corporation,3.7 out of 5 from 458 employee ratings,"West Chester, PA 19380","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Front-end and back-end web development', 'Support and improve existing codebase', 'Debug user-reported issues', 'Architect new products and upgrade existing features', 'Work collaboratively with team members and other stakeholders to ensure successful delivery and implementation of assigned tasks', 'Participate in several aspects of the software development life cycle (SDLC)', '3+ years’ experience in the following areas:', 'Solid understanding of web technologies', 'Programming (C#, JavaScript, Typescript, Node, React, etc.)', 'Databases (Microsoft SQL, MongoDb, Redis, MySQL, etc.)', 'Source code management tools (Subversion, Git, VSS, etc.)', 'Cloud (Amazon Web Services, Microsoft Azure, Google) services', 'BS in Computer Science (or equivalent)', 'Knowledge of the software development life cycle (SDLC) including Agile Development Methodology', 'Strong analytical, problem-solving, and troubleshooting skills', 'Ability to stay current on trends within functional area of expertise and the industry', 'Excellent time management and organizational skills', 'Strong written, verbal, and interpersonal communication skills', 'Demonstrated team player', 'Willingness to learn, a can-do attitude, and motivated to succeed and grow']",2020-12-30 22:27:00
Data Engineer II,Expedia.com,3.9 out of 5 from 927 employee ratings,"Seattle, WA 98119","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, architect, implement, and support key datasets that provide structured and timely access to actionable business information with the needs of the end customer always in view', 'Retrieve and analyze data using SQ and other data management systems', 'Create ETLs/ELTs to take data from various operational systems and craft a unified dimensional or star schema data model for analytics and reporting', 'Develop a deep understanding of vast data sources (existing on the cloud) and know exactly how, when, and which data to use to solve particular business problems', 'Experience developing and operating large scale analytical databases/platforms/data warehouses and performing ETL across multiple operating systems (Microsoft and Linux)', 'Experience in working with Cloud BI Production implementation', 'Experience with Agile, DevOps, CICD frameworks', 'Experience working with multi-terabyte data sets using relational databases (RDBMS) and SQL', 'Experience using Agile/Scrum methodologies to iterate quickly on product changes, developing user stories and working through backlogs.', '5+ years of experience with detailed knowledge of data warehouse technical architectures, ETL/ ELT, reporting/analytic tools, and data security', '3+ years of experience in designing data warehouse solutions and integrating technical components', '2+ yrs of experience with any scripting language (Ruby, python, etc.)', '2+ yrs of experience leading data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies', '1+ yr of experience with production BI implementation in the Cloud', 'Exposure in at least one reporting tool like Qlikview, Tableau, Power BI etc.', 'Capable of investigating, familiarizing and mastering new data sets quickly', 'Experience with building data platform on cloud (AWS)', 'Good familiarity with Linux/Unix scripting', 'Experience with Snowflake Computing, Kafka, or Kinesis are a huge plus', 'LI-ES1']",2020-12-30 22:27:00
Data Warehouse Engineer,Solution Street,5 out of 5 from 2 employee ratings,"Herndon, VA 20171","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Responsible for assisting with the architecture and design of enterprise data warehouse processes, including migration of existing data warehouse data/schema/processes to a new data warehouse architecture', 'Designs and develops Extraction, Transformation and Loading (ETL) processes to acquire and load data from internal and external sources', 'Designs and develops all aspects of the data warehouse processes including data modeling, ETL, data validation and implementation', 'Documents and maintains business definitions, data dictionary and data mapping', 'Implements data source integrations using various services like REST, flat file processing, etc.', 'Evaluates data process optimization opportunities and develops recommendations and improvements', 'Provides support to users in training and education on available data tools as required', '5+ years of experience in Information Technology', '5+ years in Data Warehouse applications', '5+ years of experience with the BI/DW lifecycle components including Source Data Analysis, ETL, ODS, Data Marts, Data Mining', '5+ years of analysis, development and programming experience', 'Significant experience with data modeling skills', 'Significant experience with SQL and Relational Databases (e.g. PostgreSQL, Oracle, SQL Server, etc)', 'Experience with BI/reporting tools (i.e. Tableau, PowerBI, Domo, MicroStrategy, SAS, etc.)', 'Strong verbal and written communication skills, with an ability to translate business requirements into actionable data warehouse processes, data, and reports', 'Strong organizational and planning skills, strong analytical abilities, and process orientation', 'Experience with Amazon Web Services, including Redshift and AWS Glue', 'Experience with PostgreSQL', 'Experience with Tableau and/or Domo reporting tools', 'Experience with git, Jira, and Confluence', 'Experience with Salesforce integration and/or development', 'Experience with mortgage banking data/systems', 'Some agile project management experience, for example managing tasks in Scrum or Kanban boards', 'This is a short term contract role.', 'NO third party candidates']",2020-12-30 22:27:00
Data Engineer,Booz Allen Hamilton,"3.9 out of 5 from 2,200 employee ratings","Fort Belvoir, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience with data pipeline and workflow management tools, including Azkaban and Airflow and AWS cloud services, including EC2, EMR, RDS, and Redshift', 'Experience with performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Knowledge of ETL tools, data APIs, data modeling, and data warehousing solutions', 'Knowledge of statistics and machine learning', 'Knowledge of R, Python, Ruby, C++, Perl, Java, SAS, SPSS, and Matlab', 'TS/SCI clearance', 'BS or BA degree', '1+ years of experience with software development', 'BA or BS degree in CS, Information Systems, or equivalent field and 7+ years of experience in a similar data engineer role, or MA or MS degree in CS, Information Systems, or equivalent field and 5+ years of experience in a similar data engineer role']",2020-12-30 22:27:00
Data/BI Engineer,Makeen Technologies LLC,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Translate business needs to technical specifications', 'Design, build and deploy BI solutions (e.g. reporting tools)', 'Maintain and support data analytics platforms', 'Create tools to store data', 'Conduct unit testing and troubleshooting', 'Evaluate and improve existing BI systems', 'Collaborate with teams to integrate systems', 'Develop and execute database queries and conduct analyses', 'Create visualizations and reports for requested projects', 'Develop and update technical documentation', 'Proven experience as a BI Developer.', 'Background in data warehouse design (e.g. dimensional modeling) and data mining', 'In-depth understanding of database management systems, online analytical processing (OLAP) and ETL (Extract, transform, load) framework', 'Familiarity with BI technologies (e.g. Microsoft Power BI, Oracle BI)', 'Knowledge of SQL queries, SQL Server Reporting Services (SSRS) and SQL Server Integration Services (SSIS)', 'Required experience with Redshift,', 'Required experience with AWS Glue,', 'Required experience with python,', 'Required experience with AWS Quick sight', 'Proven abilities to take initiative and be innovative', 'Analytical mind with a problem-solving aptitude', 'BSc/BA in Computer Science, Engineering or relevant field']",2020-12-30 22:27:00
Data Engineer,BetterUp,4.3 out of 5 from 3 employee ratings,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Accessibility: Collected data should be accessible, or appropriately inaccessible, to all services, products, and people of the organization.', 'Data Approachability: Data should be intuitively familiar to the observer.', 'Data Awareness: Cultivate a community of data-conscious practitioners.', 'Data Unifier: Architect, assemble, assimilate, clean, and conform large, complex datasets to deliver business insights and power product experiences.', 'Data Advocate: Weave data into decision-making and drive cross-functional data-oriented approaches and solutions.', 'Data Protector: Design and build reliable, scalable data infrastructure with leading privacy and security techniques to safe guard data.', 'Data Builder: Own the end-to-end data stack including event collection, data governance, data integrations, and modeling.', 'Data Custodian: Ensure consistency and quality through metrics, documentation, processes, data testing, and training.', 'Experience with analytic databases (e.g. Snowflake).', 'Advanced knowledge of SQL and experience with relational databases.', 'Hands-on experience developing data pipelines. We use (e.g. dbt, Airflow, Stitch Data / Singer specs) .', 'Hands-on experience with event streams and stream processing (e.g. Kafka, Spark, Data Bricks, Segment).', 'Decoupling transactional or source systems from business intelligence reporting (e.g. dimensional modeling).', 'Experience with creating high-quality, fast services and projects in Python.', 'Experience with modern business intelligence and product reporting tools (e.g. Mode, Looker, Periscope).', 'Access to BetterUp coaching; one for you and one for a friend or family member', 'A competitive compensation plan with opportunity for advancement', 'Full coverage for medical, dental and vision insurance', 'Employer Paid Life, AD&D, STD and LTD insurance', 'Flexible paid time off', 'Per year:', 'Holiday charitable contribution of your choice on behalf of BetterUp', '401(k) self contribution']",2020-12-30 22:27:00
Data Engineer,ICF,3.5 out of 5 from 576 employee ratings,"Washington, DC 20006","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Extract, transform, and load (ETL) processing routines and data feeds to transmit data to and from clients and subcontractors; create necessary data structures or data models to support data at all stages; and design and implement custom data analytic and BI/reporting products.', 'Perform extensive data profiling and analysis based on the client’s data', 'Work with UI teams and/or client to define BI and reporting requirements', 'Developer custom reports and data visualization products', 'Support project delivery on Data Warehouse/BI projects for external and internal clients, including partnering with ICF subject matter experts on project execution', 'Bachelor’s degree (e.g., Computer Science, Engineering, or related discipline)', '2-5 years’ experience developing database ETL environments with business intelligence applications such as Talend, Informatica, SAS', '2-5 years’ experience in SQL and procedural programming', '1-2 years of experience working with databases and BI tools such as Tableau, PowerBI', '1+ years’ experience with services AWS Glue, Lambda, Microsoft Azure Data Factory, Google Cloud Data Flow', 'US Citizen or Permanent Lawful Resident (Green Card Holder) preferred. Employment must be compliant with eligibility for Public Trust Clearance due to Government Contract.', 'Understand ETL concepts of data flow, data enrichment, data consolidation, change data capture and transformation', 'Understand database concepts of referential integrity, indexes and keys and table metadata', 'Demonstrated experience showing strong critical thinking and problem-solving skills paired with a desire to take initiative', 'Proficient with data warehouse design and development and big data systems', 'Proficient with one or more programming languages such as Java or Python', 'Knowledge of Big Data integration tools such as Storm, and Spark, AWS Kinesis, Kafka a plus', 'Experience with DevOps tools like Jenkins/Git to assist development process', 'Experience with agile development process', 'SQL, BI, Talend, Informatica, SAS, Tableau, PowerBI', 'Spark, AWS Kinesis, Storm, Kafka', 'Jenkins/Git', 'Agile', 'AWS, Azure, Google Cloud Platform', 'Comprehensive health benefits', 'Generous vacation and retirement plans', 'Employee support program', 'Participation in charity initiatives']",2020-12-30 22:27:00
Data Engineer for CloudLinux projects [Remote],CloudLinux,N/A,"Palo Alto, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop automatic solution to ingest data from various sources', 'Develop new tools to match data from various sources', 'Develop new tools and metrics for key decision-makers', '2+ years experience in Python with a solid grasp of the pydata stack (numpy, pandas)', 'Experience with Spark or similar framework', '1+ year of experience in SQL', 'Knowledge of Linux (scripting, simple administrating)', '1+ year experience in gathering data from various data sources, experience of work with big databases', 'Experience of work with GIT', 'Excellent communication skills', 'Smart but humble, with a bias for action', 'Knowledge of English language', 'Experience with Tableau would be a plus', 'Experience with data analysis/ data science would be a plus', 'Ability to learn quickly and use new technologies', 'Strong self-motivation, ability to deliver results under a limited supervision', 'Ability to work in a team and independently', 'Formulates new and alternate ideas, approaches, and designs', 'Open to and values collaboration and feedback from others', 'Ability to make decisions and be accountable for decisions and actions', 'Ability to independently analyze a task and find a right solution', 'Adaptable and able to work in a fast paced, rapidly changing environment', 'the chance of a lifetime to get onboard a young, dynamic, and fast-growing technology company;', 'access to ground-breaking technology, and the freedom to expand your skills;', 'a full-time, regular monthly contract, with a competitive compensation paid in US dollars;', 'paid vacation, compensation for coworking, English language training, individual coaching, paid sick leave, medical insurance (if based in Russia or Ukraine), additional national holidays for your region;', 'The freedom to choose where to work, anywhere in the world, so long as you’re online.']",2020-12-30 22:27:00
Data Engineer,Verana Health,N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Forensically explore relational databases to investigate, identify, and understand RDBMS data models.', 'Incubate/Design/Create SQL - DDL, DQL, DML, DCL.', 'Profile various healthcare databases - MySQL, Oracle, PostgreSQL, SQL Server. SQL Server knowledge is preferred.', 'Characterize database instances by utilizing SQL Server toolchain to identify and understand ER models.', 'Create/Review logical entities, define their attributes, and establish relationships between the various data objects.', 'Design physical data models and generate DDLs.', 'Understand healthcare-specific EMR data models, catalog data dictionaries, and map data elements to standard data specifications.', 'Work closely with technology teams to understand processes and policies driving the team goals.', 'Document and improve data mapping and data element identification processes across the entire data ingestion team.', 'A minimum of a BS degree in computer science, software engineering, or related scientific discipline is desired.', '4+ years of experience in Data Modeling, logical/physical database designing.', 'Extensive experience in data modeling and logical data model design.', 'Demonstrated expertise in logical and physical data modeling (ER).', 'Demonstrated proficiency in using data modeling tools, data profiling toolchain, and data (de)normalization techniques.', 'Experience in data models of one/two of the major EMRs - Epic, Cerner, Allscripts, Athena, CareCloud, GE Centricity, Nextgen, eClinicalWorks, Intelichart Pro (MDIntellesys), Compulink, iMedicWare, Integrity etc.', 'Basic understanding of the clinical & EMR workflow, including knowledge of expected high-level data elements and categories, and understanding of standard medical terminologies and coding systems (e.g., ICD-10-CM, CPT)', 'Python and Spark programming skills.', 'Experience with health interoperability standard information models (e.g., FHIR CDM)']",2020-12-30 22:28:43
Data Engineering Intern (Summer 2021),CrowdStrike,3 out of 5 from 14 employee ratings,"Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop, and implement a data model to deliver insightful analytics while ensuring the highest standards in data integrity', 'Implement a data pipeline and to bring in new data to an existing project, and develop a report to demonstrate its effectiveness', 'Assist in the definition and QA of new metrics and KPIs for eCommerce and Marketing Analysts', 'Undergraduate student (preferably Juniors or Seniors) pursuing an Engineering, Math, or Computer Science Degree', 'Proficiency with RDBMS technologies and SQL', 'Proficiency with a programming language – ideally Python', 'Proactive. Excellent writing skills and verbal communication.', 'Problem solving skills. Research technical issues and make recommendations based on findings as issues arise.', 'Exposure to or interest in web analytics, digital marketing, and data visualization', 'Expierence with a major BI Platform (Domo, Power BI, Tableau, etc…)', 'Market leader in compensation and equity awards', 'Competitive vacation policy', 'Comprehensive health benefits + 401k plan', 'Paid parental leave, including adoption', 'Flexible work environment', 'Wellness programs', 'Stocked fridges, coffee, soda, and lots of treats']",2020-12-30 22:28:43
Data Engineer,Zensar Technologies,3.7 out of 5 from 580 employee ratings,"San Jose, CA 95131","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:28:43
Software Engineer/Data Engineer,BlueVoyant,3.5 out of 5 from 2 employee ratings,"College Park, MD 20740","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Strong hands-on programming skills, with expertise in multiple implementation languages/frameworks including a subset of Python, Java, and Scala with delivery background in middleware, and backend implementations.', 'Familiarity with large-scale, big data, and streaming data technologies, as well as exposure to a variety of structured (Postgres, MySQL) and unstructured data sources (Elastic, Kafka, and the Hadoop ecosystem) as implemented at Internet-scale.', 'Experience writing and optimizing streaming and batch analytics.', 'Experience with Agile frameworks, secure software design, test-driven development, and modern, container-delivered code deployment in a cloud-based DevOps environment.', 'BS/BA in Computer Science, Engineering, or relevant field experience.', 'What you will do as a Software Engineer/Data Engineer:', 'Work closely with analysts to transform threat analytics into production-level code.', 'Actively contribute to application architecture and product vision.', 'Participate in requirements gathering and transformation from prototype to product design.', 'Participate in daily development stand-up meetings and regular sprint planning and product demo meetings.', 'Help us stay current on the latest data processing tools and trends.', 'Thrive in our small, fast-paced, product-driven environment', 'Collaborate with teams from across the organization', 'Deliver features and fixes on tight schedules and under pressure', 'Present ideas in business-friendly and user-friendly language', 'Create systems that are maintainable, flexible and scalable', 'Define and follow a disciplined development and engineering workflow', 'Demonstrate ownership of tasks with escalation as needed', 'Be a subject matter expert in one or more of the technologies employed', 'Relentlessly push for successful customer outcomes', 'Possess a strong interest or background in cyber security', 'Participate in all stages of an agile software development lifecycle, including product ideation, requirements gathering, architecture, design, implementation, testing, documentation, and support', 'Refine our software development methodology based on agile/lean practices with continuous feedback and well-defined metrics to drive improvement', 'Maintain up-to-date knowledge of technology standards, industry trends, emerging technologies, and software development best practices', 'Ensure technical issues are quickly resolved and help implement strategies and solutions to reduce the likelihood of reoccurrence', 'Identify competitive offerings and opportunities for innovation including assessments of risk/reward to the company.']",2020-12-30 22:28:43
Data Engineer,Gannett,3.1 out of 5 from 959 employee ratings,"Cambridge, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Create data models and processes for measuring affiliate performance, advertising, and product development efforts.', 'Develop and produce KPI dashboard using APIs to pull data from Google Ads, affiliate platforms, Google Analytics, and more.', 'Automate daily, weekly, and monthly reports, and forecasts for core KPIs for all traffic sources.', 'Work closely with the product engineering team to make sure all new features are properly capturing data.', 'Define best practices and new processes to collect, analyze, and manage data.', 'Troubleshoot data discrepancies; resolve and articulate them.', ""Bachelor's or master's degree in Computer Science, Data Science, Engineering, MIS or related technical field or equivalent combination of education and experience."", 'You have 2+ years working as a Data Engineer.', 'Expertise in JavaScript, Python, Java or another high-level programming language.', 'Experience building and maintaining data pipelines.', 'Experience working with SEM, affiliate marketing platforms, and web analytics.', 'Mastery of SQL.', 'You have a working knowledge of BI tools like Google Data Studio and Tableau.', 'You have a logical, problem-solving mentality.', 'You have a strong understanding of data modeling concepts and methodologies.', 'Strong communication skills and a proven ability to communicate not just raw data but what the data means to various non-technical audiences.', 'You are creative, flexible, eager to learn, and able to work productively in a multi-project, deadline-driven environment.', 'Experience in the digital media industry is a strong plus.', 'Job Family Business Intelligence', 'Job Function General Administration', 'Pay Type Salary']",2020-12-30 22:28:43
Data Engineer,Ryden Global LLC,N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Data analysis skills: 5 years (Preferred)AWS/DevOps: 2 years (Preferred)Glue, Kafka, Redshift: 1 year (Preferred)Python/ETL: 2 years (Preferred)"", 'Collaborate on a daily basis with the product team. This includes pairing for all aspects of software delivery.', 'Create and maintain optimal data pipeline architecture.', 'Assemble large, complex data sets that meet functional and non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Bachelors Degree in Computer Science or job-related discipline or equivalent experience', '5 years of experience with software delivery', 'Experience delivering a product with Agile / Scrum methodologies', 'Experience with PY-Spark', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience with ETL flows using Python', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Proficiency with the following tools that enable the candidate to contribute autonomously: Glue, Kafka, Redshift (with a focus on infrastructure-as-code), Python.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'AWS DevOps skills', 'Humble – is open to being coached, has high Emotional Quotient (EQ) and is self-aware', 'Hungry – desires to get things done while honoring people, and seeks better ways to do the job, is highly motivated by the significant impact this work will have', 'Collaborative – has strong interpersonal skills; demonstrates empathy with teammates and stakeholders, cares about and works well with teammates', 'Willingness to impact beyond defined role', 'Experience with data & analytics product development', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Data analysis skills: 5 years (Preferred)', 'AWS/DevOps: 2 years (Preferred)', 'Glue, Kafka, Redshift: 1 year (Preferred)', 'Python/ETL: 2 years (Preferred)', 'More than 1 year', 'Likely', 'No', 'One location', 'Temporarily due to COVID-19']",2020-12-30 22:28:43
TS/SCI Poly Big Data Engineer,ManTech International Corporation,"3.9 out of 5 from 1,572 employee ratings","McLean, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Top Secret (Required)', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Top Secret (Required)', 'Remote interview process']",2020-12-30 22:28:43
QA Data Engineer (remote),Thrivent Financial,3.9 out of 5 from 368 employee ratings,"Minneapolis, MN 55415","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Develop, implement physical and virtual test data management and test environment solutions across the organization, to contribute towards the success of technology initiatives', 'Develop test data management strategies and plans relevant to each test environment (Dev, Sys and ITE) to provide right-sized, production-like, re-usable and secured test data per data requirements', 'Key responsibilities include source system data analysis, business & privacy data requirements definition, data discovery, profiling, masking & monitoring rules definition and overall data provisioning for setting up a test environment.', 'Works closely with application subject matter experts/business partners/testers to determine appropriate data sources and to define data provisioning mechanism based on the need for test data', 'Learn and contribute to the design of data management and any future transformation of the test environment landscape', 'Works very closely with Application Availability, Compliance and Support teams leads to maintain and support all test environments to maintain SLAs and applicable policies / standards', 'Participates in all phases of a solution delivery including test data and env requirements gathering and provisioning the required test data in the appropriate test environments', 'Conducts full lifecycle activities including requirements analysis and design, develop and deliver capabilities, and continuously monitor performance and quality control plans to identify improvements around Test Data and Test Env management process', 'Lead initiatives to design processes to capture and review test data requirements and test data provisioning techniques and plans', 'Lead work to advance and support information management practices within business processes, applications and technology that underpin the Test Data and Test Env management discipline (e.g. establishing quality processes, performing analysis, participating in technology implementation planning and verification to ensure successful installation of software and/or projects), implementing data provisioning processes, providing the right amount of data in an appropriately provisioned test environment', 'Provide leadership for Test Data & Test Env management related tasks in support of projects', ""Lead the Management and proactive improvement of Thrivent's Test Data & Test Env provisioning practice by analyzing the current systems environment, leveraging proven practices, applications, technology, tools and platforms to support and enhance the discipline"", 'Handle budget responsibilities', 'Leads the delivery, support and maintenance of solutions with one or more business and technology areas.', 'Organizational impact results from mid-large sized projects', 'Lead discussions with tool / product vendors in support of evaluating solutions for process improvements or future offerings', 'Lead set up of test data and virtual environment based on functional test requirements utilizing Enterprise standard tool sets', 'Bachelor’s degree or equivalent in MIS, Computer Science, Mathematics, Business or related field.', '3+ years of experience in data QA.', 'In-depth knowledge of data handling and transformation techniques such as ETL, Test Data and Test Env management concepts and practices.', 'Knowledge of Test Data and Test Env Management concepts and tools.', 'Strong organizational, analytical and critical thinking.']",2020-12-30 22:28:43
Data Science Engineer,Moogsoft,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, implement, and deploy good microservices (bonus points for Python/Java)', 'Expand and build out our correlation and anomaly detection services', 'Work closely with Data Science / Research in designing and implementing machine learning models into fully operationalized services and data feeds', 'Interface with Product/UX and collaborate with them on new designs, existing implementations, stakeholder demos, etc', 'Coach/mentor more junior staff on patterns and practices of good distributed systems development', 'Support the services that you and your team deploy, including Pagerduty rotation', 'Identify and champion for tech-debt items to be addressed/resolved', 'Experience designing and delivering enterprise-grade highly available globally distributed services (more bonus points for Rust/Java)', 'Experience with Data Science frameworks and libraries (TensorFlow, Spark, mlpack, etc)', 'Knowledge on cluster algorithms and ML techniques (k-means clustering, shallow and deep neural networks, etc)', 'Experience building RESTful APIs, preferably with Java or Python', 'Experience with Kafka or similar distributed message queues', 'Experience with various databases and data modeling/data management', 'Mongo, Elastic, MySQL, etc.', 'Comfortable in Linux/JVM based development environments', 'Comfortable navigating and utilizing various tools such as JIRA, Confluence, Gitlab, PagerDuty, Kibana, Grafana, etc', 'Comfortable working without a dedicated “QA” team in a true “service ownership” model', 'Experience with Cloud Provider ML and AI offerings (AWS SageMaker, GCP AI Platform) a plus']",2020-12-30 22:28:43
Big Data Engineer,SoHo Dragon,N/A,"Short Hills, NJ 07078","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop Data pipelines/Ingestion/Engineering and Analytic Application processes to business specification and technology standards that leverage/extend existing Data Analytics platforms.', 'Work with technologies like Cloudera Hadoop, Apache Spark/Spark (DataBricks), Amazon Elastic Map Reduce (EMR), Amazon Athena, AWS Glue, and other related services.', 'Collaborate with project teams (solution architects, business, QA and project management) to ensure solutions meet business objectives and fall within timelines and acceptance criteria', 'Participate in testing of prototypes & validate test procedures to ensure that they are applicable to the design', 'Perform root-cause analysis (RCA) of complex issues ranging from hardware, operating system, application, network, and information security platforms while working closely with various infrastructure teams and business users to quickly arrive at creative, tactical and long-term solutions.', 'Bachelor’s degree in computer science, information systems, or other related field or equivalent work experience', '3-5+ years of high-tech industry and/or IT work experience in Big Data project hands on development and solution engineering roles', 'Experience with AWS ecosystem (Redshift, RDS, EMR, Kinesis, S3, Data pipeline, Glue, Athena, EC2, Lambda, etc.) is required', 'Experience with working on projects in multiple technological and business environments simultaneously', 'A thirst for knowledge, learning, and problem solving', 'Experience in Hadoop, Pig, Hive, Impala (Cloudera a plus)', 'Understanding of micro-services, web-based applications and REST APIs', 'Strong organization skills with high attention to detail', 'Able to work independently with minimal supervision', 'Excellent communication skills – written, verbal, presentation and interpersonal', 'Willing to learn new skills and implement new technologies']",2020-12-30 22:28:43
Full Stack Engineer – Big Data,Deloitte,"4 out of 5 from 9,921 employee ratings","Glen Mills, PA 19342","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'BS or higher in a technical field: CS, Physics, Maths etc…', '3+ years expertise in building large scale big data applications', 'Strong core programming skills in either C#, C++, Python, NodeJS or Java', 'Solid foundation in data structures, algorithms, design patterns', 'Strong understanding of backend and UI development with modern frameworks', 'Strong experience working with relational and non-relational databases', 'Strong proclivity for automation and DevOps practices, Azure DevOps is a plus', 'Experience with managing increasing data volume, velocity and variety', 'Outstanding communicator with both business and technology audiences', 'Knows what is possible using latest technologies (open source, data stores, algorithms, etc.)', 'Experience working across teams and operating in an Agile Scrum culture', 'Experience with continuous delivery and using agile techniques', 'Firm sense of accountability and ownership', 'Passionate for making things better and driving action', 'Desire to understand our businesses and users', 'MS or higher in a technical field: CS, Physics, Maths etc..', '3+ years expertise in building large scale ETL pipelines to onboard data into the platform, define schema, build DAG processing pipelines and monitor data quality', 'Experience in .Net and Azure stack', 'Experience working with databases such as MySQL, PostgreSQL, SQL Server', 'Experience in managing and run mission critical production services.', 'Strong understanding of scalable data query engines: e.g. BigQuery, Presto, Snowflake, Databricks, Spark etc…']",2020-12-30 22:28:43
Data Engineer,Susquehanna International Group,3.8 out of 5 from 58 employee ratings,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with quantitative analysts, trading technologists and traders to provide datasets which help in optimizing trading behavior and results', 'Use your data analysis skills to ensure the data is clean and correct', 'Be comfortable working in an environment where moving fast and developing iteratively is standard', 'Bachelor’s degree in Computer Science, Engineering, Mathematics or related discipline or its foreign equivalent', '2+ years of professional experience developing software and data systems, or advanced graduate work', 'Expertise in C#, C++, or Python']",2020-12-30 22:28:43
Data Engineer,Gradient AI,N/A,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, build, and implement data systems that fuel our ML and AI models', 'Develop tools to extract and process client data from different sources and tools to profile and validate data', 'Work cross functionally with data scientists to transform large amounts of data and store it in a format to facilitate modeling', 'Contribute to production operations, data pipelines, workflow management, reliability engineering, and much more', ""Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'big data' technologies"", 'BS in Computer Science (or in another quantitative discipline); 5+ years of working experience', 'Fluency in SQL and experience with non-relational/alternative databases', 'Experience working in Python in a professional environment', 'Desire to learn new skills and tools (e.g. Redshift, Tableau, AWS Lambda, etc.)', 'Exposure working with a cloud-computing environment (e.g. AWS EC2)', 'Comfortable with Linux, including developing shell scripts', 'Experience working in insurtech or on AI/ML products is a bonus', 'A fun and fast-paced startup culture', 'A culture of employee engagement, diversity and inclusion', 'Full benefits package including medical, dental, vision, 401k, disability, life insurance, and more', 'Unlimited vacation days and ample holidays- we all work hard and take time for ourselves when we need it', ""Competitive salary and generous stock options - we all get to own a piece of what we're building"", 'Ample opportunities to learn and take on new responsibilities']",2020-12-30 22:28:43
Data Engineer : 20-03234,Akraya Inc.,3.7 out of 5 from 15 employee ratings,"Sunnyvale, CA 94089","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'At least 4 years experience in managing Apache Hadoop/Cloudera Hadoop Clusters in a Production environment, including providing monitoring and administration support ofHadoop, HBase, HDFS, Hive, Kafka , Solr ,Spark, Yarn', 'At least 4 years experience in Linux Administration (Redhat and CentOS distributions preferred).', 'Experience with configuration management tools, deployment pipelines, and orchestration services', 'Ansible or Chef or Jenkins', 'Three years experience with GIS', 'Good written and verbal communication skills Strong problem solving skills Self starter, innovator, and team player', 'Advanced Skills Familiarity with GIS tools, such as MapInfo ,Quantum GIS, ESRI , FME (SafeSoft) Familiarity with SQL, Database management, Postgres, POSTGIS', ""Bachelor's degree in a related field, such as GIS, GeoSpatial Technology, Geoinformatics, Geography Candidates with the above basic and advanced skills are encouraged to apply"", 'Responsibilities Research, extract, analyse, and manage geographic reference material Manipulate and curate geographic data from multiple sources for production mapping system Extrapolate general issues from specific issues Ensure geographic data meets accuracy and quality specifications', ""Basic Skills Strong understanding of the world's political geography (countries, administrative areas), named places and postal geography Good understanding of internet search tools Familiarity with geographic principles (coordinate systems, terminology, categorization, data schemas)""]",2020-12-30 22:28:43
"Data Engineer, Financial Services",DataArt,3.9 out of 5 from 12 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience with data analytics, data engineering, and big-data technologies', 'Knowledge of Python', 'Experience with Airflow, and SQL and NoSQL DBs.', 'Experience building data warehouses/lakes and data pipelines using cloud platform tools as well as vendor ETL/ELT technologies', 'Knowledge of data and analytics fundamentals, data modelling, data quality, and data governance principles', 'Spoken English']",2020-12-30 22:28:43
Data Engineer : 20-03234,Akraya Inc.,3.7 out of 5 from 15 employee ratings,"Sunnyvale, CA 94089","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'At least 4 years experience in managing Apache Hadoop/Cloudera Hadoop Clusters in a Production environment, including providing monitoring and administration support ofHadoop, HBase, HDFS, Hive, Kafka , Solr ,Spark, Yarn', 'At least 4 years experience in Linux Administration (Redhat and CentOS distributions preferred).', 'Experience with configuration management tools, deployment pipelines, and orchestration services', 'Ansible or Chef or Jenkins', 'Three years experience with GIS', 'Good written and verbal communication skills Strong problem solving skills Self starter, innovator, and team player', 'Advanced Skills Familiarity with GIS tools, such as MapInfo ,Quantum GIS, ESRI , FME (SafeSoft) Familiarity with SQL, Database management, Postgres, POSTGIS', ""Bachelor's degree in a related field, such as GIS, GeoSpatial Technology, Geoinformatics, Geography Candidates with the above basic and advanced skills are encouraged to apply"", 'Responsibilities Research, extract, analyse, and manage geographic reference material Manipulate and curate geographic data from multiple sources for production mapping system Extrapolate general issues from specific issues Ensure geographic data meets accuracy and quality specifications', ""Basic Skills Strong understanding of the world's political geography (countries, administrative areas), named places and postal geography Good understanding of internet search tools Familiarity with geographic principles (coordinate systems, terminology, categorization, data schemas)""]",2020-12-30 22:30:24
Data Specialist,Construction Journal,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Heavy outbound calling to owners, architects, engineers, and general contractors to obtain specific construction project information.', 'Developing relationships with Construction Managers, Architects, and Engineers to obtain notice of construction projects in conception and planning phases.', 'Collect, process, and input information provided from public offices of zoning notices, site plan approvals, newspaper articles for potential construction projects being considered.', 'Obtaining, plans, specifications, and bidders/plan holders list on out to bid projects.', 'Computer Proficiency with ability to type 55 WPM.', 'Professional work ethic and can-do attitude.', 'Excellent written and verbal communication skills.', 'Strong organizational skills with the ability to meet daily and weekly deadlines.', 'Ability to work independently in a fast-paced environment that also requires strong team work.', 'Advanced education preferred or previous industry work experience.', 'Knowledge in the construction industry is a plus, but is not a requirement.']",2020-12-30 22:30:24
Data Engineer,TechAzimuth Solutions,N/A,"Herndon, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Minimum of 3 years of experience (within the last 10 years) in data engineering', 'Demonstrated experience in Extract, Transform, and Load (ETL) data engineering', 'Demonstrated experience with REST APIs', 'Demonstrated experience in building data models and analytics to support mission needs', 'Demonstrated experience in RESTful protocols, SOAP, RSS and other publishing mechanisms', 'Demonstrated experience with Java', 'Building data products in Apache Avro', 'Utilization of Nifi', 'Utilization of ActiveMQ', 'Demonstrated experience deploying the complete DevOps Lifecyle including integration of build pipelines, automated deployments, and compliance scanning using test driven development.']",2020-12-30 22:30:24
Data Engineer,Catalyte,3.8 out of 5 from 12 employee ratings,"Baltimore, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '401(k)', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Professional development assistance', 'Vision insurance', 'Monday to Friday']",2020-12-30 22:30:24
"Data Engineer, Peacock",NBCUniversal,"4 out of 5 from 2,293 employee ratings","New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, build, test, scale and maintain data pipelines from a variety of source systems and streams (Internal, third party, cloud based, etc.), according to business and technical requirements.', 'Continually work on improving the codebase and have active participation in all aspects of the team, including agile ceremonies.', 'Take an active role in story definition, assisting business stakeholders with acceptance criteria.', 'Work with Principal Engineers and Architects to share and contribute to the broader technical vision.', 'Develop and champion best practices, striving towards excellence and raising the bar within the department.', 'Develop solutions combining data blending, profiling, mining, statistical analysis, and machine learning, to better define and curate models, test hypothesis, and deliver key insights', 'Operationalize data processing systems (dev ops)', 'Experience of near Real Time & Batch Data Pipeline development in a similar Big Data Engineering role.', 'Programming skills in one or more of the following: Java, Scala, R, Python, SQL and experience in writing reusable/efficient code to automate analysis and data processes', 'Experience in processing structured and unstructured data into a form suitable for analysis and reporting with integration with a variety of data metric providers ranging from advertising, web analytics, and consumer devices', 'Hands on programming experience of the following (or similar) technologies: Apache Beam, Scio, Apache Spark, and Snowflake.', 'Experience in progressive data application development, working in large scale/distributed SQL, NoSQL, and/or Hadoop environment.', 'Build and maintain dimensional data warehouses in support of BI tools', 'Develop data catalogs and data cleanliness to ensure clarity and correctness of key business metrics', 'Experience building streaming data pipelines using Kafka, Spark, or Flink', 'Bachelors’ degree with a specialization in Computer Science, Engineering, Physics, other quantitative field or equivalent industry experience.', 'Experience with graph-based data workflows using Apache Airflow', 'Experience building and deploying ML pipelines: training models, feature development, regression testing', 'Data modelling experience (operationalizing data science models/products)', 'Experience with cloud environments such as AWS, GCP, or Azure', 'Strong Test-Driven Development background, with understanding of levels of testing required to continuously deliver value to production.', 'Experience with large-scale video assets', 'Ability to work effectively across functions, disciplines, and levels', 'Team-oriented and collaborative approach with a demonstrated aptitude, enthusiasm and willingness to learn new methods, tools, practices and skills', 'Ability to recognize discordant views and take part in constructive dialogue to resolve them', 'Pride and ownership in your work and confident representation of your team to other parts of']",2020-12-30 22:30:24
Analytics Engineer,Cubesmart,3.3 out of 5 from 414 employee ratings,"Malvern, PA 19355","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Develop, maintain and improve data generation and ingestion pipelines (data processing – 40%)Collaborate with marketers, data scientists, and analysts to develop, maintain and improve data ingestion pipelines; write standardized R or Python codes that are frequently needed for the team.Develop and maintain complex SQL queries; pull and join data from disparate sources and perform data transformations, in support of data science and analytics projects.Evaluate marketing technologies for their data gathering capability; validate and consolidate diverse sources of data such as Salesforce.com, DialogTech, and Adobe', 'Develop and maintain ML algorithms (data analytics – 40%)Work with Data Scientists and Analysts to develop and maintain predictive models and machine learning algorithms, including marketing, pricing, and revenue management programs.Create and maintain standard (daily, weekly or monthly) and ad hoc performance reports', 'Conduct ad hoc analytics (ad hoc support – 20%)Provide strategic data and analytics support to develop and evaluate growth opportunities.Perform ad hoc analysis to discover business insights to enhance marketing programs and optimize pricing systems.', 'BA/BS in a technical discipline or equivalent (e.g., Computer Science, Engineering, Math).', 'Strong in writing complex SQL queries against relational database systems.', 'Proficient in SQL and Python; experience with R strongly preferred.', '3+ years of work experience in providing data support or conducting analytics.', 'Experience with developing and/or implementing machine learning algorithms a plus.']",2020-12-30 22:30:24
Data Engineer - ETL/Integration,Bill.com,3.3 out of 5 from 24 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '3+ years data engineering experience in large scale data warehouse or datalake environment.', 'BS/MS in Computer Science or equivalent is required.', 'Proficiency in building data pipelines using Apache Spark or other ETL technologies is required.', 'Expertise in SQL and data analysis is required.', 'Experience with at least one programming language such as Python or Java is required.', 'Experience with Mulesoft/Workato will be a strong plus.', 'Experience working directly on a Customer Hub or Customer 360 project will be a strong plus.', 'Experience with Amazon AWS is a plus.', 'Humble – No ego', 'Fun – Celebrate the moments', 'Authentic – We are who we are', 'Passionate – Love what you do', 'Dedicated – To each other and the customer']",2020-12-30 22:30:24
Cloud Data Engineer,World Fuel,3.3 out of 5 from 158 employee ratings,"Miami, FL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Own, design, develop, document, and manage scalable solutions for new and ongoing metrics, reports, analyses, and dashboards to support organization needs.', 'Own and develop queries and data visualizations for ad-hoc, recurring, troubleshooting requests and projects, as well as for ongoing reporting by leveraging SQL, AWS Glue and Amazon QuickSight', 'Improve existing data processes and pipelines by implementing automation, data tuning and performance concepts creatively', 'Design and drive experiments to form actionable recommendations. Present to business leaders and drive decisions.', 'Manage AWS resources including Amazon QuickSight, AWS Glue, Amazon Athena, AWS S3', 'Collaborate to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Explore and learn the latest AWS technologies to provide new insights and recommendations to optimize cloud costs', 'Demonstrate exceptional judgment, integrity, business acumen, and communication skills', 'Demonstrate experience in developing complex integrations using Cloud APIs and also including ability to work with cloud development tools, methodologies', 'Attend project meetings and daily standups; raise issues and report progress, Document cloud environments and related processes', ""Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline, or equivalent experience"", 'Relevant experience in business intelligence or business analyst role, including data warehousing, business intelligence, data visualization tools, techniques and technology, or experience in analytics', 'Experience gathering requirements, using business intelligence tools to extract data, formulate metrics, & build reports', '2+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets', '2+ years of experience with traditional RDBMS technologies, SQL, data modeling and ETL development', '2+ years of experience with data visualization tools, techniques and related analytics', '2+ years of programming experience with at least one modern language such as Python', 'Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations', 'Experience with data visualization using Amazon Quicksight or similar tools', 'Experience with SQL', 'Knowledge of at least one modern programming language such as Python', 'Knowledge of managing IaC using AWS CloudFormation, AWS Lambda through AWS CodePipeline', 'AWS associate level certification', 'Experience in Agile software development organization']",2020-12-30 22:30:24
Software Engineer Intern (Summer 2021),"Alteryx, Inc.",4 out of 5 from 25 employee ratings,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Contribute to open source technologies and tools', 'Develop code that may be included in our next release', 'Build and implement new features or tools', 'Help us innovate and design next generation technologies', 'Actively participate in code review sessions', 'Ensure scalable, quality code through unit and functional testing', ""Students currently enrolled in a degree program in pursuit of a Bachelor's or Master's degree in Computer Science or related field"", 'Ability to work for 12 consecutive weeks during the Summer 2020', 'L egally authorized to work in the U.S. and should not require visa sponsorship now or in the future', 'Previous experience in Python and/or Javascript', 'Passion for open source software (no prior experience required)', 'Ability to learn quickly and work autonomously with appropriate mentorship, support, and guidance from your manager', 'Students within 1 year of graduation preferred (e.g., g raduating between December 202 1 through June 202 2)', 'Software engineering experience from previous internship, work experience, personal projects, hackathons, and/or coding competitions', 'Paid company holidays', 'Ownership of high-impact, real-life projects', 'Participation in special events like social/community building activities, speaker series, opportunity to volunteer in local communities, and more', 'Showcase impact by presenting intern projects at company/department-wide events']",2020-12-30 22:30:24
Big Data Engineer,Pentasia,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Ownership of features and code, from inception of ideas to deployment and maintenance', 'Implement message producers and consumers in various programming languages following the common patterns and best practices', 'Design and implement data streaming applications to allow users to explore large set of data near real time', 'Work autonomously on a well developed product using a great range of different technologies', 'Strong coding skills in one of the following; Scala, Python, Bash and SQL', 'Experience with Hadoop ecosystem, Spark, Hive and data warehousing in general', 'Familiar with most popular cloud computing big data services (e.g. EMR, Sagemaker, Glue, ElasticSearch)', 'Experienced with modern workflow/orchestration/automation tools (Airflow, Docker, Jenkins) to enable proficient data engineering development']",2020-12-30 22:30:24
Data Engineer,RTS Labs,N/A,"Glen Allen, VA 23060","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Have strong SQL skills and knowledge of BI concept', 'Solve challenges with out-of-the-box thinking', 'Love to learn and to share your insights', 'Know what it means to be a team player', 'Build relationships with clients based on trust', 'Reliably manage yourself', 'a high standard, ensuring that you work with smart people', 'a technically proficient, learning-oriented culture', 'a hard-working, but casual workplace, few meetings, and a get-it-done philosophy', 'MS SQL (T-SQL, Stored Procedures, Functions), SSRS, SSIS, SSAS, Microsoft Power View, Tableau, Jaspersoft']",2020-12-30 22:30:24
Big Data Engineer,PayPal,"3.9 out of 5 from 1,386 employee ratings","Austin, TX 78729","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Lead, develop, and grow a high performance, multi-function team of talented and passionate professionals, who are results driven to take the business forward and demonstrate superior leadership in line with the PayPal values.', 'Participating and collaborating with cross functional teams in the organization to understand the business requirements and to deliver solutions that can scale.', 'Planning the execution of the project in an effective and efficient manner.', 'Proactively anticipating problems and appropriately communicating to the team and management in a timely manner.', 'Being flexible and being able to support all functions of product life cycle when required.', 'Collaborate with core engineering team and business stakeholders to help define Tax data mart, data models and data integration solutions.', 'Capture and document data requirements in Functional specifications for the engineering team to build. Review technical specs and design and provide feedback to team.', '8+ years of experience in the IT industry, experience in Data Technology space is preferred and good at Data Analysis.', 'Advanced Hadoop Skills , SQL and Python scripting experience and proficiency in scripting language like Unix', 'Working experience in any MPP systems', 'Strong in Hadoop, HBase and Hive and Big Data Technologies', 'Knowledge of Financial Regulatory domain particularly US TAX Compliance programs like 1099K, CP2100, FATCA & CRS is highly preferred.', 'Conceptual knowledge on any ETL tool (i.e. Informatica/ Ab Initio) is preferable.', 'Strong communication skills and willingness to take initiative to contribute beyond basic responsibilities', 'Working experience in an Agile methodology is highly preferred']",2020-12-30 22:30:24
Database/Data Engineer,"Incept Data Solutions, Inc",4.2 out of 5 from 5 employee ratings,"Washington, DC 20006","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)development in DoD or secured Government installation: 9 years (Required)Confidential (Required)"", 'Monday to Friday', ""Bachelor's (Required)"", 'development in DoD or secured Government installation: 9 years (Required)', 'Public Trust Clearance (Required)', 'Confidential (Required)', 'One location', 'Temporarily due to COVID-19']",2020-12-30 22:30:24
Sr. Data Engineer,Infolob Solutions Inc,4 out of 5 from 3 employee ratings,"Burlington, NC 27217","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Talend: 6 years (Preferred)AWS: 7 years (Preferred)US work authorization (Preferred)"", 'Quantity: 6! – looking for a mix of 4x Mid-Level + 2x Sr.-Level', 'Must Haves:', 'Experience with modernizing data integration by streaming data to the cloud, e.g. S3, object buckets', 'Database design experience', 'Data modeling, e.g. OLAP, Star Schema', 'Experience in migrations from on-prem to the cloud', 'Cloud experience – preferably AWS, but other cloud experience should suffice', 'Talend (ETL) tool', 'Snowflake (Database); they have loaded data into Snowflake leveraging Talend', 'Scripting: Python, Javascript', 'Jira', 'Healthcare vertical or provider/payor/pharma', 'Soft Skills:', 'Communication skills on a scale of 1 to 10 for this role? – 10', '8 hour shift', ""Bachelor's (Preferred)"", 'Data Enginee: 10 years (Preferred)', 'Talend: 6 years (Preferred)', 'Snowflake: 6 years (Preferred)', 'AWS: 7 years (Preferred)', 'Netezza: 6 years (Preferred)', '1 year', 'Yes']",2020-12-30 22:30:24
Data Engineer,Blue State,N/A,"Washington, DC 20005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and support systems and processes for managing, compiling, manipulating, and analyzing data for client and internal projects', ""Work with Blue State's client organizations to solve difficult data migration, management, and integration challenges"", 'Build data pipelines, data warehouses, reporting dashboards, automated exports, and synchronization processes', 'Automate workflows and look for further opportunities to improve efficiency in our work', 'Always maintain a high level of data security and privacy', 'Good foundational understanding of statistical analysis', 'Extensive experience working with SQL databases in an analytics or business intelligence context', 'Familiarity with common marketing technology platforms like Google Analytics, Google Ads, Facebook Ads, email marketing tools, and other marketing automation tools', 'Experience with ETL/ELT tools, processes, and best practices', 'Strong Python experience:', 'Strong working knowledge of Google BigQuery and the Google Cloud Platform data product ecosystem including:', ""Comfortable working within a spreadsheet (even if you prefer a database) - preferably in Google Sheets - bonus points if you've extended Google Sheets using Google Apps Script"", 'Familiarity with Git and maintains good habits around code maintenance', 'Able to build repeatable and well-documented processes and tools that can be used by other technically-savvy but non-Python developer analytics team members (think easy to use command-line scripts - not GUIs)', 'Good at teaching others what you know.']",2020-12-30 22:30:24
Data Engineer,Moxie,3.6 out of 5 from 541 employee ratings,"Atlanta, GA 30313","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Write application and workflow based on business requirements or user stories, architectural requirements, and existing code.', 'Design, development, and enhancement of data models and workflows.', 'Responsible for system performance of the data tier and the reliabitlity of data feeds across the enterprise system.', 'Modify and improve data engineering processes to handle ever larger, more complex, and more types of data sources and pipelines', 'Estimate and plan development work, track and report on task progress, and deliver work on schedule', 'Write ad-hoc queries based on schema knowledge for various application requirements', 'Contribute to on call support and to operational support documentationation', '1 Yrs+ experience working with SQL Server Management Studio, SQL Server Integration Services', 'Experience executing solutions with Salesforce Marketing Cloud and leveraging APIs and ETL tools.', '1+ years of experience with data technologies including Hadoop(Cloudera) , HBase, Spark, Hive, RedShift etc.', 'Expertise in SQL, especially within cloud-based data warehouses MS Azure and Amazon Redshift', '1+ years of Python coding experience', 'Excellent communication and intra-personal skills', 'Self-motivated and a self-starter with strong ability to multitask projects/tasks effectively']",2020-12-30 22:32:05
Data Engineer,Dealer Inspire,3 out of 5 from 12 employee ratings,Illinois,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '2-5 year experience as a data engineer designing and implementing data pipelines', 'Experience with big data infrastructure to support data science on linux based systems', 'Knowledge of the ETL process and patterns of real time data products', 'Working knowledge of SQL', 'Working knowledge of Python', 'Ability to allocate and utilize AWS resources', 'Experience integrating with diverse APIs', 'Work closely with data scientists on the data demand side', 'Work closely with domain experts and data source owners on the data supply side', 'An ability to build a data pipeline monitoring system with robust, scalable dashboards and alerts for 24/7 operations.', 'College degree in a technical area (Computer Science, Information Technology, Mathematics or Statistics)', 'Experience with Apache Kafka, Spark, Ignite and/or Redis', 'Working knowledge of MySQL', 'An expert at all things Python, including Jupyter notebooks, Conda, Pandas, and/or Cython', 'Experience with node.js and PHP', 'Familiarity with common AWS services such as EC2, S3, EBS, Glacier, and RDS', 'Experience with big data tools, data pipelines, databases, cloud services, and Python', 'Experience building modular, scalable, cloud-based system infrastructure', 'Willingness to learn new technologies and a whatever-it-takes attitude towards building the best possible data science platform', 'Looking to get into data science? This is a great gateway position.', 'Enthusiasm and a ""get it done"" attitude!', '18 days of paid time off, plus select paid holidays', 'Paid Volunteer Day & Paid Pet Wellness Day', 'Work from home Fridays', 'Fully stocked kitchen and refrigerator', 'Robust Health Insurance Options: BCBS, Delta Dental, EyeMed', '401k plan with company match', 'Subsidized internet access for your home', 'Peer-to-Peer Bonus program', 'Subsidized gym membership', 'Weekly in-office yoga classes', 'Parental Leave', 'Life & Disability Insurance', 'Tuition Reimbursement', 'Not a complete, detailed list. Benefits have terms and requirements before employees are eligible.']",2020-12-30 22:32:05
Business Intelligence Data Engineer,Major League Baseball,4.3 out of 5 from 88 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'B.S. or M.S. in computer Science, equivalent engineering degree, or relevant practical experience.', '3-5 years of progressively complex related experience.', 'High proficiency in SQL (ANSI) with the ability to write complex freehand SQL including sub-queries, nested queries, and other advanced SQL features.', 'Experience with a RDBMS (MySQL, PostgreSQL, SQL Server a plus).', 'Proven experience with development and scripting in Java, Object-Oriented Languages, Python or any of the major languages to build robust data pipelines and dynamic systems.', 'Proven ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources and build innovative solutions.', 'Proven knowledge of GCP including services in their compute, storage, databases, management tools, and analytics portfolio. (open to AWS/Azure equivalents)', 'A passion for data, and an understanding of how to work with large data sets consisting of as well as willingness to learn new technologies and methodologies under minimum guidance.', 'Excellent written and verbal communication', 'Development and execution of data structures and pipelines to organize, collect and standardize data to generate insights and addresses reporting needs.', 'Demonstrate a deep knowledge of, and ability to operationalize, leading data technologies and best practices in order to identify and assess critical capabilities and recommend solutions.', 'Design and modify components of new and existing IT systems to promote integrated corporate business systems.', 'Baseball knowledge a plus', 'Experience with SAP DataService is a plus', 'Experience with MPP Data Warehouses (BigQuery is a plus)', 'Experience with implementing complex, enterprise-wide data transformation and processing solutions', 'Experience with data in various forms (data warehouses/relational SQL, NoSQL, JSON, unstructured data environments/PIG, HIVE, Impala)', 'Experience with GCP Data Pipelines (GCP Professional Data Engineer certification) a plus', 'End-to-end SDLC experience a plus']",2020-12-30 22:32:05
Data Pipeline Engineer,TMP Worldwide,3.7 out of 5 from 133 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'TMP Programmatic works on data services across the programmatic platform within TMP, and supports building customer facing data visualization products', 'The team has extensive experience in ETL development and works with large scale data in real time', 'Providing technical support for all data pipeline environments', 'Set up, configure, maintain and enhance proper infrastructure to support a large scale data analytics environment', 'Evaluate the technical tradeoffs of every decision', 'Build and maintain ETL pipelines utilizing Python', 'Work with Cloud Computing Platforms (AWS), Kafka and other open-source technologies', 'Conduct data modeling, schema design, and SQL development', 'Ingest and aggregate data from both internal and external data sources', 'Collaborate with Product Owner and domain experts to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'Assist with the development and review of technical and end user documentation including ETL workflows, research, and data analysis', 'Work with Product team to define data collection and engineering frameworks', 'Responsible for daily integrity checks, performing deployments and releases', 'Own meaningful parts of our service, have an impact, grow with the company', 'Excellent and proven knowledge of Python', 'Excellent and proven knowledge of SQL', 'Excellent and proven knowledge of streaming technologies, such as Kafka or Kinesis', 'Excellent and proven knowledge of queue based infrastructures such as AWS SQS, SNS, etc.', 'Good knowledge of the following technologies is a bonus:Postgres on Amazon RDSAmazon RedshiftDocker', 'Proficiency in Git, JIRA and Teamcity are a plus', '2+ years in a production environment a plus']",2020-12-30 22:32:05
Manufacturing Technician,"Agilent Technologies, Inc.",4.1 out of 5 from 697 employee ratings,"Wilmington, DE 19808","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Execute routine and non-routine tests, troubleshooting and repair, and quality verification of electronic modules, assemblies and boards used in GCMS instruments with limited technical support.', 'Perform complex test/process work requiring an in-depth technical background of GCMS instrumentation with limited documentation.', ""With engineering, developing and writing documentation for the assembly of new products and writing ECO's to release controlled documentation to production."", 'Closely work with engineering and peers to provide clear and concise documents and explanations of assembly/test procedures.', 'Meet NPI deadlines regarding released documentation so that NPI phases are not delayed.', 'Support all GCMS production operations.', 'Assist engineering in developing new processes, test procedures, tools and prototype fabrication.', 'Independently monitors and adjusts process parameters; collects, manages and analyzes data and feedback; determines data collection needs and continuously improves processes; identifies root causes and drives the implementation of solutions.', 'Helps suggest and develop process designs, program modifications, and fixtures and works with manufacturing engineers to implement them.', 'Proactively addresses customer or department needs and resolves problems.', 'May lead team efforts.', 'Reduce data to information (e.g. graphs, charts, including statistical analysis) and develop methods to apply the information and drive improvements.', 'Provide technical support for coworkers', 'Support team members in achieving the production line objectives and goals through effective teamwork. This includes providing constructive feedback to peers and maintaining flexibility to adapt to changing business priorities.', 'This position may also include the coordination of some ESD responsibilities for the team.Physical Requirements:', 'This position will require the lifting of up to 40 lbs. multiple times per day/week.', 'It may also require standing, sitting, stooping, bending for at least eight hours or more per day.']",2020-12-30 22:32:05
Jr. Data Engineer - TAP,Chubb,3.7 out of 5 from 774 employee ratings,"Jersey City, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'On-the-job and educational technical training (offered through Pluralsight) to enhance skills within your chosen discipline', 'Business acumen and professional development training specific to IT and an understanding of our broader industry', 'Networking opportunities with IT and Business leaders and TAP associate peers', 'Hackathons', 'You are highly collaborative, creative, and intellectually curious individual who is passionate about data engineering and supporting cutting-edge computing capabilities.', 'You are able work well, both individually and within a team.', 'You are adaptable and able to overcome technical challenges.', 'You are a self-starter and motivated to learn and succeed.', 'You are data driven and are able to identify and solution problems as they arise.', 'Collaborate and work with global data management stakeholders to identify requirements for complex business problems that may be loosely defined.', 'Work with the business, applications owners, solutions architects, and with technical architects to understand the implications of respective data architectures to maximize the value of information across the organization.', 'Build the enterprise conceptual and logical data models for analytics, operational and data mart structures in accordance to industry best practices models.', 'Identify, evaluate and implement leading edge data management frameworks required to address complex large-scale data challenges.', 'Work within multi-functional agile teams with end-to-end responsibility for product development and delivery.', 'Provide architectural support by building proof of concepts & prototypes.', 'Working knowledge of Excel, PowerPoint, and Word is required.', 'Energetic, able to build and sustain long-term relationships across a multitude of stakeholders in a fast paced, multi-national work environment.', 'Strong time management and organizational skills', 'Possess strong verbal and written communication skills and ability to present, persuade and influence peers.', 'Internship or Job experience in software development', ""Bachelor's degree in Information Systems or related field with GPA of 3.0+ required"", 'Excellent data analysis skills', 'Experience in performing analysis and design for data management and data driven projects.', 'Exposure or knowledge of tools such as T-SQL on Spark SQL, ANSI SQL etc.', 'Experience or exposure Python, Jupyter Notebook, etc.', 'Experienced in programming languages such as Python, Sscala or Java', 'Familiarity with data science and analytic tool sets such as Jupyter hub', 'Exposure or experience with Cloud Platforms', 'Experience in designing and leading the conceptual, logical and physical design for distributed databases.', 'Experience with operating system command languages such as bash or ksh', 'Experience with development tools such as git and integrated development environments', 'Understanding of the SAFe Agile development methodology']",2020-12-30 22:32:05
Technical Support Engineer,Cockroach Labs,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Provide extraordinary service for both our open source users and Enterprise customers across our various support channels: chat, forum, Github, and phone.', 'Develop deep technical expertise in CRDB and accompanying technologies.', 'Recognize patterns among user issues, and suggest ways to improve our product and offerings.', 'Partner with our Documentation, Product, Sales, and Engineering teams to guide those improvements.', 'Help develop and iterate on our support processes and systems.', ""A passion for working with users directly and know how to adjust the tone and content of a message, so it's well received."", 'A natural knack for collaboratively crafting solutions with users and colleagues.', 'Excitement about working with a growing list of Enterprise customers, and can provide the polish expected by Fortune 500 companies.', 'A take charge attitude where you can anticipate issues and ensure resolution to technical issues that come your way.', 'Familiarity with, or are willing to learn about, the various technologies that make web-scale applications function.', 'Experience creating order out of chaos, and are excited to tackle the unique challenges of teams face in their early stages.', ""The ability to absorb information. You love getting into the weeds technically, but don't let that distract you from achieving your end goals."", 'You are a systems thinker and critical thinker, with experience solving problems at their root cause.', '2-6 years of experience working in technical support at a software company.', '100% health insurance coverage (for you and your dependents!)', 'Paid parental leave (with baby bucks)', 'Flex Fridays', 'Flexible time off & flexible hours', 'Education reimbursement', 'Relocation support']",2020-12-30 22:32:05
"Machine Learning Engineering Internship, Search and Recommendations - Summer 2021",Vimeo,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Write clean, portable, and well-documented code', ""Work with various machine learning algorithms to boost our search systems' ability to provide relevant, personalized results in any context"", 'Gain experience using docker, kubernetes, and Google Cloud technologies for deployments of models', 'Iterate on your implementations and designs in a data driven environment', 'Gain domain knowledge related to Search by working with experienced search relevance engineers.', 'Grow technically by learning from talented full stack engineers', 'Some familiarity, interest, and experience with Data Science and Machine Learning (bonus for anything search related, NLP, computer vision, or recommendation systems)', 'You have an understanding of Web services and REST APIs', 'You are problem-solver who is interested in scale, efficiency, and performance optimization', 'You dream big with solutions but also have a strong practical streak in evaluating whether they can and should be implemented', ""You're driven towards projects that have an impact on user experience"", 'You are familiar with PHP, Python, Go, or Java', 'You have strong opinions about how Vimeo search can be improved and are interested in search as a problem', 'You have public code viewable on Github, Bitbucket, etc.']",2020-12-30 22:32:05
"Data Engineering Intern, Data Science and Engineering",Netflix,3.9 out of 5 from 576 employee ratings,"Los Gatos, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Curious and motivated learner - competing for an MS/PhD degree in Computer Science, Engineering, Math, Statistics, graduating in Winter 2021 or Summer 2022.', 'Clear communicator - you are concise and articulate in speech and writing', 'Coursework or some experience with data structures and dimensional data modeling, ETL, data warehouse architecture', 'Understand principles of distributed systems (Hadoop, Spark, MPP)', 'Practical knowledge of scripting languages (ideally Python or Scala)', 'Able to write a SQL query with minimal guidance', 'Build large-scale batch and real-time pipelines with data processing frameworks like Spark or Flink', 'Collaborate on designing components of analytical data model', 'Design technical and business driven data audits to ensure data quality', 'Monitor and troubleshoot data issues in the data pipelines', 'Collaborate with other Data Engineers and build relationships with Analytics and ML Engineers, and Data Scientists', 'Learn how to work closely with business stakeholders in a high paced environment']",2020-12-30 22:32:05
Data Analyst/Engineer,creamitinc,N/A,"San Jose, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)"", '8 hour shift', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)', 'Remote interview process']",2020-12-30 22:32:05
Data Engineer,Fast Dolphin,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience in Data modeling, Lambda', 'Experience in setting up Authorization and Authentication', 'Experience in Datavant', 'Working with client to understand the specification and translate into technical code', 'Experience with Postgres, SQL', 'English', 'Spanish']",2020-12-30 22:32:05
"Data Engineer, BI",Square,3.6 out of 5 from 100 employee ratings,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with functional leads to understand their data and reporting requirements, and translate them into definitions and technical specifications (PRD)', 'Develop curated datasets with standardized metrics across the company', 'Develop and maintain ETL jobs and visualizations', 'Work with the data platform engineering team to develop data structures and reliable data pipelines', 'Troubleshoot technical issues', 'Perform ad hoc analysis, insight requests and data extractions to resolve important business issues', '8+ years of direct BI Data Engineering experience', 'Expert knowledge in data modeling concepts and implementation', 'Technical accomplishments in SQL, ETLs and familiarity with technologies such as Airflow', 'MySQL, Snowflake, Redshift, or similar data handling experience', 'Experience processing extremely large datasets', 'Experience with Python', 'Experience with Linux/OSX command line, version control software (git), and general software development', 'Expertise in visualization technologies including Tableau and/or Looker', 'Knowledge of payment network data and SaaS', 'Healthcare coverage', 'Retirement Plans', 'Employee Stock Purchase Program', 'Wellness perks', 'Paid parental leave', 'Paid time off', 'Learning and Development resources']",2020-12-30 22:32:05
Data Engineer,Sanofi,"4.1 out of 5 from 4,171 employee ratings","Bridgewater, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Responsible for building the pipelines and tools in the DARWIN environment', 'Produce data sets for specific analysis projects, dashboards and applications, and general reuse.', 'Identify data engineering needs and implement optimal solutions.', 'Provide subject matter expertise to other users who are working in the DARWIN environment.', 'Maintain effectiveness relationships with the end stakeholders with an end objective to develop education and communication content as per requirement', 'Interact effectively with healthcare professional on publications content', 'Constantly assist other writers in developing knowledge and sharing expertise', 'Create and maintain optimal data pipelines using Sanofi’s data platform and infrastructure', 'Assemble large, complex data sets that meet the needs of data analysts and data scientists as per agreed timelines and quality', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that facilitate their discovery, access and use of data', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Successfully manipulate, process and extract value from large disconnected datasets.', 'Bring Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', '5+ years of experience in a Data Engineer role', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong project management and organizational skills.', 'Strong analytic skills related to working with unstructured datasets.', 'Excellent English language knowledge', 'Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field', 'Experience and knowledge PySpark programming', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.']",2020-12-30 22:32:05
Data Engineer,Rhythm Energy,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with our Engineering team to maintain the pipelines through which we ingest data into our Snowflake data warehouse, from both internal and 3rd-party platforms', 'Own the ETL pipeline through which that data is transformed, managing complex data and timing dependencies and a mixture of SQL and python-based transformations', 'Integrate a scalable ML pipeline within our ETL, providing our BI users and customer platform just-in-time access to our analytics', 'Be an expert in not only the orchestration but the nature of our data, understanding how it is integrated from disparate systems and built up into the business objects that our team and our customers depend on', 'Build out a streaming pipeline for customer events, enabling real-time intelligence within our platform and situational awareness for our marketing and operations teams', ""Be the data science team's go-to expert on our infrastructure, including database, container, and application management, responsible for monitoring, maintenance, and troubleshooting"", 'Contribute to our BI environment, Looker, and support our business users in their use of it', 'On occasion, contribute to our data applications, writing data-driven python-based services', ""Be a champion for Rhythm's mission and values, both at work and in your community"", '5+ years of technical experience working in modern, cloud-based environments (8-10 years preferred)', '3+ years of data engineering experience specifically', 'Bachelors degree in CS or a quantitative field (M.S. preferred)', 'Expertise in the AWS ecosystem, including ECS, S3, Aurora, SNS, and SQS', 'Expertise with ETL and data pipelines, using tools such as Airflow, Kinesis, DBT, and Celery', 'Expertise architecting and managing data warehouses (we use Snowflake and Timescale)', 'Expertise building, monitoring, and maintaining scalable ML pipelines, preferably on AWS (SageMaker a plus)', 'Expertise with web and data access in python, in particular via SQLAlchemy and Flask', 'Expertise with Docker, Docker Compose, and containerized testing and deployment', 'Experience supporting data warehouse BI tools (we use Looker)', 'Experience developing, testing, and maintaining production applications in Python', 'Experience with basic devops, including managing local dev environments and data access', 'Excellent written and verbal communication skills', 'Excellent organizational skills, and a willingness to work hard and jump on whatever the team needs', 'Rhythm is headquartered in Houston, Texas and is building out a New York City office', 'Remote candidates will be actively considered, but preference will be given to candidates in the NYC or Houston area', 'Travel required <5%', 'Competitive base salary and bonus', 'Complete benefits package, including medical, 401k, HSA/FSA, and unlimited PTO.']",2020-12-30 22:32:05
Big Data Engineer,Bankers Healthcare Group,4.1 out of 5 from 40 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Ensure high throughput of development teams by identifying potential issues, removing impediments or guiding the team to remove impediments by collaborating with the appropriate resource', 'Enabling real-time analytics and event driven architecture', 'Develop pipelines real-time streaming from different sources like FTP, Windows Blob Storage, SQL Server, Cosmos or Mongo DB and scheduling the pipelines as per requirement using Kafka and Databricks', 'Work with cross functional teams such as IT and Marketing', '2+ years’ experience in data engineering and custom coding using Python, Java, or Scala utilizing tools such as Databricks.', 'Experience working with NoSQL databases such as MongoDB or Cosmos DB', 'Experience with real-time analytics and event driven architecture', 'Ability to build Python scripts for scheduling, monitoring, & management', 'Experience managing Spark and/or Kafka clusters on-prem or in the cloud', 'Experience with Data lake or Delta Lake', 'Understanding of big data pipelines', 'Familiarity with docker', '100% coverage of monthly health insurance premiums', 'Competitive PTO and vacation policies', 'Company 401(k) plan with employer contributions after one year', 'On-site gym access and memberships, with personal trainers, and certified nutritionists on staff', 'Company-sponsored training and certification opportunities', 'Monthly award ceremonies where top achievers are celebrated and receive additional bonuses', 'Ongoing volunteer opportunities to give back to the community through our BHG Cares program']",2020-12-30 22:32:05
"Data Engineer II - (Hadoop, AWS, Java)",Indeed,4.3 out of 5 from 723 employee ratings,"Austin, TX 78731","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'comScore Total Visits, March 2020', 'BS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field', '5+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl', 'OR Masters in Computer Science or Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field AND 3+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl.', 'Minimum 5 years of experience in the following skills:', 'Big data platforms (Hadoop, GCP, AWS, Azure)', 'Advanced SQL scripting', 'Database Management Systems (for example, Oracle, MySQL or SQLServers', 'Data transformation tools']",2020-12-30 22:33:56
Data Engineer,Capital One,"3.9 out of 5 from 9,133 employee ratings","Plano, TX 75023","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-12-30 22:33:56
Data Engineer,Verstand AI,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Management and mentoring of junior data engineers.', 'Experience with setting up and operating data pipelines (batch and real time) and data wrangling procedures using Python or SQL in a cloud environment.', 'Collaborate with engineers and business customers to understand data needs, capture requirements and deliver complete BI solutions', 'Design and build data extraction, transformation, and loading processes by writing custom data pipelines', 'Design, implement and support platforms that can provide ad-hoc access to large datasets and unstructured data', 'Model data and metadata to support ad-hoc and pre-built reporting', 'Tune application and query performance using performance profiling tools and SQL', 'Build data expertise and own data quality for allocated areas of ownership', '7+ years of experience in using SQL and databases in a business environment', '6+ years of experience in cloud environment, distributed systems, system automation, and real-time platforms.', '5+ years of experience in custom ETL design, implementation, and maintenance', '5+ years of experience with data warehouse schema design and data modeling', '2+ years of production level experience with Kafka, Python, SQL, and shell scripting', '3+ years experience with cloud databases (e.g., AWS, Azure, GCP)', 'Experience with batch and stream processing (Confluent preferred)', 'Experience with building large scale data processing systems', 'Solid understanding of data design patterns and best practices', 'Working knowledge of data visualization tools such as Tableau, PowerBI and Looker is a plus', 'Experience in analyzing data to identify deliverables, gaps, and inconsistencies in data sets', 'Familiarity with agile software development practices and drive to ship quickly', 'Experience in leading change, taking initiative, and driving results', 'Effective communication skills and strong problem-solving skills', 'Proven ability and desire to mentor others in a team environment', 'Retail production experience highly desired', ""Bachelor's degree from four-year College or university in Computer Science, Technology or related field"", ""Master's degree in Computer Science is a plus"", 'Experience with microservice patterns, API development, and containers', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', 'Fully Remote', 'Yes']",2020-12-30 22:33:56
Data Engineer,FlairTech Solutions LLC,N/A,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Hadoop: 5 years (Preferred)Microsoft SQL Server: 4 years (Preferred)Data warehouse: 5 years (Preferred)Big data: 5 years (Preferred)', 'Good experience in AWS Analytics stack in Spark/Databricks, Kubernetes,', 'Using data engineering tools, languages, frameworks to mine, cleanse and explore data.', 'Fluent in NoSQL & relational based systems.', 'Strong analytical and problem-solving skills.', 'Strong understanding of database technologies and management systems.', 'Strong understanding of cloud-based systems/services.', 'Excellent analytical and problem-solving skills.', 'Aware of the Agile methodologies', 'Ability to work on collaboration with local and external teams', 'Good Verbal and Written Communication skills', 'Monday to Friday', 'Hadoop: 5 years (Preferred)', 'Microsoft SQL Server: 4 years (Preferred)', 'Data warehouse: 5 years (Preferred)', 'Big data: 5 years (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 22:33:56
Data Entry Clerk 1,TriOpz,N/A,"Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Candidate have to come to the office to get their computer and for some training when they start. Then the position will be remote until the team returns to the office post COVID. Then the candidate will be required to work from the office when everyone returns. LOCAL CANDIDATES ONLY.']",2020-12-30 22:33:56
"Mechanical Engineer, Data Center Design",Facebook,4.2 out of 5 from 602 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with internal stakeholders to define project design criteria and develop Basis of Design', 'Manage consultants to implement the project through schematic design, design development, to construction documents', 'Manage the design build contractor to ensure the project meet the business and technical needs defined in the BOD', 'Provide construction administrative support to the project manager during construction with tasks including, but not limited to, responding to RFI’s, issuance of technical bulletins, review submittals and shop-drawings, and conducting source inspections at vendor factories', 'Review consultants’ engineering calculations, run independent engineering and cost analysis', 'Research new designs, materials, and construction methods for data center HVAC equipment and related components', 'Travel to datacenter sites for engineering studies, mechanical systems audits, startup testing, and full commissioning, as required', 'Provide instructions to design consultants, installation contractors, and validate quality of installed works', 'Take ownership and work to achieve the goal with good team spirit', 'Provide solutions to projects under pressure', 'Respond on an as-needed basis to emergencies', 'BS in Mechanical Engineering, or other technical discipline', 'Knowledge of HVAC systems including Direct Evaporative Systems, Chilled Water Systems, Condenser Water Systems, Pump Controls, Glycool/Glycol, AHU units (DX, split, RTU, CRAC, etc.), CRAH Units, Raised Floor Systems, Hot/Cold aisle containment, Air Filtration, and Building Management System/Controls Automation', 'Knowledge of Plumbing systems including Electric Water Heaters, Water Treatment, Booster Pumps, Distribution, Sanitary/Waste Systems, and Storm Drainage Systems', 'Knowledge of industry standards, building codes and safety standards including UMC, NFPA, ASHRAE, UBC, IMC and LEED', 'Trouble shooting and analytical experience making data driven decisions', 'Experience with construction process and cost estimating process', 'Fluent in English']",2020-12-30 22:33:56
Data Engineer,VTS3,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Will be required to help with the discovery of existing .NET applications', 'Will help building any conversion programs and integrations from Cloud to on-premise as needed to support the Oracle HCM Cloud/OAC implementation', 'Will be required to support and make enhancements to existing systems if needed', 'Would be required to perform analysis of business and system requirements and system design for the development', 'Should be able to start working on the system from day one with minimal hands holding. (Must be experienced)', 'Would have to design, build, unit test, and deploy changes to existing applications based on requirements', 'Would have to work closely with other Developers, DBAs, and Business/Functional users', 'Will have to maintain technical and standard documentation for program development activity in a timely and high-quality manner', 'Strong experience in Transact-SQL', 'Strong experience in MS SQL Server Integration Services', 'Strong experience in Database Design & Analysis', 'Experience in ASP.NET (VB, C#)', 'Experience in JavaScript', 'Experience in VBScript', 'Experience in HTML and CSSExperience working with Webservices and APIs', 'Experience in Visual Studio 2010 and higher', 'Ability to establish and meet target dates', 'Ability to handle multiple projects at the same time', 'Excellent communications skills (written and verbal)', 'BA/BS in Computer Science to Information Technology', 'Experience working with Oracle database and PL/SQL', 'The referral must be made by using the ""Refer a friend"" button on this page', 'The person you refer must be placed within 90 days of being referred', 'The person you refer must complete 480 billable hours', 'Cannot be someone we already have on our team or are currently working with']",2020-12-30 22:33:56
Data Engineer,Dow Jones,3.9 out of 5 from 222 employee ratings,"New York, NY 10176","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Strong familiarity and experience with ingestion, streaming and batch processing, data infrastructure design, and data analytics.', 'Top-notch understanding of basic statistics and issues surrounding data quality', 'Experience building infrastructure required for optimal extraction, transformation and loading of data from diverse data resources', 'Experience running and supporting production of enterprise data platforms.', 'Experience with relational and non-relational databases.', 'Experience building data pipelines in AWS (preferred) or GCP.', 'Proficiency in Scala, Python, Bash, Git, Spark, and SQL.', '2 or more years of data engineering experience', 'Excellent written and verbal communication skills, as well as top organizational, time management, and documentation skills.', 'Experience working with digital media content tracking across websites and mobile applications.', 'Exposure to, or direct experience with, implementing machine learning driven product features or tools.', 'You will report to the Chief of Data Science, who leads our News Insights team.', 'LI-JA1-WSJ']",2020-12-30 22:33:56
Data Engineer,at HomeLight,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Optimize and execute on requests to pull, analyze, interpret and visualize data', 'Partner with team leaders across the organization to build out and iterate on team, and individual performance metrics', 'Optimize our data release processes, and partner with team leads to iterate on and improve existing data pipelines.', 'Design and develop systems that ingest and transform our data streams using the latest tools.', 'Design, build, and integrate new cutting edge databases and data warehouses, develop new data schemas and figure out new innovative ways of storing and representing our data.', 'Research, architect, build, and test robust, highly available and massively scalable systems, software, and services.', '3+ years of Python and ETL experience, preferably Airflow', 'Experience writing and executing complex SQL queries', 'Experience building data pipelines and ETL design (implementation and maintenance)', 'Scrum/Agile software development process.', 'Expertise with Ruby on Rails.', 'Familiarity with AWS, Elasticsearch, Ruby/Rails, Django, Heroku', 'Experience setting up and managing internal API services.', 'Experience working on a small team, ideally at a startup.', 'Familiarity with the Amazon AWS ecosystem']",2020-12-30 22:33:56
Azure Data Engineer,Tech Golden,N/A,"Cincinnati, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Leverages enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses', 'Guides high level data architecture design (functional, non-functional) and ensures teams adhere to data architecture standards', 'Develops information processes for data acquisition, data transformation, data migration, data verification, data modeling, and data mining', 'Accountable for cost viability and technical estimation of data platform usage', 'Designs data solutions for data distributions and partitions, scalability, disaster recovery and high availability', 'Designs security for data policies and standards', 'Monitors and optimizes data solutions', 'Actively governs and automates standard data architecture patterns and blueprints', 'Partners with architecture, security, infrastructure, and application teams to design and implement the automation of data, data platforms, and tools', 'Creates and updates automation to eliminate routine management processes', 'Articulates the need for scalability and understand the importance of improving quality through testing', '5+ years of hands-on experience with data platforms', 'Experience in designing data solutions in Azure including data distributions and partitions, scalability, disaster recovery and high availability', 'Experience in monitoring and optimizing data solutions in Azure including using Azure Monitor', 'Experience in implementing data solutions in Azure including Azure SQL, Azure Synapse, Cosmos DB, Databricks, ADLS, Blob Storage, ADF, Azure Stream Analytics', 'Experience in designing security for data policies and standards', 'In depth understanding and proficiency in automation of cloud platforms and data platforms', 'Expertise in on-prem and cloud database automation and platform automation with Azure', 'Proficiency with cloud automation tooling such as Ansible and Terraform', 'Proficiency with DevOps and CI/CD methodologies and tools for automated infrastructure code test, integration, deployment, and assurance', 'Proficiency with Languages such as Ruby, bash, Python or Go', 'Experience with Software Development and automation methodologies', 'Experience with data security best practices', 'Strong problem-solving skills', 'Strong collaboration skills and excellent verbal and written communication skills', '8 hour shift', 'Temporarily due to COVID-19']",2020-12-30 22:33:56
Data Engineer,Vivint Smart Home,"3.4 out of 5 from 1,074 employee ratings","Lehi, UT 84043","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Must have a passion for data and helping the business turn data into information and action', '1+ years of data engineering experience', '1+ years of ETL & data pipeline development experience', 'Ability to initiate, drive, and manage projects with competing priorities', 'Ability to communicate effectively with business leaders, IT leadership, and engineers', 'Expert in SQL, databases, and ETL development processes & tools (Cloud MPP like Snowflake or Redshift)', 'Proficiency in the python scripting language. Preference given to knowledge of more (Perl, .net, etc.)', 'Familiarity with one or more web technologies (Angular, React, PHP, ASP.net, etc.)', 'Experience with big data technologies (HDFS, Hadoop, Spark, Elastic Search, Redshift, Snowflake, etc...)', 'Experience with Tableau or similar data visualization tool', 'Experience with AWS or Azure data product offerings and platform', 'Experience with machine learning technologies (R, SparkML, AzureML, etc.)', 'Paid holidays and flexible paid time away', 'Your choice between Mac or PC', 'Employee pricing on smart home products', 'Casual dress code', 'Onsite gym, gaming tables across our campus', 'Onsite health clinic', 'Medical/dental/vision/life coverage', 'Must have a passion for data and helping the business turn data into information and action', '1+ years of data engineering experience', '1+ years of ETL & data pipeline development experience', 'Ability to initiate, drive, and manage projects with competing priorities', 'Ability to communicate effectively with business leaders, IT leadership, and engineers', 'Expert in SQL, databases, and ETL development processes & tools (Cloud MPP like Snowflake or Redshift)', 'Proficiency in the python scripting language. Preference given to knowledge of more (Perl, .net, etc.)', 'Familiarity with one or more web technologies (Angular, React, PHP, ASP.net, etc.)', 'Experience with big data technologies (HDFS, Hadoop, Spark, Elastic Search, Redshift, Snowflake, etc...)', 'Experience with Tableau or similar data visualization tool', 'Experience with AWS or Azure data product offerings and platform', 'Experience with machine learning technologies (R, SparkML, AzureML, etc.)', 'Paid holidays and flexible paid time away', 'Your choice between Mac or PC', 'Employee pricing on smart home products', 'Casual dress code', 'Onsite gym, gaming tables across our campus', 'Onsite health clinic', 'Medical/dental/vision/life coverage']",2020-12-30 22:33:56
Data Engineer,Logistics Management Institute,3.9 out of 5 from 66 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop data structures and systems to support the generation of business insights', 'Knowledge and experience in overall ETL processes', 'Maintain data infrastructure and develop scripts for regular processes', 'Define, design, and develop data flow diagrams, data dictionaries, and logical and physical models', 'Define data requirements, document data elements, and capture and maintain metadeta', 'Identify and clean incomplete, incorrect, inaccurate or irrelevant data', 'Identify new opportunities to use data to improve business performance', 'Communicate and present data by developing reports using Tableau or Business Intelligence tools', 'Adhere to compliance and audit requirements for data storage, architecture, cybersecurity, etc.', 'Bachelor’s degree in a quantitative field (e.g., engineering, statistics, mathematics, information technology, etc.) is preferred.', 'Must have at least 2 years of experience, preferably with a federal government customer.', 'Experience with big data tools: Hadoop, Spark, Kafka', 'Experience with relational SQL and NoSQL databases: Postgres, Cassandra, MongoDB', 'Experience with data governance tools: Collibra, Immuta', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala', 'Must possess strong written and verbal communication skills.']",2020-12-30 22:33:56
Data Engineer,Altimetrik Corp,N/A,"Dearborn, MI 48120","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience working with hadoop hive spark and oozie', 'Should have previous experience in developing complex SQL scripts for data analysis and extraction, developing and maintaining programs as required for the ETL process', 'Experience with Spark, SparkSQL, Spark Streaming', 'Good understanding of Hive, HQL, Hadoop, HDFS, Map Reduce', 'Experience in supporting ETL, production data operations (File processing, data distribution etc.,) including debugging, addressing production issues and performing Root Cause Analysis']",2020-12-30 22:33:56
Software Data Engineer - Python,Capital One,"3.9 out of 5 from 9,133 employee ratings","Plano, TX 75023","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-12-30 22:33:56
Senior Software Engineer (Customer Data Platform),Macy's,"3.7 out of 5 from 34,265 employee ratings","Johns Creek, GA 30097","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Perform coding/configuration, testing, implementation and documentation on solutions developed including design specifications.', 'Perform applications programming activities, to include code, test, debug, document, maintain, and modify applications programs.', 'Ability to extract, analyze, and report the data.', 'Strong attention to detail when identifying data relationships, trends, and anomalies.', 'Thinking through long-term impacts of key design decisions and handling failure scenarios.', 'Maintain awareness of industry trends and evaluate applicability of new software tools to platform development.', 'Serve as a coach and mentor to more junior developers to include delegating and managing tasks, as appropriate.', 'Consistently demonstrate regular, dependable attendance and punctuality.', 'Commit to overall deliverables with customers and/or management.', 'Perform other duties as assigned.', 'Bachelor’s Degree and 5+ years of related experience or an equivalent combination of education and experience.', '3+ years hands-on experience with SQL like relational data stores (For example: Oracle, Hive or similar), NoSQL data stores (Cassandra, Elasticsearch or similar).', '2+ years deep hands-on skills in Data Integrations stack, namely EMS, Kafka, Python, GCP (Dataflow, Pub-Sub, GCS, BigQuery, IAM).', 'Experience building scalable web services and event/stream processing.', 'Good understanding of data engineering, ingestion and processing of data within GCP platform and performing complex query analysis and analytics on the data.', 'Expert understanding of all application development processes including software development using the Agile methodology; ability to serve as a resource to others.', 'Expert in existing applications supporting the business area. Able to serve as a key resource to ensure the system is performing up to requirements.', 'Possesses understanding of multiple systems/customer areas, gained through previous experience in different areas and leverages that knowledge to support current customer(s).', 'Works independently and provides guidance within technical area, applying in-depth knowledge of multiple technologies, as appropriate.', 'Understands architectural issues, and factors them into decisions and recommendations.', 'Provides technical leadership in areas of specialization.', 'Excellent written and verbal communication skills.', 'Ability to read, write, and interpret complex technical documents.', 'Basic math functions such as addition, subtraction, multiplication, division, and analytical skills.', 'Very strong analysis/troubleshooting skills, strong partnering/relationship building skills.', 'Ability to consider options and make business decisions (e.g. selection of tools/methodologies for projects).', 'This position involves regular ambulating, sitting, hearing, and talking.', 'May occasionally involve stooping, kneeling, or crouching.', 'May involve close vision, color vision, depth perception, and focus adjustment.', 'Involve use of hands and fingers for typing on keyboard and using a mouse.', 'May be a need to move or lift items under 10 pounds.', 'Ability to work a flexible schedule based on department and company needs.']",2020-12-30 22:33:56
Data Engineer,Apex Global Solutions,2.5 out of 5 from 6 employee ratings,"Suffern, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Multiple locations', 'No: Not providing sponsorship for this job', 'ApexGlobalUs.Com', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-12-30 22:33:56
Data Engineer,Marsh and McLennan,3.7 out of 5 from 919 employee ratings,"New York, NY 10036","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work in a diverse and inclusive culture as part of a global CIO organization', 'A fast pace, demanding and collaborative environment with exposure to the senior most leaders in the Technology organization', 'Career Growth – performance is rewarded with new opportunities', 'Impact – Opportunity to work on exciting projects as part of a program that is on the executive committee agenda', 'Benefits – competitive salaries and comprehensive benefits and programs including: health and welfare, tuition assistance, 401K, employee assistance program, domestic partnership benefits, career mobility, employee network groups, volunteer opportunities, and other programs', 'Specializes in one or more of the following areas: Server, Network (voice/data), messaging/collaboration, mainframe, Architecture, Storage/backup, Applied Engineering and/or Application engineering.', 'Designs, develops, implements, and analysis of Technical product/systems.', 'Creates, manages and maintains strategy, standards, roadmaps and new technologies.', 'Provides advanced design and engineering functions for one or more of the following skillset areas: Server, Network (voice/data), Messaging/Collaboration, Mainframe, Implementation, Architecture, Storage/Backup, and/or Application design.', 'Recommends alterations to developments and designs; improving quality of products/procedures', 'Manages Engineering Support staff in one or more of the following areas: standards, projects, level III support issues, designs and overall IT Engineering for Infrastructure/Technology.', 'Trains, leads, mentors, Engineers and Managers.', 'Creates, manages, maintains departmental policies, processes and procedures; relating to standards, projects and cross functional interoperability.', 'Prepares and tracks budgets, project/staffing plans.', 'Understands/communicates, Strategic/Global Initiatives and Infrastructures.', 'Consultants to aid in the development of solutions; Works closely with the Project Management Office and stakeholders to provide guidance/ advice concerning infrastructure issues', 'Identifies opportunities and recommends solutions for improving service efficiency and effectiveness.', 'Provides levels II/III support for Hardware and Operating System issues.', 'Documents Operational procedures; hand-off to the Operations Group.', 'Understands/communicates, Strategic/Global Initiatives and Infrastructures.', 'Solid expertise in setting up pipelines to ingest streaming, batch data from diverse sources, and perform data virtualization and/or ETL processes to make the data more usable, both with on-promise technologies and cloud-based solution providers', 'Proficiency in a programming language, such as Python, Java, SQL query engines Apache Spark, Rest APIs and the Hadoop ecosystem', 'Experience with data buffering such as with Apache Kafka, data stores such as any SQL or NoSQL,', 'Solid understanding of physical data base/structure modeling and implementations', 'Expert use and understanding of SQL', 'Solid understanding of data virtualization tools such as Dremio, data catalogues such as INFA EDC, Alation, ETL tools and BI tools such as Power BI and Tableau', 'Workflow tools for Orchestration/Automation/Pipelining', 'Solid logical Data Modelling for OLAP solutions – for Data Lakes, Data Marts and Data Warehouses', 'Experience with Dremio', 'Experience with quality review processes', 'Experience with data profilingData Visualization with Tableau or Power BI']",2020-12-30 22:35:44
Data Engineer,Zoetis,3.7 out of 5 from 295 employee ratings,"Parsippany, NJ 07054","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:35:44
Data Center Technician,Google,"4.3 out of 5 from 3,811 employee ratings","Reston, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '2 years of experience with diagnosing, navigating and troubleshooting computer hardware and server hardware.', '2 years of experience with operating systems and networking protocols.', 'Experience collaborating and partnering with teams.', 'Ability to lift and move 50 lbs of equipment, work on platforms, ladders and under raised floors.', ""Bachelor's degree."", 'Experience working within a data center or network operation center environment.', 'Linux/Unix desktop support experience, including installation, systems administration and troubleshooting.', 'Experience in project management and leadership.', 'Experience as a team or project lead.', 'Intermediate networking knowledge, including basic topology and protocol.', 'Repair broken equipment, including servers, networking and storage devices, replace hard drives, replace bad sticks of RAM, swap CPUs, motherboards, etc.', 'Contribute and lead efforts/projects in the deployment, maintenance, and support of current and new data center servers and network infrastructure. Lead troubleshooting and resolve critical or escalated technical issues over a significant population of affected equipment.', 'Follow the site’s environmental health and safety policies.', 'Work on shifts including nights, weekends and holidays.']",2020-12-30 22:35:44
Data Analytics Engineer - TechOps (Remote),CrowdStrike,3 out of 5 from 14 employee ratings,"Sunnyvale, CA 94086","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:35:44
"Data Engineer, Associate","JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Lewisville, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Expertise in application data and infrastructure architecture disciplines', 'Implement business and IT data requirements through new data strategies and designs across data platforms', 'In depth knowledge of Data protection, replication, reconciliation, and distribution', 'Experience in Data Modeling: ERWin ,', 'Experience working on 1 or more NoSQL Databases such as Cassandra, DynamoDB, Elastic Search', 'Proficiency in one or more Database Platforms / Language: SQL, Hadoop, Cassandra and Hive', 'In Depth Knowledge of Kafka and Kafka Streams Platform , API Gateway', 'Familiarity with Agile engineering practices', 'In Depth Knowledge of AWS Bigdata ecosystem including AWS Glue', 'Experience working with PCI Data is a plus']",2020-12-30 22:35:44
Data Engineer,Cityblock Health,3.9 out of 5 from 7 employee ratings,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Aim for Understanding', 'Be All In', 'Bring Your Whole Self', 'Lean Into Discomfort', 'Put Members First', 'You have a passion for doing mission-oriented work.', 'You enjoy working with a diverse group of people with different expertise.', 'You enjoy building and improving cloud-native data pipelines and warehouses.', 'You have a process-oriented mindset, and enjoy writing and debating design documents.', 'You have 4+ years of data modeling and SQL experience', 'You have 2+ years experience leading members of a data engineering team.', 'You have 2+ years of experience using Python and supporting technologies to build data pipelines.', 'Co-create and own a strong technical vision, strategy, and roadmap for impactful health data warehousing and resulting data products.', 'Build and maintain strong relationships with your collaborators, including fellow Engineering teams, the Product team, Data Analytics, Data Science, and Actuary', 'Create an engaging work environment for the Data Management and Governance Engineering team by focusing on the most impactful work, creating growth opportunities, modeling transparency, and high-quality communication.', 'Use JIRA and other tools to effectively identify, track, and communicate priorities both for day-to-day and long-term planning.', 'Rapidly deliver value to our stakeholders, care teams, and ultimately our members.', 'Triage issues effectively and use that information to help guide the work of the team to make our data products more reliable and maintainable.', ""Define and maintain standards for the team's infrastructure, code, and development processes."", 'Experience with the technologies in our stack.', 'Experience modeling health data', 'Previous exposure to clinical operations and/or working with physicians.', 'A CS degree.', 'A resume and/or LinkedIn profile', 'A short cover letter, please!', '']",2020-12-30 22:35:44
Big Data and Python Engineer,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Jersey City, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company']",2020-12-30 22:35:44
Strategic Data Science - Intern,"Two Sigma Investments, LLC.",3.8 out of 5 from 12 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Independently research and develop hypotheses based on diverse and unique real-world datasets', 'Conduct literature reviews to develop and apply cutting-edge methodologies for extracting real-world signals from our vast data holdings.', 'Partner with our engineers and business stakeholders to rigorously explore and test your theories', 'All the while, you’ll remain engaged in the academic community. As examples, you can:', 'Join our reading circles to stay up to date on the latest research papers in your fields', 'Attend academic seminars to learn from thought leaders from top universities', 'Are pursuing a degree in a technical or quantitative discipline, like chemistry, computer science, economics, statistics, or quantitative social science, with approximately one year remaining in your programs (all levels welcome, from bachelor’s to doctorate)', 'Proficient in Python and SQL', 'Performed an in-depth research project, examining real-world data', 'Are an independent thinker who can creatively approach data analysis and communicate complex ideas clearly', 'You don’t need a background in finance. It’s nice to have, but more than half of Two Sigma’s employees come from outside the finance industry. If you’ve got the research skills, we can teach you the financial aspects of the job.']",2020-12-30 22:35:44
Data Software Engineer,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Houston, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'BS/BA degree or equivalent experience', 'Advanced knowledge of application, data, and infrastructure architecture disciplines', 'Understanding of architecture and design across all systems', 'Working proficiency in developmental toolsets', 'Knowledge of industry-wide technology trends and best practices', 'Ability to work in large, collaborative teams to achieve organizational goals', 'Passionate about building an innovative culture', 'Proficiency in one or more modern programming languages', 'Understanding of software skills such as business analysis, development, maintenance, and software improvement', '7+ years of software design and application development experience using any OOPs Languages (C#, C++ JAVA, etc....)', ""5+ years' experience with any of the following data orchestration stack, ingestion frameworks, cloud-native patterns: Apache Airflow, Kafka, Nomad/Terraform, Kubernetes/Docker, etc."", '3+ years of experience with scripting languages like Python, Bash or PowerShell, etc.', 'Hands-on experience with any of the ""open-source"" distributed ingestion/processing stack like Hadoop, Spark and Kafka is a must.', 'Solid exposure working in data engineering team, and can demonstrate best practices for building robust data controls and governance practices', 'Experience with infrastructure automation technologies like Docker and K8s is huge plus.', 'Exposure with building APIs and services using REST.', 'Designed and developed scalable data solutions using cloud infra such as AWS, Azure or GCP.', 'Ability to manage multiple tasks and thrive in a fast-paced team environment.', 'Strong written and verbal communications skills.', 'Working knowledge of Agile and scrum practices.']",2020-12-30 22:35:44
Data Engineer,Canary - US,"3.6 out of 5 from 67,873 employee ratings","Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', '3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role', 'Good analytical skills with excellent knowledge of SQL.', '4+ years of work experience with very large data warehousing environment', 'Good communication skills']",2020-12-30 22:35:44
Data Engineer,"Scuttlebutt Services, LLC",N/A,"Chantilly, VA 20151","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assess, transform, organize, and optimize data for use by machine learning algorithms', 'Generating representative data sets for systems development and data science initiatives', 'Build data pipelines that enable data scientists and engineers and other stakeholders', 'TS/SCI clearance required', '4+ years of experience designing data models and data warehouses supporting analytics, using both relational and non-relational distributed data storage systems', 'Demonstrated experience in building and maintaining ETL pipelines. Bonus points for experience with Apache Beam', 'Demonstrated experience working with Synthetic Aperture Radar (SAR) data', 'Demonstrated experience with large-scale distributed processing', 'Experience building data pipelines in ML frameworks. Kubeflow experience is desired', 'Experience working in a fast-paced agile environment', 'Familiarity with the machine and deep learning libraries such as Scikit-learn and PyTorch.', 'Experiences in a high-level programing language, such as Java, Python or GoLang', 'Demonstrated proficiency with Git version control systems', 'Experience working in Linux environments']",2020-12-30 22:35:44
Data Center Infrastructure Systems Engineer,Leidos,"3.7 out of 5 from 1,175 employee ratings","Reston, VA 20190","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Think strategically to assist Architecture team in developing multi-year Roadmaps for hardware and storage solutions.', 'Work with leads in other sub-systems, customers, and process owners to insure solution integration', 'Produce and maintain documentation of the server sub-systems in the data center environment, including as-built documentation, capacity/performance plans, as well as all other areas of server system life-cycle planning', 'Explore new technologies, and making recommendations for their introduction into the enterprise infrastructure environment', 'Provide Tier 3 problem resolution including root cause analysis as requested by Systems Administration team.', 'Adhere to company policies and processes including change control, security, corporate policies, ITIL and Sarbanes Oxley 404.', 'Functions as the technical lead for all design-to-cost and life-cycle activities for small-to medium-scale projects.', 'Work in a Scaled Agile Framework and participate in Agile Team events, including providing leadership and performing Product Owner duties as required.', 'Establishes and recommends changes to policies that affect subordinate organization(s).', 'Provides guidance to others to achieve goals in accordance with established policies.', ""Bachelor's degree in related technical discipline and 8+years of relevant experience. Additional years of relevant experience will be considered in lieu of Bachelor’s degree."", 'Solid knowledge and experience working with IT systems such as Storage, Computer Hardware, virtualization software (VMWare) and / or Public Cloud (AWS and Azure), and is expected to already have in-depth specialized knowledge of specific IT systems engineering processes and practices', 'Ability to work well in a team environment', 'Excellent analytical and problem solving skills', 'Ability to communicate and interact effectively at all levels of staff and management', 'Experience with server management utilities, such as HP OneView, Dell Openmanage Enterprise and Dell OMIVV', 'HP Blades / HP C7000 series experience and/or HPe Synergy, HP Virtual Connect, Dell MX and FX2', 'Storage administration experience, including SAN and SAN based Arrays, Network-based Storage utilizing CIFS/NFS and Object Storage, VMWare VSAN, Modern Backup Tools and Strategies', 'Should have VMWare enterprise level experience. Examples of enterprise experience include: Distributed virtual switch and VMWare VSAN', 'Experience with other Enterprise suite products such as vRealize Operations manager, vRealize Log Insight and vRealize Network Insight, vRealize Automation 7.x, VMware NSX, VMware vSAN for hyper-converged platforms.', 'Experience planning and leading VMware migrations.', 'Experience with the following network tools: VMware NSX, Cisco and Arista Networking', 'VMWare Automation tools experience, such as PowerCLI and vRealize Automation', 'Experience with scripting language such as Python or BASH', 'Experience with the following SAN/ Storage tools: Cisco MDS 9000 Series, NetApp, OnTap Select, Isilon, HP 3PAR, EMC Storage (CLARiiON, VNX, VMAX)', 'Experience with VMware VSphere Enterprise 6.x +, VMware vRealize Automation 7.x, VMware NSX, VMware vSAN for hyper-converged platforms, VMWare on Cloud', 'Experience with Cisco UCS, HP DL Series, Dell RX Series', 'AWS and/or Azure Design and/or Operations experience', 'Experience with NetBackup, MS Windows 2016 / 2019, Red Hat Linux 7/8 experience', 'Worked in an ITIL environment', 'Formal system engineering process/educational experience also desired, such as INCOSE and COBIT models', 'Ability to estimate level of effort and budgets', 'Ability to exercise independent judgment, develop relationships, and obtain consensus among interested parties', 'Ability to develop peer networks across an enterprise to maintain technology awareness and to support resolution of problems.', 'Ability to lead architectural design discussions, and carry those designs through deployment and into operations']",2020-12-30 22:35:44
Data Engineer – Spark/Scala (remote),Thrivent,N/A,"Dallas, TX 75243","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.', 'Own and define DevOps pipelines and release management for data engineering', 'Apply business knowledge and experience to effectively advise others on technology as an enabler.', 'Lead efforts to analyze IT industry and market trends and determine potential impacts.', 'Develop concepts and constructs necessary to create technology-enabled business systems.', 'Influence technology direction and provide thought leadership and execution to large complex efforts.', 'Utilize breadth of technical understanding and dive deep when necessary.', 'Consult on and manage initiatives to ensure alignment across multiple business and IT areas.', 'Proactively mitigate risks across multiple assets, information domains, technologies and platforms.', 'Provide leadership, mentoring and technical guidance to others to drive initiatives.', 'Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.', 'Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.', 'Act as a change agent to continuously improve and move the organization forward.', 'Accountable to successfully deliver the right results on initiatives in a timely and effective manner.', 'Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.', 'Ability to work within a diverse team of skillsets and experience levels to deliver results.', 'Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business, or related field.', '3+ years of experience in data engineering or equivalent experience.', 'Implement and configure data platforms including but not limited to Hadoop, Spark, Scala, Kafka and batch integration is preferred.', 'Working Experience developing data processes with Java, Python, R or other scripting languages preferred.', 'Cloud experience is preferred.', 'Expert knowledge of predictive analytics, statistical modeling, advanced mathematics, data integration concepts, business intelligence and data warehousing and implementing large systems.']",2020-12-30 22:35:44
Data Modeling Internship,MilliporeSigma,3.9 out of 5 from 241 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Data modeling: 1 year (Required)SQL: 1 year (Required)Python: 1 year (Required)Master's (Preferred)"", 'Enrolled or recent graduated Master student in Computer Science, Engineering, Mathematics, Physical Sciences or related fields.', 'Proficient computer skills, including Microsoft Office Suite (Word, PowerPoint, and Excel)', 'Strong coding skills in SQL', 'Basic knowledge of REST APIs and/or JSON', 'Understandings of data lifecycle management', 'Strong technical ability, willing to learn and evolve your skills in advanced analytics', 'Data Modeling experience with ability to collaborate effectively across global teams and communicate complex ideas in a simple manner', 'Strong attention to detail when identifying data relationships, trends and anomalies.', 'Experience with Hadoop technology or other big data platforms', 'Experience with ETL process.', 'Experience of data modelling and data warehousing.', 'Experience with Model Driven Architecture', 'Programming Language design and implementation', 'Coding skills in python, R, Spark, etc.', '1 year experience in advanced analytics area', ""Master's (Preferred)"", 'Data modeling: 1 year (Required)', 'SQL: 1 year (Required)', 'Python: 1 year (Required)']",2020-12-30 22:35:44
Data Engineer,ECI,N/A,"Austin, TX 78735","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", '401(k)', 'Health insurance', 'Paid time off', 'Monday to Friday', 'Weekends', ""Bachelor's (Preferred)"", 'One location', 'Temporarily due to COVID-19']",2020-12-30 22:35:44
"Senior Software Engineer, Professional Services",AppointmentPlus,N/A,"Scottsdale, AZ 85260","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Meet directly with clients to help gather requirements', 'Convert business requirements to technical specifications', 'Architect solutions in conjunction with the sales engineer', 'Provide estimates and timelines, and report status to stakeholders', 'Maintain end to end ownership of custom apps, from design to deployment', 'Deliver engineering and testing estimates', 'Work with sales engineer to provide mockups, wireframes, and workflow diagrams as needed', 'Write technical requirements and user stories', 'Plan, coordinate, and execute releases of custom applications', 'Provide ongoing support and change management for custom applications', 'Build reusable toolkit and services to reduce cost and timelines for custom applications', 'Deliver engineering and testing estimates', 'Contribute to requirements, mockups, and user stories', 'Execute development and/or manage through offshore teams', 'Participate in sprint planning and other Agile activities', 'Reporting status updates and exceptions', 'Assigning tasks to local and offshore teams', 'Establish devops culture and processes, in partnership with core technology teams.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday']",2020-12-30 22:37:25
Staff Engineer-PE required,H.A. Reynolds & Associates,N/A,"Parker, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:PE, 4 years (Preferred)', 'License:State of Colorado Professional Engineer (Required)', 'Work authorization:United States (Required)', 'PE: 4 years (Preferred)', 'State of Colorado Professional Engineer (Required)', 'United States (Required)']",2020-12-30 22:37:25
Data Engineer,Apex Global Solutions,2.5 out of 5 from 6 employee ratings,"Suffern, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Multiple locations', 'No: Not providing sponsorship for this job', 'ApexGlobalUs.Com', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-12-30 22:37:25
Data Engineer,Capital One,"3.9 out of 5 from 9,133 employee ratings","Chicago, IL 60695","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-12-30 22:37:25
Infrastructure Engineer,Chester County Intermediate Unit,4.2 out of 5 from 65 employee ratings,"Downingtown, PA 19335","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Bachelor’s Degree in Computer Science (or 4 years’ equivalent field experience), combined with 4+ years of relevant Infrastructure experience.', 'Competent with Windows and OS X server and client computing environments.', 'Competent with routers, switches, firewalls, wireless access points, server hardware, tape backup systems, SAN, NAS, PBX/VoIP, surveillance, door access control, and all other related technologies.', 'Ability to transport between central office and various locations throughout the county and state as required by the position.', 'Current police, child abuse, and FBI Fingerprint clearances required.', 'Install, configure, troubleshoot and maintain intermediate level server hardware and software across the entire organization.', 'Troubleshoot, monitor and maintain advanced configurations for wired and wireless ethernet data networks and associated hardware including routers, switches, and firewalls.', 'Competent in project management, including overseeing external contractors and internal Infrastructure Administrator staff.', 'Assist senior technical staff with system lifecycle planning.', 'Provide staff training on important topics such as “best security practices”.', 'Develop and implement penetration testing to continually harden existing infrastructure systems.', 'Install, troubleshoot, and maintain remote location services such as internet and telephone, and advanced services such as SD-WAN or VPN Tunnels.', 'Provide on-call 24x7x365 response to all infrastructure outages.', 'Evaluate and recommend potential upgrades to equipment, components, and software.', 'Develop and implement appropriate data recovery plans for every critical function and ensure the disaster recovery backup systems are operating properly.', 'Develop and implement advanced call flow or other basic configuration changes for VoIP systems.', 'Any other related duties as required by the Director of External Technology or Director of Innovative Educational Services.', 'Competent with installing, configuring and troubleshooting network devices such as switches, routers, wireless access points, firewalls, tape backup systems, and servers/clients of varying operating systems.', 'Competent with installing, configuring, and troubleshooting various telecommunications systems including PBX/VoIP hardware and cell phones.', 'Competent with installing, configuring, and troubleshooting various security access/surveillance systems.', 'Competent with installing, terminating, and troubleshooting various types of copper and fiber optic cabling used in network environments, maintaining an expertise in complex diagnostic tools such as TDRs, OTDRs, inductive-amplifiers, tone generators, RF spectrum analyzers, multi-meters, and network packet analyzers.', 'Excellent medical, prescription, vision and dental coverage at minimal cost to employee', 'If medical, prescription, vision and dental coverage is not needed, up to $10,391 in opt-out payments available', '1.5% of annual salary flexible benefit cash payment', 'Life insurance in amount of 2.5x annual salary paid by CCIU', 'Long-term disability insurance effective 31st day of illness/injury', ""Retirement through PSERS, PA's Public School Employees Retirement System"", ""Worker's Compensentation"", 'New employees start with 10 vacation days, 12 sick days, and 2 personal days annually; unlimited accumulation on vacation and sick days', 'Tuition reimbursement - 100% of 15 credits per year', '2020-2021 Project Benefit Summary.pdf']",2020-12-30 22:37:25
Data Engineer,Flashpoint,N/A,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help build and maintain our data infrastructure.', 'Become an expert in Apache Beam.', 'Create observability tooling to help other teams debug, understand, and tune their big data jobs and pipelines.', 'Assist and mentor other teams with building and managing their data pipelines.', 'Write tools to automate data processes and deployments.', 'Create maintainable, scalable code to address data needs', 'Write empathetic documentation and runbooks to enable your team to be force multipliers for each other.', 'Help bring in new technologies and develop innovative approaches to the data challenges we face.', 'Apply your honesty, strong sense of morals and ethics, and sense of responsibility towards making Flashpoint and those around you smarter, stronger, and kinder.', 'Identify opportunities for automation and drive process improvements.', '1 - 5 years experience contributing to production systems or other relevant experience.', 'Experience with big data infrastructure.', 'Proficient with Java or Scala.', 'Solid foundation in computer science fundamentals from data structures and algorithms to high level design patterns.', 'Excellent analytical, problem solving and technical skills.', 'Demonstrated ability to learn and leverage new technologies.', 'Experience with SQL schema design and data warehousing.', 'Experience working with queuing systems and stream processing patterns.', 'Basic understanding of privacy and security.', 'An organized work ethic.', 'A humble attitude and persistence to learn and to Get Stuff Done Right.', ""Experience with public cloud data services, particularly Google Cloud Platform's."", 'Experience with Spark, Hive, and/or Hadoop.', 'Experience working with data science teams.', 'Experience with automating infrastructure using leading cloud providers.', 'Proficiency with Python.', 'Diversity. Flashpoint is committed to fostering, cultivating and preserving a culture of diversity, inclusion, belonging, and equity. We recognize that diversity is key to achieving our vision. We believe that every person and their experiences contribute to building a work environment and a product that will change the world.', ""Culture and Belonging. Our company's culture isn't something you join, it's something you build and shape, and each person's unique backgrounds and experiences contribute to who Flashpoint is and will become. You will have ample opportunities to connect with coworkers through various communication channels and company-funded events: dietary & allergy conscious catered lunches, book clubs, happy hours, committees and much more."", 'Benefits. We offer a competitive salary and benefits package, including unlimited PTO, 401(K), mental health and wellness benefits, commuter benefits, and generous parental leave policies.', ""Perks. Flashpoint understands that personal wellness is one of the keys to a happy, healthy and productive work environment. That's why we also prioritize health and wellness perks like gym reimbursements and daily meditation, well-stocked kitchens, cool cultural initiatives and inclusive employee events."", 'Career Growth. Flashpoint is invested in the growth of our team members and understands that frequent, two-way feedback is critical to that growth. We encourage regular one-on-ones with your manager, a regular schedule of performance reviews, learning and development opportunities, and guidance through formalized career paths; whether that be towards being a great manager, being a great individual contributor, or a lateral move to gain breadth of knowledge and experience.', 'A Great Place to Work. Literally. According to the 99% of employees surveyed, Flashpoint earned designation as a Great Place to Work-Certified™ Company for 2021. 100% of employees agree that new hires are made to feel welcome and appreciated. If you are interested in learning more, please check out our Certified Profile.']",2020-12-30 22:37:25
CAD Drafter,Aegion Corporation,3.2 out of 5 from 32 employee ratings,"Malvern, PA 19355","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Interpret engineering and construction sketches and mock-ups for graphical intent', 'Implement consistent style in preparing plan, section, elevation, and detail drawings', 'Update standard details as directed by supervisor or engineering manager', 'Complete all drawings using high professional standards for clarity and neatness', 'Review blueprints, sketches, and specifications related to drafting requirements', 'Exercise judgment to determine essential information', 'Scale drawings for accurate proportion and relationship among components', 'Prepare CAD drawings to represent physical features of client facilities', 'Annotate cathodic protection components to client facility drawings as designed or as installed', 'Measure and record field data as directed by project engineers or project managers', 'Analyze and tabulate data for customer reports', 'Associates of Arts degree with a concentration in Computer Aided Drafting or related field or equivalent required', 'Experience with AutoCAD 14.0 required', 'Persist at difficult tasks despite unexpected obstacles']",2020-12-30 22:37:25
"Data Science & Analytics, Lifestyle Brands Internship- Summer 2021",Discovery Communications,4.1 out of 5 from 392 employee ratings,"Bellevue, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Must be currently enrolled as a student (proof of enrollment will be required if selected for an', 'Must be a rising Junior, Senior, or Graduate student', 'Must have at least a 3.0 GPA', 'Must have the legal right to work in the United States.', 'Our internships are paid opportunities. Credit is not required; however, we will provide documentation if necessary.', 'The application deadline is November 6th. After this date, we cannot guarantee your application will be reviewed for the position.', 'We do not require a cover letter. Please demonstrate your passion for the position through your resume.']",2020-12-30 22:37:25
Data engineer,DiamondPick,N/A,"Dallas, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4+ years of experience in IT industry', 'Expertise in Python and Pyspark', '2+ years of experience using Apache spark', 'Good working experience on Delta Lake and ETL processing', 'Proficiency in SQL queries', 'Prior experience of working in a Unix environment', 'Experience building data platforms using Azure stack', 'Experience in harmonizing raw data into a consumer-friendly format using Azure Databricks', 'Experience extracting/querying/joining large data sets at scale', 'Experience building data ingestion pipelines using Azure Data Factory to ingest structured and unstructured data', 'Experience in data wrangling, advanced analytic modeling is preferred', 'Exposure to Java is a plus', 'Strong communication and organizational skills', '8 hour shift', 'One location', 'Yes: Other non-immigrant work authorization (e.g. L-1, TN, E-3, O-1, etc.)', 'No: Not providing sponsorship for this job', 'Temporarily due to COVID-19']",2020-12-30 22:37:25
Federal - Data Engineer,Accenture,"4 out of 5 from 20,306 employee ratings","Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Architect, design, and implement updates and enhancements to data repositories and indices to support data ingest, enrichment, analysis, visualization, and dissemination', 'Perform database engineering and management activities associated with designing, developing, maintaining, and enhancing data analytic systems from multiple data models using an Agile DevSecOps model', 'Integrate data from multiple sources in batches and real time', 'Review, design, and develop data quality management processes and automated procedures intended to produce high levels of data integrity', 'Research and recommend solutions to complex problems', 'Oversee code reviews and delivering feedback regarding designs/code', 'Perform research and development and provide technical support to identify and integrate new and emerging technologies into the data environment', 'Design and implement storage and indexing strategies to provide efficient storage and retrieval to support visualizations such as graph-based and geospatial indices', 'Support design and development of data access APIs that allow enterprise access (as appropriate) to data', 'Develop or provide input to engineering artifacts associated with the data repositories', 'Experience with SQL / NOSQL databases, and/or Graph Databases (Neo4J)', 'Experience with scripting using (Python, Java, Perl, or PL/SQL)', 'Exposure to Cloud Data Services (AWS)', 'Experience with Architecting and building', 'Experience with Data Engineering and Data transformation', 'Familiarity with no-SQL databases like Neo4j, ElasticSearch, or Cassandra', 'Familiarity with SQL query engines, preferably PrestoDB or SparkSQL', 'Familiarity with distributed platforms (i.e. HBase, Kafka, Spark, NiFi) and the cloud (i.e. AWS, GCP, Azure), preferably Amazon Web Services', 'Experience integrating open API based data access and processing']",2020-12-30 22:37:25
Data Engineer,Super Systems Inc,4.7 out of 5 from 6 employee ratings,"Chantilly, VA 20151","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Science or Data Engineering: 2 years (Required)Secret (Required)', '2+ years of experience with machine learning, data science, or data engineering', 'Experience with the design, implementation and ETL process for databases', 'Experience with creating data pipelines', 'Experience with building machine learning models and predictive analytics', 'Experience with common programming languages, including SQL, Python, or R', 'Ability to articulate workflows and explain technical concepts to non-technical audiences', 'Ability to interact with multidisciplinary teams including data scientists and technical consultants in project- based areas', 'BA or BS degree', 'Experience with Big Data technologies, including HDFS, Impala, AWS, Glue, Azure, Cloudera, Hadoop, or Spark', 'Experience with data science frameworks including DataBricks, Data Robot, or Cloudera', 'Experience with distributed computing and optimizing pipelines', 'Experience with parsing a variety of data sources including Oracle, XML, JSON, or parquet', 'Experience with data visualization development and role of data integration', 'Secret', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Chantilly, VA 20151 (Required)', 'Data Science or Data Engineering: 2 years (Required)', 'Secret (Required)', 'One location']",2020-12-30 22:37:25
Data Visualization Engineer,AgileOC,N/A,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)Tableau: 1 year (Required)SAP Business Objects (Crystal, Webi, others): 1 year (Required)SQL: 1 year (Required)US work authorization (Preferred)"", 'Help business and other users by developing data visualization dashboards/reports in Business Objects and/or Tableau', 'Access various business systems and cleans data as required', 'Five plus years of data visualization experience', 'One year of experience in SAP BusinessObjects', 'One year of experience in Tableau', 'Strong SQL skills', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Chicago, IL (Required)', ""Bachelor's (Required)"", 'Tableau: 1 year (Required)', 'SAP Business Objects (Crystal, Webi, others): 1 year (Required)', 'SQL: 1 year (Required)', 'Information Technology: 5 years (Required)', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Only full-time employees eligible', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:37:25
Data Engineer,Beyond Finance,3.2 out of 5 from 42 employee ratings,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Own small to medium sized projects independently', 'Work with the latest cutting edge technologies which include AWS, Snowflake, Airflow and Terraform', 'Integrate all our data sources under one data warehouse which will allow our business to examine what is going on in endless ways.', 'Be a team player in contributing your thoughts and ideas to the overall goals of the team', 'Work closely with the Business Intelligence team to deliver them the data they need to answer business questions.', 'Design and build data pipelines while thinking of creating standards and common tools to be as productive as possible', 'Learn how to take deep dives into technologies and troubleshoot issues to understand the root cause', 'Think about how to handle security issues surrounding access, PII, and business-sensitive data.', ""Design for scalability and robustness of availability ensuring the data pipelines work or provide a clear error when they can't proceed."", ""Bachelor's degree in Computer Science or other technical field or equivalent work experience"", '2-5 years of experience working on building services or data integrations; Airflow experience is a plus', 'Solid Python coding and scripting experience', 'Good knowledge of a relational database platform such as MySQL, Postgres, Redshift, Snowflake, Oracle or SQL Server; any cloud database technologies is a plus', 'Experience working with cloud platforms such as AWS, Azure and GCP', 'Exposure in developing batch systems and real time streaming platforms and a sense of the benefits of each approach.', 'Excellent SQL experience working through complex queries', 'Experience in setting up configuration-as-code tools such as Ansible, Terraform, or Chef.', 'Ability to work in a fast-paced environment where continuous innovation is desired, and ambiguity is the norm', 'Experience with agile or Kanban development methodologies']",2020-12-30 22:37:25
Data Engineer,"Adswerve, Inc.",N/A,"Denver, CO 80202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop applications (visualization, routing data, cleaning data, access to data, interacting with data) for analytics pipelines', 'Develop various Big Data capabilities in the cloud for our clients, aligning them with business strategies and requirements', 'Build data pipelines from leading digital marketing platforms including Google Marketing Platform (GMP), Facebook and Instagram to data warehouses', 'Create data warehouses including determining what datasets to include, the right architecture and tools for the job, while also implementing the architecture, automating pipelines, reporting on results, demonstrating and training clients on value of data warehouses for analysis and how to utilize them', 'Support digital analytics implementations with broad understanding of tag management, HTML and JavaScript on websites, as well as installing advanced JavaScript data analytics tools', 'Work with teams of Google Engineers (Googlers) to architect solutions for massive scale, resiliency and maintainability, leveraging various cloud providers which meet technical, security, and business needs for applications and workloads', 'Work with teams including Google Engineers (Googlers) to develop and lead best-in-class engineering practices to help Clients define and set up frameworks for utilizing Big Data in the cloud', 'Work closely with Data Scientists to execute strategic engineering proof of concepts and contribute to technology strategy and engineering roadmaps', 'Develop monitoring strategies for infrastructure, platforms and applications aligning with enterprise strategy and overall industry trends', 'Translate solutions and complicated concepts to all audiences, from executive level members to marketing teams', 'Other duties as assigned', 'College degree in Computer Science, Information Science or related field preferred - OR - successful completion of code school program combined with experience in data engineering', 'Skilled with SQL (for pulling data), Python (for writing pipelines) and JavaScript (for accessing data from websites)', 'Experience with Google BigQuery or Google Cloud Platform (GCP), AWS or Azure tools as they relate to big data', 'Familiarity with HTML, CSS and JavaScript / Modern JavaScript Frameworks (React)', 'Proven ability to solve complex problems with on-time delivery, the highest quality, and creativity in the approach', 'Ability to listen and understand business needs and creatively develop solutions', 'Ability to work on a team and manage and prioritize individual workloads', 'Strong desire to become a proficient Data Engineer for a fast paced company']",2020-12-30 22:37:25
Data Analytics Engineer - TechOps (Remote),CrowdStrike,3 out of 5 from 14 employee ratings,"Sunnyvale, CA 94086","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:37:25
Sr. Data Engineer,Fracsys Inc,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Advanced degree in a quantitative discipline, such as statistics, data science, computer science, mathematics, engineering, physics, etc.', '4+ years of experience in designing, developing, evaluating, and deploying predictive modeling, machine learning, advanced analytics', 'Experience in Java or Python programming language', 'Superior coding skills using common data science tools, including Python (strongly preferred), R, Linux/Unix command line and shell scripting.', 'Experience with Notebooks such as Jupyter or Apache Zeppelin preferred. Experience with R Studio is required.', 'Experience with NLP pretrained libraries', 'Excellent skill and significant experience in data processing using SQL, Hive, Impala, Spark, or equivalent querying language', 'Strong experience with distributed storage and big data computing technology, such as AWS, Hadoop, or Spark', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Retirement plan', 'Monday to Friday', ""Bachelor's (Preferred)"", 'One location', 'Temporarily due to COVID-19']",2020-12-30 22:37:25
"Data Engineer II - (Hadoop, AWS, Java)",Indeed,4.3 out of 5 from 723 employee ratings,"Austin, TX 78731","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'comScore Total Visits, March 2020', 'BS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field', '5+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl', 'OR Masters in Computer Science or Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field AND 3+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl.', 'Minimum 5 years of experience in the following skills:', 'Big data platforms (Hadoop, GCP, AWS, Azure)', 'Advanced SQL scripting', 'Database Management Systems (for example, Oracle, MySQL or SQLServers', 'Data transformation tools']",2020-12-30 22:37:25
Data Engineer,Engineering Software and Network Services (ESNS),N/A,"Washington, DC 20010","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)Criminal background check (Required)developing data extraction, transformation, and (ETL): 3 years (Preferred)Python, R, and SQL languages: 3 years (Preferred)Hive, Hadoop, Kylin, and other big data analytic tools: 3 years (Preferred)Confidential (Preferred)"", 'Work closely with software engineers and architects to extract, transform, and standardize data to prepare for ingest into target sources', 'Design and develop data services and/or pipelines as part of an Agile/Scrum team', 'Support continuous process automation for data ingest', 'Work with program management and engineers to implement and document complex and evolving requirements', 'Perform multiple tasks simultaneously and successful perform under changing requirements and deadlines', 'Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork', 'Must be a US Citizen', 'Must be able to obtain a Public Trust Clearance', 'BS degree in Computer Science or related IT field/equivalent experience', '5+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.', 'Experience handling multiple tasks, changing priorities, and timely action;', 'Experience with developing data pipelines from many sources for structure and unstructured data sets in a variety of formats', 'Proficiency developing data extraction, transformation, and loading (ETL) processes, and performing test and validation steps', 'Proficiency with Python, R, and SQL languages, as well as various command line interfaces (Linux, AWS, Git Bash, etc.)', 'Technical proficiency with various database architectures, designs, and modeling', 'Familiarity with Hive, Hadoop, Kylin, and other big data analytic tools', 'Excellent communication, and presentation skills with the demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences with an impeccable attention to detail', 'Experience with DHS and knowledge of DHS standards a plus', 'Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions', 'Mid-level expertise in developing and managing data technologies, technical operations, reusable data services, and related tools and technologies', 'Demonstrated ability to adequately plan and meet delivery objectives and maintain adequate service levels in a highly dynamic, complex environments', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', ""Bachelor's (Required)"", 'developing data pipelines: 1 year (Preferred)', 'developing data extraction, transformation, and (ETL): 3 years (Preferred)', 'Python, R, and SQL languages: 3 years (Preferred)', 'design, management, and solutioning of large data sets: 7 years (Preferred)', 'Hive, Hadoop, Kylin, and other big data analytic tools: 3 years (Preferred)', 'database architectures, designs, and modeling: 3 years (Preferred)', 'performing test and validation steps: 3 years (Preferred)', 'Confidential (Preferred)', 'One location', 'esnscorp.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-12-30 22:39:15
Senior Data Engineer,Attentive Mobile,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, implement, and maintain an ever-growing ETL pipeline using state-of-the-art technology', 'Lead the burgeoning data engineering team', 'Establish best practices and standards for managing large collections of data', 'Discover and integrate with new data sources', 'Work closely with data analysts and data scientists, enabling them to provide insight into key performance metrics of the business', 'Identify ways to improve data reliability, efficiency, and quality', '5+ years of experience designing and developing a data warehouse, Snowflake preferred', 'Experience designing, developing, and maintaining a high-throughput and low-latency ETL pipeline', 'You are knowledgeable about data modeling, data access, and data storage techniques', 'Experience with big data tools such as Kinesis, Kafka, Spark, or Amazon EMR', 'Strong data-modeling skills. Good understanding and experience in building star schema and denormalized data structures.', 'Experience with SQL (MySQL or Postgres preferred), ETL, Python', 'Successfully implemented data applications and pipelines in the public cloud, especially Amazon Web Services', 'Robust health benefits packages including access to a 401k and various medical, dental and vision plans, and $100/month fitness reimbursement', 'Full support for remote work during COVID-19', 'Daily lunch delivery credit and other goodies sent to home', 'Regular company-wide social events (even virtually!)', 'Generous annual education stipend toward job-related external learning opportunities', 'An extremely enthusiastic team that appreciates collaboration']",2020-12-30 22:39:15
Data Quality Engineer,Auth0,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and implement automated build, test, and release processes.', 'Define and continuously improve testing strategies.', 'Drive adoption of tools, frameworks, and best practices for data quality.', 'Create and maintain test automation frameworks and tests.', 'Support users of tools and frameworks used for testing.', 'Assist project teams determining whether a given component or feature is ready for release.', 'Define the approach and infrastructure needed for functional and performance testing.', '3+ years of experience in software testing or data analysis.', '3+ years of experience with SQL.', 'Experience with: continuous delivery, service-oriented architecture, cloud platform environments.', 'Demonstrated skill with one or more of the following: test automation, data profiling, data validation, refactoring, debugging.', 'Proficiency in at least one programming language including but not limited to: JavaScript, Go, Python.', 'Strong written and verbal communication skills.', 'Comfort working in a globally distributed environment with a remote workforce.', 'Knowledge of data privacy regulations (GDPR, CCPA) and practices is a plus.', '#US; #CA; #UK; #ES;']",2020-12-30 22:39:15
Data Engineer,Terray Therapeutics,N/A,"Pasadena, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Manage and improve our data lake of millions of fluorescence microscopy images', 'Work with our data scientists to incorporate our image processing workflow into the data pipeline', 'Build and manage our databases of billions to trillions of chemical structures, intensities, affinities, and data from other biological assays', 'Design and architect a data warehouse to support downstream analytics', 'Expert in engineering big data pipelines using modern technologies and cloud infrastructures', 'Expert in building and managing scalable relational databases, preferably in the life sciences space', 'Experience with cloud computing services, preferably AWS (EMR, Redshift)', 'Experience with high-end distributed data processing environments (Spark, Hadoop, etc.)', 'Proficiency in Linux environment, experience with database languages (e.g., SQL) and experience with version control practices and tools (Git)', 'Experience with pipeline/workflow managers (Luigi, Airflow, Nextflow, etc.)', 'Highly proficient in Python and the PyData stack (numpy, pandas, scipy, dask, etc.)']",2020-12-30 22:39:15
Data Mining Engineer Intern (Data Mining) -2021 Summer,TikTok,4.2 out of 5 from 11 employee ratings,"Mountain View, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Enable and contribute to establishing fast and continuous threat response, in partnership with product risk operations, by building advanced analytics systems and data mining insights;', 'Enable and contribute to establishing robust and powerful automated defense, in partnership with Machine Learning peers, by creating and improving risk prevention rules and models;', 'Currently pursuing a Bachelor, Master, or Ph.D. degree in Computer Science, Computer Engineering, Electrical Engineering, Statistics or other relevant majors, ability to complete an at least 12-weeks program beginning in May/June 2021', 'Solid technical / data-mining skills and ability to work with large volume data to identify and abstract abusive behavior patterns in ByteDance products (e.g. TikTok).', 'Ability to think critically and to properly communicate problem solutions to cross-functional partners in a clear, concise, and timely manner.', 'Research background on relevant data mining topics about social platform communities. E.g. Botnet, interest group mining, fraud detection.', 'Basic understanding of Machine Learning, e.g. natural language processing, gradient boost decision trees, graph embedding, and/or popular neural net topics.', 'Applications will be reviewed on a rolling basis and we encourage you to apply early;', 'Interview starts in Dec 2020.']",2020-12-30 22:39:15
AWS Cloud Data Engineer,First Soft Solutions [ Direct],N/A,"Newark, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Along with Cloud Architect assumes overall responsibility for data migration solution', 'Work with AWS services like S3 EC2 VPC Glue Lambda etc and any of the databases like AWS Aurora Dynamo Db RDS database engines and Redshift', 'Supports in designing the migration solution while focusing development of reusable components', 'Ensures adherence to Client standards policies and quality compliance enterprise metadata definition', 'Design the data migration routines Design and develop Security control measures', 'Develop pipeline to improve ELASTICITY', 'Design and Development of source to target mappings', 'Design the process for documenting the business rules', 'Lead the developers and testers for the development validation activities', 'Review the data extraction scripts and business rule documentation', 'More than 1 year', 'Likely', 'No', 'Bonuses', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Paid time off', 'Relocation assistance', 'Yes: H-1B work authorization', 'Yes: Other non-immigrant work authorization (e.g. L-1, TN, E-3, O-1, etc.)', 'Yes: Immigrant visa sponsorship (e.g., green card sponsorship)']",2020-12-30 22:39:15
Robotics Engineer,Robotic Imaging Group,N/A,"Philadelphia, PA 19106","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Derive and allocate hardware requirements, generate design concepts to satisfy operational and functional requirements.', 'Design and document engineering solutions, including cost, fabrication, and serviceability aspects.', 'Develop mathematical formulas to develop and design detailed specifications for components and machinery.', 'manufacturing, production and assembly of the LiDAR Scanner from proof-of-concept (POC) phase through production stabilization.', 'Troubleshoot and resolve design challenges and operating deficiencies.', 'Provide clear, concise, accurate and timely verbal and written updates to company management.', 'Take ownership of tasks from start to finish.', 'Must be a self-starter, and have the ability to work well independently and as part of a team', 'Strong written and verbal communication skills', 'Commitment to details and deadlines', 'Ability to use time productively, maximize efficiency, and meet challenging work goals', 'Ability to take on additional responsibilities as needed, as well as uphold company values and demand the highest standard of conduct from self and others', 'On call', 'One location', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'No']",2020-12-30 22:39:15
Data Engineer,Awning,N/A,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Set up, maintain, and scale our data warehouse', 'Define the vision for our machine learning and data infrastructure', 'Build and maintain our ETL pipeline', 'Integrate third-party data sources with our data infrastructure', 'Deploy ML models to production', 'Build ML models to help us better find and analyze great properties', 'Build dashboards and internal tools to help us find great investments for our customers', 'Contribute to our product backend', 'You love high impact, fast paced roles.', 'You are a great communicator.', 'You can manage your own technical roadmap.', 'You have strong SQL experience and have worked in production Python environments before.', 'You have brought machine learning models to production.', 'You have experience with Airflow and Docker or similar.', 'You are analytical and strong mathematically — doing an analysis on an a/b test or debugging a computer vision model is more exciting than daunting.', 'You are excited about working on a diversity of problems day-to-day, whether that be building and deploying a model to production, improving our deployment processes, integrating new data sources, analyzing customer data for the team, containerizing our infrastructure, or adding a feature to our backend.', 'You have 3+ years or experience and are capable of working as the sole data & machine learning infrastructure engineer.', ""Open by Default: We value trust, transparency, empathy, and collaboration. Our founding team is committed to taking lead by being far more transparent with our team than you'll find at other companies."", 'Be an Owner: We expect everyone on the team to take on an ownership mentality. A double entendre, being an owner means taking initiative as a part owner of our company and having empathy for our customers, the owners on our platform.', 'Break New Ground: We value and encourage innovation. Real estate is an archaic industry with very little change — we believe by leading that change ourselves that we can have a meaningful impact on the industry.', 'Full medical, dental, and vision with optional 70% coverage for dependents', 'Flexible vacation policy', 'A stipend to invest in your career development', 'Generous parental leave']",2020-12-30 22:39:15
Junior Data Feeds Engineer,StarCompliance,N/A,"Rockville, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data feed administration', 'Create and manage SFTP accounts and access permissions', 'Liaising with client/brokers to establish new feeds', 'PGP/GPG Encryption configuration', 'File Import Monitoring', 'Application of new file import packages / releases', 'Creation and management of batch files to move/rename data feeds as needed', 'Configuration and monitoring of MoveIT application', 'Provide 2nd level major and minor incident resolution support regarding data feeds', 'Demonstrate familiarity with the StarCompliance software application to understand and resolve technical issues', 'Handle escalations around receiving daily and intraday file feeds', 'Categorization / reporting of incidents to an agreed scale of impact/severity/priority', 'Being pro-active on resolving operational alerts relating to file feeds', 'Test files transmissions and importing into application', 'SFTP Connectivity (experience with WS_FTP, MoveIt, FTPGetter, Filezilla)', 'PGP/GPG encryption mechanisms including SSH Key pairs', 'T-SQL – Entry level experience for troubleshooting data', 'SSIS – Entry level experience', 'SQL Server 2012/2016 – Entry level experience', 'Exceptional time management skills toward managing priorities effectively.', 'Strong attention to detail, methodical and organised.', 'Strong analytical skills.', 'Ability to develop working relationships with offshore team members.', 'Good written and verbal communication skills.', 'Financial services experience beneficial, but not essential.', 'All StarCompliance employees are expected to commit to a high standard of personal integrity and carry out their responsibilities in an ethical manner.']",2020-12-30 22:39:15
Data Engineer,Cogito Corporation,N/A,"Boston, MA 02109","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Love working with very large data; exploring data and mining it for insights.', 'Build and maintain robust and resilient data pipelines that enable complex analysis by data science and business intelligence reporting.', 'Love being a part of a high-performing analytics team.', 'Be passionate about DataOps best practices to work smarter, not harder, to ensure baked in quality and efficiency in our data pipelines.', 'Be comfortable working in agile sprints methodology to co-discover the best approach with our stakeholders.', 'Be intellectually curious and enjoy learning, teaching yourself and others the latest big data tools.', 'Build and maintain robust and resilient data pipelines (ETL).', 'Exploratory data analysis and data interpretation.', 'Lead with best practices in DataOps to scale our team efficiently.', 'Work collaboratively with our fellow Cogicians.', 'Minimum Masters degree in advanced technical field, or business analytics, or related prior work experience.', 'Modern Big Data ETL tools', 'Python', 'Docker and Kubernetes', 'SQL', 'AirFlow/Jenkins preferred', 'DataOps methodology', 'Ability to collaborate with fellow Cogicians', 'Ability to multi-task and work in a fast-paced start-up culture', 'Knowledge of git and code repository methods', 'Your choice of comprehensive benefits for you and your family’s health, dental, vision, disability, and life insurance', 'Frequent catered lunch and live product demos', '401(k) retirement plan options', 'Ongoing professional development and cross-training', '20 days vacation time, 5 days sick time, 2 floating holidays and 11 company holidays (yes, Patriot’s Day is a holiday)', '2 ""Be Gentle"" personal days', 'Company paid parental leave upon hire', 'Competitive pay, stock options, and annual bonus eligibility', 'Stock options via equity grants', 'Eligibility for annual bonus for all non commissioned employees', 'Casual and inclusive office atmosphere', 'Office Optional policy where Cogician’s choose where they work either primarily remote, primarily in office or hybrid', 'Ability to support Cogician’s anywhere in the US through our Office Optional policy']",2020-12-30 22:39:15
Data Architect,TCS,3.8 out of 5 from 199 employee ratings,"West Chester, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design short term resolutions to achieve all goals and prepare data roadmap for management', 'Determine procedure to identify and collect all required data, validate process and recommend improvements to corporate data', 'Manage all frameworks to manage data across organization', 'Design and provide support to all data management methodologies according to required standards', 'Good knowledge in data modeling and data warehousing.', 'Good knowledge in SQL.', 'Coordinate with customers, data users and key stakeholders and develop and achieve various long term objectives for data architecture', 'Design short term resolutions to achieve all goals and prepare data roadmap for management', 'Determine procedure to identify and collect all required data, validate process and recommend improvements to corporate data', 'Manage all frameworks to manage data across organization', 'Design and provide support to all data management methodologies according to required standards', 'Administer mapping of all data sources and movement and analyze it to ensure appropriate quality of all data', 'Coordinate with project supervisors and business heads and manages all projects regarding enterprise data', 'Develop key metrics for tests on data and ensure integrity of same on data architecture', '']",2020-12-30 22:39:15
Data Engineer,OverlayAnalytics,N/A,"Dallas, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work across our full modern BI stack - infrastructure (AWS), database (Snowflake, Postgres), services/modeling (dbt, cubeJS)', 'Design and build elegant data structures in support of existing reporting tools and custom visualization platforms', 'Navigate new data sets frequently and model data efficiently and effectively', 'Translate complex business requirements into generic and highly scalable technical solutions', 'Data enthusiast and analytics junkie with an intellectual curiosity and desire to innovate ahead of the curve', 'Proven ability and commitment to delivering clean, tested code', 'Proficient experience writing advanced SQL queries and performance tuning existing queries', 'Solid experience modeling dirty and often unstructured data from a variety of sources', 'Experience with Python, R or JavaScript and modern SDLC methodologies', 'Experience in developing and maintaining ETL/ELT data pipelines', 'Hands-on experience in a recognized reporting tool (preferably Tableau).', 'Experience with a variety of ERP systems, databases, and other business applications', 'Experience in multi-tenant environments and the inherent security risks associated with such environments']",2020-12-30 22:39:15
Data Engineer (Remote),Red Ventures,3.2 out of 5 from 690 employee ratings,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Engineers with in FinServ vertical at Red Ventures is responsible for building and maintaining optimized and highly available data pipelines to facilitate data analysis by Data analysts and to build data models by Data Scientists.', 'Use Spark for streaming applications and/or as an ETL tool, Data Aggregation, User Defined Functions, as well as the Spark UI to analyze behavior and performance.', 'Design, develop and automate high-quality, scalable solutions across the entire data lifecycle, from raw data to powerful insights and analytics.', '3 years of experience developing large scale complex data solutions', ""Bachelor's Degree in Computer Science or related field"", 'Spark, working in RDDs and DataFrames/Datasets API (with emphasis on DataFrames) to query and perform data manipulation', 'Spark Structured Streaming (We process a ton of data in real time)', 'Experience building large scale Spark applications, ideally with either Batch processing and/or Streaming processing', 'Scala would be ideal but a solid knowledge of python or Java is also acceptable', 'Experience in SparkSQL (Broadcast Joins)', 'Experience with cloud computing platforms, we use AWS (Kinesis, S3, Lambda or DynamoDB would also work)', 'Has experience with ANSI SQL relational database (Oracle, SQL, Postgres, MySQL)', 'Has experience with Terraform, Airflow', 'Linux common working knowledge, including navigating through the file system and simple bash scripting', 'General knowledge of distributed systems and distributed data processing frameworks', 'Experience with Storm, Kafka, or Cassandra is a plus', 'Knowledge about agile software processes']",2020-12-30 22:39:15
Data Engineer,Decision Point Healthcare,N/A,"Boston, MA 02109","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop data integration (ETL) processes (including ingestion, cleansing, unification, etc.)', 'Automate the processing of customer data feeds', 'Design and develop tools to support data profiling and data quality methodologies', 'Work with our data science team to assist with data prep and data enrichment for predictive modelling', 'Engage with application development team to ensure all data points are included per application specification', 'Provide periodic support to the customer success team', 'BS / MS in Computer Science, Engineering or applicable experience', '3+ years of experience with ETL principles', '3+ years of experience with Python, JavaScript, and/or PowerShell', '3+ years of SQL experience; Microsoft SQL Server or PostgreSQL preferred', 'Excellent verbal and written communication', 'Knowledge of data manipulation methodologies', 'Ability to discover and highlight unique patterns/trends within data and solve complex problems', 'Keen understanding of database design principles; has worked within staging, data warehouse, and analytic database environments', 'Comfortable working with very large data sets and VLDB environments', 'Experience with version control tools: Git preferred', 'Understanding of data science and predictive modelling concepts preferred', 'Experience working within host vendor and cloud-based infrastructure; AWS and Rackspace preferred', 'Familiarity with statistical software R and BI tool Tableau a plus', 'Familiarity with healthcare data a plus']",2020-12-30 22:39:15
Cloud Data Engineer,Twitter,4.1 out of 5 from 90 employee ratings,"San Francisco, CA 94103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Building a Petabyte-scale Data Warehouse (Google Cloud Next '18) https://youtu.be/APBF9Z3uBCc"", ""How Twitter Migrated its On-Prem Analytics to Google Cloud (Google Cloud Next '18) https://youtu.be/sitnQxyejUg"", 'Strong programming and algorithmic skills', 'Experience with data processing (such as Hadoop, Spark, Pig, Hive, MapReduce etc).', 'Proficiency with SQL (Relational, Redshift, Hive, Presto, Vertica)', 'Experience writing Big Data pipelines, as well as custom or structured ETL, implementation and maintenance', 'Experience with large-scale data warehousing architecture and data modeling', 'Proficiency with Java, Scala, or Python', 'Experience with GCP (BigQuery, BigTable, DataFlow)', 'Experience with Druid or Apache Flink', 'Experience with real-time streaming (Apache Kafka, Apache Beam, Heron, Spark Streaming)', 'Ability in managing and communicating data warehouse project plans to internal clients']",2020-12-30 22:39:15
Data Engineer Summer Intern,Swiss Re,4 out of 5 from 156 employee ratings,"Armonk, NY 10504","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Pursuing a B.S. or M.S. Degree in Computer Science/Computer Engineering', 'Experience with large data sets and distributed computing (Spark/Hive/Hadoop) a plus', 'Proficient in Python and SQL. Familiarity with PySpark and Spark SQL a plus', 'Strong background in the fundamentals of Computer Science', 'Experience with JavaScript/HTML/CSS a plus', 'Experience working in a cloud environment such as AWS or Azure a plus', 'Approaches problems with curiosity and open-mindedness, is a fast learner', 'Ability and enthusiasm to work in a global and multicultural environment', 'Strong analytical skills and can focus on details without losing track of the big picture', 'Excellent oral and written English skills']",2020-12-30 22:40:56
Data Transmission Engineer,Simplex Info,N/A,"Springfield, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Unix operating systems, 5 years (Required)Expert Axway B2Bi, 5 years (Required)Cloud Technologies (AWS), 5 years (Required)', '- Expert Axway B2Bi experience', '- Unix operating systems', '- Cloud Technologies (AWS)', '8 hour shift', 'Monday to Friday', 'Unix operating systems: 5 years (Required)', 'Expert Axway B2Bi: 5 years (Required)', 'Cloud Technologies (AWS): 5 years (Required)']",2020-12-30 22:40:56
Data Center Project Engineer Intern,"Amazon Data Services, Inc.","3.6 out of 5 from 67,873 employee ratings","Herndon, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Pursuing Bsc or MSc in Electrical Engineering, Mechanical Engineering, Construction Management or a similar field', 'Graduating between Fall 2021 and Summer 2022', 'Experience with SQL, mySQL or similar database languages', 'Excel', 'Self-starter who shows good judgment and instincts in decision-making', 'Ability to prioritize in a complex, fast-paced environment', 'Strong verbal and written communication skills', 'Quantitative analytical abilities and problem solving skills', 'Proactively and continually improve your level of knowledge about data center relevant technologies.']",2020-12-30 22:40:56
Data Engineer Lead,Kani Solutions Inc.,N/A,"Los Angeles, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift', 'Day shift', 'Monday to Friday', 'Temporarily due to COVID-19', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:40:56
Data Engineer,Meredith Corporation,3.6 out of 5 from 148 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Understanding business objectives', 'Developing models that help to achieve the objectives', 'Developing metrics to track their progress', 'Managing available resources such as hardware, data, and personnel so that deadlines are met', 'Analyzing the ML algorithms that could be used to solve a given problem and ranking them by success probability', 'Exploring and visualizing data to gain an understanding of it', 'Identifying differences in data distribution that could affect performance when deploying the model in the real world', 'Verifying data quality, and/or ensuring it via data cleaning', 'Supervising the data acquisition process if more data is needed', 'Finding/filtering available datasets online that could be used for training', 'Defining validation strategies', 'Defining the pre-processing or feature engineering to be done on a given dataset', 'Defining data augmentation pipelines', 'Training models and tuning their hyper-parameters', 'Analyzing the errors of the model and designing strategies to overcome them', 'Deploying models to production', 'Excellent problem solving and communication.', 'Strong experience in Algorithms, Object Oriented Programming and Design Patterns.', 'Strong experience in Testing: mocking and stubbing.', 'Strong experience using Git.', 'Strong experience with data modeling and SQL (PostgreSQL 10.5+, MySQL 5.2+).', 'Experience with NoSQL databases (Key Value, Document-Oriented, etc).', 'Comfortable working in a fast paced and agile environment.', 'Constantly seeking ways to improve the data, algorithms, and processes.', 'Proficiency with a deep learning framework such as TensorFlow, Keras, Amazon, Google, MonkeyLearn, etc.', 'Proficiency with Python and libraries for machine learning such as scikit-learn and pandas', 'Expertise in visualizing and manipulating big datasets (up to billions of records)', 'Proficiency with OpenCV', 'Familiarity with Linux', 'Ability to select and configure cloud resources to run an ML model with the required latency', 'Ability to set up Sisense / Periscope visualizations based on the data sets']",2020-12-30 22:40:56
Data Architecture Engineer,Booz Allen Hamilton,"3.9 out of 5 from 2,200 employee ratings","Aberdeen Proving Ground, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience with new capability development and technology evaluation', 'Experience with complex development efforts in a security constrained environment', 'Knowledge of configuration and risk management on data architecture', 'Knowledge of test activities and documentation', 'Secret clearance', 'BA or BS degree', '5+ years of experience with network or system engineering', 'Knowledge of Microsoft products', 'Knowledge of DoD acqusition', 'Ability to multi-task and pay strict attention to detail']",2020-12-30 22:40:56
Sr. Manager - Data Warehouse/ETL,Piper Companies,4.5 out of 5 from 12 employee ratings,"Collegeville, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with Sr. Directors for the streamlining of data processes + building of new data warehouse(s)', 'Drive the adoption of Big Data technologies', '10+ years of Data Engineering/Architecture experience', 'Extensive experience with business intelligence (BI), analytics, and data warehousing', 'Heavy focus on data warehousing work using SQL Server, MySQL, NoSQL', 'Early hands on ETL/Informatica experience', 'Experience with Big Data technologies (Hadoop, Spark, Apache) – a plus', 'Hands on experience with data modeling and building data marts', 'Expert level knowledge of SQL querying', 'Must have experience within financial services', 'Excellent presentation and interpersonal skills', '$80-85/hr W2 (12 month contract to hire), Conversion salary $175k - $185k', 'Comprehensive benefit package; Medical, Dental, Vision, 401k, PTO']",2020-12-30 22:40:56
Data Scientist / Data Engineer,SEVEN,3.8 out of 5 from 98 employee ratings,"Marshall, TX 75672","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Overall responsibility for creating insights from internal and external data sources', 'Provide insight into SEVEN product management and executive team on key performance indicators and improvement opportunities of SEVEN products and users at the marketplace', 'Provide analytics and insights on user behavior, network performance, and mobile application performance to respective customers and ecosystem partners', 'Drive and design improvements to SEVEN mobile products to incorporate data collection that allows continuously better insights', 'Drive and design improvements to SEVEN analytics products from data collection to data frameworks, processing, dashboards and presentation', 'Work with customers and customer support in troubleshooting as a subject matter expert in mobile analytics', '2+ years of relevant experience in analysis and statistics, and corresponding analytics engineering skills', 'Technical or Scientific Master’s degree is required with strong background in mathematics. Ph.D. or other advanced degrees are desirable', 'Experience in SQL, R, Python for analytics, combining data from multiple sources, experience in cleaning up data before jumping to conclusions', 'Excellent verbal, written and visual presentation skills', 'Demonstrated ability and curiosity to find and explain stories and insights from the granular data, connecting the data to real-world benefits', 'Experience in business intelligence packages is preferred', 'Experience in Hadoop is preferred', 'Passion for mobile applications and smartphones']",2020-12-30 22:40:56
Data Engineer,PayPal,"3.9 out of 5 from 1,386 employee ratings","San Jose, CA 95131","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Developing, maintaining, and managing advanced reporting, analytics, dashboards and other BI solutions.', 'Performing and documenting data analysis, data validation, and data mapping/design.', 'Reviewing and improving existing systems and collaborating with teams to integrate new systems.', 'Conducting unit tests and developing database queries to analyze the effects and troubleshoot any issues.', 'A solid understanding of SQL, rational databases, and normalization. Will be expected to write DDL and DML as needed including: create tables, create views, analyze execution plans, and create indexes.', 'Degree in Mathematics, Computer Science, Information Systems, or related field.', 'Relevant work experience.', 'A solid understanding of SQL, rational databases, and normalization.', 'Experience in database schema design preferred.', 'Proficiency in use of query and reporting analysis tools.', 'Competency in Excel (macros, pivot tables, etc.)', 'Extensive experience in developing, maintaining and managing Tableau driven dashboards & analytics and working knowledge of Tableau administration/architecture.', 'Experience with Power Query, Power Pivot, SQL, Power BI a plus', 'Ability to utilize a diversity of software packages, applications and automated systems for collecting and managing data', 'Minimum Experience: Bachelor’s degree and 6-9 years of directly applicable experience; Master’s degree and 4+ years experience preferred.', 'Excellent written and verbal communication skills.', 'Self-starter demonstrates independence, initiative and follow-through. Delivers on time while meeting quality objectives and customer expectations', 'Work across the company to drive to decisions, build consensus and bridge gaps. Builds rapport, credibility and relationships with multiple stakeholders. Great team player.', 'Must be detail-oriented, conscientious, thorough and accurate', 'Must be able to step back and analyze at a broader level, while still being detailed oriented, conscientious, thorough and accurate', 'Strong interpersonal skills, diplomacy, and client service-oriented attitude and mindset', 'Ability to work globally and cross-functionally and lead change in a fast-paced environment', 'Proven ability to function well independently as well as in a team', 'Be comfortable in a fast paced and dynamic environment with a high degree of accuracy', 'Comfortable working in a fluid environment where roles and responsibilities are still evolving', 'Good project management and reporting skills', 'Ability to facilitate group discussions and run meetings', 'Ability to handle multiple projects under pressure', 'Well-developed sense of urgency and follow through', 'Ability to resolve complex issues and settle disputes equitably', 'Ability to determine when to escalate to management and identify the right stakeholders for decision making', 'Proficient with tools such as Power Point, Microsoft Project, MS Word, Excel, Access and Visio']",2020-12-30 22:40:56
Data Engineer,ServiceTitan,3.7 out of 5 from 13 employee ratings,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Map data from various legacy databases into the ServiceTitan platform, subsequently developing SQL scripts that will extract the information efficiently and accurately', 'Develop automated scripts to validate legacy database values and identify previously unmapped fields prior to loading them into the ServiceTitan platform', 'Apply feedback from customers and internal stakeholders on data import quality into previously developed extraction scripts', 'Discover opportunities to leverage information from legacy databases into the implementation process to avoid inquiring for additional information from customers', 'Establish quality working relationships with internal stakeholders', 'Contribute material input to go/no-go/continue decisions upon test completion', '2-5 years of experience with SQL Server 2008/2012/2014/2016', 'Advanced knowledge and experience in T-SQL, complex ETL tools and operations, and SSIS', 'Given the experimental nature of this job, we will require very tight compliance when it comes to data - we need to focus on learning', 'Strong analytical thinking skills', 'Expert level understanding of database and data model concepts', 'Vertical SaaS experience is highly desirable', ""Results and solution oriented - we want to know how we can win, not why we can't"", 'Ability to work independently and cross functionally']",2020-12-30 22:40:56
Data Engineer,Genome Medical,N/A,"South San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and implement scalable robust, and secure data lake and/or data warehouse solutions', 'Take full end-end ownership of new features and be a key point of contact from engineering for cross-functional stakeholders showing positivity and great communication skills', 'Help augment our genomics platform with new reporting functionalities to augment the business intelligence team', 'Adhere to flexible, simple, well-documented, and secure design of internal and external-facing services and be an ardent preacher of it for the rest of the team', 'Participate in design reviews and code reviews to further shape a healthy diligent technical culture', 'Uphold company values and contribute to making Genome Medical a great place to work.', '3+ years of software development experience, from application design through implementation', '2+ years of experience building data warehousing technical components such as ETL, ELT, databases and reporting', '4+ years of experience writing production backend code in Python (preferred) or Java on Linux systems', '3+ years of integrating datasets between multiple microservices using one or more of SQL/noSQL databases', '2+ years of experience designing/developing high performance ETL systems on top of queueing technology components like Kafka, RabbitMQ, Apache Storm is a plus', 'Experience building backends of machine learning pipelines is a plus', 'Knowledge of software engineering practices including coding standards, code reviews, SCM, CI/CD in a containerized environment (e.g. Docker)']",2020-12-30 22:40:56
Data Analyst - DC,BlueLabs Analytics,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyzes data, as well as contributes to the design, implementation, and delivery of analytics products and services.', 'Builds predictive models, tools, and data visualizations.', 'Checks data and modeling results for quality and cleans, transforms, aggregates, and reports on data as needed.', 'Strives to support team excellence by documenting processes and evangelizing new approaches', 'An undergraduate degree in a quantitative field or equivalent work experience.', 'Conceptual understanding of foundations of statistics and modeling (distributions, parameter estimation, confidence intervals and tests, etc.).', 'Proficient understanding of a statistical programming language such as R, Python, or Julia.', 'The ability to effectively communicate technical concepts to a non-technical audience, both in writing and verbally', 'The ability to manipulate data with SQL.', 'Experience building predictive models using regression and machine learning techniques.', 'Knowledge of experimental design and causal inference experience with GIS.', 'Experience creating informative and engaging data visualizations using industry leading tools.', 'The ability to create user interfaces for new products using frameworks such as Shiny or Django.']",2020-12-30 22:40:56
Data Engineer,BriteCore Intuitive Web Solutions,N/A,"Atlanta, GA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs', 'Review code changes introduced by engineers', 'Accept code changes as sufficient and merge the changes into the codebase', 'Demonstrate software to stakeholders', 'Work with relational databases and unstructured data sources, query authoring (SQL and AWS Athena)', 'Build and optimize ‘big data’ data pipelines, architectures, and data sets', 'Build processes supporting data transformation, data structures, metadata, dependency, and workload management', 'Work with message queuing, stream processing, and highly scalable ‘big data’ data stores', 'Support and work with cross-functional teams in a dynamic environment', 'Work with big data tools: Spark', 'Manage data pipeline and workflow management tools: Airflow', 'Work with AWS cloud services: EC2, EMR, RDS, Athena, Glue', 'Help choose and work with stream-processing systems: Storm, Spark-Streaming, etc.', 'Develop APIs and UIs with the following languages and frameworks: Python (2.7 and 3.8), JavaScript (Vue)', 'Experience with data analysis and manipulation tools: Pandas, Spark, etc', 'Proactive actor quick to assume responsibility', 'A collaborator who seeks consensus among peers', 'Organized planner with diligent execution skills', 'Patience and empathy for new team members', 'Willingness to mentor engineers who are not as experienced', 'AWS experience and certifications', 'Remote work experience']",2020-12-30 22:40:56
Data Engineer,SIMON Markets,N/A,"New York, NY 10001","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Leverage open-source technologies and cloud solutions to build elegant features that SIMON platform users love', 'Develop and automate large scale, high-performance data platform infrastructure to drive SIMON business growth and enable data-driven organization', 'Design and develop reusable components and frameworks for ingestion, cleansing, and data quality', 'Streamline the ingestion of raw data from various sources into our Data Lake and Data Warehouse', 'Design data models for optimal storage and retrieval that represent the product entities and meet business requirements', 'Coordinate closely with sales and product development teams daily to push SIMON’s FinTech strategy and improve the overall profitability of our', 'Bachelor’s Degree in Computer Science, Data Science, Mathematics, Statistics or other quantitative area or related field', '1–4 years of experience with open-source technologies or object-oriented/functional programming, strong ability to write easy-to-scale, high-quality code', 'Experienced in at least 1 numeric research framework (python/pandas, R/Splus, Octave/Matlab)', 'Familiarity with OLAP (Redshift, Snowflake) and OLTP (PostgreSQL, MongoDB) databases.', 'Familiarity with various database designs (Relational, Columnar, NoSQL)', 'Some background in probability/statistics', 'Detail-oriented, ability to multitask and work in a fast-paced environment', 'Ability to work independently while also being a strong team player', 'Excellent written and verbal communication', 'Passionate about programming and cutting-edge technologies', 'Master’s or Ph.D. Degree in Computer Science, Data Science or related field', 'Professional experience with Python and JVM based languages such as Scala, Java, and Kotlin', 'Experience building data-pipelines, data-lakes and data warehouses.', 'Good knowledge of financial markets and financial instruments', 'Experience with AWS solutions such as Lambda, S3, Kinesis, ElastiCache', 'Familiarity with AWS and infrastructure-as-code (terraform or cloud formation)', 'Full-time or internship experience as a data engineer in the financial technology industry is a plus']",2020-12-30 22:40:56
Data Engineer,BRAZE,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Own and audit the technical implementation of Braze @ Braze, our instance of the Braze software which runs on our own tool.', 'Build, enhance, and maintain data pipelines which ensure synchronicity between Braze @ Braze, Salesforce, the Braze backend, and other tools like Demandbase, Marketo, etc.', 'Partner with the Customer Marketing team to drive adoption of advanced technical marketing techniques like using AMP for Email, or building API endpoints which can furnish personalized content in real-time to our customers via Connected Content.', 'Collaborate with Product, Customer Marketing, and Product Marketing to instrument new events and attributes in Braze @ Braze in a consistent, documented, and reliable manner.', '3+ years of engineering experience with a strong track record of success.', 'Pride yourself on writing elegant, maintainable code.', 'Comfortable working in a large code-base with many stakeholders across multiple departments and functions.', 'Able to learn new technologies quickly and act independently', 'Have a user-centric attitude and care deeply about CX (Customer Experience)', 'Familiarity with the following technologies is a strong plus (Braze, JS, Ruby, Rails, MongoDB, React, HTML, CSS)', 'Degree in computer science or equivalent experience.', 'Competitive compensation that includes equity', 'Flexible time off policy to balance your work and life, including paid parental leave', 'Free daily lunch in the office, including snacks and beverages', 'Competitive medical, dental, and vision coverage for you and your dependents', 'Collaborative, transparent, and fun loving office culture']",2020-12-30 22:40:56
Data Engineer,BRAZE,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Own and audit the technical implementation of Braze @ Braze, our instance of the Braze software which runs on our own tool.', 'Build, enhance, and maintain data pipelines which ensure synchronicity between Braze @ Braze, Salesforce, the Braze backend, and other tools like Demandbase, Marketo, etc.', 'Partner with the Customer Marketing team to drive adoption of advanced technical marketing techniques like using AMP for Email, or building API endpoints which can furnish personalized content in real-time to our customers via Connected Content.', 'Collaborate with Product, Customer Marketing, and Product Marketing to instrument new events and attributes in Braze @ Braze in a consistent, documented, and reliable manner.', '3+ years of engineering experience with a strong track record of success.', 'Pride yourself on writing elegant, maintainable code.', 'Comfortable working in a large code-base with many stakeholders across multiple departments and functions.', 'Able to learn new technologies quickly and act independently', 'Have a user-centric attitude and care deeply about CX (Customer Experience)', 'Familiarity with the following technologies is a strong plus (Braze, JS, Ruby, Rails, MongoDB, React, HTML, CSS)', 'Degree in computer science or equivalent experience.', 'Competitive compensation that includes equity', 'Flexible time off policy to balance your work and life, including paid parental leave', 'Free daily lunch in the office, including snacks and beverages', 'Competitive medical, dental, and vision coverage for you and your dependents', 'Collaborative, transparent, and fun loving office culture']",2020-12-30 22:42:39
Data Engineer III,Astreya,2.8 out of 5 from 46 employee ratings,"Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Resolves a wide range of issues in creative ways', 'Seasoned, experienced professional with a full understanding of their specialty', 'Works on problems of a diverse scope', 'Receives little instruction on day to day work, general instruction on new assignments', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Create data tools for team members to assist them in building and optimizing analytics production.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Other duties as required. This list is not meant to be a comprehensive inventory of all responsibilities assigned to this position', 'Bachelor’s degree (B.S/B.A) from four-college or university and 5 to 8 years’ related experience and/or training; or equivalent combination of education and experience', 'Networks with senior internal and external personnel in own area of expertise', 'Demonstrates good judgment in selecting methods and techniques for obtaining solutions', 'Proficiency in languages SAS, Python, Java, and MatLab', 'ETL (Extract, Transform, and Load)', 'Database - SQL and NoSQL', 'Data Warehousing – Hadoop, MapReduce, HIVE, Presto', 'Operating system: UNIX, Linux', 'Follows standard practice and procedures when analyzing situations or data', 'Programming language: Javascript, R', 'Basic Machine Learning', 'Must have the ability to perform office-related tasks which may include prolonged sitting or standing', 'Must have the ability to move from place to place within an office environment', 'Must be able to use a computer', 'Must have the ability to communicate effectively', 'Some positions may require occasional repetitive motion or movements of the wrists, hands, and/or fingers', 'Employment in the fast-growing IT space providing you with a variety of career options', 'Opportunity to work with some of the biggest firms in the world as part of the Astreya delivery network', 'Introduction to new ways of working and awesome technologies', 'Career paths to help you establish where you want to go', 'Focus on internal promotion and internal mobility - we love to build teams from within', 'Free 24/7 accessible Professional Development through LinkedIn Learning and other online courses to give you opportunities to upskill at your own pace', 'Education Assistance', 'Dedicated management to provide you with on point leadership and care', 'Numerous on the job perks', 'Market competitive compensation and insurance, health and wellness benefits']",2020-12-30 22:42:39
Data Engineer- Python,Park Computer Systems Inc,N/A,"Tempe, AZ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)SQL: 5 years (Required)Python: 5 years (Required)Criminal background check (Required)US work authorization (Required)"", 'Best in breed technology – Google Big Query & Tableau', 'Small, smart team of engineers and analysts and data scientists', 'Well executed dashboards, self-service modules, alerting and real-time monitoring tools', 'Evangelizing the incremental business value to aid platform adoption', 'Play a key role in building out a large scale distributed and event based Data Platform that serves as an underpinning for all of Freedom’s businesses and products', 'Work with Data Product Managers and Analysts on a daily basis to understand reporting requirements', 'Design and model data structures to support daily, operational and ad hoc reporting', 'Build and own data pipelines and APIs used for data insights and ML predictions', 'Own and support production data warehouse objects', 'Participate in daily scrums and work with data engineers to ensure data availability', 'Effectively manage your time and lead platform development efforts for the line of business', '2-8 years’ experience in developing and maintaining BI solutions.', '2-8 years’ experience in building and enhancing data warehouses.', 'Strong data modeling skills. Good understanding and experience in building star schema and denormalized data structures.', 'Report authoring experience. Working knowledge of reporting tools like Tableau, Looker, SSRS, Business Objects etc.', 'Strong SQL skills.', '1-2 years’ experience implementing ETL.', 'Experience with Python', 'Experience with Apache Nifi/spark', 'GCP or other cloud experience', 'Ability to translate business questions to technical specifications.', 'Strong communication skills', 'Bachelors degree in Electronics, Technology, Computer Science, or another related field', 'Monday to Friday', ""Bachelor's (Required)"", 'SQL: 5 years (Required)', 'Python: 5 years (Required)', 'Temporarily due to COVID-19']",2020-12-30 22:42:39
Data Engineer,ITResonance,N/A,"Dearborn, MI","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:42:39
Senior Data Engineer,silicon tech solutions,N/A,"Wilmington, DE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:42:39
"2021 Intern, Machine Learning Infrastructure",Waymo,3.1 out of 5 from 26 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Learn about and contribute to our machine learning infrastructure, frameworks, and libraries', 'Experience in at least one of: C++, Javascript/Typescript, Python', 'Experience in UI/UX, Web Development, Data Visualization, Data Processing, Distributed Computing, Tensorflow, GPU/accelerator Performance, ML Compression / Optimization, or ML basics', 'Help solve challenging problems with a direct impact on the company', 'Competitive compensation packages with a housing/relocation bonus (if applicable)', 'Medical, dental, and vision insurance', 'Fun intern events and networking opportunities', 'Free breakfast, lunch, dinner, and snacks', 'Free access to Google shuttles', 'Onsite gym']",2020-12-30 22:42:39
Data Engineer,Dun & Bradstreet,3.7 out of 5 from 737 employee ratings,"Waltham, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'The Data Engineer role involves developing applications designed to accumulate, derive meaning from, and apply stewardship to, large datasets.', 'The Data Engineer will have to both be able to work with the Global People Data team’s internal datasets and tools, as well as be able to coordinate with outside groups to continuously meet their needs.', 'The Data Engineer is expected to be a key developer of Global People Data tools and products , both in maintaining and upgrading existing tools and in developing new products using state of the art techniques and programming concepts.', 'Bachelor’s degree (preferable in computer science or a related field', 'Experience with Machine Learning and/or Artificial Intelligence Technologies', '2 - 5 yrs. experience with SQL for data analysis', '2 - 5 yrs. experience with Python for data analysis', '1 - 3 yrs. experience with ETL pipeline development', 'Ability to work closely with others and problem solve complex situations', 'Experience with hosted environments (AWS, and Azure recommended)']",2020-12-30 22:42:39
Data Engineer (Messenger),Facebook,4.2 out of 5 from 602 employee ratings,"Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Drive vision, data strategy for Messenger RTC', 'Plan, build roadmap for longer data strategies, data foundation, data assets to drive longer term needs for the team', 'Define goals and technical direction within Messenger RTC and participate in defining team goals and technical direction within org', 'Design, build and own the optimal data processing architecture and systems for new data and ETL pipelines, dashboards and experimentation metrics', 'Build core datasets as well as scalable and fault-tolerant pipelines', 'Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage', 'Define and own the data engineering roadmap for long term data foundation', 'Collaborate with cross functional partners including data scientists, product managers and Software Engineers and RTC leadership to design and develop end-to-end data assets', 'Actively mentored team members in their careers', '4+ years experience in the data warehouse space', '4+ years experience working with either a MapReduce or an MPP system', '7+ years experience in writing complex SQL and ETL processes', '7+ years experience with schema design and dimensional data modeling', '4+ years experience with object-oriented programming languages']",2020-12-30 22:42:39
Data Engineer Level 2,Pinnacle Group,3.8 out of 5 from 39 employee ratings,"Blue Ash, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'The client is looking for a Data Engineer experienced in implementing data solutions in Azure.', 'The Data Engineer will analyze, design and develop enterprise data and information architecture deliverables, focusing on data as an asset for the enterprise.', 'The Data Engineer will also support the implementation of Infrastructure as Code (IaC) by working with teams to help engineer scalable, reliable, and resilient software running in the cloud.', 'Leverages enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses', 'Guides high level data architecture design (functional, non-functional) and ensures teams adhere to data architecture standards', 'Develops information processes for data acquisition, data transformation, data migration, data verification, data modeling, and data mining', 'Accountable for cost viability and technical estimation of data platform usage', 'Designs data solutions for data distributions and partitions, scalability, disaster recovery and high availability', 'Designs security for data policies and standards', 'Monitors and optimizes data solutions', 'Actively governs and automates standard data architecture patterns and blueprints', 'Partners with architecture, security, infrastructure, and application teams to design and implement the automation of data, data platforms, and tools', 'Creates and updates automation to eliminate routine management processes', 'Articulates the need for scalability and understand the importance of improving quality through testing', '5 plus years of hands-on experience with data platforms', 'Experience in designing data solutions in Azure including data distributions and partitions, scalability, disaster recovery and high availability', 'Experience in monitoring and optimizing data solutions in Azure including using Azure Monitor', 'Experience in implementing data solutions in Azure including Azure SQL, Azure Synapse, Cosmos DB, Databricks, ADLS, Blob Storage, ADF, Azure Stream Analytics', 'Experience in designing security for data policies and standards', 'In depth understanding and proficiency in automation of cloud platforms and data platforms', 'Expertise in on-prem and cloud database automation and platform automation with Azure', 'Proficiency with cloud automation tooling such as Ansible and Terraform', 'Proficiency with DevOps and CI/CD methodologies and tools for automated infrastructure code test, integration, deployment, and assurance', 'Proficiency with Languages such as Ruby, bash, Python or Go', 'Experience with Software Development and automation methodologies', 'Experience with data security best practices', 'Strong problem-solving skills', 'Strong collaboration skills and excellent verbal and written communication skills', 'Leverages enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses', 'Guides high level data architecture design (functional, non-functional) and ensures teams adhere to data architecture standards', 'Develops information processes for data acquisition, data transformation, data migration, data verification, data modeling, and data mining', 'Accountable for cost viability and technical estimation of data platform usage', 'Designs data solutions for data distributions and partitions, scalability, disaster recovery and high availability', 'Designs security for data policies and standards', 'Monitors and optimizes data solutions', 'Actively governs and automates standard data architecture patterns and blueprints', 'Partners with architecture, security, infrastructure, and application teams to design and implement the automation of data, data platforms, and tools', 'Creates and updates automation to eliminate routine management processes', 'Articulates the need for scalability and understand the importance of improving quality through testing']",2020-12-30 22:42:39
Data Engineer,Fundrise,N/A,"Washington, DC 20036","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Serve as the internal product owner for analytics data infrastructure', 'Partner with analysts to build scalable systems that help unlock the value of data from a wide range of sources such as backend databases, event streams, and marketing platforms', 'Consult with our Product and Engineering Teams in the creation of new data in the production environment', 'Manage the complete data stack from ETL through Data Presentation Layer', 'Create company wide alignment through standardized metrics across the company', 'Connect our teams and their workflows to centralized and secure databases', 'Build tools to increase transparency in reporting company wide business outcomes', '2+ years data engineering experience', 'Advanced proficiency using SQL and Python', 'Experience with data warehousing (Redshift is a plus)', 'Experience managing ETL processes (Spark is a plus)']",2020-12-30 22:42:39
Data Engineer,Invitae,3.4 out of 5 from 26 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Understand our complex data ecosystem and build ETL solutions', 'Develop a real-time streaming infrastructure that supports critical business functions', 'Design and develop tools to enable teams to consume and understand data faster', 'Collaborate with multiple teams and own solutions from end-to-end', 'Are self-starters and can work towards a larger goal with minimal guidance', 'Prior experience utilizing data warehousing or building out data warehouses', 'Have at least 3 years of hands-on experience working with large datasets, pipelines, and warehouses', 'Have a focus on high-quality code, including automated testing and coding best practices', 'Have experience with messaging/queuing systems or stream processing systems', 'Have architected distributed systems with infrastructure automation, monitoring and alerting']",2020-12-30 22:42:39
Data Engineer,TTS Solutions Inc,N/A,"Buffalo, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)"", 'Participate in detailed technical design, development, implementation and support of Data applications.', 'Develop, construct, test, automate and maintain Data Pipeline for enterprise and non-enterprise platforms.', 'Maintain standards compliance and ensure development artifacts are in alignment with patterns/ frameworks designed by software engineering teams.', 'Experience in solving the business problem with the right Data architecture.', 'Identify ways to improve data reliability, efficiency and quality.', 'Use large data sets to address business issues.', 'Prepare data for predictive and prescriptive modeling.', 'Leverage data to discover tasks that can be automated.', 'Deliver updates to stakeholders based on analytics.', 'Familiarity with spark programming paradigms (batch and stream-processing)', 'Understanding of different data abstraction objects used in spark for different use cases, use of optimal data format and other optimization techniques.', 'Strong programming skills in at least one of the following languages: Java, Scala. Familiarity with a scripting language like Python as well as Unix/Linux shells.', 'Strong knowledge of writing optimized Spark & Hive sql and experience to tune poor performing queries.', 'Outstanding programming and debugging skills. Strong knowledge of common algorithms and data structures.', 'Good understanding of job scheduling and workflow orchestration through enterprise scheduling tools preferably CA-Automic or Control-M.', 'Strong experience with SQL and relational databases like PostgreSQL, MySQL, Teradata, SQL Server and Oracle.', 'Experience in Data wrangling.', 'Must have the analytical background to find hidden patterns using data.', 'Strong understanding of Data modelling concepts.', 'Familiarity with one or more stream processing / queuing technologies like Spark Streaming, Kafka, Kinesis, Flink, etc. preferred.', 'Familiarity and prior experience with Agile / Scrum development methodologies.', 'Prior Experience deploying to cloud platforms, preferably Azure or AWS Cloud', 'Familiarity with any Object-Oriented Programming language', 'Prior experience in Continuous Integration/Continuous Delivery tools and pipelines such as Jenkins, Maven, Gradle, etc.', 'Experience working in a Regulated Banking Industry is preferred.', '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)']",2020-12-30 22:42:39
Azure Data Engineer,srsconsultancy,N/A,"Fremont, CA 94538","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift']",2020-12-30 22:42:39
Data Engineer,Colsh Consultants,N/A,"Bridgewater, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'The primary job responsibility is to migrate existing R script library to Python.', 'Will also help with process automation', 'Experience working in R for data science – tidyverse, ggplot2 and other relevant data packages, R Studio, Git & command line (bash)', 'Experience working in Python for data science –numpy, matplotlib, pandas data frame, Jupyter notebooks', 'Experience with Microsoft data technologies – MySQL (T-SQL), Spark (MS or Apache)', 'Experience working with data pipelines in Hadoop', 'Process automation']",2020-12-30 22:42:39
Data Engineer,Samsung Electronics,"4 out of 5 from 8,167 employee ratings","Mountain View, CA 94043","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop scalable data stores and frameworks with sub-second query latency on highly multi-dimensional data.', 'Engineering solutions to aggregate and automate large scale data flows from varying sources', 'Build real time streaming pipelines that deliver data with measurable quality under the SLA', 'Ability to effectively communicate ideas to peers and distributed teams', 'Delivering products with top notch quality in a fast-paced environment', 'Contributing towards building a system with a test-driven development / agile approach', 'Collaborate with other team members in breaking down tasks and implementation of the initiatives all the way to release.', 'Works on complex issues where analyzing situations or data requires an in-depth evaluation of variables. Exercises judgement in selecting methods, techniques and evaluation criteria to obtain results.', 'Champion best practices for high availability, scalability and reliability of data processing components', ""Bachelor's degree in Computer Science/Engineering with 8+ years of experience or Master’s degree with 6+ years directly related experience."", 'Experience with large-scale distributed systems as pertains to data storage and computing.', 'Extensive experience with Amazon AWS technologies S3, EMR or similar cloud offerings.', 'Strong development skills in Java, Scala and/or PySpark', 'Knowledge of various databases / database technologies - Oracle, Postgres, Cassandra (NoSQL), Vertica or other columnar databases.', 'Advanced disciplinary knowledge in data technologies like Airflow, Spark, Python, Sql, Java, AWS and strong CS Fundamentals', 'Experience with caching technologies using Redis, Memcached', 'Experience with Full Stack development and building services on the data stack', 'Demonstrated strength in data modeling, ETL development, and data warehousing', 'Highly proficient in Object Oriented Design and Development', 'Experience building micro services on Kubernetes a plus', 'Experience working in the Advertising domain a big plus', 'Samsung Electronics America, Inc. and its subsidiaries are committed to employing a diverse workforce, and provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.']",2020-12-30 22:42:39
Data Engineer,Stitch Fix,3.2 out of 5 from 373 employee ratings,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Senior IC position on the data engineering team, within our Algorithms organization, focusing on our data infrastructure, optimization and scalability', 'You will build and own large additions to our data engineering framework, charged with finding ways to improve scalability, reliability and performance of our most central data pipelines', 'You will lead us in identifying opportunities for more optimized data storage in S3 and better usage of our spark resources across the data engineering organization', 'You will build scalable data engineering solutions & frameworks to solve business and data problems', 'You will be involved in the day-to-day operations of the team, including maintaining and improving our current tools & scripts and supporting full-stack data scientists', 'You will have autonomy to help shape the future of data engineering at Stitch Fix by bringing your ideas on improving and automating what we do and how we do it', 'Work with different teams of data scientists and engineers on how to solve data and business problems in a scalable way', 'Be part of a team which has high visibility across the organization', ""Contribute ideas and direct the team's investment to impactful directions"", 'Contribute to a culture of technical collaboration and scalable development', 'Experience in building out scalable data engineering capabilities', '5+ years of fully independent project experience with significant contributions.', 'Exceptional coding and design skills in Python and SQL', 'Excellent experience in Spark optimization and an understanding of data storage with Amazon S3', 'Experience in working autonomously and taking ownership of projects.', 'Ability to think globally, devising and building solutions to meet many needs rather than completing individual projects or tasks', 'Strong prioritization skills with business impact in mind', 'Strong cross functional communication skills that help simplify and move complex problems forward', 'We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same!', 'We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation', 'We are a technologically and data-driven business', 'We are committed to our clients and connected through our vision of ""Transforming the way people find what they love""', 'We love solving problems, thinking creatively and trying new things', 'We believe in autonomy & taking initiative', 'We are challenged, developed and have meaningful impact', ""We take what we do seriously. We don't take ourselves seriously"", 'We have a smart, experienced leadership team that wants to do it right & is open to new ideas', 'We offer competitive compensation packages and comprehensive health benefits', 'You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day']",2020-12-30 22:44:23
Data Engineer,TTS Solutions Inc,N/A,"Buffalo, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)"", 'Participate in detailed technical design, development, implementation and support of Data applications.', 'Develop, construct, test, automate and maintain Data Pipeline for enterprise and non-enterprise platforms.', 'Maintain standards compliance and ensure development artifacts are in alignment with patterns/ frameworks designed by software engineering teams.', 'Experience in solving the business problem with the right Data architecture.', 'Identify ways to improve data reliability, efficiency and quality.', 'Use large data sets to address business issues.', 'Prepare data for predictive and prescriptive modeling.', 'Leverage data to discover tasks that can be automated.', 'Deliver updates to stakeholders based on analytics.', 'Familiarity with spark programming paradigms (batch and stream-processing)', 'Understanding of different data abstraction objects used in spark for different use cases, use of optimal data format and other optimization techniques.', 'Strong programming skills in at least one of the following languages: Java, Scala. Familiarity with a scripting language like Python as well as Unix/Linux shells.', 'Strong knowledge of writing optimized Spark & Hive sql and experience to tune poor performing queries.', 'Outstanding programming and debugging skills. Strong knowledge of common algorithms and data structures.', 'Good understanding of job scheduling and workflow orchestration through enterprise scheduling tools preferably CA-Automic or Control-M.', 'Strong experience with SQL and relational databases like PostgreSQL, MySQL, Teradata, SQL Server and Oracle.', 'Experience in Data wrangling.', 'Must have the analytical background to find hidden patterns using data.', 'Strong understanding of Data modelling concepts.', 'Familiarity with one or more stream processing / queuing technologies like Spark Streaming, Kafka, Kinesis, Flink, etc. preferred.', 'Familiarity and prior experience with Agile / Scrum development methodologies.', 'Prior Experience deploying to cloud platforms, preferably Azure or AWS Cloud', 'Familiarity with any Object-Oriented Programming language', 'Prior experience in Continuous Integration/Continuous Delivery tools and pipelines such as Jenkins, Maven, Gradle, etc.', 'Experience working in a Regulated Banking Industry is preferred.', '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)']",2020-12-30 22:44:23
Data Analytics Engineer (Boston/Remote),Reify Health,N/A,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work closely with customer, product, design, marketing, and engineering teams to design, develop, iterate, and expand data analytics tools, models, libraries, or features.', 'Develop and support new/existing ETL pipelines and integrations with internal/external data sources.', 'Support a data-driven culture by expanding internal intelligence reporting and dashboard systems', 'Become an expert on our data models and advise technical teams on data model expansion.', 'Perform statistical analyses and prototype the next generation of intelligent features for StudyTeam users', 'Become intimately familiar with HIPAA, GDPR, and other applicable regulatory frameworks and how they influence our architecture and development decisions.', 'Frequently communicate your efforts to Head of Data and other technical/non-technical stakeholders in clear written, verbal, or presentation form.', 'Live our data philosophy, which focuses on ethical decision making, being aware of how biased data (and assumptions) can affect results (and people), and being laser-focused on business needs.', 'At least 3 years of professional work experience in a role dealing with regulated data (such as healthcare).', 'Deep, performance-conscious comfort with various database, warehouse, and streaming platforms such as PostgreSQL, Redshift, and Kafka.', 'Expertise in Python and ideally high comfort (or ability to become comfortable) with Clojure and R.', 'Existing experience managing a self-hosted analytics reporting or dashboard system.', 'Familiarity with AWS ecosystem (Athena, Glue, Redshift, S3, Lambda) and some comfort with CloudFormation or Terraform.', 'Understanding of the nuances of testing and addressing scalability/accuracy of analytical processes in distributed/probabilistic systems.', 'Experience with applied statistics, supervised/unsupervised learning techniques in a healthcare/clinical setting', 'Experience with developing or integrating clinical or other medical taxonomies and ontologies.', 'Experience in a startup environment as a remote employee', 'Advanced degree in computer science, biostatistics, or other related field.', 'Relevant published or publicized professional or academic work such as open-source contributions, blog posts, or publications.', 'Competitive Salary and Stock Options: Salary and stock options commensurate to your experience and expertise.', 'Comprehensive Health and Wellness Coverage: 100% premium coverage for you (and >50% for your dependents) for: a top-tier health plan covering you in all 50 states (with option of HSA) dental, vision, disability (short-term and long-term), and basic term life insurance (for your entire tenure at Reify). We enable 24/7 access to doctor by phone or online via telemedicine coverage.', 'Retirement Plan: 401(k) plan with employer matching program.', 'Company-provided Workstation: You will receive a brand new MacBook Pro laptop to use for work.', 'Location Flexibility: You can work from anywhere in the U.S. compatible with an EST work schedule. Additionally, we fly remoters in for company summits and team events, filled with fun activities, good food, and many opportunities to get to know your colleagues better.', 'Vacation and Holiday Flexibility: Generous paid-time-off policy that accrues with your tenure at Reify which includes holiday flexibility and parental leave.']",2020-12-30 22:44:23
Sr. Data Engineer,Fracsys Inc,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Advanced degree in a quantitative discipline, such as statistics, data science, computer science, mathematics, engineering, physics, etc.', '4+ years of experience in designing, developing, evaluating, and deploying predictive modeling, machine learning, advanced analytics', 'Experience in Java or Python programming language', 'Superior coding skills using common data science tools, including Python (strongly preferred), R, Linux/Unix command line and shell scripting.', 'Experience with Notebooks such as Jupyter or Apache Zeppelin preferred. Experience with R Studio is required.', 'Experience with NLP pretrained libraries', 'Excellent skill and significant experience in data processing using SQL, Hive, Impala, Spark, or equivalent querying language', 'Strong experience with distributed storage and big data computing technology, such as AWS, Hadoop, or Spark', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Retirement plan', 'Monday to Friday', ""Bachelor's (Preferred)"", 'One location', 'Temporarily due to COVID-19']",2020-12-30 22:44:23
Data Scientist,Mystery.org,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Can you translate questions from non-technical stakeholders into decisions that can be answered with data?', 'Can you communicate complicated/foreign concepts or methodology to non-experts?', 'Are you familiar with Python? Numerical & analytical programming (i.e. pandas, scipy, etc)? SQL? Experimentation?', 'Do you have basic proficiency in statistics and statistical modeling?', 'Do you have experience, knowledge or interest in one or more of the following areas: Practical A/B testing for websites, feature engineering, predictive modeling (including using models in production), familiarity with machine learning algorithms?']",2020-12-30 22:44:23
Data Engineer,SpringML,N/A,"Herndon, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Ability to work as a member of a team assigned to design and implement data integration solutions.', 'Build Data pipelines using standard frameworks in Hadoop, Apache Beam and other open source solutions.', 'Learn quickly – ability to understand and rapidly comprehend new areas – functional and technical – and apply detailed and critical thinking to customer solutions.', 'Propose design solutions and recommend best practices for large scale data analysis', 'B.S. or equivalent degree in computer science, mathematics or other relevant fields.', '5-10 years of experience in ETL, Datawarehouse, Visualization and building data pipelines.', 'Strong Programming skills – experience and expertise in one of the following: Java, Python, Scala, C.', 'Proficient in big data/distributed computing frameworks such as Apache Spark, Kafka,', 'Experience with Agile implementation methodologies.']",2020-12-30 22:44:23
Data Analyst - DC,BlueLabs Analytics,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyzes data, as well as contributes to the design, implementation, and delivery of analytics products and services.', 'Builds predictive models, tools, and data visualizations.', 'Checks data and modeling results for quality and cleans, transforms, aggregates, and reports on data as needed.', 'Strives to support team excellence by documenting processes and evangelizing new approaches', 'An undergraduate degree in a quantitative field or equivalent work experience.', 'Conceptual understanding of foundations of statistics and modeling (distributions, parameter estimation, confidence intervals and tests, etc.).', 'Proficient understanding of a statistical programming language such as R, Python, or Julia.', 'The ability to effectively communicate technical concepts to a non-technical audience, both in writing and verbally', 'The ability to manipulate data with SQL.', 'Experience building predictive models using regression and machine learning techniques.', 'Knowledge of experimental design and causal inference experience with GIS.', 'Experience creating informative and engaging data visualizations using industry leading tools.', 'The ability to create user interfaces for new products using frameworks such as Shiny or Django.']",2020-12-30 22:44:23
Data Integration Engineer,at HomeLight,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Building, testing, and releasing product-facing features with stringent correctness and scalability requirements.', 'Designing a solution with other engineers and the ops team to fix a scalability problem and then implement it.', 'Working with other engineering teams to fine tune our REST API.', 'Design and refactor our databases to support our current and future products and growth.', 'Decompose our core application where appropriate into smaller services using the best technologies for the problem at hand.', 'Having a dedicated mentor in the first months who will review your code and help you get ramped up.', '3+ years of API Development with Ruby', 'Experience with Rails engine', 'Good intuition for REST API design', 'Strong SQL skills', 'Experience with one or more web frameworks: Rails, Django.', 'Experience with Data Modeling, ElasticSearch', 'Familiarity with writing highly concurrent systems', 'Experience with Heroku, Postgres', 'Familiarity with python', 'Experience debugging distributed systems.', 'Experience working on a small team, ideally at a startup.', 'Familiarity with the Amazon AWS ecosystem']",2020-12-30 22:44:23
Data Engineer Summer Intern,Swiss Re,4 out of 5 from 156 employee ratings,"Armonk, NY 10504","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Pursuing a B.S. or M.S. Degree in Computer Science/Computer Engineering', 'Experience with large data sets and distributed computing (Spark/Hive/Hadoop) a plus', 'Proficient in Python and SQL. Familiarity with PySpark and Spark SQL a plus', 'Strong background in the fundamentals of Computer Science', 'Experience with JavaScript/HTML/CSS a plus', 'Experience working in a cloud environment such as AWS or Azure a plus', 'Approaches problems with curiosity and open-mindedness, is a fast learner', 'Ability and enthusiasm to work in a global and multicultural environment', 'Strong analytical skills and can focus on details without losing track of the big picture', 'Excellent oral and written English skills']",2020-12-30 22:44:23
Data Scientist / Machine Learning Engineer,BambooHR,3.9 out of 5 from 15 employee ratings,"Lindon, UT 84042","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Train and optimize machine learning models', 'Write code to explore data, facilitate feature engineering, model training, and evaluation', 'Apply natural language processing to understand unstructured text and aid in conversational interfaces', 'Explore, understand, and help improve available data sources and features', 'Collaborate with data engineers, AI software engineers, data analysts, and stakeholders to make effective use of core data assets and model deployment', 'Evaluate emerging techniques by understanding academic papers and new technical tools, and by conducting labs, prototypes, and explorations', 'Monitor and optimize production models', 'Implement machine learning algorithms', 'Design and build deep learning architectures and models', 'Work with NLP, text processing, and conversational interfaces', 'Engineer data features and manipulate data with SQL and scripts', 'Code in languages such as Python and various relevant libraries', 'Collaborate in workflows using git, notebook systems, and cloud-based workflows', 'Clear communicators with the team and stakeholders', 'Analytical and perceptive of patterns', 'Strong in understanding underlying math and algorithms', 'Creative in finding relevant and novel approaches', 'Productive in a dynamic setting', 'Understand the problem and available data deeply', 'Value building robust training, validation, and test sets', 'Write high-quality deployable code', 'Use empirical evidence to guide decisions and to select and tune worthwhile approaches', 'Know when to pursue more / less complex model solutions for the problem at hand', 'Have productive interactions with the team and stakeholders', 'Great Company Culture. We’ve been recognized by multiple organizations like Inc, Salt Lake Tribune, Glassdoor, & Comparably for our great workplace culture.', 'Work that Stays at Work. Genuine work/life balance served here!', 'Rest and Relaxation. 4 weeks paid time off, 11 paid holidays, and you’ll never work on your birthday!', 'Health Benefits. Medical with HSA and FSA options, dental, and vision.', 'Prepare for the Future. 401(k) with a generous company match, access to a personal financial planner, and both legal and life insurance.', 'Financial Peace University. We pay for the class and you walk away with financial savvy and a bonus.', 'Give back. Get paid to give your time to the community: ask us about this!']",2020-12-30 22:44:23
Data Engineer Lead,Kani Solutions Inc.,N/A,"Los Angeles, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift', 'Day shift', 'Monday to Friday', 'Temporarily due to COVID-19', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:44:23
ETL Data Engineer with SQL and PHP,Advanced Technology,N/A,"Phoenix, AZ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL and PHP/Python: 5 years (Required)High school or equivalent (Preferred)', 'Raw data ingestion from files (CSV or Text) to MySQL database using PHP or Python scripts (PHP preferred)', 'Build aggregation ETL programs to aggregate & calcuate to a data warehouse from the raw data', 'Expert in SQL script and language to debug, troubleshoot and report on the data', 'Troubleshoot dashboard and report problems independently, determining the root cause and fixing the problem.', 'Experience with QA transactional level data into the data warehouse', 'Experience with large data sets (50Gb raw data)', 'Experience with tableau report is a major plus', 'Experience with Snowflake is a major plus', 'Implement industry BI standards and best practices', 'Minimum 5 years of ETL scripting experience with PHP or Python. Minimum 3 years experience with Data Analytics and SQL structured programming, ad hoc queries, and data analysis development', 'Understand and apply best practices related to reporting, dashboards, and data visualization;', 'Experienced developing dashboards wireframes and design requirements based on discussion with an understanding of technical and visual design considerations.', 'Data Management and Architecture experience.', 'Conceptual thinker, learner, and effective problem solver', 'Comfortable delivering complex solutions in tight timeframes', 'Must have good written and verbal communication skills, and be able to communicate effectively in business terms with business partners', 'Strong client focus/customer service skills', 'Must be able to work independently as well as in a team environment', 'Ability to consistently deliver solid, successful solutions with short development cycles that hit the mark on the initial delivery', 'High school or equivalent (Preferred)', 'SQL and PHP/Python: 5 years (Required)', 'More than 1 year', 'Likely', 'Yes', 'No: Not providing sponsorship for this job', 'Dependable -- more reliable than spontaneous', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'High stress tolerance -- thrives in a high-pressure environment', 'A job for which military experienced candidates are encouraged to apply', 'Open to applicants who do not have a high school diploma/GED', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'www.bestit.com']",2020-12-30 22:44:23
Data Infrastructure Engineer,Github,4.3 out of 5 from 11 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build services and systems that empathetically and pragmatically meet real operability needs of GitHub developers', 'Use data to understand the availability, reliability, and sustainability of our infrastructure', 'You will respond to the needs of users and of other developers at GitHub.', 'Work closely with other teams from across the organization', 'Experience building and deploying large, complex distributed systems with an eye toward reliability.', 'Proficiency in Golang, Python, and/or Ruby.', 'You take a pragmatic approach to decision making and design choices.', 'Experience building highly available services at scale.', 'You have developed and scaled services in Go.', 'Experience diagnosing and resolving complex multi-system performance problems.', 'Experience with Docker and container orchestration systems.']",2020-12-30 22:44:23
Data Operations Engineer,"HealthCare Partners, MSO",1.8 out of 5 from 4 employee ratings,"Garden City, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Lead the development of ANSI SQL (DDL/DML) as it pertains to the enterprise’s data warehouse and other critical database solutions.', 'Serve as the resident technical expert with respect to relational database and database technologies (triggers, stored procedures, views, indexing, data partitioning and performance tuning).', 'Design and implement data cleansing and de-duplication methodologies/techniques.', 'Define and maintain database standards.', 'Implement and enforce data access standards as required by established information security policies.', 'Lead in the development of an enterprise-wide standard E-MPAC-TL process.', 'Peer review solutions and mentor Enterprise Architecture staff in E-MPAC-TL best practices.', 'Identify and maintain the enterprise’s information management lifecycle.', 'Contribute to the enterprise data governance and data management processes.', 'Adhere to existing processes as documented and actively participate in the development of new processes that adhere to best practices methodology.', 'Research and make recommendations on new technology products and services in support of procurement and development efforts.', 'Evaluate and anticipate the impact of technical solutions on environments; identify key performance indicators to quantify systems performance and deployment deliverables.', 'Review key performance indicator (KPI) reports to determine system and design changes.', 'Ensure that database solutions meet business requirements and goals, fulfill end-user requirements, and identify and resolve issues (execution of a plan that turns an idea into a solution).', 'Research and make recommendations on new technology products and services in support of development efforts and system solutions.', 'Liaise with Information Technology Operations, Business Technology Solutions and the Project Management Office to coordinate technology solutions.', 'Cultivate, disseminate, and enforce Information Technology policies, procedures and best practices, ensuring all Information Technology methodology and processes (Project Management, SDLC and Change Management) are followed and that code is documented (following the programming specification standards).', 'Possess strong skills in relationship management, communications, presentation and mentoring/coaching.', 'Participate in Business Continuity and Disaster Recovery Plan planning, drills, data back-up, recovery and reconciliation testing.', ""Attend technical training's to stay up-to-date on solution trends and new technologies."", 'Perform other duties as assigned.', 'Bachelor’s Degree in Computer Science or a related field, or an equivalent combination of education and related work experience required.', 'Minimum of Four (10) years’ work experience in Information Technology, incliding data warehouse responsibilities.', 'Demonstrate design, development and implementation of highly complex solutions.', 'Demonstrate logical approach to problem solving and high-level analytical capabilities, programming and related technical skills showing ingenuity and creativity, including an attention to detail and an understanding of business processes and constraints.', 'Work within a change management framework that incorporates distinct development, test, and production environments, solution promotion and deployment processes, as well as solution testing and defect management.', 'Demonstrate knowledge of application system networks, technology and concepts in an enterprise Information Technology environment, with the ability to grasp quickly new technologies, applications and concepts, and apply them as required.', 'Ability to work in a team environment, meet deadlines, mentor, share knowledge and take on responsibility and accountability for assigned areas.', 'Ability to organize and structure a growing inventory of application assets, and be able to draw and maintain diagrams that can quickly convey the overall context of the environment/solution.', 'Demonstrate experience in participating in multiple projects and ability to work with limited supervision, showing creativity, innovation, motivation, initiative and professionalism. Excellent interpersonal, analytical, written and verbal communication skills, including the ability to convey information to non-technical colleagues in a concise and clear way.', 'Demonstrate understanding and sensitivity to multi-cultural values, beliefs, and attitudes of both internal and external contacts.', 'Demonstrate appropriate behaviors in accordance with the organization’s vision, mission, and values.']",2020-12-30 22:44:23
Machine Learning Engineer - Search & Recommendations (various levels),Twitter,4.1 out of 5 from 90 employee ratings,"San Francisco, CA 94103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Improve existing search engine and recommendation systems, experiment with new directions and provide ML solutions in recommendation systems within Twitter.', 'Build models and algorithms to understand user interest, user intent, and improve content relevancy.', 'Build features and develop new ranking algorithms.', 'Work closely with live production systems and product teams, and deliver ML solutions at scale within the Twitter tech stack.', 'Thrive on working in concert with other smart people, including from distributed offices.', 'Communicate fluidly, at the level of your audience, and seek to understand and be understood.', 'Have the ability to take on complex problems, learn quickly, iterate, and persist towards a good solution.', 'Take pride in polishing and supporting our products.', 'In the role, you are employing a basic understanding of one or more of these concepts: Information Retrieval, Recommendation Systems, Social Network Analysis.', 'You regularly verify the performance & correctness of the implementations of ML techniques. You are able to triage and fix bugs/issues when they arise.', 'BS, MS, or Ph.D. in Computer Science with 2+ years of related or equivalent experience', 'Fluent in one or more languages like Java, Scala, C++, Python', 'Experience with offline and online data processing frameworks', 'Knowledgeable of core CS concepts such as common data structures and algorithms', 'Comfortable conducting design and code reviews']",2020-12-30 22:44:23
Data Analyst - DC,BlueLabs Analytics,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyzes data, as well as contributes to the design, implementation, and delivery of analytics products and services.', 'Builds predictive models, tools, and data visualizations.', 'Checks data and modeling results for quality and cleans, transforms, aggregates, and reports on data as needed.', 'Strives to support team excellence by documenting processes and evangelizing new approaches', 'An undergraduate degree in a quantitative field or equivalent work experience.', 'Conceptual understanding of foundations of statistics and modeling (distributions, parameter estimation, confidence intervals and tests, etc.).', 'Proficient understanding of a statistical programming language such as R, Python, or Julia.', 'The ability to effectively communicate technical concepts to a non-technical audience, both in writing and verbally', 'The ability to manipulate data with SQL.', 'Experience building predictive models using regression and machine learning techniques.', 'Knowledge of experimental design and causal inference experience with GIS.', 'Experience creating informative and engaging data visualizations using industry leading tools.', 'The ability to create user interfaces for new products using frameworks such as Shiny or Django.']",2020-12-30 22:46:04
Data Integration Engineer,at HomeLight,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Building, testing, and releasing product-facing features with stringent correctness and scalability requirements.', 'Designing a solution with other engineers and the ops team to fix a scalability problem and then implement it.', 'Working with other engineering teams to fine tune our REST API.', 'Design and refactor our databases to support our current and future products and growth.', 'Decompose our core application where appropriate into smaller services using the best technologies for the problem at hand.', 'Having a dedicated mentor in the first months who will review your code and help you get ramped up.', '3+ years of API Development with Ruby', 'Experience with Rails engine', 'Good intuition for REST API design', 'Strong SQL skills', 'Experience with one or more web frameworks: Rails, Django.', 'Experience with Data Modeling, ElasticSearch', 'Familiarity with writing highly concurrent systems', 'Experience with Heroku, Postgres', 'Familiarity with python', 'Experience debugging distributed systems.', 'Experience working on a small team, ideally at a startup.', 'Familiarity with the Amazon AWS ecosystem']",2020-12-30 22:46:04
Data Engineer Summer Intern,Swiss Re,4 out of 5 from 156 employee ratings,"Armonk, NY 10504","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Pursuing a B.S. or M.S. Degree in Computer Science/Computer Engineering', 'Experience with large data sets and distributed computing (Spark/Hive/Hadoop) a plus', 'Proficient in Python and SQL. Familiarity with PySpark and Spark SQL a plus', 'Strong background in the fundamentals of Computer Science', 'Experience with JavaScript/HTML/CSS a plus', 'Experience working in a cloud environment such as AWS or Azure a plus', 'Approaches problems with curiosity and open-mindedness, is a fast learner', 'Ability and enthusiasm to work in a global and multicultural environment', 'Strong analytical skills and can focus on details without losing track of the big picture', 'Excellent oral and written English skills']",2020-12-30 22:46:04
Data Scientist / Machine Learning Engineer,BambooHR,3.9 out of 5 from 15 employee ratings,"Lindon, UT 84042","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Train and optimize machine learning models', 'Write code to explore data, facilitate feature engineering, model training, and evaluation', 'Apply natural language processing to understand unstructured text and aid in conversational interfaces', 'Explore, understand, and help improve available data sources and features', 'Collaborate with data engineers, AI software engineers, data analysts, and stakeholders to make effective use of core data assets and model deployment', 'Evaluate emerging techniques by understanding academic papers and new technical tools, and by conducting labs, prototypes, and explorations', 'Monitor and optimize production models', 'Implement machine learning algorithms', 'Design and build deep learning architectures and models', 'Work with NLP, text processing, and conversational interfaces', 'Engineer data features and manipulate data with SQL and scripts', 'Code in languages such as Python and various relevant libraries', 'Collaborate in workflows using git, notebook systems, and cloud-based workflows', 'Clear communicators with the team and stakeholders', 'Analytical and perceptive of patterns', 'Strong in understanding underlying math and algorithms', 'Creative in finding relevant and novel approaches', 'Productive in a dynamic setting', 'Understand the problem and available data deeply', 'Value building robust training, validation, and test sets', 'Write high-quality deployable code', 'Use empirical evidence to guide decisions and to select and tune worthwhile approaches', 'Know when to pursue more / less complex model solutions for the problem at hand', 'Have productive interactions with the team and stakeholders', 'Great Company Culture. We’ve been recognized by multiple organizations like Inc, Salt Lake Tribune, Glassdoor, & Comparably for our great workplace culture.', 'Work that Stays at Work. Genuine work/life balance served here!', 'Rest and Relaxation. 4 weeks paid time off, 11 paid holidays, and you’ll never work on your birthday!', 'Health Benefits. Medical with HSA and FSA options, dental, and vision.', 'Prepare for the Future. 401(k) with a generous company match, access to a personal financial planner, and both legal and life insurance.', 'Financial Peace University. We pay for the class and you walk away with financial savvy and a bonus.', 'Give back. Get paid to give your time to the community: ask us about this!']",2020-12-30 22:46:04
Data Engineer Lead,Kani Solutions Inc.,N/A,"Los Angeles, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 hour shift', 'Day shift', 'Monday to Friday', 'Temporarily due to COVID-19', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:46:04
ETL Data Engineer with SQL and PHP,Advanced Technology,N/A,"Phoenix, AZ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL and PHP/Python: 5 years (Required)High school or equivalent (Preferred)', 'Raw data ingestion from files (CSV or Text) to MySQL database using PHP or Python scripts (PHP preferred)', 'Build aggregation ETL programs to aggregate & calcuate to a data warehouse from the raw data', 'Expert in SQL script and language to debug, troubleshoot and report on the data', 'Troubleshoot dashboard and report problems independently, determining the root cause and fixing the problem.', 'Experience with QA transactional level data into the data warehouse', 'Experience with large data sets (50Gb raw data)', 'Experience with tableau report is a major plus', 'Experience with Snowflake is a major plus', 'Implement industry BI standards and best practices', 'Minimum 5 years of ETL scripting experience with PHP or Python. Minimum 3 years experience with Data Analytics and SQL structured programming, ad hoc queries, and data analysis development', 'Understand and apply best practices related to reporting, dashboards, and data visualization;', 'Experienced developing dashboards wireframes and design requirements based on discussion with an understanding of technical and visual design considerations.', 'Data Management and Architecture experience.', 'Conceptual thinker, learner, and effective problem solver', 'Comfortable delivering complex solutions in tight timeframes', 'Must have good written and verbal communication skills, and be able to communicate effectively in business terms with business partners', 'Strong client focus/customer service skills', 'Must be able to work independently as well as in a team environment', 'Ability to consistently deliver solid, successful solutions with short development cycles that hit the mark on the initial delivery', 'High school or equivalent (Preferred)', 'SQL and PHP/Python: 5 years (Required)', 'More than 1 year', 'Likely', 'Yes', 'No: Not providing sponsorship for this job', 'Dependable -- more reliable than spontaneous', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'High stress tolerance -- thrives in a high-pressure environment', 'A job for which military experienced candidates are encouraged to apply', 'Open to applicants who do not have a high school diploma/GED', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'www.bestit.com']",2020-12-30 22:46:04
Data Infrastructure Engineer,Github,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build services and systems that empathetically and pragmatically meet real operability needs of GitHub developers', 'Use data to understand the availability, reliability, and sustainability of our infrastructure', 'You will respond to the needs of users and of other developers at GitHub.', 'Work closely with other teams from across the organization', 'Experience building and deploying large, complex distributed systems with an eye toward reliability.', 'Proficiency in Golang, Python, and/or Ruby.', 'You take a pragmatic approach to decision making and design choices.', 'Experience building highly available services at scale.', 'You have developed and scaled services in Go.', 'Experience diagnosing and resolving complex multi-system performance problems.', 'Experience with Docker and container orchestration systems.']",2020-12-30 22:46:04
Data Operations Engineer,"HealthCare Partners, MSO",1.8 out of 5 from 4 employee ratings,"Garden City, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Lead the development of ANSI SQL (DDL/DML) as it pertains to the enterprise’s data warehouse and other critical database solutions.', 'Serve as the resident technical expert with respect to relational database and database technologies (triggers, stored procedures, views, indexing, data partitioning and performance tuning).', 'Design and implement data cleansing and de-duplication methodologies/techniques.', 'Define and maintain database standards.', 'Implement and enforce data access standards as required by established information security policies.', 'Lead in the development of an enterprise-wide standard E-MPAC-TL process.', 'Peer review solutions and mentor Enterprise Architecture staff in E-MPAC-TL best practices.', 'Identify and maintain the enterprise’s information management lifecycle.', 'Contribute to the enterprise data governance and data management processes.', 'Adhere to existing processes as documented and actively participate in the development of new processes that adhere to best practices methodology.', 'Research and make recommendations on new technology products and services in support of procurement and development efforts.', 'Evaluate and anticipate the impact of technical solutions on environments; identify key performance indicators to quantify systems performance and deployment deliverables.', 'Review key performance indicator (KPI) reports to determine system and design changes.', 'Ensure that database solutions meet business requirements and goals, fulfill end-user requirements, and identify and resolve issues (execution of a plan that turns an idea into a solution).', 'Research and make recommendations on new technology products and services in support of development efforts and system solutions.', 'Liaise with Information Technology Operations, Business Technology Solutions and the Project Management Office to coordinate technology solutions.', 'Cultivate, disseminate, and enforce Information Technology policies, procedures and best practices, ensuring all Information Technology methodology and processes (Project Management, SDLC and Change Management) are followed and that code is documented (following the programming specification standards).', 'Possess strong skills in relationship management, communications, presentation and mentoring/coaching.', 'Participate in Business Continuity and Disaster Recovery Plan planning, drills, data back-up, recovery and reconciliation testing.', ""Attend technical training's to stay up-to-date on solution trends and new technologies."", 'Perform other duties as assigned.', 'Bachelor’s Degree in Computer Science or a related field, or an equivalent combination of education and related work experience required.', 'Minimum of Four (10) years’ work experience in Information Technology, incliding data warehouse responsibilities.', 'Demonstrate design, development and implementation of highly complex solutions.', 'Demonstrate logical approach to problem solving and high-level analytical capabilities, programming and related technical skills showing ingenuity and creativity, including an attention to detail and an understanding of business processes and constraints.', 'Work within a change management framework that incorporates distinct development, test, and production environments, solution promotion and deployment processes, as well as solution testing and defect management.', 'Demonstrate knowledge of application system networks, technology and concepts in an enterprise Information Technology environment, with the ability to grasp quickly new technologies, applications and concepts, and apply them as required.', 'Ability to work in a team environment, meet deadlines, mentor, share knowledge and take on responsibility and accountability for assigned areas.', 'Ability to organize and structure a growing inventory of application assets, and be able to draw and maintain diagrams that can quickly convey the overall context of the environment/solution.', 'Demonstrate experience in participating in multiple projects and ability to work with limited supervision, showing creativity, innovation, motivation, initiative and professionalism. Excellent interpersonal, analytical, written and verbal communication skills, including the ability to convey information to non-technical colleagues in a concise and clear way.', 'Demonstrate understanding and sensitivity to multi-cultural values, beliefs, and attitudes of both internal and external contacts.', 'Demonstrate appropriate behaviors in accordance with the organization’s vision, mission, and values.']",2020-12-30 22:46:04
Machine Learning Engineer - Search & Recommendations (various levels),Twitter,4.1 out of 5 from 90 employee ratings,"San Francisco, CA 94103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Improve existing search engine and recommendation systems, experiment with new directions and provide ML solutions in recommendation systems within Twitter.', 'Build models and algorithms to understand user interest, user intent, and improve content relevancy.', 'Build features and develop new ranking algorithms.', 'Work closely with live production systems and product teams, and deliver ML solutions at scale within the Twitter tech stack.', 'Thrive on working in concert with other smart people, including from distributed offices.', 'Communicate fluidly, at the level of your audience, and seek to understand and be understood.', 'Have the ability to take on complex problems, learn quickly, iterate, and persist towards a good solution.', 'Take pride in polishing and supporting our products.', 'In the role, you are employing a basic understanding of one or more of these concepts: Information Retrieval, Recommendation Systems, Social Network Analysis.', 'You regularly verify the performance & correctness of the implementations of ML techniques. You are able to triage and fix bugs/issues when they arise.', 'BS, MS, or Ph.D. in Computer Science with 2+ years of related or equivalent experience', 'Fluent in one or more languages like Java, Scala, C++, Python', 'Experience with offline and online data processing frameworks', 'Knowledgeable of core CS concepts such as common data structures and algorithms', 'Comfortable conducting design and code reviews']",2020-12-30 22:46:04
Oops! That page can’t be found.,Twitter,N/A,"San Francisco, CA 94103","['Indeed Jobs', '404', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Facebook', 'Twitter', 'instagram', 'Youtube', 'Soundcloud']",2020-12-30 22:46:04
Data Engineer,InfoQuest Consulting Group Inc.,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop solutions to big data problems utilizing common tools found in the ecosystem.', 'Develop solutions to real-time and offline event collecting from various systems.', 'Develop, maintain, and perform analysis within a real-time architecture supporting large amounts of data from various sources.', 'Analyze massive amounts of data and help drive prototype ideas for new tools and products.', 'Design, build and support APIs and services that are exposed to other internal teams', 'Employ rigorous continuous delivery practices managed under an agile software development approach', 'Ensure a quality transition to production and solid production operation of the software', '5+ years programming experience', 'Bachelors or Masters in Computer Science, Statistics or related discipline', 'Experience in one or more languages: Python, Scala/Java, Spark, Batch, Streaming, ML', 'Experience with Python unit testing and code coverage frameworks', 'Experienced in NoSQL / SQL, Microservice, RESTful API development', 'Strong Experience with AWS Core such as Kinesis, Lambda, API Gateway, CloudFormation, CloudWatch', 'Experienced with one of the Analytics tools – Presto / Athena, QuickSight, Tableau', 'Strong Experience with Container technologies and Real-time Streaming (such as Kafka, Kinesis)', 'Test-driven development/test automation, continuous integration, and deployment automation experience', 'Experience with Performance tuning at scale', 'Experience working on big data platforms in the cloud or on traditional Hadoop platforms', 'Experience working in agile/iterative development and delivery environments', 'Enjoy working with data – data analysis, data quality, reporting, and visualization', 'Great design and problem solving skills, with a strong bias for architecting at scale', 'Excellent communication skills', 'Experience in software development of large-scale distributed systems']",2020-12-30 22:46:04
Bioinformatics Data Engineer / Programmer (Contract),"GRAIL, Inc.",N/A,"Menlo Park, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Contribute to derived clinical feature workflows for clinical study data, working from raw data extracts, through data dissemination with a strong focus on automation and data QC.', 'Assist in developing and managing interactive data visualization and analytics tools for reporting.', 'Play a key role in understanding user requirements, implementing systems and authoring procedures related to system use.', 'Maintain data integrity and quality throughout the data lifecycle, including ensuring clinical study-related blinding where appropriate.', 'BS or MS in quantitative scientific fields (computer science, engineering, mathematics, statistics, bioinformatics, etc.).', 'Experience with R or Python programming.', 'Experience with CDISC data models is a plus.', 'Experience with Amazon Web Services is a plus.', 'Experience with cross-functional collaboration while ensuring data quality and commitment to analysis reproducibility.', 'Experience with data visualization and analytics tools.', 'Excellent interpersonal communication (written and verbal) and organizational skills.', 'Excellent team player with a demonstrated track record of success in a cross-functional team environment.', 'Consistent commitment to delivering on team goals with a sense of shared urgency.']",2020-12-30 22:46:04
Machine Learning Engineer,Alaffia Technology Solutions,N/A,"New York, NY 10038","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Machine Learning: 1 year (Preferred)Python: 1 year (Preferred)"", 'Writing production-level machine learning models', 'Building end-to-end services that leverage data science techniques at their core', 'Developing engineering solutions that incorporate the best of existing and nascent technologies to identify improper charges and patterns of fraud, waste, and abuse in healthcare payments', 'Using tools like Jupyter notebooks and wrangling data frames using Pandas to discover insights, and turning these learnings into statistical inference methods, and features for machine learning models', 'Using a variety of technologies such as NLP and OCR to analyze unstructured medical claim data', 'Engaging in infrastructural and architectural decisions that enables scalability of the data platform to support computation on millions of data points', 'Working closely with our backend engineering team to implement new APIs and services to be deployed to our infrastructure', 'Collaborating with our Auditing team which consists of experts in medical billing and clinical settings, to incorporate their expertise into development', 'Collaborating with our frontend and backend engineering teams to design solutions that collect the right feedback data (labels) from manual claim auditing', '2-4 years of experience (5+ years is a plus)', 'Experience building out production-ready machine learning solutions', 'Experience with:', 'Natural Language Processing (NLP)', 'Python, SciPy, PyTorch or Tensorflow', 'Performant SQL', 'Others:', 'Team development, Agile development', 'Production deployments', 'AWS, GitHub, CI/CD', 'Pluses:', 'Experience with:', 'Backend development languages such as C++, Java, or Go', 'Postgres', 'Apache Spark, especially PySpark', 'Pandas', 'AWS technologies such as SageMaker, Comprehend, & Textract', 'Exposure to:', 'Rust', 'Optical Character Recognition (OCR) (e.g. Tesseract)', 'Healthcare software systems such as Epic EHR', 'Competitive compensation package (cash + equity)', 'Benefits: medical & dental', 'Flexible vacation policy', 'Work in a flat organizational structure — direct access to management', 'Dental insurance', 'Health insurance', 'Paid time off', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'Machine Learning: 1 year (Preferred)', 'Python: 1 year (Preferred)', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'alaffia.io', 'Waiting period may apply', 'Only full-time employees eligible', 'Yes', 'Remote interview process', 'Social distancing guidelines in place', 'Virtual meetings', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 22:46:04
Data Engineer,Colsh Consultants,N/A,"Bridgewater, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'The primary job responsibility is to migrate existing R script library to Python.', 'Will also help with process automation', 'Experience working in R for data science – tidyverse, ggplot2 and other relevant data packages, R Studio, Git & command line (bash)', 'Experience working in Python for data science –numpy, matplotlib, pandas data frame, Jupyter notebooks', 'Experience with Microsoft data technologies – MySQL (T-SQL), Spark (MS or Apache)', 'Experience working with data pipelines in Hadoop', 'Process automation']",2020-12-30 22:46:04
Data Migration Engineer,Techficient LLC,N/A,"Fort Wayne, IN 46802","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Learn and understand our core data model', 'Work with software providers, customers and implementation team to obtain data files', 'Downloading, decrypting and placement of raw data files to Azure Storage', 'Creation of stage and target SQL databases for new customer via scripts', 'Creation and configuration of customer migration pipelines in Azure Data Factory from template', 'Execute on importing raw customer data to customer’s staging data via Azure Data Factory pipelines', 'Analysis on tables imported to look for new/unexpected objects within the schema', 'Provide implementations team with statistical overview of the data received (how many files, record counts, any other data explicitly requested.)', 'Build migration SQL views/objects for the given source system based on existing templates', 'Execute on object data migration via Azure Data Factory to customer target database based on implementation timelines/deadlines', 'Review data migration feedback provided by implementation team and make any customer specific adjustments as required', 'Will oversee and be responsible for the final “go-live” production migration', 'Will also have responsibility for ensuring customer data security and segmentation', 'Mitigate any post “go-live” production issues related to data mapping or in support of app development team’s needs', 'A Bachelor’s degree in Computer Science, Information System, or a related field, or equivalent experience;', 'A minimum of 5 years’ experience working on a database team or on database projects;', 'Proven development experience with Microsoft SQL Server Database platform;', 'Proven experience in data migrations between two systems and/or ETL experience', 'Ability to create and maintain database objects including but not limited to tables, views, indexes, user-defined functions, stored procedures, triggers, constraints, custom data types, etc.;', 'Demonstrated understanding of database architectural concepts including but not limited to creating relational models, data segmentation/partitioning, implementing data security models, etc.;', 'Prior experience with or understanding the following is a plus:', 'Microsoft SQL Server Reporting Services or similar enterprise reporting tool;', 'Microsoft Azure Data Factory', 'Microsoft SQL Server Integration Services or similar ETL tool;', 'Creation and/or management of data feeds utilizing both structured (ex XML/JSON) and flat schemas (ex CSV,TXT,XLSX) across a wide range of electronic delivery mechanisms (ex API/ASMX/SFTP)', 'Database performance optimizations including index tuning, execution plan analysis and troubleshooting', '401(k)', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Yes']",2020-12-30 22:46:04
Software Data Engineer Internship,Milliman,3.6 out of 5 from 118 employee ratings,"Indianapolis, IN 46204","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Write code to maintain and enhance data/analytics pipeline(s)', 'Strive for fault tolerant processes and scalable solutions', 'Understand and work with complex data structures and advanced analytics', 'Work with team-members to propose technical solutions to business problems', 'Contribute to the growth of your team by sharing knowledge', 'Communication that is clear, logical, and cordial', 'A helpful, collaborative, and team-oriented attitude', 'Insatiable appetite to learn', 'Professional poise', 'Grit to make it through the difficult problems', 'Pride and ownership to want to make everything better', 'Desire to work with code and data', 'Basic statistics and an intuition for data', 'Basic software development principles (e.g. ""Don\'t Repeat Yourself"")', 'Git and GitHub', 'Python', 'Javascript / Typescript', 'Apache Spark / Databricks', 'Azure / AWS', 'KanBan Workflows']",2020-12-30 22:47:46
Data Engineer,LegitScript,4 out of 5 from 2 employee ratings,"Portland, OR 97204","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop a robust, scalable data model and optimize the consumption of data sources we require to generate important insights about our systems.', 'Share in the ownership of the technical vision and direction for advanced analytics and insight products.', 'Work with top-notch technical professionals developing complex systems at scale and with a focus on sustained operational excellence.', 'Design, implement and support an analytical data infrastructure providing ad-hoc access to large datasets and computing power', 'Manage AWS resources including EC2, RDS, Redshift, et cetera', 'Work with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies', '2+ years of professional experience in data engineering and administration developing large-scale, cloud-native systems on AWS.', 'Experience with data platform technologies in AWS built on-top of S3, MySql, ElasticSearch, and Redshift.', 'Experience with Graph structured data (AWS Neptune, Neo4, etc).', 'Experience supporting a team focused on data science and machine learning.', ""Bachelor's degree in computer science, information systems, engineering, mathematics, or a related technical discipline, or equivalent experience."", 'Expert-level knowledge of data management fundamentals, distributed systems as it pertains to data storage and computing.', 'Proficiency in building data products incrementally and integrating and managing datasets from multiple sources.', 'Expertise in structuring data to enable querying and manipulating data in preparation for analytics or data visualization using SQL, Spark, R/Python, etc.', 'A collaborative work style that seeks consensus', 'Expert at developing with database platforms - SQL and NoSQL.', 'Ability to learn complex methodologies quickly and draw on your creative problem-solving skills to achieve results.', 'Ability to convey complex analytical approaches and findings to technical and non-technical audiences.', 'Experience managing Extract, Transform and Load services', 'Experience maintaining distributed data layers or data lakes', 'Experience with Jira and Confluence.', 'Competitive compensation', 'Work remotely', 'Monthly remote work stipend', 'Multiple Medical plans (one with $0 employee premium option), Dental & Vision plans', '401k with company match and immediate vesting', 'Generous paid time off package and 11 paid holidays', 'And much more!']",2020-12-30 22:47:46
Data Engineer,Spreetail,2.6 out of 5 from 60 employee ratings,"Lincoln, NE 68508","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Gain a deep understanding of Spreetail’s data and how source system changes affect the data warehouse.', 'Develop systems and processes to be fast, efficient, and scale to increasing business demands.', 'Build excellent relationships with team mates and stakeholders that enable you to build the best solutions.', 'Develop, build, and cultivate strong relationships with all stakeholders that are built on trust and respect.', 'Collect and analyze system data to guide decisions for feature prioritization, scope, and design.', 'Take total ownership results of design, solution, or ways to solve measurable problems.', 'Bring energy on a daily basis.', '2+ years of experience in data warehouse modeling, design, and development.', '2+ years of experience in ETL tools (SSIS, DataStage, Informatica, etc.) and OLAP tools.', 'Very strong with SQL development skills (stored procedures, views, functions, etc.).', 'Experienced with on-premises, hybrid, and cloud-based analytical solutions.', 'Quick to learn and adapt to new technologies.', 'Experienced with end-user data integration tools (Power Query, Alteryx, etc.).', 'Experienced with data presentation tools (Power BI, Tableau, QlikView, etc.).', 'Unit Appreciation Rights: Up to 5% of yearly salary; based upon company and team performance', 'Company Bonus: Up to 5% of yearly salary; based upon company and team performance', 'Health Insurance: Spreetail offers two plans:', 'Aetna PPO: Spreetail covers 100% of premiums for employees and 50% for your spouse and dependents included on the plan.', 'Aetna HDHP HSA Plan: Spreetail will contribute $500 to an HSA for an employee-only plan or $1000 for your spouse and dependents included on the plan.', 'Dental Insurance: Spreetail will pay half of the dental coverage for you/spouse/family plans', '401k: Spreetail partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan options', 'Paid Time Off: untracked time off', 'Wedding Week: Enjoy an additional 5 paid days off before or after your wedding', 'Creating a Home: After 2 years of employment, Spreetail will give you $5,000 when you buy a home', 'Year 3 Vacation: After 3 years of employment, you will be eligible for an all-inclusive vacation', 'Year 5 Sabbatical: After 5 years of employment, you will be eligible for a 2-week paid sabbatical', 'Donation Matching: Spreetail will match your donation dollar for dollar, up to $250 a', 'Community Involvement: Spreetail encourages employees to take time off for volunteer opportunities throughout the year, including a semi-annual volunteer week in every community we serve', 'Product Discount: Enjoy a 20% discount on the products we sell']",2020-12-30 22:47:46
Data Engineer,CNA Insurance,3.6 out of 5 from 465 employee ratings,"Chicago, IL 60604","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'A collaborative and growing analytics team with diverse skills and experiences, combined with deep expertise in insurance applications of data and analytics', 'Modern cloud computing environment that enables you to explore data, build and deploy sophisticated processes that impact key areas such as underwriting, pricing, claims management and risk control', 'Sponsorship of continued professional growth through support for attending technical conferences, meetings and symposia', 'Work cross functionally at CNA to build next generation data capabilities to enable superior decision support and insight generation', 'Support data and processes for the pricing, underwriting, claims, operations and marketing for an exciting mix of business insurance products', 'Assemble large and complex data sets from disparate data sources into consumable formats that meet business requirements', 'Create efficient and reproducible ETL Data Pipelines using SQL, Python or big data tools such as Spark', 'Work closely with Data Science, DevOps and data management teams to assist with data-related technical issues and support their data infrastructure needs', 'Build and maintain capabilities for data quality control, identify data quality issues and pipeline failures', 'Build exploratory Dashboards/tools for data scientists and business partners that can be deployed relatively quickly and require low maintenance', 'Create streamlined process for geocoding internal data for matching to external sources', 'Collaborate with application owners to help define data collection requirements', 'Work with Data Scientists to understand requirements and help design systems and processes to deliver business value. Research new uses for existing data', 'Build infrastructure required for flexible and scalable extraction, transformation and loading of data from a wide variety of data sources', 'Design and implement functionality, participate in team code reviews, and provide feedback on performance, logic, standard methodologies and maintenance issues to ensure code-level consistency', 'Create production quality code to support deployment of predictive models', 'Produce coherent documentation, metadata, and reports', 'Own data processing pipelines from conception to production deployment.', 'Advanced SQL knowledge and proven experience working with relational databases.', 'Demonstrated experience in manipulating, merging, cleaning, profiling, and preparing large datasets for analytics, from disparate sources', 'Working knowledge of Python, including pandas', 'Experience working with XML and JSON formats', 'Practical experience with version control, preferably git', 'Experience implementing and maintaining ETL and CI/CD data pipelines', 'Ability to write efficient, well documented data wrangling code', 'Intellectual curiosity to find new and innovative ways to solve data management issues', 'Employ an array of technologies and tools to connect systems together', 'Strong analytical, problem solving and critical thinking skills', 'Attention to detail and accuracy of work, ability to spot and correct issues', 'Strong interpersonal and communication skills', 'Drive to continuously improve and learn new tools and methods', 'Ability to work collaboratively with colleagues with diverse perspectives and backgrounds', 'Strong time management skills', 'Capable of operating with little supervision and thinking independently and innovatively', 'Experience with data pipeline and workflow management tools such as Airflow', 'Experience with GCP cloud services such as Big Query, Google Storage, Google Cloud Functions', 'Experience with distributed data processing technologies such as Spark', 'Knowledge of R, including the dplyr and data.table packages', 'Experience working with unstructured data', 'Experience working with insurance data', 'Familiarity with data dash-boarding tools such as Python dash, R Shiny, or Tableau', 'Experience in extracting meaningful information from data using visualization', 'Bachelor’s degree, with two or more years of relevant work experience.']",2020-12-30 22:47:46
Data Engineer - Remote work,TWD,4.5 out of 5 from 13 employee ratings,"Washington, DC 20002","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work closely with software engineers and architects to extract, transform, and standardize data to prepare for ingest into target sources', 'Responsible for the day-to-day operations of systems that depend on data, ensuring data is properly processed and securely transferred to its appropriate location, in a timely manner', 'Process data include managing, manipulating, storing and parsing data in a data pipeline for variety of target sources', 'Design and develop data services and/or pipelines as part of an Agile/Scrum team', 'Support continuous process automation for data ingest', 'Support maintenance of applications and tools that reside on these systems such as upgrades, patches, configuration changes, etc.', 'Work with program management and engineers to implement and document complex and evolving requirements', 'Perform multiple tasks simultaneously and successful perform under changing requirements and deadlines', 'Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork', 'Other duties as assigned', 'BS degree in Computer Science or related IT field/equivalent experience', '7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.', 'Experience handling multiple tasks, changing priorities, and timely action;', 'Experience with developing data pipelines from many sources for structure and unstructured data sets in a variety of formats', 'Proficiency developing data extraction, transformation, and loading (ETL) processes, and performing test and validation steps', 'Proficiency with Python, R, and SQL languages, as well as various command line interfaces (Linux, AWS, Git Bash, etc.)', 'Technical proficiency with various database architectures, designs, and modeling', 'Familiarity with Hive, Hadoop, Kylin, and other big data analytic tools', 'Excellent communication, and presentation skills with the demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences with an impeccable attention to detail', 'Experience with DHS and knowledge of DHS standards a plus', 'Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions', 'Mid-level expertise in developing and managing data technologies, technical operations, reusable data services, and related tools and technologies', 'Demonstrated ability to adequately plan and meet delivery objectives and maintain adequate service levels in a highly dynamic, complex environments']",2020-12-30 22:47:46
Data Center Engineer,Data Bridge Consultants,4.5 out of 5 from 2 employee ratings,"Charlotte, NC 28246","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Knowledge of industry structured cabling standards and best-practices', 'Experience working with copper and fiber cables (CAT6, SFP+, QSFP+, LC, SC)', 'At least 5 years on-prem large scale data center experience supporting the Data Center equipment and/or infrastructure (Power, Space, Cooling, Equipment)', 'Experience setting up RAID, IPMI, and BIOS configurations', 'Data center support including Rack and Stack, Cabling Infrastructure', 'Hands on experience building servers (bare metal chassis, adding motherboard, CPU,', 'RAM, drives, cables, etc.)', 'Remote-hands management', 'Break fix server expertise', 'Hardware experience (Supermicro, Arista, Juniper, Cisco)', 'Power consumption understanding (3-phase, single-phase, KW, KVA)', 'Basic linux understanding and experience (ssh, bash, scp, grep, awk) including basic commands and logging into the server’s to monitor for disk failures, etc.', 'Coordinate data center remote hands teams to perform various tasks. Including firmware and BIOS upgrades, IPMI configuration, hardware troubleshooting (i.e. PSU, RAM HD/SSD replacement)', 'Work with vendors to receive and verify new equipment for BOM’s', 'Configure and test management or IPMI controllers, burn-in process, racking, and cabling', 'Create data center diagrams and rack elevations', 'Travel to remote data centers to perform racks audits of legacy racks (trace cables from server LAN interface to switch port', 'Importing spreadsheets using GitHub in to our DCIM (Netbox, previously Device42)', 'Maintain an updated inventory of spare parts and accessories at each data center', 'Standardized documents, references, and procedures that explain common recurring tasks in data centers', 'Work within multiple Jira projects to complete and assign tasks', 'Point of contact for any data center hardware related (DC sites, vendors)']",2020-12-30 22:47:46
Sr. Data Engineer,Wrench.ai Inc,N/A,"Salt Lake City, UT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL: 3 years (Required)Day Shift (Required)Associate (Preferred)python: 3 years (Preferred)Criminal background check (Preferred)', 'Evaluate new data sources, approaches and technology, make recommendations for solutions and conduct quarterly evaluations of the data science team’s efficiency and make changes as necessary.', 'Participate in strategic planning, data acquisition, API integrations, and product line planning with the executive team.', 'Aid in the creation, automation, production, and tuning of advanced analytical models that ingest data and provide actionable insights and outputs.', 'Work with compliance team members to create, implement, and maintain data governance policies consistent with all compliance requirements, GDPR, and CCPA.', '3+ years of data-related experience at the management level and in the trenches', 'RDS, Postgres, SQL, AWS, including Glue, Step Functions, Workflows, etc, and Python experience.', 'Analytical modeling across more than one industry', 'ETL and automation expertise', 'Extensive experience with data sourcing and selection', 'Extensive experience managing data ingestion, data engineers, and data wrangling', 'NLP, NLU experience a plus', 'Graph/Neo4j database experience a plus', 'Data visualization and interpretation (Plot.ly, Dash, D3, etc) also a plus', 'Willingness to work closely with other teams on business and technical points', 'A futurist mindset, the ability to recognize that in others', 'Savvy data acumen and willingness to ask questions or admit you need help', 'Systems level thinking and the ability to comprehend and retain complex concepts', 'Flexible schedule', 'Health insurance', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'Associate (Preferred)', 'SQL: 3 years (Required)', 'python: 3 years (Preferred)', 'Day Shift (Required)', 'More than 1 year', 'Fully Remote', '20-29', '30-39', 'Open to applicants who do not have a high school diploma/GED', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'A job for which people with disabilities are encouraged to apply', 'Wrench.ai']",2020-12-30 22:47:46
Data Engineer III,Astreya,2.8 out of 5 from 46 employee ratings,"Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Resolves a wide range of issues in creative ways', 'Seasoned, experienced professional with a full understanding of their specialty', 'Works on problems of a diverse scope', 'Receives little instruction on day to day work, general instruction on new assignments', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Create data tools for team members to assist them in building and optimizing analytics production.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Other duties as required. This list is not meant to be a comprehensive inventory of all responsibilities assigned to this position', 'Bachelor’s degree (B.S/B.A) from four-college or university and 5 to 8 years’ related experience and/or training; or equivalent combination of education and experience', 'Networks with senior internal and external personnel in own area of expertise', 'Demonstrates good judgment in selecting methods and techniques for obtaining solutions', 'Proficiency in languages SAS, Python, Java, and MatLab', 'ETL (Extract, Transform, and Load)', 'Database - SQL and NoSQL', 'Data Warehousing – Hadoop, MapReduce, HIVE, Presto', 'Operating system: UNIX, Linux', 'Follows standard practice and procedures when analyzing situations or data', 'Programming language: Javascript, R', 'Basic Machine Learning', 'Must have the ability to perform office-related tasks which may include prolonged sitting or standing', 'Must have the ability to move from place to place within an office environment', 'Must be able to use a computer', 'Must have the ability to communicate effectively', 'Some positions may require occasional repetitive motion or movements of the wrists, hands, and/or fingers', 'Employment in the fast-growing IT space providing you with a variety of career options', 'Opportunity to work with some of the biggest firms in the world as part of the Astreya delivery network', 'Introduction to new ways of working and awesome technologies', 'Career paths to help you establish where you want to go', 'Focus on internal promotion and internal mobility - we love to build teams from within', 'Free 24/7 accessible Professional Development through LinkedIn Learning and other online courses to give you opportunities to upskill at your own pace', 'Education Assistance', 'Dedicated management to provide you with on point leadership and care', 'Numerous on the job perks', 'Market competitive compensation and insurance, health and wellness benefits']",2020-12-30 22:47:46
Data Engineer,StockX,3.2 out of 5 from 16 employee ratings,Washington State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:47:46
Hadoop Data Engineer,Cognizant Technology Solutions,"3.9 out of 5 from 13,859 employee ratings","Richmond, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', '3+ years of experience (Mid-level) Strong Programming experience with object-oriented/object function scripting languages: Python/Scala, Spark.', '3+ years of experience (Mid-level) Experience with big data tools: Hadoop, Apache Spark, Kafka, etc', '1+ years of experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc. (Nice to have)', '1+ Years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.']",2020-12-30 22:47:46
Data Engineer,ServiceTitan,3.7 out of 5 from 13 employee ratings,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Map data from various legacy databases into the ServiceTitan platform, subsequently developing SQL scripts that will extract the information efficiently and accurately', 'Develop automated scripts to validate legacy database values and identify previously unmapped fields prior to loading them into the ServiceTitan platform', 'Apply feedback from customers and internal stakeholders on data import quality into previously developed extraction scripts', 'Discover opportunities to leverage information from legacy databases into the implementation process to avoid inquiring for additional information from customers', 'Establish quality working relationships with internal stakeholders', 'Contribute material input to go/no-go/continue decisions upon test completion', '2-5 years of experience with SQL Server 2008/2012/2014/2016', 'Advanced knowledge and experience in T-SQL, complex ETL tools and operations, and SSIS', 'Given the experimental nature of this job, we will require very tight compliance when it comes to data - we need to focus on learning', 'Strong analytical thinking skills', 'Expert level understanding of database and data model concepts', 'Vertical SaaS experience is highly desirable', ""Results and solution oriented - we want to know how we can win, not why we can't"", 'Ability to work independently and cross functionally']",2020-12-30 22:47:46
Scientist or Engineer,Integral Consulting Inc.,N/A,"Annapolis, MD 21401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assisting with data preparation activities such as organizing, tracking, and summarizing environmental data sources', 'Participating in environmental sample collection activities', 'Participating in data and regulatory analysis in support of soil, groundwater, and sediment quality projects', 'Assisting with technical writing and data presentation for reports.', 'Bachelor’s or master’s degree in the natural life, environmental, or geological sciences or environmental, civil, geotechnical, or related engineering field', '0–3 years of experience', 'Strong oral and written communication skills', 'Strong quantitative skills', 'Good working knowledge of environmental science and chemistry', 'Experience with Microsoft® Office programs', 'A desire to grow intellectually and professionally.']",2020-12-30 22:47:46
Data Engineer,Data Science Works Inc.,N/A,"San Francisco, CA 94105","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 Hour Shift', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Aggressive -- competitive and growth-oriented', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-12-30 22:47:46
Data Engineer,Metabolon,3.5 out of 5 from 13 employee ratings,"Morrisville, NC 27560","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design data schema and operate internal data warehouses and SQL/NoSQL database systems. Develop and integrate data pipelines in support and concert with machine learning needs (ex. ETL processes, triggers, stored procedures)', ""Modify, transform, clean, and normalize data so that it is usable by the team's data scientists and analysts"", 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions', 'Monitor and troubleshoot operational or data issues in the data pipelines', 'Drive architectural plans and implementation for future data storage, reporting, and analytic solutions', 'Work collaboratively with business analysts, data scientists, and other internal partners to identify opportunities/problems', 'Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem', 'Develop across multiple codebases for in the service of scientific, business, internal and external concerns', 'Lead multiple simultaneous initiatives in an entrepreneurial environment', 'Experience with several query languages, schema definition languages, and scripting languages', 'Experience in writing and optimizing SQL queries in a business environment with large-scale, complex datasets', 'Practical experience in Python, UNIX/Linux, SQL', 'Experience with big data processing technology (e.g., Hadoop or ApacheSpark), data warehouse technical architecture, infrastructure components, ETL, and reporting/analytic tools and environments', 'Experience designing and implementing genomic data pipelines', 'Experience with modern machine learning toolkits (Tensorflow, Keras, etc…)', 'ML in the cloud experience is a plus', 'Direct experience with Microsoft Azure or Amazon EC2 and Redshift', 'Experience with NoSQL systems like MongoDB, Redis, or Cassandra', 'Experience in a .NET environment is a plus', 'Experience with data visualization software (e.g., Tableau) or open-source project', 'Ability to deal with ambiguity in a fast-paced environment', 'BS with 3-5 years of experience in a data driven field, PhD w/5-8 a plus', 'Experience maintaining database/data cube architecture, configuration, management, and growth', 'Demonstrated ability to design and implement ETL workflows across both Windows and Linux environments', 'Experience with data warehouse design and implementation', 'Experience with dimensional data modeling and schema design in data warehouses', 'Experience interacting with machine learning approaches on a variety of large data sets', 'Broad base of experience in data structures, modern platforms, evolving best practices', 'Experience integrating scientific data, business data, reports and providing custom hooks for natural language processing, deep learning, and other modern mining approaches are all pluses']",2020-12-30 22:47:46
Data Engineer,Academic Analytics Llc,N/A,Wisconsin,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Have strong experience with data-oriented products', 'Identify and proactively create new data ingestion and processing tooling to eliminate manual processes, inefficient or repetitive work, or address quality issues', 'Have strong experience with ETL tools', 'Have ingested large scale structured data in the past', 'Execute one-off imports of data', 'Demonstrate common sense in applying business logic to ontological/schema decisions', 'Be able connect to public databases to ingest data', 'Have deep scraper experience', 'Make thoughtful judgements on data quality to clean data sources for import', 'Use third-party APIs and web scraping tools to source data at scale', 'Use Python, Jupyter notebooks, and Pandas to inspect and analyze data sources', 'Bachelor’s degree from an accredited college or university; a degree in Computer Science, Engineering preferred.', '5+ years of professional experience.', 'Experience with Microsoft SQL Server', 'Excellent written and verbal skills.', 'Ability to work on multiple projects simultaneously.', 'Experience with UX methodology', 'Exposure to agile methodologies and best practices', 'Exposure to cloud and DevOps environments', 'Have experience with disambiguation techniques', 'Experience with C#', 'Experience collaborating directly with clients', 'Strong Microsoft SQL Server experience', 'Experience with Beautiful Soup and Selenium', 'Willing to engage in modest manual data editing when appropriate']",2020-12-30 22:47:46
Data Engineer - Remote work,TWD,4.5 out of 5 from 13 employee ratings,"Washington, DC 20002","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work closely with software engineers and architects to extract, transform, and standardize data to prepare for ingest into target sources', 'Responsible for the day-to-day operations of systems that depend on data, ensuring data is properly processed and securely transferred to its appropriate location, in a timely manner', 'Process data include managing, manipulating, storing and parsing data in a data pipeline for variety of target sources', 'Design and develop data services and/or pipelines as part of an Agile/Scrum team', 'Support continuous process automation for data ingest', 'Support maintenance of applications and tools that reside on these systems such as upgrades, patches, configuration changes, etc.', 'Work with program management and engineers to implement and document complex and evolving requirements', 'Perform multiple tasks simultaneously and successful perform under changing requirements and deadlines', 'Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork', 'Other duties as assigned', 'BS degree in Computer Science or related IT field/equivalent experience', '7+ years of IT experience including experience in design, management, and solutioning of large, complex data sets and models.', 'Experience handling multiple tasks, changing priorities, and timely action;', 'Experience with developing data pipelines from many sources for structure and unstructured data sets in a variety of formats', 'Proficiency developing data extraction, transformation, and loading (ETL) processes, and performing test and validation steps', 'Proficiency with Python, R, and SQL languages, as well as various command line interfaces (Linux, AWS, Git Bash, etc.)', 'Technical proficiency with various database architectures, designs, and modeling', 'Familiarity with Hive, Hadoop, Kylin, and other big data analytic tools', 'Excellent communication, and presentation skills with the demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences with an impeccable attention to detail', 'Experience with DHS and knowledge of DHS standards a plus', 'Demonstrated experience translating business and technical requirements into comprehensive data strategies and analytic solutions', 'Mid-level expertise in developing and managing data technologies, technical operations, reusable data services, and related tools and technologies', 'Demonstrated ability to adequately plan and meet delivery objectives and maintain adequate service levels in a highly dynamic, complex environments']",2020-12-30 22:49:28
Data Center Engineer,Data Bridge Consultants,4.5 out of 5 from 2 employee ratings,"Charlotte, NC 28246","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Knowledge of industry structured cabling standards and best-practices', 'Experience working with copper and fiber cables (CAT6, SFP+, QSFP+, LC, SC)', 'At least 5 years on-prem large scale data center experience supporting the Data Center equipment and/or infrastructure (Power, Space, Cooling, Equipment)', 'Experience setting up RAID, IPMI, and BIOS configurations', 'Data center support including Rack and Stack, Cabling Infrastructure', 'Hands on experience building servers (bare metal chassis, adding motherboard, CPU,', 'RAM, drives, cables, etc.)', 'Remote-hands management', 'Break fix server expertise', 'Hardware experience (Supermicro, Arista, Juniper, Cisco)', 'Power consumption understanding (3-phase, single-phase, KW, KVA)', 'Basic linux understanding and experience (ssh, bash, scp, grep, awk) including basic commands and logging into the server’s to monitor for disk failures, etc.', 'Coordinate data center remote hands teams to perform various tasks. Including firmware and BIOS upgrades, IPMI configuration, hardware troubleshooting (i.e. PSU, RAM HD/SSD replacement)', 'Work with vendors to receive and verify new equipment for BOM’s', 'Configure and test management or IPMI controllers, burn-in process, racking, and cabling', 'Create data center diagrams and rack elevations', 'Travel to remote data centers to perform racks audits of legacy racks (trace cables from server LAN interface to switch port', 'Importing spreadsheets using GitHub in to our DCIM (Netbox, previously Device42)', 'Maintain an updated inventory of spare parts and accessories at each data center', 'Standardized documents, references, and procedures that explain common recurring tasks in data centers', 'Work within multiple Jira projects to complete and assign tasks', 'Point of contact for any data center hardware related (DC sites, vendors)']",2020-12-30 22:49:28
Sr. Data Engineer,Wrench.ai Inc,N/A,"Salt Lake City, UT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL: 3 years (Required)Day Shift (Required)Associate (Preferred)python: 3 years (Preferred)Criminal background check (Preferred)', 'Evaluate new data sources, approaches and technology, make recommendations for solutions and conduct quarterly evaluations of the data science team’s efficiency and make changes as necessary.', 'Participate in strategic planning, data acquisition, API integrations, and product line planning with the executive team.', 'Aid in the creation, automation, production, and tuning of advanced analytical models that ingest data and provide actionable insights and outputs.', 'Work with compliance team members to create, implement, and maintain data governance policies consistent with all compliance requirements, GDPR, and CCPA.', '3+ years of data-related experience at the management level and in the trenches', 'RDS, Postgres, SQL, AWS, including Glue, Step Functions, Workflows, etc, and Python experience.', 'Analytical modeling across more than one industry', 'ETL and automation expertise', 'Extensive experience with data sourcing and selection', 'Extensive experience managing data ingestion, data engineers, and data wrangling', 'NLP, NLU experience a plus', 'Graph/Neo4j database experience a plus', 'Data visualization and interpretation (Plot.ly, Dash, D3, etc) also a plus', 'Willingness to work closely with other teams on business and technical points', 'A futurist mindset, the ability to recognize that in others', 'Savvy data acumen and willingness to ask questions or admit you need help', 'Systems level thinking and the ability to comprehend and retain complex concepts', 'Flexible schedule', 'Health insurance', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'Associate (Preferred)', 'SQL: 3 years (Required)', 'python: 3 years (Preferred)', 'Day Shift (Required)', 'More than 1 year', 'Fully Remote', '20-29', '30-39', 'Open to applicants who do not have a high school diploma/GED', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'A job for which people with disabilities are encouraged to apply', 'Wrench.ai']",2020-12-30 22:49:28
Data Engineer III,Astreya,2.8 out of 5 from 46 employee ratings,"Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Resolves a wide range of issues in creative ways', 'Seasoned, experienced professional with a full understanding of their specialty', 'Works on problems of a diverse scope', 'Receives little instruction on day to day work, general instruction on new assignments', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Create data tools for team members to assist them in building and optimizing analytics production.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Other duties as required. This list is not meant to be a comprehensive inventory of all responsibilities assigned to this position', 'Bachelor’s degree (B.S/B.A) from four-college or university and 5 to 8 years’ related experience and/or training; or equivalent combination of education and experience', 'Networks with senior internal and external personnel in own area of expertise', 'Demonstrates good judgment in selecting methods and techniques for obtaining solutions', 'Proficiency in languages SAS, Python, Java, and MatLab', 'ETL (Extract, Transform, and Load)', 'Database - SQL and NoSQL', 'Data Warehousing – Hadoop, MapReduce, HIVE, Presto', 'Operating system: UNIX, Linux', 'Follows standard practice and procedures when analyzing situations or data', 'Programming language: Javascript, R', 'Basic Machine Learning', 'Must have the ability to perform office-related tasks which may include prolonged sitting or standing', 'Must have the ability to move from place to place within an office environment', 'Must be able to use a computer', 'Must have the ability to communicate effectively', 'Some positions may require occasional repetitive motion or movements of the wrists, hands, and/or fingers', 'Employment in the fast-growing IT space providing you with a variety of career options', 'Opportunity to work with some of the biggest firms in the world as part of the Astreya delivery network', 'Introduction to new ways of working and awesome technologies', 'Career paths to help you establish where you want to go', 'Focus on internal promotion and internal mobility - we love to build teams from within', 'Free 24/7 accessible Professional Development through LinkedIn Learning and other online courses to give you opportunities to upskill at your own pace', 'Education Assistance', 'Dedicated management to provide you with on point leadership and care', 'Numerous on the job perks', 'Market competitive compensation and insurance, health and wellness benefits']",2020-12-30 22:49:28
Data Engineer,StockX,3.2 out of 5 from 16 employee ratings,Washington State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:49:28
Hadoop Data Engineer,Cognizant Technology Solutions,"3.9 out of 5 from 13,859 employee ratings","Richmond, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', '3+ years of experience (Mid-level) Strong Programming experience with object-oriented/object function scripting languages: Python/Scala, Spark.', '3+ years of experience (Mid-level) Experience with big data tools: Hadoop, Apache Spark, Kafka, etc', '1+ years of experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc. (Nice to have)', '1+ Years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.']",2020-12-30 22:49:28
Data Engineer,ServiceTitan,3.7 out of 5 from 13 employee ratings,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Map data from various legacy databases into the ServiceTitan platform, subsequently developing SQL scripts that will extract the information efficiently and accurately', 'Develop automated scripts to validate legacy database values and identify previously unmapped fields prior to loading them into the ServiceTitan platform', 'Apply feedback from customers and internal stakeholders on data import quality into previously developed extraction scripts', 'Discover opportunities to leverage information from legacy databases into the implementation process to avoid inquiring for additional information from customers', 'Establish quality working relationships with internal stakeholders', 'Contribute material input to go/no-go/continue decisions upon test completion', '2-5 years of experience with SQL Server 2008/2012/2014/2016', 'Advanced knowledge and experience in T-SQL, complex ETL tools and operations, and SSIS', 'Given the experimental nature of this job, we will require very tight compliance when it comes to data - we need to focus on learning', 'Strong analytical thinking skills', 'Expert level understanding of database and data model concepts', 'Vertical SaaS experience is highly desirable', ""Results and solution oriented - we want to know how we can win, not why we can't"", 'Ability to work independently and cross functionally']",2020-12-30 22:49:28
Scientist or Engineer,Integral Consulting Inc.,N/A,"Annapolis, MD 21401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assisting with data preparation activities such as organizing, tracking, and summarizing environmental data sources', 'Participating in environmental sample collection activities', 'Participating in data and regulatory analysis in support of soil, groundwater, and sediment quality projects', 'Assisting with technical writing and data presentation for reports.', 'Bachelor’s or master’s degree in the natural life, environmental, or geological sciences or environmental, civil, geotechnical, or related engineering field', '0–3 years of experience', 'Strong oral and written communication skills', 'Strong quantitative skills', 'Good working knowledge of environmental science and chemistry', 'Experience with Microsoft® Office programs', 'A desire to grow intellectually and professionally.']",2020-12-30 22:49:28
Data Engineer,Data Science Works Inc.,N/A,"San Francisco, CA 94105","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '8 Hour Shift', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Aggressive -- competitive and growth-oriented', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-12-30 22:49:28
Data Engineer,Metabolon,3.5 out of 5 from 13 employee ratings,"Morrisville, NC 27560","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design data schema and operate internal data warehouses and SQL/NoSQL database systems. Develop and integrate data pipelines in support and concert with machine learning needs (ex. ETL processes, triggers, stored procedures)', ""Modify, transform, clean, and normalize data so that it is usable by the team's data scientists and analysts"", 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions', 'Monitor and troubleshoot operational or data issues in the data pipelines', 'Drive architectural plans and implementation for future data storage, reporting, and analytic solutions', 'Work collaboratively with business analysts, data scientists, and other internal partners to identify opportunities/problems', 'Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem', 'Develop across multiple codebases for in the service of scientific, business, internal and external concerns', 'Lead multiple simultaneous initiatives in an entrepreneurial environment', 'Experience with several query languages, schema definition languages, and scripting languages', 'Experience in writing and optimizing SQL queries in a business environment with large-scale, complex datasets', 'Practical experience in Python, UNIX/Linux, SQL', 'Experience with big data processing technology (e.g., Hadoop or ApacheSpark), data warehouse technical architecture, infrastructure components, ETL, and reporting/analytic tools and environments', 'Experience designing and implementing genomic data pipelines', 'Experience with modern machine learning toolkits (Tensorflow, Keras, etc…)', 'ML in the cloud experience is a plus', 'Direct experience with Microsoft Azure or Amazon EC2 and Redshift', 'Experience with NoSQL systems like MongoDB, Redis, or Cassandra', 'Experience in a .NET environment is a plus', 'Experience with data visualization software (e.g., Tableau) or open-source project', 'Ability to deal with ambiguity in a fast-paced environment', 'BS with 3-5 years of experience in a data driven field, PhD w/5-8 a plus', 'Experience maintaining database/data cube architecture, configuration, management, and growth', 'Demonstrated ability to design and implement ETL workflows across both Windows and Linux environments', 'Experience with data warehouse design and implementation', 'Experience with dimensional data modeling and schema design in data warehouses', 'Experience interacting with machine learning approaches on a variety of large data sets', 'Broad base of experience in data structures, modern platforms, evolving best practices', 'Experience integrating scientific data, business data, reports and providing custom hooks for natural language processing, deep learning, and other modern mining approaches are all pluses']",2020-12-30 22:49:28
Data Engineer,Academic Analytics Llc,N/A,Wisconsin,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Have strong experience with data-oriented products', 'Identify and proactively create new data ingestion and processing tooling to eliminate manual processes, inefficient or repetitive work, or address quality issues', 'Have strong experience with ETL tools', 'Have ingested large scale structured data in the past', 'Execute one-off imports of data', 'Demonstrate common sense in applying business logic to ontological/schema decisions', 'Be able connect to public databases to ingest data', 'Have deep scraper experience', 'Make thoughtful judgements on data quality to clean data sources for import', 'Use third-party APIs and web scraping tools to source data at scale', 'Use Python, Jupyter notebooks, and Pandas to inspect and analyze data sources', 'Bachelor’s degree from an accredited college or university; a degree in Computer Science, Engineering preferred.', '5+ years of professional experience.', 'Experience with Microsoft SQL Server', 'Excellent written and verbal skills.', 'Ability to work on multiple projects simultaneously.', 'Experience with UX methodology', 'Exposure to agile methodologies and best practices', 'Exposure to cloud and DevOps environments', 'Have experience with disambiguation techniques', 'Experience with C#', 'Experience collaborating directly with clients', 'Strong Microsoft SQL Server experience', 'Experience with Beautiful Soup and Selenium', 'Willing to engage in modest manual data editing when appropriate']",2020-12-30 22:49:28
Data Engineer,Wunderman Thompson,4 out of 5 from 23 employee ratings,"Dallas, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build data engineering solutions | Build new enterprise level products, including, our analytical mart for use across Wunderman Thompson. This includes data wrangling, feature engineering, as well as formulation of required features for analytical consumption.', 'Create | Build and implement a flexible data mart solution in python that enables auto build cycles and flexible runs to create data marts on the fly.', 'Collaborate | You will be an active participant in the Wunderman Thompson data science community where best practices are shared, innovations are hatched, and cross-vertical collaboration with the product, data science and delivery teams.', 'Cutting edge technology | Cloud based engineering to manage and deploy data pipe-lines end to end from problem formulation, raw data to implementation and optimization.', 'Curious | With an inquisitive mindset you embrace the unknown and see as an opportunity to explore and innovate.', 'Ambitious | Willing to take calculated risks, stretch yourself and your team to do new things vs. plugging into existing solutions.', ""Passionate | You take great pride in your work. You approach our own and our clients' business challenges with enthusiasm and a commitment to getting it right. You love working in health. You see data science as a way of expressing creativity."", 'Humble | Wear any hat that needs to be worn, and you know you do not know everything. You want to learn from others.', 'Deep data science and data engineering skill set with grounding in practical marketing applications oriented towards content, customer insights and customer experience in a digital marketing-heavy environment.', 'Minimum of 2 years of experience deploying enterprise level data engineering solutions.', 'Strong experience with structure data warehouse design and management. Historic knowledge of Oracle, schema design, and Snowflake.', 'Production level PL/SQL scripting, bash scripting.', 'Production level experience with Python, scala/spark.', 'Proven track record building cloud-based infrastructure; AWS required.', 'Some experience with Kafka, Storm, Hadoop, Hive, Presto, MySQL, Redshift, Cassandra, DynamoDB, Elasticsearch.']",2020-12-30 22:49:28
Data Engineer,Innovative Defense Technologies (IDT),N/A,"Arlington, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, implement, deploy and maintain optimal data pipeline and data management architectures.', 'Assemble large, complex data sets that meet functional / non-functional project requirements', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, streaming and ‘big data’ technologies', 'Implement data pipelines to ingest data to the platform, standardize and transform the data', 'Support the development of analytics tools that utilize the data pipeline to provide actionable insights into the data and optimization of objectives.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Design and architect solutions with Big Data technologies (e.g Hadoop, Hive, Spark, Kafka)', 'Design and implement systems that run at scale leveraging containerized deployments', 'Design, build, and scale data pipelines across a variety of source systems and streams (internal, third-party, as well as cloud-based), distributed/elastic environments, and downstream applications and/or self-service solutions', 'Ability to travel up to 10%', 'Master’s Degree in Computer Science, Computer Engineering, Informatics, Information Systems or another quantitative field', '5+ years of experience in a Data Engineer role', 'Experience with big data tools: Hadoop, Spark, etc.', 'Experience with relational SQL and NoSQL databases, including Postgres', 'Experience with AWS cloud or remote services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Kafka, Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Julia, Java, C++, Scala, etc.', 'Experience with data encryption/security features applied to data-in-transit', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific questions and identify opportunities for improvement', 'Experience with development, management, and manipulation of large, complex datasets', 'Experience with database & ETL technologies', 'Demonstrated knowledge of data management competencies and implementation', 'Understands the Big Data related problems and requirements to identify the correct technical approach. Core understanding of Big Data principles and architectural patterns', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Experience with containerized deployment technologies (Kubernetes, Openshift, etc.)', 'Experience with instantiating and configuring Virtual Machines (VMware, VirtualBox, etc.)', 'Experience with Machine Learning algorithms and applications interfacing with data management solutions', 'Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive', 'Attention to detail', 'Initiative, creativity, reliability, teamwork', 'Ability to adapt to and thrive in a fast-paced environment']",2020-12-30 22:49:28
ETL Snowflake Data Engineer,SSIT,N/A,"Columbus, OH 43205","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 7 years (Preferred)DataStage: 8 years (Preferred)"", '5+ years of strong (8.5 out of 10) ETL experience on either DataStage, Informatica, Ab-Initio, Talend etc. (Datastage is preferred)', 'Excellent Proficiency in SQL coding, Strong database fundamentals including SQL, performance and schema design. (8.5 out of 10)', 'Should have hands-on experience in Python scripting. (7 out of 10)', 'Ability to interpret/write custom shell scripts. (7 out of 10)', 'Experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS', 'Experience with AWS platform and Snowflake CDW platform big plus. DBT knowledge will be a big plus too.', 'Experience with Git', 'To be able to work in a fast-paced agile development environment.', 'Day shift', ""Bachelor's (Preferred)"", 'SQL: 7 years (Preferred)', 'DataStage: 8 years (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 22:49:28
Data Scientist Intern (Summer 2021),BCG Digital Ventures,4.3 out of 5 from 10 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Demonstrate and communicate a passion about building the data foundation, products and capabilities that drive business growth', 'Build innovative data products: e.g., real-time services, such as personalization; customer segmentation; unified profile; commerce graph; as well as a big data platforms on Hadoop and Spark with real-time data streaming (e.g. Kinesis) and analysis', 'Conceptualize, define, and oversee regular updates around key product and business metrics as the company’s challenges and data evolve', 'Execute descriptive analyses, ranging from identifying product opportunities to understanding user behavior', 'Cultivate strong collaborations with product, engineering and senior stakeholders', 'Share your technical solutions and product ideas with the BCG DV team through design reviews, pair programming, code reviews, and tech talks', 'Balance competing priorities while adhering to deadlines and aligning resources with value demands', 'Active enrollment in a BS, MS or PhD program in Computer Science, Engineering or a related subject from an accredited University', '3.5 GPA or higher', 'Ability to plan, prioritize and organize work effectively and efficiently within a team', 'Experience with statistical methods such as multivariate analysis, linear models, quantitative approaches, and sampling methods', 'Experience with a programming language like Python, Java, R and C++', 'Ability to translate data insights into product decisions', 'Enthusiasm for learning new concepts and diving deep into data analysis', 'Workflow flexibility and strong teamwork skills']",2020-12-30 22:49:28
Data Engineer,Bluestone Analytics,N/A,"Alexandria, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Integrate OSINT data across multiple disparate systems.', 'Clean, normalize, and aggregate reporting and develop analytics.', 'Provide support to functional areas by acting as an expert in tools and methods for accessing, analyzing, and reporting OSINT data.', 'Create and maintain optimal data pipeline architecture.', 'Apply semantic data modeling techniques to classify, aggregate, and generalize data stored in hierarchical, network, or relational database management systems to define the meaning of data within the context of its interrelationships with other data;', 'Design physical database management systems to represent semantic data models, including relational and objective-relational Databases (e.g. Postgress, SQL Server, MySQL), Key value stores, Inverted Indexes (Lucene, Elastic Search), and distributed file systems (e.g. Tachyon, HDFS);', 'Work with stakeholders and other teams to assist with data-related technical issues and support data infrastructure needs.', 'Integrate software code and scripts for the automation of repeatable extract, transform, and load', 'Work with data and analytics experts to strive for greater functionality in data systems.', 'Participating in special projects and performs other duties as assigned.', 'US DoD Top Secret Security Clearance with SCI eligibility', ""At least five years of experience and a Bachelor's degree in Computer Science or a related technical field, or equivalent combination of education and experience."", 'Fully proficient data engineering abilities, typically gained through five years of working with Python/Java, SQL, working schema design, and dimensional data modeling.', 'DOD Counterintelligence Polygraph', 'Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Working knowledge of Python or Java.', 'Knowledge of building and optimizing data pipelines, architectures and data sets.', 'Ability to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable data stores.', 'Strong project management and organizational skills.', 'Ability to support and work with cross-functional teams in a dynamic environment.']",2020-12-30 22:51:09
Analytics Data Engineer (Remote) - Operations,Progressive Leasing,3.6 out of 5 from 184 employee ratings,"Draper, UT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work in a self-directed but not isolated manner, proactively collaborating with the Operations Analyst team to drive business value', 'Ensure data pipelines to operations analysis environments are stable, controlled, and accurate', 'Quickly deliver new application data to the data warehouse for data analysts', 'Understand data flow from application to data warehouse so you can guarantee data delivery at the requisite velocity for near-real time dashboards', 'Collaborate with the operations analysts to source and make available data that drives business value', 'Actively work on migrating from SQL Server to the new cloud data storage platform (combination of Databricks’ DeltaLake & Snowflake on Azure', 'Support legacy SQL Server stored procedures while migrating to a combination of Python, Airflow, DBT, Spark, and Snowflake code', 'Bachelor’s degree in a technical field (Engineering, Computer Science, Information Systems, etc.)', '2+ years of professional experience in data & analytics or software engineering', '1+ years moving data into a data lake & transforming it for downstream analysis', 'Ability to understand and explain multiple data storage technologies at a high level', 'Knowledge of tuning and performance optimization techniques in 1 technology (Hadoop, SQL Server, Cosmos DB, Snowflake, Azure Data Lake Gen2, etc.)', 'Solid knowledge of SQL and some experience in 1 other programming language (Python, R, Java, C#, PowerShell, Bash, etc.)', 'Experience writing data pipelines and ETL code, ideally on a major cloud provider (GCP, AWS, Azure, etc.)', 'Competitive Compensation + Eligible for STI', 'Full Health Benefits; Medical/Dental/Vision/Life Insurance + Paid Parental Leave', 'Company Matched 401k', 'Paid Time Off + Paid Holidays + Paid Volunteer Hours', 'Diversity Alliance Resource Groups', 'Employee Stock Purchase Program', 'Tuition Reimbursement', 'Charitable Gift Matching', 'Job required equipment and services']",2020-12-30 22:51:09
Data Engineer,TapRecruit,N/A,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build scalable data pipelines that integrate multiple data sources (both internal and external APIs).', 'Generate fault-resistant data extraction and transformation processes with monitoring.', 'Prototyping data products and productionalizing data models', 'Improve engineering standards by developing internal tools that will be used by the data and engineering teams', 'Write code that is maintainable and includes relevant tests. Maintain and advocate for these standards through code review within the data and engineering teams.', '4+ years of experience building large-scale software applications with Python', 'Expert-level understanding of SQL and common relational database systems', 'Excellent debugging and data flow optimization skills', 'Experience querying and setting up NoSQL databases (ElasticSearch, MongoDB)', 'Familiarity with containerized development workflows', 'Desirable: Experience deploying data pipelines through AWS', 'Comprehensive healthcare plans', 'Flexible PTO policy', '401k retirement plan', 'Commuter benefits', 'Remote-friendly team and open to more flexible work arrangements']",2020-12-30 22:51:09
Data Engineer - Healthcare,Nuna,N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Map, extract, transform and load data from source to target through multiple stages', 'Perform data quality assessment, measurement, and reporting', ""Collaborate with product managers, data scientists, data analysts and engineers to define user requirements and database design specifications for our clients' needs."", 'Analyze data feed requirements received from vendors, translate business requirements into technical design specifications.', 'Use your knowledge of SQL to perform data analysis based on business requirements and data profiling reports.', 'Maintain and ensure monthly data updates are delivered on-time to our customers', 'Serve as a technical resource in resolving client issues related to database or other data issues', 'Work closely with client-facing teams', 'Work directly with clients and lead client calls when needed', 'Construction and automation of data pipelines', 'Experience working with data, preferably healthcare data, and databases.', 'Ability to use SQL or other query and scripting languages to aggregate, gather and manipulate data.', 'Experience with data quality processes, data quality checks, validations, data quality metrics definition and measurement.', 'Ability to construct and debug complex SQL queries.', 'Ability to operate with cross-functional teams (e.g., implementation managers, data science, engineers, etc.).', 'Strong communication and teamwork skills.', 'Data manipulation skills using text processing utilities, Python, Scala, and/or Java.', 'Healthcare experience is strongly preferred.', 'BA/BS in statistics, math, data science, or computer science preferred.', 'Demonstrated track record working with data warehouse and ETL architectures and concepts plus.']",2020-12-30 22:51:09
Data Migration Engineer,"Rhythm Software, Inc.",N/A,"Atlanta, GA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Running scripts on the CloverDX ETL package to migrate data from Excel/CSV/SQL/Oracle database into JSON for import by our platform', 'Novice to moderate knowledge of SQL, T-SQL and table structures - Writing needed statements, with some guidance on structure and best practices.', 'Building needed scripts to perform conversions with some help and post launch cases.', 'Table location and column placement (with some guidance).', 'Working closely with our Implementation team and communicating risks and/or roadblocks regarding assigned projects appropriately.', 'Building reports for customers as necessary to surface data', 'Minimum 1 year of professional experience involving:', ""Bachelor's degree or 2 years of professional SQL/ETL experience."", 'Demonstrated high level of aptitude for attention to detail and ability to prioritize a multitude of tasks.', 'Strong analytical/problem-solving skills', 'Consistent professional demeanor and the ability to make positive contributions to the team', 'Demonstrate understanding of the conversion process by providing feedback and suggestions on process improvement.', 'Willingness to find answers to problems and demonstrated ability to build script solutions.', 'Work with other teams (Project Managers, Training, Data Conversion, Solutions Analysts) to learn their processes and understand their roles in the implementation process', 'Professional Development efforts are used toward career growth (Certification classes, database development classes, programming classes)', '80% reimbursement of COBRA from the previous employer', 'Medical: Aetna + Kaiser Permanente (16 different options) - 80% reimbursement', 'Dental: Aetna, MetLife, Guardian + Delta Dental (9 different options) - 80% reimbursement', 'Vision: Aetna + VSP (4 options) - 80% reimbursement', 'Life: Metlife (7 options)', 'Short & Long Term Disability', '401K/IRA']",2020-12-30 22:51:09
Assistant Chief Engineer,Innovative Solutions and Support,2.6 out of 5 from 18 employee ratings,"Exton, PA 19341","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Undertakes special Engineering projects at the direction of the CEO, President or Vice President Product Development.', 'Provides technical direction regarding all projects within the engineering department. Offers technical, product and procedural guidance to engineering staff.', 'Among those responsible to provide technological direction to the staff and company.', 'Bears shared responsibility for the overall health of the Company based on designs that meet customer expectations, manufacturing capabilities and which comply with pertinent governing agencies.', 'Coordinates efforts with the VP of Product Development to best advance Company goals.', 'Engaged in mechanical, electrical and software related aspects on all engineering projects.', 'Assists in developing product and system specifications', 'Involved with the candidate selection process for engineering professionals.', 'Is aware of the status of engineering projects, can make reports as directed or undertake investigations to determine progress.', 'Assists the VP of Product Development and fills in, as necessary.', 'Responsible for overseeing all engineering design activities.', 'MS degree in Electrical Engineering or equivalent.', 'Fifteen (15) years of experience designing avionics.', 'Direct knowledge of Electrical Design as well as Software Engineering.', 'Experience with ISO 9000.', 'Verified understanding of aircraft interfaces.', 'Pilot license is a plus', 'Must be able to see and manipulate small parts.', 'Must be able to sit, stand, walk, bend, or stretch in keeping with the demands of a typical office role.', 'Must be able to lift and carry components up to 30 lbs.', 'Must be able to speak clearly and convey technical data with colleagues.', 'Must be able to operate computer equipment for both design and programming.']",2020-12-30 22:51:09
Software or Machine Learning Engineer - Entry Level,Apple,"4.2 out of 5 from 9,978 employee ratings","Santa Clara Valley, CA 95014","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Software Roles:', 'Proficiency with C/C++/Java', 'Familiarity with Objective-C/Cocoa', 'Experience with UNIX and/or OS X preferred', 'Strong analytical and problem solving skills', 'Excellent written and verbal communication skills', 'Machine Learning Roles:', 'Experience in machine learning, deep learning, search, natural language processing, data science, or computer vision', 'Experience in one of the following languages: Python, Java, C++', 'Strong analytical and problem solving skills', 'Strong background in algorithms and data structures']",2020-12-30 22:51:09
Data Engineer,SIMON Markets,N/A,"New York, NY 10001","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Leverage open-source technologies and cloud solutions to build elegant features that SIMON platform users love', 'Develop and automate large scale, high-performance data platform infrastructure to drive SIMON business growth and enable data-driven organization', 'Design and develop reusable components and frameworks for ingestion, cleansing, and data quality', 'Streamline the ingestion of raw data from various sources into our Data Lake and Data Warehouse', 'Design data models for optimal storage and retrieval that represent the product entities and meet business requirements', 'Coordinate closely with sales and product development teams daily to push SIMON’s FinTech strategy and improve the overall profitability of our', 'Bachelor’s Degree in Computer Science, Data Science, Mathematics, Statistics or other quantitative area or related field', '1–4 years of experience with open-source technologies or object-oriented/functional programming, strong ability to write easy-to-scale, high-quality code', 'Experienced in at least 1 numeric research framework (python/pandas, R/Splus, Octave/Matlab)', 'Familiarity with OLAP (Redshift, Snowflake) and OLTP (PostgreSQL, MongoDB) databases.', 'Familiarity with various database designs (Relational, Columnar, NoSQL)', 'Some background in probability/statistics', 'Detail-oriented, ability to multitask and work in a fast-paced environment', 'Ability to work independently while also being a strong team player', 'Excellent written and verbal communication', 'Passionate about programming and cutting-edge technologies', 'Master’s or Ph.D. Degree in Computer Science, Data Science or related field', 'Professional experience with Python and JVM based languages such as Scala, Java, and Kotlin', 'Experience building data-pipelines, data-lakes and data warehouses.', 'Good knowledge of financial markets and financial instruments', 'Experience with AWS solutions such as Lambda, S3, Kinesis, ElastiCache', 'Familiarity with AWS and infrastructure-as-code (terraform or cloud formation)', 'Full-time or internship experience as a data engineer in the financial technology industry is a plus']",2020-12-30 22:51:09
Data Engineer,Government Tactical Solutions,N/A,"Washington, DC 20006","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""APIs: 1 year (Required)Java Coding: 2 years (Required)Data analytics: 1 year (Required)Criminal background check (Required)Top Secret (Required)High school or equivalent (Preferred)Web services: 1 year (Preferred)Linux based operating system's: 1 year (Preferred)XML and JSON: 1 year (Preferred)Configuration management: 1 year (Preferred)CompTIA Security+ (Preferred)"", 'Provide technical delivery for assigned engagements and drive customer satisfaction.', 'Ensure the technical success of professional services engagements by engaging peers, leading design discussions, troubleshooting, and delivering as needed.', 'Articulate the overall services solution and subsequent service delivery plan to implement the solution to the customer in terms the customer understands.', 'Build relationships and trust with Engagement Managers, Project Managers, Solutions', 'Work with the project manager to provide regular communication to all stakeholders about the status of professional services engagements.', 'Listen to customer needs and map customer challenges to GSS services and solutions.', 'Exceed our customer expectations for services delivery quality, competence, and professionalism.', 'Develop and test Java software plugins and integration modules for HCP family of products', 'Develop and test components using TCP/IP, RSS, SMTP, ODBC/SQL, HTTP/REST, XML, JSON', 'Assist the technical support team in the isolation and resolution of customer issues', 'Author developer documentation and participate in the development of end-user documentation', 'Mentor and advise junior team members', 'Communicate effectively with technical and non-technical members of the project team', 'Support consultants, partners, and the open source community', 'Must possess a TS/SCI clearance or currently have a TS with the ability to upgrade  * Demonstrate knowledge of three or more of the following: o Java development for API based solutions o Enterprise object storage solutions (e.g., S3, HCP, Centera) o Object storage data migrations o Data Analytics solution development o GUI development and programming o Scripting for operational needs', 'Minimum 1 to 3 years professional experience in troubleshooting, maintaining, and developing data-driven applications for enterprise environments', 'Hands-on experience with one or more of the following core technologies: o Experience writing, extending and maintaining Java programs o', 'Must be able to quickly understand technical and business requirements and be able to translate into technical implementation', 'Experience with Pentaho and/or Hitachi Content Intelligence a strong plus', 'Experience with APIs for SharePoint, MS Exchange or MS Work Folder Server', 'Create internal and customer facing documentation using Microsoft Office product suite.', 'Demonstrate excellent verbal and written communications skills', 'Demonstrate excellent customer/business presentation skills', 'Willingness to work a flexible schedule and travel 15-30%', 'Security+ Certification (must be completed prior to start)', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'Washington, DC 20502 (Required)', 'High school or equivalent (Preferred)', 'Web services: 1 year (Preferred)', ""Linux based operating system's: 1 year (Preferred)"", 'XML and JSON: 1 year (Preferred)', 'Configuration management: 1 year (Preferred)', 'APIs: 1 year (Required)', 'Java Coding: 2 years (Required)', 'Data analytics: 1 year (Required)', 'CompTIA Security+ (Preferred)', 'Top Secret (Required)', '25% (Required)', 'Likely', 'Yes', 'A job for which military experienced candidates are encouraged to apply', 'www.Govtact.com', 'YES_OCCASIONALLY']",2020-12-30 22:51:09
Data Engineer,Toast,3.3 out of 5 from 64 employee ratings,"Boston, MA 02215","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Extract data from various sources (Salesforce, NetSuite, Workday, Toast backend, etc.) and load into our data lake (Amazon s3) and ultimately our data warehouse (Snowflake)', 'Synthesize business requests from stakeholders and translate key points into a workable technical solution', ""Enable data self-service across the organization, for which we currently use Looker (you'll be writing LookML) and a Snowflake data warehouse (you'll be writing SQL and Python, and using Apache Airflow for orchestration)"", 'Partner with stakeholders and business leaders to provide strategic support and recommendations for how data can best serve various Toast departments, including Sales, Marketing, Support, Finance, Product, Services, and Executives', ""Bachelor's degree in Computer Science, Information Systems, or a related field (or proven experience in these areas)"", '2+ years professional experience in BI, Data Analytics, and/or similar role', 'Proficient SQL skills', 'Familiarity with orchestration tools and version control tools', 'Ability to disambiguate stakeholder needs in order to provide data necessary to hit business goals', 'Communication skills that enable relating complex technical problems or solutions to non-technical folks and vice versa', 'Relevant work experience in a high-growth tech or SaaS company', 'Experience using Snowflake, Airflow, Agile, EC2, and Docker', 'Familiarity with backend data from common cloud vendors such as Salesforce, NetSuite, Workday, Greenhouse, etc.', 'Bread puns encouraged but not required']",2020-12-30 22:51:09
Data Engineer,CAPITAL CENTER LLC,N/A,"Richmond, VA 23060","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate across the organization to support mission-critical business processes with data', 'Maintain and develop existing data infrastructure including overall design, ETL, and systems', 'Design and construct ETLs that communicate with APIs and internal systems', 'Over time, assume responsibility for furthering machine learning within the firm', 'Bachelor’s Degree', 'At least 1 year of API development experience', 'At least 1 year of ETL development experience', 'At least 1 year of SQL database experience', 'Organized, entrepreneurial, ambitious, and attentive to detail', 'Master’s Degree', 'At least 1 year of cloud service experience', 'At least 1 year of application development (Node, .NET, etc.) experience', 'At least 1 year of scripting language (Python, R, Perl, JavaScript, Shell, etc.) experience', 'At least 1 year of big data technology (Spark, Hadoop, Snowflake, etc.) experience', 'At least 1 year of NoSQL experience', 'At least 1 year of Agile engineering practices experience', 'At least 1 year of machine learning/predictive analytics experience', 'A competitive salary & annual bonus', '401k w/ match, health, dental & vision benefits', 'Exposure to the mortgage, real estate and insurance industries, front to back', 'To participate in cross-functional collaboration and leadership', 'The opportunity to lead transformative projects for an innovative and disruptive business']",2020-12-30 22:51:09
Data Scientist/Data Engineer/Data Analyst,PNC,"3.6 out of 5 from 6,532 employee ratings","Pittsburgh, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Days: M-F', 'Hours per week: 40', 'Flexible hours: start and end time', 'OT: n/a', 'Weekends/Travel: weekend or night deployments', 'Remote']",2020-12-30 22:51:09
Data Engineer,Everlywell,2.5 out of 5 from 2 employee ratings,"Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Be an essential part of designing and building our new data architecture and platform', 'Build and maintain ETL pipelines that are reliable and scalable', 'Explore and evaluate new technologies and make recommendations where necessary', 'Develop, test and maintain existing architecture', 'Identify gaps and monitor in current data processes and drive improvements', 'Recommend ways to improve data reliability, efficiency and quality of the data platform and optimize for performance, scalability and cost', 'Work with ELT tools to sync data to/from 3rd party services', 'Collaborate with the Data Analytics team to build the correct datasets for further consumption by various visualization tools', 'Design data models that support business needs', 'Programming experience and a demonstrated interest in statistical analysis and business intelligence', '5+ years experience with SQL, Data Warehouse development and ETL', 'Hands-on experience with at least one cloud-based data warehouse (e.g. Snowflake, Redshift, etc.)', 'Expert-level scripting skills using Python, Shell or similar', 'Expertise in PySpark and Pandas', 'Experience with standard warehousing concepts like Data Marts and Dimensional Modeling', 'Excellent communication skills, both verbal and written', 'Experience with at least one data modeling tool', 'Strong problem-solving abilities and critical thinking', 'Hands-on experience managing and performance-tuning PostgreSQL', 'Experience with ETL tools like Stitch, Fivetran, Pentaho, etc.', 'Experience with data warehouse schema design and architecture', 'Experience with Big Data solutions such as Snowflake or Redshift', 'Experience managing RDS, a definite plus', 'Experience with Data Science Notebooks', 'Experience with NoSQL databases', 'Venture backed by top-tier firms', 'The opportunity ahead knows no bounds', 'Open vacation policy', 'Employee discounts', 'Paid parental leave', 'Health benefits', '401(k)']",2020-12-30 22:51:09
Data Engineer-ETL,"Trusted Concepts, Inc",N/A,"Herndon, VA 20170","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Bachelor’s Degree in Computer Science, Electrical or Computer Engineering or a related technical discipline, or the equivalent combination of education, technical training, or work/military experience', '8+ years of related software engineering and ETL experience.', 'Excellent organizational, coordination, interpersonal and team building skills.', 'Experience with the following languages: Java/J2EE, SQL, XML, XQuery, XPath, HTML/XHTML, CSS, Python, Shell Scripting, JSON', 'Experience building and maintaining data flows in NiFi or Pentaho', 'Knowledge of servers operating systems: Linux, windows', 'Strong problem solving skills', 'Focus on continual process improvement with a proactive approach to problem solving', 'Ability to follow directions and finish task', 'Provide support in the areas of data extraction, transformation and load (ETL), data mapping, data extraction, analytical support, operational support, database support, and maintenance support of data and associated systems', 'Troubleshoots complex problems and provides customer support for the ETL process', 'Develop complex data flows, or makes significant enhancements to existing pipelines.', 'Conducts investigations and tests of considerable complexity.', 'Researches emerging technologies to determine impact on application execution.', 'Provides input to staff involved in writing and updating technical documentation.', 'Prepares reports on analyses, findings, and project progress.', 'Provides guidance and work leadership to less-experienced software engineers.', 'May serve as a technical team or task leader.']",2020-12-30 22:51:09
Senior Data Integration Engineer and Developer,Inova Health System,"3.7 out of 5 from 1,410 employee ratings","Falls Church, VA 22042","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', ""Bachelor's (Required)REDCap system administration and project development: 3 years (Required)US work authorization (Required)working on cloud infrastructure i.e. AWS: 3 years (Preferred)as a Systems Analyst or equivalent: 5 years (Preferred)"", 'Serve as the primary system administrator for the Research Electronic Data Capture (REDCap) platform.', 'Assist with the development of the structure and datasets for a large-scale data warehouse supporting Inova’s growing research efforts.', 'Serve as the internal business intelligence reporting subject matter expert in requirements gathering, rapid prototyping and development of proofs of concept and production dashboards.', 'Build and deploy software architecture to support program initiatives and improve access to data and it’s fidelity.', 'Lead ad hoc data cleansing, data analysis and research to answer internal and external inquiries.', 'Develop to and maintain technical documentation for each solution. Including data dictionary, data flow diagrams, etc.', 'Gather requirements and propose, research, and develop advanced analytics solutions that will expand the technical capabilities and data of Inova assets.', 'Identify and propose solutions for improving redundancies in skills and procedures that insure smooth business performance and good data stewardship.', 'Other duties as requested by Office of Research at Inova staff/management.', '3 years as a systems analyst or equivalent experience', 'College Degree', 'Experience in more than two of the following: Relational Databases (SQL), Python, ETL pipelines, data profiling and reporting using enterprise grade tools.', 'Experience with code control, code deployment and documentation best practices.', 'Experience working on a small team with direct input from the end users', 'Demonstrated ability to manage disparate data from various source to deliver a user focused and scalable solutions', 'Ability to manage multiple small projects and deliver results as part of a self organizing team', 'An understanding of and preference for working in an agile framework using Safee principles.', 'Strong proficiency in Microsoft Office suite', 'Excellent written and verbal communication skills', 'Demonstrated data analysis and visualizations in Tableau', 'Experience with REDCap system administration and project development', 'Experience working on cloud infrastructure i.e. AWS', 'Experience using Microsoft SQL server tools (Management Studio, SSIS, etc.)', 'Degree in Information Systems', '5+ years as a Systems Analyst or equivalent experience', 'Experience in a research setting a plus', 'Experience designing data dictionaries, relationship diagrams and relative technical documentation', 'Experience using Atlassian suite (Jira and Confluence)', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Referral program', 'Retirement plan', 'Vision insurance', '8 hour shift', 'Falls Church, VA (Preferred)', ""Bachelor's (Required)"", 'REDCap system administration and project development: 3 years (Required)', 'working on cloud infrastructure i.e. AWS: 3 years (Preferred)', 'as a Systems Analyst or equivalent: 5 years (Preferred)', 'designing data dictionaries,: 3 years (Preferred)', 'One location', 'No: Not providing sponsorship for this job', 'A job for which military experienced candidates are encouraged to apply', 'www.inova.org', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-12-30 22:51:09
Systems Engineer,LOCKHEED MARTIN CORPORATION,"4 out of 5 from 8,473 employee ratings","King of Prussia, PA 19406","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Installation of components and', 'Perform, conduct, and document', 'Update maintenance data collection', 'Apply technical knowledge to solve', 'Complete/assist with installations, testing,', 'Isolate and report malfunctions and', 'Document and maintain system cabling', 'Preventative Maintenance Checks', 'Corrective Maintenance Actions, HW/SW', 'Transportation and Shipping/Receiving of', 'Inventory/Warehouse management', 'Various material and license tracking', 'Coordination with varying LM and', 'Tech Manual creation / maintenance', 'Training Program & material creation /', 'Configuration Management of SW,', 'Facilities and Infrastructure footprint', 'Reliability, Maintainability, and Availability', 'Sparing modeling and coordination', 'Bachelors degree from an accredited', 'Experience with Technical Writing', 'Experience with Technical Drawing', 'Basic analysis / trade study experience', 'Demonstrated ability to work multiple', 'Experience working in classified/accesscontrolled facilities', 'Ability to read and use technical', 'Ability to brief/teach technical information', 'Experience with Linux and/or C++', 'Agile Experience', 'Experience with JIRA', 'Fluent in Microsoft Office']",2020-12-30 22:52:50
Data Engineer,Memorial Healthcare,3.4 out of 5 from 85 employee ratings,"Owosso, MI 48867","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Expert in data gathering and analysis through strong database knowledge.', 'Database administration knowledge, including design, optimization and performance is preferred.', 'Evaluates manual and automated work processes, systems, and procedures to determine areas for improvement.', 'Analyzes, implements and maintains computer applications, procedures and other systems that satisfy the needs of the end-user departments.', 'Analyzes and develops necessary design work, including testing, documentation and training.', 'Reviews, evaluates and implements requests from user departments.', 'Strong problem solving skills, including the ability to analyze problems, determine cause and initiate corrective action.', 'Maintains a high level of interaction with all clinical areas to continually enhance/improve patient are and the end-user experience.', 'Shares on-call duties with other individuals within Information Services.', 'Coordinates and participates in both internal and external user group functions.', 'Demonstrates an independent work initiative, sound judgement, diplomacy, tact and professional demeanor.', 'Demonstrates knowledge of and supports hospital mission, vision, value statements, standards, policies and procedures, operating instructions, confidentiality statements, corporate compliance plan, customer service standards, and the code of ethical behavior.', 'Has a working knowledge of all software modules of the HIS.', 'Stays current with technology through seminars, educational opportunities, and trade magazines.', 'Other duties as assigned.', 'Bachelor’s Degree in Business Administration, Computer Science, Healthcare or related field.', 'Experience with computer information systems and software applications preferred', 'Work experience with developing reports required.', 'Experience with SQL database required.', 'Experience with interfaces preferred.', 'Experience with HL7 preferred.', 'Database administration knowledge preferred.', 'Experience in inter- and intra-departmental communications required. Highly effective and proven customer service skills required.', 'Scripting/Programming experience preferred.', 'Healthcare experience preferred.', 'Sedentary Work: Frequently required to stand, kneel and crouch. On a daily basis may be required to move about, sit, climb stairs and bend. Is frequently required to lift and carry up to 20 lbs. May be required to push/pull/carry items between 20-100 lbs.', 'Vision: Requires the ability to perceive the nature of objects by the eye. Near acuity: Clarity of vision at 20 inches or less. Midrange Acuity: Clarity of vision at distances of more than 20 inches and less than 20 feet.', 'Motor Coordination: While performing the duties of the job, it is required to regularly perform functions that include using hand and finger movement, handle or feel objects, be able to use tools or equipment that requires reaching with hands and arms. Must be able to travel independently throughout the hospital; access patients/families including areas confined by space and/or equipment.', 'Speaking/Hearing: Ability to give and receive information through speaking and listening.', 'Proficiency using modern office, computer and telephone equipment as used by Memorial Healthcare.', ""Basic computer skills are required including keyboarding, MS Windows and/or PC's, thin clients, printers, and understanding of general technical concepts used in Healthcare Information Management."", 'Basic understanding of Client / Server computing, Remote Access, Server and Application monitoring.', 'Good understanding of project management; including project planning, budget, implementation and tracking.', 'Ability to adapt and maintain focus in fast paced, quickly changing or stressful situations.', 'Ability to read and interpret a variety of documents including, but not limited to policies, operating instructions, white papers, regulations, rules and laws.', 'Able to see for the purpose of reading information received in formats including but not limited to paper, computer, tablets, reports, bulletins, updates, manuals.', 'Able to see and hear for work-related purposes.', 'Must be able to lift printers, terminals, and other hardware not to exceed 25 pounds.', 'Ability to interact with co-workers, hospital staff, administration, patients, physicians, the public and all internal and external customers in a professional and effective, courteous and tactful manner, at all times, physically, verbally and in all written and electronic communication.', 'Required to remain calm when adversity is encountered.', 'Open, honest, and tactful communication skills.', 'Ability to work as a team member in all activities.', 'Positive, cooperative and motivated attitude.']",2020-12-30 22:52:50
Data Scientist / Engineer,AWM SMART SHELF,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Identifies business trends and problems through complex big data analysis.', 'Interprets results from our proprietary data capture engine using variety of techniques, ranging from simple data aggregation via statistical analysis to data-mining independently.', 'Designs and develops sophisticated charts and methods to visually demonstrate data results for AWM’s Sales Team and customers.', 'Designs, develops and implements the most valuable business solutions for the organization.', 'Prepares big data, implements data models and develops database solutions to support the business offerings.', 'Is experienced with, and knowledgeable in, industry-standard software and tools such as reporting services and business intelligence software.', ""Requires bachelor's degree in a related field. master's degree or higher (PhD) is preferred"", 'Requires 3-5+ years of related experience.', 'Computer science degree is strongly preferred, though experience and/or other degrees may be substituted - MOOCs will be evaluated on a case-by-case basis', 'Strong computer vision skills, including non-trivial on-the-job experience', 'Machine learning is a requirement', 'Experience with surveillance analytics is a plus', 'Hardware optimization is a plus', 'Camera knowledge is a plus', 'Video Analytics', 'Object and person recognition experience are requirements', 'Able to work well on a development team and produce good code according to company’s standards', 'Experience working with other developers using Git/GitHub or another relatively similar version control system', 'Works well in a fast-paced environment learning new things', 'Likes to be challenged on engaging work vs. zoning out and simply collecting a paycheck', 'Takes initiative', 'Responsible', 'Smart and quick learner', 'Good team player and willing to take direction from others', 'Willing and able to collaborate with other developers', 'Disciplined (the culture is fun but not a goof off mentality as there is important work to get done)', 'Employee stock option plan participation', 'Paid vacation and sick time provided', 'Health benefits', 'Opportunity for growth']",2020-12-30 22:52:50
Data Engineer - National,"PONDURANCE, LLC",N/A,"Indianapolis, IN 46280","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Systems programming experience and concurrent programming, Rust preferred', 'Experience with API design and maintenance, REST or similar.', 'Familiarity with the OSI model, TCP/IP, UDP networking, and popular communication protocols such as FTP, HTTP, RDP, and SSH.', 'Strong data modeling skills', 'Scripting languages and data science experience, Python, Ruby, etc.', 'Familiarity with message queues, Kafka', 'Comfortable with Git/version control workflows.', 'Familiarity with Continuous Integration (CI), Github Actions, etc.', 'Highly organized, able to multitask, the ability to work individually, within a team, and with other groups.', 'Degree or pursuing Degree in Computer Science, Engineering, or a related technical discipline and/or equivalent experience', 'Prior development experience required', 'Strong technical and analytical skills', 'Data science and machine learning experience', 'Database programming, SQL, etc.', 'Domain-Specific Language design', 'Agile Development', 'Experience creating or contributing to open source projects.', 'Experience with statistical programming and graphing', 'GPU programming experience, CUDA, etc.']",2020-12-30 22:52:50
Data Engineer,Caserta,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:52:50
Data Engineer/Architect,HCI Group,N/A,Pennsylvania,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop, and test enhancements to Big Data ETL and Business Intelligence (BI) solutions both on premise and Cloud', 'Work with complex Data modeling and design patterns for BI/Analytics requirements.', 'Lead ETL design and development initiatives including data analysis, source-target mapping, data profiling, change data capture, ETL coding, QA testing, and performance tuning.', 'Support technical development in designing, testing and implementing database changes.', 'Partner with product owners to deliver high performing quality customer experiences that are engaging, purposeful and powerful in their simplicity', 'Participate in automation script code reviews and provide guidance on their compliance with automation best practices', 'Demonstrate skills using code repositories', 'Interact with the product delivery team and participate in product requirement/design reviews to provide input on completeness of functional requirements, product designs and schedules', 'Identify interdependencies, ambiguities or omissions and make suggestions to improve requirements and ensure usability/testability', 'Review software documentation to ensure technical accuracy, compliance or completeness with focus to mitigate risks', 'Learn rapidly and enthusiastically, focusing on understanding the application/product/area in detail', 'Perform other duties as assigned by Management.']",2020-12-30 22:52:50
Data Engineer,Talroo,3 out of 5 from 2 employee ratings,"Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyze and organize raw data', 'Build data systems and pipelines', 'Evaluate business needs and objectives', 'Interpret trends and patterns', 'Own ETL pipeline performance and cost optimizations', 'Conduct complex data analysis and report on results', 'Prepare data for prescriptive and predictive modeling', 'Build algorithms and prototypes', 'Combine raw information from different sources', 'Explore ways to enhance data quality and reliability', 'Identify opportunities for data acquisition', 'Develop analytical tools and programs', 'Collaborate with data scientists and architects on several projects', 'Previous experience as a data engineer or in a similar role', 'Technical expertise with data models, data mining, and segmentation techniques', 'Knowledge of programming languages (e.g., Java and Python)', 'Hands-on experience with SQL database design', 'Great numerical and analytical skills', ""Degree in Computer Science, IT, or similar field; a Master's is a plus"", 'Snowflake Platform', 'Databricks/Spark', 'AWS Data Tools', 'Data engineering certification (e.g., Amazon Web Services (AWS) Certified Data Analytics or Snowflake Snowpro Certification is a plus)', 'Very competitive compensation package', 'Company-paid gym membership', 'Comprehensive, company-paid health, vision, and dental insurance premiums for you and your dependents', '401(k) retirement plan with 3% employer contribution', 'Paid company holidays, vacation and sick time', 'Awesome company events']",2020-12-30 22:52:50
Data Scientist,Betterview,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Establish performance metrics and benchmarks that computer vision models must meet based on customer and internal requirements.', ""Conduct model validation studies of Betterview's computer vision models to determine suitability for release to production."", 'Use insights from model evaluation in collaboration with machine learning engineers to identify areas of improvement and target features for data collection, then work to collect that data and enrich it into a trainable state.', ""Design and maintain dashboarding and reporting of Betterview's data and models, replete with relevant and meaningful metrics (e.g., size of datasets, model performance)."", ""Create models using Betterview's and third-party data to derive insights about property risk."", ""Contribute to ideation, design and implementation of Betterview's suite of analytical products, including but not limited to its computer vision models (e.g., scoring algorithm)."", 'Serve as representative of the Data Science team as necessary in technical and non-technical discussions with colleagues and customers.', ""Evaluate data sources for accuracy and potential to augment Betterview's existing data catalog."", 'Identify issues with existing data, models and processes; propose and implement solutions to resolve issues.', 'Update tasks in Jira and keep good notes.', ""Minimum Master's in Engineering, Statistics, Data Science or related field with 2+ years of work experience, or Bachelor's with 4+ years of relevant work experience. PhD a plus but not required!"", 'Ability to translate abstract goals into targeted and technical problem statements, design and run data science experiments to test hypotheses, and synthesize findings to internal and external stakeholders.', 'Working style and attitude consistent with the scientific method, e.g., designing/running experiments that can test hypotheses to inform strategy; making decisions based on data and evidence.', ""Scripting: Python, Node, or some other language that can be used for scripting and pulling data from APIs and other data sources. We aren't looking for an enterprise application developer here, just someone who knows enough to get dirty."", ""SQL is fairly important here though more at an analyst's level. Writing stored procs and evaluating query plans is not a requirement here."", 'Solid technical and data science foundation.', 'Experience in model validation, data collection and/or working with geospatial data in the machine learning space.', ""A strong analyst's nose for data issues."", 'An excellent communicator that is able to explain deep statistical and mathematical concepts to business representatives effectively.', 'Strong initiative, accountability, and a self-starter.', 'Agility and comfort pivoting between various workstreams given shift in priorities.', 'Comfort making data-driven decisions with incomplete information.', 'Compensation commensurate with experience.', 'Generous Health benefits – medical, dental and vision.Offering Kaiser and Blue ShieldProviding PPO plans, PPO plans, and HDHP options.Betterview covers 50% of employee premium, 10% of dependentsFor dental and vision, Betterview covers 75% of the premium for employees', 'FSA and HSA', 'Retirement PlanBetterview matches 100% of employee contributions to the first 3% of pay, then 50% of employee contributions on the next 2% of pay.Paid holidays.', 'Charity contribution matches, up to $100.', 'Cell phone reimbursement', 'Commuter benefits', 'All employees receive 160 hours per year of paid time off, with accrual every pay period.', 'Typically work schedule is Monday-Friday (8:30am-5pm)']",2020-12-30 22:52:50
REMOTE JOB | Data Integration Engineer (HL7 & Clinical),iknowvate technologies,N/A,"Charlotte, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4+ years of Data Engineering an/or Integration experience', 'Operational experience in clinical health care information systems, specifically with HL7 data, including experience integrating large, complex, mission-critical systems.', 'Experience with object-oriented programming languages, specifically Java', 'In-depth understanding and practical knowledge of relational databases (MySQL)', 'Comfort working with UNIX/Linux systems specifically working at the command line.']",2020-12-30 22:52:50
"Data Engineer, Analytics","Take-Two Interactive Software, Inc.",4.1 out of 5 from 7 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop data quality framework to provide transparency into data quality across systems (timeliness, accuracy, completeness, etc.) and ensure delivery of high-quality data to business teams.', 'Provide thought leadership and collaborate with other team members to continue to scale our architecture to evolve for the needs of tomorrow.', 'Maintain API based ETL/ELT processes from multi source raw data collection to reporting/visualization.', 'Develop and support continuous integrations build and deployment processes using Jenkins, Docker, Git, etc.', 'Define and implement monitoring and alerting policies for data solutions.', '2+ years of hands-on experience in Python.', '3+ years of hands-on experience in using sophisticated SQL queries and writing/optimizing highly efficient SQL queries.', 'Experience integrating with 3rd party APIs.', 'Comfortable working with business customers to collect requirements and gain a deep understanding of varied business domains.', 'Experienced in testing and monitoring data for anomalies and rectifying them.', 'Knowledge of software coding practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.', 'Python (required)', 'SQL (required)', 'Git (required)', 'Developing solutions using Docker (required)', 'Data modeling for data warehousing (nice to have)', 'Developing microservices (nice to have)', 'Great Company Culture. Ranked as one of the most creative and innovative places to work, creativity, innovation, efficiency, diversity and philanthropy are among the core tenets of our organization and are integral drivers of our continued success.', 'Growth: As a global entertainment company, we pride ourselves on creating environments where employees are encouraged to be themselves, inquisitive, collaborative and to grow within and around the company.', 'Work Hard, Enjoy Life. Our employees bond, blow-off steam, and flex some creative muscles – through corporate boot camp classes, company parties, game release events, monthly socials, and team challenges.', 'Benefits. Medical (HSA & FSA), dental, vision, 401(k) with company match, employee stock purchase plan, commuter benefits, in-house wellness program, broad learning & development opportunities, a charitable giving platform and more!', 'Perks. Fitness allowance, employee discount programs, free games & events, stocked pantries and the ability to earn up to $500+ per year for taking care of yourself and more!']",2020-12-30 22:52:50
Data Engineer,"Amick Brown, LLC",5 out of 5 from 2 employee ratings,"Santa Clara, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and build data models to conform to our existing EDW architecture.', 'Strong understanding and prior experience with data related security concepts such as row level security and data masking.', 'Design and build data pipelines using tools - SAP SLT, SAP Data Services, Python and Microsoft SSIS.', 'Proficiency in Python to extract data from source systems and perform data transformations programmatically.', 'Design and development of data warehouse using T-SQL, SQL, and python', 'Work with teams to deliver effective, high-value reporting solutions by leveraging an established delivery methodology.', 'Implement data structures using best practices in data modeling, processes, and technologies.', 'Design and development of data warehouse using Microsoft SQL Server.', 'Writing analytics programs (transformations/calculations) in T-SQL,R, Python or comparable', 'Knowledge and understanding of Enterprise HR Applications like HCM.', 'Knowledge and functional understanding of HR Functional area and related business processes', 'Perform data mining and analysis to uncover trends and correlations to develop insights that can materially improve our decisions.', 'Development with one or more data visualization/reporting tools (Tableau, Business Objects, Hana Analytics, Microsoft PowerBI)', 'Work with various product owners to ensure applications are instrumented with proper tracking mechanisms to enable analytics.', 'Continually recommend, develop, and implement process improvements and tools to collect and analyze data, and visualize/present insights..', 'Bachelor’s degree in Business, MIS or related area. Master’s degree a plus.', '8+ years Business Intelligence / Data Warehouse development experience', '3+ years of experience in ETL development tools, preferably with knowledge of Microsoft Integration Services 2005 or greater (SSIS), SAP Data Services, SAP SLT and Python.', '5+ years of experience in design and development using Microsoft SQL Server.', 'Strong experience in full life cycle development, implementation, management and performance tuning of the Enterprise Data Warehouse', 'Experience in database development (T-SQL, PLSQL, and/or SQL scripts)', 'Experience in building data pipelines using python, C# and JSON', 'Experience in Microsoft BI development in Integration Services (SSIS), Analysis Services (SSAS) or Reporting Services (SSRS)', 'Experience building and managing data flows to and from cloud applications', 'Demonstrated experience in utilizing R, Python, SPSS or comparable to develop analyses', 'Experience visualizing data in business intelligence tools such as Tableau, Business Objects or Hana Analytics', 'Experience and functional understanding with Enterprise applications like SAP ECC and SAP CRM, Salesforce etc.', 'Strong experience with performance and scalability design and testing', 'Experience creating test plans, testing and resolving data discrepancies', 'Must be a self-motivated, energetic, detail-oriented team player passionate about producing high quality BI & Analytics deliverables', 'Strong sense of customer service for internal customers', 'Medical robotics has unique characteristics that will require immersion in clinical and technical training and he or she must come up to speed quickly– an interest and desire to learn are critical', 'Health', 'Vision', 'Dental', '401k with company match', 'Paid time off', 'Sick Leave', 'Short-Term Disability', 'Life Insurance', 'Wellness & Discount Programs', '8 hour shift']",2020-12-30 22:52:50
Data ETL Engineer,TTS Solutions Inc,N/A,"Boise, ID","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)"", '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)']",2020-12-30 22:52:50
Data Engineer,RISIRISA,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Ability to wrangle and process large data files into usable formats and databases', 'Experience designing algorithms to perform analysis and aggregation on data', 'Experience building and deploying production-level web services', 'Enthusiasm for learning new techniques and technologies to solve hard problems', 'Python', 'SQL', 'Java', 'Hadoop Ecosystem (Hive, Pig, etc.)', 'Web/API building', 'Familiarity with Javascript and NodeJS', 'Familiarity with Git for version control', 'PHP', 'Familiarity with production deployment and administration in Linux, Amazon AWS, Heroku, etc.', 'Django', 'NoSQL (Mongo, etc.)', 'PostGRES', 'Redis', 'C++', 'iOS/Android development']",2020-12-30 22:52:50
Data Engineer,Everytown for Gun Safety,2 out of 5 from 5 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Gather and spec requirements for a successful project;', 'Maintain existing systems, and deliver enhancements;', 'Perform peer code review and quality assurance as part of a team;', 'Build pipelines for automated transforms of data into data marts in order to support reporting, predictive analytics, and targeting.', ""Provide support and training for staff and volunteers on Everytown's suite of tools and best practices for using data effectively;"", 'Make recommendations and provide guidance on ways to make programs, campaigns, and data collection more efficient and effective;', 'Other responsibilities as assigned.', '2-3 Years in SQL;', '2-3 Years in software development languages, Python preferred.', 'Developing and maintaining pipelines to perform ETL;', 'Working with version control systems such as Git;', 'Experience using APIs to construct and maintain data synchronizations', ""Experience training people on a variety of activities, experienced/comfortable at conducting trainings (even if you didn't create them);"", 'Ability to manage several tasks or projects concurrently and prioritize work effectively;', 'Ability to communicate effectively, especially technical ideas to non-technical people, work well under pressure, be detail oriented and meet deadlines;', 'Strong attention to detail, including producing technical documentation.', 'Mapping visualization, D3, GIS applications or R Leaflet;', 'Familiarity with R, Javascript, or other scripting languages;', 'Experience with Civis Analytics Platform;', 'Ability to diagnose and improve database and query performance issues;', 'Digital Campaigning platforms data schemas;', 'Data Visualization & reporting of metrics using tools such as Tableau;', 'Knowledge of CRM & Donation Data Schemas']",2020-12-30 22:52:50
Software Engineer Internship,"WebFX, Inc.",4.8 out of 5 from 56 employee ratings,"Harrisburg, PA 17102","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Our web-based projects use a variety of frameworks selected on a per-project basis. Some of the more popular frameworks our team leverages in projects are WordPress, Magento, Bootstrap, Zend Framework 2, and Google Functions. Training will be provided on all of our core platforms, tools, and technologies.']",2020-12-30 22:52:50
"Frontend Software Engineer Intern, 2021 Summer U.S.",Atlassian,4.6 out of 5 from 16 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Be currently enrolled in a full-time degree program and returning to the program after the completion of the internship, graduating by June 2022', 'Have a solid understanding of JavaScript, HTML and CSS', 'Commit to a full-time internship (40hrs / week)', 'A real passion for frontend software engineering, as demonstrated by previous internships, work experience, projects, or publications', 'Familiarity with the application of common design patterns', 'The ability to write components in JavaScript in addition to being interested in leveraging existing libraries when it makes sense', 'Exposure to JavaScript frameworks (React, Angular, Vue, etc.)', 'A deep understanding of data structures, in particular how they are implemented and how to apply them to solve problems', 'Familiarity with REST or GraphQL APIs and JSON']",2020-12-30 22:54:32
Data & Quality Assurance Engineer,GovernmentCIO,3.3 out of 5 from 13 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Responsible for the design, creation, maintenance, and execution of Test suites/cases across the application', 'Building out testing capabilities between Jira and the ServiceNow Automated Test framework', 'Responsible for the maintenance and processing of data across multiple sources, ensuring data is understood and managed appropriately based on organizational and application standards', 'Responsible for the overall quality of the system as a whole, including its data, and ensuring development is held to a high standard of delivery', '5 years writing, executing, reviewing, analyzing, and supporting software testing during development in order to ensure quality', '3-5 years writing test automation scripts, SQL, keyword-driven and data-driven automation techniques, and web application white box testing', '5 years’ experience in an agile environment using Scrum and Kanban', '1-year direct, continuous work experience in ServiceNow and the Now Platform – App Dev Engine and/or Integration Hub', 'Must be able to design, discuss, and document system strategies for platform, applications, and networks', 'Experience designing, creating, and executing in-depth test plans, test suites and application wide regression testing', 'Experience writing both unit and end-to-end automated tests.', 'Proficient with Jira and GitHub', 'Bachelor’s Degree in Computer Science, Information Systems, Engineering, Mathematics, Science, and related fields. On a special case-by-case basis, five years of related work experience may be considered in lieu of a degree for otherwise highly qualified', 'Must be a U.S. Citizen.', 'ServiceNow Automated Test Framework (ATF)', 'ServiceNow development and the Now Platform including AppDev Engine, Integration Hub, Mobile Studio, and Automated Test Framework', 'Working knowledge of AWS, Infrastructure as Code, and DevSecOps', 'Working knowledge of containers and container management', 'Experience supporting public-facing web applications with a large userbase.', 'Hands-on with ITIL Process implementation', 'Experience supporting DHS mission space Desired Certifications', 'ServiceNow Automated Test Framework Fundamentals', 'ServiceNow System Administrator', 'ServiceNow Implementation Specialist', 'ServiceNow Application Developer']",2020-12-30 22:54:32
Data Engineer,BOEING,"4 out of 5 from 8,064 employee ratings","Crystal City, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Write code on a data extract, transform and load (ETL) platform to ingest and transform data to a suitable formats', 'Add features to ETL platform to shorten timelines for future data integration efforts', 'Develop, maintain code, and integrate software into a fully functional software system', 'Participate in daily scrum meetings, sprint retrospectives, and other agile processes', 'Work with external teams to validate data ingest', 'Provide and maintain documentation of system architecture, development and enhancements', ""Bachelor's Degree and 5 or more years' experience or master's degree with 3 or more years' experience from an accredited course of study in a technical field such as engineering, computer science, mathematics, physics or chemistry"", 'An Active TS/SCI clearance', '5+ years of software development experience', 'Demonstrated understanding of high scale cloud architecture', 'Linux/Unix experience', 'Object Oriented programming language skills', 'Possess strong verbal and written communication skills', 'Possess strong analytical skills, with excellent problem-solving abilities in the face of ambiguity', 'Expertise in data ingestion, data transformation (ETL) and data modeling', 'Experience with Java, Ruby or Python', 'Experience in Agile/SCRUM enterprise-scale software development', '3 years experience working with batch-processing and tools (e.g., Nifi, Midpoint, MapReduce, Yarn, Pig, Hive, HDFS, Oozie)', '1 year experience working with Restful web services', 'Experience with Code development, deployment, versioning and build tools (e.g., Eclipse, git, svn, maven, Jenkins)', 'Experience working with tools in stream-processing (e.g., Storm)', 'Experience developing applications that work with NoSQL stores (e.g., ElasticSearch, Hbase, Cassandra, MongoDB, CouchDB)', 'Working in cloud architecture with AWS EC2, RDS, S3, VPC, ElasticSearch', 'Experience working with moving data across different networks and security domains']",2020-12-30 22:54:32
Data Engineer,GEI Consultants Inc,4.3 out of 5 from 19 employee ratings,"Woburn, MA 01801","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'ETL of data from a wide variety of sources', 'Database and Data Warehouse design/expansion/backup & recovery', 'Index management and optimization', 'Support data sources for Tableau Server and ArcGIS', 'Stored procedure development and maintenance', 'Identify new opportunities within GEI where existing business approaches to data can be replaced with a more efficient/automated data flow and presentation of data for analysis', 'Develop and optimize ETL/SSIS packages to facilitate data transfer between FTP, remote data loggers, Azure, and on-premises databases', 'Troubleshoot SSIS package permission issues related to execute-as/data source read/write access', 'SQL Agent Job development and monitoring', 'Develop data reporting and visualizations as specified by clients using Tableau, SSRS, etc', 'Perform DML and DDL via tsql/stored procedures executed directly within SSMS and remotely via SSIS', 'Develop test plans, implementation plans, and project timelines for various data engineering projects', 'Define, prioritize, communicate, and foster shared understanding of project objectives and scope', 'Coordinate the development of standard operating procedures (SOPs), technical training programs, and QA/QC procedures for staff and work product', 'Team with all staff necessary to complete assignments', 'Collaborate with technical team members to ensure the solution design satisfies project objectives and business requirements', 'Other duties as assigned', '10+ years of experience in a position performing similar data engineering tasks', 'Proven record of ability to design, manage, and support MS SQL Server and Azure databases', 'Proven ability to write effective proposals for projects involving database design, data flow, and/or data management and visualization.', 'Ability to work with the following programming/mark-up/scripting languages preferred: VB.net, python, XML, javascript, and R', ""Bachelor's Degree, from an accredited college or university"", 'MS SQL Server/Azure certification preferred', 'Ability to plan and meet budget, develop project plans and meet deadlines', 'Self-starter with attention to detail and stakeholder needs', 'Able to critically analyze and solve problems of a complex nature', 'Excellent Communication skills', 'Able to work on multiple projects of moderate complexity simultaneously and independently', 'Proficient in organization and time management skills', 'Familiarity with engineering and/or environmental projects and data preferred.', 'Able to work effectively in GEI s partnership model, including a team environment, building rapport and relationships.']",2020-12-30 22:54:32
Data Engineer,BCC Software,3.4 out of 5 from 10 employee ratings,"Rochester, NY 14623","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop performant and scalable data structures to power processing, reporting and analytics areas of our SaaS customer offerings', 'Work closely with DBAs, architects, software engineers and IT on positioning our data management systems for both performance and scale', 'Develop software with all its related activities', 'Develop/review code as well as writing unit tests', 'Estimate/size stories', 'Test own work and the work of others', 'Document and collaborate on all assigned Sprint activities', 'Meet individual as well as your team’s commitments', 'Deliver results on a consistent basis in an Agile SCRUM environment', 'Mentor other team members on best practices of working with large data sets', '10+ years of experience in the fields of Database Development, Design & Architecture, Data Analytics and Warehousing', 'Highly technical expert-level knowledge with hands-on experience of working with MS SQL Server (or like) RDBMS', 'Experience with non-relational databases is a plus', 'Working knowledge and experience with Microsoft C#/.Net in a SaaS type environment', 'Proven track record of developing, maintaining, and scaling data structures/processes/platforms to power customer facing web applications and services with high degree of concurrency and large data sets', 'Actively practiced software engineering agile methodology of consistently delivering results', 'Experienced in BI-type solutions (Tableau preferred), understanding of its components as well as how to configure and tune them to achieve optimally performing customer facing visualizations and reports is a major plus']",2020-12-30 22:54:32
Data Engineer Mid Level,USAA,"3.9 out of 5 from 3,355 employee ratings","Phoenix, AZ 85085","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Identifies and manages existing and emerging risks that stem from business activities and the job role.', 'Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.', 'Follows written risk and compliance policies and procedures for business activities.', 'Design and implement technical solutions.', 'Identify and solve significant technical problems and architecture deficiencies.', 'Participate in daily standups and design reviews.', 'Breakdown business features and into technical stories and approaches.', 'Analyze data and enable machine learning.Create proof of concepts and prototypes.', 'Help on-board entry level engineers.', 'Collaborate with the team and other engineers to plan and execute assignments and tasks.', 'May begin mentoring junior engineers.', ""Bachelor's degree in related field of study,"", 'OR', 'Certification from an approved technical field of study,', 'OR', '4 additional years of related experience beyond the minimum required.', '4 years of data management experience implementing data solutions demonstrating depth of technical understanding within a specific discipline(s)/technology(s)', '4-6 Years Experience with Tableau Reporting OR Cognos BI OR Business Object', '4-6 Years Experience with SQL or Python', '4-6 Years Experience with IBM DataStage or Informatica', '4-6 Years Experience with Unix Shell Scripting', 'In-depth knowledge of Snowflake cloud architecture']",2020-12-30 22:54:32
Data Engineer,Trimble,3.7 out of 5 from 262 employee ratings,"Minnetonka, MN","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:54:32
Cloud Data Engineer,Resiliency LLC,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop and implement approaches, policies, and standards to ensure data quality and integrity is maintained and that any inaccurate data is uncovered and corrected', 'Develop and implement security standards for data storage and transport', 'Bachelor’s degree and 5 to 10 years of relevant work experience, ideally with highly relevant data administration experience', 'Cloud Data Engineering background strongly preferred including experience with web services (SOAP / REST)', 'Expert SQL skills', 'Strong working knowledge of Informatica, PowerBI, and Azure Data Factory and ETL – or comparable systems in each of these 3 categories', 'Experience with digital process automation and/or robotic process automation', 'Very strong data analytic capabilities including experience with data collection, manipulation, cleaning, analysis, ETL, and visualization. Strong data Modeling skills (conceptual, logical, physical)', 'Exceptional Excel skills including high level of expertise at pivot tables and various Excel functions used for data manipulation, cleaning, parsing, etc.', 'Must have strong ability to quickly master and become expert in new data solutions', 'Academic, extracurricular, and/or work record of tackling ambitious goals successfully', 'Excellent organization skills, time management and problem-solving skills; the ability to juggle many tasks at the same time; strong attention to detail', 'Strong communication and interpersonal skills over the phone, in person, and via video conference', 'Ability to assess needs related to the job function and create new processes, documents, structures, and systems accordingly', 'Experience working with multidisciplinary teams and diverse groups; Independent worker, self-starter', 'Intellectual curiosity, along with a competitive spirit and friendly, likable personality', 'Last but not least, a strong interest in impacting the future of behavioral health in the U.S.']",2020-12-30 22:54:32
Clinical Data Engineer,Dascena,3.7 out of 5 from 6 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and implement optimal and compliant data pipeline architecture', 'Assemble complex data sets that meet business requirements', 'Identify, design, and implement internal process improvements, including CI/CD for automated testing and deployment, and scalable data transformation and delivery processes', 'Build analytics tools that utilize the data pipeline to better support data science research projects and applications', 'Work with stakeholders including the Executive, Data, and Writing teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data and infrastructure secure and maintain compliance with the regulatory requirements', 'Bachelor’s degree in Computer Science, Data Science, or similar discipline', '2+ years of experience in building scalable data solutions', 'Advanced working knowledge of SQL and NoSQL databases, including Postgres and MongoDB', 'Experience building and optimizing scalable data pipelines and architectures', 'Working knowledge of message queuing, stream processing, scalable data stores, and distributed computing', 'Strong Python skills, and experience with the numeric libraries and distributed computing frameworks in the Python ecosystem', 'Experience with CI/CD pipelines and application deployment in the cloud', 'Excellent understanding of security principles, best practices, and compliance', 'Knowledge and experience with the healthcare industry is a plus', 'Experience with healthcare data and data formats (e.g. HL7) is a plus', 'Experience working with clinical data in a machine learning setting is a plus', 'Excellent communication skills', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Competitive compensation', 'Health benefits', 'Flexible hours and PTO', 'Remote work']",2020-12-30 22:54:32
AWS Data Engineer,Deloitte,"4 out of 5 from 9,921 employee ratings","Davenport, IA 52807","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Creating/managing AWS services.', 'Work with distributed systems as it pertains to data storage and computing.', 'Building and supporting real-time data pipelines', 'Design and build of data extraction, transformation, and loading processes by writing Step functions or custom data pipelines.', 'Must have significant experience with AWS data services', 'Strong database experience in Relational, Columnar, NOSQL & Timeseries databases.', 'Working experience on building and supporting real-time data pipelines using AWS Glue, Redshift/Spectrum, Kinesis, Firehose, Pyspark, EMR and Athena.', 'Knowledge and hands-on experience with AWS solutions including S3, SNS, SQS, DynamoDB, Redshift and AWS RDS.', 'Experience in the design and build of data extraction, transformation, and loading processes by writing Step functions or custom data pipelines.', 'Nice to have experience working on Hadoop, Data Bricks', 'Familiarity with log formats from various AWS services such as S3 server access , CloudFront distribution, Lambda execution, ELB, Container execution etc.', 'Experience on creating AWS Lambda functions using Python or R scripts.', 'Familiarity with AWS infrastructure related services such as: AWS VPC, EC2 Instances, Network policies and Cloud Watch.']",2020-12-30 22:54:32
Data Engineer,Chenega Corporation,3.7 out of 5 from 590 employee ratings,"Springfield, VA 22151","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL Server Integration Services (SSIS) including UI and custom code features.', 'Write or create stored procedures, SQL scripts, SSIS packages that can be used to:', 'Move data from source databases to target databases', 'Clean / Condition data', 'Convert or transform data', 'Reconcile and confirm converted data', 'Find data errors', 'Validate data to business rules', 'Ability to examine existing ETL scripts and track data back tosource', 'SQL Server administration, tuning, and workbench.', 'Work with business experts to understand data and completedata mappings.', 'Focus on the development of extract, transform, and load (ETL) jobs currently using Microsoft SQL, Server, and SSIS.', 'The environment currently supports hundreds of related ETL jobs that move data between 30 different source systems and between multiple classifications.', 'Part of the challenge as a data engineer will be to find scalable and efficient coding solutions that plug into this extensible system in order to add more data to the Enterprise data store.', 'Other duties as assigned', 'Bachelor’s Degree in Statistics, Mathematics, Computer Science or another quantitative field', 'Equivalent years of experience in lieu of degree', '4 years of relevant experience with the following software / tools:', 'Experience with Microsoft SQL', 'Prior experience supporting IC/DoD', 'The existing data warehouse is built on Microsoft SQL hosted on Amazon Web Services (AWS), so experience developing solutions that scale well in these environments is a plus.', 'Active Top-Secret Clearance with ability to obtain SCI', 'Ability to work independently and yet be effective within a team setting', 'Must be capable of managing multiple efforts with time related constraints in a fast-paced contracting environment', 'Demonstrated ability to effectively communicate and collaborate with diverse internal and external stakeholder groups and individuals', 'Friendly presence, helpful attitude, good interpersonal skills, and ability to work well with others.', 'Excellent skills in Microsoft Word, Excel, and other Office applications', 'Proficient with Microsoft Office Applications, and experience working in a home office setting as well as the ability to train end users on frequently asked technical issues.', 'Ability to provide technical assistance and support over the phone; good phone skills, professional demeanor, previous customer service experience strongly desired.', 'While performing the duties of this Job, the employee is regularly required to sit and talk or hear. The employee is frequently required to walk; use hands to finger, handle, or feel and reach with hands and arms. The employee is occasionally required to stand; climb or balance and stoop, kneel, crouch, or crawl. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include close vision.']",2020-12-30 22:54:32
Data Engineer,Planned Systems International,3.9 out of 5 from 40 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build and automate data pipelines.', 'Ability to work as a member of a team assigned to design and implement data collection, integration, and transformation solutions.', 'Learn quickly ability to understand and rapidly comprehend new areas functional and technical and apply detailed and critical thinking to customer solutions.', 'Propose design solutions and recommend best practices for large scale data analysis.', 'Meet the data needs of Data Scientists', 'B.S. or equivalent degree in computer science, mathematics or other relevant fields', '3-7 years of hands-on experience in ETL, Data warehouse, Data Marts, Visualization and/or building data pipelines, modeling and designing schema for data lakes or for data platforms', 'Strong programming and scripting skills experience and expertise in two or more of the following: Java, XML/XSLT, Python, Perl, Shell Scala, C', 'Proficient in big data/distributed computing frameworks such as Spring, Hadoop, Apache Hive, Spark, Kafka, etc.', 'Practice working with, processing, and managing large data sets (multi TB/PB scale)', 'Experience with Agile implementation methodologies', 'Must have TS/SCI CI POLY']",2020-12-30 22:54:32
Sr Big Data/Data Engineer,American Business Solutions Inc,N/A,"Columbus, OH 43215","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Big data: 8 years (Preferred)etl: 4 years (Preferred)', '6+ years of experience with Big Data, Hadoop on Data Warehousing or Data Integration projects.', 'Analysis, Design, development, support and Enhancements of ETL/ELT in data warehouse environment with Cloudera Bigdata Technologies (Hadoop, MapReduce, Sqoop, PySpark, Spark, HDFS, Hive, Impala, StreamSets, Kudu, Oozie, Hue, Kafka, Yarn, Python, Flume, Zookeeper, Sentry, Cloudera Navigator) along with Oracle SQL/PL-SQL, Unix commands and shell scripting;', 'Strong development experience in creating Sqoop scripts, PySpark programs, HDFS commands, HDFS file formats (Parquet, Avro, ORC etc.), StreamSets pipeline creation, jobs scheduling, hive/impala queries, Unix commands, scripting and shell scripting etc.', 'Writing Hadoop/Hive/Impala scripts for gathering stats on table post data loads.', 'Strong SQL experience (Oracle and Hadoop (Hive/Impala etc.)).', 'Writing complex SQL queries and performed tuning based on the Hadoop/Hive/Impala explain plan results.', 'Proven ability to write high quality code.', 'Experience building data sets and familiarity with PHI and PII data.', 'Expertise implementing complex ETL/ELT logic.', 'Develop and enforce strong reconciliation process.', 'Accountable for ETL/ELT design documentation.', 'Good knowledge of Big Data, Hadoop, Hive, Impala database, data security and dimensional model design.', 'Basic knowledge of UNIX/LINUX shell scripting.', 'Utilize ETL/ELT standards and practices towards establishing and following centralized metadata repository.', 'Good experience in working with Visio, Excel, PowerPoint, Word, etc.', 'Effective communication, presentation, & organizational skills.', 'Familiar with Project Management methodologies like Waterfall and Agile', 'Ability to establish priorities & follow through on projects, paying close attention to detail with minimal supervision.', 'Required Education: BS/BA degree or combination of education & experience', 'Demonstrate effective leadership, analytical and problem-solving skills', 'Required excellent written and oral communication skills with technical and business teams.', 'Ability to work independently, as well as part of a team', 'Stay abreast of current technologies in area of IT assigned', 'Establish facts and draw valid conclusions', 'Recognize patterns and opportunities for improvement throughout the entire organization', 'Ability to discern critical from minor problems and innovate new solutions', 'Dental insurance', 'Health insurance', 'Vision insurance', '8 hour shift', 'Big data: 8 years (Preferred)', 'etl: 4 years (Preferred)', 'No', 'One location']",2020-12-30 22:54:32
Data Scientist,Equinox Consulting Partners LLC,N/A,"Richmond, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Acquire access to various databases, and other source systems.', 'Help to create data pipelines for more efficient and repeatable data science projects.', 'Apply statistical analysis and visualization techniques to various data.', 'Network with domain experts to better understand the business mechanics that generated the data.', 'Apply various ML and advanced analytics techniques to perform classification or prediction tasks.', 'Integrate domain knowledge into the ML solution. Collaborate with ML operations (MLOps), data engineers, and IT to evaluate and implement ML deployment options.', 'Continuously monitor execution and health of production ML models.', 'Establish best practices around ML production infrastructure.', 'Knowledge/experience in statistical modeling, data mining and ML using tools/techniques, Python, R, Deep Learning, Text Mining, Graphic Analysis (3 years)', 'Geospatial analysis packages: ArcGIS or similar products (1 year highly desired)', 'Business Intelligence packages: Microsoft PowerBI, Tableau, or similar products (2 years highly desired)', 'Must be self-driven, curious, creative and a good communicator. Demonstrate the ability to work in diverse, cross-functional teams (3 years)']",2020-12-30 22:54:32
Data Engineer,"Double Line, Inc.",N/A,"Austin, TX 78758","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Think creatively and help other data experts on the team figure out the solution to really tough data load or transformation problems', 'Leverage SQL and/or ETL development, data mapping, and data modeling experience to manage and organize our customer education data', 'Be obsessed about continuously improving our approach and doing it better and faster the next time', 'Consultancy experience with a focus on Agile practices', 'AWS and Azure Cloud', 'Python or similar scripting languages', 'AWS Quicksight, Tableau, Power BI, or other visualization tools', 'Soak up knowledge from the existing team of experts in the first 30 days', 'Bring fresh eyes to our processes and techniques and bring new ideas to the table in the first 2 months', ""Grow your skills so much that you're ready to teach the next new hire by 2021"", 'A mission-driven company with a long-term focus on helping the world by untangling the technical messes that hold back education in our country', 'A home where your voice matters, and you can effect real change', ""A company who cares about you, makes sure you're engaged with exciting work and provides medical benefits, 401k, and a great culture.""]",2020-12-30 22:54:32
Data Engineer,BOEING,"4 out of 5 from 8,064 employee ratings","Crystal City, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Write code on a data extract, transform and load (ETL) platform to ingest and transform data to a suitable formats', 'Add features to ETL platform to shorten timelines for future data integration efforts', 'Develop, maintain code, and integrate software into a fully functional software system', 'Participate in daily scrum meetings, sprint retrospectives, and other agile processes', 'Work with external teams to validate data ingest', 'Provide and maintain documentation of system architecture, development and enhancements', ""Bachelor's Degree and 5 or more years' experience or master's degree with 3 or more years' experience from an accredited course of study in a technical field such as engineering, computer science, mathematics, physics or chemistry"", 'An Active TS/SCI clearance', '5+ years of software development experience', 'Demonstrated understanding of high scale cloud architecture', 'Linux/Unix experience', 'Object Oriented programming language skills', 'Possess strong verbal and written communication skills', 'Possess strong analytical skills, with excellent problem-solving abilities in the face of ambiguity', 'Expertise in data ingestion, data transformation (ETL) and data modeling', 'Experience with Java, Ruby or Python', 'Experience in Agile/SCRUM enterprise-scale software development', '3 years experience working with batch-processing and tools (e.g., Nifi, Midpoint, MapReduce, Yarn, Pig, Hive, HDFS, Oozie)', '1 year experience working with Restful web services', 'Experience with Code development, deployment, versioning and build tools (e.g., Eclipse, git, svn, maven, Jenkins)', 'Experience working with tools in stream-processing (e.g., Storm)', 'Experience developing applications that work with NoSQL stores (e.g., ElasticSearch, Hbase, Cassandra, MongoDB, CouchDB)', 'Working in cloud architecture with AWS EC2, RDS, S3, VPC, ElasticSearch', 'Experience working with moving data across different networks and security domains']",2020-12-30 22:56:13
Data Engineer,BCC Software,3.4 out of 5 from 10 employee ratings,"Rochester, NY 14623","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop performant and scalable data structures to power processing, reporting and analytics areas of our SaaS customer offerings', 'Work closely with DBAs, architects, software engineers and IT on positioning our data management systems for both performance and scale', 'Develop software with all its related activities', 'Develop/review code as well as writing unit tests', 'Estimate/size stories', 'Test own work and the work of others', 'Document and collaborate on all assigned Sprint activities', 'Meet individual as well as your team’s commitments', 'Deliver results on a consistent basis in an Agile SCRUM environment', 'Mentor other team members on best practices of working with large data sets', '10+ years of experience in the fields of Database Development, Design & Architecture, Data Analytics and Warehousing', 'Highly technical expert-level knowledge with hands-on experience of working with MS SQL Server (or like) RDBMS', 'Experience with non-relational databases is a plus', 'Working knowledge and experience with Microsoft C#/.Net in a SaaS type environment', 'Proven track record of developing, maintaining, and scaling data structures/processes/platforms to power customer facing web applications and services with high degree of concurrency and large data sets', 'Actively practiced software engineering agile methodology of consistently delivering results', 'Experienced in BI-type solutions (Tableau preferred), understanding of its components as well as how to configure and tune them to achieve optimally performing customer facing visualizations and reports is a major plus']",2020-12-30 22:56:13
Engineer - Python/Big Data,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Newark, DE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Undergraduate degree in a technology discipline required', 'Experience managing project sponsors to accomplish common goals', ""7+ years' experience on software development projects, with hands-on experience in:"", 'Indepth Python•experience', 'Big Data e.g Hadoop/ HDFS/ Spark / Scala', 'Advanced knowledge of application, data and infrastructure architecture disciplines', 'Core Java 8, Spring, JPA/Hibernate, React JavaScript desirable', 'Experience in Agile SDLC and working proficiency in developmental toolsets', 'Knowledge of various financial instruments is desirable', 'Successful track record on several major technology implementation projects', 'Excellent team spirit and ability to work in collaborative environment', 'Ability to working under own initiative']",2020-12-30 22:56:13
AWS Data Engineer,Deloitte,"4 out of 5 from 9,921 employee ratings","Davenport, IA 52807","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Creating/managing AWS services.', 'Work with distributed systems as it pertains to data storage and computing.', 'Building and supporting real-time data pipelines', 'Design and build of data extraction, transformation, and loading processes by writing Step functions or custom data pipelines.', 'Must have significant experience with AWS data services', 'Strong database experience in Relational, Columnar, NOSQL & Timeseries databases.', 'Working experience on building and supporting real-time data pipelines using AWS Glue, Redshift/Spectrum, Kinesis, Firehose, Pyspark, EMR and Athena.', 'Knowledge and hands-on experience with AWS solutions including S3, SNS, SQS, DynamoDB, Redshift and AWS RDS.', 'Experience in the design and build of data extraction, transformation, and loading processes by writing Step functions or custom data pipelines.', 'Nice to have experience working on Hadoop, Data Bricks', 'Familiarity with log formats from various AWS services such as S3 server access , CloudFront distribution, Lambda execution, ELB, Container execution etc.', 'Experience on creating AWS Lambda functions using Python or R scripts.', 'Familiarity with AWS infrastructure related services such as: AWS VPC, EC2 Instances, Network policies and Cloud Watch.']",2020-12-30 22:56:13
Cloud Data Engineer,Resiliency LLC,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop and implement approaches, policies, and standards to ensure data quality and integrity is maintained and that any inaccurate data is uncovered and corrected', 'Develop and implement security standards for data storage and transport', 'Bachelor’s degree and 5 to 10 years of relevant work experience, ideally with highly relevant data administration experience', 'Cloud Data Engineering background strongly preferred including experience with web services (SOAP / REST)', 'Expert SQL skills', 'Strong working knowledge of Informatica, PowerBI, and Azure Data Factory and ETL – or comparable systems in each of these 3 categories', 'Experience with digital process automation and/or robotic process automation', 'Very strong data analytic capabilities including experience with data collection, manipulation, cleaning, analysis, ETL, and visualization. Strong data Modeling skills (conceptual, logical, physical)', 'Exceptional Excel skills including high level of expertise at pivot tables and various Excel functions used for data manipulation, cleaning, parsing, etc.', 'Must have strong ability to quickly master and become expert in new data solutions', 'Academic, extracurricular, and/or work record of tackling ambitious goals successfully', 'Excellent organization skills, time management and problem-solving skills; the ability to juggle many tasks at the same time; strong attention to detail', 'Strong communication and interpersonal skills over the phone, in person, and via video conference', 'Ability to assess needs related to the job function and create new processes, documents, structures, and systems accordingly', 'Experience working with multidisciplinary teams and diverse groups; Independent worker, self-starter', 'Intellectual curiosity, along with a competitive spirit and friendly, likable personality', 'Last but not least, a strong interest in impacting the future of behavioral health in the U.S.']",2020-12-30 22:56:13
Data Engineer,Trimble,3.7 out of 5 from 262 employee ratings,"Minnetonka, MN","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:56:13
Data Engineer Mid Level,USAA,"3.9 out of 5 from 3,355 employee ratings","Phoenix, AZ 85085","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Identifies and manages existing and emerging risks that stem from business activities and the job role.', 'Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.', 'Follows written risk and compliance policies and procedures for business activities.', 'Design and implement technical solutions.', 'Identify and solve significant technical problems and architecture deficiencies.', 'Participate in daily standups and design reviews.', 'Breakdown business features and into technical stories and approaches.', 'Analyze data and enable machine learning.Create proof of concepts and prototypes.', 'Help on-board entry level engineers.', 'Collaborate with the team and other engineers to plan and execute assignments and tasks.', 'May begin mentoring junior engineers.', ""Bachelor's degree in related field of study,"", 'OR', 'Certification from an approved technical field of study,', 'OR', '4 additional years of related experience beyond the minimum required.', '4 years of data management experience implementing data solutions demonstrating depth of technical understanding within a specific discipline(s)/technology(s)', '4-6 Years Experience with Tableau Reporting OR Cognos BI OR Business Object', '4-6 Years Experience with SQL or Python', '4-6 Years Experience with IBM DataStage or Informatica', '4-6 Years Experience with Unix Shell Scripting', 'In-depth knowledge of Snowflake cloud architecture']",2020-12-30 22:56:13
Data Engineer,Chenega Corporation,3.7 out of 5 from 590 employee ratings,"Springfield, VA 22151","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL Server Integration Services (SSIS) including UI and custom code features.', 'Write or create stored procedures, SQL scripts, SSIS packages that can be used to:', 'Move data from source databases to target databases', 'Clean / Condition data', 'Convert or transform data', 'Reconcile and confirm converted data', 'Find data errors', 'Validate data to business rules', 'Ability to examine existing ETL scripts and track data back tosource', 'SQL Server administration, tuning, and workbench.', 'Work with business experts to understand data and completedata mappings.', 'Focus on the development of extract, transform, and load (ETL) jobs currently using Microsoft SQL, Server, and SSIS.', 'The environment currently supports hundreds of related ETL jobs that move data between 30 different source systems and between multiple classifications.', 'Part of the challenge as a data engineer will be to find scalable and efficient coding solutions that plug into this extensible system in order to add more data to the Enterprise data store.', 'Other duties as assigned', 'Bachelor’s Degree in Statistics, Mathematics, Computer Science or another quantitative field', 'Equivalent years of experience in lieu of degree', '4 years of relevant experience with the following software / tools:', 'Experience with Microsoft SQL', 'Prior experience supporting IC/DoD', 'The existing data warehouse is built on Microsoft SQL hosted on Amazon Web Services (AWS), so experience developing solutions that scale well in these environments is a plus.', 'Active Top-Secret Clearance with ability to obtain SCI', 'Ability to work independently and yet be effective within a team setting', 'Must be capable of managing multiple efforts with time related constraints in a fast-paced contracting environment', 'Demonstrated ability to effectively communicate and collaborate with diverse internal and external stakeholder groups and individuals', 'Friendly presence, helpful attitude, good interpersonal skills, and ability to work well with others.', 'Excellent skills in Microsoft Word, Excel, and other Office applications', 'Proficient with Microsoft Office Applications, and experience working in a home office setting as well as the ability to train end users on frequently asked technical issues.', 'Ability to provide technical assistance and support over the phone; good phone skills, professional demeanor, previous customer service experience strongly desired.', 'While performing the duties of this Job, the employee is regularly required to sit and talk or hear. The employee is frequently required to walk; use hands to finger, handle, or feel and reach with hands and arms. The employee is occasionally required to stand; climb or balance and stoop, kneel, crouch, or crawl. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include close vision.']",2020-12-30 22:56:13
Clinical Data Engineer,Dascena,3.7 out of 5 from 6 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and implement optimal and compliant data pipeline architecture', 'Assemble complex data sets that meet business requirements', 'Identify, design, and implement internal process improvements, including CI/CD for automated testing and deployment, and scalable data transformation and delivery processes', 'Build analytics tools that utilize the data pipeline to better support data science research projects and applications', 'Work with stakeholders including the Executive, Data, and Writing teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data and infrastructure secure and maintain compliance with the regulatory requirements', 'Bachelor’s degree in Computer Science, Data Science, or similar discipline', '2+ years of experience in building scalable data solutions', 'Advanced working knowledge of SQL and NoSQL databases, including Postgres and MongoDB', 'Experience building and optimizing scalable data pipelines and architectures', 'Working knowledge of message queuing, stream processing, scalable data stores, and distributed computing', 'Strong Python skills, and experience with the numeric libraries and distributed computing frameworks in the Python ecosystem', 'Experience with CI/CD pipelines and application deployment in the cloud', 'Excellent understanding of security principles, best practices, and compliance', 'Knowledge and experience with the healthcare industry is a plus', 'Experience with healthcare data and data formats (e.g. HL7) is a plus', 'Experience working with clinical data in a machine learning setting is a plus', 'Excellent communication skills', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Competitive compensation', 'Health benefits', 'Flexible hours and PTO', 'Remote work']",2020-12-30 22:56:13
Sr Big Data/Data Engineer,American Business Solutions Inc,N/A,"Columbus, OH 43215","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Big data: 8 years (Preferred)etl: 4 years (Preferred)', '6+ years of experience with Big Data, Hadoop on Data Warehousing or Data Integration projects.', 'Analysis, Design, development, support and Enhancements of ETL/ELT in data warehouse environment with Cloudera Bigdata Technologies (Hadoop, MapReduce, Sqoop, PySpark, Spark, HDFS, Hive, Impala, StreamSets, Kudu, Oozie, Hue, Kafka, Yarn, Python, Flume, Zookeeper, Sentry, Cloudera Navigator) along with Oracle SQL/PL-SQL, Unix commands and shell scripting;', 'Strong development experience in creating Sqoop scripts, PySpark programs, HDFS commands, HDFS file formats (Parquet, Avro, ORC etc.), StreamSets pipeline creation, jobs scheduling, hive/impala queries, Unix commands, scripting and shell scripting etc.', 'Writing Hadoop/Hive/Impala scripts for gathering stats on table post data loads.', 'Strong SQL experience (Oracle and Hadoop (Hive/Impala etc.)).', 'Writing complex SQL queries and performed tuning based on the Hadoop/Hive/Impala explain plan results.', 'Proven ability to write high quality code.', 'Experience building data sets and familiarity with PHI and PII data.', 'Expertise implementing complex ETL/ELT logic.', 'Develop and enforce strong reconciliation process.', 'Accountable for ETL/ELT design documentation.', 'Good knowledge of Big Data, Hadoop, Hive, Impala database, data security and dimensional model design.', 'Basic knowledge of UNIX/LINUX shell scripting.', 'Utilize ETL/ELT standards and practices towards establishing and following centralized metadata repository.', 'Good experience in working with Visio, Excel, PowerPoint, Word, etc.', 'Effective communication, presentation, & organizational skills.', 'Familiar with Project Management methodologies like Waterfall and Agile', 'Ability to establish priorities & follow through on projects, paying close attention to detail with minimal supervision.', 'Required Education: BS/BA degree or combination of education & experience', 'Demonstrate effective leadership, analytical and problem-solving skills', 'Required excellent written and oral communication skills with technical and business teams.', 'Ability to work independently, as well as part of a team', 'Stay abreast of current technologies in area of IT assigned', 'Establish facts and draw valid conclusions', 'Recognize patterns and opportunities for improvement throughout the entire organization', 'Ability to discern critical from minor problems and innovate new solutions', 'Dental insurance', 'Health insurance', 'Vision insurance', '8 hour shift', 'Big data: 8 years (Preferred)', 'etl: 4 years (Preferred)', 'No', 'One location']",2020-12-30 22:56:13
Data Engineer,Planned Systems International,3.9 out of 5 from 40 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build and automate data pipelines.', 'Ability to work as a member of a team assigned to design and implement data collection, integration, and transformation solutions.', 'Learn quickly ability to understand and rapidly comprehend new areas functional and technical and apply detailed and critical thinking to customer solutions.', 'Propose design solutions and recommend best practices for large scale data analysis.', 'Meet the data needs of Data Scientists', 'B.S. or equivalent degree in computer science, mathematics or other relevant fields', '3-7 years of hands-on experience in ETL, Data warehouse, Data Marts, Visualization and/or building data pipelines, modeling and designing schema for data lakes or for data platforms', 'Strong programming and scripting skills experience and expertise in two or more of the following: Java, XML/XSLT, Python, Perl, Shell Scala, C', 'Proficient in big data/distributed computing frameworks such as Spring, Hadoop, Apache Hive, Spark, Kafka, etc.', 'Practice working with, processing, and managing large data sets (multi TB/PB scale)', 'Experience with Agile implementation methodologies', 'Must have TS/SCI CI POLY']",2020-12-30 22:56:13
Data Scientist,Equinox Consulting Partners LLC,N/A,"Richmond, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Acquire access to various databases, and other source systems.', 'Help to create data pipelines for more efficient and repeatable data science projects.', 'Apply statistical analysis and visualization techniques to various data.', 'Network with domain experts to better understand the business mechanics that generated the data.', 'Apply various ML and advanced analytics techniques to perform classification or prediction tasks.', 'Integrate domain knowledge into the ML solution. Collaborate with ML operations (MLOps), data engineers, and IT to evaluate and implement ML deployment options.', 'Continuously monitor execution and health of production ML models.', 'Establish best practices around ML production infrastructure.', 'Knowledge/experience in statistical modeling, data mining and ML using tools/techniques, Python, R, Deep Learning, Text Mining, Graphic Analysis (3 years)', 'Geospatial analysis packages: ArcGIS or similar products (1 year highly desired)', 'Business Intelligence packages: Microsoft PowerBI, Tableau, or similar products (2 years highly desired)', 'Must be self-driven, curious, creative and a good communicator. Demonstrate the ability to work in diverse, cross-functional teams (3 years)']",2020-12-30 22:56:13
Data Engineer - 2020-21 - Technology,Salem Keizer Public School,N/A,"Salem, OR 97309","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Dental insurance', 'Employee assistance program', 'Employee discount', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Retirement plan', 'Vision insurance', '8 hour shift', 'Day shift', 'Monday to Friday', 'Multiple locations', 'Personal protective equipment provided or required', 'Social distancing guidelines in place', 'Virtual meetings', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 22:56:13
Data Engineer,"Double Line, Inc.",N/A,"Austin, TX 78758","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Think creatively and help other data experts on the team figure out the solution to really tough data load or transformation problems', 'Leverage SQL and/or ETL development, data mapping, and data modeling experience to manage and organize our customer education data', 'Be obsessed about continuously improving our approach and doing it better and faster the next time', 'Consultancy experience with a focus on Agile practices', 'AWS and Azure Cloud', 'Python or similar scripting languages', 'AWS Quicksight, Tableau, Power BI, or other visualization tools', 'Soak up knowledge from the existing team of experts in the first 30 days', 'Bring fresh eyes to our processes and techniques and bring new ideas to the table in the first 2 months', ""Grow your skills so much that you're ready to teach the next new hire by 2021"", 'A mission-driven company with a long-term focus on helping the world by untangling the technical messes that hold back education in our country', 'A home where your voice matters, and you can effect real change', ""A company who cares about you, makes sure you're engaged with exciting work and provides medical benefits, 401k, and a great culture.""]",2020-12-30 22:56:13
Software Engineer Internship - Summer 2021,Higharc,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Full stack engineers (e.g. TypeScript, node.js, next.js, PostgreSQL)', 'Graphics engineers (e.g. computational geometry, three.js, WebGL)', 'Experience using a statically typed programming language like Java, C++, or TypeScript', 'Experience using a version control system like git', 'Experience with basic data structures and algorithms', 'Must be enrolled currently at an accredited University', 'Must be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future.', 'Must be available to work 40 hours per week during the internship within normal business hours, Monday - Friday 9:00am - 5:00pm.', 'Start/End dates TBD, based on each candidate’s schedule']",2020-12-30 22:56:13
Systems Engineer -100% remote,Dun & Bradstreet,3.7 out of 5 from 737 employee ratings,"Center Valley, PA 18034","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Must have advanced/expert level experience administering Citrix VDI/VDA images and maintaining software updates to the gold image a must for this position.', 'Must have experience using Symantec End Point Protection experience on the SEPM server level, or experience with other similar tools.', 'Exhibit a strong technical aptitude and excellent communication skills with the ability to work effectively across a multitude of technical and non-technical groups', 'Fluent in scripting technologies such as Power Shell', 'Must have experience in a mixed operating system environment', 'Experience in a large global environment required', 'Experience in Intune / AzureAD for managing Endpoints', 'Microsoft System Center Configuration Manager (SCCM) experience.', 'Experience using JAMF for Apple management', 'Experience in Windows Defender and Defender ATP', 'Working knowledge of networking topologies, TCP/IP, DNS, DHCP, PXE, Wireless', 'Citrix Certification preferred', 'Build and Maintain images and applications via Citrix for VDI/VDA.', 'Create and implement Intune policies to Windows 10 and Mobile Fleet.', 'Establishes global images, including localized hardware and software', 'Troubleshoot complex software issues, integrations and conflicts at a global level', 'Create and manage update and patching packages to support current operating systems', 'Develop and document standards related to package creation, OSD, patching, infrastructure', 'Create queries and reports to support business and audit requests', 'Create operational support documents for various tasks related to SCCM', 'Provide technical documentation to project teams as part of project deliverables', 'Troubleshoot technical issues with SCCM infrastructure including SQL (basic proficiency) and SCCM agents', 'Security and policy enforcement using automated tools and scripting', 'Maintain existing SCCM environment including upgrades', 'Maintain existing enterprise images and create new enterprise images', 'Train operational team to perform day-to-day SCCM tasks such as security update deployments', 'Develops automated hardware deployment routines', 'Maintains standard management platforms such as Citrix, Intune, SCCM, PXE, WSUS, JAMF.', 'Provides training, process and procedure documentation for Desktop Technicians and end-users.', 'Ensure software compliance', 'Demonstrate s trong communication and interpersonal skills, must be customer-service oriented', 'Ability to work independently and with strong time management skills', 'Demonstrates technical proficiency through the pursuit and achievement of industry certifications', 'Flexibility and willingness to be available in the event of afterhours emergencies or priority tasks. Provide occasional weekend support as needed']",2020-12-30 22:57:53
Sr. Data Engineer,AVIVA Talent Advisors,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Data Engineering , 5 years (Preferred)', 'Serve as the Data expert together with your Technical Account Manager and Solution Architect team members when designing and implementing our most complex accounts solutions', 'Senior technical lead for the different data sources being utilized by their most advanced customers from technical requirements and data pipeline design to training and solution delivery', 'Execute an extensive analysis to design the solution and describe it through architecture and design artifacts', 'Present proposed solutions and maintain ongoing technical discussions with the customer across all levels, including C-suite', 'Build data-prep best practices for technical deployments and extensive performance tests for our customers', 'Coach and supervise technical team members on Cloud DWH best practices', 'Work with R&D Data teams to design sophisticated and non-trivial solutions', 'Serve as the Data expert together with your Technical Account Manager and Solution Architect team members when designing and implementing our most complex accounts solutions', 'You have hands-on experience with at least one of the following Cloud DWH technologies: AWS Redshift, Snowflake, Google BigQuery.', 'You are a technical lead of all aspects for a successful implementation from requirements and design to training and delivery.', 'Experience working with either a Map Reduce or an MPP system - Advantage', 'You have experience with schema design and dimensional data modeling', 'Programming experience and knowledge of software development life cycle', 'You have the ability to effectively communicate in English complex concepts in a clear and professional manner.', 'You thrive in a fast-paced, high-growth environment while working with a team.', 'You’ve turned your lifelong curiosity into business outcomes.', 'Ability to travel to customer locations and industry events (when Covid goes away)', 'You will have a much deeper understanding of the client technology, and how customers can utilize it', 'You will better understand the the product Architecture', 'You will start interacting with customers and getting to know their challenges/use cases', 'You will do lots of hands-on exercises in order to know the ins and outs of the technology', 'You will begin building Dashboards, configuring the product and understanding on-boarding customers at different stages of data maturity', 'You will also start shadowing projects with Senior team members', 'You will be familiar with the different types of PS engagements and project types', 'You will learn PS methodologies and tools you’ll use', 'You will start mastering the data challenges customers face', 'You will do several internal projects to champion Data architecture practice within Customer Success', 'You will learn and sharpen PS soft skills such as session management, how to interact with customers, working with Customer Success Managers, Technical Account Manager & Solutions Architects and other teams as well as handling challenging situations', 'You will be joining your first projects as Data Engineer shadowed by Senior team members', 'You’ll already own a handful of customer engagements where you will lead the data engineering challanges', 'You will start laying the foundations for the client’s Cloud DWH best practices', 'You’ll be the team’s focal point for Data, Modeling and BI realm, best practices on their proprietary database and while working with Cloud DWH partners', 'You’ll be able to leverage your acquired knowledge together with your Data expertise and start your journey to lead the Data Architecture field within Customer Success', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Parental leave', 'Vision insurance', 'Monday to Friday', 'Data Engineering : 5 years (Preferred)', 'Other forms', 'Remote interview process', 'Virtual meetings']",2020-12-30 22:57:53
Data Engineer (Boston/Remote),Reify Health,N/A,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Support the development and international expansion of our next-generation, privacy-aware, Kappa-style data architecture using Kafka, PostgreSQL, AWS, and Confluent Platform.', 'Prototype new algorithms or intelligence modules to support forthcoming data products.', 'Support our analytics team by building, scaling, and integrating data ingestion and ETL processes.', 'Frequently communicate your efforts to Head of Data and other technical/non-technical stakeholders in clear written, verbal, or presentation form.', 'Become intimately familiar with HIPAA, GDPR, and other applicable regulatory frameworks and how they influence our architecture and development decisions.', 'Live our data philosophy, which focuses on ethical decision making, being aware of how biased data (and assumptions) can affect results (and people), and being laser-focused on business needs.', 'At least 4 years of professional work experience in a role at a startup company dealing with regulated data (such as healthcare).', 'Deep practical experience with AWS (Redshift, S3, MSK, etc.), Kafka, and distributed systems.', 'Expertise in Clojure or Python in the context of data applications.', 'Demonstrated ability to rapidly develop and/or convert data science projects into modules that can be readily integrated into an existing product.', 'Experience with systems engineering, orchestration (e.g. Terraform), and awareness of the nuances of testing and deploying distributed data architecture at scale (particularly with probabilistic output).', 'Notable open-source contributions to software used by the data engineering or data science communities.', 'Advanced degree in a related field.', 'Competitive Salary and Stock Options: Salary and stock options commensurate to your experience and expertise.', 'Comprehensive Health and Wellness Coverage: 100% premium coverage for you (and >50% for your dependents) for: a top-tier health plan covering you in all 50 states (with option of HSA) dental, vision, disability (short-term and long-term), and basic term life insurance (for your entire tenure at Reify). We enable 24/7 access to doctor by phone or online via telemedicine coverage.', 'Retirement Plan: 401(k) plan with employer matching program.', 'Company-provided Workstation: You will receive a brand new MacBook Pro laptop to use for work.', 'Location Flexibility: You can work from anywhere in the U.S. compatible with an EST work schedule. Additionally, we fly remoters in for company summits and team events, filled with fun activities, good food, and many opportunities to get to know your colleagues better.', 'Vacation and Holiday Flexibility: Generous paid-time-off policy that accrues with your tenure at Reify which includes holiday flexibility and parental leave.']",2020-12-30 22:57:53
Analytics Engineer (Data Governance),InfoTrust,N/A,Ohio,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Technical challenge?', 'A way to come in and problem solve everyday?', ""Be part of new team and help grow our business to lengths we haven't even dreamed of yet?"", 'A role that flexes your experience with Javascript and love for automation?', 'A collaborative team environment?', 'A flexible work environment that embraces diversity, innovation, ownership, and growth?', 'A role that enables you to interact with some of the biggest brands in the world and delight both internal and external teams on a daily basis?', ""Delight potential Clients by:Demoing Tag InspectorShowcasing Tag Inspector capabilities to larger growth opportunities including performance, PII identification and Governance (Audit, Policy Creation and Ongoing Monitoring)Regularly identifying ways to utilize Tag Inspector data to improve data collection and optimize the organization's governance strategy."", 'Delight new or existing Clients by:Using various technologies (node.js, Google Apps Script, Google Cloud, etc.) to leverage the Tag Inspector API to automate the creation of deliverablesProviding support to Tag Inspector client in lower license tiers (Self Service Tier)Providing support to Governance ClientsUnderstanding Client challenges and sharing it with both the Customer Data Governance and Tag Inspector teams to help solve and think about growth opportunitiesLinking current solutions provided to other possible solutions that we offer (including Tag Management)', 'Delight our own teams by being able to automate manual processes', 'Delight our own teams by being able to automate work associated with Tag Management', 'Working knowledge of JavaScript and Project Architecture', 'Specific experience with Node.js and TypeScript, preferred, but not required', 'Understanding of (or a willingness to learn) Tag Management tools like Google Tag Manager', '3+ years of experience, preferably in a client-facing role', 'You enjoy working with data, and may even consider yourself ""data-driven""', 'Strong empathy and often use your strong communication and presentation skills to convey a message and secure buy-in, explain a technical complexity or deep dive into a client a hurdle', 'Adaptability and ability to take ownership', 'Seeking knowledge and understanding of complex technical concepts', 'Located in Ohio', ""An alignment between your personal core values and InfoTrust's; Ownership, Diversity, Respect, Impact, Growth, Innovation""]",2020-12-30 22:57:53
Data Engineer,Syngenta,"4.1 out of 5 from 1,083 employee ratings","Durham, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Degree in computer science, information science, engineering, mathematics or related technical discipline.', '5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets.', 'Strong experience with data integration (ETL/ELT) concepts.', 'Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets', 'Knowledge of, and experience with data transformation technologies and tools', 'Experience with SQL and NoSQL technologies', 'Desire to work with Agile/DataOps practices and methodologies', 'Experience with continuous integration practices', 'Able to write, debug, unit test, and performance test data integration processes', 'Able to clearly define data quality issues', 'Strong problem solving/critical thinking skills', 'Relational databases including Amazon RDS and Redshift.', 'AWS technologies including Redshift/Spectrum, S3/parquet, Glue, EMR, Lambda', 'Data streaming technologies (Kinesis, Kafka) desirable', 'IoT pipelines (AWS IoT Core, Kinesis) desirable', 'Geospatial data manipulation and storage desirable', 'Python and Java programming', 'R and statistical methods', 'Business rules engines such as Drools a plus', 'Data virtualization such as Denodo or Tibco a plus', 'Data modeling and virtualization', 'Full Benefit Package (Medical, Dental & Vision) that starts the same day you do', '401k plan with company match, Profit Sharing & Retirement Savings Contribution', 'Paid Vacation, 12 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts among others', 'A culture that promotes work/life balance, celebrates diversity and offers numerous family-oriented events throughout the year']",2020-12-30 22:57:53
Customer Success Manager,Rippleshot,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Customer Service: 5 years (Preferred)', 'Serve as project manager during technical on-boarding, managing expectations, resources and timelines', 'Identify and cultivate strong relationships with the key stakeholders, engaging via email, phone, and in-person', 'Lead regular business reviews to ensure usage of the tool and partners are realizing value and ROI', 'Track customer engagement and satisfaction indicators and look for ways to improve customer satisfaction', 'Manage customer success plans to exceed customer expectations working with a FinTech solution', 'Support customers by removing friction from the customer experience and meeting contractual SLAs', 'Manage renewal and upsell opportunities', 'Identify barriers to customer success, define resolutions, and manage action plans with internal resources', 'Provide product feedback (client requirements, product enhancements, etc.) to product management team', 'Collaborate with Customer Success Director and technical resources to develop scalable processes', 'Understanding the customers’ needs and delivering on them, exceeding customer expectations', 'Interacting with people and helping them solve problems', 'Bringing fresh ideas about customer success', 'Using technology and being able to explain it effectively to others', 'Collaborating with Product, Engineering, Sales, and Marketing to ensure customer feedback and requirements are communicated', 'Working in a fast-paced environment with the ability to adapt to change', '3-5+ years of customer success experience with B2B customers', 'Experience working for or with financial institutions (banks and credit unions) a plus', 'Experience with fraud solutions and analytics for financial institutions a plus', 'Chicago-based ideal, open to remote', 'Attention to detail and process-oriented', 'Excellent written, and oral skills, as well as strong time management and organization skills', 'Track record of establishing and retaining high-value client relationships', 'Self-motivated, intellectually curious, people person with high emotional intelligence', 'Customer-first mentality; ability to empathize and build customer loyalty', 'Experience acting as the liaison between technology teams and clients', '401(k)', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Customer Service: 5 years (Preferred)', 'Fully Remote', 'Yes']",2020-12-30 22:57:53
Software Engineer Intern,Balyasny,4 out of 5 from 8 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:57:53
Data Analyst / Software Development Engineer,Suna Solutions Inc,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Software Engineering, 1 year (Required)Unit Testing, 1 year (Required)Programming (Java, C, C++, C#, Python or Perl), 1 year (Required)Object Oriented Analysis & Design, 1 year (Required)Agile, 1 year (Required)Design Patterns and Algorithms, 1 year (Required)Data Analysis, 1 year (Required)', ""Education:Bachelor's (Preferred)"", 'Monday to Friday', 'Software Engineering: 1 year (Required)', 'Unit Testing: 1 year (Required)', 'Programming (Java, C, C++, C#, Python or Perl): 1 year (Required)', 'Object Oriented Analysis & Design: 1 year (Required)', 'Agile: 1 year (Required)', 'Design Patterns and Algorithms: 1 year (Required)', 'Data Analysis: 1 year (Required)', ""Bachelor's (Preferred)"", 'If there are no benefits, then what will be your desired hourly all-inclusive rate on W2 (for 100% remote work)?', 'Yes']",2020-12-30 22:57:53
Data Engineer,Data Axle,N/A,"Washington, DC 20006","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Must have applied experience with developing, implementing and using data models, including integration of massive amounts of data across multiple databases in a data warehousing, ETL or analytic environment.', 'Must possess expertise with multiple program languages across language types.', 'Must have strong communications and facilitation skills, with ability to work with analysts and end users to clearly capture requirements.', 'Must have experience in preparing and/or reviewing technical model requirements documentation to ensure accuracy and to ensure that impacts are identified, understood and communicated.', 'Must possess knowledge and experience in data extract, transform and load (ETL) processes, Talend experience preferred.', 'Responsible for technical leadership, setting standards and procedures and following up to mentor and train technical staff.', 'Meet and/or exceed data delivery time service standards. This role must support time critical corporate reporting requirements. Meeting these needs can entail intense periods of work to meet timeliness standards.', 'Work with appropriate customers to create and manage project schedules for reporting solutions.', 'Actively participate in the overall Data Warehouse/Business Intelligence strategy.', 'Document and conduct unit and system testing as it pertains to new Business Information/Data Warehouse development and maintenance.', 'Working closely with development team to clearly understand the business applications and databases supporting the applications.', 'Maintenance of database dictionaries, and integration of systems through database design.', 'Logical and Physical design of the warehouse BI and OLTP systems.', 'Working with the DBA group helping develop best practices, policies, and design of logical and physical tables within the databases.', 'Support in all aspects of data analysis and data movement among different systems - source systems and data warehouses.', 'Essential functions are the basic job duties that an employee must be able to perform, with or without reasonable accommodation. The function is considered essential if the reason the position exists is to perform that function.', 'Perform other miscellaneous duties as assigned by management.', 'These tasks do not meet the Americans with Disabilities Act definition of essential job functions and usually equal 5% or less of time spent. However, these tasks still constitute important performance aspects of the job.']",2020-12-30 22:57:53
Data Engineer,GTL,3.1 out of 5 from 76 employee ratings,"Falls Church, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with internal business stakeholders to gather required information to perform data analysis', 'Assist in maintaining efficient operation of the reports, visualizations and ETL processes within the GTL back-office', 'Support proper data governance processes and policies; implement and/or validate data lineage, quality checks, classification, etc.', 'Analyze and improve efficiency, scalability, and stability of various system processes', 'Be passionate about solving customer problems and develop solutions that are customer focused', 'Prepare ad-hoc reports, extracts and visualizations as needed', 'Convert ad-hoc reports to automated managed reports using appropriate tools, development and QA processes', 'Identify data inconsistencies, provide workarounds, and report them to stakeholders', 'Troubleshoot data issues, validate result sets, and implement process improvements', 'Generate tracking and monitoring tools to validate data', 'Discuss database structure and application data with developers and DBAs or others in data engineering to obtain best results from data', 'Use acquired information to help build out a big data schema and infrastructure', 'Reading, writing and editing system, architecture, processes and other documentation in documentation tool.', 'Reading, responding to, and writing service tickets in ticketing system.', 'Reviewing and responding to system alerts in internal and external alerting and metrics systems.', '4 Year College Degree in Computer Science, Mathematics, Statistics or a similar quantitative field or comparable experience in lieu of degree', '2-5 years of experience conducting data analytics, financial analysis, ETL, data cleansing', 'Familiarity with Business Intelligence', 'Solid analytical and organizational skills, with ability to analyze processes', 'Proficiency in SQL', 'Experience with Python or equivalent scripting language', 'Familiarity with the command line (Windows CMD or Linux Shell)', 'Experience with scripting languages such as Bash and Perl', 'Proficiency in Excel', 'Experience in analyzing data using statistics', 'Must be accurate and detail oriented in a fast-faced environment with multiple responsibilities', 'Work quickly with a sense of urgency and flexibility to adapt changes resulting from a dynamic and growing environment', 'Ability to handle confidential information with diplomacy and tact', 'Ability to respond to after-hours issues based on escalation', 'Professional attitude and demeanor', 'Experience working with Business Intelligence software such as Business Objects, Looker and PowerBI', 'Experience with Microsoft SQL Server, Oracle and opensource databases such as MySQL and MariaDB', 'Experience with Snowflake, Apache Airflow, Spark and Hive']",2020-12-30 22:57:53
Associate Documentation Specialist,Globus Medical,3.4 out of 5 from 72 employee ratings,"Eagleville, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Issuing Quality System documents and coordinate training process', 'Issuing device master record documents (manufacturing process specifications, inspection plans, routers, etc.) and other technical documents during development, release, and maintenance phases of product realization', 'Processing Document Change Orders (DCOs) to implement all controlled documentation and maintain distribution of controlled copy documents', 'Organizing and communicating status of work to management and other personnel as required and to keep them informed of objectives and progress', 'Ensuring documentation is complete, properly formatted and meets corporate standards', 'Assisting in assigning and tracking new part numbers through the development cycle', 'Performing database searches, data analysis, and reporting to assist design engineers on product development', 'Using multiple manufacturing business systems, spreadsheets, graphs, word processors and product information management systems in order to facilitate the document release, change, and data storage & retrieval processes', 'Assisting in conducting various training classes relating to documentation practices that pertain to Quality on an as needed basis', 'Participating in continuous improvement activities and implement changes for improvement', 'Keeping supervisor informed of work-related activities and issues towards agreed upon goals and objectives', 'Maintaining cooperative and friendly attitude with coworkers', 'Adhering to the letter and spirit of the company Code of Conduct, the AdvaMed Code, MedTech Code, and all other company policies. Ensure Compliance with applicable governmental laws, rules, and regulations, both in the United States and internationally, by completing introductory and annual training and maintaining knowledge of compliance as it applies to your role', 'Representing the company in a professional manner and uphold the highest standards of ethical business practices and socially responsible conduct in all interactions with other employees, customers, suppliers, and other third parties of Globus', 'High School Diploma or equivalent; Minimum one year of work experience', 'Ability to review documentation for accuracy, perform data entry, scan and file documents', 'Must be knowledgeable with Microsoft word and Excel programs', 'Good organizational, typing, analytical, and critical thinking skills', 'Good communication and writing skills']",2020-12-30 22:57:53
SQL Developer/Data Engineer,ELLKAY LLC,1.5 out of 5 from 6 employee ratings,"Elmwood Park, NJ 07407","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Extract data from Client’s machines and restoring databases.', 'Identify data elements from various database as requested by client.', 'Working with Several Different Database Management Systems.', 'Be very proficient with SQL Server.', 'Strong SQL skills (SQL Server, Oracle, MySQL, Postgres etc.).', 'Experience in database design and structure, with an emphasis on scalability.', 'A strong desire to develop new and innovative ways to improve our data storage and processing.', 'Prepare and perform data analysis and transformations to align data to business rules.', 'Work with our clients Subject Matter Experts to obtain a greater understating of the business needs and goals.', 'Contribute to knowledge management activities and promote best practices for project execution.', 'Programming experience required in any object oriented programming languages like C#, Java etc.', 'Excellent SQL skills, with experience in building and interpreting complex queries.', 'A minimum 3 years of professional experience as SQL Developer or Data Engineer', 'A minimum 5 years of professional experience in information technology.', ""A minimum of bachelor's or higher in Computer Science, Information Systems, or equivalent degree or strong industry experience."", 'Healthcare Domain knowledge preferred.', 'Experience in HL7,CCDA preferred.']",2020-12-30 22:57:53
Data Engineer,OneMagnify,3.6 out of 5 from 9 employee ratings,"Dearborn, MI","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with data scientists and software engineers to support data acquisition activities, data solution ideation, and implementation', 'Work with technical and business leads to transfer global business requirements into sound solutions and implementation', 'Share support responsibilities for implemented components', '3+ years of experience with R, Python, SAS, MATLAB, Java, etc.', '3+ years of Hive, Spark, JavaScript, SQL, HTML', '3+ years of experience with PCF cloud services', 'Experience with Hadoop, Spark, Kafka', 'Familiar with big data and machine learning tools and platforms', 'Experience with BI tools, such as Informatica, Data Stage, QlikView, Tableau, etc.', 'Design data pipelines and data robots, take a vision and bring it to life', 'Master data engineer; teaches others; works closely with IT architects to set strategy and design projects', 'Lead a team of Associate Data Engineers and Data Engineers', 'Provide extensive technical, strategic advice and guidance to key stakeholders around the data transformation efforts', 'Redesign data flows to prevent recurring data issues', 'Strong analytical and problem-solving skills', 'Possess excellent oral and written communication skills, as well as facilitation and presentation skills, and engaging presentation style.', 'Ability to work as a global team member, as well as independently, in a changing environment and managing multiple priorities.', 'Ability to establish and maintain cooperative and effective working relationships with application implementation teams, IT project teams, business customers, and end users.', 'Ability to deliver work within deadlines.', 'Experience with agile/lean methodologies', 'Experience working independently and with minimal supervision', 'Experience with a global team', 'Experience with Test Driven Development and Software Craftsmanship', 'Strong Communications skills', 'Ability to illustrate and convey ideas and prototypes effectively with team and partners', 'Presence demonstrating confidence, ability to learn quickly, influence, and shape ideas']",2020-12-30 22:57:53
Data Scientist,Apple,"4.2 out of 5 from 9,978 employee ratings","Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Practical experience with and theoretical understanding of algorithms for classification, regression, clustering, and anomaly detection', 'Working knowledge of relational databases, including SQL, and large-scale distributed systems such as Hadoop and Spark', 'Ability to implement data science pipelines and applications in a general programming language such as Python, Scala, or Java', 'Ability to comprehend and debug complex systems integrations spanning toolchains and teams', 'Ability to extract meaningful business insights from data and identify the stories behind the patterns', 'Excellent presentation skills, distilling complex analysis and concepts into concise business-focused takeaways', 'Creativity to engineer novel features and signals, and to push beyond current tools and approaches']",2020-12-30 22:57:53
Data Engineer - 2020-21 - Technology,Salem Keizer Public School District,3.7 out of 5 from 101 employee ratings,"Marion County, OR","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:57:53
Data Science Intern - Summer 2021,MongoDB,3.7 out of 5 from 27 employee ratings,"New York, NY 10019","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'A Masters or PhD student in a quantitative field (Computer Science, Data Science, Statistics, Physics, Economics, Mathematics, Analytics, or other field with significant course work in statistics and research).', 'Confident programming in a statistical programming/scripting language (R, Python).', 'Have an understanding of data structures, machine learning algorithms, and computational complexity. Familiarity with design of online experiments is a plus.', 'Have a solid ability to collaborate and communicate with people from diverse professional and educational backgrounds.', 'Comfortable thinking analytically about ambiguous problems and willing to problem solve and troubleshoot regardless of methods, techniques, or tools; not hung up on implementing a convolutional neural net!', 'Write code (Python, R, SQL, etc.) for analyzing data, and build statistical models to solve specific business problems.', 'Build stakeholder-facing reports & visualizations to provide insights and metrics which help understand user behavior.', 'Collaborate with data engineers, UX researchers, software developers, and data analysts/scientists to build data science solutions and provide analytical support.', 'Find like-minded teammates who will make your New York City internship the most fun ever!']",2020-12-30 22:59:33
Software Engineer Intern - Summer 2021 (Virtual),SurveyMonkey,4.1 out of 5 from 19 employee ratings,"Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Currently enrolled Junior (graduating in Spring 2022) pursuing a Bachelor's degree in Computer Science, Software Engineering, or a similar degree"", 'Solid CS fundamentals (data structures and algorithms)', 'Experience with programming languages and frameworks such as Python, Java, or C++', 'Experience with web development technologies including HTML, CSS, or JavaScript', 'Eagerness to learn and get hands on experience with the latest technologies', 'Willingness to own a project from start to finish', 'Strong analytical and problem solving skills', 'Excellent written and verbal communication skills', 'Strong work ethic and desire to have fun working with great people']",2020-12-30 22:59:33
Summer 2021 Social Media/Digital Intern,Rocky Mountain Institute,4.6 out of 5 from 5 employee ratings,"Basalt, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Support social media campaigns across 13 programs—write and produce clear and compelling digital content to a variety of audiences in support of diverse programs in electricity / renewable energy, aviation, shipping, trucking, personal mobility, building efficiency, islands, and our work in Africa, China, India and more.', 'Schedule planned digital messaging across Facebook, Twitter, LinkedIn, Instagram, and other platforms.', 'Complete weekly metrics reports on media and social media activity', 'Using tools like Cision, SproutSocial, Google Analytics', 'Set up meetings/interviews, capture action items, update status reports.', 'Monitor social media and stay ahead of news events and media trends/conversations in key industries.', 'Support reactive media requests from journalists for organizational information, commentary/interviews, spokespeople, and event participation.', 'Support proactive media outreach', 'Build relationships for RMI with influencers, media and bloggers on social media', 'News monitoring', 'Competitor monitoring, reporting and analysis on social media and traditional media', 'Must be enrolled in a Bachelor’s program, ideally Sophomore and Junior applicants', 'Must be able to work 40 hours per week, over 12 weeks throughout Summer 2021', 'Digitally savvy; experience with B2B social media marketing experience is a plus', 'Experience with the latest social media platforms as well as Google Analytics is a plus', 'Excellent written communication skills', 'Highly organized, meticulously attentive to detail, and good at multitasking', 'Excellent initiative and follow-through', 'Very creative, innovative, and a problem-solver', 'A strong team player with excellent interpersonal / collaborative skills with staff and counterparts at all organizational levels and with external partners', 'An intense drive for results and impact', 'Eloquent and articulate, confident telephone manner and salesmanship style', 'A newshound who lives and breathes daily news', 'Interest and passion in renewable energy and climate change issues', 'A fast learner, can take a complex idea/topic and can explain it in a simple, accessible and engaging way', 'Self-starter, can take initiative', 'Passion to change the way we use energy and tackle climate change', 'Learn the basics of B2B social media marketing and the use of digital tools for analyzing online data.', 'Master content writing and ad / creative building to inform our diverse audience of C-suite leaders, businesses, NGOs, government, policymakers, researchers, engineers, journalists/media and more.', 'Develop an eye for a sharp, relevant news angle in the energy & environment field.', 'Learn how to craft nuanced pitches for key media outlets and sell in these stories to the press', 'Work alongside our Marketing & Communications team to test and refine our social media and email platforms.', 'Exposure to the organization of 260 clean energy-focused researchers, operations staff and senior leaders.', 'Applications without a cover letter will not be considered. Be sure to answer why you are considering RMI for an internship in this document.', 'Have the different array of thinking that comes from diverse backgrounds and cultures, enabling us to solve some of the world’s greatest challenges.', 'Strive for a culture of inclusion and belonging by treating others with dignity, respect and appreciation enabling them to feel welcomed, supported and valued.', 'Effectively connect, communicate and build long-lasting relationships with decision makers, stakeholders and constituents within diverse communities.']",2020-12-30 22:59:33
"Software Engineering Internship, Summer 2021",Etsy,4.3 out of 5 from 58 employee ratings,"Brooklyn, NY 11201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:59:33
Analytics Engineer Internship - ASO,Health Catalyst,4.7 out of 5 from 15 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Data: integrate data in a flexible, open & scalable platform to power healthcare’s digital transformation', 'Analytics: deliver analytic applications & services that generate insight on how to measurably improve', 'Expertise: provide clinical, financial & operational experts who enable & accelerate improvement', 'Engagement: attract, develop and retain world-class team members by being a best place to work', 'Partnership : Work with your team to accomplish your assigned tasks and deliver value.', 'Communication : Effectively and regularly communicate status, issues, and progress of assigned tasks; Ask question', 'Learning : Gain an understanding of Health Catalyst culture, products, and methodologies; Grow your technical skills through practical application.', 'Opportunity Identification: Identify improvement opportunities within the scope of assigned work.', 'Improvement: Learn formal methods for process improvement and apply them to solve problems.', 'Leverage HC software and technologies to perform varied analyses in support of client outcomes improvement initiatives across clinical, operational and financial domains.', 'Design data models and visualizations that meet project requirements and comply with HC design standards and principles.', 'Ensure assigned projects are executed efficiently and according to project requirements and timelines.', 'Perform data validation tests to ensure quality of measurement.', 'All other duties as assigned', 'Understanding of Extract, Transform, and Load (ETL) processes.', 'Ability to deliver analytics to technical, non-technical, and key stakeholders.', 'Experience developing visualizations that consume data models for non-technical users', 'Effective written and verbal communication, and presentation skills', 'Ability to Interact with and communicate with all levels of employees and clients', 'Comfortable working under general direction', 'Problem/puzzle Solving', 'Willingness to ask question']",2020-12-30 22:59:33
Data Engineer,Thumbtack,4.3 out of 5 from 50 employee ratings,"San Francisco, CA 94103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Proactively drive the vision for BI and Data Warehousing across the company, and define and execute on a roadmap to achieve that vision', 'Design, architect, and maintain a data warehouse that supports a rapidly evolving product, in partnership with our stellar analytics and data services teams', 'Define, document and socialize foundational aspects of our reporting and analytical data model', 'Build and own the reporting pipelines and infrastructure that organize and structure our terabytes of data into digestible tables that empower analysis and reporting across the company', 'Drive data quality across key product and business areas', 'Collaborate closely with analysts to ensure our analytical infrastructure helps meet our company goals and allows product development to move fast', 'Partner with data services and product engineering teams to ensure consistent, seamless tracking and measurement of key company and product metrics', '6 or more years of experience working in data or backend engineering, where your primary focus was on datastores and business intelligence, serving analysis and reporting functions', 'Experience building ETL data pipelines in a programming language like Python or Scala', 'Experience designing, architecting, and maintaining a data warehouse that seamlessly stitches together data from production databases, clickstream event data, and external APIs to serve teams of analysts', 'Experience being a project manager across a set of diverse projects with a strong track record of delivering against aggressive timelines', 'Excellent ability to understand the needs of and collaborate with stakeholders in other functions, especially the Analytics team', 'Experience managing or leading a data engineering team', 'Experience in an online marketplace or similar consumer technology company', 'Experience with a modern public cloud-based tech stack on AWS/GCP and the Google BigQuery data environment', 'Experience orchestrating data pipelines that serve hourly or daily metric reporting in Airflow', 'Experience with streaming or near-real time data pipelines', 'Experience building data pipelines in Scala', ""See what it's like to work here"", 'Meet the pros who inspire us', 'Engineers on a mission', 'Follow us on LinkedIn', ""Identifiers such as a real name, alias, postal address, unique personal identifier, online identifier, Internet Protocol address, email address, account name, driver's license number, passport number, social security number, or other similar identifiers;"", 'Professional or employment-related information.']",2020-12-30 22:59:33
2021 MD Engineering Development Program (MD EDP) - Summer Internship,Johnson & Johnson Family of Companies,"4.2 out of 5 from 5,353 employee ratings","West Chester, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You will have opportunities to participate and/or lead in rotational assignments encompassing entire project or a large portion of a major project. This may include resolving advanced materials, process, inspection/testing or procedural approaches to advance a medical device through the pipeline process into full R&D, and potentially into commercialization.', 'Support of products’ design development, manufacturing and commercialization, leveraging technical expertise to anticipate and proactively address challenges and risks.', 'Increase the productivity of product’s design, improve the quality of projects, improve communications through documentation, and to create a database for manufacturing.', 'Engineer capabilities required to develop and deliver automated medical devices - including requisite instruments, advanced imaging, and user interface / experience.', 'Pursue a number of internal developmental training programs as well as externally recognized qualifications.', 'Opportunity to work in a fast-paced cross functional, technologically advanced corporate environment in a program focused on developing individual engineers capable of pursuing careers across medical device businesses and high-volume manufacturers.', 'Currently enrolled in an Undergraduate or Graduate Engineering Degrees graduating in the Fall 2021 or Spring 2022.', 'The following engineering disciplines or specialties are preferred: Mechanical, Robotics, Electrical, Computer, Systems, Software, Chemistry, Materials Science, Biomedical and Computer Science.', 'Up to two years of professional full-time postgraduate work experience (excluding internships, co-ops and military)', 'The following concentration fields and/or skills are strongly preferred: Machine Learning, IoT, Embedded Software, Deep Machine Learning, Prototyping, Robot Design, Systems Reliability, Firmware and hardware integration.', 'A minimum GPA of 3.3 is strongly preferred.', 'Ability to work closely with technical and non-technical personnel and have excellent communication skills with the ability to influence others.', 'Demonstrated excellent problem-solving skills, intellectual curiosity and a dedicated approach to achieving success.', 'Validated leadership experience through extra-curricular activities, employment and/or internship experiences is required.', 'Ability to relocate across the United States as required by the internship program.']",2020-12-30 22:59:33
Intern Audio Recording Engineer,MPowerRecords LLC,N/A,"Bloomfield, NJ 07003","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Great time management,', 'Effective communication,', 'Proficient in Logic Pro X', 'Flexible Schedule', 'Basic Data Entry Skills', 'Great Costumer Service Skills.', '8 hour shift', 'Monday to Friday', 'Weekends', 'www.mpowerrecords.com', 'No']",2020-12-30 22:59:33
"Engineer, Data",StrongArm Technologies,3.5 out of 5 from 2 employee ratings,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Individual contributor using Python with a system trajectory towards Scala', 'Provide technical leadership in Data Engineering design principles', 'Design and implement highly available / scalable data pipelines using Apache Spark for ETL jobs that process data from 100s of thousands of sensors.', 'Build big data interfaces compatible across IoT systems using SWIG', 'Partner with the Data Science team to implement advanced statistical models and machine learning that run on edge devices', 'Partner with the Embedded Engineering team to build interfaces between IoT devices and data pipelines for ingesting data', 'Own data modeling implementation for huge scale', 'Optimize data pipelines for performance and scalability', 'Establish automated mechanisms to improve data integrity across all big data sets.', 'Leverage strategic and analytical skills to understand and solve customer and business centric questions', 'Monitor and troubleshoot performance issues for production pipelines', ""Learn about new technologies and add to StrongArm's Big Data tech stack"", 'Data Warehouse management in Databricks using Delta Lake', '2+ years experience in data engineering', 'Experience building systems using Apache Spark that have processed terabytes of data in production', 'Experience productionizing data science models and algorithms to run at scale', 'Experience with distributed data streaming frameworks like Spark Structured Streaming, Apache Flink, Kinesis, etc', 'Advanced Experience with RDBMS and SQL', 'Experience with automated testing for distributed systems in Spark (unit testing, end to end testing, QA, CI/CD)', 'Experience designing end to end pipeline architectures', 'Experience managing data warehouses in a production environment (Delta Lake, Snowflake, Redshift, Bigquery, Presto)', 'Scala and Python proficiency', 'Experience leveraging cloud systems to build data pipelines (BigQuery, Redshift, AWS Kinesis, AWS S3, GCS)', 'Linux proficiency, this is the means by which things are engineered well.', 'Experience extending Apache Spark (DataSource API, Catalyst Optimizer)', 'Experience with productionizing machine learning at scale and A/B testing new models: scikit-learn, tensorflow, pytorch', 'Experience building systems to train machine learning models at terabyte scale.', 'Experience working with Hadoop', 'Experience using workflow management systems like Airflow or equivalent', 'Experience working with datasets that measure physical phenomena.', 'noSQL solutions: Cassandra, HDFS and/or Elasticsearch', 'Experience as an open source contributor', 'Experience with BI tools (Looker, Redash)', 'Experience building systems with data governance', 'Strong Mathematics background (Linear Algebra, Statistics, Physics, Complex Variables, Calculus)']",2020-12-30 22:59:33
Data Mining Engineer Intern (Data Mining) - 2021 Summer,Bytedance,N/A,"Mountain View, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Enable and contribute to establishing fast and continuous threat response, in partnership with product risk operations, by building advanced analytics systems and data mining insights;', 'Enable and contribute to establishing robust and powerful automated defense, in partnership with Machine Learning peers, by creating and improving risk prevention rules and models;', 'Currently pursuing a Bachelor, Master, or Ph.D. degree in Computer Science, Computer Engineering, Electrical Engineering, Statistics or other relevant majors, ability to complete an at least 12-weeks program beginning in May/June 2021', 'Solid technical / data-mining skills and ability to work with large volume data to identify and abstract abusive behavior patterns in ByteDance products (e.g. TikTok).', 'Ability to think critically and to properly communicate problem solutions to cross-functional partners in a clear, concise, and timely manner.', 'Research background on relevant data mining topics about social platform communities. E.g. Botnet, interest group mining, fraud detection.', 'Basic understanding of Machine Learning, e.g. natural language processing, gradient boost decision trees, graph embedding, and/or popular neural net topics.', 'Applications will be reviewed on a rolling basis and we encourage you to apply early;', 'Interview starts in Dec 2020.']",2020-12-30 22:59:33
Software Engineer,Listrak,3.5 out of 5 from 4 employee ratings,"King of Prussia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Advanced Knowledge of Microsoft .NET framework, C#, VB.NET, ASP.NET, jQuery, JavaScript, HTML, CSS, XML as well as testing these technologies', '4+ years professional development experience', ""Bachelor's Degree in Computer Science or related work experience"", 'An understanding of Agile Development Methodology (Scrum)', 'Proficient experience with MS SQL Server.', 'Experience with Visual Studio / TFS / Git or similar version control system', 'Working knowledge of Big Data technologies such as Hadoop, Hive, HDFS, HBase, Oozie, Impala, MongoDB or similar technologies a plus']",2020-12-30 22:59:33
Data Engineer,St. Luke's Health System,3.3 out of 5 from 200 employee ratings,"Boise, ID","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Education: Bachelor's degree or 4 years of relevant experience in lieu of degree"", 'Experience: Minimum of 4 years related experience', 'Design, implement, and maintain data management capabilities including data models, ETL processes, and data architecture requirements.', 'Build cross functional relationships with data analytic teams and business leaders to understand information needs, data flows, and data quality considerations to enable solution deployment.', 'Utilize data quality techniques for data validation, unit testing, and automated integration testing. Implement frameworks for automated and scripted testing.', 'Contribute to improving solution stability, reliability, efficiency, and quality.', 'Work with architects to implement solutions in alignment with standards.', 'Test new software products/updates; working with other members of the Master Data Management team and business partners to improve usability and recommend improvements.', 'Identify technical solutions that achieve efficiency and effectiveness and enable data usage as a strategic, business asset.', 'Strong SQL experience, writing queries and stored procedures', 'Experience with database management systems including performance optimization, tuning, and security', 'Capability to develop data warehouse data models', 'Development experience with Microsoft SQL Server Integration Services', 'Exposure to data warehousing methodologies', 'Some experience with REST and .NET preferred', 'St. Luke’s is an equal opportunity employer and does not discriminate against any person on the basis of race, religion, color, gender, gender identity, sexual orientation, age, national origin, disability, veteran status, or any other status or condition protected by law.']",2020-12-30 22:59:33
Data Engineer,Excella,4.4 out of 5 from 11 employee ratings,"Arlington, VA 22201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Developing and managing data processes to ensure that data is available and usable', 'Creation and automation of data pipelines and platforms', 'Managing and monitoring data quality via automated testing frameworks (Data Driven Testing, TDD, etc.)', 'Working closely with Architects, Data Scientists, and DevOps to design, build, test, deliver, and maintain sustainable and highly scalable data solutions', 'Researching data acquisition and evaluating suitability', 'Integration of data management solutions into client environment', 'Actively managing risks to data and ensuring there is a data recovery plan', 'Building data repositories such as: data warehouses, data lakes, and operational data stores, etc.', '3+ years relevant professional work experience.', 'Experience and expertise in the following:', 'Project experience using the Scrum or Kanban framework.', 'Professionalism; to include written and oral communication – the ability to communicate collaboratively in front of a whiteboard. An ability to understand your audience and adjust your communication style to fit', 'Aptitude and desire for learning new technologies.', 'Technically savvy, entrepreneurial spirit who thrives in environments that reward self-initiative and resourcefulness.', ""You'll work with great people who love what they do: our team includes published authors, certified trainers, and internationally renowned speakers."", 'We have a ""bring your own device"" workplace and will share the cost of a new computer of your choice - Mac or PC. It\'s up to you.', ""We'll invest in your career by providing 3 days of paid professional development every year, including travel and registration fees to attend classes and conferences, in addition to tuition assistance for degrees and certifications."", 'Starting day one, every employee is bonus eligible and receives 15 days of paid vacation, 6 federal holidays, and 4 floating holidays.', 'You can bike, drive, or metro to work - our commute reimbursement plan has you covered.', ""You'll have fun! We hold monthly social events all year long, including a summer event for you and your family.""]",2020-12-30 22:59:33
VP Big Data Java Software Engineer,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Wilmington, DE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'BS/BA degree or equivalent experience', 'Expertise in application, data and infrastructure architecture disciplines', 'Advanced knowledge of architecture, design across all systems', 'Knowledge of industry wide technology strategies and best practices', 'Keen understanding of financial control and budget management', 'Excellent analytical communication. Organizational and problem solving skills coupled with strong work ethic.', 'Proficient in one or more programming languages - Java, Python, Scala and open to learning additional.', 'Current hands on experience with Java/Spark programming', 'Experience with Hadoop ecosystem technology stacks as Spark, Pig and Hive is essential', 'Data warehouse application management experience with full development lifecycle from inception through implementation.', 'Data Governance applications- Metadata,', 'Experience with development, deployment and support of large scale distributed applications in a mission critical production environment']",2020-12-30 22:59:33
Data Engineer,BasisPath,N/A,"Herndon, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 22:59:33
Software Engineer Intern,LOCKHEED MARTIN CORPORATION,"4 out of 5 from 8,473 employee ratings","King of Prussia, PA 19406","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Java', 'Python', 'C++', 'Javascript Frameworks', 'Docker', 'Mean Stack (Mongo, Express, Angular, Node)', 'Analyze user requirements to derive software design and performance requirements', 'Design and code new software or modify existing software to add new features', 'Debug existing software and correct defects', 'Integrate existing software into new or modified systems or operating environments', 'Develop simple data queries for existing or proposed databases or data repositories', 'Provide recommendations for improving documentation and software development process standards']",2020-12-30 23:01:14
"Data Center Capacity Engineer, Intern",Facebook,4.2 out of 5 from 602 employee ratings,"New Albany, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Responsible for assisting the planning and technical execution of projects throughout the Data Center', 'Perform hands on troubleshooting and repair of server hardware, software, and network circuits', 'Provide cross functional data center support and identify potentially larger issues, displaying effective communication when something is identified.', 'Manage and update work assignments through our internal task tools and repair ticketing systems', 'Maintain asset database and related documentation for installed server infrastructure', 'Work cross-functionally to plan and execute on projects and manage operational incidents', 'Currently has, or is in the process of obtaining, a BS or MS in Computer Science, Engineering, Telecommunications, or a related technical discipline', 'Basic proficiency in UNIX/Linux and hardware fundamentals', 'Ability to pick up new concepts around network design and management', 'Ability to communicate cross-functionally and solve problems under pressure', 'Detail oriented with strong troubleshooting and analytical skills', 'Ability to lift/move 30-40 pounds on a daily basis', 'Must obtain work authorization in the country of employment at the time of hire, and maintain ongoing work authorization during employment']",2020-12-30 23:01:14
Data Engineer Role,SPR Software systems LLC,N/A,"San Antonio, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop & implement ETL/ELT processes for Cloud Datawarehouse platform Snowflake', 'Ability to understand legacy DataStage ETL components and rewrite them into SQLs and DBT (Data Build Tool) components', 'Work closely with other data engineering teams to ensure alignment of methodologies and best practices', ""Bachelor's Degree or master’s degree in Computer Science."", '10+ years of hands-on software engineering experience.', '5+ years of strong ETL experience on either DataStage, Informatica, Ab-Initio, Talend etc.', 'Experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS', 'Strong database fundamentals including SQL, performance and schema design.', 'Proficiency in SQL coding', 'Ability to interpret/write custom shell scripts. Python scripting is a plus.', 'Experience with AWS platform and Snowflake CDW platform big plus', 'Experience with Git.', 'To be able to work in a fast-paced agile development environment', '8 hour shift']",2020-12-30 23:01:14
Data Engineer - Experience Management,Deloitte,"4 out of 5 from 9,921 employee ratings","New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Interface with clients to gather requirements, map solutions, and make recommendations', 'Lead customer project conference calls or interface with project manager', 'Create technical specifications to drive development of the solution', 'Deliver technical specifications documents for customer review', 'Design custom development solutions that meet customer requirements', 'Progress through full development lifecycle for custom solution', 'Deploy new solutions to production environments', 'Maintain and support new and existing solutions and frameworks', 'Innovate on new ideas to solve customer needs and assist to market internally new solutions', 'Provide project estimates and timelines to drive new business', 'Partnership and collaboration with sales and other internal teams', 'Teaming with engagement managers to communicate project status, risk and issues to clients as appropriate', 'Engaging cloud solution engineers and other domain-specific SMEs (Adobe, Salesforce, Oracle, Google and similar) to support platform implementation as needed', 'Coordinating Testing/SIT/UAT activities as required by project scope and team structure', 'Unify disparate data sources in initial phase of engagements', 'Vet, type check, transform data sources before consumption by data scientists', 'Build automation between engagements to ease the above, in collaboration with our product engineers', 'Cross-channel customer engagement strategy, design and development (web, mobile, social, physical)', 'eCommerce strategy, implementation and operations', 'Marketing Content and digital asset management solutions', 'Marketing Technology and Advertising Technology solutions', 'Marketing analytics implementation and operations', 'Advertising campaign ideation, development and execution', 'Acquisition and engagement campaign ideation, development and execution', 'Agile based, design-thinking, user-centric, empirical projects that accelerate results', '3+ years experience in ETL development using Big Data Technologies', '3+ years experience in building large-scale data processing projects using cloud technologies', '3+ years experience with data modeling and tuning of relational as well as NoSQL datastores', 'Experience with Programming and Scripting Languages (.NET, Python, Powershell, Java, Batch, Bash and similar)', 'Industry experience as a data engineer or related specialty (software engineer, application developer)', 'Experience building/operating highly scalable, fault tolerant, distributed systems for extraction, ingestion and processing of large data sets', 'Experience with software engineering best-practices, including but not limited to version control, CICD, automated unit testing', 'Track record of being able to deploy in production across multiple tech stacks', 'Ability to understand, apply, and implement API frameworks', 'Experience using cloud-native tools and design patterns', 'Degree in computer science, engineering, or relevant industry experience', 'Excellent interpersonal skills and the ability to articulate complex technology concepts with technical and non-technical individuals', 'Ability to approach a technical solution to solve for challenges from a business perspective', 'Understanding and experience working with customer centric data and how to define uses for this data to enable business goals', 'Understanding of the full SDLC process', 'Travel up to 25% (while up to 25% of travel is a requirement of the role, due to COVID-19, non-essential travel has been suspended until further notice)', 'Limited immigration sponsorship may be available', 'Experience and knowledge with marketing cloud solutions', 'Experience and knowledge with web analytics or digital marketing', 'Experience working with public cloud offerings (AWS, Azure, Google Cloud Platform, and similar)GCP - (Cloud Functions, Composer, SQL, Storage, Dataproc, Datastore, Kubernetes, Big Query, Stackdriver, Pub/Sub)AWS – (Lambda, Glue, Data Pipeline, Redshift, Aurora, Athena/Spectrum, S3/Glacier, Fargate, Cloud Watch, Kinesis)Azure - (Functions, Batch, Blob Storage, Data Warehouse, Data Factory, Containers, Monitor, Service Bus)Experience and knowledge with data science, ML/AI, R, or Jupyter', 'Experience and knowledge with customer data platforms or demand side platforms', 'Experience as an enterprise technical or engineer consultant', 'Experience using C#, Java or Python', 'Experience with Martech/Adtech tools and how to integrate technologies into the data management solution. (Adobe, Salesforce, Oracle, Google, and similar)', 'Git (Github or Gitlab)', 'CI/CD Tools - Jenkins, Github Actions, similar', 'Docker experience a strong plus', 'Good Linux + macOS experience', 'Tecton.ai, Algorithmia.io, ReviewNB, Grafana', 'Familiarity with machine learning libraries', 'Well-versed in (or contributes to) data-centric open source projects', 'Reads Hacker News, blogs, or stays on top of emerging tools in some other way', 'Data visualization', 'Industry-specific marketing data']",2020-12-30 23:01:14
Senior Data Engineer,Kamis,N/A,"McLean, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Minimum of 5+ years experience with SQL development demonstrating a mastery of use.', '5-8 years experience working with data in a variety of capacities – analyst, developer, report development', 'Hands-on experience with at least one of the following Databases (SqlServer, Oracle, Snowflake)', 'Ability to create reports using PowerBi or other industry leading Business Intelligence Software', 'Experience with ETL/ELT tools such as SSIS, Azure Data Factory, Pentaho, Talend, etc', 'Dev-ops experience using GIT, developing, deploying code to production', 'Proficient in working in Unix/Linux as well as Windows server environment', 'Proficient in using Azure Cloud Services such as Azure Data Factory, key vaults, service bus, logic apps, power automate, etc', 'Proficient in programming in Python/shell or other scripting languages for the purpose of data movement', 'Make major contributions in setting the foundation for ETL/ELT framework for Data Analytics Team', 'Design and develop pipelines to bring data into and send data from our Data warehouse to other analytical solutions', 'Support existing pipelines and troubleshoot issues as they arise.', 'Create and maintain PowerBI apps, reports, dashboards that assist various departments and communities to use analytics to increase organizational efficiencies and help improve senior care.', 'Improve governance of our data assets including our PowerBi Datasets, Dataflows.', 'Taking a lead role in selection/creation of data catalog for all data assets.', 'Is an active and influential technical leader and a recognized data expert within the department.', 'Partners closely with department peers to ensure holistic data solutions for our data science community and analytic users.', 'Identifies new areas of data, research and data technology that can solve business problems', 'Utilize effective project planning techniques to break down complex projects into tasks, manage the scope of projects, and ensure deadlines are kept', 'Leverages, contributes and uses data best practices / lessons learned to develop technical solutions used for descriptive analytics, ETL, predictive modeling, and prescriptive “real time decisions” analytics', 'Develops technical solutions using data techniques in data & analytics processes.', 'Develops and builds frameworks/prototypes that integrate data and advanced analytics to make business decisions.', 'Implements new areas of data technologies, (ingestion, processing, distribution) and research delivery methods that can solve business problems.', 'Understands the data related problems and requirements to identify the optimal technical approach.', 'Works with peers to ensure efforts within owned tracks of work will meet their needs.', 'Identifies and develops data sources & techniques to solve business problems.', 'Co-mingles data sources to lead work on data and problems across departments to drive improved business & technical results through designing.', 'Bachelor’s degree in Computer Science or Information Technology or equivalent experience']",2020-12-30 23:01:14
Voice Data Communications Engineer,Caelum Research Corporation,3.5 out of 5 from 22 employee ratings,"Aberdeen, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Serve as part of a team supporting 40+ VTC/SVTC systems. Responds to telephone calls, email and personnel requests for technical support.', 'Setup, operation, troubleshoot issues & maintain video teleconferencing (VTC) equipment. Knowledge of audio and video equipment including microphones, connecting wires and cables, sound speakers and related electronic equipment for internal rehearsals & retirement ceremonies.', 'Responds and follows-up on customer support problems & troubleshooting of VTC equipment issues.', 'Provide administrative support to include coordination, scheduling and maintaining Microsoft calendars for VTC/SVTC’s.', 'Associate’s Degree and 3 years experience; Bachelor’s Degree and 1 year experience; or 3 years experience and 2 years specialized training; or 5 years experience.', 'Must possess DISA DVS Level II Certification or equivalent certification']",2020-12-30 23:01:14
Data Platform Engineer,Coinbase,4.4 out of 5 from 7 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build out and operate our foundational data infrastructure: storage (cloud data warehouse, S3 data lake), orchestration (Airflow), processing (Spark, Flink), streaming services (AWS Kinesis & Kafka), BI tools (Looker & Redash), graph database, and real-time large scale event aggregation store.', 'Build the next iteration of our ingestion pipeline for scale, speed, and reliability. Read from a variety of upstream systems (MongoDB, Postgres, DynamoDB, MySQL, APIs), in both batch and streaming fashion, including change data capture. Make it self-service for non-engineers.', 'Build and evolve the tools that empower colleagues across the company to access data and build reliable and scalable transformations. This includes UIs and simple frameworks for derived tables and dimensional modeling, APIs and caching layers for high-throughput serving, and SDKs for the orchestration of complex Spark and Flink pipelines.', 'Build systems that secure and govern our data end to end: control access across multiple storage and access layers (including BI tools), track data quality, catalogue datasets and their lineage, detect duplication, audit usage and ensure correct data semantics.', 'Exhibit our core cultural values: positive energy, clear communication, efficient execution, continuous learning', 'Experience building data backend systems at scale with parallel/distributed compute', 'Experience using data tools and frameworks like Airflow, Spark, Flink, Hadoop, Presto, Hive, or Kafka', 'Experience with Python, Go and/or Java/Scala', 'A data-oriented mindset', 'Knowledge of SQL', 'Experience building API layers and microservices', 'Experience with AWS, and especially EMR, S3, Glue, Kinesis, IAM', 'Computer Science or related engineering degree', 'A resume that describes scalable systems you’ve built']",2020-12-30 23:01:14
Data Engineer,Adobe,4.3 out of 5 from 693 employee ratings,"Lehi, UT 84043","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with Data architects, Enterprise architects, Solution consultants and Product engineering teams to capture customer data integration requirements, conceptualize solutions & build required technology stack', ""Collaborate with enterprise customer's engineering team to identify data sources, profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating customer data sources and third party data sources with Adobe solutions"", 'Develop new features and improve existing data integrations with customer data ecosystem', 'Encourage team to think out-of-the-box and overcome engineering obstacles while incorporating new innovative design principles.', 'Collaborate with a Project Manager to bill and forecast time for customer solutions', 'Proven experience in building/operating/maintaining fault tolerant and scalable data processing integrations using AWS', '3+ years experience in Python programming language', 'Software development experience working with Apache Airflow, Spark, MongoDB, MySQL', 'Experience using Docker or Kubernetes is a plus', 'BS/MS degree in Computer Science or equivalent industry experience', 'Ability to identify and resolve problems associated with production grade large scale data processing workflows', 'Excellent communication skills (we’re a geographically distributed team)', 'Experience creating and maintaining unit tests and continuous integration.', 'Passion for creating I ntelligent data pipelines that customers love to use', 'Strong capacity to manage numerous projects are a must']",2020-12-30 23:01:14
Senior Data Engineer,West Creek Financial,4 out of 5 from 19 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop, test, and deploy data pipelines and use case driven data sets that meet critical business needs, both operational and analytical', 'Engage with the data analyst community to train and guide them on engineering best practices and new development patterns', 'Conduct research and on emerging technologies, approaches, and best practices to incorporate into the data environment', 'Design and build modern and traditional data warehousing solutions for business intelligence consumption', 'Partner closely with stakeholders to understand requirements and create consensus on approach and outcomes', 'Model business and application processes based on findings through use case scenarios, workflow diagrams, and data models.', 'Provide guidance and mentor new/junior members of the team.', 'Lead in the preparation and documentation of data process requirements and specifications.', 'Lead other data consumers in conceptualizing and developing new data solutions', 'Exceptional analytical, conceptual, and problem-solving abilities', 'Highly self-motivated and directed, with keen attention to detail', 'Ability to drive towards outcomes that meet stakeholder needs', 'Skilled at performing research into emerging technologies and trends, standards, and products', 'Proven experience in development of complex projects including technical design and analyzing requirements', 'Strong knowledge of scrum/agile software development process', 'Expert in building data pipelines in a production environment that supports critical data output', 'Experience and exposure to a variety of ETL/ELT tools and approaches', 'Experience with construction or maintenance of modern or traditional data warehouse environments', 'Expert knowledge of ANSI-SQL (T-SQL also helpful)', 'Experience with Python, Apache Spark library or other programming language', 'Experience with managing services within any of the major cloud providers: AWS (preferred), Azure, or GCE', 'Experience building solutions with Snowflake, dbt, and Stitch Data (or similar technologies)', 'Experience with source control tools such as Git, and familiarity with CICD concepts', 'Four-year college or university program certificate in Computer Science/Engineering or Information Systems; or 5+ years related experience and/or training; or equivalent combination of education and experience.', '5+ years hands experience designing and developing enterprise data solutions', '2+ years experience owning outcomes and driving results']",2020-12-30 23:01:14
Data Engineer,B12,4.1 out of 5 from 7 employee ratings,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'We build our product on Python/Django and JavaScript/React.', ""We store blobs in Amazon's S3, munch on them in Amazon's EC2, develop in Docker, and deploy containers to Amazon's Elastic Beanstalk."", 'We believe Postgres should be the first system you consider when you think about persisting structured data.', ""We religiously clean and centralize data in Amazon's Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!"", 'Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.', 'We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.', ""We set up continuous integration and deployment because, while this model comes with its own pains, we've disliked being on fixed release schedules on previous projects."", 'We like to move fast and support point-in-time recovery :).', 'Collaborate with operational teams including sales, marketing, and customer success.', ""Contribute to infrastructure that enables and informs B12's analytical efforts."", 'Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.', 'Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.', 'Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.', 'You are fluent in SQL and Python.', 'You have experience building and using data infrastructure, including systems like Postgres and Redshift.', ""You've used reporting tools like Metabase, Tableau, or Looker in the past."", 'You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.', ""You've contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse."", 'You feel comfortable managing your time and deciding amongst competing priorities.', 'You have worked with non-engineering teams and are comfortable explaining technical solutions to them.', 'You are passionate about the future of work.', 'You enjoy learning and teaching.', 'You have strong written and verbal communication skills in English.', 'You care about and want to contribute to our mission of helping people do meaningful work.', ""We don't have a minimum number of years of experience for this role. We highly favor talent and interest."", ""Some candidates may see this list and feel discouraged because they don't match all the items. Please apply anyway: there's a good chance you're more wonderful than you think you are."", 'B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.', 'A pointer to your CV, resume, LinkedIn profile, or any other summary of your career so far.', 'Some informal text introducing yourself and what you are excited about.', ""If you have a profile on websites like GitHub or other repositories of open source software, you can provide that as well. If you don't have one, it's still very possible for us to get along just fine!""]",2020-12-30 23:01:14
Senior Data Engineer,Softvision,3.7 out of 5 from 20 employee ratings,"Buffalo, NY","['Participate in detailed technical design, development, implementation and support of Data applications.', 'Develop, construct, test, automate and maintain Data Pipeline for enterprise and non-enterprise platforms', 'Maintain standards compliance and ensure development artifacts are in alignment with patterns/ frameworks designed by software engineering teams.', 'Experience in solving the business problem with the right Data architecture', 'Identify ways to improve data reliability, efficiency and quality', 'Use large data sets to address business issues', 'Prepare data for predictive and prescriptive modeling', 'Leverage data to discover tasks that can be automated', 'Deliver updates to stakeholders based on analytics', 'Familiarity with spark programming paradigms (batch and stream-processing)', 'Understanding of different data abstraction objects used in spark for different use cases, use of optimal data format and other optimization techniques.', 'Strong programming skills in at least one of the following languages: Java, Scala. Familiarity with a scripting language like Python as well as Unix/Linux shells.', 'Strong knowledge of writing optimized Spark & Hive sql and experience to tune poor performing queries.', 'Outstanding programming and debugging skills. Strong knowledge of common algorithms and data structures.', 'Good understanding of job scheduling and workflow orchestration through enterprise scheduling tools preferably CA-Automic or Control-M.', 'Strong experience with SQL and relational databases like PostgreSQL, MySQL, Teradata, SQL Server and Oracle.', 'Should be experienced in Data wrangling', 'Should have analytical background to find hidden patterns using data', 'Have a good understanding on Data modelling concepts.', 'Familiarity with one or more stream processing / queuing technologies like Spark Streaming, Kafka, Kinesis, Flink, etc. preferred.', 'Familiarity and prior experience with Agile / Scrum development methodologies.', 'Prior Experience deploying to cloud platforms, preferably Azure or AWS Cloud', 'Familiarity with any Object-Oriented Programming language', 'Prior experience in Continuous Integration/Continuous Delivery tools and pipelines such as Jenkins, Maven, Gradle, etc.', 'Experience working in a Regulated industry is preferred.', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Relocation assistance', '8 hour shift', 'Monday to Friday', 'One location', 'Temporarily due to COVID-19']",2020-12-30 23:01:14
Data Scientist,kraken,3.9 out of 5 from 25 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with product, engineering, marketing, finance and other relevant stakeholders to identify, prioritize, and answer the most important questions where analytics and modeling will have a material impact.', 'Drive cross functional analytic projects from beginning to end: build relationships with partner teams, frame and structure questions, collect and analyze data, summarize and present key insights in support of decision making.', 'Work with engineers to evangelize data best practices and implement analytics solutions.', 'Collaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models.', 'Communicate key results with self-serve tools (dashboards, analytics tools) for leadership and product management.', 'Develop anomaly detection, and data modelling tools to monitor key performance indicators to improve the efficiency of the products.', 'Design experiments for product teams to test hypothesis and help with idea generation and refinement.', 'Build key datasets and data pipelines using Python/ETL frameworks.', 'PhD or Masters degree in Statistics, Computer Science, Physical Sciences, Economics, Math or a related technical field.', '5+ years industry experience in data science or analytics', 'A consistent track record of performing data analysis using Python, R, and/or SQL', 'Experience using statistics and predictive analytics to solve complex business problems.', 'The versatility and willingness to learn new technologies on the job.', 'The ability to clearly communicate complex results to technical and non-technical audiences.', 'Familiarity with other data tools such as Druid, Hadoop, Tableau, Superset is a plus']",2020-12-30 23:01:14
"Data Engineer, Analytics (Product Foundation)",Facebook,4.2 out of 5 from 602 employee ratings,"Menlo Park, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Able to immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions', 'Craft optimal data processing architecture and systems for new data and ETL pipelines', 'Recommend improvements and modifications to existing data and ETL pipelines', 'Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership', 'Drive internal process improvements and automating manual processes for data quality and SLA management', 'Provide ongoing proactive communication and collaboration throughout the organization', '4+ years experience in the data warehouse space', '4+ years experience working with either a MapReduce or an MPP system', '4+ years experience with object-oriented programming languages', '7+ years experience in writing SQL and ETL processes']",2020-12-30 23:01:14
Data Engineer,Chameleon Technology,N/A,"Kirkland, WA 98033","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help to build and maintain infrastructure development and improvements using Microsoft BI stack and (eventually) AWS or other Cloud technology', 'Work with SDET to perform end-to-end data analysis and ensure data quality gaps are identified', 'Work with business/system analysts to understand business requirements for data warehouse development, enhancement, and maintenance', 'Clearly communicate and resolve issues during development, testing, and release of new code', 'Collaboratively work with other members of the Data Warehouse team, IT and Business partners', 'Work on multiple projects in parallel while managing priorities', 'Minimum 5 years development experience using PowerShell, Stored Procedure and T-SQL', 'Minimum 5 year development experience using PythonAbility to program using PowerShell, Microsoft Stored Procedure, T-SQL and Python', 'Understanding of database design, configuration, and performance tuning', 'Knowledge of data warehouse, data modelling and dimensional modelling', 'Strong analytical and organizational skills, and a great team player', 'Ability to work independently and to adapt to new and changing technologies', 'Capability to communicate effectively to technical and non-technical team members', '5+ years of hands-on data warehouse and business intelligence development experience', 'Familiarity with Cloud technology and Tableau', 'Understanding of Visual Studio Solutions and Projects', 'Understanding of HIPAA regulations', 'Familiarity with diverse kinds of healthcare and/or clinical data', 'Familiarity with Cerner and/or Epic healthcare systems', 'Familiarly with the Systems/Software Development Life Cycle', 'Experience with Agile software development']",2020-12-30 23:01:14
Data Engineer,DPR Construction,3.9 out of 5 from 158 employee ratings,"Washington, DC 20002","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Enable data access, data processing, and data products by architecting, maintaining, scaling, monitoring and securing Data Warehouse, EL & ETL system, and data pipelines and BI systems', 'Identify, design, and implement internal process improvements, automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Define and lead API integration strategies and for the enterprise', 'Implement enterprise integrations that result in a scalable, flexible, and highly available solutions that perform well under high traffic', 'Secure the movement of sensitive information in a manner consistent with company policy and management expectations', 'Control integration quality and develop ways to detect and correct anomalies with data exchange', 'Solid understanding of database engineering and design (Relational, De-normalized, Data Lakes, etc.)', 'Knowledge of AWS and Azure platforms', 'Experience in Software development.', 'Ability to understand, consume and use API’s, JSON, Webservices for Data pipelines.', 'Excellent knowledge of EL and ELT, Datawarehousing, and cloud-based tools', 'Strong with SQL development knowledge for Relational Databases', 'Business and Technical Analysis skills', 'Experience in scripting languages like Batch, Shell in Unix environment', 'Experience with integration of data from multiple data sources like API’s, JSON and any other databases, Flat-files, Spreadsheets.', 'Experience in Data Mapping, XML/JSON, and web service', 'Ability to adapt quickly to change & deep curiosity to learn new tools and technologies and apply them', 'Ability to work with and collaborate across the team and work effectively with others to identify the impact on the company’s business processes, other applications, network, etc.', 'Strong analytical and problem-solving abilities.', 'Seek and Embrace Change – Continuously improve work processes rather than accepting the status quo', 'Growth and Development – Know or learn what is needed to deliver results and successfully compete', 'Ability to work effectively with others who are in remote locations and varying time zones', 'Resourceful creative approach to problem-solving is expected', 'Strong communication skills, with the ability to work both independently and in project teams', 'Motivation to continually learn and take on added responsibilities while maintaining a positive attitude']",2020-12-30 23:01:14
Senior Data Engineer,Kamis,N/A,"McLean, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Minimum of 5+ years experience with SQL development demonstrating a mastery of use.', '5-8 years experience working with data in a variety of capacities – analyst, developer, report development', 'Hands-on experience with at least one of the following Databases (SqlServer, Oracle, Snowflake)', 'Ability to create reports using PowerBi or other industry leading Business Intelligence Software', 'Experience with ETL/ELT tools such as SSIS, Azure Data Factory, Pentaho, Talend, etc', 'Dev-ops experience using GIT, developing, deploying code to production', 'Proficient in working in Unix/Linux as well as Windows server environment', 'Proficient in using Azure Cloud Services such as Azure Data Factory, key vaults, service bus, logic apps, power automate, etc', 'Proficient in programming in Python/shell or other scripting languages for the purpose of data movement', 'Make major contributions in setting the foundation for ETL/ELT framework for Data Analytics Team', 'Design and develop pipelines to bring data into and send data from our Data warehouse to other analytical solutions', 'Support existing pipelines and troubleshoot issues as they arise.', 'Create and maintain PowerBI apps, reports, dashboards that assist various departments and communities to use analytics to increase organizational efficiencies and help improve senior care.', 'Improve governance of our data assets including our PowerBi Datasets, Dataflows.', 'Taking a lead role in selection/creation of data catalog for all data assets.', 'Is an active and influential technical leader and a recognized data expert within the department.', 'Partners closely with department peers to ensure holistic data solutions for our data science community and analytic users.', 'Identifies new areas of data, research and data technology that can solve business problems', 'Utilize effective project planning techniques to break down complex projects into tasks, manage the scope of projects, and ensure deadlines are kept', 'Leverages, contributes and uses data best practices / lessons learned to develop technical solutions used for descriptive analytics, ETL, predictive modeling, and prescriptive “real time decisions” analytics', 'Develops technical solutions using data techniques in data & analytics processes.', 'Develops and builds frameworks/prototypes that integrate data and advanced analytics to make business decisions.', 'Implements new areas of data technologies, (ingestion, processing, distribution) and research delivery methods that can solve business problems.', 'Understands the data related problems and requirements to identify the optimal technical approach.', 'Works with peers to ensure efforts within owned tracks of work will meet their needs.', 'Identifies and develops data sources & techniques to solve business problems.', 'Co-mingles data sources to lead work on data and problems across departments to drive improved business & technical results through designing.', 'Bachelor’s degree in Computer Science or Information Technology or equivalent experience']",2020-12-30 23:02:54
Voice Data Communications Engineer,Caelum Research Corporation,3.5 out of 5 from 22 employee ratings,"Aberdeen, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Serve as part of a team supporting 40+ VTC/SVTC systems. Responds to telephone calls, email and personnel requests for technical support.', 'Setup, operation, troubleshoot issues & maintain video teleconferencing (VTC) equipment. Knowledge of audio and video equipment including microphones, connecting wires and cables, sound speakers and related electronic equipment for internal rehearsals & retirement ceremonies.', 'Responds and follows-up on customer support problems & troubleshooting of VTC equipment issues.', 'Provide administrative support to include coordination, scheduling and maintaining Microsoft calendars for VTC/SVTC’s.', 'Associate’s Degree and 3 years experience; Bachelor’s Degree and 1 year experience; or 3 years experience and 2 years specialized training; or 5 years experience.', 'Must possess DISA DVS Level II Certification or equivalent certification']",2020-12-30 23:02:54
Data Platform Engineer,Coinbase,4.4 out of 5 from 7 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build out and operate our foundational data infrastructure: storage (cloud data warehouse, S3 data lake), orchestration (Airflow), processing (Spark, Flink), streaming services (AWS Kinesis & Kafka), BI tools (Looker & Redash), graph database, and real-time large scale event aggregation store.', 'Build the next iteration of our ingestion pipeline for scale, speed, and reliability. Read from a variety of upstream systems (MongoDB, Postgres, DynamoDB, MySQL, APIs), in both batch and streaming fashion, including change data capture. Make it self-service for non-engineers.', 'Build and evolve the tools that empower colleagues across the company to access data and build reliable and scalable transformations. This includes UIs and simple frameworks for derived tables and dimensional modeling, APIs and caching layers for high-throughput serving, and SDKs for the orchestration of complex Spark and Flink pipelines.', 'Build systems that secure and govern our data end to end: control access across multiple storage and access layers (including BI tools), track data quality, catalogue datasets and their lineage, detect duplication, audit usage and ensure correct data semantics.', 'Exhibit our core cultural values: positive energy, clear communication, efficient execution, continuous learning', 'Experience building data backend systems at scale with parallel/distributed compute', 'Experience using data tools and frameworks like Airflow, Spark, Flink, Hadoop, Presto, Hive, or Kafka', 'Experience with Python, Go and/or Java/Scala', 'A data-oriented mindset', 'Knowledge of SQL', 'Experience building API layers and microservices', 'Experience with AWS, and especially EMR, S3, Glue, Kinesis, IAM', 'Computer Science or related engineering degree', 'A resume that describes scalable systems you’ve built']",2020-12-30 23:02:54
Data Engineer,Adobe,4.3 out of 5 from 693 employee ratings,"Lehi, UT 84043","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with Data architects, Enterprise architects, Solution consultants and Product engineering teams to capture customer data integration requirements, conceptualize solutions & build required technology stack', ""Collaborate with enterprise customer's engineering team to identify data sources, profile and quantify quality of data sources, develop tools to prepare data and build data pipelines for integrating customer data sources and third party data sources with Adobe solutions"", 'Develop new features and improve existing data integrations with customer data ecosystem', 'Encourage team to think out-of-the-box and overcome engineering obstacles while incorporating new innovative design principles.', 'Collaborate with a Project Manager to bill and forecast time for customer solutions', 'Proven experience in building/operating/maintaining fault tolerant and scalable data processing integrations using AWS', '3+ years experience in Python programming language', 'Software development experience working with Apache Airflow, Spark, MongoDB, MySQL', 'Experience using Docker or Kubernetes is a plus', 'BS/MS degree in Computer Science or equivalent industry experience', 'Ability to identify and resolve problems associated with production grade large scale data processing workflows', 'Excellent communication skills (we’re a geographically distributed team)', 'Experience creating and maintaining unit tests and continuous integration.', 'Passion for creating I ntelligent data pipelines that customers love to use', 'Strong capacity to manage numerous projects are a must']",2020-12-30 23:02:54
Senior Data Engineer,West Creek Financial,4 out of 5 from 19 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop, test, and deploy data pipelines and use case driven data sets that meet critical business needs, both operational and analytical', 'Engage with the data analyst community to train and guide them on engineering best practices and new development patterns', 'Conduct research and on emerging technologies, approaches, and best practices to incorporate into the data environment', 'Design and build modern and traditional data warehousing solutions for business intelligence consumption', 'Partner closely with stakeholders to understand requirements and create consensus on approach and outcomes', 'Model business and application processes based on findings through use case scenarios, workflow diagrams, and data models.', 'Provide guidance and mentor new/junior members of the team.', 'Lead in the preparation and documentation of data process requirements and specifications.', 'Lead other data consumers in conceptualizing and developing new data solutions', 'Exceptional analytical, conceptual, and problem-solving abilities', 'Highly self-motivated and directed, with keen attention to detail', 'Ability to drive towards outcomes that meet stakeholder needs', 'Skilled at performing research into emerging technologies and trends, standards, and products', 'Proven experience in development of complex projects including technical design and analyzing requirements', 'Strong knowledge of scrum/agile software development process', 'Expert in building data pipelines in a production environment that supports critical data output', 'Experience and exposure to a variety of ETL/ELT tools and approaches', 'Experience with construction or maintenance of modern or traditional data warehouse environments', 'Expert knowledge of ANSI-SQL (T-SQL also helpful)', 'Experience with Python, Apache Spark library or other programming language', 'Experience with managing services within any of the major cloud providers: AWS (preferred), Azure, or GCE', 'Experience building solutions with Snowflake, dbt, and Stitch Data (or similar technologies)', 'Experience with source control tools such as Git, and familiarity with CICD concepts', 'Four-year college or university program certificate in Computer Science/Engineering or Information Systems; or 5+ years related experience and/or training; or equivalent combination of education and experience.', '5+ years hands experience designing and developing enterprise data solutions', '2+ years experience owning outcomes and driving results']",2020-12-30 23:02:54
Data Engineer,B12,4.1 out of 5 from 7 employee ratings,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'We build our product on Python/Django and JavaScript/React.', ""We store blobs in Amazon's S3, munch on them in Amazon's EC2, develop in Docker, and deploy containers to Amazon's Elastic Beanstalk."", 'We believe Postgres should be the first system you consider when you think about persisting structured data.', ""We religiously clean and centralize data in Amazon's Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!"", 'Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.', 'We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.', ""We set up continuous integration and deployment because, while this model comes with its own pains, we've disliked being on fixed release schedules on previous projects."", 'We like to move fast and support point-in-time recovery :).', 'Collaborate with operational teams including sales, marketing, and customer success.', ""Contribute to infrastructure that enables and informs B12's analytical efforts."", 'Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.', 'Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.', 'Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.', 'You are fluent in SQL and Python.', 'You have experience building and using data infrastructure, including systems like Postgres and Redshift.', ""You've used reporting tools like Metabase, Tableau, or Looker in the past."", 'You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.', ""You've contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse."", 'You feel comfortable managing your time and deciding amongst competing priorities.', 'You have worked with non-engineering teams and are comfortable explaining technical solutions to them.', 'You are passionate about the future of work.', 'You enjoy learning and teaching.', 'You have strong written and verbal communication skills in English.', 'You care about and want to contribute to our mission of helping people do meaningful work.', ""We don't have a minimum number of years of experience for this role. We highly favor talent and interest."", ""Some candidates may see this list and feel discouraged because they don't match all the items. Please apply anyway: there's a good chance you're more wonderful than you think you are."", 'B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.', 'A pointer to your CV, resume, LinkedIn profile, or any other summary of your career so far.', 'Some informal text introducing yourself and what you are excited about.', ""If you have a profile on websites like GitHub or other repositories of open source software, you can provide that as well. If you don't have one, it's still very possible for us to get along just fine!""]",2020-12-30 23:02:54
Senior Data Engineer,Softvision,3.7 out of 5 from 20 employee ratings,"Buffalo, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participate in detailed technical design, development, implementation and support of Data applications.', 'Develop, construct, test, automate and maintain Data Pipeline for enterprise and non-enterprise platforms', 'Maintain standards compliance and ensure development artifacts are in alignment with patterns/ frameworks designed by software engineering teams.', 'Experience in solving the business problem with the right Data architecture', 'Identify ways to improve data reliability, efficiency and quality', 'Use large data sets to address business issues', 'Prepare data for predictive and prescriptive modeling', 'Leverage data to discover tasks that can be automated', 'Deliver updates to stakeholders based on analytics', 'Familiarity with spark programming paradigms (batch and stream-processing)', 'Understanding of different data abstraction objects used in spark for different use cases, use of optimal data format and other optimization techniques.', 'Strong programming skills in at least one of the following languages: Java, Scala. Familiarity with a scripting language like Python as well as Unix/Linux shells.', 'Strong knowledge of writing optimized Spark & Hive sql and experience to tune poor performing queries.', 'Outstanding programming and debugging skills. Strong knowledge of common algorithms and data structures.', 'Good understanding of job scheduling and workflow orchestration through enterprise scheduling tools preferably CA-Automic or Control-M.', 'Strong experience with SQL and relational databases like PostgreSQL, MySQL, Teradata, SQL Server and Oracle.', 'Should be experienced in Data wrangling', 'Should have analytical background to find hidden patterns using data', 'Have a good understanding on Data modelling concepts.', 'Familiarity with one or more stream processing / queuing technologies like Spark Streaming, Kafka, Kinesis, Flink, etc. preferred.', 'Familiarity and prior experience with Agile / Scrum development methodologies.', 'Prior Experience deploying to cloud platforms, preferably Azure or AWS Cloud', 'Familiarity with any Object-Oriented Programming language', 'Prior experience in Continuous Integration/Continuous Delivery tools and pipelines such as Jenkins, Maven, Gradle, etc.', 'Experience working in a Regulated industry is preferred.', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Relocation assistance', '8 hour shift', 'Monday to Friday', 'One location', 'Temporarily due to COVID-19']",2020-12-30 23:02:54
Scientist or Engineer,Integral Consulting Inc.,N/A,"Annapolis, MD 21401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assisting with data preparation activities such as organizing, tracking, and summarizing environmental data sources', 'Participating in environmental sample collection activities', 'Participating in data and regulatory analysis in support of soil, groundwater, and sediment quality projects', 'Assisting with technical writing and data presentation for reports.', 'Bachelor’s or master’s degree in the natural life, environmental, or geological sciences or environmental, civil, geotechnical, or related engineering field', '0–3 years of experience', 'Strong oral and written communication skills', 'Strong quantitative skills', 'Good working knowledge of environmental science and chemistry', 'Experience with Microsoft® Office programs', 'A desire to grow intellectually and professionally.']",2020-12-30 23:02:54
Data Scientist,kraken,3.9 out of 5 from 25 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with product, engineering, marketing, finance and other relevant stakeholders to identify, prioritize, and answer the most important questions where analytics and modeling will have a material impact.', 'Drive cross functional analytic projects from beginning to end: build relationships with partner teams, frame and structure questions, collect and analyze data, summarize and present key insights in support of decision making.', 'Work with engineers to evangelize data best practices and implement analytics solutions.', 'Collaborate with business leaders, subject matter experts, and decision makers to develop success criteria and optimize new products, features, policies, and models.', 'Communicate key results with self-serve tools (dashboards, analytics tools) for leadership and product management.', 'Develop anomaly detection, and data modelling tools to monitor key performance indicators to improve the efficiency of the products.', 'Design experiments for product teams to test hypothesis and help with idea generation and refinement.', 'Build key datasets and data pipelines using Python/ETL frameworks.', 'PhD or Masters degree in Statistics, Computer Science, Physical Sciences, Economics, Math or a related technical field.', '5+ years industry experience in data science or analytics', 'A consistent track record of performing data analysis using Python, R, and/or SQL', 'Experience using statistics and predictive analytics to solve complex business problems.', 'The versatility and willingness to learn new technologies on the job.', 'The ability to clearly communicate complex results to technical and non-technical audiences.', 'Familiarity with other data tools such as Druid, Hadoop, Tableau, Superset is a plus']",2020-12-30 23:02:54
"Data Engineer, Analytics (Product Foundation)",Facebook,4.2 out of 5 from 602 employee ratings,"Menlo Park, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Able to immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions', 'Craft optimal data processing architecture and systems for new data and ETL pipelines', 'Recommend improvements and modifications to existing data and ETL pipelines', 'Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership', 'Drive internal process improvements and automating manual processes for data quality and SLA management', 'Provide ongoing proactive communication and collaboration throughout the organization', '4+ years experience in the data warehouse space', '4+ years experience working with either a MapReduce or an MPP system', '4+ years experience with object-oriented programming languages', '7+ years experience in writing SQL and ETL processes']",2020-12-30 23:02:54
Data Engineer,Chameleon Technology,N/A,"Kirkland, WA 98033","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help to build and maintain infrastructure development and improvements using Microsoft BI stack and (eventually) AWS or other Cloud technology', 'Work with SDET to perform end-to-end data analysis and ensure data quality gaps are identified', 'Work with business/system analysts to understand business requirements for data warehouse development, enhancement, and maintenance', 'Clearly communicate and resolve issues during development, testing, and release of new code', 'Collaboratively work with other members of the Data Warehouse team, IT and Business partners', 'Work on multiple projects in parallel while managing priorities', 'Minimum 5 years development experience using PowerShell, Stored Procedure and T-SQL', 'Minimum 5 year development experience using PythonAbility to program using PowerShell, Microsoft Stored Procedure, T-SQL and Python', 'Understanding of database design, configuration, and performance tuning', 'Knowledge of data warehouse, data modelling and dimensional modelling', 'Strong analytical and organizational skills, and a great team player', 'Ability to work independently and to adapt to new and changing technologies', 'Capability to communicate effectively to technical and non-technical team members', '5+ years of hands-on data warehouse and business intelligence development experience', 'Familiarity with Cloud technology and Tableau', 'Understanding of Visual Studio Solutions and Projects', 'Understanding of HIPAA regulations', 'Familiarity with diverse kinds of healthcare and/or clinical data', 'Familiarity with Cerner and/or Epic healthcare systems', 'Familiarly with the Systems/Software Development Life Cycle', 'Experience with Agile software development']",2020-12-30 23:02:54
Data Engineer,DPR Construction,3.9 out of 5 from 158 employee ratings,"Washington, DC 20002","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Enable data access, data processing, and data products by architecting, maintaining, scaling, monitoring and securing Data Warehouse, EL & ETL system, and data pipelines and BI systems', 'Identify, design, and implement internal process improvements, automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Define and lead API integration strategies and for the enterprise', 'Implement enterprise integrations that result in a scalable, flexible, and highly available solutions that perform well under high traffic', 'Secure the movement of sensitive information in a manner consistent with company policy and management expectations', 'Control integration quality and develop ways to detect and correct anomalies with data exchange', 'Solid understanding of database engineering and design (Relational, De-normalized, Data Lakes, etc.)', 'Knowledge of AWS and Azure platforms', 'Experience in Software development.', 'Ability to understand, consume and use API’s, JSON, Webservices for Data pipelines.', 'Excellent knowledge of EL and ELT, Datawarehousing, and cloud-based tools', 'Strong with SQL development knowledge for Relational Databases', 'Business and Technical Analysis skills', 'Experience in scripting languages like Batch, Shell in Unix environment', 'Experience with integration of data from multiple data sources like API’s, JSON and any other databases, Flat-files, Spreadsheets.', 'Experience in Data Mapping, XML/JSON, and web service', 'Ability to adapt quickly to change & deep curiosity to learn new tools and technologies and apply them', 'Ability to work with and collaborate across the team and work effectively with others to identify the impact on the company’s business processes, other applications, network, etc.', 'Strong analytical and problem-solving abilities.', 'Seek and Embrace Change – Continuously improve work processes rather than accepting the status quo', 'Growth and Development – Know or learn what is needed to deliver results and successfully compete', 'Ability to work effectively with others who are in remote locations and varying time zones', 'Resourceful creative approach to problem-solving is expected', 'Strong communication skills, with the ability to work both independently and in project teams', 'Motivation to continually learn and take on added responsibilities while maintaining a positive attitude']",2020-12-30 23:02:54
Data Engineer,WellNow Urgent Care,2.7 out of 5 from 99 employee ratings,"Chicago, IL 60607","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop complex ETL data loading packages.', 'Drive for and create ETL architectural and development standards.', 'Drive ETL development efforts and share knowledge capital.', 'Assist in design, architecture and development of Data Warehouse/Datamart.', 'Adhere to ETL/Data Warehouse/Datamart development best practices.', 'Identify and resolve any performance and/or data related issues', 'Analyze business requirements as a guide to data preparation and modeling', 'Build data models with the flexibility to change when business requirements change', 'Provide documentation (Data Mapping, Technical Specifications, Production Support, data dictionaries, test cases, etc.)', 'Provide Production Support of Data Warehouse as well as ETL jobs used to support the Data Warehouse.', 'Provide support for stakeholders, analysts and report creators.', 'Perform duties & responsibilities specific to department functions & activities and any other assigned task by reporting manager.', 'Bachelor’s degree in Information Technology, Management of Information Systems, or a related field', '5+ Years of experience with MS SQL Server Integration Services (SSIS)', '5+ Years of experience with MS SQL Server Reporting Services (SSRS)', '3+ Years of experience with MS SQL Server Database Design/Development', '3+ Years of Data Warehousing Experience', 'Experience implementing and supporting Enterprise Level Data Warehouse', '2+ Years of experience with MS SQL Server Analytical Services (SSAS)', 'Expert Microsoft SQL Development (T-SQL)', 'Experience in Data Modeling (Erwin, Power designer, etc.)', 'Strong Understanding of Agile Data Warehouse Development, data modeling and data classification', 'Advance knowledge of performance tuning related to ETL Development', 'Strong experience with Source Control (TFS, RedGate, etc.)', 'Strong experience with job automation tools (Autosys, Tidal, BMC, etc.)', 'Strong experience with SQL Server Management Studio & BIDS', 'Strong Leadership, communication (verbal & written) and problem-solving skills', 'Business analyst experience helpful', 'Results/Goal oriented', 'Ability to handle multiple projects and manage time efficiently']",2020-12-30 23:02:54
Data Engineer,HDR,3.8 out of 5 from 351 employee ratings,"Omaha, NE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'HDR’s Data-driven Design (D3) Team is a key component of the Architecture Business Group responsible for supporting the planning phase of projects. As a Data Engineer, you will be responsible for the ETL process, cleaning and warehousing of data. You will be expected to provide strategic input and develop enhancements to HDR’s proprietary databases and data pipelines. You must be comfortable working in a fast-paced environment, with ability to derive requirements independently. This position reports to the Vice President of HDR Consulting and is a key member of the D3 team.', 'Collaborate with a team of data/analytics experts and subject matter experts to solve company and client problems using data;', 'Design and develop data warehouse for ease of use, organization, accessibility, security, regulatory (HIPAA, FERPA, etc.) compliance, performance, scalability, monitoring, and availability;', 'Clean, transform, aggregate and integrate data into data warehouse;', 'Design and develop ETL system and data pipelines that move data from a variety of sources into warehouse, monitor data quality, check for errors and conform data to standards;', 'Build Database objects (tables, views, stored procedures, functions, etc.) and data services that provide data in format most useful for analysis and predictive modeling;', 'Maintain data pipelines, architecture and schemas to maximize the (re-)usability, accuracy, robustness, performance, and scalability;', 'Source data from public sources such as web services (e.g. REST APIs), files (CSV, xlsx, xml, etc.) and web pages (e.g. web scraping);', 'Create and maintain documentation, data governance policy and metadata repository to ensure the accuracy, validity, reusability, and consistency;', 'Learn and evaluate 3rd party data tools, develop in-house data tools, and train team on use;', 'Stay abreast of trends and new developments in data technology;', 'Contribute to strategy and roadmap for Predictive Analytics;', 'Work to understand the needs of Data Scientists, develop and document data objects to anticipate the needs of Data Scientists and Data Analysts;', 'Work iteratively without complete specifications to solve complex problems involving challenging data sets with little to no guidance or direction.', ""Bachelor's degree in computer science, engineering, mathematics, statistics, management information systems or related field required;"", 'Master’s degree in similar field preferred;', 'Minimum two (2) years related experience preferred', 'Experience working with health care data is preferred', 'Has extensive knowledge of database technology, best practices and patterns;', 'Knowledge of and experience with dimensional data modeling and data warehousing;', 'Has experience building data pipelines and ETL systems;', 'Independent worker able to manage multiple projects and priorities;', 'Advanced analytical thinking and problem solving skills;', 'Strong communication skills with the ability to compile and present information;', 'A high level performer and self-starter with a strong customer service focus;', 'Comfortable working with clients to make data requests and resolve issues with client data;', 'Must work responsibly with confidential and private information;', 'Potential travel up to 25%. Passport required;', 'Microsoft SQL Server; SSIS or other ETL tools such as Informatica; R, Tableau, Power BI', 'Why HDR']",2020-12-30 23:02:54
Data Engineer,Rock Central,5 out of 5 from 2 employee ratings,"Detroit, MI 48226","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's degree in computer science, information technology, or a related field or equivalent experience"", '3 years of experience working with database tools', '3 years of programming experience using Python and C#', '3 years of experience working with SQL server integration services or ETL tools', '3 years of experience working with data integration tools', 'Proficiency in the Microsoft Office suite', 'Experience working with ETL tools', 'Knowledge of data integration tools', 'Software programming languages, such as Python and C#', 'Design and support the new and evolving sources of data being brought into the data warehouse', 'Work closely with data architects and follow best practices for data management consumption', 'Work closely with business analysts to work through business requirements and develop processes to provide the needed data visibility via the data warehouse and reporting platform', 'Model application layer and metadata design', 'Design and create automated applications and reporting solutions', 'Work closely with front-end developers to ensure data is being brought in and data integrity is being maintained', 'Monitor and troubleshoot performance issues on the data warehouse servers']",2020-12-30 23:02:54
Data Engineer,WellNow Urgent Care,2.7 out of 5 from 99 employee ratings,"Chicago, IL 60607","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop complex ETL data loading packages.', 'Drive for and create ETL architectural and development standards.', 'Drive ETL development efforts and share knowledge capital.', 'Assist in design, architecture and development of Data Warehouse/Datamart.', 'Adhere to ETL/Data Warehouse/Datamart development best practices.', 'Identify and resolve any performance and/or data related issues', 'Analyze business requirements as a guide to data preparation and modeling', 'Build data models with the flexibility to change when business requirements change', 'Provide documentation (Data Mapping, Technical Specifications, Production Support, data dictionaries, test cases, etc.)', 'Provide Production Support of Data Warehouse as well as ETL jobs used to support the Data Warehouse.', 'Provide support for stakeholders, analysts and report creators.', 'Perform duties & responsibilities specific to department functions & activities and any other assigned task by reporting manager.', 'Bachelor’s degree in Information Technology, Management of Information Systems, or a related field', '5+ Years of experience with MS SQL Server Integration Services (SSIS)', '5+ Years of experience with MS SQL Server Reporting Services (SSRS)', '3+ Years of experience with MS SQL Server Database Design/Development', '3+ Years of Data Warehousing Experience', 'Experience implementing and supporting Enterprise Level Data Warehouse', '2+ Years of experience with MS SQL Server Analytical Services (SSAS)', 'Expert Microsoft SQL Development (T-SQL)', 'Experience in Data Modeling (Erwin, Power designer, etc.)', 'Strong Understanding of Agile Data Warehouse Development, data modeling and data classification', 'Advance knowledge of performance tuning related to ETL Development', 'Strong experience with Source Control (TFS, RedGate, etc.)', 'Strong experience with job automation tools (Autosys, Tidal, BMC, etc.)', 'Strong experience with SQL Server Management Studio & BIDS', 'Strong Leadership, communication (verbal & written) and problem-solving skills', 'Business analyst experience helpful', 'Results/Goal oriented', 'Ability to handle multiple projects and manage time efficiently']",2020-12-30 23:04:34
Data Engineer,HDR,3.8 out of 5 from 351 employee ratings,"Omaha, NE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'HDR’s Data-driven Design (D3) Team is a key component of the Architecture Business Group responsible for supporting the planning phase of projects. As a Data Engineer, you will be responsible for the ETL process, cleaning and warehousing of data. You will be expected to provide strategic input and develop enhancements to HDR’s proprietary databases and data pipelines. You must be comfortable working in a fast-paced environment, with ability to derive requirements independently. This position reports to the Vice President of HDR Consulting and is a key member of the D3 team.', 'Collaborate with a team of data/analytics experts and subject matter experts to solve company and client problems using data;', 'Design and develop data warehouse for ease of use, organization, accessibility, security, regulatory (HIPAA, FERPA, etc.) compliance, performance, scalability, monitoring, and availability;', 'Clean, transform, aggregate and integrate data into data warehouse;', 'Design and develop ETL system and data pipelines that move data from a variety of sources into warehouse, monitor data quality, check for errors and conform data to standards;', 'Build Database objects (tables, views, stored procedures, functions, etc.) and data services that provide data in format most useful for analysis and predictive modeling;', 'Maintain data pipelines, architecture and schemas to maximize the (re-)usability, accuracy, robustness, performance, and scalability;', 'Source data from public sources such as web services (e.g. REST APIs), files (CSV, xlsx, xml, etc.) and web pages (e.g. web scraping);', 'Create and maintain documentation, data governance policy and metadata repository to ensure the accuracy, validity, reusability, and consistency;', 'Learn and evaluate 3rd party data tools, develop in-house data tools, and train team on use;', 'Stay abreast of trends and new developments in data technology;', 'Contribute to strategy and roadmap for Predictive Analytics;', 'Work to understand the needs of Data Scientists, develop and document data objects to anticipate the needs of Data Scientists and Data Analysts;', 'Work iteratively without complete specifications to solve complex problems involving challenging data sets with little to no guidance or direction.', ""Bachelor's degree in computer science, engineering, mathematics, statistics, management information systems or related field required;"", 'Master’s degree in similar field preferred;', 'Minimum two (2) years related experience preferred', 'Experience working with health care data is preferred', 'Has extensive knowledge of database technology, best practices and patterns;', 'Knowledge of and experience with dimensional data modeling and data warehousing;', 'Has experience building data pipelines and ETL systems;', 'Independent worker able to manage multiple projects and priorities;', 'Advanced analytical thinking and problem solving skills;', 'Strong communication skills with the ability to compile and present information;', 'A high level performer and self-starter with a strong customer service focus;', 'Comfortable working with clients to make data requests and resolve issues with client data;', 'Must work responsibly with confidential and private information;', 'Potential travel up to 25%. Passport required;', 'Microsoft SQL Server; SSIS or other ETL tools such as Informatica; R, Tableau, Power BI', 'Why HDR']",2020-12-30 23:04:34
Data Engineer,Rock Central,5 out of 5 from 2 employee ratings,"Detroit, MI 48226","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's degree in computer science, information technology, or a related field or equivalent experience"", '3 years of experience working with database tools', '3 years of programming experience using Python and C#', '3 years of experience working with SQL server integration services or ETL tools', '3 years of experience working with data integration tools', 'Proficiency in the Microsoft Office suite', 'Experience working with ETL tools', 'Knowledge of data integration tools', 'Software programming languages, such as Python and C#', 'Design and support the new and evolving sources of data being brought into the data warehouse', 'Work closely with data architects and follow best practices for data management consumption', 'Work closely with business analysts to work through business requirements and develop processes to provide the needed data visibility via the data warehouse and reporting platform', 'Model application layer and metadata design', 'Design and create automated applications and reporting solutions', 'Work closely with front-end developers to ensure data is being brought in and data integrity is being maintained', 'Monitor and troubleshoot performance issues on the data warehouse servers']",2020-12-30 23:04:34
"Software Engineer, Data",Ribbon Health,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Passion and drive to simplify healthcare by building products that increase access to care and power every healthcare decision to be high-quality, cost-effective, and convenient', 'Commitment to Ribbon Health company values, working on an exceptional team, and building an exceptional company', 'Grit, hustle, desire, and a “get-it-done” attitude; strong comfort with a lean startup environment, where everyone is encouraged to participate in and contribute across all teams', 'Dedication to the creation of a diverse, equitable, and inclusive environment where teammates are celebrated for their unique perspectives and work together to simplify healthcare for all', 'You have experience designing and implementing data warehouses and ETL architecture in the cloud and are excited to leverage your experience to build from the ground up', 'You are very comfortable with SQL (Hive, Oracle, Vertica…etc.) and relational databases; Python experience would be a big plus but not required', 'You have a unique ability and passion for transforming large and complex datasets into information that is useful for real life decision making', 'You are able to break down ambiguous problems and propose clear data modeling designs', 'You have the ability to make thoughtful trade-offs between long-term scalability and moving quickly in the short-term', 'You care deeply about implementing best practices that ensure data integrity and reliability because you understand how our products meaningfully impact patients downstream', 'Helpful but not required: You have experience working with healthcare data (e.g. claims, directory, medical records)', 'Architect and build our data warehouse: You will design and build a data warehouse that will serve as the foundation for our data pipelines and machine learning', 'Scale our machine learning efforts: You will build data infrastructure to enable our machine learning engineers to deploy existing models to our production data pipeline and expand their analytics efforts', 'Build a data extraction framework: You will design and improve upon our current system of record for ingesting data from hundreds of different sources', 'Build data pipelines: You will integrate many data sources into the Ribbon data pipeline. You will set the standards by which other engineers building data pipelines will follow', 'Build light-weight automation: You will develop systems and tools to configure, monitor, and orchestrate our data infrastructure', 'Develop data standards: You will develop Ribbon’s internal standards for data management and data governance']",2020-12-30 23:04:34
Charleston - Junior Data Engineer,MSC Mediterranean Shipping Company,4 out of 5 from 439 employee ratings,"Mount Pleasant, SC 29464","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assist in all aspects of the development life cycle, including architecture, requirement gathering, development, testing, training, implementation, and support', 'Build and deliver high quality data architecture to support business analyst, data scientists, and customer reporting needs', 'Interface with other teams to extract, transform, and load data from a wide variety of data sources.', 'Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support', 'Drive the collection of new data and the refinement of existing data sources to continually improve data quality and implement business logic using efficient transformations.', 'Creates Ad Hoc reports, queries and/or analyses upon request', 'Responsible for improving data quality to increase data accuracy, viability, and value', 'Create and maintain training materials and train business end-users and power users as necessary', 'Assist in quality control and validation processes and testing efforts, providing guidance and supervision to end users to ensure adequate and thorough testing', 'Provides day to day support to the division as required to ensure the availability and performance of systems, users interface and dashboards', 'Strong data visualization skills', 'Oral Communication: Speaks clearly and persuasively; Listens and gets clarification; Responds well to questions; Demonstrates group presentation skills.', 'Analytical skills: Collects and researches data; uses intuition and experience to complement data', 'Ability to own the full cycle of dashboard development from requirement gathering and design through development and launch/support', 'Bachelor’s degree, preferably in a math, science, or technology related field of study', 'Ability to manage multiple priorities and adjust quickly', '1-2 years’ experience with Microsoft Power BI, Tableau, Looker or any other data visualization tool', 'Demonstrated knowledge of Data Visualization best practices', 'Experience with relational databases', 'SQL knowledge', 'Medical Insurance Plan', 'Dental/Vision Insurance Plan', '401K Plan – effective Day One', 'Life Insurance – one-time annual salary up to $50,000 / Separate Business Travel Insurance', 'Short Term / Long Term Disability', 'Pregnancy Disability Leave / Paid Parental Leave', 'Supplemental Benefits (Life, Disability, Accident Insurance)', 'Paid vacation & holidays', 'Annual bonus']",2020-12-30 23:04:34
Senior Data Engineer,ION IP Optical Networks,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:04:34
Data Engineer,DataDog,3.5 out of 5 from 13 employee ratings,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build distributed, high-volume data pipelines that power this core product', 'Do it with Spark, Luigi and other open-source technologies', 'Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more', 'Join a tightly knit team solving hard problems the right way', 'Own meaningful parts of our service, have an impact, grow with the company', 'You have a BS/MS/PhD in a scientific field or equivalent experience', 'You have built and operated data pipelines for real customers in production systems', 'You are fluent in several programming languages (JVM & otherwise)', 'You enjoy wrangling huge amounts of data and exploring new data sets', 'You value code simplicity and performance', 'You want to work in a fast, high growth startup environment that respects its engineers and customers', 'You are deeply familiar with Spark and/or Hadoop', 'In addition to data pipelines, you’re also quite good with Kubernetes and cloud technology', 'You’ve built applications that run on AWS', 'You’ve built your own data pipelines from scratch, know what goes wrong, and have ideas for how to fix it']",2020-12-30 23:04:34
Graph Theory Data Engineer,AE Strategies,4.7 out of 5 from 3 employee ratings,"Alexandria, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)Cloudera Hadoop (Hive, PIG, Sqoop and Flume): 1 year (Required)R and Natural Language Processing (R, Spark and SAS): 1 year (Required)"", 'Provide data engineering, analysis, and visualization support, including graph-theory based algorithm development and social network analysis', 'Assist with creation, troubleshooting, and deployment of analytical processes that utilize social network analysis and graph-theory algorithms, including Datawalk and/or NEO4J', 'Assist project teams with identifying, gathering, and understanding relevant data to support analysis, as well as, assess relative quality and reliability of the data', 'Examine large data sets using social network analysis and graph-theory based algorithms to identify trends, develop charts, and create visual presentations', 'Assist with regular training sessions and maintain open office hours for teams to directly ask for analytics software support', 'Apply various techniques to produce large scale optimization solutions, including data pre-processing, indexing, blocking, field and record comparison and classification', 'Develop, refine and oversees data management standards, including establishing and enforcing governance procedures and ensuring data integrity across multiple functions', 'Responsible for owning data quality metrics and meeting defined data accuracy goals according to industry best practice', 'Collaborate with data science team in the development of predictive models using machine learning, natural language and statistical analysis methods', 'Bachelor’s Degree and 10 years of experience or Master’s Degree and 5 years of experience', 'Ability to qualify for a DoD Secret Clearance', 'Direct experience creating sustainable, automated processes for data analysis', 'Expert at understanding and creating high-level architectural specifications', 'Advanced technical expertise with programmatically manipulating data', 'Familiarity or experience with Datawalk', 'Working knowledge of Applied mathematics (e.g. probability and statistics, multivariable calculus, linear algebra, ordinary and partial differential equations, stochastic processes, graph theory)', 'Maintain proficiency in data management systems and statistical packages such as: Cloudera Hadoop (priority): Hive, PIG, Sqoop, and Flume; R (priority) and Natural Language Processing (NLP) within R, Spark, SAS programming', '401(k)', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Required)"", 'professional: 5 years (Required)', 'Datawalk: 1 year (Required)', 'Cloudera Hadoop (Hive, PIG, Sqoop and Flume): 1 year (Required)', 'R and Natural Language Processing (R, Spark and SAS): 1 year (Required)', 'applied mathematics (eg, graph theory) knowledge or: 1 year (Required)', 'US citizenship (position will require a security clearance) (Required)', 'One location', 'Yes']",2020-12-30 23:04:34
Data Engineer – Salesforce Einstein,General Dynamics Information Technology,"3.8 out of 5 from 7,499 employee ratings","Washington, DC 20003","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop and maintain dashboards in Einstein for all functional teams', 'Work with business owners and data analysts to develop technical specifications for reporting products', 'Provide ongoing training for data analysts and staff on development and use of dashboards in Salesforce', 'Support data collection, analysis and visualization projects as needed, including data modeling, data cleansing, statistics, data mining, predictive analysis, and other data analysis techniques to collect, explore, and extract insights from data sets', 'Participate in developing a data governance framework to ensure integrity, reliability, and security of data', 'Research emerging tools and applications that are applicable for the functional needs', 'Recommend and develop technical, automated solutions for manual processes', 'Provide recommendations to streamline and improve current business processes', 'Respond and fulfill data requests as required', 'Participate in special projects as needed', '3-5 years of experience in working with Salesforce Einstein development and building AI powered apps', 'Knowledge in integration apps from Salesforce AppExchange', 'Demonstrated understanding of Einstein Analytics and managing datasets', 'Expert knowledge of Salesforce Analytics Query Language (SAQL) and Salesforce Object Query Language (SOQL)', 'Experience in data ingestion, data modeling, and importing data from different sources', 'Hands-on experience with developing and deploying reports & dashboards', 'Hands-on experience in creating and managing data flows', 'Salesforce Einstein Analytics Certification preferred', 'Experience in reporting platforms and data visualization tools (e.g. Tableau, Einstein Analytics & etc.)', 'Experience with scripting languages like R, Python, JavaScript, JSON, etc.', 'Experience with databases and writing SQL (Oracle, PostgreSQL)', 'Thorough understanding of fundamentals of Data Science, AI, Machine Learning and BI', 'Excellent analytical and writing skills', 'Strong verbal and written communication skills', 'Highly motivated and collaborative']",2020-12-30 23:04:34
Data Science Software Engineer,"Wurl, Inc",N/A,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Contribute to Wurl's data processing and machine learning initiatives."", 'Identify quality metrics and data features.', 'Build data models and prediction models.', ""Contribute to Wurl's ML frameworks."", 'Drive A/B & multivariate tests and design of experiments to facilitate testing of new product and design features, with focus on improving engagement, retention, and conversion.', '5+ years experience with python, other scripting languages, R, C++, SQL', 'Highly effective communication skills and team player.', 'Understanding of professional coding practices, versioning systems, bug tracking, agile processes, etc.', 'Experience with SaaS offerings: AWS preferred. Containerization, serverless processes, microservice architectures, etc.', 'Big plus: experience with OTT streaming formats (HLS, DASH), SSAI architectures, ad management architectures.', 'Experience with AI, including building ML models using frameworks such as MXNet, TensorFlow, PyTorch, SparkML, scikit-learn.', 'Using probability, statistics, predictive modeling, machine learning, or other quantitative methodologies to solve real-world TV delivery and advertisement problems.', 'Data pre-processing, visualization and cleaning experience.']",2020-12-30 23:04:34
Senior Data Engineer/Developer,Lenora Systems Inc,N/A,"Raleigh, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Building and maintaining an optimized and highly available data pipelines', 'Deeper analysis to build data processing framework (Managed data layer)', 'Top-level knowledge in Database design, Architecture and performance tuning.', 'Be part of the thriving team to develop the new strategic regulatory functionality.', 'This individual will work closely with the Product Control (PC), Financial Accounting (FA),', 'Risk clients, and Change teams to understand requirements and work', 'with business analysts, architecture and development resources to design solutions to', 'meet business needs. He/she will liaise with multiple IT teams to drive forward delivery.', 'Bachelor’s degree or higher in an analytical area such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.', 'Experience in financial services industry products and regulatory development.', 'Solid working experience in various forms of data infrastructure inclusive of RDBMS such as SQL, Hadoop, Spark, Java, Unix, Oracle and OBIEE', '8+ years relevant professional experience in Data Engineering and Business Intelligence', '10+ years in with Advanced Oracle SQL (analytical functions), RDBMS, ETL, Data warehousing.', 'Advanced data analysis skills', 'Strong knowledge of data warehousing concepts, including data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures, data modeling and performance tuning.', 'Temporarily due to COVID-19']",2020-12-30 23:04:34
Data Engineer,Penn Interactive Ventures - Philadelphia,N/A,"Philadelphia, PA 19107","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design a big data stack and data processing infrastructure and platform', 'Architect and rearchitect multi-tenant databases to meet the needs of our enormous customer base', 'Improve data validation and data quality monitoring', 'Work with client and backend teams to ensure appropriate logging', 'Optimize and tune the databases to improve performance and reduce cost', 'BSc or MSc in Computer Science or another STEM field', 'Minimum 5+ years of experience building large scale, cost effective and robust data processing platforms', 'Strong experience in database schema design, data governance and data modeling for analytics purposes', 'Experience with Spark, Redshift, Tableau, MySQL, etc.', 'Experience with AWS and/or Azure cloud', 'Good understanding of data security and encryption', 'Ability to work effectively as part of a small team, with strong interpersonal and communication skills', 'Experience with tools like Airflow, Dagster or DBT', 'Familiarity with Go', 'A passion for sports or betting']",2020-12-30 23:04:34
Data Engineer,Seated,2.8 out of 5 from 5 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with product, engineering & business teams to deliver complex data analysis requests', 'Visualize datasets across multiple databases & warehouses using tools such as Tableau, D3, Looker, etc.', 'Build financial models & growth projections for new products and business initiatives', 'Build ETL pipelines for regular reporting on business and operational KPIs', 'Help business understand key trends by executing complex analysis via Tableau or ad-hoc SQL queries', 'Coordinate within cross-functional teams such as engineering, product, marketing, customer experience for various data analysis needs', 'Proactively build data and event-driven dashboard for real-time business operations and consumer insights', 'Bachelors in CS, Statistics, Economics or Engineering, Masters preferred', '3+ years of hands-on SQL experience', '2+ years of experience in using data visualization tools such as Tableau, Looker, PowerBI', '2+ years of experience in building financial models, growth projections & ETL data pipelines', 'experience either in R or Python and working with data warehousing solution such as AWS Redshift or Google BigQuery', 'Comprehensive Healthcare, Dental, and Vision', 'Generous 401(k) Matching', 'Stock options', 'Unlimited PTO', 'Pre-Tax Flexible healthcare spending account (FSA), Dependent Care FSA and Commuter Benefits', 'Paid Family Leave', '$100 monthly Seated allowance (dine on us)', 'Stocked fridges, coffee, soda, and lots of treats', 'Collaborative, dynamic work environment within a fast-paced, mission-driven company']",2020-12-30 23:04:34
Data Engineer,auticon,N/A,"Columbus, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Stitch and normalize sparse and noisy data across various data sources', 'Undertake pre-processing of structured and unstructured data', 'Design, develop, implement, test, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, analytics, distributed microservices, or full stack systems', 'Utilize programming languages like Python, Java, Scala, Ruby, or Elixir and Open Source RDBMS, streaming, messaging, or cloud-based data warehousing services', 'Collaborate with engineering and product development teams', 'Deliver on timeline commitments where necessary', 'Prior experience (but willing to consider new data engineers depending on background)', 'Experience with all stages of the product development cycle especially designing, developing, and supporting a complex software solution while maintaining engineering best practices including defect tracking, design reviews, and appropriate testing', 'Proficient in SQL and/or NoSQL', 'Strong organizational and problem-solving skills', 'Pragmatic, product-oriented approach', 'Ability to work cross-functionally with minimal supervision', 'BS in Computer Science, Electrical Engineering, Mathematics, Statistics, Physics, or similar quantitative fields.', 'Experience with cloud environments (e.g., AWS, GCP, Azure)', 'Experience in application development', 'Experience in at least one scripting language (e.g., Python, Ruby, Perl, JavaScript, Shell)', 'Experience working on streaming data applications', 'Experience with Agile engineering practices', 'Experience with UNIX/Linux including basic commands and shell scripting', 'Experience with at least one DevOps technology (e.g., Ansible, Terraform, SaltStack, Kubernetes)']",2020-12-30 23:04:34
Test Engineer (Fully Remote),TCG,4 out of 5 from 5 employee ratings,"Washington, DC 20012","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Ensuring that every phase and feature of the software solution is tested and that any potential issue is identified and fixed before the product goes live', 'Creating test plans, test cases, and test scripts', 'Performing functional testing of the system', 'Supporting users with application training and technical support', 'Minimum 2 years in testing through a full system development life cycle, including implementing test plans, test cases, and test procedures', 'Minimum 2 years in analyzing test data', 'Minimum 2 years performing unit, integration, system, and regression software testing in an Agile Scrum environment', 'Minimum 2 years documenting test results for corrective actions, reports, and audits', 'Experience working as a member of an Agile software development team', 'Understanding of the basic principles of system analysis and quality assurance', 'Comfort collaborating with developers and other analysts to define system needs', 'Experience developing test plans, test cases, and test scripts', 'Clear communication, writing, and presentation skills', 'Attention to detail', 'Initiative and ability to work with minimal supervision', 'Demonstrates an ability to learn and contribute quickly to project requirements', 'Demonstrates an ability to prioritize and organize efforts in a fast-paced environment', 'Independent problem-solving skills, strong analytical abilities, creativity and a customer service-orientated personality', 'Bachelors’ degree in a related discipline']",2020-12-30 23:04:34
Principal Data Engineer,SAP,"4.3 out of 5 from 2,497 employee ratings","San Ramon, CA 94583","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '10+ years of relevant experience', 'BS/MS/PhD in Computer Science or related field', 'Experience with Java, Scala & Python', 'Expert knowledge of machine learning algorithms and operationalization of data science pipelines', 'Demonstrable experience with ETL/ELT tools', 'Expert Knowledge of distributed data processing such as Hadoop ecosystem and spark', 'Strong knowledge of SQL (eg: MySQL) & Linux', 'Comfortable with Data Security Concepts & SDLC', 'Familiarity with leading cloud vendors such as GCP, Azure, AWS and related tools']",2020-12-30 23:06:12
Data Engineer,CVS Health,"3.3 out of 5 from 25,650 employee ratings","Irving, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Experience building effective data management and analytic applications; Demonstrated experience in leading cross functional initiatives along with demonstrated experience interacting with and influencing decision-making by non-analytical business audiences', 'Excellent project management and problem solving skills along with experience in constructing data management, automated reporting and analytic solutions, including defining reporting methodologies to address business problems', 'Experience in leading and guiding matrix business and IT teams to coordinate rapid prototyping and data discovery leveraging specialty datasets with a view to reducing the manual effort requiring multiple analysts across business areas to create reports and insights', 'Proficiency with data access, manipulation and retrieving data from large databases with SQL and experience with other similar data access, manipulations and statistical analysis tools like SAS', 'Experience in relational databases such as Teradata, Oracle, and SQL Server', 'Strong experience in reporting tools such as Microstrategy, Tableau, PL/SQL, T-SQL', 'Specialty Pharmacy Dispensing Technology or Pharmacy Benefit Management (PBM) experience.', 'Certification in Microstrategy, Tableau, Oracle or Teradata.', 'CATS, HBS/SPARCS, or similar pharmacy dispensing system applications experience desired.', 'Programming experience with other languages such as SAS, Python and R', '3 years of hands-on experience in architecture, design or development of analytics applications and integration', '2 years of experience in analytics dashboards, reporting projects development & delivery', 'Strong knowledge of architecture and design patterns and the ability to apply them in analytics projects.', 'In depth understanding of BI and Analytics Solution Architecture', 'Healthcare industry experience', 'Experience with Big Data / Analytics technologies like Hadoop, Spark, Python, Scala, R, Machine Learning']",2020-12-30 23:06:12
Software Engineer - Vendor Data Group,Jump Trading,N/A,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Working with a variety of datasets provide a scalable, centralized, validated representation of reference data for consumers to utilize. This includes though is not limited to Security Master, Corporate Actions, Pricing and Entity Master data.', 'Review and understand various datasets leveraging vendor documentation, liaising with external vendors as needed to better understand data.', 'Anticipate data behavior, based on analysis and understood vendor and market conventions, and implement appropriate solutions and controls to identify and resolve issues during daily processing.', 'Other duties as assigned or needed.', 'At least 2+ years of demonstrated strong development skills in Python', 'Exposure/use of data analytics tools such as Pandas a bonus', 'Strong unit-testing / test-driven coding style', 'Willingness to diversify and master other technical skills on the job', 'Experience working with relational databases', 'Hands-on experience working within a Linux environment', 'Excellent written and verbal communication, analytical, and problem-solving skills', 'Reliable and predictable availability']",2020-12-30 23:06:12
Data & Analytics Visualization Engineer,Divisions Maintenance Group,2.8 out of 5 from 35 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Using expertise in data visualization and workflow design to bring the power of our data mining, machine learning, and statistical techniques on large-scale facilities maintenance and field operations data to life at commercial scale and quality', 'Drive end-to-end data and analytical solutions through robust, user-friendly visual tools to develop and support a culture of “citizen data scientists”', 'Work across important Data & Analytics Community of Excellence capability areas of: Data Science, Data Engineering, Data Wrangling, Edge Programming, SME Analyst/Business Intelligence, Visualization/Citizen Scientist Ux', 'Engage project teams to understand project needs/requirements and provide technical expertise with data and analytical tools', 'Collaborate with data leaders and multi-discipline teams to design, develop and ensure critical data systems infrastructures and integration offer critical data model availability and scalability', 'Ensure relevant data and analytics are available to meet initiatives and technical readiness needs by continuously addressing the data models, wrangling and cleansing data, and improving data solutions and platforms', 'Explore emerging capabilities and Artificial Intelligence/Machine Learning for flawless integration and application between systems, functions and their key user cases', 'Strategic, systems problem solver who will automate existing manual decision support and data workflows to drive key innovation and business performance improvement', 'Apply and build mastery in our product innovation and delivery efforts, while demonstrating diverse data, analytics and visualization skills', '3+ years or more of full time work experience (internships alone do not qualify).', 'Skills in data visualization (Tableau, Qlik, Logi, Power BI, as well as open-source libraries).', 'Front end UI skills using modern typescript frameworks.', 'Expertise in UXD.', 'Skills in script program languages (SQL, Python/Scala, R, JAVA, or C+).', 'Skills with data analytics and insight environments (Spark, Hive, SQL Server, etc).', 'Experience with data analytics insights and work processes for learning and decision support', 'Strong leadership skills, business problem definition, and priority setting skills', 'An aptitude for communicating insights and collaborating across teams/organizations', 'A passion to learn/develop and bring in emerging trends/technology that drive further insight value', 'Proven success of applied analytics through related full-time experience', 'Experience with data management, ingesting new data, transforming/harmonizing data and making it actionable', 'The mindset of an entrepreneurial thinker and is a self-starter, displaying proactive thinking']",2020-12-30 23:06:12
Test Engineer,MedeAnalytics,3.2 out of 5 from 30 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'We leverage the innovation in all of us', 'We solve the challenges of today and tomorrow', 'We seek the best answers to the most', 'We work as “One Mede”', 'We know everyone has something valuable to offer', 'We engage with our clients and partners to take on challenges', 'We get the job done every time', 'We act with urgency', 'We only look backwards to be smarter moving forward', 'We are accountable to one another', 'We do what we say we will do', 'We measure ourselves to improve in everything', 'We operate with honesty all the time', 'We are inclusive and respect differences in thought, culture,belief and experience', 'We listen', 'We bring passion and energy to our work', 'We recognize and celebrate each other', 'We remind our Clients of how great they are', 'Execute test cases (manual) and analyze results', 'Report bugs and errors to development teams', 'Help troubleshoot issues', 'Knowledge of software testing process, test types and test technics', 'Strong knowledge and experience in manual web testing (at least 1 year)', 'Experience/knowledge in defect report creation/verification with bug-tracking systems', 'Basic SQL knowledge', 'Good spoken and written English (Intermediate is required)']",2020-12-30 23:06:12
Big Data engineer with Python,Arisoft Group,N/A,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:AWS , 2 years (Required)total IT, 10 years (Preferred)python development, 5 years (Required)Devops, 2 years (Preferred)Big data, 5 years (Required)Postgres SQL, 3 years (Required)', 'AWS : 2 years (Required)', 'total IT: 10 years (Preferred)', 'python development: 5 years (Required)', 'Devops: 2 years (Preferred)', 'Big data: 5 years (Required)', 'Postgres SQL: 3 years (Required)']",2020-12-30 23:06:12
Data Engineer,Pluralsight,4.3 out of 5 from 20 employee ratings,"Draper, UT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You utilize a multidisciplinary approach to providing solutions for the business, combining technical, analytical, and domain knowledge.', 'You have strong development skills, experience transforming and profiling data', 'You understand the benefits and risks of a variety of data technology solutions, which guide your implementation decisions.', 'You love interfacing with data scientists and analysts to understand their needs.', 'You have an eagerness to dive in to data sources to understand availability, utility, and integrity of our data', 'Building and maintaining production data pipelines for data science and analytics', 'Developing tooling and solutions for data practitioners using a deep understanding of their objectives and pain points', 'Modeling and curating product data sets, such as web analytics and kafka topics', 'Improving observability in our data environment, including uptime, usage, data quality, and data freshness', 'Building production applications from data science research and exploratory analytical work', '5+ years of taking a multidisciplinary approach to data development: we emphasize picking the right tool for the job', 'Deep experience with a number of data tools: e.g. SQL, Spark, Hadoop, Python', 'Managed systems with complex dependency management and orchestration requirements', 'Strong capability to manipulate and analyze complex, high-volume data from a variety of sources', 'Effective communication skills with technical team members as well as business partners. Able to distill complex ideas into straightforward language', 'Ability to problem solve independently and prioritize work based on the anticipated business value']",2020-12-30 23:06:12
Data Science and Machine Learning Engineer,Booz Allen Hamilton,"3.9 out of 5 from 2,200 employee ratings","Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4+ years of experience with computer vision (CV) machine learning, including classical, deep learning image or video analytics methods', 'Experience with building systems based on machine learning or deep learning methods', 'Experience with a wide range of CV tasks such as object recognition, segmentation, and classification', 'Experience with a wide variety of machine learning/CV tools, including Python, Keras, TensorFlow, OpenCV or Tesseract', 'Ability to obtain a security clearance', 'BA or BS degree', 'Experience with edge computing or edge deployment experience', 'Experience with embedded systems, high-performance computing, cloud, or on-premise GPU device model deployment', 'Experience with working on multi-disciplinary Agile teams', 'Experience with data engineering, DevSecOps, version control, and operationalizing models', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'change the world with the Data Science Bowl—the world’s premier data science for social good competition', 'participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government']",2020-12-30 23:06:12
Data Engineer,Nespon IT Services,N/A,"Oklahoma City, OK 73105","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Data engineering,database engineering, business intelligence: 5 years (Preferred)SQL queries across large data sets: 5 years (Preferred)data visualization and reporting packages: 5 years (Preferred)databases :SQL, MSSQL, MYSQL: 5 years (Preferred)programming languages :SQL, •\tR, C#, Python, JavaScript, XML: 5 years (Preferred)Big Data Technologies :Hadoop, Hive, Hbase, Pig, Spark: 3 years (Preferred)"", 'The Data Engineer should be an expert familiar with all areas of data warehousing technical components (e.g. ETL, Reporting, Data Model), infrastructure (e.g. hardware and software) and their integrations.', 'The ideal candidate will be responsible for developing the overall architecture and high-level design of the data schema environment. The candidate must have extensive experience with Star Schemas, Dimensional Models, and Data Mart’s.', 'The individual is expected to build efficient, flexible, extensible, and scalable ETL design and mappings. Excellent written and verbal communication skills are required as the candidate will work very closely with diverse teams.', 'A wide degree of creativity and latitude is expected. Reports to the Director of Data Services.', ""Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering). Master’s in computer science, mathematics, statistics, economics, or another quantitative field preferred."", '5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.', '5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.', '5+ years of experience in knowledge of and experience with data visualization and reporting packages (Cognos, Pureshare, PowerBI, etc.), databases (SQL, MSSQL, MYSQL, etc.), programming languages (SQL, R, C#, Python, JavaScript, XML, etc.).', 'Demonstrated strength in data modeling, ETL development, and Data warehousing.', 'Advanced knowledge and skills with Azure Data Lake, Azure SQL, Azure Data Factory, or similar cloud platforms.', 'Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.).', 'Experience in working and delivering end-to-end projects independently.', 'Knowledge of distributed systems as it pertains to data storage and computing.', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.', 'Technical expertise regarding data models, database design, data mining and segmentation techniques.', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.', 'Continuously monitor industry trends, technologies, and standards and be able to research, recommend, and apply new technologies as they emerge.', 'Experience with Microsoft platform-based SQL Server data systems is desired.', 'Experience with IBM midrange-based platforms and DB2 systems is desired.', 'Must be self-sufficient and have excellent English oral and written communications skills.', 'Ability to collaborate effectively and work as part of a team.', 'Experience in a franchised organization is a plus.', '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Data engineering,database engineering, business intelligence: 5 years (Preferred)', 'SQL queries across large data sets: 5 years (Preferred)', 'data visualization and reporting packages: 5 years (Preferred)', 'databases : SQL, MSSQL, MYSQL: 5 years (Preferred)', 'programming languages : SQL,  * R, C#, Python, JavaScript, XML: 5 years (Preferred)', 'Big Data Technologies : Hadoop, Hive, Hbase, Pig, Spark: 3 years (Preferred)', '1 year', 'Likely', 'Fully Remote', 'Temporarily due to COVID-19']",2020-12-30 23:06:12
Software Engineering Summer Internship 2021,Tapad,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Studying to finish a BS, MS, or Ph.D. in a technical major', 'Understanding of concurrent and parallel programming', 'Knowledge of algorithms and data structures', 'Bonus: SQL and functional programming experience, specifically Scala', 'Designing, implementing, and running big data pipelines that canvas over petabytes of data', ""Contributing to real production projects that constitute Tapad's core offering"", 'Collaborate with your team of engineers, and contribute to product, account, and business development functions to create new products and features', 'Google Cloud Platform (GCP)', 'Scala, Cats, SBT, Play!, Akka,', 'Spark, Python', 'Kubernetes, BigTable, BigQuery', 'TypeScript, Angular, Node.js, Hapi.js, Postgres, MySql', 'Google Cloud Platform (GCP)', 'Scala, SBT, Play!, Akka', 'Spark, Python, SQL, BigQuery', 'Gain valuable experience working in a cutting edge and data-driven environment using state of the art technologies', 'Dynamic and fast-paced well-established start-up', 'A designated mentor to help guide you through the 10-week internship program', 'Ongoing training, which will include Scala School, access to Coursera, peer-led professional development, and an abundance of resources to help guide you through your internship', 'Catered lunches and unlimited in-office snacks and beverages', 'Leadership lunches - sit with the CEO, CTO, and CPO, and ask them anything your heart desires', 'Foosball, ping pong, diversity and inclusion group, book club, and tons of other extra-curricular activities that will make you feel like part of the Tapad family', 'Virtual game nights, diversity and inclusion group, book club, and other extra-curricular activities that will make you feel like part of the Tapad family', ""Leadership lunches over zoom. We'll deliver food to your doorstep!""]",2020-12-30 23:06:12
"Data Engineer, Analytics (Payments Ecosystem)",Facebook,4.2 out of 5 from 602 employee ratings,"Menlo Park, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Ensure conformance of metrics and detailed understanding of the metric definitions from business and technical implementation', 'Craft and own the optimal data processing architecture and systems for new data and ETL pipelines', 'Build core datasets as well as scalable and fault-tolerant pipelines', 'Build data anomaly detection, data quality checks, and enable easy root cause analysis', 'Define and own the data engineering roadmap for payments ecosystem and other areas to ensure seamless integration', 'Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline', 'Work with different cross-functional partners - WhatsApp Payments Team, Compliance, Tax and Finance', 'Build visualizations to provide insights into the data & metrics generated on the Payments Platform', 'Work with data infrastructure teams to suggest improvements and influence their roadmap', 'Able to immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions', 'Recommend improvements and modifications to existing data and ETL pipelines', 'Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership', 'Drive internal process improvements and automating manual processes for data quality and SLA management', 'Provide ongoing proactive communication and collaboration throughout the organization', 'Actively mentor team members in their careers', '4+ years’ experience in the data warehouse space', ""4+ years' experience in payments analytics"", '4+ years’ experience working with either a MapReduce or an MPP system', '7+ years’ experience in writing complex SQL and ETL processes', '4+ years’ experience with object-oriented programming languages', '7+ years’ experience with schema design and dimensional data modeling']",2020-12-30 23:06:12
Spark/Big Data Engineer,GEICO,"3.4 out of 5 from 5,164 employee ratings","Chevy Chase, MD 20815","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'At least two years of experience with SQL and Java or Scala', 'Experience with manipulating and transforming data', 'Exposure to NoSQL databases, Spark and the Hadoop Ecosystem (MapReduce, Oozie, Hive, Pig)', 'Strong critical thinking, decision making, and problem-solving skills', 'Excellent verbal/written communication skills, including communicating technical issues to non-technical audiences', 'Bachelor’s degree in a computer related field or equivalent professional experience required', 'Experience in designing efficient and robust ETL/ELT workflows, schedulers, and event-based triggers', 'Experience with Spark core and Spark SQL', 'Experience as a Big Data Developer', 'Exposure to Data Mining, Data Engineering and Data Modeling', 'Exposure to Graph Databases', 'Premier Medical, Dental and Vision Insurance with no waiting period**', 'Paid Vacation, Sick and Parental Leave', '401(k) Plan with Profit Sharing', 'Tuition Reimbursement', 'Paid Training and Licensures', 'Benefits may be different by location. Benefit eligibility requirements vary and may include length of service.']",2020-12-30 23:06:12
Data Engineer,Cognitio,N/A,"McLean, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop complex data flows, or makes significant enhancements to existing pipelines.', 'Resolves complex hardware/software compatibility and interface design considerations.', 'Conducts investigations and tests of considerable complexity.', 'Researches emerging technologies to determine impact on application execution.', 'Provides input to staff involved in writing and updating technical documentation.', 'Troubleshoots complex problems and provides customer support for the ETL process', 'Advises hardware engineers on machine characteristics that affect software systems, such as storage capacity, processing speed, and input/output requirements.', 'Prepares reports on analyses, findings, and project progress.', 'Provides guidance and work leadership to less-experienced software engineers.', 'May serve as a technical team or task leader.', 'Candidate must have an active TS/SCI Full Scope Polygraph.', 'Bachelor’s Degree in Computer Science, Electrical or Computer Engineering or a related technical discipline, or the equivalent combination of education, technical training, or work/military experience', '10+ years of related software engineering and ETL experience.', 'Experience building and maintaining data flows in NiFi or Pentaho.', 'Excellent organizational, coordination, interpersonal and team building skills.', 'Experience with the following languages: Java/J2EE, C, C++, SQL, XML, XQuery, XPath, Ruby on Rails, HTML/XHTML, CSS, Python, Shell Scripting, JSON', 'Knowledge of servers operating systems; Windows, Linux, Distributed Computing, Blade Centers, and cloud infrastructure', 'Strong problem solving skills', 'Ability to comprehend database methodologies', 'Focus on continual process improvement with a proactive approach to problem solving', 'Ability to follow directions and finish task']",2020-12-30 23:06:12
Associate Data Engineer,Uplight,4.3 out of 5 from 3 employee ratings,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work as an Engineer on our analytics engineering team, primarily developing in Python and leveraging a wide range of technologies, notably: AWS and GCP, Docker, Apache Airflow, Apache Spark, and PostgreSQL', 'Take problems from inception all the way to completion - own the building, testing, deployment, and maintenance of the code that you work on', 'Tackle complex problems that span a wide range of technical abilities, including:', 'Work effectively on an Agile team and collaborate well with your other team members.', 'Skills programming in at least one language', 'Interest in developing Machine Learning Engineering skills', 'A value for testing and developing quality software', 'Strong critical thinking skills and a desire to work with ambiguous challenges', 'Experience working in an Agile environment and a strong understanding of the full SDLC', 'Strong troubleshooting skills that span the full-stack (front-end clients, APIs, networking, DNS, Linux, containers, databases, distributed systems, etc.)', 'Experience deploying production applications on at least one major cloud provider (AWS, GCP, Azure)', 'Experience writing and maintaining data pipelines and ETLs leveraging Spark', 'Experience working cross-functionally with design, product, customer success, sales, etc.', 'Are proud to be over 300+ rebels with an important cause by helping to create a more sustainable planet.', 'Are committed to the environment, our employees, and our communities.', 'Are focused on career growth by following defined career ladders', 'Take our work and mission seriously and….we love to laugh!', 'Provide a 401k Match', 'Have an innovative flexible time-off policy', 'Keep you energized with plenty of food and drink']",2020-12-30 23:06:12
Data Engineer - Data Platform,Sift,4.3 out of 5 from 6 employee ratings,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience with Python, Java, or similar languages', 'Experience writing and optimizing complex SQL and ETL development', 'Experience designing and building data warehouse, data lake or lake house solutions', 'Experience with distributed systems and distributed data storage.', 'Experience with large scale data warehousing solutions, like BigQuery, Athena, Snowflake, Redshift, Presto, etc.', 'Experience with a batch or streaming big data processing framework such as Spark or Flink', 'Strong communication and collaboration skills particularly across teams or with functions like data scientists or business analyst.', 'Experience with cloud infrastructure (e.g. GCP, AWS)', 'Experience with workflow orchestrators such as Airflow or Cloud Composer', 'Experience with the analytics presentation layer (Dashboards, Reporting, and OLAP)', 'Experience with designing for data compliance and privacy', 'Competitive total compensation package', '401k plan', 'Medical, dental and vision coverage', 'Wellness reimbursement', 'Education reimbursement', 'Flexible time off']",2020-12-30 23:06:12
Data Science and Machine Learning Engineer,Booz Allen Hamilton,"3.9 out of 5 from 2,200 employee ratings","Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4+ years of experience with computer vision (CV) machine learning, including classical, deep learning image or video analytics methods', 'Experience with building systems based on machine learning or deep learning methods', 'Experience with a wide range of CV tasks such as object recognition, segmentation, and classification', 'Experience with a wide variety of machine learning/CV tools, including Python, Keras, TensorFlow, OpenCV or Tesseract', 'Ability to obtain a security clearance', 'BA or BS degree', 'Experience with edge computing or edge deployment experience', 'Experience with embedded systems, high-performance computing, cloud, or on-premise GPU device model deployment', 'Experience with working on multi-disciplinary Agile teams', 'Experience with data engineering, DevSecOps, version control, and operationalizing models', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'change the world with the Data Science Bowl—the world’s premier data science for social good competition', 'participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government']",2020-12-30 23:07:54
Data Engineer,Nespon IT Services,N/A,"Oklahoma City, OK 73105","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Data engineering,database engineering, business intelligence: 5 years (Preferred)SQL queries across large data sets: 5 years (Preferred)data visualization and reporting packages: 5 years (Preferred)databases :SQL, MSSQL, MYSQL: 5 years (Preferred)programming languages :SQL, •\tR, C#, Python, JavaScript, XML: 5 years (Preferred)Big Data Technologies :Hadoop, Hive, Hbase, Pig, Spark: 3 years (Preferred)"", 'The Data Engineer should be an expert familiar with all areas of data warehousing technical components (e.g. ETL, Reporting, Data Model), infrastructure (e.g. hardware and software) and their integrations.', 'The ideal candidate will be responsible for developing the overall architecture and high-level design of the data schema environment. The candidate must have extensive experience with Star Schemas, Dimensional Models, and Data Mart’s.', 'The individual is expected to build efficient, flexible, extensible, and scalable ETL design and mappings. Excellent written and verbal communication skills are required as the candidate will work very closely with diverse teams.', 'A wide degree of creativity and latitude is expected. Reports to the Director of Data Services.', ""Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering). Master’s in computer science, mathematics, statistics, economics, or another quantitative field preferred."", '5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.', '5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.', '5+ years of experience in knowledge of and experience with data visualization and reporting packages (Cognos, Pureshare, PowerBI, etc.), databases (SQL, MSSQL, MYSQL, etc.), programming languages (SQL, R, C#, Python, JavaScript, XML, etc.).', 'Demonstrated strength in data modeling, ETL development, and Data warehousing.', 'Advanced knowledge and skills with Azure Data Lake, Azure SQL, Azure Data Factory, or similar cloud platforms.', 'Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.).', 'Experience in working and delivering end-to-end projects independently.', 'Knowledge of distributed systems as it pertains to data storage and computing.', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.', 'Technical expertise regarding data models, database design, data mining and segmentation techniques.', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.', 'Continuously monitor industry trends, technologies, and standards and be able to research, recommend, and apply new technologies as they emerge.', 'Experience with Microsoft platform-based SQL Server data systems is desired.', 'Experience with IBM midrange-based platforms and DB2 systems is desired.', 'Must be self-sufficient and have excellent English oral and written communications skills.', 'Ability to collaborate effectively and work as part of a team.', 'Experience in a franchised organization is a plus.', '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Data engineering,database engineering, business intelligence: 5 years (Preferred)', 'SQL queries across large data sets: 5 years (Preferred)', 'data visualization and reporting packages: 5 years (Preferred)', 'databases : SQL, MSSQL, MYSQL: 5 years (Preferred)', 'programming languages : SQL,  * R, C#, Python, JavaScript, XML: 5 years (Preferred)', 'Big Data Technologies : Hadoop, Hive, Hbase, Pig, Spark: 3 years (Preferred)', '1 year', 'Likely', 'Fully Remote', 'Temporarily due to COVID-19']",2020-12-30 23:07:54
Software Engineering Summer Internship 2021,Tapad,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Studying to finish a BS, MS, or Ph.D. in a technical major', 'Understanding of concurrent and parallel programming', 'Knowledge of algorithms and data structures', 'Bonus: SQL and functional programming experience, specifically Scala', 'Designing, implementing, and running big data pipelines that canvas over petabytes of data', ""Contributing to real production projects that constitute Tapad's core offering"", 'Collaborate with your team of engineers, and contribute to product, account, and business development functions to create new products and features', 'Google Cloud Platform (GCP)', 'Scala, Cats, SBT, Play!, Akka,', 'Spark, Python', 'Kubernetes, BigTable, BigQuery', 'TypeScript, Angular, Node.js, Hapi.js, Postgres, MySql', 'Google Cloud Platform (GCP)', 'Scala, SBT, Play!, Akka', 'Spark, Python, SQL, BigQuery', 'Gain valuable experience working in a cutting edge and data-driven environment using state of the art technologies', 'Dynamic and fast-paced well-established start-up', 'A designated mentor to help guide you through the 10-week internship program', 'Ongoing training, which will include Scala School, access to Coursera, peer-led professional development, and an abundance of resources to help guide you through your internship', 'Catered lunches and unlimited in-office snacks and beverages', 'Leadership lunches - sit with the CEO, CTO, and CPO, and ask them anything your heart desires', 'Foosball, ping pong, diversity and inclusion group, book club, and tons of other extra-curricular activities that will make you feel like part of the Tapad family', 'Virtual game nights, diversity and inclusion group, book club, and other extra-curricular activities that will make you feel like part of the Tapad family', ""Leadership lunches over zoom. We'll deliver food to your doorstep!""]",2020-12-30 23:07:54
"Data Engineer, Analytics (Payments Ecosystem)",Facebook,4.2 out of 5 from 602 employee ratings,"Menlo Park, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Ensure conformance of metrics and detailed understanding of the metric definitions from business and technical implementation', 'Craft and own the optimal data processing architecture and systems for new data and ETL pipelines', 'Build core datasets as well as scalable and fault-tolerant pipelines', 'Build data anomaly detection, data quality checks, and enable easy root cause analysis', 'Define and own the data engineering roadmap for payments ecosystem and other areas to ensure seamless integration', 'Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline', 'Work with different cross-functional partners - WhatsApp Payments Team, Compliance, Tax and Finance', 'Build visualizations to provide insights into the data & metrics generated on the Payments Platform', 'Work with data infrastructure teams to suggest improvements and influence their roadmap', 'Able to immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions', 'Recommend improvements and modifications to existing data and ETL pipelines', 'Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership', 'Drive internal process improvements and automating manual processes for data quality and SLA management', 'Provide ongoing proactive communication and collaboration throughout the organization', 'Actively mentor team members in their careers', '4+ years’ experience in the data warehouse space', ""4+ years' experience in payments analytics"", '4+ years’ experience working with either a MapReduce or an MPP system', '7+ years’ experience in writing complex SQL and ETL processes', '4+ years’ experience with object-oriented programming languages', '7+ years’ experience with schema design and dimensional data modeling']",2020-12-30 23:07:54
Spark/Big Data Engineer,GEICO,"3.4 out of 5 from 5,164 employee ratings","Chevy Chase, MD 20815","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'At least two years of experience with SQL and Java or Scala', 'Experience with manipulating and transforming data', 'Exposure to NoSQL databases, Spark and the Hadoop Ecosystem (MapReduce, Oozie, Hive, Pig)', 'Strong critical thinking, decision making, and problem-solving skills', 'Excellent verbal/written communication skills, including communicating technical issues to non-technical audiences', 'Bachelor’s degree in a computer related field or equivalent professional experience required', 'Experience in designing efficient and robust ETL/ELT workflows, schedulers, and event-based triggers', 'Experience with Spark core and Spark SQL', 'Experience as a Big Data Developer', 'Exposure to Data Mining, Data Engineering and Data Modeling', 'Exposure to Graph Databases', 'Premier Medical, Dental and Vision Insurance with no waiting period**', 'Paid Vacation, Sick and Parental Leave', '401(k) Plan with Profit Sharing', 'Tuition Reimbursement', 'Paid Training and Licensures', 'Benefits may be different by location. Benefit eligibility requirements vary and may include length of service.']",2020-12-30 23:07:54
Data Engineer,Cognitio,N/A,"McLean, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop complex data flows, or makes significant enhancements to existing pipelines.', 'Resolves complex hardware/software compatibility and interface design considerations.', 'Conducts investigations and tests of considerable complexity.', 'Researches emerging technologies to determine impact on application execution.', 'Provides input to staff involved in writing and updating technical documentation.', 'Troubleshoots complex problems and provides customer support for the ETL process', 'Advises hardware engineers on machine characteristics that affect software systems, such as storage capacity, processing speed, and input/output requirements.', 'Prepares reports on analyses, findings, and project progress.', 'Provides guidance and work leadership to less-experienced software engineers.', 'May serve as a technical team or task leader.', 'Candidate must have an active TS/SCI Full Scope Polygraph.', 'Bachelor’s Degree in Computer Science, Electrical or Computer Engineering or a related technical discipline, or the equivalent combination of education, technical training, or work/military experience', '10+ years of related software engineering and ETL experience.', 'Experience building and maintaining data flows in NiFi or Pentaho.', 'Excellent organizational, coordination, interpersonal and team building skills.', 'Experience with the following languages: Java/J2EE, C, C++, SQL, XML, XQuery, XPath, Ruby on Rails, HTML/XHTML, CSS, Python, Shell Scripting, JSON', 'Knowledge of servers operating systems; Windows, Linux, Distributed Computing, Blade Centers, and cloud infrastructure', 'Strong problem solving skills', 'Ability to comprehend database methodologies', 'Focus on continual process improvement with a proactive approach to problem solving', 'Ability to follow directions and finish task']",2020-12-30 23:07:54
Associate Data Engineer,Uplight,4.3 out of 5 from 3 employee ratings,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work as an Engineer on our analytics engineering team, primarily developing in Python and leveraging a wide range of technologies, notably: AWS and GCP, Docker, Apache Airflow, Apache Spark, and PostgreSQL', 'Take problems from inception all the way to completion - own the building, testing, deployment, and maintenance of the code that you work on', 'Tackle complex problems that span a wide range of technical abilities, including:', 'Work effectively on an Agile team and collaborate well with your other team members.', 'Skills programming in at least one language', 'Interest in developing Machine Learning Engineering skills', 'A value for testing and developing quality software', 'Strong critical thinking skills and a desire to work with ambiguous challenges', 'Experience working in an Agile environment and a strong understanding of the full SDLC', 'Strong troubleshooting skills that span the full-stack (front-end clients, APIs, networking, DNS, Linux, containers, databases, distributed systems, etc.)', 'Experience deploying production applications on at least one major cloud provider (AWS, GCP, Azure)', 'Experience writing and maintaining data pipelines and ETLs leveraging Spark', 'Experience working cross-functionally with design, product, customer success, sales, etc.', 'Are proud to be over 300+ rebels with an important cause by helping to create a more sustainable planet.', 'Are committed to the environment, our employees, and our communities.', 'Are focused on career growth by following defined career ladders', 'Take our work and mission seriously and….we love to laugh!', 'Provide a 401k Match', 'Have an innovative flexible time-off policy', 'Keep you energized with plenty of food and drink']",2020-12-30 23:07:54
Data Engineer - Data Platform,Sift,4.3 out of 5 from 6 employee ratings,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience with Python, Java, or similar languages', 'Experience writing and optimizing complex SQL and ETL development', 'Experience designing and building data warehouse, data lake or lake house solutions', 'Experience with distributed systems and distributed data storage.', 'Experience with large scale data warehousing solutions, like BigQuery, Athena, Snowflake, Redshift, Presto, etc.', 'Experience with a batch or streaming big data processing framework such as Spark or Flink', 'Strong communication and collaboration skills particularly across teams or with functions like data scientists or business analyst.', 'Experience with cloud infrastructure (e.g. GCP, AWS)', 'Experience with workflow orchestrators such as Airflow or Cloud Composer', 'Experience with the analytics presentation layer (Dashboards, Reporting, and OLAP)', 'Experience with designing for data compliance and privacy', 'Competitive total compensation package', '401k plan', 'Medical, dental and vision coverage', 'Wellness reimbursement', 'Education reimbursement', 'Flexible time off']",2020-12-30 23:07:54
Cloud Data Engineer,Weber-Stephen Products LLC,3.1 out of 5 from 41 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'This position is responsible for planning, managing and executing an array and analytics activities to provide insights and model results that benefit the consumer marketing and product development teams. This involves, in part, collecting data and constructing solutions to business problems.', 'Performs complex statistical analysis on sample and real-world business datasets to validate and quantify trends or patterns of interest to the business groups worldwide.', 'Constructs both explanatory and predictive models to support data analysis or product functions; verifies model effectiveness based on real-world results.', 'Designs data experiments and methodologies to generate and collect data for business use.', 'Conducts some data engineering activities on the Google Cloud Platform, including developing ETL processes, scheduling ETL jobs and modifying existing Python code and Google BigQuery scripts, as necessary to update ETL jobs.']",2020-12-30 23:07:54
Lead Data Engineer,Saint-Gobain,"3.9 out of 5 from 3,193 employee ratings","Malvern, PA 19355","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Conceptualize, architect, design and develop data integration, transformation and analytics solutions that provide semantically meaningful information to consumers, including internal and external business stakeholders, data visualization specialists and data scientists', 'Work with Business Stakeholders, Data Visualization Specialists and/or Data Scientists, to determine semantic data access requirements, Architect, design and develop data access layers and data transformation and aggregation logic. Technologies include RDBMS, Hadoop, Hive, Spark, Cloud databases, ETL tools such as, Talend, Java, etc', 'Develop and review data models, technical design of complex data sourcing, transformation and aggregation logic, ETL mapping/specification documents', 'Ensure consistent and stable delta processing for data loads', 'Leverage enterprise standard tools and platforms to develop data transformation and aggregation logic', 'Lead Design sessions, provide guidance, best practices and collaborate with the team', 'Create Architecture blueprint and reference architectures', 'Develop relationships with others and being able to explain potentially complex technical concepts to non-technical colleagues in a non-threatening manner', 'Architect, design and build solutions with High Availability, Scalability, reliability', 'Create a culture of Quality Assurance excellence and strong testing processes', 'BS in Computer and Information Sciences or related field', '8+ years of Data Engineering experience with significant business exposure, including 4+ years’ experience in: Enterprise data warehousing, architecting, managing and development in Hadoop technology stack, as well as other Big Data framework. Underlying infrastructure (e.g. cloud, Hadoop, NAS, MPP, SAN)', 'Deep expertise in traditional data warehousing architectures coupled with more modern technologies that can help enable analytics agility and optimize TCO, e.g. Hadoop, RDBMS, Snowflake databases', 'Data Modelling experience using industry standard tools', 'Demonstrated working experience with Data Engineering, ETL using Talend, Unix shell scripting, Hive, Impala, HDFS, Kafka, Spark, & Spark Streaming', 'Strong Linux skills is required', 'Project Management skills. Agile methodology preferred', 'Experience with Continuous Integration and development operations is preferred', 'Experience in the Construction Products / Manufacturing / Building Materials industry is preferred', 'Experience in requirements engineering, Architecture, design, development and deployment of data and analytics services', 'Knowledge of Metadata Management and industry trends is preferred', 'Knowledge of Azure Cloud, Snowflake, core Java, Micro services is preferred']",2020-12-30 23:07:54
Data Infrastructure Engineer,Nexient,3.4 out of 5 from 17 employee ratings,"Columbus, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Deploy and maintain AWS infrastructure, network, and services', 'Deploy and maintain data infrastructure solutions such as Redshift or Snowflake in AWS', 'Deploy and maintain BI tools such as Looker or Tableau in AWS', 'Maintain critical data flows from source systems to our data stores', 'Setup security, alerting, logging and monitoring solutions', ""Bachelor's degree in Computer Science, Engineering or related field"", 'Minimum of 3 years of experience with AWS infrastructure (AWS VPC, Route53, IAM, Cloudformation, EC2 )', 'Direct experience with deploying and operationalizing data solutions in AWS ( S3, EMR, Redfshift, Snowflake, Airflow )', 'Implementing security, logging, monitoring, and alerting solutions in AWS or Kubernetes', 'Experience with containerized workloads, Kubernetes and infrastructure-as-code principles', 'Maintaining streaming and ETL pipelines in a production environment (Apache Spark, AWS Kinesis, EMR, EKS)', 'Strong programming skills, able to write modular, maintainable code, preferably Python', 'Designing and maintaining databases to support data products and reports', 'Collaborating well in a focused, agile environment']",2020-12-30 23:07:54
"Senior Business Intelligence Engineer, Data Engineering - (Remote)",Cimpress/Vistaprint,N/A,"Waltham, MA 02451","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build self-service business intelligence & reporting capabilities using technologies such as Snowflake, Looker, S3, Databricks (Spark), Matillion, Tableau, and more', 'Work directly with analysts, data scientists, product owners and business experts in a multi-functional, agile, software development team', 'Integrate data products with Vistaprint’s suite of microservices for use in analytic solutions and customer facing features on our website or marketing channels', 'Provide feedback for new features to the Vistaprint Data Platform team', 'Strong SQL skills and expert in working with ETL & relational databases', 'Experience building and optimizing ‘Big Data’ data pipelines and workflow management tools', 'Experience handling large volume data as well as both structured/unstructured data of various quality', 'Experience analyzing the data and processes to answer specific business questions/use cases and find opportunities for improvement.', 'Coding proficiency in at least one modern programming language: Python, Java, Scala etc.', 'Experience with NoSql databases and Hadoop ecosystem (especially streaming data)', 'Experience with cloud services in AWS (Preferred), Azure or Google', 'Experience with Snowflake, S3, airflow and Databricks', 'Statistics experience is a plus!', 'Familiarity with API’s/microservices (REST)', 'Degree in Computer Science, Engineering, Mathematics, or a related field', 'Problem solving and multi-tasking ability in a fast-paced, globally distributed environment']",2020-12-30 23:07:54
Data Engineer,Verstand AI,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Management and mentoring of junior data engineers.', 'Experience with setting up and operating data pipelines (batch and real time) and data wrangling procedures using Python or SQL in a cloud environment.', 'Collaborate with engineers and business customers to understand data needs, capture requirements and deliver complete BI solutions', 'Design and build data extraction, transformation, and loading processes by writing custom data pipelines', 'Design, implement and support platforms that can provide ad-hoc access to large datasets and unstructured data', 'Model data and metadata to support ad-hoc and pre-built reporting', 'Tune application and query performance using performance profiling tools and SQL', 'Build data expertise and own data quality for allocated areas of ownership', '7+ years of experience in using SQL and databases in a business environment', '6+ years of experience in cloud environment, distributed systems, system automation, and real-time platforms.', '5+ years of experience in custom ETL design, implementation, and maintenance', '5+ years of experience with data warehouse schema design and data modeling', '2+ years of production level experience with Kafka, Python, SQL, and shell scripting', '3+ years experience with cloud databases (e.g., AWS, Azure, GCP)', 'Experience with batch and stream processing (Confluent preferred)', 'Experience with building large scale data processing systems', 'Solid understanding of data design patterns and best practices', 'Working knowledge of data visualization tools such as Tableau, PowerBI and Looker is a plus', 'Experience in analyzing data to identify deliverables, gaps, and inconsistencies in data sets', 'Familiarity with agile software development practices and drive to ship quickly', 'Experience in leading change, taking initiative, and driving results', 'Effective communication skills and strong problem-solving skills', 'Proven ability and desire to mentor others in a team environment', 'Retail production experience highly desired', ""Bachelor's degree from four-year College or university in Computer Science, Technology or related field"", ""Master's degree in Computer Science is a plus"", 'Experience with microservice patterns, API development, and containers', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', 'Fully Remote', 'Yes']",2020-12-30 23:07:54
DATA ANALYST (REMOTE),TE Connectivity,"3.8 out of 5 from 1,616 employee ratings","Middletown, PA 17057","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Run daily, weekly and monthly jobs from TED / AWS data into TESS business processes and reporting tools.', 'Develop and maintain standard and ad-hoc charts and reports for sales, orders, margin, and backlog.', 'Integrate customer and product forecasts sourced from various TE systems into the TESS reporting and analytic processes and tools.', 'Create opportunity pipeline funnel charts and reports to support tracking and analysis of new product introductions and sales opportunities in SFDC.', 'Collaborate with business leaders to define informative, actionable and repeatable analytics that highlight relevant business trends and insights.', 'Develop custom report and dashboard solutions as required by colleagues in Sales, Product Management, Finance and other functional areas within TESS.', 'Support acquisition integration activities as required to support the sales operations master data and associated web applications.', 'Provide training and support for reporting and business intelligence tools.', 'Associates or bachelor’s degree in Business or Information Technology', '1-3 years of experience', 'Experience with C#, Visual Studio, MS SQL Server, and Java Script', 'Excellent computer skills and working Knowledge in MS Office (Access, Excel, Outlook)', 'Strong analytical skills with attention to detail', 'Organizational skills with the ability to manage multiple projects and priorities', 'Effective communication skills and fluency in the English language', 'Diligent and meets deadlines', 'Strong interpersonal skills, team player', 'Competitive Salary Package', 'Performance-Based Bonus Plans', 'Health and Wellness Incentives', 'Employee Stock Purchase Program', 'Community Outreach Programs / Charity Events', 'Employee Resource Groups']",2020-12-30 23:07:54
ETL Test Engineer,VedaInfo,N/A,"Parsippany, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:ETL Testing, 5 years (Preferred)', 'ETL Testing: 5 years (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 23:07:54
Data Engineer,Verstand AI,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Management and mentoring of junior data engineers.', 'Experience with setting up and operating data pipelines (batch and real time) and data wrangling procedures using Python or SQL in a cloud environment.', 'Collaborate with engineers and business customers to understand data needs, capture requirements and deliver complete BI solutions', 'Design and build data extraction, transformation, and loading processes by writing custom data pipelines', 'Design, implement and support platforms that can provide ad-hoc access to large datasets and unstructured data', 'Model data and metadata to support ad-hoc and pre-built reporting', 'Tune application and query performance using performance profiling tools and SQL', 'Build data expertise and own data quality for allocated areas of ownership', '7+ years of experience in using SQL and databases in a business environment', '6+ years of experience in cloud environment, distributed systems, system automation, and real-time platforms.', '5+ years of experience in custom ETL design, implementation, and maintenance', '5+ years of experience with data warehouse schema design and data modeling', '2+ years of production level experience with Kafka, Python, SQL, and shell scripting', '3+ years experience with cloud databases (e.g., AWS, Azure, GCP)', 'Experience with batch and stream processing (Confluent preferred)', 'Experience with building large scale data processing systems', 'Solid understanding of data design patterns and best practices', 'Working knowledge of data visualization tools such as Tableau, PowerBI and Looker is a plus', 'Experience in analyzing data to identify deliverables, gaps, and inconsistencies in data sets', 'Familiarity with agile software development practices and drive to ship quickly', 'Experience in leading change, taking initiative, and driving results', 'Effective communication skills and strong problem-solving skills', 'Proven ability and desire to mentor others in a team environment', 'Retail production experience highly desired', ""Bachelor's degree from four-year College or university in Computer Science, Technology or related field"", ""Master's degree in Computer Science is a plus"", 'Experience with microservice patterns, API development, and containers', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', 'Fully Remote', 'Yes']",2020-12-30 23:09:35
DATA ANALYST (REMOTE),TE Connectivity,"3.8 out of 5 from 1,616 employee ratings","Middletown, PA 17057","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Run daily, weekly and monthly jobs from TED / AWS data into TESS business processes and reporting tools.', 'Develop and maintain standard and ad-hoc charts and reports for sales, orders, margin, and backlog.', 'Integrate customer and product forecasts sourced from various TE systems into the TESS reporting and analytic processes and tools.', 'Create opportunity pipeline funnel charts and reports to support tracking and analysis of new product introductions and sales opportunities in SFDC.', 'Collaborate with business leaders to define informative, actionable and repeatable analytics that highlight relevant business trends and insights.', 'Develop custom report and dashboard solutions as required by colleagues in Sales, Product Management, Finance and other functional areas within TESS.', 'Support acquisition integration activities as required to support the sales operations master data and associated web applications.', 'Provide training and support for reporting and business intelligence tools.', 'Associates or bachelor’s degree in Business or Information Technology', '1-3 years of experience', 'Experience with C#, Visual Studio, MS SQL Server, and Java Script', 'Excellent computer skills and working Knowledge in MS Office (Access, Excel, Outlook)', 'Strong analytical skills with attention to detail', 'Organizational skills with the ability to manage multiple projects and priorities', 'Effective communication skills and fluency in the English language', 'Diligent and meets deadlines', 'Strong interpersonal skills, team player', 'Competitive Salary Package', 'Performance-Based Bonus Plans', 'Health and Wellness Incentives', 'Employee Stock Purchase Program', 'Community Outreach Programs / Charity Events', 'Employee Resource Groups']",2020-12-30 23:09:35
Data Engineer,Verizon,"3.9 out of 5 from 27,913 employee ratings","San Antonio, TX 78202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Gather requirements, assess gaps, and build roadmaps and architectures to help the analytics driven organization achieve its goals.', 'Work closely with Data Analysts to ensure data quality and availability for analytical modelling.', 'Explore suitable options and designs for specific analytical solutions.', 'Define extract, load, and transform (ELT) based on jointly defined requirements.', 'Prepare, clean, and massage data for use in modeling and prototypes', 'Identify gaps and implement solutions for data security, quality, and automation of processes.', 'Support maintenance, bug fixes and, performance analysis along data pipeline.', 'Bachelor’s degree or four or more years of work experience.', 'Four or more years of relevant work experience.', 'Four or more years of experience as a data engineer', 'Four or more years of experience finding, cleaning, and preparing data for use by Data Scientists', 'Experience knitting disperate data sources together', 'Four or more years of experience building data pipelines', 'Experience using SQL (i.e., PL/SQL or T-SQL with RDBMSs like Teradata, MS SQL Server, Oracle, etc.)', 'Experience in data engineering, databases, and data warehouses.', 'Strong experience with data engineering in Python.', 'Ability to travel occasionally', 'Master’s degree in Computer Science, Engineering, Statistics, IT, or related field.', 'Experience with Scala, Julia, R, Python or other machine learning programming language', 'Experience on Big Data platforms (i.e., Hadoop, Map/Reduce, Spark, HBase, CouchDB, Hive, etc.)', 'Strong analytical and problem-solving skills.', 'Experience working in a network operations center environment.', 'Experience as an open source Ccntributor.']",2020-12-30 23:09:35
Data Engineer,NT Concepts,3.3 out of 5 from 73 employee ratings,"Herndon, VA 20171","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assess, transform, organize, and optimize data for use by machine learning algorithms', 'Generating representative data sets for systems development and data science initiatives', 'Build data pipelines that enable data scientists and engineers and other stakeholders', 'TS/SCI clearance required', '4+ years of experience designing data models and data warehouses supporting analytics, using both relational and non-relational distributed data storage systems', 'Demonstrated experience in building and maintaining ETL pipelines. Bonus points for experience with Apache Beam', 'Demonstrated experience working with Synthetic Aperture Radar (SAR) data', 'Demonstrated experience with large-scale distributed processing', 'Experience building data pipelines in ML frameworks. Kubeflow experience is desired', 'Experience working in a fast-paced agile environment is a plus', 'Familiarity with machine and deep learning libraries such as Scikit-learn and PyTorch.', 'Experience in a high-level programing language, such as Java, Python or GoLang', 'Demonstrated proficiency with Git version control systems', 'Experience working in Linux environments', ""Meaningfully impact the company's growth, and share in the rewards accordingly"", 'Develop your own career path through our What’s Next program, which emphasizes person growth through training and certification', 'Work on programs of importance that directly impact National Security and the world', 'Work in a fun, “challenging yet rewarding” fast-paced environment', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Vision insurance', 'Monday to Friday', 'One location', 'No']",2020-12-30 23:09:35
Data Services Engineer,Denodo Technologies,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical discussion, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning.', 'Constantly learn new things and maintain an overview of modern technologies.', 'Provide technical consulting, training and support.', 'Diagnose and resolve clients inquiries related to operating Denodo software products in their environment.', 'Participate in problem escalation and call prevention activities to help clients and other technical specialists increase their efficiency when using Denodo products.', 'Be able to address a majority of technical questions concerning customization, integration, enterprise architecture and general feature / functionality of our product.', 'Provide timely, prioritized and complete customer-based feedback to Product Management, Sales, Support and/or Development regarding client’s business cases, requirements and issues.', 'Train and engage clients in the product architecture, configuration, and use of the Denodo Platform.', 'Promote knowledge and best practices while managing deliverables and timelines.', 'Capable of building and/or leading the development of custom deployments based on and even beyond client’s requirements.', 'Manage client expectations, establish credibility at all levels within the client and build problem-solving partnerships with the client, partners and colleagues.', 'Participate in on-call support of Denodo products.', 'Be willing to travel as necessary to address or service customer needs.', 'BS or higher degree in Computer Science.', 'Solid understanding of SQL and good grasp of relational and analytical database management theory and practice.', 'Good knowledge of JDBC, XML and Web Services APIs.', 'Excellent verbal and written communication skills to be able to interact with technical and business counterparts.', 'Active listener.', 'Strong analytical and problem solving abilities.', 'Lots of curiosity. You never stop learning new things.', 'Creativity. We love to be surprised with innovative solutions.', 'Willingness to travel on occasion.', 'Be a team worker with positive attitude.', 'Experience working with GIT or other version control systems.', 'Experience working with Big Data and/or noSQL environments like Hadoop, mongoDB, others.', 'Knowledge and experience with systems and services hosted in the main cloud vendors (AWS, Azure, GCP).', 'Experience working with caching approaches and technologies such as JCS.', 'Experience in Windows & Linux (and UNIX) operating systems in server environments.', 'Business software implementation and integration projects (e.g. ETL/Data Warehouse architectures, CEP, BPM).', 'Integration with packaged applications (e.g. relational databases, SAP, Siebel, Oracle Financials, Business Intelligence tools, …).', 'Industry experience in supporting mission critical software components.', 'Experience in attending customer meetings and writing technical documentation.', 'Experience in Java software development, especially in the web and database fields.', 'Foreign language skills are a plus.', 'We are committed to equal employment opportunity.', 'We respect, value and welcome diversity in our workforce.', 'We do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement. Therefore, any resume received from an unapproved supplier will be considered unsolicited, and we will not be obligated to pay a referral fee.']",2020-12-30 23:09:35
Data Engineer,FlexIT Inc,N/A,"Beaverton, OR 97005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Python', 'Apache Spark', 'SQL', 'AWS (S3, EMR, EKS)', 'Git', 'Deploying Spark jobs in Kubernetes', 'Apache AirFlow', 'Apachi NiFi', 'Terraform or CloudFormation', 'Hive', 'SnowFlake']",2020-12-30 23:09:35
Data Pipeline Engineer,IBM,"3.9 out of 5 from 30,506 employee ratings","Baton Rouge, LA 70802","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'http://www.ibm.com/ibm/responsibility/initiatives.html', 'http://www.ibm.com/ibm/responsibility/corporateservicecorps', 'Minimum 5 year of hands-on coding experience in Scala or Java', 'Minimum 3 years of experience in Big Data technologies (Kafka and Hive and Hadoop and HBase and Spring Cloud)', 'Minimum 3 years of hands-on experience in core Spark and Spark SQL and Spark Streaming', 'Experience in CI/CD using Jenkins and Gradle', 'Experience in Kubernetes and Docker', 'Big Data Certifications on Cloudera/Hortonworks/AWS/GCP/Azure']",2020-12-30 23:09:35
Azure Enterprise Data Engineer,Stratford Solutions Inc.,N/A,"Nashville, TN","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience: 8+ years experience in reporting analytics space', 'Data Engineering experience with Azure Databricks, Azure Data Factory, AI, Microservices and Large Retail client experience', 'Provide thought leadership leveraging analytics to improve our everyday operation and future business growth.', 'Establish centralized reporting analytics excellence within Omni-channel space.', 'Propose solutions and strategies to drive business growth.', 'Implement best practices tools to increase speed to insights.', 'Articulate insights clearly to executive level leadership.']",2020-12-30 23:09:35
"Data Engineer, Education",Chan Zuckerberg Initiative,4.8 out of 5 from 4 employee ratings,"Redwood City, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'We aim to be daring, but humble: We look for bold ideas — regardless of structure and stage — and help them scale by pairing engineers with subject matter experts to build tools that accelerate the pace of social progress.', 'We want to learn fast, but build for the long-term: We want to iterate fast and help bring new solutions to the table, but we also realize that important breakthroughs often take decades, or even centuries.', ""Stay close to the real problems: We engage directly in the communities we serve because no one understands our society's challenges like those who live them every day."", ""Support data scientists' access to data that is accurate, easy to access, and reliable"", 'Maintain key data pipelines', 'Ingest external data sets for use by the team', 'Improve data usability and data quality in our data warehouse', 'Launch new ETL (extract, transform, load) processes in production', 'Identify impactful improvements to our data warehouse infrastructure', 'Understand and improve the workflow of initiative members who use data for decision making', 'Help members of the initiative adopt and use tools that improve their access to data needed for their work', 'Educate initiative members about standard methodologies for use of data', 'Experience in Software Engineering or Data Engineering', 'Expertise writing efficient and optimized SQL', 'Experience with dimensional data modeling and schema design in a database or data warehouse', 'Expertise with scripting languages such as Python', 'Experience with ETL tooling such as Airflow', 'Experience with large scale cloud data warehouses such as Snowflake', 'Passion for education and bringing technology to improving education', 'Experience working with large data sets', 'Love for collaborating and working with people in understanding data needs as well as scoping and executing on projects.']",2020-12-30 23:09:35
Product Engineer,Parachute Health,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop in an agile environment, including TDD and flexible pair programming.', 'Contribute to balanced teams, working with product and design to shape the application.', 'Direct key technical decisions related to application and data model design.', 'Maintain stable and performant application stacks.', 'Consistently deliver quality code that supports business goals.']",2020-12-30 23:09:35
Data Scientist Summer Intern: 2021,IBM,"3.9 out of 5 from 30,506 employee ratings",United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You will implement and validate predictive models as well as create and maintain statistical models with a focus on big data.', 'You will be exposed to and incorporate a variety of statistical and machine learning techniques such as logistic regression, experimental design, generalized linear models, mixed modeling, CHAID/decision trees, neural networks and ensemble models.', 'You will communicate with internal and external clients to understand business needs and provide analytical solutions.', 'You will use leading edge tools such as COGNOS, Watson Studio and Watson Machine Learning.', 'You’ll work in an agile, collaborative environment, partnering with other scientists, engineers, and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'You are great at solving problems, debugging, troubleshooting, and designing & implementing solutions to complex technical issues.', 'You thrive on teamwork and have excellent verbal and written communication skills.', 'You have strong technical and analytical abilities, a knack for driving impact and growth, and some experience with programming/scripting in a language such as Java or Python.', 'You have an interest in, understanding of, or experience with Design Thinking and Agile Development methodologies.', 'Must have basic understanding of statistical programming in a language such as R, SAS or Python', 'Experience with programming/scripting in a language such as Java or Python', 'Basic knowledge of statistical concepts such as regressions, time series, mixed model, Bayesian methods, clustering, etc., to analyze data and provide insights', 'One or more internship or co-op experiences']",2020-12-30 23:09:35
Junior Data Engineer- Spark/Scala/Python,Cognizant Technology Solutions,"3.9 out of 5 from 13,859 employee ratings","Plano, TX 75023","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Scala, Scala and AWS technologies.']",2020-12-30 23:09:35
Data Scientist,"Katapult Group, Inc.",N/A,"New York, NY 10010","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Deploy and maintain a credit-based model (or models) and integrate new data sources into our decisioning infrastructure', 'Work with senior Risk team members to build out cloud-based infrastructure to enable real time underwriting and offline analysis', 'With the guidance of senior Risk team members, work to understand the performance of current approaches and help improve on them', 'Partner with the Engineering team to develop, test and deploy credit models', 'Monitor portfolio performance and propose strategy enhancements', 'Other duties as assigned', 'Undergraduate and/or graduate degree in Math, Economics, Statistics, Engineering, Computer Science, or another quantitative field', 'Professional or internship experience as a Data Scientist, Software Engineer, or other role which involves computer programming and data analysis', 'Comfortable in modern programming language such as Python, R, Java, C++, etc.', 'Understanding of probability and statistics gained from academic coursework', 'A detail-oriented approach and an ability to deliver on tight deadlines', 'Ability to prioritize tasks while maintaining quality', 'Ability to work independently', 'Experience using SQL for querying databases', 'Experience in A/B testing', 'Experience working with cloud computing platforms such as AWS, Google Cloud or Azure', 'Excellent communication and organization skills', 'Prior experience in Financial Technology']",2020-12-30 23:09:35
Associate Data Engineer,Housecall Pro,5 out of 5 from 2 employee ratings,"Denver, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Inclusion: Integrate data from a wide variety of data sources into our data model', 'Data Solutions:Apply dimensional modeling to design tables and views that map business processes into an enterprise data model.Build and maintain scalable data pipelines for both batch and stream processing in a cloud-computing environment.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Data Access:Support administration of data warehouse & BI solutionsWork with data and analytics experts to strive for greater functionality in our data systems', 'DataOps: Build out best practices around measurement, testing, alerting.', 'Collaborate with stakeholders on the data demand side (finance, analysts, department leads) and data supply side (domain experts on source systems of the data)', 'BS or MS in Computer Science, Information Technology or related field', 'Strong in SQL & Python', 'Solid understanding of data warehouse design and data modelling standards.', 'Ability and willingness to learn', 'Housecall Pro is a mission-driven company - Champion the Pro to Success.', 'We save our home service professionals time, and help them, in turn, to delight their homeowner customers.', 'We are tackling a large market ($700b+) generally underserved by technology and unencumbered by a dominant competitor.', 'We have fun at work. Really.', 'Competitive compensation and benefits (medical, dental, vision, life, disability, employee assistance program, 401K)', 'Our passionate employees bring their authentic selves to work. Housecall Pro employees are encouraged to create employee resource groups to make the world better.', 'Equity in a growth stage startup backed by top-tier VCs.', 'Paid holidays and self-managed (unlimited) paid time off.']",2020-12-30 23:09:35
Data Engineer,Ryzen Staffing,N/A,"Cupertino, CA 95014","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Python: 3 years (Preferred)"", '401(k)', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Python: 3 years (Preferred)', 'No', 'Temporarily due to COVID-19']",2020-12-30 23:09:35
Data Engineer,Science 37,3 out of 5 from 2 employee ratings,Massachusetts,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Understand how to Install, configure, monitor and maintain databases in the production, development, testing environments', 'Working with cloud vendors like AWS or GCP', 'Working with cloud distributed file systems, data lakes, and data warehouses', 'Creating a data pipelines to help with Internal and External analytics users', 'Define and implement database schemas and configurations working with our development teams', 'Optimize database performance by identifying and resolving application bottlenecks, tuning of DB queries, implementation of stored procedures, conducting performance tests, troubleshooting and integrating new elements', 'Work with development team design and implement reporting capabilities', 'Implement solutions for database performance monitoring and tuning', 'Recommend operational efficiencies, eliminate duplicate work efforts and remove unnecessary complexities; create and implement new procedures and workflows', 'Process database change requests, including the creation and modification of databases, tables, views, stored procedures, triggers, jobs, etc. in accordance with change control policies', 'Utilize an understanding of Agile management to help the team with all release and configuration related tasks around software builds into preproduction and production environments.', ""Bachelor's degree in Computer Science or equivalent"", 'Knowledge architectural & database design skills', 'Experience using SQL, NoSQL and Graph Databases', 'Must have experience with AWS (other cloud providers are a plus)', 'Scripting experience with Python or Bash required.', 'Proficient with SQL and Programming Languages like Python, Java, or Scala', 'Have an understanding of data architecture for microservices', 'Experience across different database platforms and tools such as MySQL, PostgreSQL, SQL Server, DynamoDB, MongoDB, AWS Neptune, Cassandra, Neo4j', 'Experience designing and building data lake and data warehouse solutions', 'Linux Server basic hands-on admin experience.', 'Some Experience with Cloud Computing management on the AWS platform', 'Experience with Monitoring/Alert planning for data services.', 'Some Experience with highly available database technologies like clustering, replication, mirroring, etc.', 'Knowledge of administration, replication, backup and restore of relational databases', 'Experience with data tools like Jupyter', 'Experience with MuleSoft Anypoint Platform and Dataweave a plus.', 'Experience in Clinical Trials and/or life science industry', 'Understanding of regulatory framework for software delivery', 'Experience with operational efficiency improvement initiatives', 'Experience with CSV (Computer Systems Validation)', 'Experience with SAFe methodology', 'Experience with JIRA, Confluence, SpiraTest is a plus', 'Thrive in fast-paced, agile environments, and able to learn new areas quickly', 'Broad knowledge of common infrastructure technologies such as web servers, load balancers, etc.', 'Excellent troubleshooting skills and ability to understand complex relationships between components of multi-tiered and distributed applications.', 'Solid understanding of load balancing and high volume, high availability environments', 'Knowledge of SDLC and project management methodologies (JIRA experience is a plus)', 'Able to analyze and review current functionality to determine potential areas of improvement and cost savings', 'Ability to work independently with minimal guidance in a fast-paced environment', 'Demonstrate excellent communication skills including the ability to effectively communicate with internal and external customers', 'Strong work ethic with good time management with the ability to work with diverse teams and lead meetings', 'Ability to work with all levels of the organization', 'Experience using both SQL, NoSQL and Graph Databases', 'Experienced in automation and automation tools such as Jenkins, Puppet, Chef, etc.', 'Amazon: RDS, Aurora, Athena, DocumentDB, DynamoDB, Neptune,', 'Apache Cassandra', 'Neo4j', 'Snowflake', 'Experience programming in Python, Java, or Scala']",2020-12-30 23:11:16
Data Engineer,CDPHP,3.7 out of 5 from 47 employee ratings,"Albany, NY 12206","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's Degree in Computer Science or Engineering. Seven (7) years relevant experience may be substituted for degree."", 'A minimum of 5 (5) years’ experience implementing large enterprise level data and analytic solutions.', 'A minimum three (3) years of development in medium to large sized development teams covering a variety of creation and delivery roles.', 'A minimum of five (5) years’ experience with release and deployment functions required.', 'Experience implementing big data solutions or other analytics solutions preferred', 'Prior hands-on knowledge of the following technologies is essential: Informatica, ASW Glue. Shell scripting, PL/SQL.', 'Demonstrated experience with data warehouse architecture and methodologies required', 'Demonstrated ability to analyze, identify, implement and monitor outcomes required.', 'Demonstrated experience in technical solution design and implementation']",2020-12-30 23:11:16
Data Governance Engineer,Vivint Smart Home,"3.4 out of 5 from 1,074 employee ratings","Lehi, UT 84043","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Candidated must possess a bachelor's degree in information systems or related field, or equivalent experience."", '2+ years working in a data related discipline.', 'Demonstrate strong analytical skills.', 'Experience with Tableau or similar data visualization tool', 'Solid experience with SQL, databases, and ETL development processes & tools (Cloud MPP like Snowflake or Redshift)', 'Ability to initiate, drive, and manage projects with competing priorities', 'Ability to communicate effectively with business leaders, IT leadership, and engineers and data stewards', 'Experience with big data technologies (HDFS, Hadoop, Spark, Elastic Search, Redshift, Snowflake, etc...)', 'Experience with Python or similar scripting language.', 'Experience with AWS or Azure data product offerings and platform', 'Experience with machine learning technologies (R, SparkML, AzureML, etc.)', 'Paid holidays and flexible paid time away', 'Your choice between Mac or PC', 'Employee pricing on smart home products', 'Casual dress code', 'Onsite gym, gaming tables across our campus', 'Onsite health clinic', 'Medical/dental/vision/life coverage']",2020-12-30 23:11:16
Data Engineer,Ramsey Solutions,4.5 out of 5 from 10 employee ratings,"Franklin, TN","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Using a wide variety of open-source technologies and tools', 'Coding and scripting all-things-database', 'Curiosity for continuously learning and perfecting your programming craft', 'Focusing on business outcomes', 'Communicating and expressing design models as well as listening to business needs', '2-5+ years of experience with Python, Scala, Java, or another object-oriented programing language (we are open to various levels of experience)', 'Experience with components in Hadoop ecosystem (Hive, Pig, Impala, Ambari, Oozie, Sqoop, Zookeeper, Mahout)', 'Experience with one or more of the following: MySQL, Redshift, Aurora, PostgreSQL', 'Experience with designing and implementing ETL processes using various tools such as Spark, Give, AWS Glue, Flink, and Beam', 'Understanding of data quality, data cleansing, data lifecycle, and metadata management', 'Experience with Business Intelligence tools such as Tableau, QuickSight', 'We’re a debt-free company that was founded in 1992 by Dave Ramsey.', 'We have over 900 team members who are 100% dedicated to our mission.', 'We believe collaboration, innovation and a shared sense of mission come from being present with each other. That’s why all of our team members work together under one roof at our headquarters in Franklin, Tennessee.', 'Ramsey Solutions was recognized by Inc. Magazine as a Best Workplace in the nation for 2020.', 'A 401(k) match of 4% after one year as a team member (you can still contribute in the first year)', 'Health insurance on day one with a $500 HSA match every year', 'One fully paid workweek of ministry time after one year to volunteer for your favorite charity or nonprofit', 'Generous PTO and paid sick time off', 'We prioritize work-life balance and rarely exceed a 40-hour work week', 'Weekly devotionals with world-renowned speakers, pastors and authors', '$300/year to put toward achieving your fitness goals', 'Casual dress and work environment']",2020-12-30 23:11:16
Data Engineer,Higher Logic,3.1 out of 5 from 16 employee ratings,"Arlington County, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Review and understand external data exports from many different platforms in many different formats.', 'Guide customers with their input on how the data should be migrated.', 'Use SSMS import tool or write custom C# program to import data.', 'Write custom SQL scripts to prepare and migrate data.', 'Use internal tools to migrate associated files.', 'Write custom C# programs to manipulate data post-migration.', 'Write custom SQL scripts to export data for customer QA.', 'Standardize and document scripts for repeated use.', 'Review and understand customer requirements.', 'Write custom SQL queries to return required data.', 'Use SSRS to design custom report.', 'Use SSMS to create and populate a new database.', 'Use SSMS to create backup file.', 'Use internal tool to download associated files.', 'Review and understand customer requirements.', 'Write custom SQL queries to return required data.', 'Write custom C# programs to return required data.', 'Format data as desired.', 'Review and understand customer requirements.', 'Restore database from backup.', 'Write custom SQL scripts to restore data from the backup to the live database.', ""Bachelor's Degree or equivalent experience."", '2 – 5 years of experience.', 'Advanced SQL (Microsoft SQL Server).', 'Intermediate C# (Microsoft Visual Studio).', 'Familiarity with bitbucket and Jira.', 'Excellent written and verbal communication skills.', 'Excellent critical thinking skills – analytical, logical, problem solving.', 'Strong desire and willingness to learn.', 'Confidence to make recommendations and decisions.', 'Respectful, patient, reliable, collaborative.', 'Strong Project Management and organizational skills.', 'Competitive compensation.', 'Comprehensive health benefits package.', '401(k) plan with employer match.', 'Healthcare and dependent-care flexible spending account.', 'Company short-term and long-term disability insurance.', 'Company culture that recognizes its employees.', 'Room for growth and development and management that cares about your professional growth and will help you achieve your goals.', 'Significant advancement opportunities for outstanding performers.']",2020-12-30 23:11:16
Data Engineer,Cloudflare,3.7 out of 5 from 10 employee ratings,"Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Gain a strong understanding of business and product data needs', 'Design, build and support scalable and reliable data solutions that can enable self-service reporting and advanced analytics using open source technologies in an agile manner.', 'Develop technical tools and programming that leverage machine learning and big-data techniques to cleanse, organize and transform data and to maintain and update data structures and integrity on an automated basis', 'Close partnership with internal stakeholders and partners from Engineering, product, and business(Finance, Sales, Customer Experience, Marketing etc.)', 'Design application components and evolve architecture: API/Services, data access, integration, application components, etc.', 'Analyze and support platform requirements for Data Science team', 'Implement automation tools and frameworks (CI/CD pipelines)', 'Build tools to automate the monitoring or workload and take proactive measure to scale the platform or to fix the problem', 'Proven ability to work closely with business and product teams to ensure data solutions are aligned with business initiatives and are of high quality.', '3+ years of development experience in Big Data space working with Petabytes of data and building large scale data solutions using Google Cloud Platform, Apache Spark, Airflow, Kafka, Scala, Python, etc.', 'Experience with API design and development of RESTful web services or Graphql.', 'Knowledge of and experience with the backend frameworks like NodeJS, Golang, Python etc.', 'Experience with environment and deployment automation, IaaS, deployment pipeline specification and development.', 'Working experience in Kubernetes, Docker etc.', 'Any experience with front end programming (React, Angular, HTML5, CSS etc.) is a plus.', ""Bachelor's or Master's Degree in Computer Science or Engineering or related experience required.""]",2020-12-30 23:11:16
Senior Data Engineer,DataRobot,4 out of 5 from 5 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Lead and build our Enterprise Data Warehouse, ELT pipelines so that it can be used by various teams to cover their analytics needs.', 'Understand how various functions of the business work, and how this is reflected in data.', 'Present Analytics and Data to other teams, advocate for high quality of data pipelines and data handling.', 'Collaborate closely with the Core Analytics team around data sources, turning raw structured and unstructured data into dimensional models that are usable by the business.', 'Strive to automate all of the steps of our data pipeline without sacrificing on the quality of data.', 'Drive team to constantly improve the quality of our data analytics code base: follow style-guide, refactor data models, implement data quality tests, increase performance, test each step of our data pipeline.', 'Adopt best engineering practices in the Data world. Drive the adoption of the DataOps mindset.', 'Document data models, most common data use cases, steps of our pipeline to scale data knowledge across the org.', 'Educate teams about best data practices, advocate for self-serve analytics.', 'Find possibilities to dogfood DataRobot AI Platform platform on our own data.', '3+ years of experience in analytics space, preferably in a software engineering role.', '2+ years leading analytics teams.', 'Experience building ELT processes, data pipelines, all the way from raw data to informative and impactful dashboards.', 'Great communication skills. The ability to explain complex business processes in a simple and concise way.', 'Advanced knowledge of SQL and analytical databases. Understand query performance optimization, ability to get to the root cause of the problem, experience with both structured and unstructured data.', 'Hands on experience with SQL, BI tools, Python/R, APIs, JSON. Familiarity with Git, source control, command line tools, Snowflake warehouse, DBT, dimensional modeling, Airflow.']",2020-12-30 23:11:16
2021 Software Engineer Summer Internship,Lazard Ltd.,3.9 out of 5 from 53 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Advanced degree in Computer Science/Engineering or equivalent work experience', 'Excellent object oriented or functional analysis and design skills', 'Experience in rational databases such as MySQL and MSSQL, or NoSQL databases such as MongoDb and ElasticSearch', 'Experience programming with Python, JavaScript, or other programming language. Experience with object-oriented programming preferred', 'Experience in the full software development lifecycle (requirements gathering, designing, building, testing and maintenance)', 'Experience on a frontend technology stack including Angular, Express, and React', 'Experience with cloud technologies such as Microsoft Azure Platform', 'A passion for understanding real world problems through data analysis and presentation', 'Ability to work both independently and as a team player', 'Experience with Devops and designing RESTful API services', 'Strong interest or previous experience in finance preferred']",2020-12-30 23:11:16
Data Engineer,BlackSky,N/A,"Herndon, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Productize prototype models produced by AI / ML team', 'Design and implement cloud architecture to facilitate scalable storage and computing', 'Load and transform data from a variety of sources', 'Engineer data features suitable for consumption by machine learning algorithms', 'Regularly attending team meetings to discuss projects, brainstorm ideas, and put forward solutions to any issues.', '3+ years of hands-on experience as a data engineer, cloud engineer, or software developer with at least 2 years focused on AI/ML and/or big data solutions', ""Bachelor's Degree or higher in one of the following fields: computer science, data science, or another computational field"", 'Python 3 proficiency', 'Experience in providing data architecture solutions for AWS Cloud applications', 'Experience with data migration to cloud based environment', 'Familiarity with database technologies (SQL and NoSQL)', 'Experienced in the use of standard ETL tools and techniques', 'Ability to manipulate raw data into effective visualization dashboards and reports', 'Understanding of data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage', 'Strong ability to communicate concepts and analytical results with customers, management, and the technical team, highlighting actionable insights', 'Must be a US Person for this role', '5+ years of hands-on experience as a service platform, cloud infrastructure, or data engineer.', 'Experience with map-reduce frameworks such as Hadoop, Spark, etc.', 'Familiarity deploying deep learning (TensorFlow, Keras) frameworks', 'Experience working with remote sensing data, ideally satellite imagery and an understanding of Geospatial software (GDAL, osgeo, etc.) and programming standards']",2020-12-30 23:11:16
Data Engineer - FinTech Team,"Groupon, Inc.",3.6 out of 5 from 825 employee ratings,"Chicago, IL 60654","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, implement, and maintain generic ETL jobs and support services for the financial data mart in the data warehouse', 'Drive and support further automatization of the international financial data pipeline in the data warehouse', 'Utilize experience and end-to-end knowledge of data warehousing and BI systems (including data architectures in translating business requirements into data models)', 'Work with business users and data analysts to design and implement data integration flows into the financial data mart in the data warehouse', 'Design data models and write specifications for the integration of heterogeneous data sources', 'Advice on and resolve any performance or scaling issue', 'Bachelor’s degree in Computer Science, Mathematics, Econometrics, or proven work experience of five years in an academic-level environment', 'Proficient with one mainstream object oriented programming languages ( e.g. Java, Python)', 'Love for detail: Being skilled and passionate for in-depth technical data analysis, explaining the last 0.001%', 'Flexibility, an independent data-driven working style being both diligent and precise', 'Strong communication skills, both verbally and written', 'Outstanding SQL scripting skills', 'Work experience in the field of Business Intelligence or Information Management', 'Practice in documentation of (logical) data models', 'Skills in database ETL with continuous desire to reduce workload by automation', 'Familiarity with working in a SOX-compliant (or similar) environment', 'Experience in handling mass data', 'Proficiency in Talend Data Integration (or comparable ETL tool)', 'Experience with JIRA (or similar ticketing tool)']",2020-12-30 23:11:16
Data Engineer - CIJ (NYC),Vera Institute of Justice,3.9 out of 5 from 15 employee ratings,"Brooklyn, NY 11232","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'We study problems that impede human dignity and justice.', 'We pilot solutions that are at once transformative and achievable.', 'We engage diverse communities in informed debate.', 'And we harness the power of evidence to drive effective policy and practice.', 'Create and support systems and processes for collecting, compiling, manipulating, and analyzing data to support CIJ’s program & researchWork with immigration research and program management staff to identify & solve for difficult data ingestion, migration, management, and integration challengesDesign data models & set up data environments to support reporting & analysisBuild and test data ingestion, migration, and ETL processesAutomate processes and schedule jobs within the data environmentWrite documentation of systems & processes for collaboration within CIJ’s research and programs', 'Ensure data ecosystems are security compliant and properly integrated with Vera’s IT systems where applicableWork closely with IT to ensure compliance & integration of systems', 'Other technical program & research support as assigned', '2-3 years of full-time experience in a data engineering capacity', 'Experience collaborating directly with data scientists and data analysts who develop analyses in any combination of R, Python, SQL, Tableau, Stata, etc. preferred', 'Prior experience designing and developing data models, building out and testing ETL data pipelines, and automating scheduled workflows using SQL & Python', 'Fluency in collaborating with Git & Github, with dedication to using these tools to conduct peer code reviews and uphold coding standards', 'High comfort level with ingesting messy source datasets that are prone to manual data entry errors and integrating these into a live database', 'Ability to build repeatable and well-documented processes and tools that can be used by other research & analytics team members, regardless of the languages they use to perform their analyses', 'Excellent oral and written communication skills, including ability to present and teach the use of data infrastructure to a range of audiences in a variety of formats, and work effectively on a large team to advance shared priorities.', 'Strong social and emotional awareness with your team and external partners.', 'Experience with Linux and bash scripting highly preferred', 'Experience with Docker and deploying Docker images highly preferred', 'Experience with automating bespoke tasks (e.g. basic web scraping, using 3rd party APIs) highly preferred', 'Familiarity with government security compliance standards is a plus', 'Working knowledge of AWS data product ecosystem is a plus', 'This position may require low-level government security clearance in the future to handle secure data. However, this is not a current requirement for hiring.', 'This is a full-time position located at Vera’s Brooklyn, New York office', 'Salary is competitive plus excellent benefits']",2020-12-30 23:11:16
Data Engineer,AE Stategies,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Provide data engineering, analysis, and visualization support, including predictive modeling, graph analysis, social network analysis', 'Assist project teams with identifying, gathering, and understanding relevant data to support analysis, as well as, assess relative quality and reliability of the data', 'Assist with data preparation, including data cleansing, transformation, combination, aggregation, and scripts for recurring ingestion in preparation for modeling and analysis', 'Assist with developing data visualizations of results for ease of use and adoption of analytics', 'Examine large data sets to identify trends, develop charts, and create visual presentations to help the organization make more strategic decisions', 'Bachelor’s Degree required and 5 years of experience OR master’s degree and 4 years of experience', 'Ability to qualify for a DoD Secret clearance', 'Direct experience creating sustainable, automated processes for data analysis', 'Expert at understanding and creating high level architectural specifications', 'Advanced technical expertise with programmatically manipulating data', 'Proficiency in data management systems and statistical packages such as: Required Experience: R, Natural Language Processing (NLP) within R, Spark, Tableau; and Preferred Experience: Hadoop, Python, SAS programming']",2020-12-30 23:11:16
Software Engineer - Entry Level,Jet Propulsion Laboratory,4.3 out of 5 from 134 employee ratings,"Pasadena, CA 91109","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Cybersecurity Engineer', 'Data Scientist', 'Data Visualization Developer', 'Electrical Ground Support Equipment Software Engineer', 'Engineering Applications Software Engineer', 'Flight Software Engineer', 'Scientific Application & Data Interaction Engineer', 'Scientific Applications Software Engineer', 'Software Systems Architect', 'Software Systems Engineer', 'Software Systems Engineer', 'User Interface Designer', 'User Interface Developer', ""Bachelor's, Master's, or PhD degree in Computer Science, Computer Engineering, Software Engineering, or related major."", 'Minimum of a 3.0/4.0 cumulative GPA.']",2020-12-30 23:11:16
Data Engineer,Crowdskout,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create highly scalable and robust data solutions for use by our products and clients', 'Design, build, and maintain multiple performant data pipelines & ETL / ELT flows against massive datasets', 'Ensure data accuracy and reliability', 'Strong SQL experience (any flavor)', 'Development experience using Python', 'Experience building large scale streaming and batch data pipelines (e.g. Python, Java)', 'Experience building out data warehouse and/or data lake infrastructure', 'Experience with data modeling and physical database design', 'Experience using Big Data technologies (e.g. Spark, Presto, Kafka)', 'Experience with SQL & NoSQL databases (e.g. MySQL, MongoDB)', 'AWS data stack (e.g. Kinesis, Glue, RDS, Athena, Redshift etc.)', 'Software development using PHP and Python', 'Graph database experience', 'Workflow management engine experience', 'Knowledge of data security best practices (e.g. data encryption, tokenization, masking)']",2020-12-30 23:11:16
Data Engineer III,SurveyMonkey,4.1 out of 5 from 19 employee ratings,Oregon,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, architect and build data pipelines to support existing data models', 'Data quality: build quality checks in the end-to-end data pipelines', 'Build new Data models (Fact vs Dimension). Write performant/idempotent transformations in Snowflake', 'Build data pipeline using Python scripting (in a modular/loop context) Write well-tested, production ready code in Python and/or Snowflake SQL', 'Experience implementing ETL (or ELT) best practices', 'Translate requirements, to technical specifications, form project scope, and achieve deployable code.', 'Write complex data engineering Snowflake - SQL jobs that perform queries on the entirety of our datasets', '5+ years experience in data engineering and Data warehousing technologies', '3+ years experience in Snowflake/ETL', 'Experience with data pipeline and workflow management tools using Airflow, Luigi', 'Experience with AWS cloud services: S3, EC2, RDS', 'Experience with object-oriented/object function scripting languages: Python, Java, Scala', 'Experience scheduling, automating and deploying production data pipelines using Airflow/Luigi', 'Experience with tools such as DBT, Matillion or Talend other similar technologies', 'Experience transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function', 'Deep knowledge of Data lakes, EDW concepts, data modeling (Star, Snowflake and Galaxy schemas)']",2020-12-30 23:11:16
"Data Engineer, Operations",NBCUniversal,"4 out of 5 from 2,293 employee ratings","Universal City, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create, test, optimize, and maintain data architectures for new and existing software applications', 'Build and automate data pipelines using internal and external datasources to be shared and consumed throughout the company', 'Work with reporting and analytics team to develop high value data products to support decisionmaking', 'Use software engineering best practices and create detailed documentation to maintain high work product standards and continuity', 'Troubleshoot issues and improve existing data systems where possible', 'Bachelor’s in Computer Science, Engineering, Mathematics, or related field', '1+ years of work experience in Software Engineering, Data Engineering, Business Intelligence, or related field', 'Knowledge of software engineering best practices', 'Knowledge of cloud computing and scalability as it pertains to data engineering', 'Experience with [Python, SQL, AWS, Google Cloud, Tableau, Linux (CentOS)]', 'Interested candidate must submit a resume/CV through www.nbcunicareers.com to be considered', 'Must be willing to work in Universal City, CA. Role will initially be remote, but will ultimately be based out of our Universal City, CA headquarters', 'Ability to display professionalism and confidence in challenging situations', 'Demonstrated attentiveness to detail and focus on excellence in work product delivery', 'Demonstrated verbal and written communication skills including effective visual representation of complex data', 'Prior experience in content, digital media, and/or technology']",2020-12-30 23:12:56
Data Engineer,"RIVA Solutions, Inc.",3.3 out of 5 from 8 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Under little or no supervision, responsible for the development of analytical solutions and databases.', 'Develops specifications for the most efficient database solutions.', 'Supports the evaluation and selection of solutions that meets customer requirements', 'Good working knowledge and hands-on experience with key software platform architectures, web servers, application servers, and relational databases.', 'Performs work involved in one or more of the phases of developing software used in products or services provided to the customer.', 'Designs and implements enterprise infrastructure and platforms required for cloud computing.', 'Analyzes system requirements and ensures that systems will be securely integrated with current applications.', 'Has a deep understanding of system development in cloud environments, including Software as Service (SaaS), Platform as Service (PaaS), or Infrastructure as a Service (IaaS).', 'Designs and builds relational databases for data storage or processing.', 'Develops strategies for warehouse implementation, data acquisition, and archive recovery.', ""May evaluate new data sources for adherence to the organization's quality standards and ease of integration."", 'Provide consultation on complex projects and is considered to be a top-level contributor/specialist', 'Key member of a data science project team supporting analytic development.', 'Eight (8) years relevant experience in applied data science research or big data analytics', 'Bachelor’s Degree in Computer Science, Engineering, Information Systems or related technical discipline. A Master’s degree may be substituted for up to two (2) years of experience. A PhD may be substituted for up to five (5) years of experience.', 'Ability to perform functional and data requirements analysis, and implementation of data engineering projects, analyze customer requirements and provide solution recommendations.', 'Demonstrate knowledge of information engineering methodologies, process improvement, and performance measurement.', 'Ability to support the development of organization-wide data models for use in designing and building integrated, shared software and database systems.']",2020-12-30 23:12:56
Data Engineer,"Velocity Works, LLC",N/A,"Pittsburgh, PA 15222","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Writing, debugging, unit testing, and performance test code in the data access layer.', 'As an agile team member, participate in code reviews, design reviews, etc.', 'Utilize domain driven techniques and design patterns to build and contribute to technical design.', 'Develop and maintain strong knowledge of implemented requirements and detailed application behaviors.', 'Assists in the development and training of junior software engineers', ""Bachelor's computer information technology, computer science, management required"", 'Strong knowledge of the Linux operating environment.', 'Familiarity and experience executing several software development methodologies and life cycles preferred.', '5+ years of developing software using object-oriented or functional language experience5+ years of SQL', '2+ years experience with AWS or Azure', '2+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.)', '3+ years with document databases (e.g. MongoDB, Accumulo, etc.)', '3+ years of experience using Agile development processes (e.g. developing and estimating user stories, sprint planning, sprint retrospectives, etc.)', '2+ years of distributed version control system (e.g. git)3+ years of experience in cloud-based development and delivery', 'Familiarity with distributed computing patterns, techniques, and technologies (e.g. ESB)Familiarity with continuous delivery technologies (e.g. Puppet, Chef, Ansible, Docker, Vagrant, etc.)', 'Familiarity with build automation and continuous integration tools (e.g. Maven, Jenkins, Bamboo, etc.)', 'Familiarity with Agile process management tools (e.g. Atlassian Jira)', 'Familiarity with test automation (Selenium, SoapUI, etc.)', 'Good software development and Object Oriented programming skills.', 'Strong analytical skills and the ability to work with end users to transform requests into robust solutions.', 'Excellent oral and written communication skills.', 'Initiative and self-motivation to work independently on projects.']",2020-12-30 23:12:56
Data Engineer,LeafLink,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assist in building a high performing data platform which will power various reporting and analytics applications at LeafLink', 'Implementing ELT / ETL procedures to pipe data from ingestion source to data warehouse', 'Develop data models and schemas in our data warehouse that enable data and analytics processes', 'Maintain the data dictionary and documentation relating to the data warehouse serving all LeafLink functions and business divisions', 'Working closely with LeafLink software engineers on implementation of data models related to LeafLink applications', 'Addressing data quality issues originating at source and working with LeafLink vendors on solving quality issues and simplifying ingestion processes', 'Handle large volumes of data and integrate our platform with a range of internal and external systems', 'Proactively research and contribute ideas for improvement of data team processes', 'Troubleshoot and diagnose issues quickly and effectively', 'Maintain and evaluate quality of documentation, code, and business logic for data management at LeafLink', 'Expertise and hands-on experience working in a cloud based data stack (AWS preferred)', 'Expertise in developing and maintaining relational database structures and relationships', 'Expertise writing processing jobs to ingest a variety of structured and unstructured data received from various sources & formats such as Rest APIs, Flat Files, Logs', 'Expert level skills in using Python for data processing coupled with AWS offerings like Lambda, Step Functions', 'Expert level skills in writing & managing optimized SQL for creating, updating and querying source of truth tables', 'Hands-on experience with deployment using CI/CD, Docker;', 'Hands on experience with Airflow is a must', 'Experience using dbt is a strong plus', 'Comfortable in diagramming and documenting processes, relational structures using tools like Visio, Lucidchart, Confluence', 'Well-versed in version control systems (Git)', 'Experience working in a team with data scientists and analysts as clients is a plus', 'Experience with platforming ML & using Spark is a plus but not required', 'Comfortable working in a fast-paced growth business with many collaborators and quickly evolving business needs', 'Flexible PTO to give our employees a little extra R&R when they need it', 'Competitive compensation and 401k', 'Comprehensive health coverage (medical, dental, vision)', 'Commuter Benefits through a Flexible Spending Account', ""A robust stock option plan to give our employees a direct stake in LeafLink's success""]",2020-12-30 23:12:56
"Big Data Engineer, Mid.",Booz Allen Hamilton,"3.9 out of 5 from 2,200 employee ratings","Alexandria, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '2+ years of experience with a computer language including Java, Python, Scala, C, C++, or C#', '1+ year of experience in data warehouse design, including snowflake and star schema or a big data store design, including Datalake', '1+ year of experience with RDBMS ETL processes using PL/SQL, T-SQL, or SQL', '1+ year of experience working on Microsoft SQL Server, Oracle, MySQL, PostgreSQL, SQLite, or AWS MariaDB', 'Ability to obtain a security clearance', 'BA or BS degree', 'Knowledge of cloud platforms including AWS and Azure', 'Knowledge of Kubernetes containerization either with native or OpenShift', 'Knowledge of docker containerized development', 'Knowledge of data ingest or real-time messaging using Kafka, Spark, Hive, NiFi, or Kinesis Firehose', 'Ability to learn big data technologies and big data design patterns', 'Ability to learn the hadoop technology stack and services in the data access layer']",2020-12-30 23:12:56
Data Software Engineer,Elasticiti,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop data pipelines', 'Retrieve data via API and FTP', 'Create ETL procedures on new datasets', 'Establish real-time and batch processes', 'Implement data model and populate with data', 'Establish data ingestion frequency rules', 'Define, detect, and correct data quality issues', 'Define data models to achieve business and scale goals', 'Closely monitor and debug data pipelines', '3+ years development experience with Python', '2+ years of experience with ETL', '2+ years experience in SQL (both querying and modeling) – Intermediate Level', '2+ years of experience in OLAP', 'Familiarity with test driven development', 'Some experience with SQL query performance tuning', 'Experience with system scaling for growth', 'Solid debugging skills and experience with automated testing', 'Experience working with multiple heterogeneous data sources', 'AWS ecosystem: experience with S3, EC2, EMR, Lambda, Redshift', 'Data pipelines like Airflow, Stitch, Talend, or AWS Data Pipeline etc', 'APIs: work with at least one of the following - Google, YouTube, Facebook, Twitter, or Oauth', 'Experience with version control (Github, Stash etc.)', 'Comfortable with Linux', 'DBT experience', 'CI/CD experience', 'Google Cloud experience', 'Experience working with data scientists', 'Experience with the media industry or an advertising agency', 'Experience with structured and semi-structured data']",2020-12-30 23:12:56
"MTS 1, Data Engineer",PayPal,"3.9 out of 5 from 1,386 employee ratings","Chandler, AZ 85286","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participating and collaborating with Product Owner/ Cross functional teams in the organization to understand the business requirements and to deliver solutions that can scale.', 'Creativity and out of the box thinking is required.', 'Proactively anticipating problems and keeping the team and management informed in a timely manner.', 'Being flexible and being able to support all functions of product life cycle when required.', 'Will be acting as tech lead and produce quality deliverables.', '8+ years of experience in the IT industry, experience in data engg is Mandatory.', 'Shell/ Perl scripting experience or proficiency in any programming language like Java/C/ C++, Python', 'Hands on in Java programming', 'Strong fundamentals of object-oriented design, data structures, algorithms and design patterns', 'Proficient in Frameworks – Spring, Maven, Hibernate', 'Knowledge of Real time Analytics', 'Expert in software engineering tools and best practices', 'Expert in design/implementation for reliability, availability, scalability and performance', 'Should have strong SQL programming skills', 'Knowledge of data warehousing concepts', 'Proficient in Big data Environments – Spark, Pig, Hive, MR', 'Excellent written and oral communication skills', 'Knowledge in MPP Databases/ Distributed systems', 'Knowledge on Data Encryption Standards is a huge plus', 'Exposure to Data Quality and Profiling tools is a plus.', 'Exposure BI tools desired, but not required (Micro strategy, Business Objects).']",2020-12-30 23:12:56
Test Engineer,ASPENSOFT CONSULTING LLC,N/A,"Blue Bell, PA 19422","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", ""Bachelor's (Preferred)""]",2020-12-30 23:12:56
Data Engineer,RxSense,2.3 out of 5 from 8 employee ratings,"Boston, MA 02110","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Analyze and interpret complex data and provide resolutions to data issues.', 'Coordinate with data analyst to validate requirements, perform interviews with users and developers.', 'Perform tests and validate data flows and prepare ETL processes according to business requirements.', 'Perform ETL tuning and SQL tuning.', 'Perform data modeling and schema design, including dimensional and big data modeling.', 'Designing and implement a data conversion strategy from legacy to new platforms.', 'Perform design validation, reconciliation, and error handling in data load processes.', 'Design and prepare technical specifications and guidelines including ER diagrams and related documents.', 'Deep expertise in data extraction, data wrangling, and data preparation', 'Experience with ETL/Data Transformation and one or more related products such as Informatica and SSIS.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience in building AWS Data Pipelines using Python/Scala, Apache Spark, SparkSQL, S3 Data Lake, Snowflake', 'Good to have - Experience with any of the NoSQL datastores such as ElasticSearch, MongoDB, DynamoDB, Cassandra', 'Location – New Jersey / New York area or Boston']",2020-12-30 23:12:56
"Technical Solutions Engineer, Big Data, Google Cloud",Google,"4.3 out of 5 from 3,811 employee ratings","Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's degree in the field of Science, Technology, Engineering, Math or equivalent practical experience."", 'Experience reading or debugging code in one or more of the following: Java, C, C++, .NET, Python, Shell, Perl, JavaScript.', 'Experience in advocating for customer needs.', 'Experience with distributed, columnar and/or analytic oriented databases or distributed data processing frameworks.', 'Experience with open source distributed storage and processing utilities in the Apache Hadoop family and/or workflow orchestration products.', 'Experience with machine learning technologies, including developing and/or training models or implementing solutions which rely on invoking such models.', 'Background in data analytics, warehousing, ETL development, data science or other Big Data applications.', 'Understanding of basic web technologies. Understanding of TCP/IP concepts, Unix/Linux basic administration and commands.', 'Excellent troubleshooting, attention to detail, and communication skills in a fast-paced setting.', 'Manage the customer’s problem through effective diagnosis, resolution, or implementation of new investigation tools to increase productivity for customer issues on Google Cloud Platform products.', ""Develop an in-depth understanding of Google's product technology and underlying architectures by troubleshooting, reproducing, determining the root cause for customer reported issues, and building tools for faster diagnosis."", 'Act as a consultant and subject matter expert for internal stakeholders in engineering, sales, and customer organizations to resolve technical deployment obstacles and improve Google Cloud.', 'Work as part of a team of Engineers/Consultants that globally ensure 24 hour customer support. This will include a need to sometimes work non-standard work hours or shifts.', 'Understand customer issues and advocate for their needs with cross-functional teams, like product and engineering, to find ways to improve the product and drive high-quality production.']",2020-12-30 23:12:56
Data Engineer,Luxoft,4.4 out of 5 from 212 employee ratings,"New York, NY 10006","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:12:56
Dashboard Engineer and Business Analyst,Praxis Metrics,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Have not had 2+ years of client-facing consulting experience', 'Have not presented to an executive leadership team', 'Have not had experience working with company leaders in explaining the value and context for dashboards and data flows', 'Do not have significant technical experience in Tableau, Domo, or PowerBI', 'Have not consulted or worked on data projects independently', 'Up to $122,000 in gross pay with an hourly rate of $60-$80', 'Type: this position will begin as a contractor role for the first 90 days with the opportunity to become an hourly W-2 employee after a 90-day review', 'Ability to build accurate, clean, and visually appealing dashboards', 'Business consulting with clients (eCommerce perspective is prefered)', 'SQL master', 'Proficient in using and building API connections, SQL, Domo, and other ETL tools to access various databases', 'Python (1 year)', 'E-commerce marketing experience', 'Capable of meeting with C-suite executives and explaining complex data in a simple and digestible way for non-technical people', 'Able to look at outputs of data and reverse engineer the data to recommend changes in business practices', 'Able to communicate confidently with a customer-centric mindset', 'Proactive in your communication (both with internal team members and external clients)', 'Motivated by challenges and complex problems', 'Detail-oriented and driven by a standard of excellence', 'Able to hold yourself accountable and can problem solve creatively and independently', 'Able to work closely and harmoniously with other team members', 'A person who has a problem-solving mindset and practice this everyday', 'Fun-loving and enjoy making an impact', 'Personally organized; able to manage your calendar, time blocks, and balance all customer requirements, and respond to emails and Slack messages daily', 'Monday to Friday']",2020-12-30 23:12:56
Data Engineer - Brand Savings,GoodRx,5 out of 5 from 5 employee ratings,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Manage data warehouse plans for product and marketing teams', 'Work closely with product managers to understand the data needs of product and marketing', 'Act as internal expert in each of the data sources so that you can own overall data quality', 'Design, build and deploy new data models and ETL pipelines into production', 'Experience contributing to full lifecycle deployments with a focus on testing and quality', 'Define and manage overall schedule and availability for all data sets', 'Work closely with other engineers to enhance infrastructure, improve reliability and efficiency', 'Make smart engineering and product decisions based on data analysis and collaboration', 'Act as in house data expert and make recommendations regarding standards for code quality and timeliness', 'Architectural understanding of Hadoop (HDFS/MapReduce) distributed computing system.', 'Good knowledge of Apache Hive, Pig, and Spark etc.', 'Experience in architecting cloud-based data infrastructure solutions.', 'Degree in Computer Science or a related field or a minimum of 3 year’s working as a Data Engineer', '2+ years professional experience in the data warehouse space', 'Expert Proficiency with Python and AWS Services (e.g. Redshift, S3)', '2+ years’ experience in custom ETL design, implementation and maintenance', 'In depth knowledge of how to write and optimize SQL statements.', 'Deep familiarity with distributed processing (Map Reduce, MPP, etc.)', '2+ years’ experience with schema design (logical and physical)', 'Ability to quickly learn complex domains', 'Innately curious and organized with the drive to analyze data to identify deliverables, anomalies and gaps and propose solutions to address these findings', 'Ability to manage and communicate data warehouse plans', 'Thrives in fast-paced startup environment']",2020-12-30 23:12:56
Sr. Data Operations Engineer I,Staples,"3.5 out of 5 from 11,347 employee ratings","Framingham, MA 01702","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Troubleshooting and resolving database issues or technical issues.', 'DB2 and NoSQL', 'Hands-on experience in AIX, Linux Operating System, python, shell scripting and Virtualized environments.', 'Monitoring performance and recommending improvements for operational efficiency;', 'Assisting in capacity planning, space management and data maintenance activities for database system;', 'Performing database recovery and backup tasks on daily and weekly basis;', 'Working with SQL;', 'Experience with data system design, architecture, database backup, recovery and monitoring;', 'Hands-on experience in using configuration management tools, including Puppet, Chef, or Ansible;', 'Database monitoring, administration, upgrades, backup, and disaster recovery of DB2/Couchbase databases;', 'Ensuring integrity, availability and performance of DB2, Mongodb and Couchbase database by providing technical support and maintenance;', 'Oracle;', 'MySQL; and', 'Working with Couchbase and Mongodb.']",2020-12-30 23:12:56
Cloud Data Engineer,ION,3.9 out of 5 from 28 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and build cloud-based advanced data strategies', 'Design and execute migration paths and validation, inclusive of parallel runs', 'Communicate with leadership, product owners, other technologists and users to create data strategies based on an understanding of business and technical priorities', 'Break down complex problems into elegant solutions', 'Work with outside data sources and APIs', 'Oversee development teams in deploying and validating of data strategies and understanding concerns such as provenance, discovery, entitlement and performance of data delivery.', 'Work with development engineers to track down defects', 'Actively contribute to improving software prior to distribution to Lab49’s client’s clients', 'Bring a passion to stay on top of tech trends', 'Experiment with and learn new technologies', 'Proven software design and development capability for data-driven projects', 'Experience with cloud-based data technologies such as Elastic/Lucne, S3, RDS, RedShift, Dynamo, Snowflake', 'Experience working distributed compute modalities with HDFS, Spark', 'Working knowledge of the general cloud-data landscape, architectures, trends and emerging technologies', 'Experience working in an Agile environment.', 'College degree in Computer Science or related field of study or equivalent experience']",2020-12-30 23:12:56
Associate Data Engineer,Uplight,4.3 out of 5 from 3 employee ratings,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work as an Engineer on our analytics engineering team, primarily developing in Python and leveraging a wide range of technologies, notably: AWS and GCP, Docker, Apache Airflow, Apache Spark, and PostgreSQL', 'Take problems from inception all the way to completion - own the building, testing, deployment, and maintenance of the code that you work on', 'Tackle complex problems that span a wide range of technical abilities, including:', 'Work effectively on an Agile team and collaborate well with your other team members.', 'Skills programming in at least one language', 'Interest in developing Machine Learning Engineering skills', 'A value for testing and developing quality software', 'Strong critical thinking skills and a desire to work with ambiguous challenges', 'Experience working in an Agile environment and a strong understanding of the full SDLC', 'Strong troubleshooting skills that span the full-stack (front-end clients, APIs, networking, DNS, Linux, containers, databases, distributed systems, etc.)', 'Experience deploying production applications on at least one major cloud provider (AWS, GCP, Azure)', 'Experience writing and maintaining data pipelines and ETLs leveraging Spark', 'Experience working cross-functionally with design, product, customer success, sales, etc.', 'Are proud to be over 300+ rebels with an important cause by helping to create a more sustainable planet.', 'Are committed to the environment, our employees, and our communities.', 'Are focused on career growth by following defined career ladders', 'Take our work and mission seriously and….we love to laugh!', 'Provide a 401k Match', 'Have an innovative flexible time-off policy', 'Keep you energized with plenty of food and drink']",2020-12-30 23:14:37
Intern - Sustainability Project Management - Spring 2021 (Jan-June),Xylem,3.4 out of 5 from 404 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Professional Development – To advance the capabilities of our people, we offer a wide variety of experiences to support our employees’ professional growth and continuous learning.', 'Total Rewards – We offer comprehensive programs for compensation, benefits, recognition, learning and development, work-life integration and corporate citizenship.', 'Watermark – Watermark is our corporate social responsibility program working to provide education and access to safe water to ensure healthy lives, gender equality, and resilient communities. Employees have the opportunity to learn and volunteer on various water-related projects.', 'Employee Networks – Our Employee Networks provide a professional, supportive network for employees from diverse backgrounds, including Women’s, LGBT+ and Allies, Veteran’s, People of Color and Allies, Emerging Leaders, and Working Parents Networks.', 'Drive delivery of the final Sustainability report on time', 'Track project milestones and track key stakeholder progress', 'Submit weekly progress updates to core report team', 'Communicate proactively with all work streams to anticipate problems, create solutions, and implement efficiency improvements', 'A key eye for data validation and adherence to reporting framework structures', 'Apply a sense of urgency, commitment and focus on the right priorities to ensuring delivery targets are achieved', 'Support the creation of content and creative materials associated with the report', 'Clear communication skills, including support of writing various pieces of sustainability report', 'Communication with key stakeholders to ensure timely return of required inputs and reviews', 'Interfacing with external consultants, driving key deliverables', 'Deeply passionate about sustainability issues and strong interest in the water industry', 'Committed to develop strong leadership and communication skills to engage team members, resolve timeline or productivity issues, and keep the team focused on achieving project goals', 'Excellent interpersonal skills and high emotional intelligence to manage relationships with various stakeholders', 'Prior project management experience desired', 'Organized and attention to detail required', 'Familiarity of sustainability reporting frameworks and ratings desired', 'Currently attending an accredited University studying engineer, business, marketing, sustainability or other applicable programs', 'Minimum Junior in standing', 'Regularly required to sit or stand, reach, bend and move about the facility', 'Part-time remote work from January through June 2021', 'A minimum of 15 hours a week is expected']",2020-12-30 23:14:37
"Intern, North America Diversity & Inclusion",SAP,"4.3 out of 5 from 2,497 employee ratings","Newtown Square, PA 19073","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Function as Chief of Staff to the leaders of the North America Diversity & Inclusion office and Human Resources Business Partner organization', 'Support North America Diversity & Inclusion Lead with planning and execution of programs and interventions, and the HRBPs with their People & Organizational Strategy- including projects, analytics, & creative ideas', 'Learn HR annual processes and consult with HRBPs & leaders a needed', 'Provide day to day support to both the regional D&I and HRBP teams which may include analysis of HR system data, auditing organizational hierarchies and programs, streamlining processes, and generating reports', 'Special projects and ancillary duties as assigned', 'Effective Communication and presentation skills – verbal and written', 'Demonstrated ability to effectively multitask in a fast-paced environment', 'Strong customer service and problem resolution skills', 'Leadership experience (academic or professional)', 'An innovative approach to marketing/attracting peer-level talent', 'A proactive and independent approach to critical thinking', 'Proficiency in MS Word, PPT, and Excel a MUST', 'Business analytics and corporate experience preferred', 'Project or program management experience a plus', 'Matriculating student in the undergraduate degree program (all majors welcome)', 'Previous internship experience helpful']",2020-12-30 23:14:37
Data Engineer,OneMagnify,3.6 out of 5 from 9 employee ratings,"Dearborn, MI","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with data scientists and software engineers to support data acquisition activities, data solution ideation, and implementation', 'Work with technical and business leads to transfer global business requirements into sound solutions and implementation', 'Share support responsibilities for implemented components', '3+ years of experience with R, Python, SAS, MATLAB, Java, etc.', '3+ years of Hive, Spark, JavaScript, SQL, HTML', '3+ years of experience with PCF cloud services', 'Experience with Hadoop, Spark, Kafka', 'Familiar with big data and machine learning tools and platforms', 'Experience with BI tools, such as Informatica, Data Stage, QlikView, Tableau, etc.', 'Design data pipelines and data robots, take a vision and bring it to life', 'Master data engineer; teaches others; works closely with IT architects to set strategy and design projects', 'Lead a team of Associate Data Engineers and Data Engineers', 'Provide extensive technical, strategic advice and guidance to key stakeholders around the data transformation efforts', 'Redesign data flows to prevent recurring data issues', 'Strong analytical and problem-solving skills', 'Possess excellent oral and written communication skills, as well as facilitation and presentation skills, and engaging presentation style.', 'Ability to work as a global team member, as well as independently, in a changing environment and managing multiple priorities.', 'Ability to establish and maintain cooperative and effective working relationships with application implementation teams, IT project teams, business customers, and end users.', 'Ability to deliver work within deadlines.', 'Experience with agile/lean methodologies', 'Experience working independently and with minimal supervision', 'Experience with a global team', 'Experience with Test Driven Development and Software Craftsmanship', 'Strong Communications skills', 'Ability to illustrate and convey ideas and prototypes effectively with team and partners', 'Presence demonstrating confidence, ability to learn quickly, influence, and shape ideas']",2020-12-30 23:14:37
Mainfram zOS Engineer,Infolob,N/A,"Malvern, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)REST: 1 year (Preferred)Java: 1 year (Preferred)"", 'Large enterprise mainframe deployment', 'Multiple data center configuration – 3 sites 65,000 shop', 'Sysplex experience', 'Z15 mainframe- comparable platforms and versions', 'z/OS 2.3 is what they are at now must be equivalent', 'TCIP experience is needed', 'Vtam - Virtual Telecommunications Access Method (VTAM) is the IBM subsystem that implements Systems Network Architecture (SNA) for mainframe environments. VTAM provides an application programming interface (API) for communication applications, and controls communication equipment such as adapters and controllers', 'WLM- Work load manager experience', 'Traditional shop, Db2, CiCS shop', 'Data Center job not a developer this person will be for the Mainframe platform.', 'Do not want programmer wants a systems side experienced individual. Storage is an EMC environment. Looking to go to IBM storage if someone had that it would be beneficial GDPS would be helpful and very attractive', 'Currently they are in 2 teams Data and z/os & Infra side, this person tends to be a blend of the both of a systems individual with a data/storage individual.', '8 hour shift', 'Malvern, PA (Preferred)', ""Bachelor's (Preferred)"", 'REST: 1 year (Preferred)', 'Java: 1 year (Preferred)', 'mainframe: 6 years (Required)', 'Zos: 1 year (Required)', 'Multiple locations', 'Temporarily due to COVID-19']",2020-12-30 23:14:37
Data Center Engineer,Nuance,3.2 out of 5 from 458 employee ratings,"Burlington, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Equipment Rack & Stack-Investigate and ensure all equipment for project PO’s/PR’s are accurately received and advise PM’s for inaccuracy.Ensure all documentation/licensing is filed and documented.Record all serial number(s) prior to racking and document them into local inventory and Nuance internal SharePoint system.Label (front & back) of all hosts/equipment with NE/SA supplied Nuance naming convention host names.Rack equipment in pre-designated location(s) per cabinet inventory space documentation availability.Install power cables to PDU’s in accordance with power balancing methods/procedures.Cabling of equipment-Carrier, iLO, Network, ConsoleAdvise PM/SA of installation completion and status of all link lights so they may identify connection issues.Review documentation completion for accuracy and adjustments as needed.', 'Demarc Extensions (cross connects)-Investigate and review LOA/CFA’s documentation/location information for correct media type tie-down circuit delivery within Sabey MMR/MPOE rooms.Ensure circuit delivery was correctly installed and labeled and advise PM with inaccuracies.Cable from circuit tie-down location(s) to Nuance patch panel rack location(s) within Sabey MMR/MPOE rooms.Label all cables and both ends with to/from location end points accordingly.Cable circuit(s) in Nuance production cage from patch panel to equipment and advice PM of completion/link light status.Update circuit inventory documentation.', 'Physical Inventory (NEAT)(Build Book)-Constantly update and cross-reference NOD Equipment Advanced Tracker (NEAT) for all equipment/spare(s) that are racked and in storage cage.Keep an accurate inventory of consumables (b', 'Inventory Management-Track/Receive all equipment/parts from PO’s through onsite security personnel.Ensure all equipment/parts for all projects was delivered to site and advise PM/SA’s for inconsistencies.Update inventory documentation with equipment.', 'Daily AdHoc/Emergency MAC Requests-Complete equipment moves/relocations per PM/SA’sRe-cable/re-IP/reboot and confirm equipment configuration requests from Nuance SA’s/DBA NE’s.Provide 24hr support for JIRA and CMENT trouble tickets.', 'NE/SA Equipment Access Requests-Provide support/participation for Nuance internal project conference calls.Provide assistance for screen share meetings and new client equipment/turn-up activities.', 'Iron Mountain Tape Transfers (IT) –Swap out data tapes from Adic & Overland storage devices (blue cases)', 'Education: Technical Diploma or equivalent', 'Years of experience: 3 + years']",2020-12-30 23:14:37
Spark/Big Data Engineer,GEICO,"3.4 out of 5 from 5,164 employee ratings","Chevy Chase, MD 20815","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'At least two years of experience with SQL and Java or Scala', 'Experience with manipulating and transforming data', 'Exposure to NoSQL databases, Spark and the Hadoop Ecosystem (MapReduce, Oozie, Hive, Pig)', 'Strong critical thinking, decision making, and problem-solving skills', 'Excellent verbal/written communication skills, including communicating technical issues to non-technical audiences', 'Bachelor’s degree in a computer related field or equivalent professional experience required', 'Experience in designing efficient and robust ETL/ELT workflows, schedulers, and event-based triggers', 'Experience with Spark core and Spark SQL', 'Experience as a Big Data Developer', 'Exposure to Data Mining, Data Engineering and Data Modeling', 'Exposure to Graph Databases', 'Premier Medical, Dental and Vision Insurance with no waiting period**', 'Paid Vacation, Sick and Parental Leave', '401(k) Plan with Profit Sharing', 'Tuition Reimbursement', 'Paid Training and Licensures', 'Benefits may be different by location. Benefit eligibility requirements vary and may include length of service.']",2020-12-30 23:14:37
"Data Software Engineer, Flight Test",LOCKHEED MARTIN CORPORATION,"4 out of 5 from 8,473 employee ratings","Jupiter, FL 33478","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'C++', 'Java', 'Hibernate', 'JPA', 'JSF 2', 'experience with aviation digital data bus technologies such as MIL-STD-1553, ARINC429, and IRIG-106 data formats', 'web application development using JSF', 'Primefaces', 'Postgres (SQL)', 'JavaScript', 'CSS', 'Html 5', 'Spring Framework', 'Spring Security', 'Tomcat', 'Version Control', 'Jasper Reports']",2020-12-30 23:14:37
Data Services Engineer,Denodo Technologies,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical discussion, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning.', 'Constantly learn new things and maintain an overview of modern technologies.', 'Provide technical consulting, training and support.', 'Diagnose and resolve clients inquiries related to operating Denodo software products in their environment.', 'Participate in problem escalation and call prevention activities to help clients and other technical specialists increase their efficiency when using Denodo products.', 'Be able to address a majority of technical questions concerning customization, integration, enterprise architecture and general feature / functionality of our product.', 'Provide timely, prioritized and complete customer-based feedback to Product Management, Sales, Support and/or Development regarding client’s business cases, requirements and issues.', 'Train and engage clients in the product architecture, configuration, and use of the Denodo Platform.', 'Promote knowledge and best practices while managing deliverables and timelines.', 'Capable of building and/or leading the development of custom deployments based on and even beyond client’s requirements.', 'Manage client expectations, establish credibility at all levels within the client and build problem-solving partnerships with the client, partners and colleagues.', 'Participate in on-call support of Denodo products.', 'Be willing to travel as necessary to address or service customer needs.', 'BS or higher degree in Computer Science.', 'Solid understanding of SQL and good grasp of relational and analytical database management theory and practice.', 'Good knowledge of JDBC, XML and Web Services APIs.', 'Excellent verbal and written communication skills to be able to interact with technical and business counterparts.', 'Active listener.', 'Strong analytical and problem solving abilities.', 'Lots of curiosity. You never stop learning new things.', 'Creativity. We love to be surprised with innovative solutions.', 'Willingness to travel on occasion.', 'Be a team worker with positive attitude.', 'Experience working with GIT or other version control systems.', 'Experience working with Big Data and/or noSQL environments like Hadoop, mongoDB, others.', 'Knowledge and experience with systems and services hosted in the main cloud vendors (AWS, Azure, GCP).', 'Experience working with caching approaches and technologies such as JCS.', 'Experience in Windows & Linux (and UNIX) operating systems in server environments.', 'Business software implementation and integration projects (e.g. ETL/Data Warehouse architectures, CEP, BPM).', 'Integration with packaged applications (e.g. relational databases, SAP, Siebel, Oracle Financials, Business Intelligence tools, …).', 'Industry experience in supporting mission critical software components.', 'Experience in attending customer meetings and writing technical documentation.', 'Experience in Java software development, especially in the web and database fields.', 'Foreign language skills are a plus.', 'We are committed to equal employment opportunity.', 'We respect, value and welcome diversity in our workforce.', 'We do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement. Therefore, any resume received from an unapproved supplier will be considered unsolicited, and we will not be obligated to pay a referral fee.']",2020-12-30 23:14:37
Data Engineer - CIJ (NYC),Vera Institute of Justice,3.9 out of 5 from 15 employee ratings,"Brooklyn, NY 11232","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'We study problems that impede human dignity and justice.', 'We pilot solutions that are at once transformative and achievable.', 'We engage diverse communities in informed debate.', 'And we harness the power of evidence to drive effective policy and practice.', 'Create and support systems and processes for collecting, compiling, manipulating, and analyzing data to support CIJ’s program & researchWork with immigration research and program management staff to identify & solve for difficult data ingestion, migration, management, and integration challengesDesign data models & set up data environments to support reporting & analysisBuild and test data ingestion, migration, and ETL processesAutomate processes and schedule jobs within the data environmentWrite documentation of systems & processes for collaboration within CIJ’s research and programs', 'Ensure data ecosystems are security compliant and properly integrated with Vera’s IT systems where applicableWork closely with IT to ensure compliance & integration of systems', 'Other technical program & research support as assigned', '2-3 years of full-time experience in a data engineering capacity', 'Experience collaborating directly with data scientists and data analysts who develop analyses in any combination of R, Python, SQL, Tableau, Stata, etc. preferred', 'Prior experience designing and developing data models, building out and testing ETL data pipelines, and automating scheduled workflows using SQL & Python', 'Fluency in collaborating with Git & Github, with dedication to using these tools to conduct peer code reviews and uphold coding standards', 'High comfort level with ingesting messy source datasets that are prone to manual data entry errors and integrating these into a live database', 'Ability to build repeatable and well-documented processes and tools that can be used by other research & analytics team members, regardless of the languages they use to perform their analyses', 'Excellent oral and written communication skills, including ability to present and teach the use of data infrastructure to a range of audiences in a variety of formats, and work effectively on a large team to advance shared priorities.', 'Strong social and emotional awareness with your team and external partners.', 'Experience with Linux and bash scripting highly preferred', 'Experience with Docker and deploying Docker images highly preferred', 'Experience with automating bespoke tasks (e.g. basic web scraping, using 3rd party APIs) highly preferred', 'Familiarity with government security compliance standards is a plus', 'Working knowledge of AWS data product ecosystem is a plus', 'This position may require low-level government security clearance in the future to handle secure data. However, this is not a current requirement for hiring.', 'This is a full-time position located at Vera’s Brooklyn, New York office', 'Salary is competitive plus excellent benefits']",2020-12-30 23:14:37
Data Scientist,US Legislative Branch,4.2 out of 5 from 82 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Leads projects through the innovation lifecycle from ideation through deployment in order to develop next generation advanced analytics capabilities in support of current and future audits, investigations, business operations, and other oversight challenges relevant to GAO’s mission. As necessary, the incumbent will work with experts outside GAO to determine leading practices for advanced analytics.', 'Applies and combines diverse data science techniques including: Machine Learning, natural language processing, artificial intelligence, geospatial analyses, graph-based network modeling, advanced visualizations, descriptive statistics, and other statistical/mathematical/analytical methods to produce cohesive, user-centric solutions.', 'Builds, optimizes, orchestrates, deploys, and tunes data science models and prototypes. Assesses disparate impacts, mitigates model biases, and evaluates relevant performance criteria, as applicable.', 'Uses common data science tools, including scripted languages such as R, Python, SQL, and Java Scripts; Integrated Development Environment (IDE) and analytics platforms such as RStudio, SageMaker, RapidMiner, SAS, and Domino Data Lab; open-source solutions such as Kibana, Kubernetes, and elastic search; commercial off-the-shelf tools such as Informatica and Neo4j; and hardware-based capabilities such as Graphics Processing Units (GPU).', 'Implements data quality considerations, including complex data processing, data quality assessment, data imputation, and data governance—including metadata as well as engineered features. Develops forensically sound, auditable, flexible, repeatable, and scalable extract transform and load (ETL) capabilities on a variety of structure and unstructured data.', 'Uses cloud-based Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and Software-as-a-Service (SaaS) capabilities to perform data science. Guides implementation and configuration of tools and other computational resources within established information security boundaries.', 'Contributes to process development for and agile team culture of the Innovation Lab. Understands Generally Accepted Government Auditing Standards (GAGAS) and other relevant standards to advise GAO teams on best technical approaches to achieve quality results.', 'Identifies deficiencies in problem statements, proposed approaches, and/or data access issues which are significant to the design, development, execution, and reporting out of advanced analytics pilots of the Innovation Lab.', 'Supports the Assistant Director in developing, defining, and driving Innovation Lab strategy with regard to the exploration and deployment of advanced analytics techniques for improved or novel business outcomes.', 'Supports Assistant Director in project management, acquisition project management, and stakeholder management. Incumbent may require certification as a level II COR, IT Project Manager, Scrum Master, or similar.', 'Expands GAO’s advanced analytics and computational capabilities through a rigorous process of problem definition, ideation, review, revision, and execution to determine the most promising solutions and approaches which, if successful, could profoundly change the business of audit, investigations, and program evaluation for the future GAO.', 'Performs other duties as assigned.', 'Job family (Series)0801 General Engineering1529 Mathematical Statistics', 'RequirementsRequirementsConditions of EmploymentMust be U.S. citizenYou must be suitable for federal employment.You must be registered with the Selective Service as applicable.You may be required to submit a financial disclosure statement.Employees new to GAO must complete a two year probationary period.QualificationsApplicants must have 1 year (52 weeks) of specialized experience at the next lower band level which has equipped the applicant with the skills and knowledge to successfully perform the duties of the position. Specialized experience for this position is defined as:Applying at least three of the following advanced data science techniques in a professional setting:Machine Learning (ML), including supervised, unsupervised, and adversarial;Natural language processing (NLP), including sentiment classification and topic modeling;Artificial Intelligence, including deep learning and robotics process automation (RPA);Mathematical/statistical/analytical methods, including dimension reduction, entity resolution, rules-based queries, algorithm development, modeling, predictive analytics, descriptive statistics, sampling design, experimental design, and significance testing;Extraction and processing methods for structured and unstructured data, including assessing data quality, imputation, applying governance, development of well-documented, flexible, repeatable, and scalable ETL routines across diverse data processing systems and data warehouses/lakes; andVisualization, including descriptive charts and maps, geospatial analyses, and graph-based network modeling.Using at least two data science languages and at least two data science tools in a professional setting. Examples include:R, SAS, or STATAPython and JupyterTableau, Neo4J, or GISMatlab, Maple, MathematicaSQL with relational databasesDeveloping automation that reduced burden, increased efficiency, reduced errors, or increased productivity.Using agile techniques to manage data science projects.Communicating technical information to non-technical audiences.You must meet all the requirements before the announcements closes.EducationThis position has a positive education requirement. Documentation to verify your education MUST be submitted with your application in order to be considered.General Engineering Series, 0801You must meet one of the following:Degree - Engineering. To be acceptable, the program must: (1) lead to a bachelor’s degree in a school of engineering with at least one program accredited by ABET; or (2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics.Professional registration or licensure - Current registration as an Engineer Intern (EI), Engineer in Training (EIT), or licensure as a Professional Engineer (PE) by any State, the District of Columbia, Guam, or Puerto Rico. You are eligible only for positions that are closely related to the specialty field of your registration.Written Test - Evidence of having successfully passed the Fundamentals of Engineering (FE) examination or any other written test required for professional registration by an engineering licensure board in the various states, the District of Columbia, Guam, and Puerto Rico.Specified academic courses - Successful completion of at least 60 semester hours of courses in the physical, mathematical, and engineering sciences and that included the courses specified in the basic requirements Degree. The courses must be fully acceptable toward meeting the requirements of an engineering program as described in Degree.Related curriculum - Successful completion of a curriculum leading to a bachelor\'s degree in an appropriate scientific field, e.g., engineering technology, physics, chemistry, architecture, computer science, mathematics, hydrology, or geology, AND at least 1 year of professional engineering experience acquired under professional engineering supervision and guidance.Mathematical Statistics Series, 1529You must meet one of the following:Degree - that included 24 semester hours of mathematics and statistics, of which at least 12 semester hours were in mathematics and 6 semester hours were in statistics.Combination of education and experience - at least 24 semester hours of mathematics and statistics, including at least 12 hours in mathematics and 6 hours in statistics, as shown in Degree, plus appropriate experience or additional education.Additional informationThis is a bargaining unit position.Based on the staffing needs, additional selections may be made through this vacancy announcement.Selectee may be required to file a Financial Disclosure Statement.Travel and relocation expenses will not be paid for by the GAO.Males born after 12/31/59 and at least 18 years of age must be registered with the Selective Service System. Visit http://www.sss.gov/.Please be aware that applicants will be required to complete questions contained on the Declaration for Federal Employment (OF-306) at the time a tentative job offer is made. If selected, at the time of appointment, selectees will be required to update the OF-306.If you are selected for this position, you will be subject to a determination of your suitability for Federal employment.The U.S. Government Accountability Office’s policy is to provide equal employment opportunity for all regardless of race, religion, color, sex (including pregnancy), national origin, age, disability, genetic information, sexual orientation, or gender identity.The U.S. GAO is part of the Legislative Branch of the Federal government. As such, all positions are in the excepted service. Initial appointments, permanent or indefinite, to the GAO require completion of a one-year or two-year probationary period.Newly hired or recently promoted PE-I staff begin their careers by participating in GAO\'s 2-year Professional Development Program (PDP) for entry-level analysts. The PDP experience includes a combination of on-the-job and classroom training, regular feedback and coaching, and exposure to different projects, issues, and management styles. Project assignments are based on a combination of GAO\'s needs and your background and interests. The PDP will place you in various project assignments that provide you with a range of developmental opportunities.How You Will Be EvaluatedYou will be evaluated for this job based on how well you meet the qualifications above.There is a severe shortage of candidates for this position. To expedite the hiring process, we have eliminated competitive rating and ranking, veterans\' preference, and ""rule of three"" or category rating procedures.Please make sure that your responses to the assessment questions are supported in your resume and follow all instructions carefully. If you provide incomplete answers, fail to provide a narrative response to any assessment question(s) that requires further explanation, or if your response to an assessment question is ""see resume,” your application may be affected or you may be determined ineligibleAll applicants will be evaluated based on their responses to the assessment questions, in conjunction with the following Knowledge, Skills and Abilities (KSA’s):Knowledge of all of, and skill in applying three or more of, the following data science techniques:Machine Learning (ML), including supervised, unsupervised, and adversarial;Natural language processing (NLP), including sentiment classification and topic modeling;Artificial Intelligence, including deep learning and robotics process automation (RPA);Mathematical/statistical/analytical methods, including dimension reduction, entity resolution, rules-based queries, algorithm development, modeling, predictive analytics, descriptive statistics, sampling design, experimental design, and significance testing;Extraction and processing methods for structured and unstructured data, including assessing data quality, imputation, applying governance, development of well-documented, flexible, repeatable, and scalable ETL routines across diverse data processing systems and data warehouses/lakes; andVisualization, including descriptive charts and maps, geospatial analyses, and graph-based network modeling.Skill in applying emerging theoretical methods to solve complex and previously unsolved data science problems.Ability to use cloud-based Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and Software-as-a-Service (SaaS) capabilities for data science, which may include implementing and configuring tools and resources within established information security boundaries.Skill applying principles and methods with sufficient rigor to support activities under the Generally Accepted Government Auditing Standards (GAGAS) and Generally Accepted Accounting Principles (GAAP).Skill in selecting, organizing, and presenting appropriate information in a concise and balanced manner as well as skill in communicating such information to non-technical and technical target audiences alike.Ability to communicate well both in writing and orally, including preparing reports, participating in interviews and meetings, and to making presentations. By way of definition, oral communication may include methods used by employees with disabilities such as sign language interpretation, text-to-speech or TTY technology, and amplification devices.Ability to collaborate and work effectively and complete projects in a group setting, particularly across organizational boundaries and with those with less technical backgrounds.To preview questions please click here.Background checks and security clearanceSecurity clearanceSecretDrug test requiredNo', 'Must be U.S. citizen', 'You must be suitable for federal employment.', 'You must be registered with the Selective Service as applicable.', 'You may be required to submit a financial disclosure statement.', 'Employees new to GAO must complete a two year probationary period.', 'Applying at least three of the following advanced data science techniques in a professional setting:Machine Learning (ML), including supervised, unsupervised, and adversarial;Natural language processing (NLP), including sentiment classification and topic modeling;Artificial Intelligence, including deep learning and robotics process automation (RPA);Mathematical/statistical/analytical methods, including dimension reduction, entity resolution, rules-based queries, algorithm development, modeling, predictive analytics, descriptive statistics, sampling design, experimental design, and significance testing;Extraction and processing methods for structured and unstructured data, including assessing data quality, imputation, applying governance, development of well-documented, flexible, repeatable, and scalable ETL routines across diverse data processing systems and data warehouses/lakes; andVisualization, including descriptive charts and maps, geospatial analyses, and graph-based network modeling.', 'Using at least two data science languages and at least two data science tools in a professional setting. Examples include:', 'Developing automation that reduced burden, increased efficiency, reduced errors, or increased productivity.', 'Using agile techniques to manage data science projects.', 'Communicating technical information to non-technical audiences.', 'Degree - Engineering. To be acceptable, the program must: (1) lead to a bachelor’s degree in a school of engineering with at least one program accredited by ABET; or (2) include differential and integral calculus and courses (more advanced than first-year physics and chemistry) in five of the following seven areas of engineering science or physics: (a) statics, dynamics; (b) strength of materials (stress-strain relationships); (c) fluid mechanics, hydraulics; (d) thermodynamics; (e) electrical fields and circuits; (f) nature and properties of materials (relating particle and aggregate structure to properties); and (g) any other comparable area of fundamental engineering science or physics, such as optics, heat transfer, soil mechanics, or electronics.', 'Professional registration or licensure - Current registration as an Engineer Intern (EI), Engineer in Training (EIT), or licensure as a Professional Engineer (PE) by any State, the District of Columbia, Guam, or Puerto Rico. You are eligible only for positions that are closely related to the specialty field of your registration.', 'Written Test - Evidence of having successfully passed the Fundamentals of Engineering (FE) examination or any other written test required for professional registration by an engineering licensure board in the various states, the District of Columbia, Guam, and Puerto Rico.', 'Specified academic courses - Successful completion of at least 60 semester hours of courses in the physical, mathematical, and engineering sciences and that included the courses specified in the basic requirements Degree. The courses must be fully acceptable toward meeting the requirements of an engineering program as described in Degree.', ""Related curriculum - Successful completion of a curriculum leading to a bachelor's degree in an appropriate scientific field, e.g., engineering technology, physics, chemistry, architecture, computer science, mathematics, hydrology, or geology, AND at least 1 year of professional engineering experience acquired under professional engineering supervision and guidance."", 'Degree - that included 24 semester hours of mathematics and statistics, of which at least 12 semester hours were in mathematics and 6 semester hours were in statistics.', 'Combination of education and experience - at least 24 semester hours of mathematics and statistics, including at least 12 hours in mathematics and 6 hours in statistics, as shown in Degree, plus appropriate experience or additional education.', 'Knowledge of all of, and skill in applying three or more of, the following data science techniques:Machine Learning (ML), including supervised, unsupervised, and adversarial;Natural language processing (NLP), including sentiment classification and topic modeling;Artificial Intelligence, including deep learning and robotics process automation (RPA);Mathematical/statistical/analytical methods, including dimension reduction, entity resolution, rules-based queries, algorithm development, modeling, predictive analytics, descriptive statistics, sampling design, experimental design, and significance testing;Extraction and processing methods for structured and unstructured data, including assessing data quality, imputation, applying governance, development of well-documented, flexible, repeatable, and scalable ETL routines across diverse data processing systems and data warehouses/lakes; andVisualization, including descriptive charts and maps, geospatial analyses, and graph-based network modeling.', 'Skill in applying emerging theoretical methods to solve complex and previously unsolved data science problems.', 'Ability to use cloud-based Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and Software-as-a-Service (SaaS) capabilities for data science, which may include implementing and configuring tools and resources within established information security boundaries.', 'Skill applying principles and methods with sufficient rigor to support activities under the Generally Accepted Government Auditing Standards (GAGAS) and Generally Accepted Accounting Principles (GAAP).', 'Skill in selecting, organizing, and presenting appropriate information in a concise and balanced manner as well as skill in communicating such information to non-technical and technical target audiences alike.', 'Ability to communicate well both in writing and orally, including preparing reports, participating in interviews and meetings, and to making presentations. By way of definition, oral communication may include methods used by employees with disabilities such as sign language interpretation, text-to-speech or TTY technology, and amplification devices.', 'Ability to collaborate and work effectively and complete projects in a group setting, particularly across organizational boundaries and with those with less technical backgrounds.', 'Required DocumentsRequired DocumentsYou must provide a complete application package which includes:Resume: must be created using the USAJOBS resume builder and show relevant work experience.If you are using your education to qualify (even partially), you must submit a copy of your transcripts. Transcripts do not need to be official, but if you are selected for this position and you used your education to qualify, you will be required to provide official transcripts. Foreign Education: If you are submitting a transcript from a non-US educational institution, applicants must submit all necessary documents to a private U.S. organization that specializes in interpretation of foreign educational credentials, commonly called a credential evaluation service.For every transcript uploaded, ensure the transcript shows the name of the school, degrees earned at the school, and the date degrees were conferred.Current or former federal employees may submit their most recent Notification of Personnel Action (SF-50 or equivalent), showing tenure, type of service (competitive/excepted) and the highest grade held.Are you using professional registration, licensure, or written test to meet the basic requirements? Upload proof of your claim under Copy of License Document Type in Career Connector.Failure to submit any of the above mentioned required documents will result in loss of consideration due to an incomplete application package. It is your responsibility to ensure all required documents have been submitted.If you are relying on your education to meet qualification requirements:Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications. Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education.Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.', 'Resume: must be created using the USAJOBS resume builder and show relevant work experience.', 'If you are using your education to qualify (even partially), you must submit a copy of your transcripts. Transcripts do not need to be official, but if you are selected for this position and you used your education to qualify, you will be required to provide official transcripts. Foreign Education: If you are submitting a transcript from a non-US educational institution, applicants must submit all necessary documents to a private U.S. organization that specializes in interpretation of foreign educational credentials, commonly called a credential evaluation service.', 'Current or former federal employees may submit their most recent Notification of Personnel Action (SF-50 or equivalent), showing tenure, type of service (competitive/excepted) and the highest grade held.', 'Are you using professional registration, licensure, or written test to meet the basic requirements? Upload proof of your claim under Copy of License Document Type in Career Connector.', 'BenefitsBenefitsA career with the U.S. Government provides employees with a comprehensive benefits package. As a federal employee, you and your family will have access to a range of benefits that are designed to make your federal career very rewarding. Learn more about federal benefits.Individuals selected will be eligible for a full range of federal employment benefits including vacation and sick leave, retirement coverage and Thrift Savings Plan, and health and life insurance. A complete list of benefits is available on the web athttp://www.gao.gov/careers/benefits.htmlReview our benefitsEligibility for benefits depends on the type of position you hold and whether your position is full-time, part-time, or intermittent. Contact the hiring agency for more information on the specific benefits offered.', 'The publicU.S. citizens, nationals or those who owe allegiance to the U.S.']",2020-12-30 23:14:37
Data Engineer,Rocket Loans,2.5 out of 5 from 2 employee ratings,"Detroit, MI 48226","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's degree in engineering, computer science, information technology or a related field"", '3 years of hands-on experience as a Data Engineer/ETL Developer working with data lake and data warehouse technologies', 'Experience with Python or R for data manipulation', 'SQL expertise in one or more relational databases', 'Architectural understanding of integration patterns, approaches, best practices and standards', 'Understanding of the technology processes such as the software development life cycle using the Agile methodology, testing approaches and software release management', 'Understanding of application integration concepts; familiarity with platforms such as Azure Data Factory or Informatica', 'Experience working with cloud infrastructure such as AWS or Azure', 'Design, develop and support the data and application integration processes', 'Assist in gathering requirements for data solutions and maintaining data mapping specifications', 'Collaborate with data analysts and data scientists on the design of data structures to support reporting and machine learning solutions', 'Understand, follow and drive design principles and best practices for the integration techniques and architecture', 'Monitor and troubleshoot production issues related to the integration jobs']",2020-12-30 23:14:37
Trading Data Analyst/Engineer,"TradeSpace, LLC",N/A,"San Juan, PR 00912","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Python: 1 year (Required)Spanish (Required)Bachelor's (Preferred)data visualization libraries: 1 year (Preferred)English (Preferred)"", 'Experience working with large financial datasets like market data, order/execution data, or positions data.', 'Experience with data visualization libraries.', 'CPA or bachelor’s degree in finance.', 'Proficiency in Python or R.', 'Experience with machine learning techniques and advanced analytics (e.g. regression, classification, time series, econometrics, etc)', '10 hour shift', 'Monday to Friday', 'On call', 'Bonus pay', 'San Juan, PR 00909 (Required)', ""Bachelor's (Preferred)"", 'data visualization libraries: 1 year (Preferred)', 'large financial datasets like market data: 1 year (Preferred)', 'Python: 1 year (Required)', 'English (Preferred)', 'Spanish (Required)', 'tradepsace.us', 'tradespace', 'Waiting period may apply', 'YES_OCCASIONALLY']",2020-12-30 23:14:37
Senior Data Visualization Engineer- Tableau,Palo Alto Networks,3.9 out of 5 from 93 employee ratings,"Santa Clara, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Responsible for delivering Executive dashboards end to end with actionable insights and sub sec performance', 'Responsible for engaging Executives to gather requirements and use agile methodology to deliver dashboards', 'Using Tableau as your primary data visualization tool', 'Quick to learn new data visualization tools like Looker, Einstein Analytics etc', 'Conduct deep analysis to discover actionable business insights to grow palo alto networks business top line', 'Act as an Coach/Mentor for other Enterprise BI developers and influence Visualization best practices', 'Develop Customer and product analytics to support Quarterly Business Reviews (QBRs), executive briefings, and other executive-level business reviews.', 'Be a storyteller who can show the tell how to get business insights from the Dashboard', 'Overall 8 to 10 yrs of experience in BI/UI/UX domain', '3 to 5 years of experience working with Tableau', 'Ability to create actionable dashboards, passionate about data and good data evangelist', 'Strong experience in building dashboards in any of the BI Platforms', 'Should have experience in writing SQL queries to understand or build dashboards', 'Solve data and analytics problems using design thinking principles', 'Deep knowledge and understanding of Sales, Marketing and Customer success business domains', 'Excellent oral and written communications skills and ability to interact with and present to all levels of management', 'Self-starter with sharp decision making skills, ability to multitask, work independently and prioritize in a fast-paced and changing environment', 'Prior experience in high tech and software industries is beneficial.']",2020-12-30 23:14:37
Data Integration Engineer Associate,BAYADA Home Health Care,"3.8 out of 5 from 2,721 employee ratings",New Jersey,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Base Salary: $80,000 - $110,000 / year depending on qualifications', 'BAYADA offers a comprehensive benefits plan that includes the following: Paid holidays, vacation and sick leave, vision, dental and medical health plans, employer paid life insurance, 401k with company match, direct deposit and employee assistance program', 'To learn more about BAYADA Benefits, click here', 'Enjoy being part of a team that cares and a company that believes in leading with our values.', 'Be recognized and rewarded for your compassion, excellence, and reliability.', ""Develop working knowledge of BAYADA's mission, services, people, organization, policies and procedures."", 'Maintains competency in the development patterns used in integration solutions and advances knowledge via self-learning and training as appropriate.', 'Seeks out educational opportunities both within and outside the organization.', 'Works diligently to achieve consistent results in all areas of responsibility.', 'Meets work standards by following production, productivity, quality, and customer-service standards.', 'Reviews, analyzes, and evaluates business systems and identifies opportunities to expand master data quality and efficiencies.', 'Works diligently to refine analytical skills and problem-solving ability.', 'Uses advanced knowledge of the company and experience to inform good judgment', 'Contributes to design and task breakdowns and can estimate the time required to complete tasks for self.', 'Troubleshoot issues in production systems, recommend corrective actions and ownership of resolution.', 'Works with minimal supervision while following processes and best practices.', 'Plans and completes operational duties, goals and initiatives within schedule, budget, and span of decision-making responsibility.', 'Manage multiple initiatives from request to requirements to test to delivery while ensuring the best value for customers.', 'Perform related duties, or as required or requested by supervisor.', 'Exemplifies characteristics of The BAYADA Way: compassion, excellence and reliability.', 'Four (4) year college degree in a related area.', 'Three (3) or more years of relevant experience with growing responsibilities.', 'Must have C# and SQL server experience', 'Nice to have .Net Core, AWS Lambda, NoSQL, etc.', 'Competence in software required to perform job functions. Ability to learn new technologies, software, and technical methodologies. Strong knowledge of subject-specific technologies.', 'Excellent verbal and written communication skills and ability to discuss technical issues with non-technical audiences.', 'Ability to work independently, in addition to being self-motivated, flexible, versatile, and creative.', 'Exceeds performance standards and possesses a record of goal achievement.', 'Excellent understanding of business complexity and project interdependencies.', 'Demonstrated record of strong interpersonal skills. Self-starter and team player who excels at building trusting relationships.', 'Ability to work in a collaborative team environment.', 'Ability to read, write and effectively communicate in English.']",2020-12-30 23:14:37
Data Engineer,Crowdskout,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create highly scalable and robust data solutions for use by our products and clients', 'Design, build, and maintain multiple performant data pipelines & ETL / ELT flows against massive datasets', 'Ensure data accuracy and reliability', 'Strong SQL experience (any flavor)', 'Development experience using Python', 'Experience building large scale streaming and batch data pipelines (e.g. Python, Java)', 'Experience building out data warehouse and/or data lake infrastructure', 'Experience with data modeling and physical database design', 'Experience using Big Data technologies (e.g. Spark, Presto, Kafka)', 'Experience with SQL & NoSQL databases (e.g. MySQL, MongoDB)', 'AWS data stack (e.g. Kinesis, Glue, RDS, Athena, Redshift etc.)', 'Software development using PHP and Python', 'Graph database experience', 'Workflow management engine experience', 'Knowledge of data security best practices (e.g. data encryption, tokenization, masking)']",2020-12-30 23:16:20
BI Data Engineer,HI-REZ STUDIOS,3.4 out of 5 from 12 employee ratings,"Alpharetta, GA 30022","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop and maintain our data warehouse environment.', '3-6 years of IT operation, with understanding of database structures, theories, principles and practices.', '2-4 years of Microsoft SQL Server experience. SQL 2016. T-SQL. Stored procedures.', '2-4 years of Microsoft SSIS experience.', '1-2 years of Amazon Redshift experience.', 'Maintain, create, and monitor ETL processes.', 'Proactively monitor the system hardware utilization, make capacity planning periodically for database systems.', 'Establish and maintain appropriate end-user database access control levels, actively monitor the databases to ensure secure availability.', 'Create, maintain and extend scripts which are used in answering business questions or processing database changes.', 'Technical documentation skills.', 'Team-oriented but self-motivated.', 'Ability to effectively prioritize and execute tasks in a high-pressure environment.', 'Strong work ethic.', 'Problem solver.', 'BS Degree in one of the following subject areas: Computer Science or Information Technology.', 'Knowledge of reporting and query tools: Tableau, AnswerRocket.', 'Other programming languages: Python, Windows Powershell.', 'Experience with Microsoft Azure and Synapse']",2020-12-30 23:16:20
Data Engineer,Unified Women’s Healthcare,1.6 out of 5 from 5 employee ratings,"Louisville, KY 40241","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Intimate knowledge of SQL', '.NET Core 2.2 (C#)', 'Python', 'Azure and cloud computing', 'Azure DevOps', 'Data warehousing experience', 'Hadoop', 'Apache spark', 'Building processes for data transformation and data structures', 'Data mapping and building requirements', 'Standard ETL tools and techniques', 'Active Listening – Whether it is a colleague in Engineering or Product, it is our responsibility to listen and gain clarity on their input.', 'Creativity – There are always constraints to solving a problem, it is our jobs as Engineers to find those creative solutions to help with scalability, efficiency, and cost.', 'Cooperation – It has been proven time and again that more heads are better than one when it comes to building software. We practice no-ego development and focus on making the best product.', 'Initiative – There are going to be these slow times that pop-up, and we all must take this time to do something to better ourselves or the team. Sometimes rest is the right thing to do, too.', 'Learning – There is always something to learn from every situation.', 'Outlook – We focus on finding the solution to a problem, not all of the ways it can’t be solved.']",2020-12-30 23:16:20
Data Engineer,Sky Consulting Inc,N/A,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:16:20
Data Engineer,Verizon,"3.9 out of 5 from 27,913 employee ratings","San Antonio, TX 78202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Gather requirements, assess gaps, and build roadmaps and architectures to help the analytics driven organization achieve its goals.', 'Work closely with Data Analysts to ensure data quality and availability for analytical modelling.', 'Explore suitable options and designs for specific analytical solutions.', 'Define extract, load, and transform (ELT) based on jointly defined requirements.', 'Prepare, clean, and massage data for use in modeling and prototypes', 'Identify gaps and implement solutions for data security, quality, and automation of processes.', 'Support maintenance, bug fixes and, performance analysis along data pipeline.', 'Bachelor’s degree or four or more years of work experience.', 'Four or more years of relevant work experience.', 'Four or more years of experience as a data engineer', 'Four or more years of experience finding, cleaning, and preparing data for use by Data Scientists', 'Experience knitting disperate data sources together', 'Four or more years of experience building data pipelines', 'Experience using SQL (i.e., PL/SQL or T-SQL with RDBMSs like Teradata, MS SQL Server, Oracle, etc.)', 'Experience in data engineering, databases, and data warehouses.', 'Strong experience with data engineering in Python.', 'Ability to travel occasionally', 'Master’s degree in Computer Science, Engineering, Statistics, IT, or related field.', 'Experience with Scala, Julia, R, Python or other machine learning programming language', 'Experience on Big Data platforms (i.e., Hadoop, Map/Reduce, Spark, HBase, CouchDB, Hive, etc.)', 'Strong analytical and problem-solving skills.', 'Experience working in a network operations center environment.', 'Experience as an open source Ccntributor.']",2020-12-30 23:16:20
Data Engineer,DemystData,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Performing data appends, extracts, and analysis to deliver curated data to clients', ""Collaborating with project management, automation, and sales teams to solve clients' business and technical problems"", 'Understanding wide arrays of data provider landscapes including consumer, business, and property data', 'Building automation to download, clean, structure, import, and host data', 'Opportunities to work on entity detection, record linking, and NLP projects will also be available', 'Other tasks as necessary', ""Computer Science or Data Science degree (or commensurate work experience); Master's degree preferred"", '1-3 years of Python programming (with Pandas experience)', 'Experience with CSV and other common formats', 'Data cleaning and structuring (ETL experience)', 'Experience with SQL', 'Experience with Git', 'Interest or experience in machine learning, data modeling and/or API integrations', 'Work with the largest consumer and business external data market in an emerging industry that is fueling AI globally', 'Have an impact in a scaling but small team offering real autonomy and responsibility for client outcomes', 'Stretch yourself to help define and support something entirely new that will impact billions', 'Work within a strong, tight-knit team of subject matter experts', 'Small enough where you matter, big enough to have the support to deliver what you promise', 'Distributed working team and culture, recognition of outcomes and merit, not presenteeism', 'Generous benefits & competitive compensation']",2020-12-30 23:16:20
Data Engineer,LeafLink,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assist in building a high performing data platform which will power various reporting and analytics applications at LeafLink', 'Implementing ELT / ETL procedures to pipe data from ingestion source to data warehouse', 'Develop data models and schemas in our data warehouse that enable data and analytics processes', 'Maintain the data dictionary and documentation relating to the data warehouse serving all LeafLink functions and business divisions', 'Working closely with LeafLink software engineers on implementation of data models related to LeafLink applications', 'Addressing data quality issues originating at source and working with LeafLink vendors on solving quality issues and simplifying ingestion processes', 'Handle large volumes of data and integrate our platform with a range of internal and external systems', 'Proactively research and contribute ideas for improvement of data team processes', 'Troubleshoot and diagnose issues quickly and effectively', 'Maintain and evaluate quality of documentation, code, and business logic for data management at LeafLink', 'Expertise and hands-on experience working in a cloud based data stack (AWS preferred)', 'Expertise in developing and maintaining relational database structures and relationships', 'Expertise writing processing jobs to ingest a variety of structured and unstructured data received from various sources & formats such as Rest APIs, Flat Files, Logs', 'Expert level skills in using Python for data processing coupled with AWS offerings like Lambda, Step Functions', 'Expert level skills in writing & managing optimized SQL for creating, updating and querying source of truth tables', 'Hands-on experience with deployment using CI/CD, Docker;', 'Hands on experience with Airflow is a must', 'Experience using dbt is a strong plus', 'Comfortable in diagramming and documenting processes, relational structures using tools like Visio, Lucidchart, Confluence', 'Well-versed in version control systems (Git)', 'Experience working in a team with data scientists and analysts as clients is a plus', 'Experience with platforming ML & using Spark is a plus but not required', 'Comfortable working in a fast-paced growth business with many collaborators and quickly evolving business needs', 'Flexible PTO to give our employees a little extra R&R when they need it', 'Competitive compensation and 401k', 'Comprehensive health coverage (medical, dental, vision)', 'Commuter Benefits through a Flexible Spending Account', ""A robust stock option plan to give our employees a direct stake in LeafLink's success""]",2020-12-30 23:16:20
Data Engineer,Cars.com,3.8 out of 5 from 84 employee ratings,Illinois,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build data pipelines and deriving insights out of the data using advanced analytic techniques, streaming and machine learning at scale', 'Work within a dynamic, forward thinking team environment where you will design, develop, and maintain mission-critical, highly visible Big Data and Machine Learning applications', 'Build, deploy and support data pipelines and ML models into production.', 'Work in close partnership with other Engineering teams, including Data Science, & cross-functional teams, such as Product Management & Product Design', 'Opportunity to mentor others on the team and share your knowledge across the Cars.com organization', 'Ability to develop Spark jobs to cleanse/enrich/process large amounts of data.', 'Ability to develop Spark streaming jobs to read data from Kafka.', 'Experience with tuning Spark jobs for efficient performance including execution time of the job, execution memory, etc.', 'Sound understanding of various file formats and compression techniques.', 'Experience with source code management systems such as Github and developing CI/CD pipelines with tools such as Jenkins for data.', 'Ability to understand deeply the entire architecture for a major part of the business and be able to articulate the scaling and reliability limits of that area; design, develop and debug at an enterprise level and design and estimate at a cross-project level.', 'Ability to mentor developers and lead projects of medium to high complexity.', 'Excellent communication and collaboration skills.', 'Software Engineering | 3 - 5 years of designing & developing complex, real-time applications at enterprise scale; specifically Python and/or Scala.', 'Big Data Ecosystem | 2+ years of hands-on, professional experience with tools and platforms like Spark Streaming, EMR, Kafka.', 'AWS Cloud | 2+ years of professional experience in developing Big Data applications in the cloud, specifically AWS.', 'Experience with developing REST APIs.', 'Experience in deploying ML models into production and integrating them into production applications for use.', 'Experience with machine learning / deep learning using R, Python, Jupyter, Zeppelin, TensorFlow, etc.']",2020-12-30 23:16:20
Data Scientist Engineer,BlackBerry,4 out of 5 from 969 employee ratings,"Irving, TX 75039","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:16:20
Software Engineer - Entry Level,Jet Propulsion Laboratory,4.3 out of 5 from 134 employee ratings,"Pasadena, CA 91109","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Cybersecurity Engineer', 'Data Scientist', 'Data Visualization Developer', 'Electrical Ground Support Equipment Software Engineer', 'Engineering Applications Software Engineer', 'Flight Software Engineer', 'Scientific Application & Data Interaction Engineer', 'Scientific Applications Software Engineer', 'Software Systems Architect', 'Software Systems Engineer', 'Software Systems Engineer', 'User Interface Designer', 'User Interface Developer', ""Bachelor's, Master's, or PhD degree in Computer Science, Computer Engineering, Software Engineering, or related major."", 'Minimum of a 3.0/4.0 cumulative GPA.']",2020-12-30 23:16:20
Software Engineer (All Levels),Ribbon Health,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Passion and drive to simplify healthcare by building products that increase access to care and power every healthcare decision to be high-quality, cost-effective, and convenient', 'Commitment to Ribbon Health company values, working on an exceptional team, and building an exceptional company', 'Grit, hustle, desire, and a “get-it-done” attitude; strong comfort with a lean startup environment, where everyone is encouraged to participate in and contribute across all teams', 'Dedication to the creation of a diverse, equitable, and inclusive environment where teammates are celebrated for their unique perspectives and work together to simplify healthcare for all', 'You have experience working with data at scale (e.g., EMR, Hadoop, Spark, HBase, Presto, pushed the limits of Postgres) and are familiar with SQL', 'You have experience developing and deploying applications to a production environment', 'You have some experience designing, building, and/or managing scalable systems in the cloud (e.g., AWS, Google Cloud, Azure)', 'You care about building enterprise-grade systems because you understand how our products meaningfully impact patients downstream', 'You have a track record of learning new technologies and languages on the job', 'Although you’ll initially work mostly in Python, you’ll help us continue to evaluate new technologies and find the best tools for the job at hand', 'Build production-grade API platform: You will design, build, and maintain Ribbon’s core APIs and services, making sure our platform is enterprise-grade across end-user functionality, security, and scalability', 'Build and launch new products: You will work with the product team to design, build, and launch new products and product features. This includes new APIs to extend the reach of our core technology', 'Build data infrastructure and work closely with data pipelines: You will develop infrastructure to support our ETL, analytics, and modeling workflows. Data engineering is a core part of what we do, so you have to love working closely with data!', 'Build internal tools: You will help our internal teams 10x their efforts by developing tools to streamline their workflows (e.g. sales, deployment, recruiting, and product)', 'Evaluate third-party and open source software: You will make decisions about what we build versus buy and where to buy']",2020-12-30 23:16:20
Data Engineer,Hagerty Consulting Inc,N/A,"New York, NY 10038","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Serve as a day-to-day lead to ensure proper hotel booking vendor managing reservation and intake data in format that allow for the program to have seamless payment and auditing.', ""Provide protocols and formal guidance to Hotel Vendor re: reservation management. This means you'll be coordinating with outside partners (hotels)."", 'Lead a small team of data professionals tasked with the same assignments (please note this is a ""working manager"" and is a higher level technical contributor).', 'Ensure daily live dashboards are set up correctly and support special projects as needed.', 'Must have 5+ years of experience in data engineering', 'Must have experience with managing large data loads, scrubbing large data loads and creating dashboads.', 'Must have experience in Excel, PowerBI, and Tableau', 'Bachelors degree required']",2020-12-30 23:16:20
Data Warehouse Engineer,Walker & Dunlop,4 out of 5 from 25 employee ratings,"Bethesda, MD 20814","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Optimize, develop and maintain integration solutions using SQL Server SSIS and ETL framework (BIDS) as necessary to connect legacy data stores, the data warehouse, and third-party platforms including Salesforce', 'Identify and analyze data discrepancies and data quality issues and work to ensure data consistency and integrity', 'Ensure the stabilization and high performance of existing ETL processes', 'Troubleshoot any complex data-related issues as well as provide support to production', 'Develop and deploy ETL job workflow with reliable error/exception handling and rollback', 'Drive process improvement and improve process efficiency', 'Document all ETL and data warehouse processes and flows', 'Communicate issues, risks and concerns proactively to management', ""Bachelor's degree in Computer Science, Engineering or related discipline"", 'Minimum 2 years of professional experience in ETL development and Microsoft SSIS, SSAS', 'Minimum 2 years of professional experience in T-SQL development, debugging and optimization', 'Experience working in an Agile environment (Scrum, Kanban)', 'Effective decision making and critical thinking skills for problem identification and solution recommendations', 'Ability to be flexible, set priorities and meet deadlines in a changing environment for self and team', 'Passionate in providing excellent customer service', 'Outstanding verbal and written communication skills', 'Detail-oriented while consistently looking at the big picture', 'Experience with SQL Server Reporting Services (SSRS) and Microsoft Power BI is a plus']",2020-12-30 23:16:20
Data Engineer,NFI Industries,"3.2 out of 5 from 1,465 employee ratings","Camden, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company']",2020-12-30 23:16:20
Data Engineer,Nespon IT Services,N/A,"Oklahoma City, OK 73105","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Data engineering,database engineering, business intelligence: 5 years (Preferred)SQL queries across large data sets: 5 years (Preferred)data visualization and reporting packages: 5 years (Preferred)databases :SQL, MSSQL, MYSQL: 5 years (Preferred)programming languages :SQL, •\tR, C#, Python, JavaScript, XML: 5 years (Preferred)Big Data Technologies :Hadoop, Hive, Hbase, Pig, Spark: 3 years (Preferred)"", 'The Data Engineer should be an expert familiar with all areas of data warehousing technical components (e.g. ETL, Reporting, Data Model), infrastructure (e.g. hardware and software) and their integrations.', 'The ideal candidate will be responsible for developing the overall architecture and high-level design of the data schema environment. The candidate must have extensive experience with Star Schemas, Dimensional Models, and Data Mart’s.', 'The individual is expected to build efficient, flexible, extensible, and scalable ETL design and mappings. Excellent written and verbal communication skills are required as the candidate will work very closely with diverse teams.', 'A wide degree of creativity and latitude is expected. Reports to the Director of Data Services.', ""Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering). Master’s in computer science, mathematics, statistics, economics, or another quantitative field preferred."", '5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.', '5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.', '5+ years of experience in knowledge of and experience with data visualization and reporting packages (Cognos, Pureshare, PowerBI, etc.), databases (SQL, MSSQL, MYSQL, etc.), programming languages (SQL, R, C#, Python, JavaScript, XML, etc.).', 'Demonstrated strength in data modeling, ETL development, and Data warehousing.', 'Advanced knowledge and skills with Azure Data Lake, Azure SQL, Azure Data Factory, or similar cloud platforms.', 'Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.).', 'Experience in working and delivering end-to-end projects independently.', 'Knowledge of distributed systems as it pertains to data storage and computing.', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.', 'Technical expertise regarding data models, database design, data mining and segmentation techniques.', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.', 'Continuously monitor industry trends, technologies, and standards and be able to research, recommend, and apply new technologies as they emerge.', 'Experience with Microsoft platform-based SQL Server data systems is desired.', 'Experience with IBM midrange-based platforms and DB2 systems is desired.', 'Must be self-sufficient and have excellent English oral and written communications skills.', 'Ability to collaborate effectively and work as part of a team.', 'Experience in a franchised organization is a plus.', '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Data engineering,database engineering, business intelligence: 5 years (Preferred)', 'SQL queries across large data sets: 5 years (Preferred)', 'data visualization and reporting packages: 5 years (Preferred)', 'databases : SQL, MSSQL, MYSQL: 5 years (Preferred)', 'programming languages : SQL,  * R, C#, Python, JavaScript, XML: 5 years (Preferred)', 'Big Data Technologies : Hadoop, Hive, Hbase, Pig, Spark: 3 years (Preferred)', '1 year', 'Likely', 'Fully Remote', 'Temporarily due to COVID-19']",2020-12-30 23:16:20
Data Engineer,Sky Consulting Inc,N/A,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:18:02
Data Engineer,Verizon,"3.9 out of 5 from 27,913 employee ratings","San Antonio, TX 78202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Gather requirements, assess gaps, and build roadmaps and architectures to help the analytics driven organization achieve its goals.', 'Work closely with Data Analysts to ensure data quality and availability for analytical modelling.', 'Explore suitable options and designs for specific analytical solutions.', 'Define extract, load, and transform (ELT) based on jointly defined requirements.', 'Prepare, clean, and massage data for use in modeling and prototypes', 'Identify gaps and implement solutions for data security, quality, and automation of processes.', 'Support maintenance, bug fixes and, performance analysis along data pipeline.', 'Bachelor’s degree or four or more years of work experience.', 'Four or more years of relevant work experience.', 'Four or more years of experience as a data engineer', 'Four or more years of experience finding, cleaning, and preparing data for use by Data Scientists', 'Experience knitting disperate data sources together', 'Four or more years of experience building data pipelines', 'Experience using SQL (i.e., PL/SQL or T-SQL with RDBMSs like Teradata, MS SQL Server, Oracle, etc.)', 'Experience in data engineering, databases, and data warehouses.', 'Strong experience with data engineering in Python.', 'Ability to travel occasionally', 'Master’s degree in Computer Science, Engineering, Statistics, IT, or related field.', 'Experience with Scala, Julia, R, Python or other machine learning programming language', 'Experience on Big Data platforms (i.e., Hadoop, Map/Reduce, Spark, HBase, CouchDB, Hive, etc.)', 'Strong analytical and problem-solving skills.', 'Experience working in a network operations center environment.', 'Experience as an open source Ccntributor.']",2020-12-30 23:18:02
Data Engineer,DemystData,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Performing data appends, extracts, and analysis to deliver curated data to clients', ""Collaborating with project management, automation, and sales teams to solve clients' business and technical problems"", 'Understanding wide arrays of data provider landscapes including consumer, business, and property data', 'Building automation to download, clean, structure, import, and host data', 'Opportunities to work on entity detection, record linking, and NLP projects will also be available', 'Other tasks as necessary', ""Computer Science or Data Science degree (or commensurate work experience); Master's degree preferred"", '1-3 years of Python programming (with Pandas experience)', 'Experience with CSV and other common formats', 'Data cleaning and structuring (ETL experience)', 'Experience with SQL', 'Experience with Git', 'Interest or experience in machine learning, data modeling and/or API integrations', 'Work with the largest consumer and business external data market in an emerging industry that is fueling AI globally', 'Have an impact in a scaling but small team offering real autonomy and responsibility for client outcomes', 'Stretch yourself to help define and support something entirely new that will impact billions', 'Work within a strong, tight-knit team of subject matter experts', 'Small enough where you matter, big enough to have the support to deliver what you promise', 'Distributed working team and culture, recognition of outcomes and merit, not presenteeism', 'Generous benefits & competitive compensation']",2020-12-30 23:18:02
Data Engineer,LeafLink,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assist in building a high performing data platform which will power various reporting and analytics applications at LeafLink', 'Implementing ELT / ETL procedures to pipe data from ingestion source to data warehouse', 'Develop data models and schemas in our data warehouse that enable data and analytics processes', 'Maintain the data dictionary and documentation relating to the data warehouse serving all LeafLink functions and business divisions', 'Working closely with LeafLink software engineers on implementation of data models related to LeafLink applications', 'Addressing data quality issues originating at source and working with LeafLink vendors on solving quality issues and simplifying ingestion processes', 'Handle large volumes of data and integrate our platform with a range of internal and external systems', 'Proactively research and contribute ideas for improvement of data team processes', 'Troubleshoot and diagnose issues quickly and effectively', 'Maintain and evaluate quality of documentation, code, and business logic for data management at LeafLink', 'Expertise and hands-on experience working in a cloud based data stack (AWS preferred)', 'Expertise in developing and maintaining relational database structures and relationships', 'Expertise writing processing jobs to ingest a variety of structured and unstructured data received from various sources & formats such as Rest APIs, Flat Files, Logs', 'Expert level skills in using Python for data processing coupled with AWS offerings like Lambda, Step Functions', 'Expert level skills in writing & managing optimized SQL for creating, updating and querying source of truth tables', 'Hands-on experience with deployment using CI/CD, Docker;', 'Hands on experience with Airflow is a must', 'Experience using dbt is a strong plus', 'Comfortable in diagramming and documenting processes, relational structures using tools like Visio, Lucidchart, Confluence', 'Well-versed in version control systems (Git)', 'Experience working in a team with data scientists and analysts as clients is a plus', 'Experience with platforming ML & using Spark is a plus but not required', 'Comfortable working in a fast-paced growth business with many collaborators and quickly evolving business needs', 'Flexible PTO to give our employees a little extra R&R when they need it', 'Competitive compensation and 401k', 'Comprehensive health coverage (medical, dental, vision)', 'Commuter Benefits through a Flexible Spending Account', ""A robust stock option plan to give our employees a direct stake in LeafLink's success""]",2020-12-30 23:18:02
Data Engineer,Cars.com,3.8 out of 5 from 84 employee ratings,Illinois,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build data pipelines and deriving insights out of the data using advanced analytic techniques, streaming and machine learning at scale', 'Work within a dynamic, forward thinking team environment where you will design, develop, and maintain mission-critical, highly visible Big Data and Machine Learning applications', 'Build, deploy and support data pipelines and ML models into production.', 'Work in close partnership with other Engineering teams, including Data Science, & cross-functional teams, such as Product Management & Product Design', 'Opportunity to mentor others on the team and share your knowledge across the Cars.com organization', 'Ability to develop Spark jobs to cleanse/enrich/process large amounts of data.', 'Ability to develop Spark streaming jobs to read data from Kafka.', 'Experience with tuning Spark jobs for efficient performance including execution time of the job, execution memory, etc.', 'Sound understanding of various file formats and compression techniques.', 'Experience with source code management systems such as Github and developing CI/CD pipelines with tools such as Jenkins for data.', 'Ability to understand deeply the entire architecture for a major part of the business and be able to articulate the scaling and reliability limits of that area; design, develop and debug at an enterprise level and design and estimate at a cross-project level.', 'Ability to mentor developers and lead projects of medium to high complexity.', 'Excellent communication and collaboration skills.', 'Software Engineering | 3 - 5 years of designing & developing complex, real-time applications at enterprise scale; specifically Python and/or Scala.', 'Big Data Ecosystem | 2+ years of hands-on, professional experience with tools and platforms like Spark Streaming, EMR, Kafka.', 'AWS Cloud | 2+ years of professional experience in developing Big Data applications in the cloud, specifically AWS.', 'Experience with developing REST APIs.', 'Experience in deploying ML models into production and integrating them into production applications for use.', 'Experience with machine learning / deep learning using R, Python, Jupyter, Zeppelin, TensorFlow, etc.']",2020-12-30 23:18:02
Data Scientist Engineer,BlackBerry,4 out of 5 from 969 employee ratings,"Irving, TX 75039","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:18:02
Software Engineer - Entry Level,Jet Propulsion Laboratory,4.3 out of 5 from 134 employee ratings,"Pasadena, CA 91109","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Cybersecurity Engineer', 'Data Scientist', 'Data Visualization Developer', 'Electrical Ground Support Equipment Software Engineer', 'Engineering Applications Software Engineer', 'Flight Software Engineer', 'Scientific Application & Data Interaction Engineer', 'Scientific Applications Software Engineer', 'Software Systems Architect', 'Software Systems Engineer', 'Software Systems Engineer', 'User Interface Designer', 'User Interface Developer', ""Bachelor's, Master's, or PhD degree in Computer Science, Computer Engineering, Software Engineering, or related major."", 'Minimum of a 3.0/4.0 cumulative GPA.']",2020-12-30 23:18:02
Software Engineer (All Levels),Ribbon Health,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Passion and drive to simplify healthcare by building products that increase access to care and power every healthcare decision to be high-quality, cost-effective, and convenient', 'Commitment to Ribbon Health company values, working on an exceptional team, and building an exceptional company', 'Grit, hustle, desire, and a “get-it-done” attitude; strong comfort with a lean startup environment, where everyone is encouraged to participate in and contribute across all teams', 'Dedication to the creation of a diverse, equitable, and inclusive environment where teammates are celebrated for their unique perspectives and work together to simplify healthcare for all', 'You have experience working with data at scale (e.g., EMR, Hadoop, Spark, HBase, Presto, pushed the limits of Postgres) and are familiar with SQL', 'You have experience developing and deploying applications to a production environment', 'You have some experience designing, building, and/or managing scalable systems in the cloud (e.g., AWS, Google Cloud, Azure)', 'You care about building enterprise-grade systems because you understand how our products meaningfully impact patients downstream', 'You have a track record of learning new technologies and languages on the job', 'Although you’ll initially work mostly in Python, you’ll help us continue to evaluate new technologies and find the best tools for the job at hand', 'Build production-grade API platform: You will design, build, and maintain Ribbon’s core APIs and services, making sure our platform is enterprise-grade across end-user functionality, security, and scalability', 'Build and launch new products: You will work with the product team to design, build, and launch new products and product features. This includes new APIs to extend the reach of our core technology', 'Build data infrastructure and work closely with data pipelines: You will develop infrastructure to support our ETL, analytics, and modeling workflows. Data engineering is a core part of what we do, so you have to love working closely with data!', 'Build internal tools: You will help our internal teams 10x their efforts by developing tools to streamline their workflows (e.g. sales, deployment, recruiting, and product)', 'Evaluate third-party and open source software: You will make decisions about what we build versus buy and where to buy']",2020-12-30 23:18:02
Data Engineer,Hagerty Consulting Inc,N/A,"New York, NY 10038","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Serve as a day-to-day lead to ensure proper hotel booking vendor managing reservation and intake data in format that allow for the program to have seamless payment and auditing.', ""Provide protocols and formal guidance to Hotel Vendor re: reservation management. This means you'll be coordinating with outside partners (hotels)."", 'Lead a small team of data professionals tasked with the same assignments (please note this is a ""working manager"" and is a higher level technical contributor).', 'Ensure daily live dashboards are set up correctly and support special projects as needed.', 'Must have 5+ years of experience in data engineering', 'Must have experience with managing large data loads, scrubbing large data loads and creating dashboads.', 'Must have experience in Excel, PowerBI, and Tableau', 'Bachelors degree required']",2020-12-30 23:18:02
Data Warehouse Engineer,Walker & Dunlop,4 out of 5 from 25 employee ratings,"Bethesda, MD 20814","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Optimize, develop and maintain integration solutions using SQL Server SSIS and ETL framework (BIDS) as necessary to connect legacy data stores, the data warehouse, and third-party platforms including Salesforce', 'Identify and analyze data discrepancies and data quality issues and work to ensure data consistency and integrity', 'Ensure the stabilization and high performance of existing ETL processes', 'Troubleshoot any complex data-related issues as well as provide support to production', 'Develop and deploy ETL job workflow with reliable error/exception handling and rollback', 'Drive process improvement and improve process efficiency', 'Document all ETL and data warehouse processes and flows', 'Communicate issues, risks and concerns proactively to management', ""Bachelor's degree in Computer Science, Engineering or related discipline"", 'Minimum 2 years of professional experience in ETL development and Microsoft SSIS, SSAS', 'Minimum 2 years of professional experience in T-SQL development, debugging and optimization', 'Experience working in an Agile environment (Scrum, Kanban)', 'Effective decision making and critical thinking skills for problem identification and solution recommendations', 'Ability to be flexible, set priorities and meet deadlines in a changing environment for self and team', 'Passionate in providing excellent customer service', 'Outstanding verbal and written communication skills', 'Detail-oriented while consistently looking at the big picture', 'Experience with SQL Server Reporting Services (SSRS) and Microsoft Power BI is a plus']",2020-12-30 23:18:02
Data Engineer,NFI Industries,"3.2 out of 5 from 1,465 employee ratings","Camden, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company']",2020-12-30 23:18:02
Data Engineer,Nespon IT Services,N/A,"Oklahoma City, OK 73105","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Data engineering,database engineering, business intelligence: 5 years (Preferred)SQL queries across large data sets: 5 years (Preferred)data visualization and reporting packages: 5 years (Preferred)databases :SQL, MSSQL, MYSQL: 5 years (Preferred)programming languages :SQL, •\tR, C#, Python, JavaScript, XML: 5 years (Preferred)Big Data Technologies :Hadoop, Hive, Hbase, Pig, Spark: 3 years (Preferred)"", 'The Data Engineer should be an expert familiar with all areas of data warehousing technical components (e.g. ETL, Reporting, Data Model), infrastructure (e.g. hardware and software) and their integrations.', 'The ideal candidate will be responsible for developing the overall architecture and high-level design of the data schema environment. The candidate must have extensive experience with Star Schemas, Dimensional Models, and Data Mart’s.', 'The individual is expected to build efficient, flexible, extensible, and scalable ETL design and mappings. Excellent written and verbal communication skills are required as the candidate will work very closely with diverse teams.', 'A wide degree of creativity and latitude is expected. Reports to the Director of Data Services.', ""Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering). Master’s in computer science, mathematics, statistics, economics, or another quantitative field preferred."", '5+ years of relevant experience in one of the following areas: Data engineering, database engineering, business intelligence or business analytics.', '5+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.', '5+ years of experience in knowledge of and experience with data visualization and reporting packages (Cognos, Pureshare, PowerBI, etc.), databases (SQL, MSSQL, MYSQL, etc.), programming languages (SQL, R, C#, Python, JavaScript, XML, etc.).', 'Demonstrated strength in data modeling, ETL development, and Data warehousing.', 'Advanced knowledge and skills with Azure Data Lake, Azure SQL, Azure Data Factory, or similar cloud platforms.', 'Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.).', 'Experience in working and delivering end-to-end projects independently.', 'Knowledge of distributed systems as it pertains to data storage and computing.', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.', 'Technical expertise regarding data models, database design, data mining and segmentation techniques.', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.', 'Continuously monitor industry trends, technologies, and standards and be able to research, recommend, and apply new technologies as they emerge.', 'Experience with Microsoft platform-based SQL Server data systems is desired.', 'Experience with IBM midrange-based platforms and DB2 systems is desired.', 'Must be self-sufficient and have excellent English oral and written communications skills.', 'Ability to collaborate effectively and work as part of a team.', 'Experience in a franchised organization is a plus.', '8 hour shift', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Data engineering,database engineering, business intelligence: 5 years (Preferred)', 'SQL queries across large data sets: 5 years (Preferred)', 'data visualization and reporting packages: 5 years (Preferred)', 'databases : SQL, MSSQL, MYSQL: 5 years (Preferred)', 'programming languages : SQL,  * R, C#, Python, JavaScript, XML: 5 years (Preferred)', 'Big Data Technologies : Hadoop, Hive, Hbase, Pig, Spark: 3 years (Preferred)', '1 year', 'Likely', 'Fully Remote', 'Temporarily due to COVID-19']",2020-12-30 23:18:02
Software Engineer Intern (Summer 2021) - Remote,Wish,3.9 out of 5 from 28 employee ratings,"San Francisco, CA 94103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Solid foundation in computer science, math and/or software engineering', 'Strong competencies in data structures, algorithms and software design', 'Interest in end-to-end feature development from design to execution', 'Self-motivated, smart, hands-on, relentlessly focused on impact, and able to operate under a great deal of independence', 'Strong desire to improve the design, implementation, and maintenance of large software systems with millions of users', 'Interest and ability to build features quickly and iterate in a data-driven fashion', 'A passion for hacking social e-commerce is a must']",2020-12-30 23:18:02
Data Pipeline Engineer,IBM,"3.9 out of 5 from 30,506 employee ratings","Baton Rouge, LA 70802","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'http://www.ibm.com/ibm/responsibility/initiatives.html', 'http://www.ibm.com/ibm/responsibility/corporateservicecorps', 'Minimum 5 year of hands-on coding experience in Scala or Java', 'Minimum 3 years of experience in Big Data technologies (Kafka and Hive and Hadoop and HBase and Spring Cloud)', 'Minimum 3 years of hands-on experience in core Spark and Spark SQL and Spark Streaming', 'Experience in CI/CD using Jenkins and Gradle', 'Experience in Kubernetes and Docker', 'Big Data Certifications on Cloudera/Hortonworks/AWS/GCP/Azure']",2020-12-30 23:18:02
Data Engineer 3,Kagr Llc,N/A,"Foxborough, MA 02035","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Data Integration', 'Using the enterprise ETL tool, create modify, and improve integration pipelines', 'Translate business requirements into data warehouse pipelines using ETL/ELT methodologies', 'Extract and load many disparate systems into a centralized data warehouse', 'Assist in gathering requirements for new pipelines', 'Documentation and Data Auditing', 'Implement data auditing strategies and processes to ensure data integrity', 'Document complex integration pipelines into easy-to-understand technical specifications', 'Perform data modeling to document existing and new tables in the data warehouse', 'BIDW Continuous Development', 'Monitor and troubleshoot data problems', 'Identify ways to improve existing processes', 'Handle multiple projects and meet deadlines', 'Additional projects and assignments as directed', ""Bachelor's Degree in Computer Science, Information Systems, or related field."", '3-5 years of experience working with data using SQL or similar technology', '3+ years of experience using a data integration platform, such as Snaplogic, SSIS, or Informatica', 'Strong understanding of data warehousing principles and methodologies', 'Ability to manage multiple projects in a fast-paced environment', 'Strong communication skills to all levels of technical expertise', 'Very high attention to detail', 'Familiarity with BI Visualization tools', 'Sitting for extended periods of time', 'Dexterity of hands and fingers to operate a computer keyboard, mouse, and other computing equipment', 'The employee frequently is required to talk or hear', 'The employee is occasionally required to reach with hands and arms', 'Specific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception, and ability to adjust focus', 'Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.', 'The noise level in the work environment is usually moderate', 'Fast paced office environment', 'Ability to work nights and weekends as business dictates']",2020-12-30 23:18:02
"Data Science Engineer, Recent Graduate",eBay Inc.,"3.9 out of 5 from 1,691 employee ratings","San Jose, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, implement and deploy Machine Learning technologies into reliable and scalable services.', 'Monitor and ensure life cycle maintenance of Machine Learning models and services.', 'Estimate engineering effort, plan feature implementations, and rollout complexRESTful services.', 'Push the bar to solve complex technical challenges of scale and performance.', 'Must be able to independently design code and test major features, as well as work jointly with other team members to deliver complex changes.', 'Must be currently enrolled in a full-time, degree-seeking program and in the process of obtaining a Bachelors, Masters or PhD degree in Computer Science, Statistics, Mathematics or a related field.', 'Well versed in machine learning, information retrieval, applied statistics', 'Expertise in Deep Learning.', 'Experience with building Machine Learning models and working with libraries like Scikit, Tensorflow or FastText.', 'Hands-on industrial experience with big data processing using Hadoop, Pig/Hive or similar.', '2+ years of software design and development experience with languages such as Java, C++, Scala, Python.', 'Agility to adapt to emerging challenges and execute under ambiguity.', 'Familiarity with NoSQL database experience.', 'Agile development experience is a plus.', 'Self-motivated and fast learner. Excellent communication, presentation, interpersonal and analytical skills.']",2020-12-30 23:19:45
Entry Level Software Engineer,BAE Systems,"3.8 out of 5 from 4,092 employee ratings","Wayne, NJ 07470","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Designing, developing and testing software solutions utilizing Agile methodologies and sound software engineering principles while conforming to existing code development strategies and processes', 'Assisting in other software engineering activities such as integration testing, algorithm & data analysis, software troubleshooting, and preparing documentation in accordance with established procedures.', 'Utilizing either Windows PC or Linux based software development environment and either x86 or PowerPC target and test environment', ""Bachelor's degree in CS (Computer Science), CE (Computer Engineering), or other Scientific degree with suitable software engineering content."", '0-3 years professional software development experience', 'Software coding utilizing modern programming languages (e.g. C++, C#, Java, etc)', 'Object oriented design/development', 'Windows/Linux/Unix OS', 'Must be eligible for a US DoD security clearance', 'Real-time embedded development or other hardware-related skills', 'GPA of 3.0 or higher is strongly preferred', 'Security clearance (secret or higher)']",2020-12-30 23:19:45
Voice/Data Engineer,Farfield Systems,N/A,"Washington, DC 20020","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Responsible for the design and development of voice, video, radio-frequency, and/or data communications networks.', 'Provides expert level analysis of data communications networks, including planning, designing, evaluating, selecting, and upgrading operating systems and protocol suites and configuring communication media with concentrators, bridges, and other devices.', 'Plans network layouts and configures systems to user environments.', 'Analyzes network topologies and traffic and capacity requirements.', 'Supports the acquisition of hardware and software as well as subcontractor services as needed.', 'May provide technical support and troubleshooting to users.', 'May perform network administration duties.', 'Provides guidance and work leadership to less-experienced network personnel and may have supervisory responsibilities.', 'Serves as technical team or task leader.', 'Maintains current knowledge of relevant technology as assigned.', 'Participates in special projects as required.']",2020-12-30 23:19:45
Data engineer,DUOPEAK,N/A,"Menlo Park, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture.', 'Identify, design, and implement internal data process improvements for security, accuracy, stability and scalability purposes.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, GCS and AWS ‘big data’ technologies.', 'Build analytics tools that utilize the data pipelines to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Create data tools and deploy ML models for the analytics/data scientist team members, which will assist them in building and optimizing our product into an innovative industry leader.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Highly analytical, data-driven individuals', 'Detail-oriented and organized people', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience with data processing software (such as Hadoop, Spark, Pig, Hive) , data processing algorithms (MapReduce, Flume) and data pipeline & workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience building processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Strong project management and organizational skills is a plus', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'A Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:Experience with Google or AWS cloud servicesExperience with stream-processing systems: Storm, Kafka, Spark-Streaming, etc.', 'Fully Covered Health insurance', 'Unlimited DTO', '401K', 'Snacks (Food/Drinks)', 'Cell Phone Reimbursement']",2020-12-30 23:19:45
Data Engineer,CDPHP,3.7 out of 5 from 47 employee ratings,"Albany, NY 12206","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's Degree in Computer Science or Engineering. Seven (7) years relevant experience may be substituted for degree."", 'A minimum of 5 (5) years’ experience implementing large enterprise level data and analytic solutions.', 'A minimum three (3) years of development in medium to large sized development teams covering a variety of creation and delivery roles.', 'A minimum of five (5) years’ experience with release and deployment functions required.', 'Experience implementing big data solutions or other analytics solutions preferred', 'Prior hands-on knowledge of the following technologies is essential: Informatica, ASW Glue. Shell scripting, PL/SQL.', 'Demonstrated experience with data warehouse architecture and methodologies required', 'Demonstrated ability to analyze, identify, implement and monitor outcomes required.', 'Demonstrated experience in technical solution design and implementation']",2020-12-30 23:19:45
Software Engineer - University Graduate,PayPal,"3.9 out of 5 from 1,386 employee ratings","Denver, CO 80202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Code high-volume and scalable software', 'Create web applications using React/Node and other technologies', 'Create back end services using Java, SQL, ReST', 'Build and develop new user facing experiences', 'Partner closely with cross functional teams in design, product and other business units', 'Graduated within the past 12 months, or will be graduating by Spring 2021, with a Bachelor’s or Master’s degree in Computer Science or related field from an accredited college or university', 'Strong applied experience. You’ve built, broken, and rebuilt software applications. We’re looking for creative thinkers who also know how to create real-world products.', 'Working knowledge of web technologies (such as HTTP, HTML/DOM, JavaScript, CSS, AJAX) will be beneficial', 'Familiarity with Node.js applications', 'Familiarity with Java, C++ and/or Python', 'Understanding around concepts like Web Services, SOA, REST APIs', 'A constant desire to grow, learn, and explore new things']",2020-12-30 23:19:45
Junior Data Scientist,Invent Analytics,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'BSc / MSc degree from a quantitative field such as Industrial Engineering, Mathematics, and Computer Engineering.', 'Strong analytical thinking and problem solving skills.', 'Strong background in Statistics, Mathematical Modeling, Operations Research.', 'Experience with statistical packages such as R, SPSS and SAS is a big plus.', 'Appreciation of team spirit.', 'Excellent communication and organizational skills.', 'No military obligation or postponement for at least 2 years for male candidates', 'Developing a forecasting and inventory planning process to improve key planning decisions of leading retail firm.', 'Performing assigned tasks as part of the project team, working together with IT team in overseeing data transfer, performing analysis on data sets, helping the design and optimization of algorithms and documentation of key project deliverable milestones.']",2020-12-30 23:19:45
Data & Analytics Visualization Engineer,Divisions Maintenance Group,2.8 out of 5 from 35 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Using expertise in data visualization and workflow design to bring the power of our data mining, machine learning, and statistical techniques on large-scale facilities maintenance and field operations data to life at commercial scale and quality', 'Drive end-to-end data and analytical solutions through robust, user-friendly visual tools to develop and support a culture of “citizen data scientists”', 'Work across important Data & Analytics Community of Excellence capability areas of: Data Science, Data Engineering, Data Wrangling, Edge Programming, SME Analyst/Business Intelligence, Visualization/Citizen Scientist Ux', 'Engage project teams to understand project needs/requirements and provide technical expertise with data and analytical tools', 'Collaborate with data leaders and multi-discipline teams to design, develop and ensure critical data systems infrastructures and integration offer critical data model availability and scalability', 'Ensure relevant data and analytics are available to meet initiatives and technical readiness needs by continuously addressing the data models, wrangling and cleansing data, and improving data solutions and platforms', 'Explore emerging capabilities and Artificial Intelligence/Machine Learning for flawless integration and application between systems, functions and their key user cases', 'Strategic, systems problem solver who will automate existing manual decision support and data workflows to drive key innovation and business performance improvement', 'Apply and build mastery in our product innovation and delivery efforts, while demonstrating diverse data, analytics and visualization skills', '3+ years or more of full time work experience (internships alone do not qualify).', 'Skills in data visualization (Tableau, Qlik, Logi, Power BI, as well as open-source libraries).', 'Front end UI skills using modern typescript frameworks.', 'Expertise in UXD.', 'Skills in script program languages (SQL, Python/Scala, R, JAVA, or C+).', 'Skills with data analytics and insight environments (Spark, Hive, SQL Server, etc).', 'Experience with data analytics insights and work processes for learning and decision support', 'Strong leadership skills, business problem definition, and priority setting skills', 'An aptitude for communicating insights and collaborating across teams/organizations', 'A passion to learn/develop and bring in emerging trends/technology that drive further insight value', 'Proven success of applied analytics through related full-time experience', 'Experience with data management, ingesting new data, transforming/harmonizing data and making it actionable', 'The mindset of an entrepreneurial thinker and is a self-starter, displaying proactive thinking']",2020-12-30 23:19:45
Data Engineer - Brand Savings,GoodRx,5 out of 5 from 5 employee ratings,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Manage data warehouse plans for product and marketing teams', 'Work closely with product managers to understand the data needs of product and marketing', 'Act as internal expert in each of the data sources so that you can own overall data quality', 'Design, build and deploy new data models and ETL pipelines into production', 'Experience contributing to full lifecycle deployments with a focus on testing and quality', 'Define and manage overall schedule and availability for all data sets', 'Work closely with other engineers to enhance infrastructure, improve reliability and efficiency', 'Make smart engineering and product decisions based on data analysis and collaboration', 'Act as in house data expert and make recommendations regarding standards for code quality and timeliness', 'Architectural understanding of Hadoop (HDFS/MapReduce) distributed computing system.', 'Good knowledge of Apache Hive, Pig, and Spark etc.', 'Experience in architecting cloud-based data infrastructure solutions.', 'Degree in Computer Science or a related field or a minimum of 3 year’s working as a Data Engineer', '2+ years professional experience in the data warehouse space', 'Expert Proficiency with Python and AWS Services (e.g. Redshift, S3)', '2+ years’ experience in custom ETL design, implementation and maintenance', 'In depth knowledge of how to write and optimize SQL statements.', 'Deep familiarity with distributed processing (Map Reduce, MPP, etc.)', '2+ years’ experience with schema design (logical and physical)', 'Ability to quickly learn complex domains', 'Innately curious and organized with the drive to analyze data to identify deliverables, anomalies and gaps and propose solutions to address these findings', 'Ability to manage and communicate data warehouse plans', 'Thrives in fast-paced startup environment']",2020-12-30 23:19:45
Undergraduate Internship/Co-op Program - Digital Forensics Engineer,Central Intelligence Agency,4.3 out of 5 from 203 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Full-time student pursuing an undergraduate degree in one of the following fields or related studies:', 'GPA of at least 3.0 on a 4-point scale', 'Availability to work two 90-day tours prior to graduation', 'Attending school on a full-time basis before/following this internship', 'Innovative and creative', 'Problem solving skills', 'Strong initiative', 'Ability to write script/code', 'A thorough medical and psychological exam', 'A polygraph interview', 'A comprehensive background investigation']",2020-12-30 23:19:45
Big Data Engineer,SpringML,N/A,"Pleasanton, CA 94588","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4-7 years Python and Java programming', '3-5 years knowledge of Java/J2EE', '3-5 years Hadoop, Big Data ecosystem experience', '3-5 years of Unix experience', 'Bachelors in Computer Science (or equivalent)', 'Design and develop applications utilizing the Spark and Hadoop Frameworks or GCP components.', 'Read, extract, transform, stage and load data to multiple targets, including Hadoop, Hive, BigQuery.', 'Migrate existing data processing from standalone or legacy technology scripts to Hadoop framework processing.', 'Should have experience working with gigabytes/terabytes of data and must understand the challenges of transforming and enriching such large datasets.', 'C, Perl, Javascript or other programming skills and experience a plus', 'Production support/troubleshooting experience', 'Data cleaning/wrangling', 'Data visualization and reporting', 'Devops, Kubernetes, Docker containers']",2020-12-30 23:19:45
Software Engineer: Data/Systems,Oscar Health,3.4 out of 5 from 92 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Vitals alerting: Implement alerting on elevated vitals measurements from patients so clinicians can intervene and get patients care sooner', 'Virtual Primary Care (VPC) team management: Build tools for patient/doctor management to support the growth of our VPC offering', 'Hybrid visits: Extend our platform to support both Virtual and In-Person visits from our providers', 'You care about what you do.', 'You care about what we do.', 'You are a self starter- you like being self led', ""You're willing and able to learn quickly, whether it be a new shiny technology or an arcane, ill-conceived data structure; our company may be new, but the health industry isn't!"", 'You pride yourself on building high-performance, fault-tolerant, and scalable distributed software systems.', 'You have at least 4 years of professional work experience.']",2020-12-30 23:19:45
Junior GNC Engineer,Relative Dynamics,N/A,"Greenbelt, MD 20771","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Performing analysis, design, and/or test of vehicle autopilot systems.', 'Work from preliminary studies developed by higher graded engineers.', 'Analyze control systems utilizing Matlab and Simulink applications.', 'Perform trajectory development, optimization, and simulation.', 'Assess the ground systems processing of navigation data for compatibility with any given flight software.', 'Provide recommendations for ground systems to assure maximum on-orbit performance of a mission.', 'Must be U.S. Citizen', 'Coding experience and proficiency in Matlab.', 'Experience in coding in C++ with control systems design experience.', '>One year of related experience.', 'BS degree in engineering from an accredited engineering school B.S. in engineering, mathematics, physics or computer sciences.']",2020-12-30 23:19:45
Fantelligence Data Engineer,Fanatics Inc.,3.6 out of 5 from 840 employee ratings,"Jacksonville, FL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:19:45
ETL Test Engineer,VedaInfo,N/A,"Parsippany, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:ETL Testing, 5 years (Preferred)', 'ETL Testing: 5 years (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 23:19:45
Data Engineer,CDPHP,3.7 out of 5 from 47 employee ratings,"Albany, NY 12206","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's Degree in Computer Science or Engineering. Seven (7) years relevant experience may be substituted for degree."", 'A minimum of 5 (5) years’ experience implementing large enterprise level data and analytic solutions.', 'A minimum three (3) years of development in medium to large sized development teams covering a variety of creation and delivery roles.', 'A minimum of five (5) years’ experience with release and deployment functions required.', 'Experience implementing big data solutions or other analytics solutions preferred', 'Prior hands-on knowledge of the following technologies is essential: Informatica, ASW Glue. Shell scripting, PL/SQL.', 'Demonstrated experience with data warehouse architecture and methodologies required', 'Demonstrated ability to analyze, identify, implement and monitor outcomes required.', 'Demonstrated experience in technical solution design and implementation']",2020-12-30 23:21:26
Software Engineer - University Graduate,PayPal,"3.9 out of 5 from 1,386 employee ratings","Denver, CO 80202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Code high-volume and scalable software', 'Create web applications using React/Node and other technologies', 'Create back end services using Java, SQL, ReST', 'Build and develop new user facing experiences', 'Partner closely with cross functional teams in design, product and other business units', 'Graduated within the past 12 months, or will be graduating by Spring 2021, with a Bachelor’s or Master’s degree in Computer Science or related field from an accredited college or university', 'Strong applied experience. You’ve built, broken, and rebuilt software applications. We’re looking for creative thinkers who also know how to create real-world products.', 'Working knowledge of web technologies (such as HTTP, HTML/DOM, JavaScript, CSS, AJAX) will be beneficial', 'Familiarity with Node.js applications', 'Familiarity with Java, C++ and/or Python', 'Understanding around concepts like Web Services, SOA, REST APIs', 'A constant desire to grow, learn, and explore new things']",2020-12-30 23:21:26
Junior Data Scientist,Invent Analytics,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'BSc / MSc degree from a quantitative field such as Industrial Engineering, Mathematics, and Computer Engineering.', 'Strong analytical thinking and problem solving skills.', 'Strong background in Statistics, Mathematical Modeling, Operations Research.', 'Experience with statistical packages such as R, SPSS and SAS is a big plus.', 'Appreciation of team spirit.', 'Excellent communication and organizational skills.', 'No military obligation or postponement for at least 2 years for male candidates', 'Developing a forecasting and inventory planning process to improve key planning decisions of leading retail firm.', 'Performing assigned tasks as part of the project team, working together with IT team in overseeing data transfer, performing analysis on data sets, helping the design and optimization of algorithms and documentation of key project deliverable milestones.']",2020-12-30 23:21:26
Data & Analytics Visualization Engineer,Divisions Maintenance Group,2.8 out of 5 from 35 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Using expertise in data visualization and workflow design to bring the power of our data mining, machine learning, and statistical techniques on large-scale facilities maintenance and field operations data to life at commercial scale and quality', 'Drive end-to-end data and analytical solutions through robust, user-friendly visual tools to develop and support a culture of “citizen data scientists”', 'Work across important Data & Analytics Community of Excellence capability areas of: Data Science, Data Engineering, Data Wrangling, Edge Programming, SME Analyst/Business Intelligence, Visualization/Citizen Scientist Ux', 'Engage project teams to understand project needs/requirements and provide technical expertise with data and analytical tools', 'Collaborate with data leaders and multi-discipline teams to design, develop and ensure critical data systems infrastructures and integration offer critical data model availability and scalability', 'Ensure relevant data and analytics are available to meet initiatives and technical readiness needs by continuously addressing the data models, wrangling and cleansing data, and improving data solutions and platforms', 'Explore emerging capabilities and Artificial Intelligence/Machine Learning for flawless integration and application between systems, functions and their key user cases', 'Strategic, systems problem solver who will automate existing manual decision support and data workflows to drive key innovation and business performance improvement', 'Apply and build mastery in our product innovation and delivery efforts, while demonstrating diverse data, analytics and visualization skills', '3+ years or more of full time work experience (internships alone do not qualify).', 'Skills in data visualization (Tableau, Qlik, Logi, Power BI, as well as open-source libraries).', 'Front end UI skills using modern typescript frameworks.', 'Expertise in UXD.', 'Skills in script program languages (SQL, Python/Scala, R, JAVA, or C+).', 'Skills with data analytics and insight environments (Spark, Hive, SQL Server, etc).', 'Experience with data analytics insights and work processes for learning and decision support', 'Strong leadership skills, business problem definition, and priority setting skills', 'An aptitude for communicating insights and collaborating across teams/organizations', 'A passion to learn/develop and bring in emerging trends/technology that drive further insight value', 'Proven success of applied analytics through related full-time experience', 'Experience with data management, ingesting new data, transforming/harmonizing data and making it actionable', 'The mindset of an entrepreneurial thinker and is a self-starter, displaying proactive thinking']",2020-12-30 23:21:26
Data Engineer - Brand Savings,GoodRx,5 out of 5 from 5 employee ratings,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Manage data warehouse plans for product and marketing teams', 'Work closely with product managers to understand the data needs of product and marketing', 'Act as internal expert in each of the data sources so that you can own overall data quality', 'Design, build and deploy new data models and ETL pipelines into production', 'Experience contributing to full lifecycle deployments with a focus on testing and quality', 'Define and manage overall schedule and availability for all data sets', 'Work closely with other engineers to enhance infrastructure, improve reliability and efficiency', 'Make smart engineering and product decisions based on data analysis and collaboration', 'Act as in house data expert and make recommendations regarding standards for code quality and timeliness', 'Architectural understanding of Hadoop (HDFS/MapReduce) distributed computing system.', 'Good knowledge of Apache Hive, Pig, and Spark etc.', 'Experience in architecting cloud-based data infrastructure solutions.', 'Degree in Computer Science or a related field or a minimum of 3 year’s working as a Data Engineer', '2+ years professional experience in the data warehouse space', 'Expert Proficiency with Python and AWS Services (e.g. Redshift, S3)', '2+ years’ experience in custom ETL design, implementation and maintenance', 'In depth knowledge of how to write and optimize SQL statements.', 'Deep familiarity with distributed processing (Map Reduce, MPP, etc.)', '2+ years’ experience with schema design (logical and physical)', 'Ability to quickly learn complex domains', 'Innately curious and organized with the drive to analyze data to identify deliverables, anomalies and gaps and propose solutions to address these findings', 'Ability to manage and communicate data warehouse plans', 'Thrives in fast-paced startup environment']",2020-12-30 23:21:26
Undergraduate Internship/Co-op Program - Digital Forensics Engineer,Central Intelligence Agency,4.3 out of 5 from 203 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Full-time student pursuing an undergraduate degree in one of the following fields or related studies:', 'GPA of at least 3.0 on a 4-point scale', 'Availability to work two 90-day tours prior to graduation', 'Attending school on a full-time basis before/following this internship', 'Innovative and creative', 'Problem solving skills', 'Strong initiative', 'Ability to write script/code', 'A thorough medical and psychological exam', 'A polygraph interview', 'A comprehensive background investigation']",2020-12-30 23:21:26
Big Data Engineer,SpringML,N/A,"Pleasanton, CA 94588","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4-7 years Python and Java programming', '3-5 years knowledge of Java/J2EE', '3-5 years Hadoop, Big Data ecosystem experience', '3-5 years of Unix experience', 'Bachelors in Computer Science (or equivalent)', 'Design and develop applications utilizing the Spark and Hadoop Frameworks or GCP components.', 'Read, extract, transform, stage and load data to multiple targets, including Hadoop, Hive, BigQuery.', 'Migrate existing data processing from standalone or legacy technology scripts to Hadoop framework processing.', 'Should have experience working with gigabytes/terabytes of data and must understand the challenges of transforming and enriching such large datasets.', 'C, Perl, Javascript or other programming skills and experience a plus', 'Production support/troubleshooting experience', 'Data cleaning/wrangling', 'Data visualization and reporting', 'Devops, Kubernetes, Docker containers']",2020-12-30 23:21:26
Software Engineer: Data/Systems,Oscar Health,3.4 out of 5 from 92 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Vitals alerting: Implement alerting on elevated vitals measurements from patients so clinicians can intervene and get patients care sooner', 'Virtual Primary Care (VPC) team management: Build tools for patient/doctor management to support the growth of our VPC offering', 'Hybrid visits: Extend our platform to support both Virtual and In-Person visits from our providers', 'You care about what you do.', 'You care about what we do.', 'You are a self starter- you like being self led', ""You're willing and able to learn quickly, whether it be a new shiny technology or an arcane, ill-conceived data structure; our company may be new, but the health industry isn't!"", 'You pride yourself on building high-performance, fault-tolerant, and scalable distributed software systems.', 'You have at least 4 years of professional work experience.']",2020-12-30 23:21:26
Junior GNC Engineer,Relative Dynamics,N/A,"Greenbelt, MD 20771","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Performing analysis, design, and/or test of vehicle autopilot systems.', 'Work from preliminary studies developed by higher graded engineers.', 'Analyze control systems utilizing Matlab and Simulink applications.', 'Perform trajectory development, optimization, and simulation.', 'Assess the ground systems processing of navigation data for compatibility with any given flight software.', 'Provide recommendations for ground systems to assure maximum on-orbit performance of a mission.', 'Must be U.S. Citizen', 'Coding experience and proficiency in Matlab.', 'Experience in coding in C++ with control systems design experience.', '>One year of related experience.', 'BS degree in engineering from an accredited engineering school B.S. in engineering, mathematics, physics or computer sciences.']",2020-12-30 23:21:26
Fantelligence Data Engineer,Fanatics Inc.,3.6 out of 5 from 840 employee ratings,"Jacksonville, FL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:21:26
ETL Test Engineer,VedaInfo,N/A,"Parsippany, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:ETL Testing, 5 years (Preferred)', 'ETL Testing: 5 years (Preferred)', 'Temporarily due to COVID-19']",2020-12-30 23:21:26
Full Time Opportunities for Students and Recent Graduates - MAIDAP Software Engineer,Microsoft,"4.2 out of 5 from 7,020 employee ratings","Cambridge, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Lead the design and the implementation of AI solutions for Microsoft’s products and services.', 'Test and review all new and modified code and data pipelines.', 'Build out new API infrastructure and endpoints, data pipelines, as necessary.', 'Build reporting and monitoring mechanisms into our solutions.', 'Analyze technology industry and market trends and choose their potential impact on the solutions.', 'Develop patterns, standards and guidelines necessary to uphold our design principles and maintain integrity of the product architecture.', 'Participate in key project design reviews.', 'Collaborate with partner teams for code integration and with program managers to translate functional requirements into working solutions.', 'Patent and publish relevant IP and scientific research.', 'Up to 10% travel may be required.', 'Currently pursuing a degree or graduated within last 12 months with a degree in the following field: Electrical Engineering, Computer Science, HCI, or other relevant fields.', 'You are energized by creating AI solutions that can positively impact the work and lives of millions of people.', 'You crave data-driven learning.', 'You are excited by the prospect of working on a wide variety of datasets and AI applications, across many products and engineering teams.', 'You believe that data science is a team sport.', 'You love being an active member of a diverse and inclusive cohort.', 'BS/MS in the aforementioned fields.', '2+ years and proven experience in developing in C/C++/Java/C#/Scala and 1+ scripting language.', 'Experience in database systems and systems engineering.', 'Experience in designing and developing high-scale distributed systems a plus.', 'Knowledge of lambda architectures a plus.', 'Knowledge of machine learning, data visualization, and AI a plus.', 'Excellent written and oral communication skills.']",2020-12-30 23:21:26
Machine Operator and Assembler,"MLP Ventures Group, LLC",N/A,"Elkton, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Monday to Friday']",2020-12-30 23:21:26
"Software Engineer, Full Stack - Data Visualization","TuSimple, Inc.",N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Building pipeline scheduling and execution platform, as well as the corresponding frontend to manage and interact with the platform, to do analysis of our simulations and datasets;', 'Developing on-premises cluster projects as well as utilizing public cloud computing infrastructure services;', 'Building front-end Web Interface for engineers and testops to control and monitor the onboard system, that visualize in real time, the perceived surroundings and decided routes of our autonomous driving system;', 'Building web-based tools to optimize the labelling of our datasets to greatly increase the efficiency and correctness;', 'Develop vehicle oversight service software to monitor vehicles remotely', 'Provide vehicle monitor and management API service to customers', 'Proactively identify problems and make technical suggestion on requirements', 'Experience in building highly scalable enterprise web applications', '3+ years experience in developing microservices using AWS or other equivalent cloud framework', 'Experience in developing secured API and publishing user document', 'Excellent knowledge of different API mechanism such as REST, RPC/gRPC, HTTP, GraphQL', 'Experience in developing extensible APIs and highly maintainable services.', 'Experience in deploying, monitoring and maintaining services and systems.', 'Excellent knowledge of databases like Dynamodb, Mongodb, SQL', 'Fluent in JavaScript & Python', 'Understanding of SOA, SAAS, and REST/OAuth/JSON architectures and services.', 'Familiar with front-end Vue.js framework', 'Familiar with back-end Flask or Django framework', 'Familiar with iOS/Android mobile application development', '100% employer-paid healthcare premiums for you and your family', 'Work visa sponsorship available', 'Relocation assistance available', 'Breakfast, lunch, and dinner served every day', 'Full kitchens on every floor with unlimited snacks, drinks, special treats, fruits, meals, and more', 'Stock options / equity', 'Gym membership reimbursement', 'Monthly team building budget', 'Learning/education budget', 'Employer-paid life insurance', 'Employer-paid long and short disability']",2020-12-30 23:21:26
"Data Engineer â€"" Advanced",MassMutual,"3.7 out of 5 from 1,262 employee ratings","Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.', 'Working on a range of projects including batch pipelines, data modeling, and data mart solutions youâ€™ll be part of collaborative project teams working to implement robust data collection and processing pipelines to meet specific business need.', 'Design, build, and measure complex ELT jobs to process disparate data sources and form a high integrity, high quality, clean data asset.', 'Executes and provides feedback for data modeling policies, procedure, processes, and standards.', 'Assists with capturing and documenting system flow and other pertinent technical information about data, database design, and systems.', 'Develop data quality standards and tools for ensuring accuracy.', 'Work across departments to understand new data patterns.', 'Translate high-level business requirements into technical specs.', 'Bachelorâ€™s degree in computer science or engineering.', '5+ years of experience with data analytics, data modeling, and database design.', '3+ years of coding and scripting (Python, Java, Scala)Â and design experience.', '3+ years of experience with Spark framework.', 'Experience with ELT methodologies and tools.', 'Expertise in tuning and troubleshooting SQL.', 'Strong data integrity, analytical and multitasking skills.', 'Excellent communication, problem solving, organizational and analytical skills.', 'Able to work independently.', 'Masterâ€™s degree in computer science or engineering.', 'Familiar with agile project delivery process.', 'Knowledge of SQL and use in data access and analysis.', 'Ability to manage diverse projects impacting multiple roles and processes.Â', 'Able to troubleshoot problem areas and identify data gaps and issues.', 'Ability to adapt to fast changing environment.', 'ExperienceÂ with Python.', 'Basic knowledge of database technologies (Vertica, Redshift, etc.).', 'Experience designing and implementing automated ETL processes.']",2020-12-30 23:21:26
Data Analytics Engineer,TrendMiner,N/A,"Houston, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You support our customers in the use of TrendMiner as their prime analytics toolbox', 'Team up with process technologists and improvement teams of our customers to:', 'discover potential areas of improvement', 'perform data analysis to find the root-cause of identified issues', 'suggest and implement analytics solutions', 'support and train users how to use TrendMiner', 'Support the sales process by giving demonstrations of TrendMiner', 'Collaborate with R&D and Product Development in defining requirements for new features for TrendMiner', 'Collaborate with Customer Success Manager and Sales to find new business leads and opportunities', 'Transfer knowledge to the team with respect to improvement results and the way the improvement is achieved', '2-5 years of experience in process engineering', 'Pro-active personality with hands-on attitude', 'A bias for action', 'Experience within the use of trending and analytics, preferably in process industry', 'Knowledge of analytical tools (eg. Matlab, R, Python)', 'Minimal level of education BSc in Engineering (Chemical, Biotechnology, Mathematical, etc.)', 'Full professional proficiency in English, Spanish is a plus', 'Excellent communication skills, customer focus and result oriented', 'Willingness to travel to collaborate with customers within US and abroad', 'Motivational and inspirational personality']",2020-12-30 23:23:08
Data Engineer - Quality Engineering (Software),Tesla,"3.5 out of 5 from 4,572 employee ratings","Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop data pipelines and automation from various data sources and systems using Airflow and Kubernetes Pod Operator in Python to power internal tools and systems', 'Develop and maintain real time data streaming and processing pipeline using Kafka', 'Develop and maintain Kubernetes YAML configuration and deploy micro-services, such as API, frontend, SSO ingress, storage, platforms and systems', 'Architect and maintain database, including SQL, NoSQL and elastic search', 'Develop and maintain continuous integration and continuous deployment pipeline in Jenkins', 'Master’s degree or higher in quantitative discipline (e.g. Computer Science, Mathematics, Physics, Electrical Engineering, Statistics, Industrial Engineering) or the equivalent in experience and evidence of exceptional ability', '3+ years of work experience in data engineering and platform engineering', 'Extensive experience building scalable and easy to maintain data pipelines using Python and Airflow', 'Expert with Docker, Kubernetes and Jenkins', 'Experience with multiple data architecture paradigms (e.g. MySQL, MicrosoftSQL, Oracle, MongoDB, ElasticSearch, Hadoop, Hbase, Spark)', 'Knowledge of various data communication protocols (e.g. REST API, Kafka, gRPC)', 'Proficient in troubleshooting using Splunk', 'Able to work under pressure while collaborating and managing competing demands with tight deadlines']",2020-12-30 23:23:08
Macroelectronics Data Engineer,Prescient Edge Federal,N/A,"Quantico, VA 22134","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop Directorate data requirements in a non-information technology (IT) environment, enabling data-driven decision-making', 'Develop a framework and thresholds for ascribing quantitative values to qualitative values to align data sets', 'Provide the Enterprise Microelectronics Report on the first Monday of each month', 'Design, develop, test, and manage the overall framework that helps analyze and process data in the way the organization needs it', 'Integrate external or new datasets into existing datasets', 'Process, clean, and verify the integrity, accuracy, completeness, and uniformity', 'Build data and analytics proofs that will offer deeper insight into datasets, allowing for critical discoveries surrounding key performance indicators and customer activity', 'Recommend and implement ways to improve data reliability, efficiency, and quality', 'Evaluate, compare, and improve the different approaches including the design patterns innovation, data lifecycle design, data ontology alignment, annotated datasets, and elastic search approaches', 'Document all processes, models, and activities', 'Work closely with the Task Manager (TM) to direct and optimize the flow of data within the framework and ensure consistency of data delivery and utilization across multiple projects', 'Curate and collect the data from a variety of traditional and non-traditional sources: extract data from sources, transform and integrate data in line with existing data, and load data into data stores for access by others', 'Communicate results and ideas to the TM, key decision makers, and other stakeholders and shall provide information regarding the dataset applicability to the stakeholder’s mission', 'Perform research and analysis of large data sets to include operational data and perform data validation and visualization and other statistical analysis of a mildly urgent/sensitive nature', 'Support change management activities with regard to data analysis across Directorates', 'Design, implement, and operate data management systems for intelligence needs', 'Design how data will be stored, accessed, used, integrated, and managed by different data regimes and digital systems', 'Work with data users to determine, create, and populate optimal data architectures, structures, and systems', 'Plan, design, and optimize data throughput and query performance', 'Participate in the selection of backend database technologies (e.g., SQL, NoSQL, HPC, etc.), their configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness', 'A competitive salary with performance bonus opportunities', 'Comprehensive healthcare benefits, including medical, vision, dental, and orthodontia coverage', 'A substantial retirement plan with no vesting schedule', 'Career development opportunities, including on-the-job training, tuition reimbursement, and networking', 'A positive work environment where employees are respected, supported, and engaged', 'Active TS/SCI security clearance', 'Minimum of 5 years of experience working in a data engineer role', 'Knowledge of basics of algorithms and data structures, distributed computing, big data querying tools, and big data toolkits', 'Experience building and optimizing data pipelines, architectures, and data sets', 'Demonstrated ability to work across the Enterprise to develop processes that support data transformation, data structures, metadata, dependency, and workload management', 'Bachelor’s degree in Computer Science, Information Systems, or an equivalent field']",2020-12-30 23:23:08
Data Scientist - Entry Level,LLNL,4.6 out of 5 from 7 employee ratings,"Livermore, CA 94550","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with scientists and researchers in one or more of the following areas: data intensive applications, text processing, graph analysis, machine learning, statistical learning, information visualization, low-level data management, data integration, data streaming, scientific data mining, data fusion, massive-scale knowledge fusion using semantic graphs, database technology, programming models for scalable parallel computing, application performance modeling and analysis, scalable tool development, novel architectures (e.g., FPGAs, GPUs and embedded systems), and HPC architecture simulation and evaluation.', 'Work with other LLNL scientists and application developers to bring research results to practical use in LLNL programs.', 'Assess the requirements for data sciences research from LLNL programs and external government sponsors.', 'Carry out development of data analysis algorithms to address program and sponsor data sciences requirements.', 'Engage other developers frequently to share relevant knowledge, opinions, and recommendations, working to fulfill deliverables as a team.', 'Contribute to technical solutions, participate as a member of a multidisciplinary team to analyze sponsor requirements and designs, and implement software and perform analyses to address these requirements.', 'Develop and integrate components-such as web-based user interfaces, access control mechanisms, and commercial indexing products-for creating an operational information and knowledge discovery system.', 'Perform other duties as assigned.', 'Bachelor’s degree in computer science, computer engineering, or related field, or the equivalent combination of education and related experience.', 'Fundamental knowledge of one or more of the following: high performance computing, scientific data analysis, statistical analysis, knowledge discovery, computer security, systems programming, large-scale data management, and big data technologies.', 'Skilled in all aspects of the software project life cycle: feasibility, requirements, design, implementation, integration, test and deployment.', 'Fundamental experience developing software with C++, C, Java, Python, R, or Matlab, software applications in Linux, UNIX, Windows environments, data analysis algorithms, data management approaches, relational databases, or machine learning algorithms.', 'Ability to effectively handle concurrent technical tasks with conflicting priorities, to approach difficult problems with enthusiasm and creativity and to change focus when necessary, and to work independently and implement research concepts in a multi-disciplinary team environment, where commitments and deadlines are important to project success.', 'Sufficient interpersonal skills necessary to interact with all levels of personnel.', 'Sufficient verbal and written communication skills necessary to effectively collaborate in a team environment and present and explain technical information.', 'Included in 2020 Best Places to Work by Glassdoor!', 'Work for a premier innovative national Laboratory', 'Comprehensive Benefits Package', 'Flexible schedules (*depending on project needs)', 'Collaborative, creative, inclusive, and fun team environment']",2020-12-30 23:23:08
"Engineer, Data",StrongArm Technologies,3.5 out of 5 from 2 employee ratings,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Individual contributor using Python with a system trajectory towards Scala', 'Provide technical leadership in Data Engineering design principles', 'Design and implement highly available / scalable data pipelines using Apache Spark for ETL jobs that process data from 100s of thousands of sensors.', 'Build big data interfaces compatible across IoT systems using SWIG', 'Partner with the Data Science team to implement advanced statistical models and machine learning that run on edge devices', 'Partner with the Embedded Engineering team to build interfaces between IoT devices and data pipelines for ingesting data', 'Own data modeling implementation for huge scale', 'Optimize data pipelines for performance and scalability', 'Establish automated mechanisms to improve data integrity across all big data sets.', 'Leverage strategic and analytical skills to understand and solve customer and business centric questions', 'Monitor and troubleshoot performance issues for production pipelines', ""Learn about new technologies and add to StrongArm's Big Data tech stack"", 'Data Warehouse management in Databricks using Delta Lake', '2+ years experience in data engineering', 'Experience building systems using Apache Spark that have processed terabytes of data in production', 'Experience productionizing data science models and algorithms to run at scale', 'Experience with distributed data streaming frameworks like Spark Structured Streaming, Apache Flink, Kinesis, etc', 'Advanced Experience with RDBMS and SQL', 'Experience with automated testing for distributed systems in Spark (unit testing, end to end testing, QA, CI/CD)', 'Experience designing end to end pipeline architectures', 'Experience managing data warehouses in a production environment (Delta Lake, Snowflake, Redshift, Bigquery, Presto)', 'Scala and Python proficiency', 'Experience leveraging cloud systems to build data pipelines (BigQuery, Redshift, AWS Kinesis, AWS S3, GCS)', 'Linux proficiency, this is the means by which things are engineered well.', 'Experience extending Apache Spark (DataSource API, Catalyst Optimizer)', 'Experience with productionizing machine learning at scale and A/B testing new models: scikit-learn, tensorflow, pytorch', 'Experience building systems to train machine learning models at terabyte scale.', 'Experience working with Hadoop', 'Experience using workflow management systems like Airflow or equivalent', 'Experience working with datasets that measure physical phenomena.', 'noSQL solutions: Cassandra, HDFS and/or Elasticsearch', 'Experience as an open source contributor', 'Experience with BI tools (Looker, Redash)', 'Experience building systems with data governance', 'Strong Mathematics background (Linear Algebra, Statistics, Physics, Complex Variables, Calculus)']",2020-12-30 23:23:08
Data Engineer,Reonomy,N/A,"New York, NY 10017","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborating with the Engineering team to design, build and improve Reonomy’s complex data layer', 'Creating data systems that ensure quality and consistency on our data platform', 'Solving real challenges around creating systems that import, cleanse, structure, and display huge volumes of data', 'Playing a major role in the future architecture of our rapidly expanding backend platform', 'Writing high quality code, participating actively in code reviews, and consistently helping to ship software', '6+ years of experience in a Data Engineering capacity', 'Expertise in building and scaling ETL/batch processing systems that organize data and manage complex rulesets', 'Proven ability leveraging database technologies to solve non-trivial, large-scale problems', 'Advanced/Expert knowledge in SQL and data analysis', 'Experience programming in both typed (Scala, Java, etc..) and non-typed (Python, Ruby, etc..) languages on production projects', 'Experience using Scala libraries such as: Cats, shapeless, fs2', 'Experience building modern, data-driven, web applications with emphasis on strong software design methodologies', 'A serious passion for data', 'History of excellence and responsibility in previous engineering positions', 'Competitive salary', 'Company stock options', '100% coverage on medical, vision and dental health plans', 'Unlimited Vacation', '401k plan and commuter benefits', 'Access to our Continuing Education Stipend', 'Perks: WFH package, FREE ClassPass membership, FREE Headspace premium membership, FREE Citi Bike membership, & team outings!', 'Applicants must be currently authorized to work in the United States on a full-time basis.', 'We do not accept unsolicited resumes from outside recruiters/placement agencies. Reonomy will not pay fees associated with resumes presented through unsolicited means.']",2020-12-30 23:23:08
Drexel Technology Co-Op Program Spring 2021,Johnson & Johnson Family of Companies,"4.2 out of 5 from 5,352 employee ratings","West Chester, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Analytics co-op will have the opportunity to work with various aspects of Johnson & Johnson's business collecting data, analyzing, and applying machine learning techniques to derive insights for business partners. They will also help build analytical applications that work with large data sets."", 'Creating applications for Android, iOS and web for our different operating companies and business units, including Bio-Sensor and Device Integration. Utilize a variety of platforms, including PHP, SQL/MySQL, UX, Java/JavaScript, HTML/CSS, Symfony2, Jira, GreenHopper, Crucible, Sonar, Subversion, AJAX, Spring & Hibernate.', ""The co-op will be working within the J&J Corporate Business Technology (CBT) Organization. CBT provides global technology capabilities to J&J's Corporate functions, including Finance, HR, Procurement, Legal, IT, Compliance, Real Estate, etc. The Enterprise Project Management Office team manages the investment portfolio of all Technology projects globally and provides status, trends, health and metrics to executive leadership."", 'This position will focus on development and delivery of Digital Health programs and initiatives within Janssen Pharma R&D IT. The candidate will research, pilot, and implement a variety of Health opportunities across multiple platforms, including biosensors, health tracking, and mobile devices. The candidate will be responsible for researching and piloting Digital Health technologies, including existing services within J&J and emerging services.', 'This position will focus on enabling and build technology pipeline, data analysis, and continuous process improvement in the supply chain organization.', 'Contribute individually and/or as a team member to support a designated functional area', 'Work towards goals and objectives assigned by experience owner (manager)', 'Analyze business processes for reengineering opportunities', 'Work within a group in IT that supports a functional area of the business', 'Have permanent work authorization in the US. We cannot consider students requiring current or future sponsorship.', 'Have a cumulative GPA of 3.0 or higher, which is reflective of all college coursework.', 'Be currently enrolled and pursuing a Bachelors or Masters degree. Preferred fields are Computer Science/Computer Engineer, Managed Information Systems, Information Technology, Software Engineering / Development, Data Science or something equivalent.', 'Ability to work full time (40 hours a week) from April 5, 2021-September 17, 2021.', 'A maximum time of one full year of full-time work experience (excluding internships, co-ops, and military).', 'Have a passion for a career in technology.', 'Students in their Sophomore year and higher are strongly preferred.']",2020-12-30 23:23:08
Senior Software Engineer - Data,Lob,N/A,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.', 'Develop and maintain data infrastructure, libraries and services with software engineering best practices.', 'Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.', 'Build and curate data model expertise and uphold data quality and freshness.', 'Work closely with multi-functional teams to build and ship data-driven product features.', 'Coach and mentor fellow engineers.', 'Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.', 'Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.', 'Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.', 'Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.', 'Production experience with Spark, Python and SQL.', 'Experience with event-driven systems and time-series analysis a plus.', '5+ years of full-time, relevant industry experience.', 'Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)', ""Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob's suite of APIs to mail fully dynamic and personalized customer communications with print media"", 'Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth', 'We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest', 'Comprehensive health benefits for you and your dependent(s)', 'Healthcare Flexible Spending Accounts', 'Paid parental leave', 'Unlimited vacation policy', 'Employee Assistance Program and free professional coaching sessions', ""Wellness program (includes monthly stipend or free Barry's Bootcamp classes!)"", 'Virtual social events', '401k']",2020-12-30 23:23:08
"MTS 1, Data Engineer",PayPal,"3.9 out of 5 from 1,386 employee ratings","Chandler, AZ 85286","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participating and collaborating with Product Owner/ Cross functional teams in the organization to understand the business requirements and to deliver solutions that can scale.', 'Creativity and out of the box thinking is required.', 'Proactively anticipating problems and keeping the team and management informed in a timely manner.', 'Being flexible and being able to support all functions of product life cycle when required.', 'Will be acting as tech lead and produce quality deliverables.', '8+ years of experience in the IT industry, experience in data engg is Mandatory.', 'Shell/ Perl scripting experience or proficiency in any programming language like Java/C/ C++, Python', 'Hands on in Java programming', 'Strong fundamentals of object-oriented design, data structures, algorithms and design patterns', 'Proficient in Frameworks – Spring, Maven, Hibernate', 'Knowledge of Real time Analytics', 'Expert in software engineering tools and best practices', 'Expert in design/implementation for reliability, availability, scalability and performance', 'Should have strong SQL programming skills', 'Knowledge of data warehousing concepts', 'Proficient in Big data Environments – Spark, Pig, Hive, MR', 'Excellent written and oral communication skills', 'Knowledge in MPP Databases/ Distributed systems', 'Knowledge on Data Encryption Standards is a huge plus', 'Exposure to Data Quality and Profiling tools is a plus.', 'Exposure BI tools desired, but not required (Micro strategy, Business Objects).']",2020-12-30 23:23:08
Data Engineer,Axos Bank,3 out of 5 from 41 employee ratings,"Las Vegas, NV 89148","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with technical and business team to understand the business requirements, functional and technical specifications', 'Design, code and maintain new and existing complex SQL stored procedures and functions', 'Performance tune existing stored procedures, tables and indexes', 'Work with other engineers to troubleshoot, repair and performance tune databases', 'Review SQL code written by other developers to ensure compliance to coding standards and best practices as well as maximum performance', 'Create SSIS packages for data transformation, cleansing, caching, aggregation, staging, and transfer', 'Troubleshoot problems that may come up with database environments: performance issues; replication issues; or operational issues', 'Perform data analysis and data profiling tasks to provide support and recommendations for development and design decisions', 'Analyze and define data flow requirements and prepare applicable system documentation and operation manuals as needed', 'Support production data loads and ongoing refreshes of the database systems', 'Define, prepare, execute and implement data validation and unit testing methods to ensure data quality', 'Maintain re-usable development standards that help implement each solution and/or enhancements to existing systems to meet current and future needs', 'Perform enhancements and bug fixes as required', 'Perform any additional duties as assigned', ""3+ years' working with relational DBs in a production environment"", ""3+ years' experience with Microsoft SQL Server"", ""2+ years' experience in SSIS packages"", ""2+ years' experience working in an Agile/SCRUM environment"", 'Experience delivering high quality, high traffic, scalable database objects', 'Expertise in SQL server design and development', 'Excellent verbal and written communication skills, including ability to simplify complex concepts for technical and non-technical audience', 'Superior problem-solving skills, self-motivation, and the capacity to work under pressure and tight deadlines', 'Demonstrated ability to learn, acquire and utilize new technologies, disciplines and frameworks as needed', 'Technical expertise in the areas of data profiling, data mining and data analytics', 'Technical expertise in building reliable data ETL/ELT processes, query optimization and dynamic SQL', 'Strong customer focus, excellent problem solving and analytical skills', 'Ability to work independently under minimal supervision and strong track record of setting and meeting delivery commitments', ""Bachelor's Degree in Computer Science, Information Systems, Computer Engineering or related field"", 'Experience in BigData', 'Banking industry experience']",2020-12-30 23:23:08
Data Engineer,Provoke,N/A,"Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Work with stakeholders and cross-functional teams to assist with data-related technical issues and support their data infrastructure needs', 'Experience building and optimizing data pipelines, architectures and data sets', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Experience working with, creating reports and dashboards in Tableau.', 'Strong expertise in SQL and Python', 'Knowledge or experience with data visualization tools like Tableau', 'Knowledge or experience with Hive, Presto, Scuba, and a variety of databases (relational, analytical, transactional).', 'Knowledge or experience with Dataswarm and/or Airflow']",2020-12-30 23:23:08
Oops! That page can’t be found.,Provoke,N/A,"Seattle, WA","['Indeed Jobs', '404', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Facebook', 'Twitter', 'instagram', 'Youtube', 'Soundcloud']",2020-12-30 23:23:08
Senior Data Engineer,The Hartford,"3.7 out of 5 from 1,824 employee ratings","Hartford, CT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Identify and validate internal and external data sources for availability and quality. Work with SME’s to describe and understand data lineage and suitability for a use case.', 'Create data assets and build data pipelines that align to modern software development principles for further analytical consumption. Perform data analysis to ensure quality of data assets.', 'Create summary statistics/reports from data warehouses, marts, and operational data stores.', 'Extract data from source systems, and data warehouses, and deliver in a pre-defined format using standard database query and parsing tools.', 'Understand ways to link or compare information already in our systems with new information.', 'Perform preliminary exploratory analysis to evaluate nulls, duplicates and other issues with data sources.', 'Work with data scientists to understand the requirements and propose and identify data sources and alternatives.', 'Produce code artifacts and documentation using Github for reproducible results and hand-off to other data science teams.', 'Propose ways to improve and standardize processes to enable new data and capability assessment and to enable pivoting to new projects.', 'Understand data classification, and adhere to the information protection and privacy restrictions on data.', 'Collaborate closely with data scientists, business partners, data suppliers, and IT resources.', 'Bachelor degree or equivalent experience in a related quantitative field', 'Experience accessing and retrieving data from disparate large data sources, by creating and tuning SQL queries. Understanding of data modeling concepts, data warehousing tools and databases (e.g. Oracle, AWS, Spark/PySpark, ETL, Big Data, and Hive)', 'Demonstrated ability to create and deliver high quality Python code using software engineering best practices. Experience with object oriented programming and software development a plus. Proficiency with Github and Linux highly desired.', 'Ability to analyze data sources and provide technical solutions. Strong exploratory and problem solving skills to check for data quality issues.', 'Determine business recommendations and translate into actionable steps', 'Self-starter with curiosity and a willingness to become a data expert', 'Demonstrate a passion to both learn new skills and lead discovery of the data research', 'Results oriented with the ability to multi-task and adjust priorities when necessary', 'Ability to work both independently and in a team environment with internal customers', 'Ability to articulate and train technical concepts regarding data to both data scientists and partners']",2020-12-30 23:23:08
Database Engineer,AssetWorks,3.5 out of 5 from 14 employee ratings,"Wayne, PA 19087","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Demonstrated ability to creatively solve problems by turning requirements into functional Azure Databricks scripts', 'Familiarity with User-Stories', 'Ability and desire to learn new skills and technologies and apply them on the job', 'Able to collaborate with and challenge product managers to solidify requirements for development', 'Ability to lead several complex projects simultaneously', 'Perform on-site work and/or support the efforts of AssetWorks on-site personnel to support the implementation of software systems in complex customer environments', 'Collaborate with team to solve complex bug verifications, release testing, and customer-specific beta software support', 'Demonstrated knowledge of all phases of product life cycle', 'Result-focused', 'At least one year of software programming or other similar work experience developing data solutions using Scala or Python in Azure Databricks', 'Analyze, design, and build modern data solutions in Azure Databricks to support visualization of data', 'Experience in database design and development for business intelligence reports', 'Experience with data migration and database programming in Oracle and SQL Server', 'Experience with source control (SVN, Git, etc.)', 'Experience with APIs (SOAP, REST, GraphQL, etc.)', 'Excellent attention to detail', 'Effective listening, communication (verbal and written) and presentation skills', 'Strong analytical and problem-solving skills', 'Successful time management and ability to adapt quickly to changing priorities', 'Be a productive team member supporting a wide range of stakeholders', 'Ability to work under pressure to meet deadlines, both as an individual and as part of a team', 'Familiarity with Microsoft Office Suite (preferred) or similar productivity suite', 'Ability to think outside of the box and present creative solutions to development challenges.', 'Demonstrates ability to effectively meet product requirements and communicate progress.', 'Detail oriented with the ability to multi-task and lead complex projects.']",2020-12-30 23:23:08
Data Engineer,AE Stategies,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Provide data engineering, analysis, and visualization support, including predictive modeling, graph analysis, social network analysis', 'Assist project teams with identifying, gathering, and understanding relevant data to support analysis, as well as, assess relative quality and reliability of the data', 'Assist with data preparation, including data cleansing, transformation, combination, aggregation, and scripts for recurring ingestion in preparation for modeling and analysis', 'Assist with developing data visualizations of results for ease of use and adoption of analytics', 'Examine large data sets to identify trends, develop charts, and create visual presentations to help the organization make more strategic decisions', 'Bachelor’s Degree required and 5 years of experience OR master’s degree and 4 years of experience', 'Ability to qualify for a DoD Secret clearance', 'Direct experience creating sustainable, automated processes for data analysis', 'Expert at understanding and creating high level architectural specifications', 'Advanced technical expertise with programmatically manipulating data', 'Proficiency in data management systems and statistical packages such as: Required Experience: R, Natural Language Processing (NLP) within R, Spark, Tableau; and Preferred Experience: Hadoop, Python, SAS programming']",2020-12-30 23:23:08
Data Engineer,CLEAR - Corporate,2.6 out of 5 from 200 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build out our data pipeline architecture, and optimize data flow and collection for cross functional teams.', 'Lead the development of a Data Lake solution that can be used for reporting and analytics across the entire organization.', 'Work closely with our engineering teams to integrate data sources across a multitude of micro-services.', 'Work with our Data Warehouse, Data Science, and Product teams to ensure that we have high quality data that meets the needs of the business.', 'Drive data acquisition and technology improvements to help our systems evolve with our needs.', 'You have 3+ years working in an AWS environment, with experience using one or more of the following: Kinesis, EMR, RDS, S3, Glue, Athena, DynamoDB', ""Have experience developing against internal and external API's to consume data from disparate structured and unstructured sources"", '5+ years of experience with languages such as Python, Java, and Scala', 'You have experience with big data tools such as Hadoop, Spark, Hive, Hudi, Presto, Sqoop', 'Experience with stream-processing systems: Kafka, Storm, Spark Streaming', 'You have experience with SQL Databases such as: Redshift, SQL Server, Snowflake, Big Query, Oracle, Postgres, MySQL', 'Experience with NoSQL databases such as Redis, Cassandra, CouchDB, MongoDB, Elasticsearch', 'Experience with data pipeline and workflow management tools: Airflow, Luigi, Oozie, Azkaban, etc.', 'Experience with queuing systems: SQS, RabbitMQ']",2020-12-30 23:24:51
Data Infrastructure Engineer I,United Power,3 out of 5 from 9 employee ratings,"Brighton, CO 80603","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL: 4 years (Preferred)US work authorization (Preferred)', 'Majority of time requires sitting, bending at neck, waist, legs, and arms; twisting body; and changing positions at will. Occasional driving, standing, walking, stooping, bending, kneeling, reaching and stooping.', 'Lift and carry 5-40 pounds frequently and push/pull up to 100 pounds occasionally.', 'Requires repetitive motions with hands and fingers such as keyboarding, use of telephones, cell phones, etc.', 'Requires close vision, distance vision, color vision, peripheral vision, depth perception and the ability to focus.', 'Noise level in work environment is moderate. Work requires close attention to detail and accuracy and is varied in nature with regular interruptions. Work is subject to irregular hours.', 'Requires the ability to drive a vehicle between office locations.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'SQL: 4 years (Preferred)', 'One location', 'unitedpower.com', 'Temporarily due to COVID-19', 'Remote interview process']",2020-12-30 23:24:51
Data Analyst,Hopper,3.5 out of 5 from 4 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Lead analytical projects to support our User Acquisition team. Deliver quantitative results, business understanding and strategic insights to help deploy millions of dollars in ad spend', 'Help create robust tracking of our campaigns, by combining data from ad networks, internal databases and analytics tools to build LTV and cohort analysis reports', 'Design and implement ad hoc and automated analysis scripts, develop and deliver your tables, charts and interactive tools to present your results', 'Work with a cross-functional team of marketers, designers and engineers', 'Find effective ways to simplify and communicate analyses to a non-technical audience', 'Strong analytical and creative problem-solving skills', 'Strong background in relational databases and SQL', 'Experience with marketing analytics concepts like LTV modelling, payback analysis, ROI analysis etc.', 'Experience working with growth teams, or running growth projects', 'Exposure to scripting with Pandas, R, SAS or other data preparation and analysis tools', 'Proven ability to communicate complex technical work to a non-technical audience', 'Enthusiasm and curiosity for conducting research and answering hard questions with data', 'The ability to work with minimal guidance, be proactive and to handle ambiguity and the challenge of quickly evolving goals', 'Experience in mobile user acquisition or in the travel industry', 'Knowledge of MMPs (AppsFlyer), Amplitude, Tableau', 'Experience using Google BigQuery', 'California', 'Connecticut', 'Florida', 'Georgia', 'Illinois', 'Maine', 'Massachusetts', 'Missouri', 'New Jersey', 'Nevada', 'New York', 'Oregon', 'Rhode Island']",2020-12-30 23:24:51
Data Engineer,Ryzen Staffing,N/A,"Cupertino, CA 95014","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Python: 3 years (Preferred)"", '401(k)', 'Dental insurance', 'Health insurance', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Python: 3 years (Preferred)', 'No', 'Temporarily due to COVID-19']",2020-12-30 23:24:51
Big Data Implementation Engineer,Dremio,N/A,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Application Architecture: tailor reference architectures to provide performance, resilient, scalable, secure, distributed architectures which can exceed SLAs and are easily maintained.', 'Data Modeling: design and test data models which are pragmatic, performant, and scalable.', 'Application Implementation: show the customer how to write robust and scalable data access code that correctly utilizes drivers.', 'Infrastructure: help the customer select on-premise hardware or cloud instance types based on workload and capacity assessments.', 'Production Operations: help the customer deploy, configure, secure, maintain, monitor, scale, troubleshoot, test and tune Enterprise clusters.', ""Instructive Consulting: in response to customer questions, provide ad-hoc instruction that is shaped by the customer's specific environment, requirements and constraints."", 'Identifying Needs: bring in the sales team when the customer will benefit from a services or license purchase / expansion.', 'A Team Effort: collaborate with other roles in Dremio Professional Services, Technical Support, pre-Sales, Sales, etc. to ensure our customer is successful.', 'In-depth, current, hands-on knowledge of SQL, particularly advanced SQL techniques used in analytic contexts, is a must.', 'Data architecture, data modeling, warehousing concepts. Deep understanding of data architectures which support reporting and analytics use cases.', 'Experience with ETL concepts, techniques, pipelines, tools, challenges', 'Performance techniques for accelerating Reporting / Dashboarding use cases (OLAP, Materialized Views, etc)', 'Hands-on experience with the Hadoop Ecosystem ( YARN, Zookeeper)', 'Hive / Impala / Spark / etc', 'AWS/Azure/GCP', 'Cloud performance considerations', 'Kubernetes / AKS / EKS', 'Excellent written and verbal communications skills', 'Ability to present on technical topics to various levels within the enterprise']",2020-12-30 23:24:51
"Big Data Engineer, Trek 3 Team (remote-centric; US or Canada)",LogMeIn,3.6 out of 5 from 99 employee ratings,"Lindon, UT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, build and launch efficient and reliable data pipelines in order to source data from complex and disparate data sources, and process that data into consumable formats that help to enable insights', 'Monitor and maintain existing data pipelines by debugging data issues, releasing hot fixes and optimizing performance to ensure data quality and adherence to SLA’s', 'Partner with Product Managers, Data Scientists, and representatives from various cross-functional teams to understand data needs', 'Understand complex business requirements and develop metrics to drive business growth and decision making', 'Introduce ideas and innovation. Suggest improvements to the existing development processes and practices to improve the overall efficiency of the team. Actively help drive the team towards the next generation of capabilities', 'Document system designs, specifications and work artifacts', 'Professional Big Data experience, (e.g. ETL/Data Pipeline Design and Development, Data Warehousing, Complex SQL Queries, Business Logic, etc.)', 'Python and Spark programming skills, (Inc. Frameworks, Libraries & Tools)', 'Hands-on experience working in Big Data and Cloud ecosystems, (e.g. Hadoop Framework, AWS, EMR, EC2, S3, Lambda, Hive Airflow, Delta Lake, Hudi, etc.)', 'Practical knowledge of Linux or Unix Shell Scripting', 'Must be passionate about Big Data, technical challenges, and problem solving, (Inc. real-time and batch processing on large volumes of data with significant complexity)', ""Bachelor's degree in Computer Science (or equivalent) required; Master’s degree preferred"", 'Ability to clearly communicate with technical and non-technical audiences, (Inc. verbal and written language skills)']",2020-12-30 23:24:51
Early Career Program: Engineering and Technology Program (United States) 2021 Opportunities,Baker Hughes,"4 out of 5 from 5,393 employee ratings","Houston, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Participating in intentional and structured career development activities and receive active coaching and mentoring', 'Completing formal training in engineering fundamentals essential to the Baker Hughes Engineers and relevant for the business', 'Networking globally and cross-functionally, leading program initiatives or projects with peers, interacting with global business leaders cross-functionally', 'Solving critical business challenges through cross-functional, mission-based teams', 'Participating in international experiences and assignments', ""Have a Bachelor's degree in Engineering, Technology, Mechanics or another STEM subject"", 'Have graduated within the last 3 years', 'Have a GPA greater than or equal to 3.0/4.0 or equivalent', 'Be fluent in English (oral and written) and have effective communication skills', 'Be geographically mobile due to location availability of role', 'Be able to legally work in the country that you are applying in, without company sponsorship or time restriction', 'Be inquisitive and outwardly present a thirst for more knowledge', 'Occasional remote working as required', 'Working flexible hours - flexing the times when you work in the day to help you fit in everything in and work when you are the most productive', 'Flexing the hours, you work to collaborate with colleagues internationally', 'Talk to us about your desired flexible working options when you apply', 'Contemporary work-life balance policies and well being activities', 'Comprehensive private medical care options', 'Safety net of life insurance and disability programs', 'Tailored financial programs', 'Additional elected or voluntary benefits']",2020-12-30 23:24:51
Associate DevOps Engineer,Moody's Corporation,3.7 out of 5 from 458 employee ratings,"West Chester, PA 19380","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Bachelor’s degree in Computer Science, related field, or equivalent experience', 'Strong understanding of DevOps concepts', 'Understanding of RTO/RPO principles', '2+ years experience building and maintaining systems in AWS (IAM, Route53, Lambda, API gateway, S3, Athena, CodePipeline)', 'Understanding of distributed cloud architecture (multiple account/region configuration)', 'Experience creating/maintaining containerized applications (ECS/Fargate)', 'Experience developing CI/CD and leveraging CloudFormation templates and/or terraform.', 'Understanding of system hardening and cloud security best practices', 'Understanding of basic cybersecurity frameworks (NIST, MAS, etc.)', 'Experience developing infrastructure as code using the gitflow workflow', 'Experience with scripting and programming, such as Powershell, Python and/or Bash', 'Experience with configuration management and automation tools', 'Understanding of enterprise services and technologies including firewalls, routing, certificates, Active Directory, IAM, etc.', 'Proactively identifies existing opportunities for automation and drive new ones', 'Strong ability to troubleshoot and solve problems independently as well as proactively identify potential flaws in existing systems.', 'Bash scripting, Linux administration and database administration', 'Experience with high traffic websites', 'Willing to work in a fast paced and multitasking environment', 'Strong communication and documentation skills']",2020-12-30 23:24:51
Research Engineer / Health Data Scientist (Multiple Locations),Evidation,N/A,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work with limited supervision from more senior team members to lead, define strategy, and execute on software development projects supporting the research team', 'Contributes to cross-functional discussion, planning and execution medium-high complexity projects', 'Mentors and coaches more junior team member with diverse backgrounds to drive learning and engagement', 'Communicate findings, roadblocks and timelines cross-functionally to ensure project objectives are supported', 'Build re-usable tools and models to predict health-related variables from time-series continuously collected from connected devices and apps', 'Maintain the highest level of rigor and apply best practices to create reproducible, generalizable, fair, unbiased, and preferably interpretable models', 'Develop and review code as a major responsibility (typically up to 50-70% of the time)', ""Master's or PhD in computer science, data science, software engineering, or electrical engineering, or related discipline, OR"", ""Bachelor's in computer science, data science, software engineering, electrical engineering, or related discipline with 2+ years experience in software development or related field(s)"", 'Exposure to data science techniques and tool kits (e.g. spark, pandas, matplotlib)', 'Highly proficient in Python or R', 'High level of motivation and willingness to learn new tools and ideas.', '1+ years of experience in a health data science or related field', 'Experience with devops and systems', 'Experience working with wearable data or IoT data', 'Health, dental, and vision benefits for you and competitive coverage for your family', 'Relocation support', 'Equity', 'Flexible work hours', 'Open vacation policy - take time when you need it', 'Support for remote work when needed', 'Relaxed work environment', 'Your choice of computing equipment and gear', 'Lots of opportunities for growth', ""Opportunity to work on fascinating challenges that improve people's lives""]",2020-12-30 23:24:51
"Software Engineer, Data Ingestion",Centricity,3.3 out of 5 from 7 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build robust, scalable and interoperable applications and services that can ingest and transfer very large amounts of data', 'Provide support for your product and applications by being the point of contact for client IT teams', 'Implement new features while applying software development and security best practices', 'Assist with the client onboarding process by facilitating ingestion of client data', ""Maintain and develop new features for existing api's and UI's"", 'Troubleshoot and fix bugs', 'Writing and maintaining developer documentation', 'Writing unit tests', 'Python, Node.js, Go, or other back end programming language', 'Strong experience with either AWS or GCP', 'Spark', 'Airflow', 'Hadoop/Hive', 'HTML/JS/CSS', 'SQL', 'Relation or NOSQL database', 'Git', 'Linux administration']",2020-12-30 23:24:51
CCB - Quantitative Modeling/Data Science - Associate,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Columbus, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Building statistical models for key business drivers, including forecasting deposits, loans, and revenue', 'Performing advanced quantitative and statistical analysis of large datasets to identify trends, patterns, and correlations that can be used to improve business performance', 'Communicating results across audiences throughout JPMorgan Chase', 'Actively contributing to the continuous learning mindset of the organization by bringing in new ideas and perspectives that stretch the thinking of the group', 'Forecasting the performance of branches or bankers to improve the branch network', 'Predicting credit card redemption patterns', 'Forecasting call volume to optimize staffing level', 'Deep quantitative/programming background with a graduate degree (M.S., Ph.D.) in Statistics, Engineering, Computer Science, Mathematics, Operations Research, or Economics,', '1-3+ years of related experience preferred', 'Hands-on experience with Machine Learning and Artificial Intelligence', 'Ability to write code and develop production-ready analytical applications', 'Significant experience working with very large scale (structured and unstructured) data', 'Expertise in at least one of the following: Python, R']",2020-12-30 23:24:51
Data Engineer,ProbablyMonsters,N/A,"Bellevue, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You take pride in being able to turn data into meaningful insights', 'You understand the challenges and pitfalls with building scalable and maintainable data systems', 'You enjoy digging into the infrastructure on which your data systems run', 'You ensure services are observable and ensure metrics, logs, and traces are readily available for the systems you deploy', 'You know how and when to leverage existing services to build solutions faster and cheaper', 'You have a strong desire to automate and test everything', 'You enjoy engaging with teams to identify their analytics needs', 'Innovate our data services to create a scalable, game-agnostic data analytics platform that serves all of our game studios and stakeholders', 'Design and implement data lake and warehouse solutions which enable studios to get the most value out of their data', 'Build supportable systems that enable successful and efficient live-ops support', 'Work with exciting datasets', 'Collaborate closely with other engineers across the entire ProbablyMonsters family of studios.', 'Promote a culture of quality, reliability, and customer-focus', 'Three years of experience building and operating data pipelines which ingest large volumes of event data from online games or services', 'Three years of experience designing and implementing analytics solutions which include data lake storage, working with large unstructured datasets, and designing data models', 'Two years of experience working with data systems hosted in the cloud; including experience with at least one managed service', 'Ability to write code in Python, Java, or equivalent language(s)', 'Ability to write complex SQL queries']",2020-12-30 23:24:51
Data Scientist / Machine Learning Engineer,SS&C Technologies,3.2 out of 5 from 859 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Support the product development teams during all phases of the application lifecycle, functioning as a subject matter expert for all things data and data-access related.', 'Identify opportunities and offer recommendations about process and technology optimizations.', 'Partner with members of business and technology teams in research, scoping, design, execution, and optimization.', 'Embrace, support and extend standards and guidelines pertaining to data and data access.', 'Share a passion for your role with all, and demonstrate a focus on continuous improvement.', 'Expertise with Python, Tensorflow framework, Scikit-Learn toolkit, Scala, R or other machine learning disciplines.', 'Knowledge of traditional RDMS or non-SQL database server ecosystem in highly available, performant and secure configurations.', 'Experience in database, programming and scripting tools: T-SQL, JavaScript,', 'Exposure to MongoDB, Cassandra and/or other document or non-sql data stores.', 'Stream processing and integration with messaging platforms like Kafka or IBM MQ.', 'Experience with machine based algorithms and different types of distributions, Outlier detection, random forest, isolation forest, Gaussian process, etc.', 'Familiarity with modern software development practices, processes, and tools.', 'Prior exposure to multi-tenant data architectures, with a focus on optimizing for large-scale data sets (multi-terabyte tables).', 'Understanding of scalability options at the data tier, including partitioning and sharding scenarios.', 'Bachelors’ degree in Computer Science or related Engineering field.', 'Masters’ Degree preferred.', 'Pay Type Salary']",2020-12-30 23:24:51
Azure Data Engineer Developer - Fully Remote,DXC Technology,"3.2 out of 5 from 3,359 employee ratings","Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)Data Warehouse: 1 year (Preferred)"", 'Work as part of a team to develop Azure Cloud Applications, work with Big Data Cloud Data and Analytics solutions', 'Participate in development of cloud SQL data warehouses, data as a service, business intelligence solutions', 'Complex Py-spark Coding', 'Creation of Pipelines', 'Transforming data to a more gradual level', 'Data wrangling of heterogeneous data', 'Ability to provide solutions that are forward-thinking in data and analytics', 'Work Eastern Standard Time Hours', 'Delivery a quality product', '2-3 years hand on experience with Azure', 'Broad depth of knowledge of the Azure environment', 'Azure Data Lake', 'Azure Data Factory', 'Data Bricks Foundation (Spark, Java, etc.)', 'Py-Spark Coding – simple to complex', 'Hive', 'Proven experience with creating applications in Azure, working with legacy application for data migration could be business application such as HR/Payroll or legacy data warehousing (oracle, SQL, MF DB2)', 'Data ingestion and data profiling into Azure', 'Data Mapping from source to cloud', 'Excellent written and verbal skills (English)', 'Flexible', 'Self-Starter', 'Detailed', 'Team Player or individual contributor', 'MS Office (excel, word, visio, etc.)', 'A Plus:', 'Proficient in a source code control system such as GIT', 'Understands capability of Informatica with Azure', 'PL/SQL', 'Transaction (Stored procedures)', 'Ability to perform complex coding', 'Logic Apps', 'Data Mapping from source to cloud', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Referral program', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)', 'Data Warehouse: 1 year (Preferred)', 'Fully Remote', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- quality and precision-focused', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'https://www.dxc.technology/', 'https://www.facebook.com/DXCTechnology']",2020-12-30 23:24:51
Data Engineer - FinTech Team,"Groupon, Inc.",3.6 out of 5 from 825 employee ratings,"Chicago, IL 60654","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, implement, and maintain generic ETL jobs and support services for the financial data mart in the data warehouse', 'Drive and support further automatization of the international financial data pipeline in the data warehouse', 'Utilize experience and end-to-end knowledge of data warehousing and BI systems (including data architectures in translating business requirements into data models)', 'Work with business users and data analysts to design and implement data integration flows into the financial data mart in the data warehouse', 'Design data models and write specifications for the integration of heterogeneous data sources', 'Advice on and resolve any performance or scaling issue', 'Bachelor’s degree in Computer Science, Mathematics, Econometrics, or proven work experience of five years in an academic-level environment', 'Proficient with one mainstream object oriented programming languages ( e.g. Java, Python)', 'Love for detail: Being skilled and passionate for in-depth technical data analysis, explaining the last 0.001%', 'Flexibility, an independent data-driven working style being both diligent and precise', 'Strong communication skills, both verbally and written', 'Outstanding SQL scripting skills', 'Work experience in the field of Business Intelligence or Information Management', 'Practice in documentation of (logical) data models', 'Skills in database ETL with continuous desire to reduce workload by automation', 'Familiarity with working in a SOX-compliant (or similar) environment', 'Experience in handling mass data', 'Proficiency in Talend Data Integration (or comparable ETL tool)', 'Experience with JIRA (or similar ticketing tool)']",2020-12-30 23:24:51
Data Engineer/ Business Intelligence developer,S2 Innovative Technologies LLC,N/A,"Dallas, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:26:33
Software Engineer Intern - Summer 2021 (Virtual),SurveyMonkey,4.1 out of 5 from 19 employee ratings,"Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Currently enrolled Junior (graduating in Spring 2022) pursuing a Bachelor's degree in Computer Science, Software Engineering, or a similar degree"", 'Solid CS fundamentals (data structures and algorithms)', 'Experience with programming languages and frameworks such as Python, Java, or C++', 'Experience with web development technologies including HTML, CSS, or JavaScript', 'Eagerness to learn and get hands on experience with the latest technologies', 'Willingness to own a project from start to finish', 'Strong analytical and problem solving skills', 'Excellent written and verbal communication skills', 'Strong work ethic and desire to have fun working with great people']",2020-12-30 23:26:33
Data Engineer,Bluestone Analytics,N/A,"Alexandria, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Integrate OSINT data across multiple disparate systems.', 'Clean, normalize, and aggregate reporting and develop analytics.', 'Provide support to functional areas by acting as an expert in tools and methods for accessing, analyzing, and reporting OSINT data.', 'Create and maintain optimal data pipeline architecture.', 'Apply semantic data modeling techniques to classify, aggregate, and generalize data stored in hierarchical, network, or relational database management systems to define the meaning of data within the context of its interrelationships with other data;', 'Design physical database management systems to represent semantic data models, including relational and objective-relational Databases (e.g. Postgress, SQL Server, MySQL), Key value stores, Inverted Indexes (Lucene, Elastic Search), and distributed file systems (e.g. Tachyon, HDFS);', 'Work with stakeholders and other teams to assist with data-related technical issues and support data infrastructure needs.', 'Integrate software code and scripts for the automation of repeatable extract, transform, and load', 'Work with data and analytics experts to strive for greater functionality in data systems.', 'Participating in special projects and performs other duties as assigned.', 'US DoD Top Secret Security Clearance with SCI eligibility', ""At least five years of experience and a Bachelor's degree in Computer Science or a related technical field, or equivalent combination of education and experience."", 'Fully proficient data engineering abilities, typically gained through five years of working with Python/Java, SQL, working schema design, and dimensional data modeling.', 'DOD Counterintelligence Polygraph', 'Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Working knowledge of Python or Java.', 'Knowledge of building and optimizing data pipelines, architectures and data sets.', 'Ability to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable data stores.', 'Strong project management and organizational skills.', 'Ability to support and work with cross-functional teams in a dynamic environment.']",2020-12-30 23:26:33
Data Engineer,Everlywell,2.5 out of 5 from 2 employee ratings,"Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Be an essential part of designing and building our new data architecture and platform', 'Build and maintain ETL pipelines that are reliable and scalable', 'Explore and evaluate new technologies and make recommendations where necessary', 'Develop, test and maintain existing architecture', 'Identify gaps and monitor in current data processes and drive improvements', 'Recommend ways to improve data reliability, efficiency and quality of the data platform and optimize for performance, scalability and cost', 'Work with ELT tools to sync data to/from 3rd party services', 'Collaborate with the Data Analytics team to build the correct datasets for further consumption by various visualization tools', 'Design data models that support business needs', 'Programming experience and a demonstrated interest in statistical analysis and business intelligence', '5+ years experience with SQL, Data Warehouse development and ETL', 'Hands-on experience with at least one cloud-based data warehouse (e.g. Snowflake, Redshift, etc.)', 'Expert-level scripting skills using Python, Shell or similar', 'Expertise in PySpark and Pandas', 'Experience with standard warehousing concepts like Data Marts and Dimensional Modeling', 'Excellent communication skills, both verbal and written', 'Experience with at least one data modeling tool', 'Strong problem-solving abilities and critical thinking', 'Hands-on experience managing and performance-tuning PostgreSQL', 'Experience with ETL tools like Stitch, Fivetran, Pentaho, etc.', 'Experience with data warehouse schema design and architecture', 'Experience with Big Data solutions such as Snowflake or Redshift', 'Experience managing RDS, a definite plus', 'Experience with Data Science Notebooks', 'Experience with NoSQL databases', 'Venture backed by top-tier firms', 'The opportunity ahead knows no bounds', 'Open vacation policy', 'Employee discounts', 'Paid parental leave', 'Health benefits', '401(k)']",2020-12-30 23:26:33
Machine Learning Engineer - Search & Recommendations (various levels),Twitter,4.1 out of 5 from 90 employee ratings,"San Francisco, CA 94103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Improve existing search engine and recommendation systems, experiment with new directions and provide ML solutions in recommendation systems within Twitter.', 'Build models and algorithms to understand user interest, user intent, and improve content relevancy.', 'Build features and develop new ranking algorithms.', 'Work closely with live production systems and product teams, and deliver ML solutions at scale within the Twitter tech stack.', 'Thrive on working in concert with other smart people, including from distributed offices.', 'Communicate fluidly, at the level of your audience, and seek to understand and be understood.', 'Have the ability to take on complex problems, learn quickly, iterate, and persist towards a good solution.', 'Take pride in polishing and supporting our products.', 'In the role, you are employing a basic understanding of one or more of these concepts: Information Retrieval, Recommendation Systems, Social Network Analysis.', 'You regularly verify the performance & correctness of the implementations of ML techniques. You are able to triage and fix bugs/issues when they arise.', 'BS, MS, or Ph.D. in Computer Science with 2+ years of related or equivalent experience', 'Fluent in one or more languages like Java, Scala, C++, Python', 'Experience with offline and online data processing frameworks', 'Knowledgeable of core CS concepts such as common data structures and algorithms', 'Comfortable conducting design and code reviews']",2020-12-30 23:26:33
Data Engineer,GTL,3.1 out of 5 from 76 employee ratings,"Falls Church, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with internal business stakeholders to gather required information to perform data analysis', 'Assist in maintaining efficient operation of the reports, visualizations and ETL processes within the GTL back-office', 'Support proper data governance processes and policies; implement and/or validate data lineage, quality checks, classification, etc.', 'Analyze and improve efficiency, scalability, and stability of various system processes', 'Be passionate about solving customer problems and develop solutions that are customer focused', 'Prepare ad-hoc reports, extracts and visualizations as needed', 'Convert ad-hoc reports to automated managed reports using appropriate tools, development and QA processes', 'Identify data inconsistencies, provide workarounds, and report them to stakeholders', 'Troubleshoot data issues, validate result sets, and implement process improvements', 'Generate tracking and monitoring tools to validate data', 'Discuss database structure and application data with developers and DBAs or others in data engineering to obtain best results from data', 'Use acquired information to help build out a big data schema and infrastructure', 'Reading, writing and editing system, architecture, processes and other documentation in documentation tool.', 'Reading, responding to, and writing service tickets in ticketing system.', 'Reviewing and responding to system alerts in internal and external alerting and metrics systems.', '4 Year College Degree in Computer Science, Mathematics, Statistics or a similar quantitative field or comparable experience in lieu of degree', '2-5 years of experience conducting data analytics, financial analysis, ETL, data cleansing', 'Familiarity with Business Intelligence', 'Solid analytical and organizational skills, with ability to analyze processes', 'Proficiency in SQL', 'Experience with Python or equivalent scripting language', 'Familiarity with the command line (Windows CMD or Linux Shell)', 'Experience with scripting languages such as Bash and Perl', 'Proficiency in Excel', 'Experience in analyzing data using statistics', 'Must be accurate and detail oriented in a fast-faced environment with multiple responsibilities', 'Work quickly with a sense of urgency and flexibility to adapt changes resulting from a dynamic and growing environment', 'Ability to handle confidential information with diplomacy and tact', 'Ability to respond to after-hours issues based on escalation', 'Professional attitude and demeanor', 'Experience working with Business Intelligence software such as Business Objects, Looker and PowerBI', 'Experience with Microsoft SQL Server, Oracle and opensource databases such as MySQL and MariaDB', 'Experience with Snowflake, Apache Airflow, Spark and Hive']",2020-12-30 23:26:33
Data Scientist,Apple,"4.2 out of 5 from 9,978 employee ratings","Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Practical experience with and theoretical understanding of algorithms for classification, regression, clustering, and anomaly detection', 'Working knowledge of relational databases, including SQL, and large-scale distributed systems such as Hadoop and Spark', 'Ability to implement data science pipelines and applications in a general programming language such as Python, Scala, or Java', 'Ability to comprehend and debug complex systems integrations spanning toolchains and teams', 'Ability to extract meaningful business insights from data and identify the stories behind the patterns', 'Excellent presentation skills, distilling complex analysis and concepts into concise business-focused takeaways', 'Creativity to engineer novel features and signals, and to push beyond current tools and approaches']",2020-12-30 23:26:33
Data Engineer,Government Tactical Solutions,N/A,"Washington, DC 20006","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""APIs: 1 year (Required)Java Coding: 2 years (Required)Data analytics: 1 year (Required)Criminal background check (Required)Top Secret (Required)High school or equivalent (Preferred)Web services: 1 year (Preferred)Linux based operating system's: 1 year (Preferred)XML and JSON: 1 year (Preferred)Configuration management: 1 year (Preferred)CompTIA Security+ (Preferred)"", 'Provide technical delivery for assigned engagements and drive customer satisfaction.', 'Ensure the technical success of professional services engagements by engaging peers, leading design discussions, troubleshooting, and delivering as needed.', 'Articulate the overall services solution and subsequent service delivery plan to implement the solution to the customer in terms the customer understands.', 'Build relationships and trust with Engagement Managers, Project Managers, Solutions', 'Work with the project manager to provide regular communication to all stakeholders about the status of professional services engagements.', 'Listen to customer needs and map customer challenges to GSS services and solutions.', 'Exceed our customer expectations for services delivery quality, competence, and professionalism.', 'Develop and test Java software plugins and integration modules for HCP family of products', 'Develop and test components using TCP/IP, RSS, SMTP, ODBC/SQL, HTTP/REST, XML, JSON', 'Assist the technical support team in the isolation and resolution of customer issues', 'Author developer documentation and participate in the development of end-user documentation', 'Mentor and advise junior team members', 'Communicate effectively with technical and non-technical members of the project team', 'Support consultants, partners, and the open source community', 'Must possess a TS/SCI clearance or currently have a TS with the ability to upgrade  * Demonstrate knowledge of three or more of the following: o Java development for API based solutions o Enterprise object storage solutions (e.g., S3, HCP, Centera) o Object storage data migrations o Data Analytics solution development o GUI development and programming o Scripting for operational needs', 'Minimum 1 to 3 years professional experience in troubleshooting, maintaining, and developing data-driven applications for enterprise environments', 'Hands-on experience with one or more of the following core technologies: o Experience writing, extending and maintaining Java programs o', 'Must be able to quickly understand technical and business requirements and be able to translate into technical implementation', 'Experience with Pentaho and/or Hitachi Content Intelligence a strong plus', 'Experience with APIs for SharePoint, MS Exchange or MS Work Folder Server', 'Create internal and customer facing documentation using Microsoft Office product suite.', 'Demonstrate excellent verbal and written communications skills', 'Demonstrate excellent customer/business presentation skills', 'Willingness to work a flexible schedule and travel 15-30%', 'Security+ Certification (must be completed prior to start)', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'Washington, DC 20502 (Required)', 'High school or equivalent (Preferred)', 'Web services: 1 year (Preferred)', ""Linux based operating system's: 1 year (Preferred)"", 'XML and JSON: 1 year (Preferred)', 'Configuration management: 1 year (Preferred)', 'APIs: 1 year (Required)', 'Java Coding: 2 years (Required)', 'Data analytics: 1 year (Required)', 'CompTIA Security+ (Preferred)', 'Top Secret (Required)', '25% (Required)', 'Likely', 'Yes', 'A job for which military experienced candidates are encouraged to apply', 'www.Govtact.com', 'YES_OCCASIONALLY']",2020-12-30 23:26:33
Data Engineer,Chenega Corporation,3.7 out of 5 from 590 employee ratings,"Springfield, VA 22151","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'SQL Server Integration Services (SSIS) including UI and custom code features.', 'Write or create stored procedures, SQL scripts, SSIS packages that can be used to:', 'Move data from source databases to target databases', 'Clean / Condition data', 'Convert or transform data', 'Reconcile and confirm converted data', 'Find data errors', 'Validate data to business rules', 'Ability to examine existing ETL scripts and track data back tosource', 'SQL Server administration, tuning, and workbench.', 'Work with business experts to understand data and completedata mappings.', 'Focus on the development of extract, transform, and load (ETL) jobs currently using Microsoft SQL, Server, and SSIS.', 'The environment currently supports hundreds of related ETL jobs that move data between 30 different source systems and between multiple classifications.', 'Part of the challenge as a data engineer will be to find scalable and efficient coding solutions that plug into this extensible system in order to add more data to the Enterprise data store.', 'Other duties as assigned', 'Bachelor’s Degree in Statistics, Mathematics, Computer Science or another quantitative field', 'Equivalent years of experience in lieu of degree', '4 years of relevant experience with the following software / tools:', 'Experience with Microsoft SQL', 'Prior experience supporting IC/DoD', 'The existing data warehouse is built on Microsoft SQL hosted on Amazon Web Services (AWS), so experience developing solutions that scale well in these environments is a plus.', 'Active Top-Secret Clearance with ability to obtain SCI', 'Ability to work independently and yet be effective within a team setting', 'Must be capable of managing multiple efforts with time related constraints in a fast-paced contracting environment', 'Demonstrated ability to effectively communicate and collaborate with diverse internal and external stakeholder groups and individuals', 'Friendly presence, helpful attitude, good interpersonal skills, and ability to work well with others.', 'Excellent skills in Microsoft Word, Excel, and other Office applications', 'Proficient with Microsoft Office Applications, and experience working in a home office setting as well as the ability to train end users on frequently asked technical issues.', 'Ability to provide technical assistance and support over the phone; good phone skills, professional demeanor, previous customer service experience strongly desired.', 'While performing the duties of this Job, the employee is regularly required to sit and talk or hear. The employee is frequently required to walk; use hands to finger, handle, or feel and reach with hands and arms. The employee is occasionally required to stand; climb or balance and stoop, kneel, crouch, or crawl. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include close vision.']",2020-12-30 23:26:33
"Software Engineering Internship, Summer 2021",Etsy,4.3 out of 5 from 58 employee ratings,"Brooklyn, NY 11201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:26:33
"Acoustic Signal Processing Engineer - Data Scientist, Machine Learning",Signal Systems Corporation,N/A,"Millersville, MD 21108","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Master's (Preferred)Signal processing: 5 years (Preferred)"", '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Relocation assistance', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Commission pay', 'Signing bonus', ""Master's (Preferred)"", 'Signal processing: 5 years (Preferred)', 'https://www.signalsystemscorp.com/', 'Temporarily due to COVID-19']",2020-12-30 23:26:33
Data Science and Database Engineer,SPN Solutions Inc.,3.3 out of 5 from 10 employee ratings,"Rosslyn, VA 22209","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)CompTIA Security+ certification (Preferred)US work authorization (Preferred)Confidential (Preferred)"", 'CompTIA Security+ certification (or obtain within 6 months of starting).', 'Expertise exploring and examining healthcare data sets from multiple sources.', 'Experience refactoring database schemas to support evolutionary development, database performance tuning, and design/structural fixes. Includes a solid understanding of data architecture, (i.e., tables, views, definitions, columns, stored procedures, triggers, data quality, and referential integrity).', 'Proven experience in data rewriting, refactoring, architecture, and scaling; to include query refactoring and index optimization.', 'Able to evaluate data architecture for legacy systems, and lead database refactoring efforts by applying enterprise application design patterns.', 'A solid understanding of architectural refactoring (i.e., changes which improve how external programs interact with databases from official data sources); to include CRUD, migrate, and replace methods.', 'Knowledge of statistical modeling techniques and advanced data analytics.', 'Ability developing data set processes for data discovery, modeling, mining, and production.', 'Experience with system comparability using sample data, and regression models.', 'An understanding of data presentation and experimentation design.', 'Superior verbal, written communication, presentation, and customer service skills.', 'DoD experience a plus', 'Knowledge of Agile and DevSecOps testing best practices', 'VPC computing environments (e.g., milCloud 2.0)', 'Knowledge of Roles of Care in Theater (Continuity of Care)', 'Operational Healthcare Functions (Patient Movement, Health Care Delivery to include Dental, MedSA, Med C2, MedLOG to include Theater Blood)', 'Familiarity with:', 'Operations Research/Systems Analyst (ORSA) Handbook.', 'Military Operations Research Society (MORS) -- preferably with published papers and/or books on analytics and experimentation.', 'Virginia Modeling, Analysis & Simulation Center (VMASC).', 'Desired Certifications –', 'Support complex and diverse IT Research and Development (R&D) and data engineering efforts for emerging technology DoD projects.', 'Explore and examine Healthcare data sets from multiple sources or interfaces.', 'Refactor database schemas to support evolutionary development, database performance tuning, and design/structural fixes. Includes a solid understanding of data architecture, (i.e., tables, views, definitions, columns, stored procedures, triggers, data quality, and referential integrity)', 'Perform data rewriting, refactoring, architecture, and scaling; to include query refactoring and index optimization.', 'Evaluate data architecture for legacy systems, and lead database refactoring efforts by applying enterprise application design patterns.', 'Perform refactoring (i.e., changes which improve how external programs interact with databases from official data sources); to include CRUD, migrate, and replace methods.', 'Leverage statistical modeling techniques and advanced data analytics.', 'Develop data set processes for data discovery, modeling, mining, and production.', 'Perform system comparability using sample data, and regression models.', 'An understanding of data presentation and experimentation design.', 'Perform Database refactoring (improving design while retaining informational semantics)', 'Design highly scalable data management systems, and integrating/preparing large, complex data sets that meet functional/non-functional mission requirements, data analysis, movement of data, extracting, transforming, and loading operations of big data sets.', 'Design and sustain data Extract, Transform, and Load (ETL) system, workflow, mapplets.', 'Development and management of Data Lake and Data Warehouse Infrastructures, Data Pipelining and storage.', 'Utilize a variety of tools (scripting languages) to pull data from different source systems critical for data ingestion, refactoring, and optimization of existing data models, to meet functional and performance needs.', 'Comprehensive Health, Dental, and Vision plans available for you and your family', 'Premier 401k retirement plan with corporate matching', 'Generous vacation and sick leave plan', 'Parental leave plan', 'Company paid Life and AD&D Insurance', 'Tuition reimbursement for continuing education', 'Free gourmet coffee, tea, fresh fruits and healthy snacking alternatives', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', ""Bachelor's (Preferred)"", 'CompTIA Security+ certification (Preferred)', 'DASCA (Preferred)', 'SAS Certified AI & Machine Learning Professional (Preferred)', 'CAP (Preferred)', 'Confidential (Preferred)']",2020-12-30 23:26:33
Cloud Data Engineer,Opinior,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Google Cloud Platform: 1 year (Required)US work authorization (Required)Bachelor's (Preferred)"", 'Experience in building solution architecture, provision infrastructure, secure and reliable data-centric services and application in GCP or Azure or AWS or on one of the prominent cloud platforms', 'Work with data team to efficiently use Hadoop/Cloud infrastructure to analyze data, build models, and generate reports/visualizations', 'Integrate massive datasets from multiple data sources for data modelling', 'Implement methods for automation of all parts of the predictive pipeline to minimize labor in development and production', 'Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management', 'Knowledge in machine learning algorithms especially in recommender systems', 'Extracting, Loading, Transforming, cleaning, and validating data', 'Designing pipelines and architectures for data processing', 'Creating and maintaining machine learning and statistical models', 'Querying datasets, visualizing query results and creating reports', 'Minimum 3 year of designing, building and operationalizing large-scale enterprise data solutions and applications using one or more of GCP data and analytics services in combination with 3rd parties - Spark, Cloud DataProc, Cloud Dataflow, Apache Beam, BigTable, Cloud BigQuery, Cloud PubSub, Cloud Functions, etc.', 'Minimum 1 year of hands-on experience analyzing, re-architecting and re-platforming on-premise data warehouses to data platforms on cloud using 3rd party services', 'Minimum 1 year of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java, Python, Scala etc.', 'Minimum 1 year of designing and implementing data engineering, ingestion and curation functions on cloud using native or custom programming', 'Minimum 1 year of experience in performing detail assessments of current state data platforms and creating an appropriate transition path to cloud', 'Hands-on Cloud experience with a minimum of 1 solution designed and implemented at production scale', ""Bachelor's degree or equivalent (minimum 12 years) work experience. If Associate Degree, must have minimum 6 years work experience"", 'Minimum 1 year of architecting and implementing next generation data and analytics platforms on GCP cloud', 'Minimum 1 year of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders', '1 year of hands-on experience designing and implementing data ingestion solutions on GCP using GCP native services or with 3rd parties such as Talend, Informatica', '1 year of hands-on experience architecting and designing data lakes on GCP cloud serving analytics and BI application integrations', 'Minimum 1 year of experience in designing and optimizing data models on GCP cloud using GCP data stores such as BigQuery, BigTable', 'Minimum 1 year of experience integrating GCP or 3rd party KMS, HSM with GCP data services for building secure data solutions', 'Minimum 1 year of experience introducing and operationalizing self-service data preparation tools (e.g. Trifacta, Paxata) on GCP', 'Minimum 1 year of architecting and operating large production Hadoop/NoSQL clusters on premise or using Cloud services', 'Minimum 1 year of architecting and implementing metadata management on GCP', 'Architecting and implementing data governance and security for data platforms on GCP', 'Designing operations architecture and conducting performance engineering for large scale data lakes a production environment', 'Craft and lead client design workshops and provide tradeoffs and recommendations towards building solutions', '2+ years of experience writing complex SQL queries, stored procedures, etc', 'Google Cloud Platform certification is a plus', 'Excellent communication (written and oral) and interpersonal skills', 'Proven ability to work creatively and analytically in a problem-solving environment', 'GC holder/Citizens only', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', ""Bachelor's (Preferred)"", 'Google Cloud Platform: 1 year (Required)', 'Google Cloud Certification (Required)', 'Fully Remote', 'A “Fair Chance” job (you or the employer follow Fair Chance hiring practices when performing background checks)', 'Waiting period may apply', 'Only full-time employees eligible', 'Remote interview process', 'Virtual meetings']",2020-12-30 23:26:33
Data Engineer,Spectral MD,N/A,"Dallas, TX 75201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)developing web and server applications: 3 years (Preferred)AWS: 1 year (Preferred)"", 'Support the transfer of data between a medical device and the cloud, as well as interoperability with a hospital’s electronic medical record system.', 'Drive continued improvement of the backend infrastructure and data pipeline.', 'Work with a cross-functional technical team composed of frontend developers, software engineers, data scientists, and product designers.', 'Develop commercial-ready, testable, reusable code, and produce necessary backend documentation to support medical device design controls.', 'Work with the data science team to develop solutions that facilitate the development of deep learning algorithms, and statistical analysis of data obtained from medical imaging devices.', 'Bachelor’s Degree in Computer Science / Engineering / related field or an equivalent combination of education and work experience', 'Minimum 3 years of related work experience with a solid understanding of specified functional area', 'At least 3 years experience developing web and server applications using Python, Java, C++, C#, or similar: Experience designing and implementing application architecture, database architecture (SQL,NOSQL), and TCP/IP and network programming', 'Knowledgeable in AWS Web Services: AWS IoT Core, Lambda, API Gateway, DynamoDB, S3', 'Knowledge in REST, SOAP, JSON, XML, and other API related standards', 'Understanding of Network Protocols - MQTT, HTTP, JSON objects', 'Understanding of emerging IoT technologies and communications protocols including MQTT, WebSockets, and Notification engines, and preferably implementation experience in AWS IoT services;', 'Experience working within networks in the hospital environment, medical devices, and electronic health record systems.', 'Deploying with Docker and Kubernetes', 'Familiar with CI/CD pipelines with cloud infrastructure', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Paid time off', 'Parental leave', 'Relocation assistance', 'Retirement plan', 'Vision insurance', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'developing web and server applications: 3 years (Preferred)', 'AWS: 1 year (Preferred)', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Team-oriented -- cooperative and collaborative', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'A job for which people with disabilities are encouraged to apply', 'www.spectralmd.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-12-30 23:26:33
.Net Senior Data Engineer,SportsBiz Group Inc,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '.NET: 8 years (Required)SQL / Database: 5 years (Required)US work authorization (Required)', 'An opportunity to make contribute to exciting products used by a highly passionate user base', 'Advanced personal learning and development opportunities', 'Comprehensive healthcare plan', 'Status as a founding partner of the Company which includes a generous revenue generation and equity package.', 'Work closely with and support product management to analyze changing needs, form solutions, and deliver quality and cost-effective results', 'Own the Data Pipeline development, implementation, maintenance, and on-going updates', ""Work flexibly within the product development and data science teams to launch and iterate SportsBiz's flagship web application, solve known problems and discover and pursue transformations of opportunities to reduce cost, complexity, and risk"", 'Adapt to changing needs, domains, technologies and programming languages', 'Apply technology to automate or transform tasks from high cost and high touch to low cost and low effort', 'Perform development integration and system testing to ensure delivery of defect free code', 'Ensure the development efforts are within the estimated time and delivered as scheduled', 'Follow development processes and policies and engage with technical community to continuously improve the effectiveness of the team', '8+ years of experience in .NET', '5+ years of experience with SQL on SQL Server, Postgres, MySQL, or other relational databases', 'Excellent command of C#.Net, Data Lakes, Data Warehouses, relational databases (Postgres, SQL Server) as well as non-sql databases (Mondo, DynamoDB)', 'Must have familiarity with AWS Lambda, AWS Glue, AWS Redshift, AWS Redshift Spectrum, AWS Kinesis, and S3', 'Experience in ETL/ELT with both batch processing and real-time', 'Strong understanding of data-driven web-based applications and web services – including AJAX, JSON, OpenAPI (Swagger), Raml, REST, and SOAP', 'Familiarity with source control systems and management practices – GIT, Bitbucket, SVN', 'Experience in Apache Spark or Hadoop', 'Experience with optimizing data for an analytics platform (Tableau, PowerBi, etc.) a plus', 'Experience with Python and Jupyter notebooks a plus', 'Experience in machine learning platforms a plus (SageMaker, Tensorflow, etc.)', 'Bachelor’s Degree in Engineering or Computer Science', 'Monday to Friday', '.NET: 8 years (Required)', 'SQL / Database: 5 years (Required)']",2020-12-30 23:26:33
"Software Engineer, Back End",eBay Inc.,"3.9 out of 5 from 1,691 employee ratings","San Jose, CA 95113","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:28:16
"Software Engineer, Data",Brex,N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and build user-friendly data platforms upon which data scientists can easily test and deploy models to production.', 'Scope, design and build tools for internal users to increase their efficiency ten-fold.', 'Improve and maintain data platform uptime', 'Design and implement customer facing data services and products from end to end.', 'Work closely with analysts and data scientists to deeply understand business problems and be a guiding voice in architecting the solutions.', 'Build and maintain robust, observable data pipelines.', 'Maintain a strong data driven culture within the company by interacting with diverse internal functions.', 'Experience with data pipelines and data warehousing, such as Big Query and Snowflake.', 'Experience working with SQL or NoSQL databases', 'Familiarity with software engineering development cycles', 'Experience working with backend programming languages (Java, Kotlin, Python)', 'Ability to hold yourself and the team to high standards', 'Strong communication and interpersonal skills', 'Experience with Airflow, SQL, python, kafka, live processing', 'Familiarity with functional programming languages', 'Strong writing skills', 'Proactive approach', 'Experience as a project lead']",2020-12-30 23:28:16
Data Engineer,SupportLogic,N/A,"Santa Clara, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Ingesting data from a variety of data sources (and for customers with anywhere from 10 to 10,000 support agents)', 'Providing custom ETL for valued customers with unique data requirements', 'Transforming and normalizing customer data so that it may be consistently used across a variety of ML and UI applications', 'Providing rich data for Machine Learning model training and inference in production', 'Providing low-latency data for UI teams in development and production environments', 'Integrating our Data Platform with the outside world (Slack/Teams/email integrations etc.,)', 'Understand customer data requirements and produce SQL queries or Python code that addresses these requirements while also adhering to the broader Data Platform schema', 'Augment existing ETL to support new Systems of Record (i.e., CRMs)', 'Convert Python “ETL” into SQL via sqlalchemy (and vice versa where appropriate)', 'Produce modular, flexible, and scalable SQL queries in Python via sqlachemy', 'Analyze, recommend & implement mechanisms to improve data reliability and quality', 'Work with the ML or UI teams to provide data access patterns to suit their needs (SQL queries for ML; APIs for the UI)', 'Located in the United States (due to customer data access requirements)', '2+ years of professional software development experience', 'S., degree in Computer Science, Engineering, or similar quantitative field of study', 'Fluency and a high degree of skill in Python', '1+ years experience with SQL databases and SQL queries, especially PostgreSQL', '1+ years experience with sqlalchemy or other Python ORMs', 'Teamwork, collaboration, and effective communication skills', 'Self-starting, with the interest and passion to contribute in a fast-paced startup environment', 'S., in Computer Science, Engineering, or similar quantitative field of study', 'Prior startup experience', 'Experience working on or with cloud platforms (AWS, GCP, Azure)', 'API (especially REST) experience, particularly in Flask or FastAPI', 'Experience providing analytics-oriented data for ML or DS teams', 'Experience using pytest to ensure high code quality, especially in data-driven applications']",2020-12-30 23:28:16
Data Engineer,Browse Info Solutions.,N/A,"Canton, MI 48187","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'The Data Engineer is responsible for the development and maintenance of the Data Lake and all the processes supporting the acquisition and integration of data.', 'Data engineer will also contribute in the design of new data lake components and data marts.', 'Responsible for the quality of all of the data integration processes as well as participation in operational support on a regular rotation basis.', 'Build data engineering expertise and own data quality for ingestion pipelines.', 'Drive technical excellence and implementation of best data engineering practices.', 'Design and delivering large scale, 24-7, mission-critical data pipelines and features using modern cloud and big data architectures.', 'Develop Batch and Stream processing services such as Kafka, AWS Kinesis, AWS Glue, Apache Storm and Spark Streaming', 'Deliver solutions in any big data and database technologies - Hadoop, EMR, Amazon Redshift, Snowflake, AWS DynamoDB, or advanced analytics tools', 'Oversee the design, scoping, implementation, and testing in short agile release cycles of in-house development and vendor implementations end-to-end.', 'Demonstrated experience working in large-scale data environments which included real-time and batch processing requirements.', 'Strong understanding of ETL processing with large data stores. Strong data modeling skills (relational, dimensional and flattened). Strong analytical and SQL skills, with attention to detail.', 'Proficiency with at least one of the following languages: Java, Python, Scala.', 'Experience with Amazon AWS services (Redshift, SQS, Kinesis, DynamoDB, RDS, Batch, Spark, and etc.)', 'Expert level proficiency in SQL. Ability to perform complex data analysis with large volumes of data.', 'Experience with Big Data technologies, e.g., Hadoop, Spark', 'Hands-on experience building real-time or near real-time data pipelines is a big plus']",2020-12-30 23:28:16
Data Engineer / ETL Developer (Remote),DataLink,3.5 out of 5 from 52 employee ratings,"Tampa, FL 33637","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop and implement ETL solutions for ingesting, cleansing, business rules execution and pushing customer data into DataLink’s systems.', 'Significant participation in analysis, interpretation, and translation of complex health plan data, issues, trends and relationships to provide our customers detailed insights into their data', 'Analyze and interpret complex data on source and target systems, identify the gaps, and provide solutions', 'Ability to write complex SQL queries', 'Optimizes SSIS package execution and SQL execution to minimize load times.', 'Ensures data integrity throughout the ETL process and appropriately handle errors', 'Work closely with Scrum team members using Agile processes to iteratively develop and improve ETL pipelines.', 'Proactively provide feedback and process improvement recommendations to the team and management', 'Other duties as assigned', 'Bachelor’s degree in Computer Science, Management Information Systems or related discipline Overall 5+ years of experience designing and developing ETL processes', '3+ years of experience with SSIS, SSRS, SQL Server and T-SQL', 'Data analysis, data presentation, spread sheet and database capabilities', '3+ years of experience automating ETL pipelines with a heavy emphasis on quality, validation and tracking', 'Experience with SAS or other statistical applications', 'Experience with SSAS, Tabular Models and/or Star Schemas', 'Experience with Healthcare data', 'Experience with NoSQL Database such as Hadoop and MongoDB', 'Excellent Medical, dental, and vision coverage', 'Life and disability insurance for income protection', '401(k) plan to save for your future, including company match of up to 4%', 'Competitive time off benefits including PTO, sick and holiday', 'Professional development reimbursement program of up to $1,500 per year', 'Tech-modern office space with casual dress code', 'Competitive time off benefits including PTO, sick and holiday', 'Coffee machine w/cappuccino and espresso, along with free snacks all-day/every day', 'Onsite Unisex hair stylist available at no cost to the employee', 'Onsite fitness center']",2020-12-30 23:28:16
Software Engineer II – Streaming Data,AT&T,"3.8 out of 5 from 43,149 employee ratings","New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'This role offers the opportunity to own and build the streaming data pipelines that give our customers insights into the performance of their advertising business. You will:', 'Work with high-throughput data streams (Gigabytes/Sec) from by our real-time auction platform', 'Develop data pipelines that refine and extract data into actionable reports used by customers', 'Implement strategies that ensure the quality, performance, and accuracy of reports', 'Ensure high availability of data pipelines and reports as platform requirements scale', '2+ years demonstrated work experience developing data pipelines and/or working with streaming technologies such as RabbitMQ or Kafka', '2+ years of experience working with analytical data sets +/- 10 TB, OLAP paradigm, and OLAP databases such as Vertica or Snowflake', 'Strong experience with and knowledge of object-oriented coding, primarily Java or other low-level and/or back-end programming languages', 'Experience working within Kubernetes Container Environment', 'Strong SQL skills with the ability write SQL Aggregation Queries at a high-level', 'Strong experience writing well-tested code, deploying code safely, and working in a team with coding standards, including unit testing, functional testing of applications, working with build systems such as Jenkins, Code Review, Design Review, etc.', 'Experience with Samza', 'Familiarity with Protobuf', 'Experience within Ad-Tech space']",2020-12-30 23:28:16
Data Engineer,Built In,N/A,Illinois,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Ownership of Built In's Data Pipeline; this is the data that we pull from our home-built data pipeline and create analytics based on raw events."", 'Must collaborate with other members of the engineering team, whether as mentor or mentee—especially via pair-programming.', 'Is primarily expected to be an individual contributor, focused on writing and reviewing code.', 'Must advocate for focus on technical debt in concert with execution of new features, and has an understanding that doing so allows our team to scale with the demands placed upon us in a stable and robust manner.', 'Be passionate about programming and learning new technologies; focused on helping themselves and the team improve their skills.', 'Must be comfortable with and supporting other other engineering teams by contributing to our service oriented architecture.', '4+ years of experience within the field of data engineering or related technical work.', 'Proven experience with Python. Understanding of Go.', 'Experience with data warehousing and data pipeline tools (examples being Snowflake and Airflow).', 'Exposure to principles of automated testing and commitment to testing as a way of producing robust code.', 'Experience with Git and understanding of our basic workflow (branching for your own work; pull requests to commit work back).', 'Experience with Unix on the command-line, whether via terminal in MacOS or directly on a version of Linux/*BSD, is greatly valued.', ""Be Inclusive, Always. We're committed to a culture where all people are respected, have a say and can be their whole selves. We will uplift and advocate for one another. Always."", 'Be Unreasonably Passionate. Our passion is borderline obsessive, and we\'re ok with that. No one ever built anything great on a ""meh."" We work with outsized passion to fulfill our mission.', ""Be Humble. You don't have all the answers. Luckily, you don't have to. Don't worry about being right. Be humble instead."", 'Stay Curious. Curiosity is a springboard to the future. It can transform the wisp of an idea into a breakthrough. We ask ""what if."" We work with wonder. It\'s how we innovate.', 'Lead with Solutions. Question everything. But offer solutions as you do. Raise issues. But propose a few answers. For every hole you poke, offer a way to patch it up.', 'Own the Result. We have no time for blame or shame. When you stumble, own it, learn from it + get back to business.', 'Do More. Do more than your job description. Take initiative. Take charge. No job is beneath you, and no job is too big. Be a leader and do more — do whatever it takes.']",2020-12-30 23:28:16
Data Scientist/ML Engineer,ACS Group,3.3 out of 5 from 38 employee ratings,"Palo Alto, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build and train production grade ML models on large-scale datasets to solve various business use cases for Commercial Banking.', 'Use large scale data processing frameworks such as Spark, AWS EMR for feature engineering and be proficient across various data both structured and un-structured.', 'Use Deep Learning models like CNN, RNN and NLP (BERT) for solving various business use cases like name entity resolution, forecasting and anomaly detection.', 'Ability to build ML models across Public and Private clouds including container-based Kubernetes environments.', 'Develop end-to-end ML pipelines necessary to transform existing applications and business processes into true AI systems.', 'Build both batch and real-time model prediction pipelines with existing application and front-end integrations.', 'You will collaborate to develop large-scale data modeling experiments, evaluating against strong baselines, and extracting key statistical insights and/or cause and effect relations.', 'Advanced Degree in field of Computer Science, Data Science or equivalent discipline.', 'Minimum 5+ years of working experience as a data scientist', 'Expertise with Python, PySpark, DL frameworks like TensorFlow and MLOps.', 'Experience in designing and building highly scalable distributed ML models in production (Scala, applied machine learning, proficient in statistical methods, algorithms)', 'Experience with analytics (ex: SQL, Presto, Spark, Python, AWS suite)', 'Experience with machine learning techniques and advanced analytics (e.g. regression, classification, clustering, time series, econometrics, causal inference, mathematical optimization)', 'Experience working with end-to-end pipelines using frameworks like KubeFlow, TensorFlow and/or crowd-sourced data labeling a plus']",2020-12-30 23:28:16
"Principal, Data Engineer",NBCUniversal,"4 out of 5 from 2,293 employee ratings","New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Open, collaborative environment with talented engineers and engaged business stakeholders.', 'An organization that encourages exploration and rewards good ideas.', 'Programs which facilitate skill development and professional growth.', 'Ability to work remotely.', 'Highly reputed benefits.', 'Serve as a senior data engineer for AdSmart data products', 'Develop and code the data tools and services that are core to AdSmart, including One Platform and Peacock, under the leadership of the VP of Architecutre.', 'Participate in code review and design processes.', 'Utilize cutting-edge cloud computing technologies to solve problems', 'Evaluate new technologies for potential use and integration with existing stack.', 'Participate in, and execute, a 12 – 36 month product roadmap with input from the delivery team, stakeholders and leadership', 'Support product with the overall roadmap and ensure updates to senior leadership are 100% technically correct.', 'Analyze and report results and adjust the overall engineering strategy accordingly with engineering leadership.', 'Someone who is a big thinker who can analyze and evangelize a long-range opportunity, architect a groundbreaking solution, and roll-up your sleeves to get code out the door when needed.', 'Someone who is data-driven and analytical', 'Someone who understands the concept of a value proposition and evaluation criteria, and you know how to align them with low-level milestones to get the work done.', 'Someone who can apply domain knowledge from one technical subject, in order to quickly ramp up and deliver on a new one.', 'Someone who knows how to learn from failure until you succeed, and you are able to articulate and quantify the reasons for your decisions.', 'Bachelor’s degree in Computer Science or related field.', '5+ years of software development experience, as a developer or manager', 'Fluency in Scala and/or Java programming languages.', 'Strong OO & FP design patterns, data structure, and algorithm design skills', 'Extensive experience developing Apache Spark applications.', '2+ years of experience with both relational database design (SQL), non-relational (NoSQL) databases, big data, real-time technologies.', 'Familiar with various cloud data sources and architectures such as AWS/S3, HDFS, Kafka.', 'Experience with software containerization, such as Docker.', 'Experience developing and/or consuming web interfaces (REST API) and associated skills (HTTP, web services).', 'Experience with Cluster Management and Container Orchestration technologies such as Mesos, Kubernetes, Hadoop/Yarn.', 'Experience with cloud native technology services like AWS Lambda.', 'Self-directed, ability to multi-task, sharp analytical abilities, excellent communication skills, capable of working effectively in a dynamic environment.']",2020-12-30 23:28:16
Data Engineer,"Baker Tilly US, LLP",3.9 out of 5 from 425 employee ratings,"Milwaukee, WI 53202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'You are very well versed in BI and data analytics, SQL, the MS Stack, Azure and other cloud services.', 'You enjoy supporting a variety of industries and embedding yourself with client teams to work together to find a solution.', 'You enjoy being face to face with clients, understand who the key stakeholders on projects are, and positively influence the business need behind the use of data.', 'You are constantly looking to grow your education in technology and staying up to date with the latest trends.', 'You are a team player that encourages collaboration and has an intrapreneurial mind.', 'You enjoy sharing what you learned with the team and are willing to be a mentor to others.', 'You love to learn and enjoy putting yourself out of your comfort zone and have done or at least entertained the idea of speaking at tech events.', 'Enjoy building relationships with your colleagues through social activities and team outings supporting work-life balance.', 'You have and are interested in maintaining different technical certifications.', 'You will be responsible for working within an agile environment to aid in the delivery of a managed service defined by the Architect of Project Manager.', 'Have strong experience building out data warehouses.', 'Lead or support the day to day sprint activities provided to you by your pod leader.', 'Work to understand business processes and possible improvements across an array of industries.', 'Utilize your scoping talents to help identify more areas within the business that our team can successfully impact for future projects.', 'Have hands on experience in Microsoft business intelligence technologies that may include:', 'Have at least 4 years of experience working within these technologies as well as other backend tech.', 'Apply different data modeling techniques and functional knowledge to both your internal team and external partners.', 'Exhibit responsibility and accountability towards quality completion of projects and consistently hitting project timelines.', 'Strong verbal and written communication skills and are not ashamed to ask questions or raise concern on projects.', 'Outstanding customer service skills following proper business requirements and human resources expectations.', 'Disciplined to be able to work in a variety of business environments.', 'Ability to travel potentially up to 50% of the time.', 'Maintained a Bachelor’s degree in Computer Science, Engineering, Math, Information Technology, or other related discipline or 10 + years of commensurate experience.']",2020-12-30 23:28:16
Data Engineer,Hiya,3 out of 5 from 2 employee ratings,"Seattle, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Be designing, coding and operating mission-critical data processing pipelines on a combination of Apache Spark and other JVM based platforms (primarily Scala)', 'Understand our entire data stack from Spark through Kafka to Scala/Akka components', 'Design and implement Machine Learning pipelines using cutting edge technologies', 'Build and operate world-class data services in the field of phone fraud detection, having the chance to create an impact on the lives of tens of millions of consumers daily', ""Be part of a team where your desire to grow and learn is valued and aptly rewarded; where you are empowered to make yourself and your team more productive every day; where using and contributing to open source are looked upon as an asset; where innovating and executing are core to your teams' beliefs"", 'Professional experience building highly scalable and available ETL solutions based on the Apache Spark ecosystem', 'A desire to own design and architecture end to end', 'You already worked with various big-data technologies (Redshift, Parquet, Athena/Presto, Airflow, Zeppelin, etc.)', 'Being fluent in data friendly languages (Python, Scala or Java, SQL)', 'Having experience with stream processing and scaling techniques (caching, message queues, eventual consistency, etc.)', 'Familiarity with modern deployment environments (AWS, Docker, Kubernetes)', 'Passionate about solving complex business problems with advanced Machine Learning and Big Data technologies']",2020-12-30 23:28:16
Data Mining Engineer (Data Mining) -2021 Start,TikTok,4.2 out of 5 from 11 employee ratings,"Mountain View, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Enable and contribute to establishing fast and continuous threat response, in partnership with product risk operations, by building advanced analytics systems and data mining insights;', 'Enable and contribute to establishing robust and powerful automated defense, in partnership with Machine Learning peers, by creating and improving risk prevention rules and models;', 'Enable and contribute to establishing an accurate, efficient, and reliable human moderation eco-system, in collaboration with multiple cross-functional partners, by identifying and realizing data or engineering opportunities surfaced in risk operations.', ""Currently pursuing your Bachelor's or above degree in Computer Science, Electrical Engineering, or related engineering field, and will graduate during December 2020 - September 2021"", 'Solid technical / data-mining skills and ability to work with large volume data to identify and abstract abusive behavior patterns in ByteDance products (e.g. TikTok).', 'Ability to think critically and to properly communicate problem solutions to cross-functional partners in a clear, concise, and timely manner.', 'Strong ownership (proactivity, initiative, followthrough) to surface and solve open-ended problems against social platform attackers with adversarial nature.', 'Pursuing a Ph.D. degree in Computer Science or Statistics.', 'Publications in top academic conferences on relevant data mining topics about social platform communities. E.g. Botnet, interest group mining, fraud detection.', 'Industry experience (internship included) in predictive analytics and/or statistical modeling.', 'Deep understanding of popular neural net models. E.g. natural language processing, graph embedding, and/or relevant unsupervised/semisupervised/transfer learning.', 'Applications will be reviewed on a rolling basis and we encourage you to apply early;', 'Interview starts in Dec 2020.']",2020-12-30 23:28:16
Data Engineer - Location Flexible,Dropbox,3.9 out of 5 from 44 employee ratings,California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Understand business processes, internal customer data needs and how to implement robust solutions into the overall data architecture', 'Design, build and manage data marts to satisfy our growing data needs', 'Develops and maintains scalable data pipelines at enterprise scale and builds out new API integrations', 'Build data expertise and own data quality for various data flows', 'Launch and support new data models that provide intuitive analytics to internal customers', 'Design and develop new framework and automation tools to enable teams to consume and understand data faster', 'Use your expert coding skills across a number of languages like SQL, Python and Java to support analysts and data scientists', 'Interface with internal data consumers to understand data needs', 'Collaborate with multiple teams in high visibility roles and own the solution end-to-end', '4+ years of SQL experience', '4+ years of Python or Java development experience', '4+ years of experience with schema design and dimensional data modeling', 'Experience working in data warehousing, data architecture and/or data engineering environments at enterprise scale', 'Ability to analyze data to identify problems, gaps and inconsistencies', 'Experience designing, building and maintaining data processing systems', 'Communication skills including the ability to identify and communicate data driven insights', 'BS or MS degree in Computer Science or a related technical field', 'Generous company contribution toward individual medical, dental, & vision insurance coverage', '401k + company match', 'Market competitive total compensation package', 'Free Dropbox space for your friends and family', 'Wellness Reimbursement', 'Generous vacation policy', '10 company paid holidays', 'Volunteer time off', 'Company sponsored tech talks (technology and other relevant professional topics)']",2020-12-30 23:28:16
Data Engineer,OIA Global,2.9 out of 5 from 30 employee ratings,"Portland, OR","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Understand and work with multiple data sources to participate in the creation of a unified, integrated solution which implements defined business rules and supports analytical needs', 'Implement scalable data acquisition and processing pipelines, transformations, and semantic layers to support end-to-end business intelligence solutions, workflows, applications and self-service reporting', 'Create, test, implement and maintain all ETL procedures and processing, ensuring the best possible performance and data quality', 'Participate in planning and defining requirements', 'Develop, test and maintain the organization’s data stores', 'Maintenance and support for test and production systems as a member of a DevOps team', 'Ensure proper source control, documentation, testing and quality assurance processes are developed and followed to maintain high data integrity', 'Participate in the development, specification and communication of a data management plan, and the infrastructure components required to support it', '5+ years of demonstrated experience with ETL processes, SSIS packages, data modeling, data warehousing, SSAS data models and cubes, and relational database design', 'Data modeling / dimensional modeling experience', 'ETL design and implementation experience', 'Data warehouse design and implementation experience', 'Proficiency w/ SQL', 'Proficiency w/ Microsoft Data Platform (SSIS, SSRS, SSAS 2016+)', ""Bachelor's degree or equivalent experience"", 'Experience with data visualization tools', 'Supply Chain Management and Logistics', 'Understanding of modern data architecture and DevOps', 'Microsoft MCSA: BI Development', 'Microsoft MCSE: Data Management and Analytics, Data Platform or Business Intelligence']",2020-12-30 23:28:16
Chief Data Engineer,Two Six Labs,N/A,"Arlington, VA 22203","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Subject Matter Expertise: Providing technical guidance and expertise to a portfolio of Research & Development projects encompassing Emergent Architectures in cloud-agnostic deployments.', 'Marketing: Enhancing the visibility of the business unit projects and product offerings through publications, conferences, technical panels and other activities.', 'Shaping: Leveraging State-of-the-Art knowledge in Real-Time cloud computing technologies in collaboration with applied research communities to shape R&D opportunities alongside potential Government sponsors.', 'Capture: Identifying and Developing next generation architecture solutions leading to the capture of new R&D programs', 'A proven track record of capturing Government R&D contracts/programs', 'State-of-the-Art knowledge in one or more of the following areas: Real-Time Platform Development, Knowledge Graphs, Unstructured Text Processing, and/or Cloud-Agnostic Deployment', 'Fluency in the principles of the Heilmeier Catechism', 'Past performance as a Principal Investigator on fast paced, innovation driven, advanced technology R&D projects for Government clients', 'A body of published research', 'An advanced degree (Masters minimum, Ph D preferred) in Computer Science, Computer/Electrical Engineering, Mathematics or related technical domain', '10+ years of professional experience in a similar role', 'Strong oral and written communication skills', 'Ability to obtain and maintain a DoD/Intel security clearance']",2020-12-30 23:28:16
Apple Music - Software Data Engineer,Apple,"4.2 out of 5 from 9,978 employee ratings","New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience in designing, implementing and supporting highly scalable data systems and services in Java and/or Scala', 'Experience with Hadoop-ecosystem technologies in particular MapReduce, Spark / Spark-SQL / Spark Streaming, Hive, YARN/MR2', 'Experience building and running large-scale data pipelines, including distributed messaging such as Kafka, data ingest to/from multiple sources to feed batch and near-realtime/streaming compute components', 'Experience in data-modeling and data-architecture optimized for big data patterns, ie. warehousing concepts; efficient storage and query on HDFS; data security and privacy techniques)', 'Knowledgable about distributed storage and network resources, at the level of hosts, clusters and DCs, to troubleshoot and prevent performance issues', 'Experience with low-latency NoSQL datastores and traditional relational databases is desired']",2020-12-30 23:29:57
"Software Engineer I, Data",Wellframe,N/A,"Boston, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Work closely with product managers and scrum masters to understand the business problems.', 'Collaborate with designers to ensure we deliver the optimal user experience.', 'Work with senior engineers to validate approach.', 'Write automated tests to ensure code is of the highest quality.', 'Help monitor and maintain operational functionality of data pipelines and other jobs that fall under the ETL domain.', 'Work with our customer support team to debug and fix bugs affecting our users.', 'Work with senior engineers to develop proof of concepts and estimates for future work.', 'A B.S. or M.S. degree in Computer Science, Computer Engineering, or a closely related field of study.', 'JavaScript and React experienceProficient in SQL and a modern scripting language such as Python.', 'Development experience building ETL pipelinesMakes good trade-offs for core design decisions — knows when to stick to convention, but also when to break it.', 'Excellent communicator, comfortable explaining technical problems and plans in person and in writing.', 'Values the difference between good code and correct code, and cares about test-driven development without dogma.', 'Thrives on diverse technical challenges — our system integrates a wide variety of healthcare and other technologies.', 'Passionate about leveraging their technical skills to help improve patient care.', 'Works effectively in fast-paced, agile startup environment, and finds fulfillment delivering innovative solutions.']",2020-12-30 23:29:57
Data Engineer,Onix Networking Corp,3 out of 5 from 4 employee ratings,"Lakewood, OH 44107","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Use Google Cloud Platform to build Enterprise-grade Big Data solutions.', 'Architect and build new cloud-based data pipelines.', 'Bring together multiple data sources into a unified data warehouse.', 'Apply analytics and visualizations to customer data sets.', 'Help customers understand the right technologies for their use case.', 'Establish strategic customer relationships and become their go-to trusted advisor for Big Data needs.', 'Assist in strategic direction and planning for the growth of the Cloud Data Team', ""Bachelor's Degree in Computer Science, Data Science, or a related discipline."", '5+ years or more of enterprise-level consulting.', 'Experience with large data sets and Enterprise-grade databases (structured and unstructured).', 'Experience architecting and building data pipelines.', 'Deep understanding of the ETL (extract, transform, load) process.', 'Experience extracting data from multiple sources via APIs and scripting.', 'Experience transforming data through field mapping, programmatic rulesets, and data integrity checking.', 'Able to expertly convey ideas and concepts to others.', 'Excellent communication skills (verbal, written, and presentation)', 'Creative problem-solving skills and the ability to design solutions not immediately apparent.', 'Ability to participate in multiple projects concurrently.', 'Customer-oriented and shows a bias for action.', 'Able to function in a highly dynamic team that moves rapidly from idea to planning to implementation.', 'Highly adaptable with the ability to learn new technologies quickly without direct oversight.', 'Google Certification - Professional Data Engineer', 'Experience with BigQuery', 'Experience with SQL (architecture and queries)', 'Experience with Tableau / other enterprise visualization and BI tools']",2020-12-30 23:29:57
Information Systems Engineer 3 (Remote Position),Mitchell International,3.5 out of 5 from 152 employee ratings,"Wayne, PA 19087","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Support maintenance of Active Directory forests', 'Support Exchange on premise and in hybrid configurations', 'Perform patching, documentation, and monitoring/alerting of Active Directory solutions', 'Perform configuration, support, documentation and monitoring/alerting of the O365 and Azure environments', 'Troubleshoot basic issues that potentially span hardware, software, network, storage to identify root cause in a highly virtualized environment', 'Participate with systems lifecycle: builds, installation, upgrades, maintenance, patching, monitoring/alerting, and documentation of server systems', 'Troubleshoot functionality and performance issues with Mitchell or 3rd-party software solutions', 'Follow established change management process to safely implement changes', 'Participate in pre-scheduled off-hours data center maintenance activities and occasional off-hours escalations', 'Work seamlessly with other system administrators and take responsibility for other tasks as assigned', 'Work with Operations staff and ensure system alerts are handled properly', 'Basic DNS management and maintenance', 'This is a remote position.', 'Minimum of 5 years of relevant Information Systems Engineer experience', 'Ability to demonstrate fundamental level experience in Active Directory required', 'Ability to research logs, services and alerts in Active Directory', 'Experience in a complex multi-forest environment with multiple Exchange organizations, O365 and Azure tenants preferred', 'Experience with Group Policy, LDAP, DNS, DHCP, and PowerShell preferred', 'Possess understanding of TCP/IP, subnets, VLANs, and packet capture analysis', 'Able to work well independently and as a team player', 'Basic troubleshooting and scripting skills', 'Excellent customer service', 'Able to work occasional off-hours for scheduled maintenance and on-call rotation', 'Experience with Windows Server administration in a highly virtualized environment (VMWare) required', 'Must possess proficient verbal and written communication skills including grammar, punctuation, and sentence structure']",2020-12-30 23:29:57
AWS Data Engineer,Syntax Systems Ltd.,N/A,"Edison, NJ 08837","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Resource on various client engagement projects to implement and deliver custom data warehousing solutions', 'Help desk, trouble ticket support for our existing data warehouse Managed Services customers', 'Minimum two years of hands-on AWS data technology experiencePython, Spark/PySpark, Glue, Redshift, S3, RDS and data movement (DMS/Kinesis)', 'Is well versed with the best practices of creating an AWS Well-Architected Environment with the Analytics Lens', 'AWS Certified Cloud Practitioner (Preferred, not required)', 'AWS Data Analytics Specialty Certification (Preferred, not required)', 'Possesses fantastic troubleshooting skills and ability to systematically break down problems to resolve issues and reach solutions', 'Prolific documentation author', 'Accountable to drive deliverables towards completion', 'Possesses an ethos of always striving for improvement and growth', 'Exposure to cloud-based and SaaS data warehouse solutions', 'Experience with JD Edwards and SAP as a data source is a plus, but not required', 'Must possess an ethos of always striving for improvement and growth, and desire to flourish in an engaging, creative, hard-working, fun-loving corporate culture environment!', 'Needs to be willing to constantly reinvent who they are to learn new technologies and approaches. Must push beyond their current skillset and limitations. Must love to learn and experiment. And not be afraid to make mistakes.', 'The most successful candidates will regularly employ the RTFM, GIYF and JFGI approaches to learning and problem solving. Willingness to teach colleagues and knowledge sharing are mandatory in our work environment.']",2020-12-30 23:29:57
Geospatial Data Analyst,Juniper Unmanned,N/A,"Golden, CO 80401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Process data from LiDAR and photogrammetric sensors', 'Use processed sensor data to create quality data-derived deliverables', 'Apply your skills for data product creation to provide industry-leading data analysis and products that solve client needs', 'Manage data storage, backup, delivery, and access across IT networks', 'Recommend sensing and analytics solutions', 'Ensure our information products meet technical requirements', 'Grow your skills by learning new software and hardware platforms and stay current with known software and hardware systems', 'Communicate with Sales, Product Development, Data Processing, and Flight Operations teams to maintain effective workflows and project outcomes', 'Partner with internal and external clients to develop new products and improve existing products', 'Be willing to become an expert in a technical domain or in a client industry', 'Legally authorized to work in the United States', 'Ability to work independently and take ownership of a challenge until it is solved', 'Intermediate knowledge of geodetic datums, coordinate systems, and transformations', '2+ years of experience using current GIS/CAD platforms to provide insight to a business', '2+ years of experience working with LiDAR, RGB Imagery, Multispectral Imagery, Thermal Imagery, or other related data', 'Good interpersonal, communication, data processing, and data analysis skills', 'Intermediate level of proficiency in Global Mapper, Microstation, photogrammetric processing, LiDAR processing, point cloud classification, Microsoft Office or other industry-standard software platforms', 'Master’s degree or equivalent work experience in GIS, Remote Sensing, Land Surveying, Engineering, or a related field', 'Advanced knowledge of geodetic datums, coordinate systems, and transformations', '3+ years of experience working with LiDAR, RGB Imagery, Multispectral Imagery, Thermal Imagery, or other related data', 'Bachelor’s degree or equivalent work experience in GIS, Remote Sensing, Land Surveying, Engineering, or a related field', 'This is a full-time position.', '0%-10% US']",2020-12-30 23:29:57
Data Solutions Engineer,Royal Caribbean Cruises Ltd.,"4.2 out of 5 from 2,186 employee ratings","Miami, FL 33132","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create, build, and maintain data pipelines from disparate sources that meet functional / non-functional business requirements', 'Create, maintain and reuse existing ETL processes, employing a variety of data integration and data preparation tools', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics', 'Work with stakeholders including Product, Data and Business teams to assist with data-related technical issues and support their data needs', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Writes, debugs and implements moderately complex queries involving multiple tables or databases across various platform', 'Creates and maintains technical design documentation', 'Participates in requirements gathering', 'Collaborates with the Enterprise Architecture team to ensure alignment on data standards and processes', 'Highly analytical and interested in data visualization', 'Work with data and analytics experts to strive for greater functionality in data systems', 'Position requires on-call and off-hours support', 'Bachelor of Science in Computer Sciences, Information Technology or equivalent', '3+ years of experience in a data/cloud engineering role', '3+ years of experience in Data Warehouse design and data modeling patterns (relational and dimensional).', '3+ years of experience with ETL tool development such as Informatica or Talend or ADF', '3+ years of cloud experience with Azure or AWS', 'Working knowledge and experience ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata and workload management', 'Working knowledge and experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies. These should include ETL/ELT, data replication/CDC, message-oriented data movement, API design and access and upcoming data ingestion and integration technologies such as stream data integration and data virtualization', 'Working knowledge and experience in performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Working knowledge and experience with programming languages including SQL, PL/SQL, T-SQL', 'Proficient with technologies such as Informatica, Talend, ADF, etc...', 'Experience with relational SQL and NoSQL databases', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Experience with cloud services/providers: AWS, Azure, etc.', 'Experience with a scripting language: Python, R, Java, Scala, etc.', 'Proven ability to collaborate with technical peers', 'Capable of working independently and as part of a team.', 'Demonstrate a certain degree of creativity with analytical and problem-solving skills', 'Strong with methodologies, tools, best practices and processes within specific area of responsibility']",2020-12-30 23:29:57
Data Policy Analyst (Supervising Associate),Ernst & Young,"4 out of 5 from 7,638 employee ratings",United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Support the development and maintenance of data policy frameworks in multiple jurisdictions, liaising with local Policy Groups at the global, area and local level, including documenting solution requirements from Policy Groups to other teams with the DO.', 'Coordinating requirements from solution delivery teams and tracking dependencies as it pertains to data policies roll-out.', 'Facilitating technology implementation of requirements and Policy Group reviews of outputs.', 'Conduct initial research of internal and external regulatory and data policy decisions and guidelines', 'Contribute to the creation and maintenance processes required by Policy Groups', 'Manage and be responsible for databases/repository of key meta-data/attributes and data policies', 'Coordinate with other teams within the Data Office and facilitate implementation from a technical perspective all aspects of data policies framework', 'Support the implementation of an ongoing communication plan to educate key stakeholders on data policy framework', 'This position exercises independent decision-making skills and will respond to or process escalated matters or sensitive transactions. The Data Policy Analyst will have the breadth and depth of knowledge/experience to appropriately determine when to escalate issues that require additional review by more senior team members to obtain the correct answer or solution.', 'Position requires the ability to apply considered and measured judgment to projects and initiatives. Will be required to reference existing policies and leverage his/her own knowledge and experience to review situations, to investigate matters by consulting and through inquiry of the stakeholders and to propose solutions to issues.', 'Ability to manage multiple workstreams of dependencies and properly delegate and take responsibility of tasks', 'Able to effectively coordinates work with peers and ensures successful delivery', 'Able to works independently with guidance and regular alignment with Data Policies leadership', 'Recognizes and manages risks in area of responsibility, ability to recommend appropriate mitigation plans and communicate these to avoid surprises with key stakeholders', 'Interest in obtaining knowledge of emerging data policy requirements (e.g. GDPR, CCPA)', 'Creative problem-solving skills that help identify practical solutions to complex, nuanced data policy issues from a multi-disciplinary perspective', 'Knowledge or background in data governance or data life cycle management', 'Strong Project Management skills; Ability to effectively coordinate and participate in workshops to gather requirements and gain consensus', 'Strong analytical skills, good knowledge of policy processes and strong team leadership', 'Ability to constructively challenge requirements and current state to increase overall value to the organization', 'Flexibility to adjust to multiple demands, shifting priorities, ambiguity and rapid change', 'Ability to rapidly comprehend the changes to key business processes and the impact on the overall data policy framework', 'Ability to understand and integrate cultural differences and motives and to lead virtual cross-cultural, cross-border teams', 'English language skills - excellent written and verbal communication', 'An overall understanding of Policy Group responsibilities and activities (e.g. role of legal, data protection, risk management)', 'Ability to work and team with a multitude of different people - including business customers, Functional managers, project managers and IT engineers - to balance demands', 'Self-starter attitude, with ability to independently lead workstreams that contribute to group objectives Ability to identify, prioritize and weigh different options and to recommend a value-add solution', 'Ability to stay focused on identified priorities while balancing multiple objectives', 'A degree in Business, Computer Science, Law or STEM related discipline or equivalent work experience.', '5+ years total work experience and experience in Data governance, Quality, Risk Management processes preferred but not required. Additionally:', 'Minimum of 3 years of hands-on information governance or policy design and implementation.', 'Minimum of 2 engaged within a multi-cultural, multi-disciplined, globally dispersed team', 'Any EA, Data Governance, Applicable Vendor or Industry certification is preferred but not mandatory', 'Minimal travel, less than 10%.', 'Long hours may occasionally be required to meet project commitments and/or preparing materials for clients (internal and external). Overtime may be required as per country overtime policy', 'Flexibility in working hours to accommodate workload and multiple time zones, as needed']",2020-12-30 23:29:57
Data Engineer,"Darwill, Inc.",N/A,"Oakbrook Terrace, IL 60181","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build and maintain data infrastructure and manage data storage and use', 'Build data expertise and own data quality across the organization', 'Design, build and launch new data models and efficient data pipelines (including ETL processes) in production', 'Partner with cross-functional teams of Account Executives, Data Scientists, and Software Engineers to understand data needs and deliver on those needs', 'Build and maintain reporting dashboards using BI tools like Tableau', 'Support data processing and reporting at scale', 'Triage mission-critical issues and drive to resolution', 'Support existing processes running in production', 'Master of Science in Computer Science, Mathematics, or other technical field', '3+ years’ experience working in SQL and relational database management systems', '3+ years’ experience with dimensional data modeling, schema design, and data warehousing', '2+ years’ experience in ETL design, implementation, and maintenance', '2+ years’ experience with AWS', 'Ability to write well-abstracted, reusable code', 'Ability to analyze data to identify deliverables, gaps, and inconsistencies', 'Ability to decompose and solve data problems and to find answers on own', 'Very strong communication skills and ability to work collaboratively with peers and stakeholders', 'Very strong work management skills', 'Experience in a Direct Marketing/Measurement company', 'Experience with data analytics', 'Experience with python', 'Experience with AWS']",2020-12-30 23:29:57
"Research Engineer, Creative AI (University Grad)",Facebook,4.2 out of 5 from 602 employee ratings,"Pittsburgh, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop highly scalable algorithms based on state-of-the-art machine learning and neural network methodologies.', 'Collaborate with Facebook AI Research (FAIR) scientists to facilitate research that enables learning the semantics of data (images, video, text, audio, and other modalities).', 'Apply knowledge of relevant research domains along with expert coding skills to platform and framework development projects.', 'Adapt machine learning and neural network algorithms and architectures to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).', 'Experience in developing and debugging in C/C++ and/or Python.', 'Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment.']",2020-12-30 23:29:57
Senior Data Engineer,Cubesmart,3.3 out of 5 from 414 employee ratings,"Malvern, PA 19355","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Collaborate with the Application Development team lead to carry out the technical development plans required to implement system changes and enable the capabilities outlined in the business requirements', 'Partner and collaborate with Revenue Management and Data Scientist teams in support of their systems, data, and reporting/analytics requirements', 'Perform the technical development tasks to support, maintain, and enhance CubeSmart’s proprietary pricing management system', 'Assist in the technical design and development of enterprise applications', 'Ensure all code written is robust, secure, efficient, and meets the requirements as outlined', 'Ensure that all coding activities are in alignment with the technical framework and enterprise technology plan as outline by the established architecture', 'Participate in code reviews and unit testing of all completed development items for quality, performance, and successful delivery of the desired capabilities', 'Responsible for adhering to the Software Development Life Cycle (SDLC)', 'Participate in code deployments of all assigned work through each step in the software development life cycle', 'Participate in all aspects of the Agile development methodology including daily standups, sprint planning sessions, code reviews and change management review sessions', 'Utilization of task management system to ensure all work is tracked in accordance with software development methodologies', 'Evaluate emerging machine learning techniques, technologies and methodologies to continue to support and evolve CubeSmart’s analytics and data science capabilities', 'Performs application performance testing, tuning and bug fixes as directed', '5-8 years’ experience in data engineering and/or data analytics, supporting data scientist team(s)', 'Bachelor Degree in Computer Science, Engineering, or equivalent related technical field', 'Experience with all aspects of the software development life cycle and Agile software development methodologies', 'Proven experience in advanced data-development skills involving analyzing, writing and modifying T-SQL queries and scripting against MS-SQL databases', 'Experience with SQL Server database tools, including SQL Server Integration Services', 'Experience in Python is required', 'Proven experience analyzing, developing and modifying machine learning algorithms', 'Working knowledge and experience with R is strongly preferred', 'Knowledge of object-oriented programming and design patterns', 'Working knowledge and experience in source code control and management using GIT or other equivalents is preferred', 'Experience with Microsoft Azure cloud development', 'Proven technical project management skills, preferably in a software product development environment', 'Strong oral, written and interpersonal communication skills. Ability to effectively convey complex information', 'Service orientation towards business-focused 24×7 support and service mentality.', 'Collaborative individual who creates open channels of communications and encourages technical dialogue and promotes technical bench across the department.', 'Well-developed analytical and problem-solving abilities', 'Ability to work on multiple tasks and projects at once, with the ability to properly prioritize one’s own work', 'Demonstrated ability to understand business drivers and design systems, processes, analytics and algorithms to support the business requirements']",2020-12-30 23:29:57
Data Engineer,AllianceBernstein,3.5 out of 5 from 217 employee ratings,"Nashville, TN","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Automation of data ingestion supporting various sources and formats both external and internal.', 'Implementing a quality control framework for ensuring data consistency.', 'Cataloging new data sets to facilitate data discovery, lineage, and self-service.', 'Building business intelligence dashboards to provide data insights.', 'Assist with ad-hoc data and research requests from the investment team.', 'Provide support for overnight jobs.', 'Learning the equity investment business and engaging directly with end users.', 'Automating complex data loads and pipelines.', 'Onboard alternative datasets including learning how to web scrape.', 'Best practices managing large data sets.', 'Building technical skills including SQL, Python, and PowerBI.', 'Applying cloud based technologies including data lakes and data pipelines.', 'BS in Computer Science/Engineering, Finance, Mathematics/Statistics or a related major', '2-3 years programing in SQL with experience in relational schema designs and optimizing query performance', '1-2 years using Python or another object oriented language (C#, Java)', 'ETL experience is a strong plus', 'Working with NoSQL is a strong plus', 'Building visualizations using Tableau, Qlik, or PowerBI is a strong plus', 'Solid analytical and technical skills', 'Candidate must be willing to take ownership of projects and show strong client commitment', 'Must demonstrate good communication skills and be comfortable working closely with business users', 'Self starter as well as a good team player', 'A strong desire to document and share work done to aid in long term support', 'Experience working in the financial industry or knowledge of basic financial statement concepts', 'Azure experience building data pipelines', 'Experience using Airflow']",2020-12-30 23:29:57
Junior Backend Developer,"Picwell, Inc.",N/A,"Philadelphia, PA 19103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Build and maintain Picwell’s API products.', 'Work with frontend developers to expose features to our consumer-facing UI.', 'Collaborate with data scientists to maintain and improve our core recommendation engine and modeling framework.', 'Improve the service infrastructure by working with site reliability engineers.', 'Enjoy writing and revising code', 'Enjoy reasoning about better ways to do things', 'Have experience with version control systems (we use git)', 'Have good verbal and written communication skills', 'Be curious to ask good questions', 'Be eager and able to learn new things', 'Degree in computer science or software engineering', 'Prior work experience (2 years or more), including interns and co-ops', 'Experience developing and maintaining APIs', 'Programming experience in Python', 'Experience in AWS', 'Experience with SQL and NoSQL storage systems', 'Experience in insurance industry', '401(k)', 'Dental insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Paid time off', 'Retirement plan', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'Software Engineering: 2 years (Preferred)', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.Picwell.com', 'Only full-time employees eligible', 'Remote interview process', 'Virtual meetings']",2020-12-30 23:29:57
Data Engineer - TS/SCI with CI Polygraph,General Dynamics Information Technology,"3.8 out of 5 from 7,499 employee ratings","Annapolis Junction, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Performs data analysis interpretation and management duties. Develops rules and methodologies for data collection and analysis', 'Researches and evaluates new concepts and processes to improve performance.', 'Analyzes cross-functional problem sets, identifies root causes and resolves issues.', 'Assists more junior level technicians, specialists, and managers in their activities.', 'Works individually, actively participates on integrated teams, and leads multiple tasks, projects or teams.', 'Oversees and monitors performance, and when required, takes steps to resolve issues.', 'Directs multiple teams through to project completion.', 'Provides guidance and direction to lower level technicians, specialists, and managers.', 'DoD 8570 compliance or information assurance certification.', 'Active TS/SCI clearance and ability to obtain and maintain a CI polygraph.', 'High School Degree + 10 years of experience', 'Associate Degree + 8 years of experience', 'Bachelor Degree + 6 years of experience', 'Master Degree + 4 years of experience', 'PhD + 2 years of experience']",2020-12-30 23:29:57
Data Engineer(Big Data),Blue5Green LLC,N/A,"Baton Rouge, LA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:29:57
Senior Data Engineer,Cubesmart,3.3 out of 5 from 414 employee ratings,"Malvern, PA 19355","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Collaborate with the Application Development team lead to carry out the technical development plans required to implement system changes and enable the capabilities outlined in the business requirements', 'Partner and collaborate with Revenue Management and Data Scientist teams in support of their systems, data, and reporting/analytics requirements', 'Perform the technical development tasks to support, maintain, and enhance CubeSmart’s proprietary pricing management system', 'Assist in the technical design and development of enterprise applications', 'Ensure all code written is robust, secure, efficient, and meets the requirements as outlined', 'Ensure that all coding activities are in alignment with the technical framework and enterprise technology plan as outline by the established architecture', 'Participate in code reviews and unit testing of all completed development items for quality, performance, and successful delivery of the desired capabilities', 'Responsible for adhering to the Software Development Life Cycle (SDLC)', 'Participate in code deployments of all assigned work through each step in the software development life cycle', 'Participate in all aspects of the Agile development methodology including daily standups, sprint planning sessions, code reviews and change management review sessions', 'Utilization of task management system to ensure all work is tracked in accordance with software development methodologies', 'Evaluate emerging machine learning techniques, technologies and methodologies to continue to support and evolve CubeSmart’s analytics and data science capabilities', 'Performs application performance testing, tuning and bug fixes as directed', '5-8 years’ experience in data engineering and/or data analytics, supporting data scientist team(s)', 'Bachelor Degree in Computer Science, Engineering, or equivalent related technical field', 'Experience with all aspects of the software development life cycle and Agile software development methodologies', 'Proven experience in advanced data-development skills involving analyzing, writing and modifying T-SQL queries and scripting against MS-SQL databases', 'Experience with SQL Server database tools, including SQL Server Integration Services', 'Experience in Python is required', 'Proven experience analyzing, developing and modifying machine learning algorithms', 'Working knowledge and experience with R is strongly preferred', 'Knowledge of object-oriented programming and design patterns', 'Working knowledge and experience in source code control and management using GIT or other equivalents is preferred', 'Experience with Microsoft Azure cloud development', 'Proven technical project management skills, preferably in a software product development environment', 'Strong oral, written and interpersonal communication skills. Ability to effectively convey complex information', 'Service orientation towards business-focused 24×7 support and service mentality.', 'Collaborative individual who creates open channels of communications and encourages technical dialogue and promotes technical bench across the department.', 'Well-developed analytical and problem-solving abilities', 'Ability to work on multiple tasks and projects at once, with the ability to properly prioritize one’s own work', 'Demonstrated ability to understand business drivers and design systems, processes, analytics and algorithms to support the business requirements']",2020-12-30 23:32:41
Data Engineer,AllianceBernstein,3.5 out of 5 from 217 employee ratings,"Nashville, TN","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Automation of data ingestion supporting various sources and formats both external and internal.', 'Implementing a quality control framework for ensuring data consistency.', 'Cataloging new data sets to facilitate data discovery, lineage, and self-service.', 'Building business intelligence dashboards to provide data insights.', 'Assist with ad-hoc data and research requests from the investment team.', 'Provide support for overnight jobs.', 'Learning the equity investment business and engaging directly with end users.', 'Automating complex data loads and pipelines.', 'Onboard alternative datasets including learning how to web scrape.', 'Best practices managing large data sets.', 'Building technical skills including SQL, Python, and PowerBI.', 'Applying cloud based technologies including data lakes and data pipelines.', 'BS in Computer Science/Engineering, Finance, Mathematics/Statistics or a related major', '2-3 years programing in SQL with experience in relational schema designs and optimizing query performance', '1-2 years using Python or another object oriented language (C#, Java)', 'ETL experience is a strong plus', 'Working with NoSQL is a strong plus', 'Building visualizations using Tableau, Qlik, or PowerBI is a strong plus', 'Solid analytical and technical skills', 'Candidate must be willing to take ownership of projects and show strong client commitment', 'Must demonstrate good communication skills and be comfortable working closely with business users', 'Self starter as well as a good team player', 'A strong desire to document and share work done to aid in long term support', 'Experience working in the financial industry or knowledge of basic financial statement concepts', 'Azure experience building data pipelines', 'Experience using Airflow']",2020-12-30 23:32:41
Junior Backend Developer,"Picwell, Inc.",N/A,"Philadelphia, PA 19103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Build and maintain Picwell’s API products.', 'Work with frontend developers to expose features to our consumer-facing UI.', 'Collaborate with data scientists to maintain and improve our core recommendation engine and modeling framework.', 'Improve the service infrastructure by working with site reliability engineers.', 'Enjoy writing and revising code', 'Enjoy reasoning about better ways to do things', 'Have experience with version control systems (we use git)', 'Have good verbal and written communication skills', 'Be curious to ask good questions', 'Be eager and able to learn new things', 'Degree in computer science or software engineering', 'Prior work experience (2 years or more), including interns and co-ops', 'Experience developing and maintaining APIs', 'Programming experience in Python', 'Experience in AWS', 'Experience with SQL and NoSQL storage systems', 'Experience in insurance industry', '401(k)', 'Dental insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Paid time off', 'Retirement plan', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'Software Engineering: 2 years (Preferred)', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.Picwell.com', 'Only full-time employees eligible', 'Remote interview process', 'Virtual meetings']",2020-12-30 23:32:41
Data Engineer - TS/SCI with CI Polygraph,General Dynamics Information Technology,"3.8 out of 5 from 7,499 employee ratings","Annapolis Junction, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Performs data analysis interpretation and management duties. Develops rules and methodologies for data collection and analysis', 'Researches and evaluates new concepts and processes to improve performance.', 'Analyzes cross-functional problem sets, identifies root causes and resolves issues.', 'Assists more junior level technicians, specialists, and managers in their activities.', 'Works individually, actively participates on integrated teams, and leads multiple tasks, projects or teams.', 'Oversees and monitors performance, and when required, takes steps to resolve issues.', 'Directs multiple teams through to project completion.', 'Provides guidance and direction to lower level technicians, specialists, and managers.', 'DoD 8570 compliance or information assurance certification.', 'Active TS/SCI clearance and ability to obtain and maintain a CI polygraph.', 'High School Degree + 10 years of experience', 'Associate Degree + 8 years of experience', 'Bachelor Degree + 6 years of experience', 'Master Degree + 4 years of experience', 'PhD + 2 years of experience']",2020-12-30 23:32:41
Data Engineer(Big Data),Blue5Green LLC,N/A,"Baton Rouge, LA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:32:41
Engineer II,PPG Industries,"3.4 out of 5 from 2,159 employee ratings","Allison Park, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Formulates and develops new and improved products, innovative ideas, processes, protocols, and techniques to support the deliverables of', 'The Additive Manufacturing Group', 'Carries out research on assigned technology, concepts, technical opportunities,', 'Identifies and/or evaluates materials or technologies to assess technical performance', 'Uses experimental designs, researches, analyzes and interprets data to determine feasibility/efficacy of proposed solutions', 'Is a technical and problem solving resource for rapidly changing requirements', 'Recommends product modifications, equipment designs, and process improvements', 'Implements, develops and/or improves test methodologies and/or processes', 'Develops, identifies, and modifies new and existing formulations and technologies for improved performance', 'Establishes new methods for evaluating products', 'Engineers new printing designs and protocols to meet part requirements according to technical drawings', 'Interacts independently with contract/full-time formulation employees in team-like manner', 'Documents projects through electronic lab notebook, technology transfer documentation, and project reports', 'BS Chemical Engineering', 'Excellent computer and communication skills', 'Ability to interpret CAD drawings, technical drawings, and overall CAD skills is a plus', 'Ability to work independently for the Additive Manufacturing Group', 'Mechanical ability with equipment and processes', 'Experience with experimental design (DOE), formulation, and problem solving is desired']",2020-12-30 23:32:41
Drive Testing,Verveba telecom,3.8 out of 5 from 32 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:32:41
"Data Engineer, Core Automation Services",Tesla,"3.5 out of 5 from 4,572 employee ratings","Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Employ and improve industry-leading, scalable, distributed open-source technologies', 'Build back-end systems from scratch that are capable of handling trillion+ events per day', 'Facilitate operation of highly-available distributed systems at scale and across multiple locations', 'Facilitate others in deploying, operating, and extending upon your clean, tested code', 'Help define a platform that is highly leveraged, multi-tenant, and self-serviced', 'Work with data engineers and data scientists to drive efficient solutions from the platform', 'Help define the data story and enable data-driven solutions at Tesla, both technically and culturally', 'Strong programming fundamentals, particularly in data structures, concurrency, Go, Python, and Java', 'Deep understanding of a complex distributed system, such as Kafka, Spark, HBase, ElasticSearch', 'Have built and optimized highly available, scalable, distributed back-end services', 'Ability to break down and deeply understand complex problems and communicate complex matters efficiently', 'Strong problem solving skills, optimizing for the simplest, most robust yet practical solutions', 'Reliable, dependable, trustworthy, participating team member', 'Smart but humble, with a bias for action']",2020-12-30 23:32:41
HID Algorithm Engineer - Data Focus,Apple,"4.2 out of 5 from 9,978 employee ratings","San Diego, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Expertise in Python programming (functional and object-oriented)', 'Strong foundation in statistical analysis', 'Able to develop optimized pipelines for data acquisition, pruning and preprocessing; insightful data and performance visualizations and iterating over algorithm variants', 'Some exposure to developing infrastructure for large-scale data processing and annotation.']",2020-12-30 23:32:41
Java Cloud Data Engineer - 12+ Months - Remote Opportunity,TMS LLC,N/A,"Richmond, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:32:41
Informatica Enterprise Data Catalog (EDC) Engineer,Numentica LLC,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Informatica EDC: 5 years (Preferred)"", 'Execute standard on boarding of technical and business metadata into the Informatica EDC and Axon environments, ensuring the population of data lineage and linkage between the technical and business metadata.', 'Participate in the development and implementation of enterprise metadata standards, guidelines, and processes to ensure quality metadata and support for ongoing data governance.', 'Providing administration support for Informatica EDC/Axon and in future other data governance related products (MDM/ Data Quality) which includes installation, configuration, upgrades and business continuity support.', 'Facilitate discussion with data stakeholders on data governance processes, and translate those requirements into Axon workflows.', 'Participate in Metadata Management scrum team to partner in work efforts, provide data management experience, including an understanding of concepts, practices, procedures, and tools providing strong analytical, innovative and creative problem-solving', 'Participate in training sessions for business and technology partners covering enterprise metadata standards, guidelines, and processes', 'Participate in product evaluations for future data governance initiatives.', 'Minimum of 5-6+ years of enterprise data integration and management experience working with Datawarehouse technologies and data governance solutions (Data Catalog, MDM and Data Quality)', 'Must have 5+ years of hands on Informatica Data Governance (Axon), EDC, Data Quality, and MDM experience, including executing at least 2 large Data Governance, Quality and MDM projects from inception to production, working as technology expert.', 'Must have 5+ years of hands on developer/designer experience as well as experience working with Informatica’s Data Governance, MDM, and Data Quality product', 'Must have 5+ years of practical experience configuring EDC and Axon, including business glossaries, dashboards, policies, search, Axon maps', 'Experience in data quality tools, including data profiling, cleansing and identity resolution.', 'Experience defining solution and technical architectures for new solutions, including experience driving project team execution from an architectural standpoint across the complete project life cycle within defined and finite time frames.', 'Must be a team player as this role requires working with multiple teams.', 'Excellent communication, presentation, interpersonal and organizational skills', 'Informatica Certification is highly desirable', '8 hour shift', ""Bachelor's (Preferred)"", 'Informatica EDC: 5 years (Preferred)', 'Fully Remote', 'Temporarily due to COVID-19']",2020-12-30 23:32:41
DMP Data Engineer,eTek IT Service | Savvysol,N/A,"Blue Ash, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Azure: 4 years (Preferred)DevOps: 4 years (Preferred)"", 'Leverages enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses', 'Guides high level data architecture design (functional, non-functional) and ensures teams adhere to data architecture standards', 'Develops information processes for data acquisition, data transformation, data migration, data verification, data modeling, and data mining', 'Accountable for cost viability and technical estimation of data platform usage', 'Designs data solutions for data distributions and partitions, scalability, disaster recovery and high availability', 'Designs security for data policies and standards', 'Monitors and optimizes data solutions', 'Actively governs and automates standard data architecture patterns and blueprints', 'Partners with architecture, security, infrastructure, and application teams to design and implement the automation of data, data platforms, and tools', 'Creates and updates automation to eliminate routine management processes', 'Articulates the need for scalability and understand the importance of improving quality through testing', '5+ years of hands-on experience with data platforms', 'Experience in designing data solutions in Azure including data distributions and partitions, scalability, disaster recovery and high availability', 'Experience in monitoring and optimizing data solutions in Azure including using Azure Monitor', 'Experience in implementing data solutions in Azure including Azure SQL, Azure Synapse, Cosmos DB, Databricks, ADLS, Blob Storage, ADF, Azure Stream Analytics', 'Experience in designing security for data policies and standards', 'In depth understanding and proficiency in automation of cloud platforms and data platforms', 'Expertise in on-prem and cloud database automation and platform automation with Azure', 'Proficiency with cloud automation tooling such as Ansible and Terraform', 'Proficiency with DevOps and CI/CD methodologies and tools for automated infrastructure code test, integration, deployment, and assurance', 'Proficiency with Languages such as Ruby, bash, Python or Go', 'Experience with Software Development and automation methodologies', 'Experience with data security best practices', 'Strong problem-solving skills', 'Strong collaboration skills and excellent verbal and written communication skills', 'Leverages enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses', 'Guides high level data architecture design (functional, non-functional) and ensures teams adhere to data architecture standards', 'Develops information processes for data acquisition, data transformation, data migration, data verification, data modeling, and data mining', 'Accountable for cost viability and technical estimation of data platform usage', 'Designs data solutions for data distributions and partitions, scalability, disaster recovery and high availability', 'Designs security for data policies and standards', 'Monitors and optimizes data solutions', 'Actively governs and automates standard data architecture patterns and blueprints', 'Partners with architecture, security, infrastructure, and application teams to design and implement the automation of data, data platforms, and tools', 'Creates and updates automation to eliminate routine management processes', 'Articulates the need for scalability and understand the importance of improving quality through testing', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Azure: 4 years (Preferred)', 'DevOps: 4 years (Preferred)', 'Data Engineer: 5 years (Preferred)', 'DMP: 3 years (Preferred)', '7 - 11 months', 'Possible', 'One location', 'Temporarily due to COVID-19']",2020-12-30 23:32:41
Data Engineer,Zero Mass Water,3 out of 5 from 6 employee ratings,"Scottsdale, AZ 85257","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop custom systems and tools, including mobile and web applications, to support the global team and business objectives.', 'Use your extensive DevOps experience to own an entire engineering problem rather than a single pice of code', 'Perform extensive data validation and quality assurance analysis within large datasets.', 'Build proactive data validation automation to catch data integrity issues.', 'Build and flesh out data models for use in regular and/or automated reporting and analysis.', 'Diagnose data-related bugs and ensure they are resolved in a timely manner.', 'Develop with a security lens and actively look for vulnerabilities in development and review.', 'Convey your work and results to a wide variety of internal and external customers, both technical and non-technical.', 'Evaluate operations for inefficiencies and identify areas where you can create, automate, and develop tools (SQL-based or otherwise).', 'Create project proposals and designs that have considerable business and/or impact or touch multiple systems. Create technical designs that are clear, well thought out, and consider dependencies, failure states, maintainability, testability, and ease of support.', 'Utilize business context knowledge to design architectural decisions, including scalability, reliability and performance of systems.', 'Work closely with individuals and department leaders to document business reporting needs and to provide meaningful data analysis, enabling sound financial and business decisions.', 'Collaborate with product owners, product managers and the business on feature development, as well as mentoring other engineers and advising managers.', 'Thoroughly understand the business model and identify opportunities to simplify product and technical design.', 'Provide thoughtful strategies in effectively resolving problems and issues. Take ownership of incidents in your domain and provide assistance to others on resolving incidents.', ""Understand data team's testing approach and use quality metrics to identify gaps. Recommend solutions that are in accordance with accepted testing frameworks and the testing pyramid. Develop elegant, resilient, tested, and secure applications."", 'Become aware of the organization’s monitoring philosophy and skilled with the monitoring tools.', 'Actively participate in all phases of the development life-cycle of our applications including architecture, implementation, testing and maintenance.', 'Organize and lead meetings with business and operational data owners.', 'Build tabular and/or visualization reports as needed with live data views and dashboards.', 'Identify opportunities to improve data and business processes utilizing JAVA, Python, R, C#, or other applicable languages.', 'Help form data management and governance processes within the data science team.', 'B.S preferred in Computer Science with 7+ years of related professional experience developing and implementing world class systems, mobile and web applications.', '7+ years professional working experience in web and distributed applications/ systems development and implementation.', '5+ years professional working experience in mobile applications development and implementation for Android and iOS.', '5+ years working experience with microservices and REST APIs.', '5+ years working experience in technical data analysis, data science, or data warehousing with proven business analysis experience.', '5+ years of working knowledge with API architecture, design, and development.', '5+ years with the following languages and frameworks: HTML5, CSS3, ReactJS, Javascript, XML, XSL, Node.js, Angular.js, Vue.js, Typescript, Python, Ruby, and PHP.', '5+ years working experience on DevOps tools such as Git, Jenkins, and Docker.', '5+ years working experience in developing and deploying secure web applications in linux environments within AWS or the greater cloud.', 'Extensive experience writing complex SQL, views, stored procedures, functions and triggers.', 'Strong working knowledge of enterprise database technologies, including but not limited to: SQL, PostgreSQL, MySQL, SQLite, and Cassandra.', 'Minimum of 10 years experience with web applications development and implementation for Android and iOS.', 'A keen interest and drive to continuously learn new techniques and technologies', 'Self-driven, self-sufficient, actively looks for ways to contribute, and knows how to get things done', 'Expert in using Test Frameworks and good understanding of test-driven development concepts and supportive.', 'Expert knowledge of object-oriented and functional programming concepts.', 'Experience in a major server-less development, including infrastructure.', 'Depth and breadth of knowledge across multiple software engineering disciplines.', 'Extensive experience with data pipeline and presentation technologies, including but not limited to Dataiku, Metabase, DataStudio, PowerBI, and Tableau.', 'Outstanding communication skills, both written and verbal, with a strong passion for providing outstanding customer service; address individual and group communications clearly and effectively.', 'Skilled with technical writing and process-driven performance.', 'Willingness and ability to work nights and/or weekends as needed to meet deadlines and deliver on company goals.', 'Excellent presentation and Microsoft Office skills.', 'Fearlessly driven – results-oriented, self-starter, self-educator, and have the ability to navigate dependencies and roadblocks with grace.', 'Passionate about data and analyzing business needs.', 'Be a passionate problem solver - breaking down problems and developing analytical insights.', 'Ability to work independently and with team members to understand database structure and business processes.', 'Strong ability to troubleshoot and resolve data issues.', 'Reviews tasks critically and ensures they are appropriately prioritized and sized for continuous integration and incremental delivery. Anticipates and communicates blockers, delays before they require escalation.', 'Continuously strive for a deeper understanding of our business drivers.', 'Determined to get problems resolved and complete tasks with timeliness and efficiency.', 'Ability to remain organized with multiple demands of your time and attention.', 'Competitive medical, dental, and vision plans', 'Paid Time Off (PTO) and 13 paid holidays', 'Employer-paid short-term disability and long-term disability plans', 'Employer-paid life insurance']",2020-12-30 23:32:41
Data Analyst,Updater,N/A,"New York, NY 10001","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Partner with our Product team to deliver a holistic performance measurement suite for the launch of a major new product; design and evaluate optimization-focused A/B tests for that product after launch.', 'Collaborate with our Manager of Client Success to design and build new data models which allow for increased insight into client health and churn risk.', 'Leverage data to define key user cohorts to be reached out to for product design user interviews.', 'Work with fellow Data team members to deploy a company-wide data education course to help all Updateers bring data to bear on their toughest business problems.', 'And many more impactful initiatives!', 'Empathy: you strive to see the world from your customers’ point of view in order to anticipate their needs - bonus points for being able to incept stakeholders before they themselves know what they need.', 'Humility: you have an opinion, but aren’t afraid to be proven wrong, and are open to suggestions on what tool or technique is best to most efficiently solve a problem.', 'Strong Communication: you’re as comfortable talking with our Senior API Engineer as you are with our Lead Product Manager.', 'Comfortable with Ambiguity: you excel at whittling a project down to a question that can be answered by hard data - and then moving mountains to answer it!', '2+ years as an analyst in a fast-paced work environment; proven ability to execute on impactful data modeling, reporting, and insights generation initiatives.', 'Expert SQL skills.', 'Basic knowledge of statistics.', 'Experience with modern reporting tools (Looker, Metabase, Superset, etc).', 'Experience implementing a data education program.']",2020-12-30 23:32:41
Data Engineer,Red Ventures,3.2 out of 5 from 690 employee ratings,"Charlotte, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Working with a cross functional team of architects, engineers, analysts and scientists to understand business requirements.', 'Design and build data pipelines from various sources to data warehouse using batch or incremental loading strategies utilizing cutting edge cloud technologies.', 'Conceptualizing and generating infrastructure that allows data to be accessed and analyzed effectively.', 'Documenting database design including data modeling, metadata and process flow for business integrations.', 'Documenting technical ETL specifications for a data warehouse. Perform periodic code reviews and test plans to ensure data quality and integrity.', '4+ years of experience in the data warehouse space.', '2+ years of experience working on AWS (Kinesis / S3 / RedShift).', '2+ years of experience working on Spark (RDDs / Data Frames / Dataset API) to query and perform data manipulation', 'Has experience with GitHub and CICD processes.', 'Has experience working on Orchestration (AWS Step Function / Airflow)', 'Has experience with ANSI SQL relational database (Oracle / Teradata / Hana)', 'Excellent understanding of development processes and agile methodologies', 'Strong analytical and interpersonal skills', 'Enthusiastic, highly motivated and ability to learn quick', 'Ability to work through ambiguity in a fast-paced, dynamically changing business environment', 'Ability to manage multiple tasks at the same time with minimum supervision']",2020-12-30 23:32:41
Data Solutions Engineer,Royal Caribbean Cruises Ltd.,"4.2 out of 5 from 2,186 employee ratings","Miami, FL 33132","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create, build, and maintain data pipelines from disparate sources that meet functional / non-functional business requirements', 'Create, maintain and reuse existing ETL processes, employing a variety of data integration and data preparation tools', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics', 'Work with stakeholders including Product, Data and Business teams to assist with data-related technical issues and support their data needs', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Writes, debugs and implements moderately complex queries involving multiple tables or databases across various platform', 'Creates and maintains technical design documentation', 'Participates in requirements gathering', 'Collaborates with the Enterprise Architecture team to ensure alignment on data standards and processes', 'Highly analytical and interested in data visualization', 'Work with data and analytics experts to strive for greater functionality in data systems', 'Position requires on-call and off-hours support', 'Bachelor of Science in Computer Sciences, Information Technology or equivalent', '3+ years of experience in a data/cloud engineering role', '3+ years of experience in Data Warehouse design and data modeling patterns (relational and dimensional).', '3+ years of experience with ETL tool development such as Informatica or Talend or ADF', '3+ years of cloud experience with Azure or AWS', 'Working knowledge and experience ability to design, build and manage data pipelines for data structures encompassing data transformation, data models, schemas, metadata and workload management', 'Working knowledge and experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies. These should include ETL/ELT, data replication/CDC, message-oriented data movement, API design and access and upcoming data ingestion and integration technologies such as stream data integration and data virtualization', 'Working knowledge and experience in performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Working knowledge and experience with programming languages including SQL, PL/SQL, T-SQL', 'Proficient with technologies such as Informatica, Talend, ADF, etc...', 'Experience with relational SQL and NoSQL databases', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Experience with cloud services/providers: AWS, Azure, etc.', 'Experience with a scripting language: Python, R, Java, Scala, etc.', 'Proven ability to collaborate with technical peers', 'Capable of working independently and as part of a team.', 'Demonstrate a certain degree of creativity with analytical and problem-solving skills', 'Strong with methodologies, tools, best practices and processes within specific area of responsibility']",2020-12-30 23:34:28
Data Policy Analyst (Supervising Associate),Ernst & Young,"4 out of 5 from 7,638 employee ratings",United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Support the development and maintenance of data policy frameworks in multiple jurisdictions, liaising with local Policy Groups at the global, area and local level, including documenting solution requirements from Policy Groups to other teams with the DO.', 'Coordinating requirements from solution delivery teams and tracking dependencies as it pertains to data policies roll-out.', 'Facilitating technology implementation of requirements and Policy Group reviews of outputs.', 'Conduct initial research of internal and external regulatory and data policy decisions and guidelines', 'Contribute to the creation and maintenance processes required by Policy Groups', 'Manage and be responsible for databases/repository of key meta-data/attributes and data policies', 'Coordinate with other teams within the Data Office and facilitate implementation from a technical perspective all aspects of data policies framework', 'Support the implementation of an ongoing communication plan to educate key stakeholders on data policy framework', 'This position exercises independent decision-making skills and will respond to or process escalated matters or sensitive transactions. The Data Policy Analyst will have the breadth and depth of knowledge/experience to appropriately determine when to escalate issues that require additional review by more senior team members to obtain the correct answer or solution.', 'Position requires the ability to apply considered and measured judgment to projects and initiatives. Will be required to reference existing policies and leverage his/her own knowledge and experience to review situations, to investigate matters by consulting and through inquiry of the stakeholders and to propose solutions to issues.', 'Ability to manage multiple workstreams of dependencies and properly delegate and take responsibility of tasks', 'Able to effectively coordinates work with peers and ensures successful delivery', 'Able to works independently with guidance and regular alignment with Data Policies leadership', 'Recognizes and manages risks in area of responsibility, ability to recommend appropriate mitigation plans and communicate these to avoid surprises with key stakeholders', 'Interest in obtaining knowledge of emerging data policy requirements (e.g. GDPR, CCPA)', 'Creative problem-solving skills that help identify practical solutions to complex, nuanced data policy issues from a multi-disciplinary perspective', 'Knowledge or background in data governance or data life cycle management', 'Strong Project Management skills; Ability to effectively coordinate and participate in workshops to gather requirements and gain consensus', 'Strong analytical skills, good knowledge of policy processes and strong team leadership', 'Ability to constructively challenge requirements and current state to increase overall value to the organization', 'Flexibility to adjust to multiple demands, shifting priorities, ambiguity and rapid change', 'Ability to rapidly comprehend the changes to key business processes and the impact on the overall data policy framework', 'Ability to understand and integrate cultural differences and motives and to lead virtual cross-cultural, cross-border teams', 'English language skills - excellent written and verbal communication', 'An overall understanding of Policy Group responsibilities and activities (e.g. role of legal, data protection, risk management)', 'Ability to work and team with a multitude of different people - including business customers, Functional managers, project managers and IT engineers - to balance demands', 'Self-starter attitude, with ability to independently lead workstreams that contribute to group objectives Ability to identify, prioritize and weigh different options and to recommend a value-add solution', 'Ability to stay focused on identified priorities while balancing multiple objectives', 'A degree in Business, Computer Science, Law or STEM related discipline or equivalent work experience.', '5+ years total work experience and experience in Data governance, Quality, Risk Management processes preferred but not required. Additionally:', 'Minimum of 3 years of hands-on information governance or policy design and implementation.', 'Minimum of 2 engaged within a multi-cultural, multi-disciplined, globally dispersed team', 'Any EA, Data Governance, Applicable Vendor or Industry certification is preferred but not mandatory', 'Minimal travel, less than 10%.', 'Long hours may occasionally be required to meet project commitments and/or preparing materials for clients (internal and external). Overtime may be required as per country overtime policy', 'Flexibility in working hours to accommodate workload and multiple time zones, as needed']",2020-12-30 23:34:28
Data Engineer,"Darwill, Inc.",N/A,"Oakbrook Terrace, IL 60181","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build and maintain data infrastructure and manage data storage and use', 'Build data expertise and own data quality across the organization', 'Design, build and launch new data models and efficient data pipelines (including ETL processes) in production', 'Partner with cross-functional teams of Account Executives, Data Scientists, and Software Engineers to understand data needs and deliver on those needs', 'Build and maintain reporting dashboards using BI tools like Tableau', 'Support data processing and reporting at scale', 'Triage mission-critical issues and drive to resolution', 'Support existing processes running in production', 'Master of Science in Computer Science, Mathematics, or other technical field', '3+ years’ experience working in SQL and relational database management systems', '3+ years’ experience with dimensional data modeling, schema design, and data warehousing', '2+ years’ experience in ETL design, implementation, and maintenance', '2+ years’ experience with AWS', 'Ability to write well-abstracted, reusable code', 'Ability to analyze data to identify deliverables, gaps, and inconsistencies', 'Ability to decompose and solve data problems and to find answers on own', 'Very strong communication skills and ability to work collaboratively with peers and stakeholders', 'Very strong work management skills', 'Experience in a Direct Marketing/Measurement company', 'Experience with data analytics', 'Experience with python', 'Experience with AWS']",2020-12-30 23:34:28
"Research Engineer, Creative AI (University Grad)",Facebook,4.2 out of 5 from 602 employee ratings,"Pittsburgh, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop highly scalable algorithms based on state-of-the-art machine learning and neural network methodologies.', 'Collaborate with Facebook AI Research (FAIR) scientists to facilitate research that enables learning the semantics of data (images, video, text, audio, and other modalities).', 'Apply knowledge of relevant research domains along with expert coding skills to platform and framework development projects.', 'Adapt machine learning and neural network algorithms and architectures to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU).', 'Experience in developing and debugging in C/C++ and/or Python.', 'Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment.']",2020-12-30 23:34:28
Senior Data Engineer,Cubesmart,3.3 out of 5 from 414 employee ratings,"Malvern, PA 19355","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Collaborate with the Application Development team lead to carry out the technical development plans required to implement system changes and enable the capabilities outlined in the business requirements', 'Partner and collaborate with Revenue Management and Data Scientist teams in support of their systems, data, and reporting/analytics requirements', 'Perform the technical development tasks to support, maintain, and enhance CubeSmart’s proprietary pricing management system', 'Assist in the technical design and development of enterprise applications', 'Ensure all code written is robust, secure, efficient, and meets the requirements as outlined', 'Ensure that all coding activities are in alignment with the technical framework and enterprise technology plan as outline by the established architecture', 'Participate in code reviews and unit testing of all completed development items for quality, performance, and successful delivery of the desired capabilities', 'Responsible for adhering to the Software Development Life Cycle (SDLC)', 'Participate in code deployments of all assigned work through each step in the software development life cycle', 'Participate in all aspects of the Agile development methodology including daily standups, sprint planning sessions, code reviews and change management review sessions', 'Utilization of task management system to ensure all work is tracked in accordance with software development methodologies', 'Evaluate emerging machine learning techniques, technologies and methodologies to continue to support and evolve CubeSmart’s analytics and data science capabilities', 'Performs application performance testing, tuning and bug fixes as directed', '5-8 years’ experience in data engineering and/or data analytics, supporting data scientist team(s)', 'Bachelor Degree in Computer Science, Engineering, or equivalent related technical field', 'Experience with all aspects of the software development life cycle and Agile software development methodologies', 'Proven experience in advanced data-development skills involving analyzing, writing and modifying T-SQL queries and scripting against MS-SQL databases', 'Experience with SQL Server database tools, including SQL Server Integration Services', 'Experience in Python is required', 'Proven experience analyzing, developing and modifying machine learning algorithms', 'Working knowledge and experience with R is strongly preferred', 'Knowledge of object-oriented programming and design patterns', 'Working knowledge and experience in source code control and management using GIT or other equivalents is preferred', 'Experience with Microsoft Azure cloud development', 'Proven technical project management skills, preferably in a software product development environment', 'Strong oral, written and interpersonal communication skills. Ability to effectively convey complex information', 'Service orientation towards business-focused 24×7 support and service mentality.', 'Collaborative individual who creates open channels of communications and encourages technical dialogue and promotes technical bench across the department.', 'Well-developed analytical and problem-solving abilities', 'Ability to work on multiple tasks and projects at once, with the ability to properly prioritize one’s own work', 'Demonstrated ability to understand business drivers and design systems, processes, analytics and algorithms to support the business requirements']",2020-12-30 23:34:28
Data Engineer,AllianceBernstein,3.5 out of 5 from 217 employee ratings,"Nashville, TN","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Automation of data ingestion supporting various sources and formats both external and internal.', 'Implementing a quality control framework for ensuring data consistency.', 'Cataloging new data sets to facilitate data discovery, lineage, and self-service.', 'Building business intelligence dashboards to provide data insights.', 'Assist with ad-hoc data and research requests from the investment team.', 'Provide support for overnight jobs.', 'Learning the equity investment business and engaging directly with end users.', 'Automating complex data loads and pipelines.', 'Onboard alternative datasets including learning how to web scrape.', 'Best practices managing large data sets.', 'Building technical skills including SQL, Python, and PowerBI.', 'Applying cloud based technologies including data lakes and data pipelines.', 'BS in Computer Science/Engineering, Finance, Mathematics/Statistics or a related major', '2-3 years programing in SQL with experience in relational schema designs and optimizing query performance', '1-2 years using Python or another object oriented language (C#, Java)', 'ETL experience is a strong plus', 'Working with NoSQL is a strong plus', 'Building visualizations using Tableau, Qlik, or PowerBI is a strong plus', 'Solid analytical and technical skills', 'Candidate must be willing to take ownership of projects and show strong client commitment', 'Must demonstrate good communication skills and be comfortable working closely with business users', 'Self starter as well as a good team player', 'A strong desire to document and share work done to aid in long term support', 'Experience working in the financial industry or knowledge of basic financial statement concepts', 'Azure experience building data pipelines', 'Experience using Airflow']",2020-12-30 23:34:28
Junior Backend Developer,"Picwell, Inc.",N/A,"Philadelphia, PA 19103","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Build and maintain Picwell’s API products.', 'Work with frontend developers to expose features to our consumer-facing UI.', 'Collaborate with data scientists to maintain and improve our core recommendation engine and modeling framework.', 'Improve the service infrastructure by working with site reliability engineers.', 'Enjoy writing and revising code', 'Enjoy reasoning about better ways to do things', 'Have experience with version control systems (we use git)', 'Have good verbal and written communication skills', 'Be curious to ask good questions', 'Be eager and able to learn new things', 'Degree in computer science or software engineering', 'Prior work experience (2 years or more), including interns and co-ops', 'Experience developing and maintaining APIs', 'Programming experience in Python', 'Experience in AWS', 'Experience with SQL and NoSQL storage systems', 'Experience in insurance industry', '401(k)', 'Dental insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Paid time off', 'Retirement plan', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'Software Engineering: 2 years (Preferred)', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.Picwell.com', 'Only full-time employees eligible', 'Remote interview process', 'Virtual meetings']",2020-12-30 23:34:28
Data Engineer - TS/SCI with CI Polygraph,General Dynamics Information Technology,"3.8 out of 5 from 7,499 employee ratings","Annapolis Junction, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Performs data analysis interpretation and management duties. Develops rules and methodologies for data collection and analysis', 'Researches and evaluates new concepts and processes to improve performance.', 'Analyzes cross-functional problem sets, identifies root causes and resolves issues.', 'Assists more junior level technicians, specialists, and managers in their activities.', 'Works individually, actively participates on integrated teams, and leads multiple tasks, projects or teams.', 'Oversees and monitors performance, and when required, takes steps to resolve issues.', 'Directs multiple teams through to project completion.', 'Provides guidance and direction to lower level technicians, specialists, and managers.', 'DoD 8570 compliance or information assurance certification.', 'Active TS/SCI clearance and ability to obtain and maintain a CI polygraph.', 'High School Degree + 10 years of experience', 'Associate Degree + 8 years of experience', 'Bachelor Degree + 6 years of experience', 'Master Degree + 4 years of experience', 'PhD + 2 years of experience']",2020-12-30 23:34:28
Data Engineer(Big Data),Blue5Green LLC,N/A,"Baton Rouge, LA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:34:28
Engineer II,PPG Industries,"3.4 out of 5 from 2,159 employee ratings","Allison Park, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Formulates and develops new and improved products, innovative ideas, processes, protocols, and techniques to support the deliverables of', 'The Additive Manufacturing Group', 'Carries out research on assigned technology, concepts, technical opportunities,', 'Identifies and/or evaluates materials or technologies to assess technical performance', 'Uses experimental designs, researches, analyzes and interprets data to determine feasibility/efficacy of proposed solutions', 'Is a technical and problem solving resource for rapidly changing requirements', 'Recommends product modifications, equipment designs, and process improvements', 'Implements, develops and/or improves test methodologies and/or processes', 'Develops, identifies, and modifies new and existing formulations and technologies for improved performance', 'Establishes new methods for evaluating products', 'Engineers new printing designs and protocols to meet part requirements according to technical drawings', 'Interacts independently with contract/full-time formulation employees in team-like manner', 'Documents projects through electronic lab notebook, technology transfer documentation, and project reports', 'BS Chemical Engineering', 'Excellent computer and communication skills', 'Ability to interpret CAD drawings, technical drawings, and overall CAD skills is a plus', 'Ability to work independently for the Additive Manufacturing Group', 'Mechanical ability with equipment and processes', 'Experience with experimental design (DOE), formulation, and problem solving is desired']",2020-12-30 23:34:28
Drive Testing,Verveba telecom,3.8 out of 5 from 32 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:34:28
"Data Engineer, Core Automation Services",Tesla,"3.5 out of 5 from 4,572 employee ratings","Fremont, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Employ and improve industry-leading, scalable, distributed open-source technologies', 'Build back-end systems from scratch that are capable of handling trillion+ events per day', 'Facilitate operation of highly-available distributed systems at scale and across multiple locations', 'Facilitate others in deploying, operating, and extending upon your clean, tested code', 'Help define a platform that is highly leveraged, multi-tenant, and self-serviced', 'Work with data engineers and data scientists to drive efficient solutions from the platform', 'Help define the data story and enable data-driven solutions at Tesla, both technically and culturally', 'Strong programming fundamentals, particularly in data structures, concurrency, Go, Python, and Java', 'Deep understanding of a complex distributed system, such as Kafka, Spark, HBase, ElasticSearch', 'Have built and optimized highly available, scalable, distributed back-end services', 'Ability to break down and deeply understand complex problems and communicate complex matters efficiently', 'Strong problem solving skills, optimizing for the simplest, most robust yet practical solutions', 'Reliable, dependable, trustworthy, participating team member', 'Smart but humble, with a bias for action']",2020-12-30 23:34:28
HID Algorithm Engineer - Data Focus,Apple,"4.2 out of 5 from 9,978 employee ratings","San Diego, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Expertise in Python programming (functional and object-oriented)', 'Strong foundation in statistical analysis', 'Able to develop optimized pipelines for data acquisition, pruning and preprocessing; insightful data and performance visualizations and iterating over algorithm variants', 'Some exposure to developing infrastructure for large-scale data processing and annotation.']",2020-12-30 23:34:28
Java Cloud Data Engineer - 12+ Months - Remote Opportunity,TMS LLC,N/A,"Richmond, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:34:28
Informatica Enterprise Data Catalog (EDC) Engineer,Numentica LLC,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)Informatica EDC: 5 years (Preferred)"", 'Execute standard on boarding of technical and business metadata into the Informatica EDC and Axon environments, ensuring the population of data lineage and linkage between the technical and business metadata.', 'Participate in the development and implementation of enterprise metadata standards, guidelines, and processes to ensure quality metadata and support for ongoing data governance.', 'Providing administration support for Informatica EDC/Axon and in future other data governance related products (MDM/ Data Quality) which includes installation, configuration, upgrades and business continuity support.', 'Facilitate discussion with data stakeholders on data governance processes, and translate those requirements into Axon workflows.', 'Participate in Metadata Management scrum team to partner in work efforts, provide data management experience, including an understanding of concepts, practices, procedures, and tools providing strong analytical, innovative and creative problem-solving', 'Participate in training sessions for business and technology partners covering enterprise metadata standards, guidelines, and processes', 'Participate in product evaluations for future data governance initiatives.', 'Minimum of 5-6+ years of enterprise data integration and management experience working with Datawarehouse technologies and data governance solutions (Data Catalog, MDM and Data Quality)', 'Must have 5+ years of hands on Informatica Data Governance (Axon), EDC, Data Quality, and MDM experience, including executing at least 2 large Data Governance, Quality and MDM projects from inception to production, working as technology expert.', 'Must have 5+ years of hands on developer/designer experience as well as experience working with Informatica’s Data Governance, MDM, and Data Quality product', 'Must have 5+ years of practical experience configuring EDC and Axon, including business glossaries, dashboards, policies, search, Axon maps', 'Experience in data quality tools, including data profiling, cleansing and identity resolution.', 'Experience defining solution and technical architectures for new solutions, including experience driving project team execution from an architectural standpoint across the complete project life cycle within defined and finite time frames.', 'Must be a team player as this role requires working with multiple teams.', 'Excellent communication, presentation, interpersonal and organizational skills', 'Informatica Certification is highly desirable', '8 hour shift', ""Bachelor's (Preferred)"", 'Informatica EDC: 5 years (Preferred)', 'Fully Remote', 'Temporarily due to COVID-19']",2020-12-30 23:34:28
Product Manager,Indeed,4.3 out of 5 from 723 employee ratings,"New York, NY 10036","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Product Management: 3 years (Required)', 'Engage in user research to understand their problems.', 'Work with engineers and designers to define product requirements and ship experiments regularly.', 'Analyze data, including analytics and A/B testing results.', 'Use data analysis to improve products and inspire new product ideas.', 'Flesh out ideas with wireframes and mockups (in conjunction with designers).', 'Research markets and competitors.', '3+ years of consumer mobile or internet software product management experience is a must', 'Comfortable with the ambiguity of zero to one product development.', 'Ability to move fast and make decisions on the fly.', 'Outstanding data analysis skills and the ability to make data-driven business decisions.', 'Deep understanding of web development technology.', 'Previous product management experience in top Silicon Valley companies is a plus.', 'Previous entrepreneurial / start-up experience a plus.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Referral program', 'Relocation assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Bonus pay', 'Signing bonus', 'Product Management: 3 years (Required)']",2020-12-30 23:36:10
Data Analyst or Data Engineer,State of Wisconsin,3.5 out of 5 from 365 employee ratings,"Dane County, WI","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:36:10
Cost Engineer,"Talson Solutions, LLC",N/A,"Philadelphia, PA 19106","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)US work authorization (Preferred)"", 'Applicant should have a minimum of 5 years professional experience in budget development, cost management, estimating, financial controls and invoice and disbursement management', 'Applicant must be well-rounded in all aspects of the construction industry, contract compliance and federal contracting', 'Conduct timely and accurate review of payment applications and lien waivers', 'Review monthly cost reporting and budget reconciliations', 'Understanding of overall project execution, including budgeting, project forecasting, cost control, schedule, and anticipated cost', 'Assist with procurement review and bid award process', 'Support preparation of audit reports and memos for internal and/or external use', 'Able to work independently, with some oversight and in a team environment displaying initiative and independent thinking', 'Must have a good work ethic and integrity, dependable, adaptable, cooperative, and motivated to take on new responsibilities', 'Willingness to join a growing capital project consulting business with excellent history, reputation and growth potential opportunities', 'Bachelor’s degree in Construction management, Finance, Engineering, Accounting required', 'Ability to solve practical problems and deal with a variety of discrete and indiscrete variables in situations where only limited standardization exists', 'Effective communicator at all levels within the organization, and externally, with strong oral and written skills', 'Must be highly organized, able to prioritize competing demands, detail-oriented, maintain accuracy and self-check work', 'Self-starter but can function effectively as part of a team', 'Strong problem-solving skills', 'Good judgment and influencing skills', 'Excellent training and presentation skills', 'General knowledge of computer applications including Microsoft Office Suite', 'Develop and maintain positive professional relationships both internally & externally', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible spending account', 'Health insurance', 'Paid time off', '8 hour shift', 'Bonus pay', ""Bachelor's (Required)"", 'One location', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'www.talsonsolutions.com', 'Waiting period may apply', 'Temporarily due to COVID-19', 'Remote interview process']",2020-12-30 23:36:10
Data Engineer,Hagerty,3.5 out of 5 from 44 employee ratings,"Traverse City, MI","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Implement data engineering best practices', 'Develop and implement robust and scalable data integration (ETL) pipelines using Python, SQL, Spark, and other AWS/Salesforce cloud solutions.', 'Develop and implement data pipeline orchestration utilities using Apache', 'Support AWS platform DevOps best practices throughout all data engineering', 'Create and manage AWS resources using infrastructure-as-code bestpractices, specifically in terraform.', 'Partner with internal and external stakeholders to collect requirements and recommend best practice solutions.', 'Develop solutions to catalog and manage metadata to support data governance and data democratization.', 'Develop and implement automated test cases and data reconciliation to validate ETL processes and data quality & integrity.', 'Partner with Data Scientists to design, code, train, test, deploy and iterate machine learning algorithms and systems at scale.', 'Associates degree, preferably in a technical/analytical field, or relevant work', 'Additional 3+ years working in another role within an IT delivery team, such as a developer, business systems analyst, data analyst, quality assurance analyst, ETL developer or DBA', 'Strong problem-solving abilities and attention to detail', 'Ability to authentically and effectively communicate (written and verbally) with various stakeholders', 'Ability to create technical artifacts and documentation to support development and maintenance of data products', 'Experience in successful delivery of data products as productionizable software solutions', 'Experience or willingness to learn open source data processing technologies such as Kafka, Hadoop, Hive, Presto, Spark, GraphX', 'Experience ensuring rigorous code development, testing, automation, and other engineering best practices.', 'Experience in imperative (e.g., Airflow) or declarative (e.g., Informatica/Talend/Pentaho) ETL design, implementation, and maintenance.', 'Experience cataloging and processing non-relational data.', 'Experience or willingness to learn one or multiple of the following languages Python, Scala, or SQL', 'Functional knowledge of relational databases and query authoring (SQL)', 'Experience or willingness to learn productionizing data science models in frameworks such as numpy, ML Spark, pandas, scikit-learn, tensorflow, MOA, mlpack, etc.', 'Preferred experience in machine learning techniques such as feature engineering, features selection, supervised and unsupervised algorithms, clustering, graph analytics, and time series analysis, K-means clustering, Gaussian distribution, decision tree, etc.', 'Competitive compensation', 'Inclusive benefits package allowing enrollment of dependents and partners', 'A flexible culture that understands the importance of quality of work over quantity', 'An opportunity to work with a diverse, global community of 1000+ Hagerty team members across multiple countries, united by our values of open, direct, and kind', 'A culture of company-wide collaboration and shared success', 'Company supported and employee-driven resource groups that promote diversity, career development and empowerment', 'Corporate social responsibility initiatives with global reach', 'Regular recognition, feedback, and open communication across all levels', 'Team building, bonding, mentorship and support to grow confidence, trust, and friendships', 'At Hagerty, we’re focused on building a world-class company and culture, and that starts with the people we hire. We take pride in being an equal opportunity, inclusive employer']",2020-12-30 23:36:10
Quantitative Product Researcher,Etsy,4.3 out of 5 from 58 employee ratings,"Brooklyn, NY 11201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, program, and field surveys across multiple parts of the marketplace experience', 'Analyze survey data; recognize patterns and uncover key trends and insights', 'Manage survey samples and ensure the quality of data collected', 'Craft engaging, recommendations-focused reporting that encourages marketplace health and drives Etsy’s business goals', '3+ years of experience in quantitative survey research, either in-house or at an agency', 'Desire to conduct the full survey research process including questionnaire development, programming, fielding, and statistical analysis (inferential stats, correlations, regression analysis, etc) of results', 'A focus on the details, with excellent written, visual and verbal communication skills', 'Able to keep multiple projects on track and handle competing demands', 'Experience with SPSS or other statistical analysis software', 'Ability to hold your own in a meeting and present research findings with a customer-centric perspective', 'Preferred: Experience with survey programming platforms (e.g., Qualtrics, SurveyGizmo) strongly preferred', 'Preferred: Experience conducting research with ecommerce or other digital product development', 'Preferred: SQL/database querying experience', 'Bachelor’s degree in a relevant field (e.g., business, marketing, psychology, sociology); Master’s degree preferred']",2020-12-30 23:36:10
Summer 2021 UX designer Internship,Guardian Life Insurance Company,3.6 out of 5 from 505 employee ratings,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Are you a problem solver who enjoys using data and research to build better consumer experiences?', 'Are you excited by design challenges and possess good interpersonal skills to effectively liaison between technical and business teams?', 'Do you think big and enjoy learning new ways of working, hands on work and opportunities to lead change?', 'Is a culture where “People Count,” “We Do the Right Thing,” and “We Hold Ourselves to Very High Standards” important to you?', 'Currently enrolled in a full-time Bachelor’s degree in UX Design, Interaction Design, Human-Computer Interaction, Cognitive Science, Human Factors, Engineering Psychology or related program', 'A self-starter who is fueled by a desire to improve customer experiences in the moments that matter most, approaching your work with a bias toward accountability, decision-making and action', 'Inquisitive and creative, with an ability to listen to identify customer needs and dig deeper to understand the reasons behind those needs', 'Able to transform conceptual thinking into deliverables that generate excitement, feedback and alignment among stakeholders', 'Thrive in a collaborative environment, partnering across the company with business experts, software developers, data engineers, and marketers', 'Enthusiasm to take the initiative to tackle problems and work with others to expand on your experience and expertise', 'Working knowledge of agile development practices, human centered design and/or UX design practices', 'An aptitude for visual storytelling and user research', 'Experience with Figma, Adobe XD, Sketch or similar tools used to visualize digital experience', 'Work closely with and learn from UX designers and user researchers to contribute to a variety of deliverables, including presentations, wireframes, storyboards, low-fidelity prototypes, polished designs, HTML/CSS, research plans, questionnaires and surveys', 'Remote work from home with potential to travel to office in New York, NY or Holmdel, NJ.']",2020-12-30 23:36:10
Cloud Data Engineer,Pluribus Digital,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '5 years experience in data engineering and/or database administration', 'AWS experience and familiarity with data-related services', 'Experience administering Oracle databases', '4-year degree in Computer Science or related field', 'Ability to obtain a public trust clearance', 'AWS database and data management tools', 'Related AWS certifications (Data Analytics, Database, Machine Learning)', 'Oracle certification', 'Machine learning', 'Database migration and modernization']",2020-12-30 23:36:10
Database / Data Engineer,"Webtellect, LLC",N/A,"Seattle, WA 98104","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Development of Tools, Reporting & Analysis:Design, develop and maintain scalable, automated, user-friendly systems, reports, dashboards, etc. that will support our analytical and business needsWrite robust SQL code to retrieve and analyze data from database tables (ex. MySQL, Redshift, Athena)Analyze projects for data quality issues and supporting the use of data in an enterprise settingDevelop analysis and visualizations for ad-hoc requests and one-off projectsUse analytical and statistical rigor to solve complex problems and drive business decisions', 'Contribute to current data infrastructure:Understand corporate data structure to be able to draw data from transactional data tables existing in the companySupport the acquisition of external data sets, interpreting data layouts, structures, fields and values to incorporate new data into the core analytics data base', 'Communication:Interface with business customers to gather data and metrics requirements, then driving analytic projects which will help solve complex challengesDraw insights from data and clearly communicate complex findings to stakeholders and external customersWork closely with the Modeling and Data Science teams to determine where gaps and opportunities lie', 'Experience working with MySQL, PostgreSQL, AWS Redshift/S3', 'Experience with Excel (including VBA) and Tableau', 'Experience with Python, PySpark, and DataRobot', 'Analytical Curiosity: Motivated individual with strong analytic, problem solving, and troubleshooting skills.', 'Teamwork and Adaptability: Ability to be flexible and work as part of a team in ever-changing start-up environment.', ""Educational Credentials: Bachelor's degree in Computer Science or a quantitative field such as Mathematics, Statistics, Economics, Finance, Physics, or Engineering"", 'Relevant experience: A minimum of 2 to 3 years of experience (3 to 5 years preferred) of SQL experience', 'Technical Knowledge: Intermediate to expert level programming experience in SQL along with a solid understanding of data warehousing concepts and ability to build and work with data from different sources efficiently.', '6 month contract.', '** No 3rd parties. **', '** No Visas allowed **']",2020-12-30 23:36:10
Data Engineer,Catalytic Data Science,N/A,"Weston, CT 06883","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build & operate automated ETL pipelines that process terabytes of text data nightly', 'Develop service frontends around our various backend datastores (AWS Aurora MySQL, Elasticsearch, S3)', 'Perform technical analyses and requirements specification with our product team on data service integrations', 'Help customers bring their data to the platform', 'Python 3 or Java programming experience, preferably both', 'Day-to-day experience using AWS technologies such as Lambda, ECS Fargate, SQS, & SNS', 'Experience building and operating cloud-native data pipelines', 'Experience extracting, processing, storing, and querying of petabyte-scale datasets', 'Familiarity with building and using containers', 'Familiarity with event-based microservices', 'Prior experience with Elasticsearch (custom development and/or administration) is a huge plus', 'Prior work with text and natural-language processing', 'Knowledge of Graph databases', 'Focus on customer’s needs and our company’s goals, not just writing code', 'Iterate until customers love what you’ve built', 'Self-start and initiate', 'Self-organize', 'Strive to grow personally and professionally, beyond just expanding technical abilities', 'Love to experiment with new technology and share knowledge with the team']",2020-12-30 23:36:10
Software Engineer in Big Data Infra,PayPal,"3.9 out of 5 from 1,386 employee ratings","Wilmington, DE 19810","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'As an software engineers you will be building services that can help operate and scale the infrastructure', 'Take responsibility for services you build', 'Work directly with Lead engineer, Architecture, Product Managers, Program Managers and stakeholders', 'Work directly with Product Managers, Program Managers, Data Scientists/Customers', 'Mentor engineers locally and globally', 'Analyze platform behavior to optimize resource usage and cost', 'Build services to support Multi-tenant environment with 200+ PBs in Datasets.', 'A successful candidate will be a strong engineer who can be part of a high performance engineering team, with excellent communication skills, and an ability to deliver results in a fast paced environment.', 'Excellent team player and great attitude. Willingness to understand and work through global software development approaches and inherent problems it surfaces', 'Experience with design and development of scalable services and platforms', '3+ years’ experience in one or more of the following language: Golang (big plus), Java, C++, NodeJS, python and scripting.', 'Knowledge and experience with cloud technologies', 'Experience with big data technologies like Spark', 'Experience with GCP Big data services', 'Experience with DevOps methodologies and tools for automating and monitoring']",2020-12-30 23:36:10
Principal Data Engineer,Womply-All,N/A,Utah,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '5+ years of experience in software engineering with experience as a senior contributor or team lead.', 'MUST HAVE - Good programming skills in Java or Scala.', 'MUST HAVE - Experience delivering Spark-based data consumption to consumer facing products / systems.', 'MUST HAVE - Data Platform and Pipeline experience', 'Experience with Cassandra, Mongo, or similar data stores.', 'Strong background in SQL, Data Modeling, and Performance Tuning in both relational and noSQL databases.', 'Experience with distributed and federated systems and data processing pipelines', 'Familiarity with monitoring, backup, and disaster recovery of data systems', 'Experience building POCs, architecting new systems and improving existing systems to solve business problems and support scaling', 'AWS experience', 'Database Administration Experience.', 'Experience with Python / Pyspark', 'Experience generating and evaluating data quality metrics', 'Experience mentoring engineers in best practices and methods.', 'Experience with PCI data practices']",2020-12-30 23:36:10
Data Engineer - Visa Consulting & Analytics,Visa,3.9 out of 5 from 986 employee ratings,"Miami, FL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Consulting services customized to the needs of Visa client’s business objectives and strategy', 'Business and economic insights and perspectives that impact business and investment decisions', 'Self-service digital solutions Visa clients can leverage to improve performance in product, marketing and operations', 'Proven data-driven marketing strategies to increase clients’ ROI', 'Work with large volumes of data; extract and manipulate large datasets using standard tools such as Hadoop (Hive), Spark, Python (pandas, NumPy), SAS, SQL, etc.', 'Hands-on skills in cleaning, manipulating, analyzing, and visualizing large data sets.', 'Data Cleansing/Wrangling – This involve parsing and aggregating messy, incomplete, and unstructured data sources to produce data sets that can be used in analytics/predictive modeling.', ""Utilize Visa's data and analytic capabilities, technology, and industry expertise to develop, standardized and implement the consulting analytical solutions."", 'Find opportunities to create and automate repeatable analyses or build streamlined solutions for business consultant and Visa’s clients.', 'Continuously develop and present innovative ideas based on data driven approach in order to improve current business practices within Visa', 'Communicate complex concepts and the results of the analyses in a clear and effective manner.', 'Document all projects developed, including clear and efficient coding, and write other documentation as needed.', 'Identify and share best practices for key topics.', '2 years of work experience with a Bachelor’s Degree or an Advanced Degree (e.g. Masters, MBA, JD, MD, or PhD)', '3 or more years of work experience or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD)', 'Experience in retail banking, payments, financial services, and/or technology industries is a plus. Strong interest in the future of payments is a must.', 'Hands-on experience extracting and manipulate large datasets (Big Data) using standard tools such as Hadoop (Hive), Spark, Python (pandas, NumPy), SAS (E. Guide, Macro programming), SQL, etc.', 'Hands-on experience in advanced analytics and statistical modeling including Linear Regression, Logistic Regression, Clustering methods (e.g. K-means), Classification models, among others.', 'Hands-on Experience with data visualization and tools like Tableau and Power BI.', 'Translate data analysis insights to a business language.', 'Continuously develop and present innovative ideas based on data driven approach in order to improve current business practices within Visa.', 'Excellent project management, organizational and presentational skills.', 'Knowledge of Agile methodology and scrum practices.', 'Proven ability to quickly learn and apply new techniques.', 'Ability to multi-task various projects while meeting required deadlines.', 'Strong teamwork, relationship management and interpersonal skills.', 'Results oriented.', 'Bilingual Spanish/English (spoken/written).', 'This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers, and reach with hands and arms.']",2020-12-30 23:36:10
Cloud Data Engineer (DC),Pandera Systems,3.3 out of 5 from 4 employee ratings,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Location: Based in Arlington VA and the surrounding area', 'Local Hire or Candidates relocating to Arlington, VA, and DC areas', 'Authorized to work in the USA', 'Travel: Remote and onsite client location(s) - overnight is based on the needs of the client', 'Responsible for data modeling and schema design that will range across multiple business domains and industries.', 'Partner with multiple client stakeholders including partners, business users, BI and Analytics teams.', 'Work with teams to conduct workshops to identify data sources, flows, and requirements.', 'Create data pipelines for batch, micro-batch, and real-time data streams.', 'Coordinate work with client teams to ensure a smooth development and transition.', 'Conduct client workshops to help shape their future data strategy by providing future state architectures, roadmaps, and implementation plans.', '3+ years of experience working with cloud-based databases, specifically Big Query and Snowflake', 'Experience developing logical data models within a data warehouse', 'Experience developing and deploying ETL / ELT processes and documentation including physical data model, source to target mappings, ETL / ELT packages (Matillion, Fivetran, Spark, Data Fusion, Custom Code)', 'Demonstrated mastery in: Snowflake or Big Query', 'Demonstrated mastery in database concepts and large-scale database implementations and design patterns', 'Implement solutions for structured, semi-structured, and unstructured data sources, relational and non-relational databases.', 'Proven ability to work with users to define requirements and business issues', 'Implementing Data Quality rules and test cases into a data environment', 'Excellent analytical and troubleshooting skills', 'Strong written and oral communication skills', 'Experience working in an AGILE environment', 'Experience with GCP infrastructure (GCS, Big Query, Dataflow, Dataproc, Data Fusion), or other equivalent Public Cloud offerings', 'Experience with cloud based ETL Tools (Matillion, Fivetran, Snaplogic)', 'Experience with Snowflake Datawarehouse', 'Hands on experience with Python', 'GIT expertise', 'MDM expertise', 'Infrastructure as Code experience (Terraform, Ansible, etc.)', 'Experience with Deploying a Data Governance Program', 'Be Healthy - Health, dental, and vision offered through top tier providers and sick leave to keep you feeling at the top of your game.', 'Be Inspired - Collaborative workspace, personal days, paid birthday off, and vacation time to keep your mind fresh and ready to take on the next new idea.', 'Be Rewarded: A competitive salary and instant vesting on 401k are only a few of the rewards for a job well done.', 'Be Supported: A large network of industry experts, internal training platform, and external learning opportunities to grow your skills and experience.', 'Be a Team: Team outings, happy hours, passion presentations, volunteer opportunities, meetups, etc. we are creating a community to continuously share and grow as a team.']",2020-12-30 23:36:10
Data Engineer/Data Analyst,Bryan Rettig Group,N/A,"Denver, CO 80202","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)Data analytics: 5 years (Required)"", 'Private-equity backed company with a track record of success', 'Work with teams across the business from accounting & finance to operations', 'Competitive base salary, STI, LTI, up to 10% 401k match, insurances and other benefits', 'Developing and maintaining ETL processes and code to support the integration of various components of the technology platform', 'Maintaining and upgrading existing data warehouse by acquiring and integrating primary and secondary sources for complex data manipulation, cleansing and querying', 'Monitoring, supporting and creating single customer view of all customer-related data', 'Understanding key business problems and drivers in order to help provide appropriate data sets', 'Addressing data quality issues and implement procedures for error checking and monitoring', 'Designing and implement auditing strategies to ensure data accuracy and integrity', 'Creating scalable reporting and dashboards', 'Bachelors degree in Computer Science or similar discipline', '5+ years of experience working with Data Analytics', 'Proficiency with SQL, SSRS, SSIS, SSAS, and Power BI', 'Python experinece preferred', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Required)"", 'Data analytics: 5 years (Required)', 'https://www.bryanrettiggroup.com/', 'Only full-time employees eligible', 'Temporarily due to COVID-19', 'Remote interview process']",2020-12-30 23:36:10
Cloud Readiness-Data Bricks Engineer,Capgemini,"3.8 out of 5 from 8,123 employee ratings",California,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Databricks Engineer Up to 3 years of working experience in Databricks Python Spark Scala', 'The developer must have sound knowledge in Apache Spark and Python programming', 'Deep experience in developing data processing tasks using pySpark such as reading data from external sources merge data perform data enrichment and load in to target data destinations', 'Experience in deployment and operationalizing the code is added advantage', 'Your career matters to you and is important to us too. Because your goals and needs are constantly evolving, we offer visibility, leeway and support to help you grow and progress in your career. This approach builds notably on our comprehensive competency framework, our personal development, training and career management programs, and our University innovative and business-focused learning curriculums.', 'We promote a culture of diversity. We believe working with talented individuals from different backgrounds and points of view is a strategic advantage and an ongoing opportunity. Diversity enriches our creative solutions and adds value for our clients.', 'With the digital tech sector growing at a rapid pace and women significantly underrepresented in the industry, we are determined to inspire and recruit more women into technology and build diverse teams that reflect the clients we serve.', 'Our Shared values have been at the heart of the group since our formation. They are honesty, boldness, trust, freedom, team spirit, modesty and fun. These values influence the way we meet client needs while respecting the regulatory requirements of each country in which we operate, and the way we promote ethically sound practices within Capgemini and in our partnerships.', 'Capgemini is committed to building a workforce of employees with diverse backgrounds and work experiences. We strongly encourage women, veterans and active military service personnel to apply.', 'Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.', '`This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.', 'Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law', 'Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.']",2020-12-30 23:36:10
Sr. Data Engineer,Fracsys Inc,N/A,"Washington, DC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Advanced degree in a quantitative discipline, such as statistics, data science, computer science, mathematics, engineering, physics, etc.', '4+ years of experience in designing, developing, evaluating, and deploying predictive modeling, machine learning, advanced analytics', 'Experience in Java or Python programming language', 'Superior coding skills using common data science tools, including Python (strongly preferred), R, Linux/Unix command line and shell scripting.', 'Experience with Notebooks such as Jupyter or Apache Zeppelin preferred. Experience with R Studio is required.', 'Experience with NLP pretrained libraries', 'Excellent skill and significant experience in data processing using SQL, Hive, Impala, Spark, or equivalent querying language', 'Strong experience with distributed storage and big data computing technology, such as AWS, Hadoop, or Spark', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Retirement plan', 'Monday to Friday', ""Bachelor's (Preferred)"", 'One location', 'Temporarily due to COVID-19']",2020-12-30 23:37:55
Data Engineer,Spectral MD,N/A,"Dallas, TX 75201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)developing web and server applications: 3 years (Preferred)AWS: 1 year (Preferred)"", 'Support the transfer of data between a medical device and the cloud, as well as interoperability with a hospital’s electronic medical record system.', 'Drive continued improvement of the backend infrastructure and data pipeline.', 'Work with a cross-functional technical team composed of frontend developers, software engineers, data scientists, and product designers.', 'Develop commercial-ready, testable, reusable code, and produce necessary backend documentation to support medical device design controls.', 'Work with the data science team to develop solutions that facilitate the development of deep learning algorithms, and statistical analysis of data obtained from medical imaging devices.', 'Bachelor’s Degree in Computer Science / Engineering / related field or an equivalent combination of education and work experience', 'Minimum 3 years of related work experience with a solid understanding of specified functional area', 'At least 3 years experience developing web and server applications using Python, Java, C++, C#, or similar: Experience designing and implementing application architecture, database architecture (SQL,NOSQL), and TCP/IP and network programming', 'Knowledgeable in AWS Web Services: AWS IoT Core, Lambda, API Gateway, DynamoDB, S3', 'Knowledge in REST, SOAP, JSON, XML, and other API related standards', 'Understanding of Network Protocols - MQTT, HTTP, JSON objects', 'Understanding of emerging IoT technologies and communications protocols including MQTT, WebSockets, and Notification engines, and preferably implementation experience in AWS IoT services;', 'Experience working within networks in the hospital environment, medical devices, and electronic health record systems.', 'Deploying with Docker and Kubernetes', 'Familiar with CI/CD pipelines with cloud infrastructure', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Paid time off', 'Parental leave', 'Relocation assistance', 'Retirement plan', 'Vision insurance', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'developing web and server applications: 3 years (Preferred)', 'AWS: 1 year (Preferred)', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Team-oriented -- cooperative and collaborative', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'A job for which people with disabilities are encouraged to apply', 'www.spectralmd.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-12-30 23:37:55
Data Mining Engineer Intern (Data Mining) - 2021 Summer,Bytedance,N/A,"Mountain View, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Enable and contribute to establishing fast and continuous threat response, in partnership with product risk operations, by building advanced analytics systems and data mining insights;', 'Enable and contribute to establishing robust and powerful automated defense, in partnership with Machine Learning peers, by creating and improving risk prevention rules and models;', 'Currently pursuing a Bachelor, Master, or Ph.D. degree in Computer Science, Computer Engineering, Electrical Engineering, Statistics or other relevant majors, ability to complete an at least 12-weeks program beginning in May/June 2021', 'Solid technical / data-mining skills and ability to work with large volume data to identify and abstract abusive behavior patterns in ByteDance products (e.g. TikTok).', 'Ability to think critically and to properly communicate problem solutions to cross-functional partners in a clear, concise, and timely manner.', 'Research background on relevant data mining topics about social platform communities. E.g. Botnet, interest group mining, fraud detection.', 'Basic understanding of Machine Learning, e.g. natural language processing, gradient boost decision trees, graph embedding, and/or popular neural net topics.', 'Applications will be reviewed on a rolling basis and we encourage you to apply early;', 'Interview starts in Dec 2020.']",2020-12-30 23:37:55
Data Analyst (REMOTE),TE Connectivity,"3.8 out of 5 from 1,616 employee ratings",United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Manufacturing: 2 years (Required)C#: 2 years (Required)Microsoft SQL Server: 2 years (Required)Java Script: 2 years (Required)Bachelor's (Preferred)"", 'Run daily, weekly and monthly jobs from TED / AWS data into TESS business processes and reporting tools.', 'Develop and maintain standard and ad-hoc charts and reports for sales, orders, margin, and backlog.', 'Integrate customer and product forecasts sourced from various TE systems into the TESS reporting and analytic processes and tools.', 'Create opportunity pipeline funnel charts and reports to support tracking and analysis of new product introductions and sales opportunities in SFDC.', 'Collaborate with business leaders to define informative, actionable and repeatable analytics that highlight relevant business trends and insights.', 'Develop custom report and dashboard solutions as required by colleagues in Sales, Product Management, Finance and other functional areas within TESS.', 'Support acquisition integration activities as required to support the sales operations master data and associated web applications.', 'Provide training and support for reporting and business intelligence tools.', 'Associates or bachelor’s degree in Business or Information Technology', '1-3 years of experience', 'Experience with C#, Visual Studio, MS SQL Server, and Java Script', 'Excellent computer skills and working Knowledge in MS Office (Access, Excel, Outlook)', 'Strong analytical skills with attention to detail', 'Organizational skills with the ability to manage multiple projects and priorities', 'Effective communication skills and fluency in the English language', 'Diligent and meets deadlines', 'Strong interpersonal skills, team player', 'Competitive Salary Package', 'Performance-Based Bonus Plans', 'Health and Wellness Incentives', 'Employee Stock Purchase Program', 'Community Outreach Programs / Charity Events', 'Employee Resource Groups', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', ""Bachelor's (Preferred)"", 'Manufacturing: 2 years (Required)', 'C#: 2 years (Required)', 'Microsoft SQL Server: 2 years (Required)', 'Java Script: 2 years (Required)', 'Fully Remote', 'https://www.te.com/usa-en/home.html', 'Temporarily due to COVID-19', 'Remote interview process', 'Personal protective equipment provided or required', 'Plastic shield at work stations', 'Temperature screenings', 'Social distancing guidelines in place', 'Virtual meetings', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 23:37:55
Oops! That page can’t be found.,TE Connectivity,N/A,United States,"['Indeed Jobs', '404', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Indeed', 'Glassdoor', 'Privacy', 'Accessibility at Indeed', 'Career advice', 'Job Market', 'Indeed Community', 'Facebook', 'Twitter', 'instagram', 'Youtube', 'Soundcloud']",2020-12-30 23:37:55
Data Engineer,Memorial Healthcare,3.4 out of 5 from 85 employee ratings,"Owosso, MI 48867","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Expert in data gathering and analysis through strong database knowledge.', 'Database administration knowledge, including design, optimization and performance is preferred.', 'Evaluates manual and automated work processes, systems, and procedures to determine areas for improvement.', 'Analyzes, implements and maintains computer applications, procedures and other systems that satisfy the needs of the end-user departments.', 'Analyzes and develops necessary design work, including testing, documentation and training.', 'Reviews, evaluates and implements requests from user departments.', 'Strong problem solving skills, including the ability to analyze problems, determine cause and initiate corrective action.', 'Maintains a high level of interaction with all clinical areas to continually enhance/improve patient are and the end-user experience.', 'Shares on-call duties with other individuals within Information Services.', 'Coordinates and participates in both internal and external user group functions.', 'Demonstrates an independent work initiative, sound judgement, diplomacy, tact and professional demeanor.', 'Demonstrates knowledge of and supports hospital mission, vision, value statements, standards, policies and procedures, operating instructions, confidentiality statements, corporate compliance plan, customer service standards, and the code of ethical behavior.', 'Has a working knowledge of all software modules of the HIS.', 'Stays current with technology through seminars, educational opportunities, and trade magazines.', 'Other duties as assigned.', 'Bachelor’s Degree in Business Administration, Computer Science, Healthcare or related field.', 'Experience with computer information systems and software applications preferred', 'Work experience with developing reports required.', 'Experience with SQL database required.', 'Experience with interfaces preferred.', 'Experience with HL7 preferred.', 'Database administration knowledge preferred.', 'Experience in inter- and intra-departmental communications required. Highly effective and proven customer service skills required.', 'Scripting/Programming experience preferred.', 'Healthcare experience preferred.', 'Sedentary Work: Frequently required to stand, kneel and crouch. On a daily basis may be required to move about, sit, climb stairs and bend. Is frequently required to lift and carry up to 20 lbs. May be required to push/pull/carry items between 20-100 lbs.', 'Vision: Requires the ability to perceive the nature of objects by the eye. Near acuity: Clarity of vision at 20 inches or less. Midrange Acuity: Clarity of vision at distances of more than 20 inches and less than 20 feet.', 'Motor Coordination: While performing the duties of the job, it is required to regularly perform functions that include using hand and finger movement, handle or feel objects, be able to use tools or equipment that requires reaching with hands and arms. Must be able to travel independently throughout the hospital; access patients/families including areas confined by space and/or equipment.', 'Speaking/Hearing: Ability to give and receive information through speaking and listening.', 'Proficiency using modern office, computer and telephone equipment as used by Memorial Healthcare.', ""Basic computer skills are required including keyboarding, MS Windows and/or PC's, thin clients, printers, and understanding of general technical concepts used in Healthcare Information Management."", 'Basic understanding of Client / Server computing, Remote Access, Server and Application monitoring.', 'Good understanding of project management; including project planning, budget, implementation and tracking.', 'Ability to adapt and maintain focus in fast paced, quickly changing or stressful situations.', 'Ability to read and interpret a variety of documents including, but not limited to policies, operating instructions, white papers, regulations, rules and laws.', 'Able to see for the purpose of reading information received in formats including but not limited to paper, computer, tablets, reports, bulletins, updates, manuals.', 'Able to see and hear for work-related purposes.', 'Must be able to lift printers, terminals, and other hardware not to exceed 25 pounds.', 'Ability to interact with co-workers, hospital staff, administration, patients, physicians, the public and all internal and external customers in a professional and effective, courteous and tactful manner, at all times, physically, verbally and in all written and electronic communication.', 'Required to remain calm when adversity is encountered.', 'Open, honest, and tactful communication skills.', 'Ability to work as a team member in all activities.', 'Positive, cooperative and motivated attitude.']",2020-12-30 23:37:55
Data Engineer,REEF,3.3 out of 5 from 332 employee ratings,"Miami, FL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Create and maintain optimal data pipeline architecture.', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using ingestion technics and AWS technologies.', 'In-depth technical knowledge and hands-on experience in the areas of Data Management, BI Architecture, Product Development, RDBMS and non-RDBMS platforms.', 'Work with stakeholders including internal and external to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', ""Experience building and optimizing 'big data' data pipelines, architectures and data sets."", 'Experience with big data tools: Hadoop, Hdfs, Spark, Hive, Sqoop, Kafka, Yarn, Zookeeper etc.', 'Experience in Scala, Python, pySpark, Java, Rest API, Microservices etc.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with structure and unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', ""Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores."", 'Strong project management and organizational skills.', 'Experience supporting and working with cross-functional teams in a very fast dynamic environment.', 'We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science or another quantitative field. They should also have experience using the following software/tools:', 'Experience with relational SQL and NoSQL databases, including redshift, Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift, ECS', 'Experience with stream-processing systems: Kafka, Storm, Spark-Streaming, etc.', 'Familiar with data platform like Cloudera, Hortonworks', 'Do not alter this section; only add additional perks under Paid Time Off (PTO)']",2020-12-30 23:37:55
Scientist or Engineer,Integral Consulting Inc.,N/A,"Annapolis, MD 21401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assisting with data preparation activities such as organizing, tracking, and summarizing environmental data sources', 'Participating in environmental sample collection activities', 'Participating in data and regulatory analysis in support of soil, groundwater, and sediment quality projects', 'Assisting with technical writing and data presentation for reports.', 'Bachelor’s or master’s degree in the natural life, environmental, or geological sciences or environmental, civil, geotechnical, or related engineering field', '0–3 years of experience', 'Strong oral and written communication skills', 'Strong quantitative skills', 'Good working knowledge of environmental science and chemistry', 'Experience with Microsoft® Office programs', 'A desire to grow intellectually and professionally.']",2020-12-30 23:37:55
Sr. Data Engineer,AVIVA Talent Advisors,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Data Engineering , 5 years (Preferred)', 'Serve as the Data expert together with your Technical Account Manager and Solution Architect team members when designing and implementing our most complex accounts solutions', 'Senior technical lead for the different data sources being utilized by their most advanced customers from technical requirements and data pipeline design to training and solution delivery', 'Execute an extensive analysis to design the solution and describe it through architecture and design artifacts', 'Present proposed solutions and maintain ongoing technical discussions with the customer across all levels, including C-suite', 'Build data-prep best practices for technical deployments and extensive performance tests for our customers', 'Coach and supervise technical team members on Cloud DWH best practices', 'Work with R&D Data teams to design sophisticated and non-trivial solutions', 'Serve as the Data expert together with your Technical Account Manager and Solution Architect team members when designing and implementing our most complex accounts solutions', 'You have hands-on experience with at least one of the following Cloud DWH technologies: AWS Redshift, Snowflake, Google BigQuery.', 'You are a technical lead of all aspects for a successful implementation from requirements and design to training and delivery.', 'Experience working with either a Map Reduce or an MPP system - Advantage', 'You have experience with schema design and dimensional data modeling', 'Programming experience and knowledge of software development life cycle', 'You have the ability to effectively communicate in English complex concepts in a clear and professional manner.', 'You thrive in a fast-paced, high-growth environment while working with a team.', 'You’ve turned your lifelong curiosity into business outcomes.', 'Ability to travel to customer locations and industry events (when Covid goes away)', 'You will have a much deeper understanding of the client technology, and how customers can utilize it', 'You will better understand the the product Architecture', 'You will start interacting with customers and getting to know their challenges/use cases', 'You will do lots of hands-on exercises in order to know the ins and outs of the technology', 'You will begin building Dashboards, configuring the product and understanding on-boarding customers at different stages of data maturity', 'You will also start shadowing projects with Senior team members', 'You will be familiar with the different types of PS engagements and project types', 'You will learn PS methodologies and tools you’ll use', 'You will start mastering the data challenges customers face', 'You will do several internal projects to champion Data architecture practice within Customer Success', 'You will learn and sharpen PS soft skills such as session management, how to interact with customers, working with Customer Success Managers, Technical Account Manager & Solutions Architects and other teams as well as handling challenging situations', 'You will be joining your first projects as Data Engineer shadowed by Senior team members', 'You’ll already own a handful of customer engagements where you will lead the data engineering challanges', 'You will start laying the foundations for the client’s Cloud DWH best practices', 'You’ll be the team’s focal point for Data, Modeling and BI realm, best practices on their proprietary database and while working with Cloud DWH partners', 'You’ll be able to leverage your acquired knowledge together with your Data expertise and start your journey to lead the Data Architecture field within Customer Success', '401(k)', '401(k) matching', 'Dental insurance', 'Health insurance', 'Paid time off', 'Parental leave', 'Vision insurance', 'Monday to Friday', 'Data Engineering : 5 years (Preferred)', 'Other forms', 'Remote interview process', 'Virtual meetings']",2020-12-30 23:37:55
Data Engineer,Metabolon,3.5 out of 5 from 13 employee ratings,"Morrisville, NC 27560","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design data schema and operate internal data warehouses and SQL/NoSQL database systems. Develop and integrate data pipelines in support and concert with machine learning needs (ex. ETL processes, triggers, stored procedures)', ""Modify, transform, clean, and normalize data so that it is usable by the team's data scientists and analysts"", 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions', 'Monitor and troubleshoot operational or data issues in the data pipelines', 'Drive architectural plans and implementation for future data storage, reporting, and analytic solutions', 'Work collaboratively with business analysts, data scientists, and other internal partners to identify opportunities/problems', 'Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem', 'Develop across multiple codebases for in the service of scientific, business, internal and external concerns', 'Lead multiple simultaneous initiatives in an entrepreneurial environment', 'Experience with several query languages, schema definition languages, and scripting languages', 'Experience in writing and optimizing SQL queries in a business environment with large-scale, complex datasets', 'Practical experience in Python, UNIX/Linux, SQL', 'Experience with big data processing technology (e.g., Hadoop or ApacheSpark), data warehouse technical architecture, infrastructure components, ETL, and reporting/analytic tools and environments', 'Experience designing and implementing genomic data pipelines', 'Experience with modern machine learning toolkits (Tensorflow, Keras, etc…)', 'ML in the cloud experience is a plus', 'Direct experience with Microsoft Azure or Amazon EC2 and Redshift', 'Experience with NoSQL systems like MongoDB, Redis, or Cassandra', 'Experience in a .NET environment is a plus', 'Experience with data visualization software (e.g., Tableau) or open-source project', 'Ability to deal with ambiguity in a fast-paced environment', 'BS with 3-5 years of experience in a data driven field, PhD w/5-8 a plus', 'Experience maintaining database/data cube architecture, configuration, management, and growth', 'Demonstrated ability to design and implement ETL workflows across both Windows and Linux environments', 'Experience with data warehouse design and implementation', 'Experience with dimensional data modeling and schema design in data warehouses', 'Experience interacting with machine learning approaches on a variety of large data sets', 'Broad base of experience in data structures, modern platforms, evolving best practices', 'Experience integrating scientific data, business data, reports and providing custom hooks for natural language processing, deep learning, and other modern mining approaches are all pluses']",2020-12-30 23:37:55
Data Engineer,Chameleon Technology,N/A,"Kirkland, WA 98033","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Help to build and maintain infrastructure development and improvements using Microsoft BI stack and (eventually) AWS or other Cloud technology', 'Work with SDET to perform end-to-end data analysis and ensure data quality gaps are identified', 'Work with business/system analysts to understand business requirements for data warehouse development, enhancement, and maintenance', 'Clearly communicate and resolve issues during development, testing, and release of new code', 'Collaboratively work with other members of the Data Warehouse team, IT and Business partners', 'Work on multiple projects in parallel while managing priorities', 'Minimum 5 years development experience using PowerShell, Stored Procedure and T-SQL', 'Minimum 5 year development experience using PythonAbility to program using PowerShell, Microsoft Stored Procedure, T-SQL and Python', 'Understanding of database design, configuration, and performance tuning', 'Knowledge of data warehouse, data modelling and dimensional modelling', 'Strong analytical and organizational skills, and a great team player', 'Ability to work independently and to adapt to new and changing technologies', 'Capability to communicate effectively to technical and non-technical team members', '5+ years of hands-on data warehouse and business intelligence development experience', 'Familiarity with Cloud technology and Tableau', 'Understanding of Visual Studio Solutions and Projects', 'Understanding of HIPAA regulations', 'Familiarity with diverse kinds of healthcare and/or clinical data', 'Familiarity with Cerner and/or Epic healthcare systems', 'Familiarly with the Systems/Software Development Life Cycle', 'Experience with Agile software development']",2020-12-30 23:37:55
Data Engineer,Cognitio,N/A,"McLean, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop complex data flows, or makes significant enhancements to existing pipelines.', 'Resolves complex hardware/software compatibility and interface design considerations.', 'Conducts investigations and tests of considerable complexity.', 'Researches emerging technologies to determine impact on application execution.', 'Provides input to staff involved in writing and updating technical documentation.', 'Troubleshoots complex problems and provides customer support for the ETL process', 'Advises hardware engineers on machine characteristics that affect software systems, such as storage capacity, processing speed, and input/output requirements.', 'Prepares reports on analyses, findings, and project progress.', 'Provides guidance and work leadership to less-experienced software engineers.', 'May serve as a technical team or task leader.', 'Candidate must have an active TS/SCI Full Scope Polygraph.', 'Bachelor’s Degree in Computer Science, Electrical or Computer Engineering or a related technical discipline, or the equivalent combination of education, technical training, or work/military experience', '10+ years of related software engineering and ETL experience.', 'Experience building and maintaining data flows in NiFi or Pentaho.', 'Excellent organizational, coordination, interpersonal and team building skills.', 'Experience with the following languages: Java/J2EE, C, C++, SQL, XML, XQuery, XPath, Ruby on Rails, HTML/XHTML, CSS, Python, Shell Scripting, JSON', 'Knowledge of servers operating systems; Windows, Linux, Distributed Computing, Blade Centers, and cloud infrastructure', 'Strong problem solving skills', 'Ability to comprehend database methodologies', 'Focus on continual process improvement with a proactive approach to problem solving', 'Ability to follow directions and finish task']",2020-12-30 23:37:55
Cloud Data Engineer,Opinior,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Google Cloud Platform: 1 year (Required)US work authorization (Required)Bachelor's (Preferred)"", 'Experience in building solution architecture, provision infrastructure, secure and reliable data-centric services and application in GCP or Azure or AWS or on one of the prominent cloud platforms', 'Work with data team to efficiently use Hadoop/Cloud infrastructure to analyze data, build models, and generate reports/visualizations', 'Integrate massive datasets from multiple data sources for data modelling', 'Implement methods for automation of all parts of the predictive pipeline to minimize labor in development and production', 'Formulate business problems as technical data problems while ensuring key business drivers are captured in collaboration with product management', 'Knowledge in machine learning algorithms especially in recommender systems', 'Extracting, Loading, Transforming, cleaning, and validating data', 'Designing pipelines and architectures for data processing', 'Creating and maintaining machine learning and statistical models', 'Querying datasets, visualizing query results and creating reports', 'Minimum 3 year of designing, building and operationalizing large-scale enterprise data solutions and applications using one or more of GCP data and analytics services in combination with 3rd parties - Spark, Cloud DataProc, Cloud Dataflow, Apache Beam, BigTable, Cloud BigQuery, Cloud PubSub, Cloud Functions, etc.', 'Minimum 1 year of hands-on experience analyzing, re-architecting and re-platforming on-premise data warehouses to data platforms on cloud using 3rd party services', 'Minimum 1 year of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java, Python, Scala etc.', 'Minimum 1 year of designing and implementing data engineering, ingestion and curation functions on cloud using native or custom programming', 'Minimum 1 year of experience in performing detail assessments of current state data platforms and creating an appropriate transition path to cloud', 'Hands-on Cloud experience with a minimum of 1 solution designed and implemented at production scale', ""Bachelor's degree or equivalent (minimum 12 years) work experience. If Associate Degree, must have minimum 6 years work experience"", 'Minimum 1 year of architecting and implementing next generation data and analytics platforms on GCP cloud', 'Minimum 1 year of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders', '1 year of hands-on experience designing and implementing data ingestion solutions on GCP using GCP native services or with 3rd parties such as Talend, Informatica', '1 year of hands-on experience architecting and designing data lakes on GCP cloud serving analytics and BI application integrations', 'Minimum 1 year of experience in designing and optimizing data models on GCP cloud using GCP data stores such as BigQuery, BigTable', 'Minimum 1 year of experience integrating GCP or 3rd party KMS, HSM with GCP data services for building secure data solutions', 'Minimum 1 year of experience introducing and operationalizing self-service data preparation tools (e.g. Trifacta, Paxata) on GCP', 'Minimum 1 year of architecting and operating large production Hadoop/NoSQL clusters on premise or using Cloud services', 'Minimum 1 year of architecting and implementing metadata management on GCP', 'Architecting and implementing data governance and security for data platforms on GCP', 'Designing operations architecture and conducting performance engineering for large scale data lakes a production environment', 'Craft and lead client design workshops and provide tradeoffs and recommendations towards building solutions', '2+ years of experience writing complex SQL queries, stored procedures, etc', 'Google Cloud Platform certification is a plus', 'Excellent communication (written and oral) and interpersonal skills', 'Proven ability to work creatively and analytically in a problem-solving environment', 'GC holder/Citizens only', '401(k)', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', ""Bachelor's (Preferred)"", 'Google Cloud Platform: 1 year (Required)', 'Google Cloud Certification (Required)', 'Fully Remote', 'A “Fair Chance” job (you or the employer follow Fair Chance hiring practices when performing background checks)', 'Waiting period may apply', 'Only full-time employees eligible', 'Remote interview process', 'Virtual meetings']",2020-12-30 23:37:55
Senior Composites Design and Manufacturing Engineer,TIGHITCO,2.9 out of 5 from 72 employee ratings,"Ladson, SC 29456","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Composites Design and Manufacturing Engineer, 10 years (Required)', 'Perform composite ply development and ply nesting for the programs within the company using CATIA V5, CPX composites design and TruComposites software.', 'Create laser programs for structures within the company using LPX software.', 'Work hands-on with composite lay-up and bonding personnel in the fabrication of composite and metal bond parts and assemblies.', 'Provide technical support and guidance to lay-up and bonding personnel in the fabrication of composite and metal bond parts', 'Ability to conduct and oversee standard mechanical and physical testing of composite materials in accordance with ASTM and aerospace industry specifications.', 'Provide technical material, process, and design assistance to the manufacturing departments within the', 'Responsible for composite material qualifications and to develop and implement test plans within the company.', 'Determine test methods and procedures in conjunction with customers and or material suppliers.', 'Lead and participate in Kaizan events to solve production/operations problems.', 'Evaluate adhesives, primers, processing techniques and materials for use within the company.', 'Interface with customers on materials and processes issues.', 'Provide technical input to assist in the fabrication of tooling and the resolution of tooling issues.', 'Lead or assist in customer audits (NADCAP, AS9100, etc.).', 'Develop manufacturing processes (Bill of Materials, Work Instructions, Travelers) for sheet metal and composite parts fabrication to customer requirements using customer supplied data (drawing, mylars and tooling). Must meet job release deadlines.', 'Lead/Support root cause and corrective action teams.', 'Confers with vendors to determine product specifications and arrange for purchase of equipment, materials, or parts, and evaluates products according to specifications and quality standards.', 'Confers with management, engineering, and other staff regarding manufacturing capabilities, production schedules, and other considerations to facilitate production processes.', 'Conducts research into and development of innovative processing and fabrication techniques in the application of advanced composite materials (graphite/polyimide, graphite /epoxy, graphite/bismaleimide, thermoplastics) honeycomb cores and adhesives to aerospace structures and vehicles.', 'This position must meet Export Control compliance requirements, therefore a “US Person” as defined by 22 C.F.R. §120.15 is required', 'Must be “Hands On”.', 'Must be proficient and have extensive experience with CATIA V5, CPX and TruComposites software.', 'Must be proficient and have extensive experience with laser projection programming and LPX software.', 'Possess a background and knowledge in composite materials and processes (graphite/polyimide, graphite /epoxy, graphite/bismaleimide, thermoplastics, honeycomb cores and adhesives) used in aerospace structures and vehicles.', 'Knowledge of industry practices and standards, with a focus on the fabrication, qualification, and testing of composite materials', 'Possess strong organizational and planning abilities.', 'Be a self-starter and be able to work independently with minimal oversight.', 'Must be able to read and understand blueprints and process specifications.', 'Must be familiar with the engineering and processing of composites and bonding processes for both metals and composites.', 'Meets commitments, is high energy, self-motivated, works independently, accepts accountability, handles changes, sets personal standards, stays focused under pressure, meets attendance/punctuality requirements.', 'Ability to work constructively with a team of manufacturing and quality personnel, engineers and technicians.', 'Ability to read, analyze, and interpret general business periodicals, professional journals, technical procedures, or governmental regulations. Ability to write reports, business correspondence, and procedure manuals.', 'Ability to write test plans and technical reports.', 'Ability to effectively present information and respond to questions from groups of managers, clients, customers, and the general public.', 'Ability to work with mathematical concepts such as probability and statistical inference, and fundamentals of plane and solid geometry and trigonometry.', 'Ability to apply concepts such as fractions, percentages, ratios, and proportions to practical situations.', 'Ability to solve technical and practical problems and deal with a variety of concrete variables in situations where only limited standardization exists. Ability to interpret a variety of instructions furnished in written, oral, diagram, or schedule form.', 'Ability to use Excel, Word, PowerPoint, and Project Software', 'In addition, having knowledge of Epicor software is desired', '8 hour shift', 'Composites Design and Manufacturing Engineer: 10 years (Required)']",2020-12-30 23:37:55
Data Engineer,Capital One,"3.9 out of 5 from 9,133 employee ratings","Plano, TX 75023","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-12-30 23:37:55
Data Analytics Engineer - TechOps (Remote),CrowdStrike,3 out of 5 from 14 employee ratings,"Sunnyvale, CA 94086","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:37:55
Data Engineer,Sony Interactive Entertainment PlayStation,3.7 out of 5 from 127 employee ratings,"San Diego, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Engineer data pipelines and provide automated solutions for GPFM teams', 'System monitoring and alerting, dashboards, charts/reports and alerts delivery', 'Document processes, architecture of systems/data flows, project plans, using the agile methodology', 'Create training materials/presentations and present slides to variety of audiences, from highly technical peers to executive management', 'Mentor team members, sharing the workloads, enabling the team to grow', 'Participate in hiring, interviewing, developing tests, reviewing (pre-screening) candidates', 'Demonstrate an outstanding work ethic', 'Finds issues and appropriately and expertly raises tickets within/without the team', 'Solve sophisticated problems through highly creative methods', 'Use cloud technologies to provide robust solutions and learn new tools/systems as they emerge', 'Passion for protecting Sony and its customers', 'BS Degree in Engineering, Computer Science or equivalent experience.', '5+ years of experience in database development, programming, design, and analysis.', 'Solid experience with data', 'Files formats - csv, xml, json, avro', 'SQL skills - writing, reading, tuning, debugging', 'Data table design skills – DDL & DML', 'Understanding SQL execution', 'Demonstrable understanding of coding and scripting languages - Java, Python, JavaScript, bash, batch files', 'General knowledge in Linux, Unix Administration and Windows Administration', 'File ownership and permissions', 'Users, access/authentication, and encryption/ssh', 'Experience with automation, configuration management, enterprise schedulers', 'Big Data- Snowflake, Hadoop, Athena, HBase, Solr, Kafka, Cassandra, Oracle Exadata', 'Reporting/BI Tools – Tableau/Splunk/QlikView', 'Basic Knowledge of Payments Processing and CNP (Card Not Present) Fraud', 'Streams – Kinesis/Kafka/ActiveMQ', 'Cloud- Common Services, AMIs, instances, automation (Packer/Ansible/Chef/Puppet), Docker etc.', 'Direct identifiers such as your first and last name.Indirect identifiers such as a government ID, your Social Security, work permit or passport #.Contact information such as your email address, mailing address, telephone number.', 'Sensitive/Protected Data. During the recruitment process, you may (voluntarily) provide us with your ethnicity, gender, military service information, or physical or mental health information, as well as your national origin and citizenship.', 'Professional or job position-related information, including your past professional experience, references; background verification; talent management and assessment; information regarding any conflicts of interests; and the terms and conditions of your job offer.', 'Non-public education information, including information about your education records, such as grades and transcripts.']",2020-12-30 23:39:41
ETL Big Data Engineer,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Columbus, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'BS/BA degree or equivalent experience.', 'Proficiency in one or more modern programming languages AbInitio, BigData ecosystem in Spark, hdfs architechture, Linux OS and scripting, Control-M, Oracle DB).', 'Understanding of software skills such as business analysis, development, maintenance and software improvement.', 'In depth grasp of the various components of the Ab Initio ETL toolset.', 'Creation of ETL pipelines to validate, enrich and persist data.', 'Operational knowledge of operating systems such as Linux/AIX.', 'Demonstrable ability to use UNIX shell scripting.', 'Ability to work in an Agile development environment.', 'Must have hands on experience with ETL using Ab Initio of at least 5+ years.', 'Must have 1+ years of hands on Spark development experience using Scala and/or Java.', 'Advanced knowledge of application, data and infrastructure architecture disciplines.', 'Understanding of architecture and design across all systems.', 'Working proficiency in developmental toolsets.', 'Knowledge of industry wide technology trends and best practices.', ""Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture.JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.""]",2020-12-30 23:39:41
Data Engineer - GCI Analytics,McKinsey & Company,4.3 out of 5 from 578 employee ratings,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Degree in a quantitative discipline (typically management information systems, information technology, computer systems) and/or certifications', 'Experience in information technology is preferred; including ETL, data warehousing, decision support systems, business systems analysis, business intelligence analysis, QA, data hygiene, meta-data and master data-management', 'SQL experience is required, AWS Redshift or other extensive database experience is a plus', 'Knowledge of reporting tools and technologies (e.g. Tableau, QlikView, Microstrategy, D3) is a plus', 'Experience developing and monitoring products on Cloud platforms like AWS is a plus', 'Self-starter and able to manage own high-capacity workload as defined by other team members', 'Able to manage multiple projects & delivery schedules under tight delivery timelines', 'Strong multi-tasking abilities, flexibility, and patience in a fluid environment', 'Ability to offer a consultative approach to solve technical problems', 'Strong written and verbal communication skills', 'Professional attitude and service orientation; team player']",2020-12-30 23:39:41
"Data Product Engineer, Revenue Science",Twitter,4.1 out of 5 from 90 employee ratings,"Los Angeles, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Building a Petabyte-scale Data Warehouse (Google Cloud Next '18)"", ""How Twitter Migrated its On-Prem Analytics to Google Cloud (Google Cloud Next '18)"", 'Strong programming and algorithmic skills', 'Experience with data processing (such as Hadoop, Spark, Pig, Hive, MapReduce etc).', 'Proficiency with SQL (Relational, Redshift, Hive, Presto, Vertica)', 'Data Modeling and ER models', 'Ability in managing and communicating data project plans and requirements to internal clients', 'Experience writing Big Data pipelines, as well as custom or structured ETL, implementation and maintenance', 'Experience with large-scale data warehousing architecture and data modeling', 'Proficiency with Java, Scala, or Python', 'Experience with GCP (BigQuery, BigTable, DataFlow)', 'Experience with Druid or Apache Flink', 'Experience with real-time streaming (Apache Kafka, Apache Beam, Heron, Spark Streaming)']",2020-12-30 23:39:41
Research Associate,Construction Journal,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Heavy outbound calling to owners, architects, engineers, and general contractors to obtain specific construction project information.', 'Developing relationships with Construction Managers, Architects, and Engineers to obtain notice of construction projects in conception and planning phases.', 'Collect, process, and input information provided from private sources and public offices of zoning notices, site plan approvals, newspaper articles for potential construction projects being considered.', 'Obtaining, plans, specifications, and bidders/plan holders list on out to bid projects.', 'Computer Proficiency with ability to type 55 WPM.', 'Professional work ethic and can-do attitude.', 'Excellent written and verbal communication skills.', 'Strong organizational skills with the ability to meet daily and weekly deadlines.', 'Tenacity in overcoming obstacles while developing positive working relationships.', 'Ability to work independently in a fast-paced environment that also requires strong team work.', 'Advanced education preferred or industry work experience.', 'Knowledge in the construction industry is a plus, but is not a requirement.']",2020-12-30 23:39:41
Data Engineer,The Hartford,"3.7 out of 5 from 1,824 employee ratings","Hartford, CT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Design and develop high quality, scalable software modules for next generation analytics solution suite', 'Prototype high impact innovations, catering to changing business needs, by learning and leveraging new technologies (AWS Cloud, Big Data, Snowflake).', 'Integrate with Data Quality Services to ensure Quality data is Published to consumers.', 'Possesses functional knowledge and skills reflective of a competent practitioner with the ability to deliver on work of varying technical complexity', 'Consults with functional management in the analysis of short and long-range business requirements and recommends innovations which anticipate the future impact of changing business needs', 'Works closely with client management to identify and specify the complex business requirements and processes for diverse development platforms, computing environments (e.g., Cloud, host based, distributed systems, client server), software, hardware, technologies and tools', 'Coordinate activities with cross-functional IT unit stakeholders (e.g., database, operations, telecommunications, technical support, etc.)', 'Researches and evaluates alternative solutions and recommends the most efficient and cost effective solution for the systems design', 'Work within a self-organized scrum development team regarding all design and implementation', 'Bachelor degree with at least 2 years of applicable work experience or equivalent', 'Experience in ETL / Data Integration Technologies', 'Knowledge of Oracle Exadata , Unix/Linux Shell scripting, Autosys, Version Control Tools', 'Data warehouse applications knowledge in insurance domain', 'Efficient scripting skills in languages like JavaScript, Python, PHP', 'Experienced in Agile and Kanban Methodologies', 'Understanding of current and emerging IT products, services, processes and methodologies.', 'Analytical approach with a strong ability to uncover and resolve problems by delivering innovative approaches and solutions.', 'Ability to develop and maintain systems according to a defined set of standards.', 'Ability to set and manage own priorities effectively in a dynamic organization.', 'Ability to work as part of and with high performing teams.', 'Big Data / Cloud (AWS)/ Talend Cloud Snowflake Technologies experience', 'Experience deeper understanding of Data analysis, emerging technologies and development practices.', 'Collaboration with a high-performing, forward-focused team, Product Owner(s) and Business stakeholder(s) engagement.', 'Opportunity to expand your communication, analytical, interpersonal, and organization capabilities.', 'Enable and influence the timely and successful delivery of business data capabilities and/or technology objectives.', 'Hone your development capabilities using various tools to enhance and build assets that enable business value generation.', 'Appreciation and opportunity to learn and support rapid software construction and deployment using a mix of technologies.', 'Supporting environment that fosters can-do attitude and opportunity for growth and advancement based on consistent demonstrative performance.', 'Optimize business value by leveraging your Data experience and depth.', 'Be part of a Scrum Team – driving work independently and collaboratively towards achieving business outcomes.']",2020-12-30 23:39:41
Cloud Data Platform DevOps Engineer - 12+ Months - Remote Opportunity,TMS LLC,N/A,"Richmond, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:39:41
Data Engineer (Datastage),IBM,"3.9 out of 5 from 30,506 employee ratings","Research Triangle Park, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Communicate work to and receive feedback by technical and non-technical audiences', 'Work with business partners to develop strategies and value from our datasets', 'Implement scalable cutting-edge solutions with machine learning and models', 'Develop POCs with quick turnaround to suffice the needs of business stakeholders', 'Leverage data management processes, available infrastructures, and API tools to develop codebases and solutions', 'Collaborate with engineers, stakeholders, and other team members to establish an analytics platform or/and standard procedures for use across the business', 'Using and improving System to accurately and efficiently identify risk based on multiple data sets and data points (e.g., person, location, activity)', 'Designing, developing and testing data analysis/collection and visualization applications in programming language(s) of choice', 'Communication and Interpersonal Skills', 'Understanding of Data modelling and schema design', 'Problem-Solving Intellect, particularly challenging real-world problems', '5+ years of experience as data professional (big data solutions)', '5+ years experience in statistical methods (e.g., correlations and regressions, anova, resampling, effect size)', 'Machine-learning Techniques (e.g., clustering, decision trees, nearest-neighbors, support vector classifiers, ensemble methods, collaborative filtering)', 'Algorithm Development in main languages to our business such as Python, Scala, and Spark', 'Demonstrate knowledge of a cross section of tools and techniques relating to support of large-scale data analysis', 'Proven understanding and proficiency of database administration and data structures', 'Significant concentration in a quantitative field', 'Demonstrated skill in AWS, NoSQL Systems, or/and Spark especially', 'Algorithm Development in additional languages (e.g., R, Java, Javascript, Bash Scripts)', 'Experience with Agile/Scrum methodologies/development – ability to accurately size user stories']",2020-12-30 23:39:41
Data Integration Engineer,Support.com,2.6 out of 5 from 560 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', ""Reducing customer effort through advanced tools embeddable in mobile and web apps. We embed in customer's support sites as well as our own full-service support offering."", 'Optimizing the interaction of support agents with customers via intelligent, contextual guidance; data-driven, step-by-step solutions; and modern visual remote tools', 'Providing actionable insights into support practices and real-world product performance through support interaction analytics', 'Use a cutting-edge data stack built on Snowflake, Fivetran, S3, PostgreSQL, and Python.', ""We love collaborative, agile software development, iterative design and testing. We form tight teams, build rapid prototypes and release frequently. You won't get bored!"", ""We encourage learning and integration of new technologies. If you're passionate about technology, we'd love to hear your story."", 'Support.com is a public company, with mature products established in the marketplace and continued innovation in support technology software.', 'Build, maintain and deploy the integration infrastructure for ingesting high-volume support data from consumer interactions, devices, and apps across a myriad collection of software solutions.', ""Design and implement the processes that turn data into insights. Model and mine the data to describe the system's behavior and to predict future actions."", 'Develop and maintain the data-related code in an automated CI/CD build/test/deploy environment', 'Research individually and in collaboration with other teams on how to solve problems', 'B.E/BTech/MCA/MTech/M. E from an accredited university or college (domestic or international).', '5+ years of experience working in a consumer internet or software company is required and 3+ years of relevant work experience; but, really, we are open to any developer that has the technical prowess', 'Excellent programming skills in Python with bonus points for Java, JavaScript, or Scala experience', 'Direct experience with some of the following; Snowflake, Fivetran, S3, Apache Spark, Airflow, and PostgreSQL or substantially similar tools', 'Ability to understand business problems and translate them into technical requirements', 'A reliable and fast internet connection and stable power supply to enable work from home.', 'Ability to benchmark systems, analyze system bottlenecks and performance issues and design solutions to eliminate them.', 'Ability to evaluate and clearly articulate pris and cons of various technical approaches related to data gathering.', 'Ability to work effectively and collaboratively from home.', 'DevOps: Jenkins', 'Experience with a modern Big Data processing stack including Fivetran, Kafka, Kinesis or equivalent technologies', 'Strong knowledge of traditional Data Warehouse-related components (Sourcing, ETL, Data Modeling, Infrastructure, BI, Reporting)', 'Competitive benefits and compensation!', 'A flexible but challenging work from home experience!', 'Ability to work with exceptionally creative and talented people!']",2020-12-30 23:39:41
Entry Level Business Analyst,Cloudinfraspecs,N/A,"Los Angeles, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Business analysts are responsible for working with management to improve operating procedures, reduce costs and inefficiencies, and achieve better performance.', 'Responsible for developing the processes and policies for effective monitoring and tracking of the project goal', 'Analyze data sources across multiple databases and software platforms.', 'Responsible for following SDLC (Software Development Life Cycle) methodology such as Waterfall, Agile.', 'May recommend solutions based on data analysis to increase business efficiency.', 'Support the team with inventory processing and analysis', 'Interact with Development Engineers and QA Analysts', 'Bachelors or Master’s degree', '0-1 of year experience', 'Fluency in MS Excel', 'Strong attention to detail as well as strong written and oral communication skills', 'Ability to multitask, set priorities and work efficiently in a high-paced environment', 'Monday to Friday', ""Bachelor's (Preferred)""]",2020-12-30 23:39:41
Healthcare Data Engineer,"Amino, Inc.",N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""You'll build and maintain a first-class data infrastructure, that supports a continuous delivery of data from many disparate sources to serve a wide-variety of analytical and product needs."", ""You'll influence the fundamentals of how we model and warehouse data that is accessed by most teams across the company."", 'Collaborate with a data-focused Product Manager to improve the coverage and accuracy of our data products.', ""Refine the conceptual model for Amino's entity, and storage patterns and policies for interacting with them."", 'Work closely with the Data Science team to define new entities, relationships, and insights, and help define technical patterns for how we bridge the gap from initial analyses in notebooks to reliable and automatic production processes.', 'Communicate with team members in Data Science, Product Engineering, Marketing, and Leadership to help understand and support their needs.', 'You will work with the following technologies (experience with them all is not necessary, but you should be interested in using or learning them): Python 3.6, Scientific Python, Jupyter; Snowflake, PostgreSQL, Elasticsearch, Redis; AWS, Terraform, Kinesis, S3, RDS, Elasticache, Lambda, Cloudwatch Logs; Git, Docker, Jenkins CI/CD; Spark, Databricks.', 'Integrate new vendor and internal sources of data into our ETL pipelines.', 'Build out the next generation of our editorial tools to create and correct data about health entities.', 'Operationalize our healthcare cost statistical and machine learning models.', 'Greenfield new projects with processing streaming analytics data from our banking and transparency products.', 'Deep experience in the healthcare domain, specifically dealing with healthcare claims data.', ""You're experienced with a variety of relational and non-relational databases. (We primarily use Snowflake, PostgreSQL, Elasticsearch, and Redis.)"", 'You are comfortable writing clean, well-tested code in Python.', 'You have experience handling and working with large datasets and the tools to manage them.', 'You have worked with ETL pipelines before and are familiar with data warehousing best practices.', 'You value and practice collaboration and feedback. You question and seek feedback on your own work and opinions.', 'Your documentation and verbal communication skills are excellent. You can communicate technical vision in clear terms to your peers as well as outside of the engineering team.', 'Experience with Apache Airflow and DBT are a plus.', 'Read note from our CTO on the people-centric processes we have adopted.', 'Read about our Ethics.', 'Check to see if you know an Amino teammate on LinkedIn.', 'To get a sampling of the sort of data and analyses we work with, check out some of our data storytelling:How we put a Price Tag on HospitalsAnd, for fun: Strange (yet surprisingly common) holiday injuries, according to medical billing codes']",2020-12-30 23:39:41
Data Engineer (USA),ITTStar Consulting LLC,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'United States America', 'full time', '40h / week', '3 years experience', 'Master or Bachelor', 'Skills RequiredPrimary Skills :- AWS, EC2, EMR, Glue, Lambda, Python, Redshift, S3, SparkSecondary Skills :- Hadoop, HBase, Hive', 'M.E/M.Tech/B.E/B.Tech/MCA/MSc or similar 4 or 4+ years degree in relevant field.', 'At least 3+ years of hands on experience onAWS [S3, EC2, ECS, EMR, GLUE, Redshift, Lambda, Dynamo DB , Kinesis, RDS, Data Pipeline etc]', 'At least 3+ years of hands on experience with Big Data stack includingSparkHadoopHiveKafkaHBase or other NoSQL solutions', 'Strong knowledge and handson experience in writing highly optimized and if required complex queries. [Oracle/Postgres /MySQL/ SQLServer etc]', 'Strong Python Programming knowledge from Data Engineering perspective. Good knowledge on libs likePandasNumpyMatlabplotSeabornScikitLearn etc', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets', 'Strong project management and organizational skills.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Good Communication Skills.']",2020-12-30 23:39:41
Distinguished Data Engineer - Director,Capital One - US,"3.9 out of 5 from 9,133 employee ratings","Vienna, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices', 'Visionaries, collaborating on Capital One’s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates', 'Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community', 'Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities', 'Leaders who gain the trust and confidence of those around them, from hands on engineers to executives', 'Design and develop cutting-edge solutions, using existing and emerging technology platforms used to deliver and optimize data enterprise services', 'Provide technical leadership, evaluation and recommendations for data consumption engines and new technologies that can be used to advance new features and capabilities around analytics and use derived data sets', 'Leverage sound judgment and problem solving to tackle some of Capital One’s most critical problems and connect the dots to broader implications of the work', 'Build awareness, increase knowledge and drive adoption of modern technologies and architecture patterns, sharing customer and engineering benefits to gain buy-in', 'Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team', 'Promote a culture of engineering excellence and being well-managed, using opportunities to reuse and innersource solutions where possible', 'Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization', 'Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an integrated manner', 'Design, architect, and help implement a recommendation engine to help Capital One engineering teams comply with open source software version policies and procedures', 'Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an integrated manner', 'Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent', 'Bachelor’s Degree', 'At least 7 years of data engineering experience', 'At least 5 years of experience developing in Spark, Python, SQL, Java, or Scala', 'At least 2 years of experience with data science Notebooks (Jupyter, Zeppelin, or RStudio)', 'Masters’ Degree', '15+ years of data engineering experience', '10+ years of data governance and security controls', '8+ years of data architecture design', '4+ years of experience with workflow automation', '4+ years of experience with AWS', '2+ years of experience with Databricks and Presto']",2020-12-30 23:39:41
Data Center Engineer,UPPER LLC,N/A,"Minneapolis, MN 55401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'data center: 1 year (Required)', 'On call', 'data center: 1 year (Required)', 'A good fit for applicants with gaps in their resume, or who have been out of the workforce for the past 6 months or more', 'A job for which all ages, including older job seekers, are encouraged to apply', 'www.upper.services', 'Remote interview process']",2020-12-30 23:39:41
Business Intelligence Engineer,"Healthwise, Incorporated",3.2 out of 5 from 5 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Builds software to extract, transform and load data – SSIS and Azure Data Factories.', 'Models data for efficient consumption by reporting and analytics tools – Azure Analysis Services and Power BI Platform.', 'Maintains previously deployed software and reports – Power BI, SSIS, AAS, SQL Server.', 'Designs dashboards and reports to meet business needs – Power BI.', 'Independently discovers solutions and collaborates on insights and best practices.', 'Evaluates and implements Azure services best fit to project requirements.', 'Bachelor’s Degree in Information Systems, Computer Science, or equivalent.', 'Experience with Standard Query Language (SQL) and database design.', 'Experience with Data Analysis Expressions (DAX).', 'Understanding of data integration engines such as SQL Server Integration Services (SSIS) or Azure Data Factories.', 'Experience delighting users and customers with work well done.', 'All offers are contingent upon the completion of a background check.', 'Experience with data engineering in a cloud development - Microsoft Azure is preferred.', 'Understanding of star schema design and managing large data volumes.', 'Familiarity with data science and machine learning capabilities.', 'Experience with self-service query tools and dashboards - preferably Power BI.', 'Experience protecting individual privacy such as required by HIPAA.']",2020-12-30 23:39:41
ETL Big Data Engineer,"JPMorgan Chase Bank, N.A.","3.9 out of 5 from 8,581 employee ratings","Columbus, OH","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'BS/BA degree or equivalent experience.', 'Proficiency in one or more modern programming languages AbInitio, BigData ecosystem in Spark, hdfs architechture, Linux OS and scripting, Control-M, Oracle DB).', 'Understanding of software skills such as business analysis, development, maintenance and software improvement.', 'In depth grasp of the various components of the Ab Initio ETL toolset.', 'Creation of ETL pipelines to validate, enrich and persist data.', 'Operational knowledge of operating systems such as Linux/AIX.', 'Demonstrable ability to use UNIX shell scripting.', 'Ability to work in an Agile development environment.', 'Must have hands on experience with ETL using Ab Initio of at least 5+ years.', 'Must have 1+ years of hands on Spark development experience using Scala and/or Java.', 'Advanced knowledge of application, data and infrastructure architecture disciplines.', 'Understanding of architecture and design across all systems.', 'Working proficiency in developmental toolsets.', 'Knowledge of industry wide technology trends and best practices.', ""Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture.JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.""]",2020-12-30 23:41:22
Data Engineer - GCI Analytics,McKinsey & Company,4.3 out of 5 from 578 employee ratings,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Degree in a quantitative discipline (typically management information systems, information technology, computer systems) and/or certifications', 'Experience in information technology is preferred; including ETL, data warehousing, decision support systems, business systems analysis, business intelligence analysis, QA, data hygiene, meta-data and master data-management', 'SQL experience is required, AWS Redshift or other extensive database experience is a plus', 'Knowledge of reporting tools and technologies (e.g. Tableau, QlikView, Microstrategy, D3) is a plus', 'Experience developing and monitoring products on Cloud platforms like AWS is a plus', 'Self-starter and able to manage own high-capacity workload as defined by other team members', 'Able to manage multiple projects & delivery schedules under tight delivery timelines', 'Strong multi-tasking abilities, flexibility, and patience in a fluid environment', 'Ability to offer a consultative approach to solve technical problems', 'Strong written and verbal communication skills', 'Professional attitude and service orientation; team player']",2020-12-30 23:41:22
"Data Product Engineer, Revenue Science",Twitter,4.1 out of 5 from 90 employee ratings,"Los Angeles, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Building a Petabyte-scale Data Warehouse (Google Cloud Next '18)"", ""How Twitter Migrated its On-Prem Analytics to Google Cloud (Google Cloud Next '18)"", 'Strong programming and algorithmic skills', 'Experience with data processing (such as Hadoop, Spark, Pig, Hive, MapReduce etc).', 'Proficiency with SQL (Relational, Redshift, Hive, Presto, Vertica)', 'Data Modeling and ER models', 'Ability in managing and communicating data project plans and requirements to internal clients', 'Experience writing Big Data pipelines, as well as custom or structured ETL, implementation and maintenance', 'Experience with large-scale data warehousing architecture and data modeling', 'Proficiency with Java, Scala, or Python', 'Experience with GCP (BigQuery, BigTable, DataFlow)', 'Experience with Druid or Apache Flink', 'Experience with real-time streaming (Apache Kafka, Apache Beam, Heron, Spark Streaming)']",2020-12-30 23:41:22
Research Associate,Construction Journal,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Heavy outbound calling to owners, architects, engineers, and general contractors to obtain specific construction project information.', 'Developing relationships with Construction Managers, Architects, and Engineers to obtain notice of construction projects in conception and planning phases.', 'Collect, process, and input information provided from private sources and public offices of zoning notices, site plan approvals, newspaper articles for potential construction projects being considered.', 'Obtaining, plans, specifications, and bidders/plan holders list on out to bid projects.', 'Computer Proficiency with ability to type 55 WPM.', 'Professional work ethic and can-do attitude.', 'Excellent written and verbal communication skills.', 'Strong organizational skills with the ability to meet daily and weekly deadlines.', 'Tenacity in overcoming obstacles while developing positive working relationships.', 'Ability to work independently in a fast-paced environment that also requires strong team work.', 'Advanced education preferred or industry work experience.', 'Knowledge in the construction industry is a plus, but is not a requirement.']",2020-12-30 23:41:22
Data Engineer,The Hartford,"3.7 out of 5 from 1,824 employee ratings","Hartford, CT","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Design and develop high quality, scalable software modules for next generation analytics solution suite', 'Prototype high impact innovations, catering to changing business needs, by learning and leveraging new technologies (AWS Cloud, Big Data, Snowflake).', 'Integrate with Data Quality Services to ensure Quality data is Published to consumers.', 'Possesses functional knowledge and skills reflective of a competent practitioner with the ability to deliver on work of varying technical complexity', 'Consults with functional management in the analysis of short and long-range business requirements and recommends innovations which anticipate the future impact of changing business needs', 'Works closely with client management to identify and specify the complex business requirements and processes for diverse development platforms, computing environments (e.g., Cloud, host based, distributed systems, client server), software, hardware, technologies and tools', 'Coordinate activities with cross-functional IT unit stakeholders (e.g., database, operations, telecommunications, technical support, etc.)', 'Researches and evaluates alternative solutions and recommends the most efficient and cost effective solution for the systems design', 'Work within a self-organized scrum development team regarding all design and implementation', 'Bachelor degree with at least 2 years of applicable work experience or equivalent', 'Experience in ETL / Data Integration Technologies', 'Knowledge of Oracle Exadata , Unix/Linux Shell scripting, Autosys, Version Control Tools', 'Data warehouse applications knowledge in insurance domain', 'Efficient scripting skills in languages like JavaScript, Python, PHP', 'Experienced in Agile and Kanban Methodologies', 'Understanding of current and emerging IT products, services, processes and methodologies.', 'Analytical approach with a strong ability to uncover and resolve problems by delivering innovative approaches and solutions.', 'Ability to develop and maintain systems according to a defined set of standards.', 'Ability to set and manage own priorities effectively in a dynamic organization.', 'Ability to work as part of and with high performing teams.', 'Big Data / Cloud (AWS)/ Talend Cloud Snowflake Technologies experience', 'Experience deeper understanding of Data analysis, emerging technologies and development practices.', 'Collaboration with a high-performing, forward-focused team, Product Owner(s) and Business stakeholder(s) engagement.', 'Opportunity to expand your communication, analytical, interpersonal, and organization capabilities.', 'Enable and influence the timely and successful delivery of business data capabilities and/or technology objectives.', 'Hone your development capabilities using various tools to enhance and build assets that enable business value generation.', 'Appreciation and opportunity to learn and support rapid software construction and deployment using a mix of technologies.', 'Supporting environment that fosters can-do attitude and opportunity for growth and advancement based on consistent demonstrative performance.', 'Optimize business value by leveraging your Data experience and depth.', 'Be part of a Scrum Team – driving work independently and collaboratively towards achieving business outcomes.']",2020-12-30 23:41:22
Cloud Data Platform DevOps Engineer - 12+ Months - Remote Opportunity,TMS LLC,N/A,"Richmond, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:41:22
Data Engineer (Datastage),IBM,"3.9 out of 5 from 30,506 employee ratings","Research Triangle Park, NC","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Communicate work to and receive feedback by technical and non-technical audiences', 'Work with business partners to develop strategies and value from our datasets', 'Implement scalable cutting-edge solutions with machine learning and models', 'Develop POCs with quick turnaround to suffice the needs of business stakeholders', 'Leverage data management processes, available infrastructures, and API tools to develop codebases and solutions', 'Collaborate with engineers, stakeholders, and other team members to establish an analytics platform or/and standard procedures for use across the business', 'Using and improving System to accurately and efficiently identify risk based on multiple data sets and data points (e.g., person, location, activity)', 'Designing, developing and testing data analysis/collection and visualization applications in programming language(s) of choice', 'Communication and Interpersonal Skills', 'Understanding of Data modelling and schema design', 'Problem-Solving Intellect, particularly challenging real-world problems', '5+ years of experience as data professional (big data solutions)', '5+ years experience in statistical methods (e.g., correlations and regressions, anova, resampling, effect size)', 'Machine-learning Techniques (e.g., clustering, decision trees, nearest-neighbors, support vector classifiers, ensemble methods, collaborative filtering)', 'Algorithm Development in main languages to our business such as Python, Scala, and Spark', 'Demonstrate knowledge of a cross section of tools and techniques relating to support of large-scale data analysis', 'Proven understanding and proficiency of database administration and data structures', 'Significant concentration in a quantitative field', 'Demonstrated skill in AWS, NoSQL Systems, or/and Spark especially', 'Algorithm Development in additional languages (e.g., R, Java, Javascript, Bash Scripts)', 'Experience with Agile/Scrum methodologies/development – ability to accurately size user stories']",2020-12-30 23:41:22
Data Integration Engineer,Support.com,2.6 out of 5 from 560 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', ""Reducing customer effort through advanced tools embeddable in mobile and web apps. We embed in customer's support sites as well as our own full-service support offering."", 'Optimizing the interaction of support agents with customers via intelligent, contextual guidance; data-driven, step-by-step solutions; and modern visual remote tools', 'Providing actionable insights into support practices and real-world product performance through support interaction analytics', 'Use a cutting-edge data stack built on Snowflake, Fivetran, S3, PostgreSQL, and Python.', ""We love collaborative, agile software development, iterative design and testing. We form tight teams, build rapid prototypes and release frequently. You won't get bored!"", ""We encourage learning and integration of new technologies. If you're passionate about technology, we'd love to hear your story."", 'Support.com is a public company, with mature products established in the marketplace and continued innovation in support technology software.', 'Build, maintain and deploy the integration infrastructure for ingesting high-volume support data from consumer interactions, devices, and apps across a myriad collection of software solutions.', ""Design and implement the processes that turn data into insights. Model and mine the data to describe the system's behavior and to predict future actions."", 'Develop and maintain the data-related code in an automated CI/CD build/test/deploy environment', 'Research individually and in collaboration with other teams on how to solve problems', 'B.E/BTech/MCA/MTech/M. E from an accredited university or college (domestic or international).', '5+ years of experience working in a consumer internet or software company is required and 3+ years of relevant work experience; but, really, we are open to any developer that has the technical prowess', 'Excellent programming skills in Python with bonus points for Java, JavaScript, or Scala experience', 'Direct experience with some of the following; Snowflake, Fivetran, S3, Apache Spark, Airflow, and PostgreSQL or substantially similar tools', 'Ability to understand business problems and translate them into technical requirements', 'A reliable and fast internet connection and stable power supply to enable work from home.', 'Ability to benchmark systems, analyze system bottlenecks and performance issues and design solutions to eliminate them.', 'Ability to evaluate and clearly articulate pris and cons of various technical approaches related to data gathering.', 'Ability to work effectively and collaboratively from home.', 'DevOps: Jenkins', 'Experience with a modern Big Data processing stack including Fivetran, Kafka, Kinesis or equivalent technologies', 'Strong knowledge of traditional Data Warehouse-related components (Sourcing, ETL, Data Modeling, Infrastructure, BI, Reporting)', 'Competitive benefits and compensation!', 'A flexible but challenging work from home experience!', 'Ability to work with exceptionally creative and talented people!']",2020-12-30 23:41:22
Entry Level Business Analyst,Cloudinfraspecs,N/A,"Los Angeles, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Business analysts are responsible for working with management to improve operating procedures, reduce costs and inefficiencies, and achieve better performance.', 'Responsible for developing the processes and policies for effective monitoring and tracking of the project goal', 'Analyze data sources across multiple databases and software platforms.', 'Responsible for following SDLC (Software Development Life Cycle) methodology such as Waterfall, Agile.', 'May recommend solutions based on data analysis to increase business efficiency.', 'Support the team with inventory processing and analysis', 'Interact with Development Engineers and QA Analysts', 'Bachelors or Master’s degree', '0-1 of year experience', 'Fluency in MS Excel', 'Strong attention to detail as well as strong written and oral communication skills', 'Ability to multitask, set priorities and work efficiently in a high-paced environment', 'Monday to Friday', ""Bachelor's (Preferred)""]",2020-12-30 23:41:22
Healthcare Data Engineer,"Amino, Inc.",N/A,"San Francisco, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""You'll build and maintain a first-class data infrastructure, that supports a continuous delivery of data from many disparate sources to serve a wide-variety of analytical and product needs."", ""You'll influence the fundamentals of how we model and warehouse data that is accessed by most teams across the company."", 'Collaborate with a data-focused Product Manager to improve the coverage and accuracy of our data products.', ""Refine the conceptual model for Amino's entity, and storage patterns and policies for interacting with them."", 'Work closely with the Data Science team to define new entities, relationships, and insights, and help define technical patterns for how we bridge the gap from initial analyses in notebooks to reliable and automatic production processes.', 'Communicate with team members in Data Science, Product Engineering, Marketing, and Leadership to help understand and support their needs.', 'You will work with the following technologies (experience with them all is not necessary, but you should be interested in using or learning them): Python 3.6, Scientific Python, Jupyter; Snowflake, PostgreSQL, Elasticsearch, Redis; AWS, Terraform, Kinesis, S3, RDS, Elasticache, Lambda, Cloudwatch Logs; Git, Docker, Jenkins CI/CD; Spark, Databricks.', 'Integrate new vendor and internal sources of data into our ETL pipelines.', 'Build out the next generation of our editorial tools to create and correct data about health entities.', 'Operationalize our healthcare cost statistical and machine learning models.', 'Greenfield new projects with processing streaming analytics data from our banking and transparency products.', 'Deep experience in the healthcare domain, specifically dealing with healthcare claims data.', ""You're experienced with a variety of relational and non-relational databases. (We primarily use Snowflake, PostgreSQL, Elasticsearch, and Redis.)"", 'You are comfortable writing clean, well-tested code in Python.', 'You have experience handling and working with large datasets and the tools to manage them.', 'You have worked with ETL pipelines before and are familiar with data warehousing best practices.', 'You value and practice collaboration and feedback. You question and seek feedback on your own work and opinions.', 'Your documentation and verbal communication skills are excellent. You can communicate technical vision in clear terms to your peers as well as outside of the engineering team.', 'Experience with Apache Airflow and DBT are a plus.', 'Read note from our CTO on the people-centric processes we have adopted.', 'Read about our Ethics.', 'Check to see if you know an Amino teammate on LinkedIn.', 'To get a sampling of the sort of data and analyses we work with, check out some of our data storytelling:How we put a Price Tag on HospitalsAnd, for fun: Strange (yet surprisingly common) holiday injuries, according to medical billing codes']",2020-12-30 23:41:22
Data Engineer (USA),ITTStar Consulting LLC,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'United States America', 'full time', '40h / week', '3 years experience', 'Master or Bachelor', 'Skills RequiredPrimary Skills :- AWS, EC2, EMR, Glue, Lambda, Python, Redshift, S3, SparkSecondary Skills :- Hadoop, HBase, Hive', 'M.E/M.Tech/B.E/B.Tech/MCA/MSc or similar 4 or 4+ years degree in relevant field.', 'At least 3+ years of hands on experience onAWS [S3, EC2, ECS, EMR, GLUE, Redshift, Lambda, Dynamo DB , Kinesis, RDS, Data Pipeline etc]', 'At least 3+ years of hands on experience with Big Data stack includingSparkHadoopHiveKafkaHBase or other NoSQL solutions', 'Strong knowledge and handson experience in writing highly optimized and if required complex queries. [Oracle/Postgres /MySQL/ SQLServer etc]', 'Strong Python Programming knowledge from Data Engineering perspective. Good knowledge on libs likePandasNumpyMatlabplotSeabornScikitLearn etc', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets', 'Strong project management and organizational skills.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Good Communication Skills.']",2020-12-30 23:41:22
Distinguished Data Engineer - Director,Capital One - US,"3.9 out of 5 from 9,133 employee ratings","Vienna, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices', 'Visionaries, collaborating on Capital One’s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates', 'Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community', 'Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities', 'Leaders who gain the trust and confidence of those around them, from hands on engineers to executives', 'Design and develop cutting-edge solutions, using existing and emerging technology platforms used to deliver and optimize data enterprise services', 'Provide technical leadership, evaluation and recommendations for data consumption engines and new technologies that can be used to advance new features and capabilities around analytics and use derived data sets', 'Leverage sound judgment and problem solving to tackle some of Capital One’s most critical problems and connect the dots to broader implications of the work', 'Build awareness, increase knowledge and drive adoption of modern technologies and architecture patterns, sharing customer and engineering benefits to gain buy-in', 'Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team', 'Promote a culture of engineering excellence and being well-managed, using opportunities to reuse and innersource solutions where possible', 'Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization', 'Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an integrated manner', 'Design, architect, and help implement a recommendation engine to help Capital One engineering teams comply with open source software version policies and procedures', 'Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an integrated manner', 'Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent', 'Bachelor’s Degree', 'At least 7 years of data engineering experience', 'At least 5 years of experience developing in Spark, Python, SQL, Java, or Scala', 'At least 2 years of experience with data science Notebooks (Jupyter, Zeppelin, or RStudio)', 'Masters’ Degree', '15+ years of data engineering experience', '10+ years of data governance and security controls', '8+ years of data architecture design', '4+ years of experience with workflow automation', '4+ years of experience with AWS', '2+ years of experience with Databricks and Presto']",2020-12-30 23:41:22
Data Center Engineer,UPPER LLC,N/A,"Minneapolis, MN 55401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'data center: 1 year (Required)', 'On call', 'data center: 1 year (Required)', 'A good fit for applicants with gaps in their resume, or who have been out of the workforce for the past 6 months or more', 'A job for which all ages, including older job seekers, are encouraged to apply', 'www.upper.services', 'Remote interview process']",2020-12-30 23:41:22
Business Intelligence Engineer,"Healthwise, Incorporated",3.2 out of 5 from 5 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Builds software to extract, transform and load data – SSIS and Azure Data Factories.', 'Models data for efficient consumption by reporting and analytics tools – Azure Analysis Services and Power BI Platform.', 'Maintains previously deployed software and reports – Power BI, SSIS, AAS, SQL Server.', 'Designs dashboards and reports to meet business needs – Power BI.', 'Independently discovers solutions and collaborates on insights and best practices.', 'Evaluates and implements Azure services best fit to project requirements.', 'Bachelor’s Degree in Information Systems, Computer Science, or equivalent.', 'Experience with Standard Query Language (SQL) and database design.', 'Experience with Data Analysis Expressions (DAX).', 'Understanding of data integration engines such as SQL Server Integration Services (SSIS) or Azure Data Factories.', 'Experience delighting users and customers with work well done.', 'All offers are contingent upon the completion of a background check.', 'Experience with data engineering in a cloud development - Microsoft Azure is preferred.', 'Understanding of star schema design and managing large data volumes.', 'Familiarity with data science and machine learning capabilities.', 'Experience with self-service query tools and dashboards - preferably Power BI.', 'Experience protecting individual privacy such as required by HIPAA.']",2020-12-30 23:41:22
Big Data Engineer,CareLytix,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Current experience with the SMACK stack (Spark, Mesos, Akka, Cassandra, Kafka) as a holistic system, and the important considerations for running this system at scale.', 'Experience or understanding of developing machine/deep learning systems in a distributed environment.', 'Conventional backend development experience with Java and common frameworks (Spring, Play).', 'Experience with distributed systems and microservices.', 'experience high-speed messaging frameworks and streaming (Kafka, Akka, reactive)', 'Current experience developing and deploying applications to public cloud (AWS)', 'Scala experience highly recommended.', 'In-depth knowledge of relational database systems, performance tuning methods, knowledge of SQL and ER modeling.', 'Aptitude to independently learn new technologies, prototype and propose software design and solutions.', 'Experience with Scala and common machine learning libraries.', 'Experience with key administrative and development scripting languages such as Python, BASH, etc.', 'Knowledge of Git/SVN.', 'Expert knowledge of Linux']",2020-12-30 23:41:22
Data Center Engineer,UPPER LLC,N/A,"Minneapolis, MN 55401","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'data center: 1 year (Required)', 'On call', 'data center: 1 year (Required)', 'A good fit for applicants with gaps in their resume, or who have been out of the workforce for the past 6 months or more', 'A job for which all ages, including older job seekers, are encouraged to apply', 'www.upper.services', 'Remote interview process']",2020-12-30 23:43:03
Business Intelligence Engineer,"Healthwise, Incorporated",3.2 out of 5 from 5 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Builds software to extract, transform and load data – SSIS and Azure Data Factories.', 'Models data for efficient consumption by reporting and analytics tools – Azure Analysis Services and Power BI Platform.', 'Maintains previously deployed software and reports – Power BI, SSIS, AAS, SQL Server.', 'Designs dashboards and reports to meet business needs – Power BI.', 'Independently discovers solutions and collaborates on insights and best practices.', 'Evaluates and implements Azure services best fit to project requirements.', 'Bachelor’s Degree in Information Systems, Computer Science, or equivalent.', 'Experience with Standard Query Language (SQL) and database design.', 'Experience with Data Analysis Expressions (DAX).', 'Understanding of data integration engines such as SQL Server Integration Services (SSIS) or Azure Data Factories.', 'Experience delighting users and customers with work well done.', 'All offers are contingent upon the completion of a background check.', 'Experience with data engineering in a cloud development - Microsoft Azure is preferred.', 'Understanding of star schema design and managing large data volumes.', 'Familiarity with data science and machine learning capabilities.', 'Experience with self-service query tools and dashboards - preferably Power BI.', 'Experience protecting individual privacy such as required by HIPAA.']",2020-12-30 23:43:03
Big Data Engineer,CareLytix,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Current experience with the SMACK stack (Spark, Mesos, Akka, Cassandra, Kafka) as a holistic system, and the important considerations for running this system at scale.', 'Experience or understanding of developing machine/deep learning systems in a distributed environment.', 'Conventional backend development experience with Java and common frameworks (Spring, Play).', 'Experience with distributed systems and microservices.', 'experience high-speed messaging frameworks and streaming (Kafka, Akka, reactive)', 'Current experience developing and deploying applications to public cloud (AWS)', 'Scala experience highly recommended.', 'In-depth knowledge of relational database systems, performance tuning methods, knowledge of SQL and ER modeling.', 'Aptitude to independently learn new technologies, prototype and propose software design and solutions.', 'Experience with Scala and common machine learning libraries.', 'Experience with key administrative and development scripting languages such as Python, BASH, etc.', 'Knowledge of Git/SVN.', 'Expert knowledge of Linux']",2020-12-30 23:43:03
Data Scientist,thredUP Inc,2.8 out of 5 from 238 employee ratings,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Implement algorithmic solutions to drive decisions around item acceptance, item pricing, and discounting and clearance strategies for 3.5M unique items in inventory and 1.5M new items every month', 'Uncover insights in our vast repository of raw data, and provide tactical guidance on how to achieve an assortment that maximizes growth and value for all marketplace participants', 'Develop rigorous forecasting systems to bring predictability to our planning around inventory growth and economics', 'Create mathematical representations of the flow of items into and out of our marketplace', 'Drive the strategy for promotions, merchandising campaigns, and sales, and investigate their effect on inventory and buyer mix', 'Participate in our knowledge-sharing culture by spreading best practices and learnings from prior experiences, helping the entire team level up', 'At least 3 years of full time, professional experience in data analytics, data science, or software engineering roles', 'Ability to effectively work with business leads; strong cross-functional communication skills that help push projects forward and encourage the development of new collaborations', 'Innate curiosity and drive to find insights that unlock new growth or efficiency - you can’t help but dig in and seek the truth', 'Well-rounded skill set in statistics, machine learning, software development, and project management', 'Advanced knowledge of SQL and Python, and experience writing code in a collaborative environment', 'Prior experience working with marketplaces and/or a relevant background in economics or operations research is a plus']",2020-12-30 23:43:03
C# Engineer,PowerInbox,N/A,Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Build and maintain the software and infrastructure powering a real-time advertising exchange.', 'Implement monitoring and instrumentation to demonstrate the health of the advertising exchange.', 'Respond to service outages in a timely manner.', 'Design and implement strategies to increase the uptime reliability of the advertising exchange.', 'Draft technical requirements and specification documents to guide the engineering team in implementing and testing new features.', 'Integrate closely with the Data Team to guarantee the persistence and correctness of auction events.', 'C#/.NET experience (at least 3 years of experience)', 'Computer science knowledge (education and/or actual work experience)', 'Azure development experience (Cloud services, Service Fabric)', 'Knowledge of/interest in the digital and AdTech landscape, especially around OpenRTB and the delivery of ads.', 'Experience with HTTP.']",2020-12-30 23:43:03
Data Engineer,MongoDB,3.7 out of 5 from 27 employee ratings,New York State,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Several programming languages (Python, Scala, Java, etc.)', 'Data processing frameworks like Spark', 'Streaming data processing frameworks like Kafka, KSQ, and Spark Streaming', 'A diverse set of databases like MongoDB, Cassandra, Redshift, Postgres, etc.', 'Different storage format like Parquet, Avro, Arrow, and JSON', 'AWS services such as EMR, Lambda, S3, Athena, Glue, IAM, RDS, etc.', 'Orchestration tools such as Airflow, Luiji, Azkaban, Cask, etc.', 'Git and Github', 'CI/CD Pipelines', 'Enjoy wrangling huge amounts of data and exploring new data sets', 'Value code simplicity and performance', 'Obsess over data: everything needs to be accounted for and be thoroughly tested', 'Plan effective data storage, security, sharing and publishing within an organization', 'Constantly thinking of ways to squeeze better performance out of data pipelines', 'You are deeply familiar with Spark and/or Hive', 'You have expert experience with Airflow', 'You understand the differences between different storage formats like Parquet, Avro, Arrow, and JSON', 'You understand the tradeoffs between different schema designs like normalization vs. denormalization', ""In addition to data pipelines, you're also quite good with Kubernetes, Drone, and Terraform"", ""You've built an end-to-end production-grade data solution that runs on AWS"", 'You have experience building machine learning pipelines using tools likeSparkML, Tensorflow, Scikit-Learn, etc.', 'Build large-scale batch and real-time data pipelines with data processing frameworks like Spark on AWS', 'Help drive best practices in continuous integration and delivery', 'Help drive optimization, testing, and tooling to improve data quality', 'Collaborate with other software engineers, machine learning experts, and stakeholders, taking learning and leadership opportunities that will arise every single day', 'Disrupting a $64 Billion market', 'Top NoSQL database in the world', 'Largest Ecosystem and the fastest growing database in the world', 'Close to 17,000 customers in over 100 countries and over 90+ million downloads', '>120% net ARR expansion rate over each of the last twenty quarters', 'Sequoia Capital and a number of other Top VC firms have invested in MongoDB. Sequoia Capital calls us out as one of their flagship portfolios; Sequoia has also invested in Apple, Google, Youtube, and WhatsApp', '9-figure revenue company, with very high double-digit growth rates', ""Be a part of the company that's reinventing the database, focused on innovation and speed"", 'Enjoy a fun, inspiring culture that is engineering focused', 'Work with talented people around the globe', 'Learn, contribute, and make an impact on the product and community']",2020-12-30 23:43:03
Design Engineer,ACTION MANUFACTURING COMPANY,3.4 out of 5 from 30 employee ratings,"Atglen, PA 19310","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)"", 'Prior training or experience in a similar environment preferred, but not required.', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Tuition reimbursement', '10 hour shift', ""Bachelor's (Preferred)"", 'One location', 'Waiting period may apply', 'Only full-time employees eligible', 'No', 'Personal protective equipment provided or required', 'Temperature screenings']",2020-12-30 23:43:03
Data Engineer,Change Healthcare,"3 out of 5 from 1,098 employee ratings","Alpharetta, GA 30005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Engage with team members including data analysts and data scientists to understand the data needs of the solution in development and turn them into logical patterns or requirements', 'Create and automate ETL (extract, transform, load) processes to populate data storage solutions confirming data integrity', 'Employ data architecture best practices. Recommends data integrity standards including frameworks and templates, naming conventions, coding standards, and file formats', 'Work with IT to leverage cloud systems (Azure/AWS/GCP) and tools to enhance business intelligence and facilitate delivery to customers', 'At least one year of experience in data science, analytics, or business intelligence', 'Comfortable working with large, complex data systems for use in business analysis', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Working knowledge of data management software packages, such as Spark, Hadoop, SQL Server, Python', 'Experience with a visualization solution like Power BI', 'Excellent verbal and written communication skills', 'Ability to excel in a dynamic work environment with a “self-start” attitude']",2020-12-30 23:43:03
Data Analyst,Voice,4.2 out of 5 from 71 employee ratings,"Brooklyn, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Identifying and integrating new datasets, working closely with the engineering team to strategize and execute the development of data products.', 'Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries.', 'Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables.', 'Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy.', 'Analyze data for trends and patterns, and Interpret data with a clear objective in mind.', 'Implement analytical models into production by collaborating with software developers and machine learning engineers.', 'Communicate analytic solutions and implement improvements as needed to operational systems.', 'Other duties as assigned.', ""Bachelor's degree in Statistics, Applied Mathematics, or related discipline"", '3 to 5 years of practical experience in data science', 'Proficiency with data mining, mathematics, and statistical analysis', 'Advanced pattern recognition and predictive modeling experience', 'Experience with Excel, PowerPoint, Tableau, SQL, and programming languages (i.e., Java/Python, SAS)', 'Comfort working in a dynamic, research-oriented group with several ongoing concurrent projects']",2020-12-30 23:43:03
Business Data Engineer,IndeVets,N/A,"Philadelphia, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '4+ years of experience with SQL querying and schema design', 'Experience as a SQL developer', 'Experience implementing ETL flows', 'Experience with Power BI or other BI tools preferred', 'Experience with PostgreSQL a plus', 'Eager to contribute to a team-oriented environment', 'Able to work creatively and analytically in a problem-solving environment', 'Excellent communication and interpersonal skills', 'Medical Insurance', 'Dental Insurance', 'Short-Term Disability Insurance', 'Long-Term Disability Insurance', 'Paid-Time Off', '401(k) contribution with 100% employer match up to the first 4% with no vesting period', 'Stock optionsplan available']",2020-12-30 23:43:03
"Staff Engineer, Data Engineering",Betterment LLC,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Contribute to the technical vision and long-term strategy of the team', 'Initiate, influence, and drive a diverse set of data-oriented problems, working with a wide range of teams and learning a great deal about finance in the process', 'Think about scale and new technologies that will enable us to achieve a high level of efficiency for our data platforms', 'Find ways to spread knowledge across the organization, leveling up engineering practices and mentoring other engineers', 'Identify and develop plans to integrate with third party partners that will help us achieve our technical goals', 'Work with people who care. We support many teams who are not engineers, but we believe everyone at Betterment is an engineer with their own tools. We’re a group of talented professionals who pride ourselves on what we do. We’re smart, innovative, energetic, and lots of fun.', 'Deep expertise in at least one backend language, such as Java, Scala, C#, C++, Python - we build our services with Python', 'Familiarity with ETL and creating pipelines for large datasets', 'Experience utilizing cloud infrastructure - we use AWS', 'A track record of developing and maintaining a long-term technical roadmap', 'Desire to mentor other smart, passionate developers, fostering best practices', 'Ability to develop and lead initiatives that affect the larger engineering organization', 'Passion for software engineering as a craft, and for creating what doesn’t yet exist', 'Ability to make the tradeoffs required to ship without compromising quality', 'Appreciation for agility and pragmatism in software development', 'You’ll join a Community:', 'You’ll stay Happy and Healthy:', 'You’ll Learn & Grow:']",2020-12-30 23:43:03
"Software Engineer, Back End",eBay Inc.,"3.9 out of 5 from 1,691 employee ratings","San Jose, CA 95113","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:43:03
Production Engineer,Greylock Energy,N/A,Pennsylvania,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Required)US work authorization (Required)"", 'Daily surveillance, forecasting and budgeting of production volumes', 'Recommending opportunities for optimization, production improvement, flow assurance, and downtime reduction of unconventional and conventional wells and surface facilities', 'Designing, executing, and supervising well work to include well intervention, work over, plugging & abandonment, and artificial lift system installation/operation', 'Managing capital projects through every step including ideation, design, cost estimating, economic evaluation, proposal, execution, and assessment', 'Assembling, analyzing, processing, and understanding production and cost-related data to draw relevant conclusions and provide recommendations for solutions', 'Supervising production-related operations required for new well development including flowback, turn-in-line, process startup and operational handoffs', 'Developing and/or researching new techniques and approaches to enhance production rates and reduce operating costs', 'Flexible work schedules', 'Competitive salary', 'Health, dental and vision insurance', '401(k) with company match', 'Reimbursement for qualified educational expenses', 'Dependent child scholarships', ""Bachelor's (Required)"", 'engineering: 5 years (Preferred)']",2020-12-30 23:43:03
Data Streaming Engineer,HUNTER Technical Resources,4.7 out of 5 from 18 employee ratings,"Alpharetta, GA 30005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '5 years of Python or Ruby scripting / development', 'Experience developing processing pipeline for real-time data streaming platform using existing on-prem frameworks, including ElasticSearch, Kafka, Streamsets, Logstash, Fluentd, etc.', 'Experience with REST, microservices', 'Experience working with AWS platform and technologies, including experience with Kinesis, Lambda, Glue, Athena, Sagemaker, etc.', 'Strong understanding of relational database application development (Oracle, MySQL, Sybase, etc.)', 'Strong understanding of development and deployment on Unix platform', 'Strong foundation in computer algorithms and distributed processing, including experience with technologies like Hadoop, Kafka, ElasticSearch, NoSQL, multi process, core, threading.', 'Experience with Scrum/Agile development methodologies']",2020-12-30 23:43:03
AWS Cloud Engineer,"Stellar Technology Solutions, LLC",2.8 out of 5 from 4 employee ratings,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Cloud computing: 2 years (Required)US work authorization (Required)AWS: 3 years (Preferred)', ""You've worked for a fintech company and have experience with implementing security controls and managing technical security/compliance programs."", 'You know what it is like to work as part of a team. You understand the importance of interfacing between different people and teams to get things done.', ""You've worked on multiple different projects and not the same project multiple times."", ""You've used a cloud provider such as AWS or Google Cloud Platform. You refuse to build your infrastructure by hand, you are a big believer in infrastructure as code."", ""You've scripted using Bash or Python."", ""Help design and implement Amazon EKS using best practices. We'll build and secure our development environment using Terraform/Terragrunt."", 'Work with stakeholders to design and implement a CI/CD process.', 'Help with containing a single page application and deploying it into EKS.', 'Help automate building out each environment using the GitOps philosophy with Terraform.', 'Work closely with our DevSecOps team to implement best practices when it comes to securing our application and infrastructure.', ""Help with data replication from our datacenter into AWS. We'll leverage Kafka, PostgreSQL, and MongoDB to support this endeavor."", 'Collaborate within our small infrastructure Engineering team to shape and improve the infrastructure.', 'Empower our cross-functional teams to deliver quality software by enhancing the developer experience of their local development by bringing new and innovative practices', 'Work closely with QA and Engineering teams to streamline our CI/CD and automated release process.', 'Have an advanced intermediate understanding of Terraform.', 'Have made significant improvements to the way we ship and monitor code, we want to be able to execute canary deploys.', '401(k)', 'Dental insurance', 'Disability insurance', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Cloud computing: 2 years (Required)', 'AWS: 3 years (Preferred)']",2020-12-30 23:43:03
Data Engineer,Apex Global Solutions,2.5 out of 5 from 6 employee ratings,"Suffern, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Referral program', 'Vision insurance', 'Monday to Friday', 'Multiple locations', 'No: Not providing sponsorship for this job', 'ApexGlobalUs.Com', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-12-30 23:44:43
Data Engineer,Spectral MD,N/A,"Dallas, TX 75201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)developing web and server applications: 3 years (Preferred)AWS: 1 year (Preferred)"", 'Support the transfer of data between a medical device and the cloud, as well as interoperability with a hospital’s electronic medical record system.', 'Drive continued improvement of the backend infrastructure and data pipeline.', 'Work with a cross-functional technical team composed of frontend developers, software engineers, data scientists, and product designers.', 'Develop commercial-ready, testable, reusable code, and produce necessary backend documentation to support medical device design controls.', 'Work with the data science team to develop solutions that facilitate the development of deep learning algorithms, and statistical analysis of data obtained from medical imaging devices.', 'Bachelor’s Degree in Computer Science / Engineering / related field or an equivalent combination of education and work experience', 'Minimum 3 years of related work experience with a solid understanding of specified functional area', 'At least 3 years experience developing web and server applications using Python, Java, C++, C#, or similar: Experience designing and implementing application architecture, database architecture (SQL,NOSQL), and TCP/IP and network programming', 'Knowledgeable in AWS Web Services: AWS IoT Core, Lambda, API Gateway, DynamoDB, S3', 'Knowledge in REST, SOAP, JSON, XML, and other API related standards', 'Understanding of Network Protocols - MQTT, HTTP, JSON objects', 'Understanding of emerging IoT technologies and communications protocols including MQTT, WebSockets, and Notification engines, and preferably implementation experience in AWS IoT services;', 'Experience working within networks in the hospital environment, medical devices, and electronic health record systems.', 'Deploying with Docker and Kubernetes', 'Familiar with CI/CD pipelines with cloud infrastructure', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Paid time off', 'Parental leave', 'Relocation assistance', 'Retirement plan', 'Vision insurance', 'Monday to Friday', 'Bonus pay', ""Bachelor's (Preferred)"", 'developing web and server applications: 3 years (Preferred)', 'AWS: 1 year (Preferred)', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Team-oriented -- cooperative and collaborative', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'A job for which people with disabilities are encouraged to apply', 'www.spectralmd.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-12-30 23:44:43
Cost Segregation Consultant/Engineer,"ELB Consulting, Inc.",N/A,"New Port Richey, FL 34652","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:cost segregation, 1 year (Preferred)', ""License:Driver's License (Required)"", '8 hour shift', 'Monday to Friday', 'cost segregation: 1 year (Preferred)', ""Driver's License (Required)"", 'One location', 'Dependable -- more reliable than spontaneous', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'www.elb360.com', 'No']",2020-12-30 23:44:43
Staff Engineer-PE required,H.A. Reynolds & Associates,N/A,"Parker, CO","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:PE, 4 years (Preferred)', 'License:State of Colorado Professional Engineer (Required)', 'Work authorization:United States (Required)', 'PE: 4 years (Preferred)', 'State of Colorado Professional Engineer (Required)', 'United States (Required)']",2020-12-30 23:44:43
Data Engineer,Capital One,"3.9 out of 5 from 9,133 employee ratings","Richmond, VA 23218","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '2+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-12-30 23:44:43
FACILITIES ENGINEER,Schenectady County,N/A,"Schenectady, NY 12305","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience:Project Management, 2 years (Required)HVAC, electrical, 6 years (Required)', ""Education:Bachelor's (Required)"", ""License:NYS Driver's License (Required)"", 'Prepares, reviews, and revises plans, specifications and designs of electrical, HVAC, and facilities projects for the construction, renovation, and maintenance of County facilities including but not limited to the Jail, office buildings, Courthouse, Libraries, Public Works, Nursing Home, Ice rink and Airport tower;', 'Prepares, reviews, and revises plans, specifications and designs for renovation and rehabilitation projects for County facilities including roofing systems, building exteriors, interior space needs evaluation and design, lighting improvements, elevator systems, fire alarm systems, security systems, building management systems and control systems;', 'Provides project management for construction, renovation, and maintenance projects for County facilities including planning, scheduling, budgeting, and coordination with engineers, architects, and contractors as necessary;', 'Participates in field surveys, inspection and data-taking for the purpose of collecting information to serve as the basis for preparation of estimates, plans and specifications for County building and facilities projects;', 'Supervises staff engineer and other assigned Office of Facilities staff;', 'Assists in the instruction and development of subordinate employees in performing the duties and work of the Office of Facilities and in the operation and maintenance of equipment assigned to the department;', 'Prepares engineering estimates, specifications and bidding documents for materials, equipment and construction projects for various County agencies and departments;', 'Provides engineering advice and expertise in the administration of Federal, State and County programs such as the New York State Uniform Fire Prevention and Building Code, Energy Conservation Code, etc.;', 'Participates in office operations of the Office of Facilities for purchasing supplies and equipment, maintenance of equipment, maintenance of filing system for correspondence, technical reference materials, maps and plans;', 'Makes field investigations to insure compliance with engineering specifications;', 'Prepares a variety of records and reports;', 'Performs a variety of related work as required.', 'Dental insurance', 'Employee assistance program', 'Flexible spending account', 'Health insurance', 'Paid time off', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', '8 hour shift', 'Project Management: 2 years (Required)', 'HVAC, electrical: 6 years (Required)', ""Bachelor's (Required)"", ""NYS Driver's License (Required)"", 'No']",2020-12-30 23:44:43
Data Engineer,FlexIT Inc,N/A,"Beaverton, OR 97005","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Python', 'Apache Spark', 'SQL', 'AWS (S3, EMR, EKS)', 'Git', 'Deploying Spark jobs in Kubernetes', 'Apache AirFlow', 'Apachi NiFi', 'Terraform or CloudFormation', 'Hive', 'SnowFlake']",2020-12-30 23:44:43
"Data Engineer, Education",Chan Zuckerberg Initiative,4.8 out of 5 from 4 employee ratings,"Redwood City, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'We aim to be daring, but humble: We look for bold ideas — regardless of structure and stage — and help them scale by pairing engineers with subject matter experts to build tools that accelerate the pace of social progress.', 'We want to learn fast, but build for the long-term: We want to iterate fast and help bring new solutions to the table, but we also realize that important breakthroughs often take decades, or even centuries.', ""Stay close to the real problems: We engage directly in the communities we serve because no one understands our society's challenges like those who live them every day."", ""Support data scientists' access to data that is accurate, easy to access, and reliable"", 'Maintain key data pipelines', 'Ingest external data sets for use by the team', 'Improve data usability and data quality in our data warehouse', 'Launch new ETL (extract, transform, load) processes in production', 'Identify impactful improvements to our data warehouse infrastructure', 'Understand and improve the workflow of initiative members who use data for decision making', 'Help members of the initiative adopt and use tools that improve their access to data needed for their work', 'Educate initiative members about standard methodologies for use of data', 'Experience in Software Engineering or Data Engineering', 'Expertise writing efficient and optimized SQL', 'Experience with dimensional data modeling and schema design in a database or data warehouse', 'Expertise with scripting languages such as Python', 'Experience with ETL tooling such as Airflow', 'Experience with large scale cloud data warehouses such as Snowflake', 'Passion for education and bringing technology to improving education', 'Experience working with large data sets', 'Love for collaborating and working with people in understanding data needs as well as scoping and executing on projects.']",2020-12-30 23:44:43
Data Engineer,Excella,4.4 out of 5 from 11 employee ratings,"Arlington, VA 22201","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Developing and managing data processes to ensure that data is available and usable', 'Creation and automation of data pipelines and platforms', 'Managing and monitoring data quality via automated testing frameworks (Data Driven Testing, TDD, etc.)', 'Working closely with Architects, Data Scientists, and DevOps to design, build, test, deliver, and maintain sustainable and highly scalable data solutions', 'Researching data acquisition and evaluating suitability', 'Integration of data management solutions into client environment', 'Actively managing risks to data and ensuring there is a data recovery plan', 'Building data repositories such as: data warehouses, data lakes, and operational data stores, etc.', '3+ years relevant professional work experience.', 'Experience and expertise in the following:', 'Project experience using the Scrum or Kanban framework.', 'Professionalism; to include written and oral communication – the ability to communicate collaboratively in front of a whiteboard. An ability to understand your audience and adjust your communication style to fit', 'Aptitude and desire for learning new technologies.', 'Technically savvy, entrepreneurial spirit who thrives in environments that reward self-initiative and resourcefulness.', ""You'll work with great people who love what they do: our team includes published authors, certified trainers, and internationally renowned speakers."", 'We have a ""bring your own device"" workplace and will share the cost of a new computer of your choice - Mac or PC. It\'s up to you.', ""We'll invest in your career by providing 3 days of paid professional development every year, including travel and registration fees to attend classes and conferences, in addition to tuition assistance for degrees and certifications."", 'Starting day one, every employee is bonus eligible and receives 15 days of paid vacation, 6 federal holidays, and 4 floating holidays.', 'You can bike, drive, or metro to work - our commute reimbursement plan has you covered.', ""You'll have fun! We hold monthly social events all year long, including a summer event for you and your family.""]",2020-12-30 23:44:43
Data Engineer,SpringML,N/A,"Herndon, VA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Ability to work as a member of a team assigned to design and implement data integration solutions.', 'Build Data pipelines using standard frameworks in Hadoop, Apache Beam and other open source solutions.', 'Learn quickly – ability to understand and rapidly comprehend new areas – functional and technical – and apply detailed and critical thinking to customer solutions.', 'Propose design solutions and recommend best practices for large scale data analysis', 'B.S. or equivalent degree in computer science, mathematics or other relevant fields.', '5-10 years of experience in ETL, Datawarehouse, Visualization and building data pipelines.', 'Strong Programming skills – experience and expertise in one of the following: Java, Python, Scala, C.', 'Proficient in big data/distributed computing frameworks such as Apache Spark, Kafka,', 'Experience with Agile implementation methodologies.']",2020-12-30 23:44:43
Data Engineer,St. Luke's Health System,3.3 out of 5 from 200 employee ratings,"Boise, ID","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Education: Bachelor's degree or 4 years of relevant experience in lieu of degree"", 'Experience: Minimum of 4 years related experience', 'Design, implement, and maintain data management capabilities including data models, ETL processes, and data architecture requirements.', 'Build cross functional relationships with data analytic teams and business leaders to understand information needs, data flows, and data quality considerations to enable solution deployment.', 'Utilize data quality techniques for data validation, unit testing, and automated integration testing. Implement frameworks for automated and scripted testing.', 'Contribute to improving solution stability, reliability, efficiency, and quality.', 'Work with architects to implement solutions in alignment with standards.', 'Test new software products/updates; working with other members of the Master Data Management team and business partners to improve usability and recommend improvements.', 'Identify technical solutions that achieve efficiency and effectiveness and enable data usage as a strategic, business asset.', 'Strong SQL experience, writing queries and stored procedures', 'Experience with database management systems including performance optimization, tuning, and security', 'Capability to develop data warehouse data models', 'Development experience with Microsoft SQL Server Integration Services', 'Exposure to data warehousing methodologies', 'Some experience with REST and .NET preferred', 'St. Luke’s is an equal opportunity employer and does not discriminate against any person on the basis of race, religion, color, gender, gender identity, sexual orientation, age, national origin, disability, veteran status, or any other status or condition protected by law.']",2020-12-30 23:44:43
Data Warehouse Engineer,Parsons,4 out of 5 from 919 employee ratings,"Springfield, VA 22150","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design the logical data relationships and query structures of new databases considering factors such as access methods, access frequency, storage media, data volatility, query requirements, and operating environments to support insider threat detection application software and data analysis.', 'Develop logical data models translated into workable physical database schema and structures in the database development process to support insider threat detection application software and data analysis.', 'Design enterprise database strategies for functions such as backup, recovery and migration or to correct extremely complex operational and performance.', 'Implement new database designs using DataVault 2.0 methodology.', 'Evaluate data sets and engineer solutions for integrating into the Data Warehouse', 'Sustain existing Data Warehouse and application databases', 'Perform daily database administration functions such as developing queries and reports based on customer requirements, modifying or developing database views, and managing backup and recovery operations.', 'Develop, sustain and preserve user manuals and instructions that guide customers in executing data access functions such as running queries and reports.', 'Participate in multi-functional teams and manage work through JIRA.', 'Possess a minimum of seven (7) years of experience in Application Software and Extract Transform Load (ETL) and/or Data, Database and/or Data Warehouse implementations', 'Possess a minimum of three (3) years of experience in implementing, managing, and maintaining data warehouses', 'Possess experience with SQL and SQL Plus', 'Possess experience building and scheduling data integration scripts that automat ingest of data from multiple sources (Oracle, SQL, Postgres).', 'Possess experience using data Extract Transform Load (ETL) applications such as IBM DataStage and WhereScape.']",2020-12-30 23:44:43
Data Engineer,Scientific Games,3.5 out of 5 from 477 employee ratings,"Austin, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:44:43
Data Science Interface Analyst/Engineer (Acuitas Health),CDPHP,3.7 out of 5 from 47 employee ratings,"Albany, NY 12206","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Bachelor’s degree or equivalent experience required.', 'Engineer: Minimum one (1) year of relevant experience required.', 'Experience with SQL, and database structure required.', 'Knowledge of demographic and clinical data, data flow, and relationships required.', 'Experience with Interface Engines, such as Rhapsody, ConnectR, or equivalent system(s) required.', 'Experience with Microsoft systems, including SQL Server Management Studio required.', 'Experience with Message Exchange Formats, including HL7, XML required.', 'Experience working with diverse clinical health care systems including, but not limited to, Electronic Healthcare Record (EHR) systems such as Allscripts, EPIC, or Athena, and health information exchange preferred.', 'Demonstrated ability to move data according to industry standards.', 'Demonstrated ability to understand the flow of clinical systems and other ancillary applications.', 'Demonstrated ability to explain complex technical concepts and issues to all levels of internal and external business partners, including those with limited or no technical background.']",2020-12-30 23:44:43
Software Engineering Summer Internship 2021,Tapad,N/A,"New York, NY","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Studying to finish a BS, MS, or Ph.D. in a technical major', 'Understanding of concurrent and parallel programming', 'Knowledge of algorithms and data structures', 'Bonus: SQL and functional programming experience, specifically Scala', 'Designing, implementing, and running big data pipelines that canvas over petabytes of data', ""Contributing to real production projects that constitute Tapad's core offering"", 'Collaborate with your team of engineers, and contribute to product, account, and business development functions to create new products and features', 'Google Cloud Platform (GCP)', 'Scala, Cats, SBT, Play!, Akka,', 'Spark, Python', 'Kubernetes, BigTable, BigQuery', 'TypeScript, Angular, Node.js, Hapi.js, Postgres, MySql', 'Google Cloud Platform (GCP)', 'Scala, SBT, Play!, Akka', 'Spark, Python, SQL, BigQuery', 'Gain valuable experience working in a cutting edge and data-driven environment using state of the art technologies', 'Dynamic and fast-paced well-established start-up', 'A designated mentor to help guide you through the 10-week internship program', 'Ongoing training, which will include Scala School, access to Coursera, peer-led professional development, and an abundance of resources to help guide you through your internship', 'Catered lunches and unlimited in-office snacks and beverages', 'Leadership lunches - sit with the CEO, CTO, and CPO, and ask them anything your heart desires', 'Foosball, ping pong, diversity and inclusion group, book club, and tons of other extra-curricular activities that will make you feel like part of the Tapad family', 'Virtual game nights, diversity and inclusion group, book club, and other extra-curricular activities that will make you feel like part of the Tapad family', ""Leadership lunches over zoom. We'll deliver food to your doorstep!""]",2020-12-30 23:44:43
Data Engineer Role,SPR Software systems LLC,N/A,"San Antonio, TX","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop & implement ETL/ELT processes for Cloud Datawarehouse platform Snowflake', 'Ability to understand legacy DataStage ETL components and rewrite them into SQLs and DBT (Data Build Tool) components', 'Work closely with other data engineering teams to ensure alignment of methodologies and best practices', ""Bachelor's Degree or master’s degree in Computer Science."", '10+ years of hands-on software engineering experience.', '5+ years of strong ETL experience on either DataStage, Informatica, Ab-Initio, Talend etc.', 'Experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS', 'Strong database fundamentals including SQL, performance and schema design.', 'Proficiency in SQL coding', 'Ability to interpret/write custom shell scripts. Python scripting is a plus.', 'Experience with AWS platform and Snowflake CDW platform big plus', 'Experience with Git.', 'To be able to work in a fast-paced agile development environment', '8 hour shift']",2020-12-30 23:44:43
Data Engineer,Belcan,3.6 out of 5 from 637 employee ratings,"Pittsburgh, PA 15220","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Develop key metrics and data visualizations that will enable prescriptive operations and optimize pipeline processes and transparency through increased data visibility', 'Responsible for building powerful, intuitive data visualizations and dashboards that clearly convey the knowledge observed from the data and drive prescriptive operations and centralized seed processing', 'Developing and deploying prototype solutions and working with our IT and data teams to deliver robust solutions in a continuously evolving technical environment', 'Bachelor of Science degree', 'Data analysis skills utilizing tools such as Spotfire, Tableau, Pipeline Pilot, or SQL; API consumption/development experience.', 'Understanding of Database systems and management of large data sets is preferred']",2020-12-30 23:46:28
Data Engineer (Azure Cloud),Who... a staffing company,N/A,"Baltimore, MD","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Azure Data Lake (Analytics and Storage), Data Warehouse / Synapse Analytics / Amazon Redshift, Data Factory, Logic Apps, Data Bricks', 'Other preferred technologies include: Advanced T-SQL (SQL Server), REST API concepts, Powershell, SSIS, PowerBI', 'Experience in database design, architecture and warehousing', 'Experience creating ETL/ELT processes to move data between internal and external sources using APIs, ETL.', 'Fundamental understanding of Data Lakes, Data Catalogs, Hardware and Network Topology', 'Experience with Object-Oriented Programming Languages such as Python, JavaScript, Java, C#, etc.', 'Experience using data reporting and visualization tools (e.g. Cognos, SSRS, Qlik, Data Studio, Power BI, Tableau, etc.', 'Gathering data requirements from stakeholders', 'Data Governance', 'Evaluating data collection for accuracy', 'Mindful of practices, procedures and legal guidelines that govern PII and other sensitive data', 'Build scalable, high performance infrastructure for delivering clear business insights from raw data sources', 'Responsible for designing, building, testing, integrating, managing, and optimizing data', 'Responsible for data format, resilience, scaling, and security', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Vision insurance', 'Monday to Friday', 'One location']",2020-12-30 23:46:28
Enterprise Data Engineer,Commonwealth Care Alliance,3.4 out of 5 from 98 employee ratings,"Boston, MA 02111","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Minimum of bachelor’s degree (Computer Science, Mathematics, Statistics, Engineering preferred)', 'Advanced degree in Applied Mathematics, Business Analytics, Statistics, Computer Science, or Data Science a plus', '4 years of experience implementing Data Management solutions or as Data Analyst/Data Architect/Business Systems Analyst', 'Must have a good understanding of Healthcare (Payer, Patient, Care Provider) data models and systems', 'Knowledge of HC Industry trends such as ACO, HIX, HIE and HC industry solution models (HL7, HIPAA) a definite plus', 'Mid-level IT resource with a broad understanding of Database Design and Data Analysis approaches and implementation methodologies', 'Ability to work with the business as well as IT stakeholders', 'Experience in large operational and analytical data environments', 'Demonstrated experience in data analysis, database design, and performance tuning', 'Advanced technical skills with proficiency in SQL coding (Teradata, SQL Server, and/or Oracle), Tableau and/or Datawatch, Looker, R, Python', 'Hands-on experience with tools such as SQL Server Management Studio and Oracle SQL Developer', 'Working knowledge of Talend ETL and other utilities such as, MDM a definite plus', 'Experience with Agile/Scrum is valuable', 'Ability to work creatively and analytically in a team environment', 'Excellent communication and documentation skills', 'Medical, dental and vision plans with low employee contributions', 'A generous paid time off program', '403(b) with company match', 'Loan Forgiveness Program', 'Educational Assistance/Reimbursement', 'Help analyze CCA’s master and transaction data to understand how it is created, maintained,\ufeff and used in financial, clinical, operational, and analytical reporting.', 'Work with business stakeholders to identify critical data elements and how they relate to each other.', 'Assist in the development of large-scale data structures and processes to organize, collect and standardize data that helps generate insights and addresses reporting needs.', 'Apply understanding of key business drivers to design algorithms, logic and models for key data domains.', 'Work with the Enterprise Architecture group to understand data generating and consuming processes and design data flows that follow them.', 'Work with Integration Analysts to document data flows within point-to-point interface architecture.', 'Assist in drafting and communicating MDM and API-based future data integration strategy and vision.', 'Work with internal/external stakeholders to secure data access ensuring CCA’s data governance policies are strictly followed.', 'Create and maintain appropriate level of system and user documentation.', 'Help maintain data dictionary for all business-critical data domains.', 'Help capture business rules that govern how data is transformed, integrated and used.', 'Identify and help define reactive and proactive alerts and controls to maintain data quality, and for audit reporting.', 'Develop relevant value metrics and tools to measure and track data quality.', 'Identify data inaccuracies (duplicates, incomplete info., inconsistencies etc.) and engage appropriate business teams to address cross-functional data issues and impacts.', 'Record, respond and help resolve data issues in a proactive manner.', 'When reacting to data issues, conduct root cause analyses to ensure the issue does not recur.', 'Develop anticipated queries, reports and related documentation for business communication of both issues and their mitigation.', 'Ensure data standards are followed.']",2020-12-30 23:46:28
Data Engineer,Synergy Solutions,N/A,"Detroit, MI","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)Data Warehouse: 1 year (Preferred)Java: 1 year (Preferred)"", '401(k)', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)', 'Data Warehouse: 1 year (Preferred)', 'Java: 1 year (Preferred)']",2020-12-30 23:46:28
Data Engineer - Machine Learning,Engtal,N/A,United States,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""US work authorization (Required)Bachelor's (Preferred)"", 'Analyze payment transaction data to identify patterns at the national or local level', 'Leverage national consortium data set to help financial institutions, especially small ones, predict future fraud', 'Analyze Terabytes of data in a cloud environment using the latest batch or streaming tools. We use Spark in AWS and look forward to trying others.', 'Optimize infrastructure to enable faster feature engineering', 'Build data processing architecture and systems for new data and ETL pipelines', 'Recommend improvements for existing data and ETL pipelines', 'Manage models and resolve data issues in production', 'Enjoy working with large data sets that are messy and constantly changing', 'Prefer to free yourself from repetitive work by building automation with quality assurance', 'Curious and drive to constantly learn and share with others', '4+ years of experience as a data engineer or data research experience in a technical field', 'Experience working with large data sets (Billion data points and Terabytes in size)', 'Experience analyzing data to identify deliverables, gaps, and inconsistencies', 'Experience with ETL processes', 'Ability to communicate complex technical concepts to a broad variety of audiences', 'Strong programming skills in python/pyspark', 'Rigor in testing and performance optimization', 'Strong experience with the Unix environment', '401(k)', 'Dental insurance', 'Health insurance', 'Paid time off', 'Vision insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Fully Remote', 'No: Not providing sponsorship for this job', 'Remote interview process']",2020-12-30 23:46:28
Lead Data Engineer,The Denzel Group,N/A,"Wayne, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:46:28
Data Engineer- Netezza,Everest Technologies,4.6 out of 5 from 11 employee ratings,"New Albany, OH 43054","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, develop and implement complex data solutions', 'Collaborate with other IT leads and developers to identify opportunities for improvement and innovation', 'Discover, evaluate, and implement new technologies to maximize development efficiency', 'Develop team members by providing coaching, code review, and process guidance', 'Support critical production systems to ensure stability and uptime', 'Assist business partners in applying data to evaluate and tackle business problems', 'Create and uphold technology standards, processes, and audit methodologies', 'Continuously improve IT platforms based on retail and data management technology trends in support of business strategies', '5+ years experience with data warehousing/BI technologies with Netezza', '3+ years experience developing and supporting complex SQL and database views in a large data warehouse environment', 'Experience supporting end user data request, questions and complex data issues, front end reporting solutions such as but not limited to OBIEE, Tableau, BOBJ.', 'Experience supporting data integration and/or reporting systems (i.e. 24x7 system support)', 'Experience with Agile and Waterfall software development methodologies and tools such as JIRA, Subversion, and GIT', 'Personal attributes: confident, self-starter, strong work ethic, highly motivated, sense of humor, a winning ‘can-do’ attitude, team-oriented', 'Retail experience is a plus', '401(k)', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Relocation assistance', 'Vision insurance', 'Monday to Friday', 'Netezza: 5 years (Required)', 'More than 1 year', 'Yes', 'Temporarily due to COVID-19', 'Remote interview process', 'Virtual meetings']",2020-12-30 23:46:28
Software Engineer - Data/ETL (fully remote),Engtal,N/A,"Chicago, IL","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)"", 'Deep appreciation and understanding of data, scale and Ruby on Rials.', 'Live and breathe a DevOps culture on a small team of Senior SDEs and SRE that work hand-in-hand with you to deliver modern, scalable, SaaS software across multiple cloud providers.', 'Own and implement the key data delivery pipelines for the company’s flagship SaaS platform.', 'Follow software development best practices to create maintainable and extensible software solutions.', 'Work with modern CI/CD tool and methodologies to ship product on a daily basis.', 'Work in an agile manner with transparency and fluid communication within the engineering team and across other teams in the company.', 'Work with product owner to understand internal and external requirements and help the team design solutions to satisfy these.', 'Work with Senior SREs to contribute to the overall platform stability, availability, and quality.', 'Enable SREs to have visibility and responsibility into the function of the code they are operating.', 'Interact directly with SREs and customers to triage, debug, and remediate production issues.', 'Education: Formal higher-education degrees in STEM fields or vocational certificates related to software development are preferred, but not required. Real-world experience and proven track records count as much, if not more.', 'Experience with Sidekiq, ActiveAdmin, Custom DSLs or very similar is a must.', '5+ years of professional experience developing ETL software for modern cloud environments.', '5+ years of professional programming experience with languages and frameworks such as Ruby, Rails, Python, etc.', 'Familiar with cloud and Linux sysadmin experience – IaaS, PaaS, and container/orchestration experience is important.', 'Real-world shipping product development experience using client-side JavaScript frameworks and backend dynamic languages/frameworks in a service-oriented architecture.', 'Proven track record of success in high-functioning continuous delivery environment.', 'Working knowledge and hands-on experience with Docker and Kubernetes (or similar container/orchestration).', 'Expertise with a variety of relational and NoSQL databases. MSSQL, PostgreSQL, MySQL, Couchbase, DocumentDB, DynamoDB, MongoDB, Redis preferred.', 'Solid understanding of modern API design patterns (REST, GraphQL, JSON, etc.)', 'Understanding of source control systems (git, hg, etc.) and related workflow pattern', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Employee assistance program', 'Employee discount', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Health savings account', 'Life insurance', 'Paid time off', 'Parental leave', 'Professional development assistance', 'Referral program', 'Relocation assistance', 'Retirement plan', 'Tuition reimbursement', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'Signing bonus', ""Bachelor's (Preferred)"", 'post-education: 3 years (Required)', 'SQL: 1 year (Preferred)', 'No: Not providing sponsorship for this job', 'Innovative -- innovative and risk-taking', 'People-oriented -- supportive and fairness-focused', 'Remote interview process']",2020-12-30 23:46:28
Data Engineer,AccruePartners,3.8 out of 5 from 32 employee ratings,"Charlotte, NC 28203","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'One of the largest providers of high-quality, single-family residences in the United States.', 'A team of hard-working individuals who take pride in providing the highest quality of safety, security, and stability.', 'A dynamic, fun, and goal-oriented company.', 'In addition to outstanding training, they host town hall meetings to encourage growth, knowledge sharing and a good time.', 'Competitive performance-based bonuses.', 'Comprehensive healthcare coverage for you and your family, parental leave, paid time off, and paid holidays', 'Offers opportunity to use upcoming technologies to help preform financial engineering', 'Will be developing applications using Java/Hibernate/Vaadin', 'The applications that are developed will be to support the acquisition, leasing, and management of different properties and homes', 'Opportunity to develop integrations with various levels of Real Estate startups', 'Opportunity to analyze various sets of data to help identify various trends along with optimizations', 'A Bachelors degree is preferred', 'Minimum of 3-5 years of experience designing, building, and maintaining data processing systems.', 'Must have strong SQL experience', 'Must have Python or Java experience', 'Knowledge of how to develop, deploy, and support data pipelines', 'Strong understanding of how to design, build, and maintain cloud-based data warehouse solutions', 'AWS or Azure experience required', 'Any MongoDB, S3, and Snowflake experience is a plus']",2020-12-30 23:46:28
Data Engineer,Indotronix International Corporation,4 out of 5 from 23 employee ratings,"Allentown, PA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center']",2020-12-30 23:46:28
Big Data Engineer (Remote for now),Ascent Services Group,3.8 out of 5 from 22 employee ratings,"Pasadena, CA 91188","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities.', 'Implementing ETL process Monitoring performance and advising any necessary infrastructure changes.', 'Defining data retention policies', 'Proficient understanding of distributed computing principles Management of Hadoop cluster, with all included services.', 'Ability to solve any ongoing issues with operating the cluster. Experience with building stream-processing systems', 'Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala.', 'Experience with Spark, Experience with integration of data from multiple data sources', 'Experience with NoSQL databases, such as HBase, Cassandra, MongoDB.', 'Knowledge of various ETL techniques and frameworks. Experience with various messaging systems, such as Kafka. Experience with Big Data Client toolkits.', 'Build robust data pipelines: develop jobs to process, validate, transport, collate, aggregate, and distribute data', 'Build workflows that empower analysts to efficiently use data', 'Develop data virtualizations and actual data movement and transformation processes, using the appropriate technologies, tools and techniques to balance performance and cost objectives.', 'Deploy machine learning models as batch and API', 'Define and establish processes to maintain the integrity of data within our data pipeline and warehouse', 'Develop tests to validate, and monitor data transfer integrity and efficiency', 'Work collaboratively across the organization to address and predict data performance issues', 'Develop documentation for the tools and data products deployed', 'Strong SQL writing skills', 'Sound understanding of areas of computer science such as algorithms, data structures and databases', 'Experience with relational databases', 'Software engineering experience with expertise in at least one high-level programming language (preferably Python, Power BI)', 'Experience with Linux command line and bash scripting.', 'Knowledge of distributed computing frameworks e.g. MapReduce, HDFS, etc.']",2020-12-30 23:46:28
Data Engineer (Python/ETL),eNGINE,N/A,"Pittsburgh, PA 15219","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', '401(k)', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Paid time off', 'Vision insurance', '8 hour shift', 'No: Not providing sponsorship for this job', 'Remote interview process', 'Social distancing guidelines in place', 'Virtual meetings']",2020-12-30 23:46:28
Data Engineer - SQL/Python/ AWS - W2 ONLY,Beacon Hill Staffing Group,3.9 out of 5 from 304 employee ratings,"Wilmington, DE","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and develop ETL processes using standard ETL tools to streamline and automate the collection of data from source systems using SQL, Snowflake and AWS technologies', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Work with stakeholders including the Marketing, CRM, Finance, Operations, Product, and Development teams to assist with data-related technical issues and support their data infrastructure needs.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Develop repeatable and scalable data quality audits', ""Bachelor's Degree in Computer Science, MIS or related field"", '5+ years Advanced SQL knowledge and experience working with relational databases, query authoring (T-SQL/Postgres SQL)', 'Ability to write advanced SQL queries with multi-table joins, group functions, subqueries, set operations, functions, Stored Procedures and basic Java Scripting.', '2+ years experience with SQL and MYSQL Server and 2+ years experience with Python and experience with AWS Cloud', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong understanding of data modeling and data warehousing principles']",2020-12-30 23:46:28
Data Engineer,Compliant Pharmacy Alliance Cooperative,N/A,"Stoughton, WI 53589","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Associate (Preferred)SQL: 1 year (Preferred)Data warehouse: 2 years (Preferred)', 'Design and build data processing components and systems utilizing Azure and Microsoft 365 technologies', ""Engineering of Azure data solutions that adhere to Microsoft's best practices"", 'Responsible for the design and creation of SQL tables, schema, views, and stored procedures that adhere to business needs and best practices', 'Responsible for the governance and security of SQL databases, including table, row, and field-level granular access', 'Build, maintain, and fix pipelines using workflow management applications such as SSIS, Azure Data Factory, and Microsoft Power Platform', 'Design data-driven models such as dimensional, relational, and distributed', 'Query various data sources using SQL On-Demand to produce datasets for report generation', 'Acquire, analyze, combine, synthesize, transform, and store data from a wide range of internal and external sources', 'Assist with building CI/CD deployment pipelines for data system components', 'Develop and support monitoring solutions for data systems and related components', 'Improve automation and consistency in all facets of data workflow lifecycle', 'Develop and produce reports for internal staff and cooperative members as needed', 'Associate’s degree or higher in a computer or related field, plus 2-5 years of experience with Database Administration, ETL Development, or Azure Cloud; or the equivalent combination of education and experience', 'Solid understanding of relational database systems', 'Experience developing SSIS packages and troubleshooting ETLs', 'Familiarity with Azure data technologies such as Azure Storage, Azure Data Lake Gen2, Azure SQL Databases, and Azure Data Factory', 'Advanced Microsoft Excel skills', 'Knowledge of Data Warehouse design and best practices using Azure Data Lake', 'Knowledge of Power BI and Microsoft SharePoint lists', 'Experience optimizing data flows based on business needs and performance metrics', 'Experience with performance tuning SQL Databases and query execution', 'Versioning of database configurations and schemas', 'Familiarity deploying through a CI/CD pipeline with Azure DevOps involving git repositories, code analysis, and dev-test development', 'Familiarity with database backup methodologies', 'PowerShell or Azure Cloud Shell skills a plus', 'Understanding of data sensitivity classifications and personally identifiable information (PII)', 'Familiarity with the full data engineering lifecycle, from project conception to building operational systems', 'Strong professional written and verbal skills, analytical skills, and attention to detail required', 'Ability to work independently in a team environment with limited direct supervision', 'Ability to occasionally work outside of regular business hours, including evenings and weekends', 'Ability to occasionally travel for work, including out-of-town and overnight, for various meetings or professional development opportunities', '401(k)', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Retirement plan', 'Vision insurance', '8 hour shift', 'Monday to Friday', 'Bonus pay', 'Associate (Preferred)', 'SQL: 1 year (Preferred)', 'Data warehouse: 2 years (Preferred)', 'No: Not providing sponsorship for this job', 'https://www.compliantrx.com', 'Yes', 'Remote interview process', 'Personal protective equipment provided or required', 'Social distancing guidelines in place', 'Virtual meetings', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 23:46:28
Data Engineer - W2 Opportunity,Facebook AR/VR,N/A,"Menlo Park, CA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Bachelor's (Preferred)SQL: 1 year (Preferred)"", 'SQL database design (must be proficient writing in SQL)', 'Python proficiency', 'Data modeling experience', 'Familiarity with java, Kafka, hive or storm', '401(k)', 'Dental insurance', 'Health insurance', 'Vision insurance', '8 hour shift', ""Bachelor's (Preferred)"", 'SQL: 1 year (Preferred)', 'No: Not providing sponsorship for this job']",2020-12-30 23:46:28
Network Engineer Consultant (Fieldwork),"Interlink Group, Inc",5 out of 5 from 2 employee ratings,"South Bend, IN 46601","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', ""Computer Networking: 1 year (Required)LAN: 1 year (Required)Driver's License (Required)Cisco CCNA (Preferred)"", 'Implement and support local area networks (LAN), wide area networks, (WAN), intranets, extranets, and other data networks.', 'Develop and execute test plans to check infrastructure and system performance.', 'Demonstrated capability of analyzing, debugging, tracking, fixing and preventing network security and performance issues.', 'Able to confidently manage systems via the command line.', 'Define blueprint designs for business technology initiatives.', 'Able to promptly respond to inquiries via email, telephone, ticketing systems and other electronic communications.', 'Able to multi-task, prioritize, and resolve multiple customer inquiries at once.', 'Able to troubleshoot complex hardware and software issues.', 'Able to work overnight, weekend on-call shifts as needed.', 'Able to sit or stand for extended periods of time. Required to assist with tasks in the data centers/customer sites and perform moderate lifting up to 80 lbs.', 'Routing: Multi-VRF Customer Edge or VRF-lite, NHRP, QoS, HSRP, OSPF, BGP, NAT/PAT (configuration and troubleshooting)', 'Switching: LACP, RPVST+, 802.1Q, 802.1ad, 802.1x, CEF, QoS, private VLANs, netflow/IPFIX, vPC, REP, and EVC (configure, maintain and troubleshoot)', 'VPN: IPSEC site-to-site VPNs, DMVPNs, Client to site VPNs, Anyconnect, OpenVPN, and pseudowire (configuration and troubleshooting)', 'Wireless: Cisco Unified Wireless, Ubiquiti, Ruckus, and Aruba Wireless (configure, maintain and troubleshoot)', 'Security: FirePOWER, Cisco AMP, Secure X, CBAC, 802.1X, Zone-based Policy Firewall, Certificate Authority, RADIUS (configure, maintain and troubleshoot)', 'Systems Management: SNMP, Zabbix, Solarwinds, PRTG, VoIPMon, Wireshark, NMAP, protocol analyzers, Wireshark (configure, maintain and troubleshoot)', 'VoIP/IP Telephony: SIP, unified communication systems, or Asterisk (configure, maintain and troubleshoot)', 'Degree in related field with 3+ years’ experience or 8+ documented years’ experience.', 'Minimum five years performing Cisco Network Administration tasks.', 'Industry certifications.', '3+ years working in consulting or service provider environment.', 'Ability to learn on the job and explore new technologies with little supervision.', 'Develop automation to increase productivity and reduce human error.', 'Linux Server (Ubuntu, CentOS, RedHat) installation, administration, and troubleshooting.', 'Virtualization: VMWare ESX(i) 5.0 and above (vSphere, vCenter), Xen, and KVM installation configuration administration and troubleshooting.', 'VoIP/IP Telephony: experience with SIP trucking, unified communication systems, or Asterisk.', 'Hands-on experience solving systems and network problems.', 'Experience using protocol analyzers and understand communication protocol details.', 'Be prepared to answer detailed questions about the protocols you claim you are knowledgeable about in your resume.', 'Must be a self-learner.', 'Must demonstrate the ability to work unsupervised', ""Driver's License"", 'CCNA', '401(k) matching', 'Dental insurance', 'Flexible schedule', 'Health insurance', 'Life insurance', 'Paid time off', 'Professional development assistance', 'Vision insurance', 'Monday to Friday', 'Bonus pay', 'South Bend, IN 46601 (Required)', 'Computer Networking: 1 year (Required)', 'LAN: 1 year (Required)', 'Cisco CCNA (Preferred)', ""Driver's License (Required)"", 'Remote interview process', 'Personal protective equipment provided or required', 'Social distancing guidelines in place', 'Virtual meetings', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 23:48:10
CONTRACT - Software Engineer (Analytics) (NTD),Nintendo of America Inc.,4.1 out of 5 from 260 employee ratings,"Redmond, WA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design, implement, and test internal libraries and cloud-based infrastructure', 'Triage incoming issues and resolve defects in a timely manner', 'Work with project managers to gather and document functional requirements', 'Effectively and proactively document work', 'Works with Nintendo’s global technical teams on project priorities', '3 – 5 years of experience developing software using C#', 'Working knowledge SQL and the ability to write queries', 'Solid experience with AWS including', 'Excellent verbal and written communication skills', 'Experience with Python, C++, JavaScript, and/or container services (i.e. Docker) is a plus', 'Legally authorized to work in the US.']",2020-12-30 23:48:10
Technical Escalations Engineer (2nd Shift),ExamSoft Worldwide,N/A,Texas,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Provide world-class technical support via telephone, email and chat for ExamSoft customers experiencing escalated technical issues', 'Troubleshoot complex issues with use of remote support software', 'Maintenance of customer support portal', 'Learn from customer interactions to help innovate customer experience improvements with better software and support tools', 'Identify early symptoms, patterns and solutions for upcoming technology challenges', 'Triage bug fixes and support related issues to be communicated to Product Owners or Engineering teams', 'Maintain list/information for security threats, bugs and enhancements', 'Mentor Support Specialist I team to develop skillsets and technical capabilities', 'Provide enterprise level support to strategic accounts to ensure successful support experience', 'Execute on retention-based projects in addition to supporting customer', 'Develop best practices, tips and training scripts for customers on proper use of', 'Communicate user challenges and software updates across multiple teams including the Development team for tracking resolution', 'Assist with Quality Assurance beta testing ALL program components and installers as needed', 'Assist with Quality Assurance in maintaining all program help files and documentation as needed', 'Opportunity to work on additional projects as necessitated by the Engineering team', ""Bachelor's Degree in Computer Science or equivalent work experience"", '3+ years of Customer Support experience (preferred)', 'Strong working knowledge of Windows and Mac OS', 'Experience with software applications or SAAS (preferred)', 'Experience working with bug ticketing software', 'Strong written and verbal communication skills', 'Strong interpersonal and customer service skills']",2020-12-30 23:48:10
"Sr IBM Storage Engineer - Remote or Omaha, NE",Mutual of Omaha,3.7 out of 5 from 701 employee ratings,"Omaha, NE 68131","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'Ensuring health of enterprise storage systems', 'Leveraging backup system capabilities', 'Improving current processes through automation, and providing support, installation, integration, configuration and day-to-day operations', 'Senior level IBM Mainframe Disk Administration experienceIBM Data Facility Hierarchical Storage Manager (DFHSM)IBM Data Facility Storage Management Subsystem/Advance Copy Services (DFSMS/ACS)IBM Flashcopy, Metro Mirror, Global MirrorIBM VTL (TS7770) hardware technologyIBM DS8*, Hitachi Storage and IBM Virtualization', 'Experienced managing and configuring various level of storage systems', 'Familiar with hybrid disk environments (on and off prem)', 'Worked with Amazon Cloud Services', 'Solid skills and working knowledge of Windows, Linux, AIX Server and TCP/IP, DNS, LDAP.', 'Strong ability to troubleshoot, resolve problems and provide Level 3 support', 'Scripting languages such as PowerShell, VBScript, command shell or other', 'Managing and Configuring Enterprise Backup Infrastructure', 'Functional understanding of DBASE backups', 'Analyze storage reporting to identify trending - capacity-based needs \\ load balancing efforts', 'Enterprise Backup systems (like IBM or Commvault or Veritas or EMC)', 'Working knowledge of Server Disaster Recovery methods', 'Working knowledge of enterprise NAS systems', 'Working knowledge of VMware Virtual Infrastructure', 'Working knowledge of Enterprise systems management solutions (like BMC Patrol)', 'A Diverse workplace where associate feel a sense of belonging', 'A company that feels like a small, close-knit community, with the strength of a Fortune 500', 'Tuition reimbursement, training and career development', 'Competitive salary, incentives, 401K, flexible work schedules and a healthy amount of time off']",2020-12-30 23:48:10
Structured Cable designer,A&A Search,N/A,"Southborough, MA","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Experience designing structured cabling systems for office space and distribution centers from small sites to sites as large as 2.5M square feet.', 'Knowledge of UPS and PDU power systems for small and large communications rooms.', 'Experience working with Tele/Data, Architectural, Electrical and Mechanical drawings.', 'Experience developing RFPs which includes working with internal and external partners documenting requirements, work with consultants to create drawings and select contractors to bid on projects.', 'Strong attention to detail to evaluate bids and analyze costs. Work with Global Sourcing and Procurement to negotiate and finalize Statement of Work (SoW).', 'Project Management experience to implement the cabling installation with the trades; the internal team & 3rd party contractors. This includes creating timelines, tracking milestones and costs. Must provide accurate documentation including minutes, issue logs and other reporting documents.', 'Knowledge of industry standards (BICSI, TIA, NEC).', 'Knowledge of Agile/SAFE program', 'Experience managing multiple priorities simultaneously.', 'Evaluate products and services from distributors, manufacturers and contractors.', 'Network equipment configuration & troubleshooting (smart hands).', 'Address incidents, install requests and moves, adds and changes', 'Experience using online incident ticketing systems such as ServiceNow', 'Off-hour and weekend availability', 'MS Word, Adobe Acrobat, Visio, Excel, Confluence and Jira experience', 'Strong communication skills', '5+ years’ experience in a similar role', 'Dental insurance', 'Health insurance', '8 hour shift', 'Monday to Friday', '1 year', 'More than 1 year', 'Likely', 'Yes', 'Remote interview process', 'Social distancing guidelines in place']",2020-12-30 23:48:10
Senior Principal Systems Engineer - Chief Engineer,RTX,4.8 out of 5 from 6 employee ratings,"Saint Pete Beach, FL 33706","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Primary program engineering leadership POC with the customer counterpart', 'Establish and manage a product vision, strategy and goals to align the Program with the Customer and facilitate conflict resolution', 'Support growth opportunities to turn into captured new business', 'Responsible for the entirety of engineering execution including technical budget, cost, schedule and metrics', 'Determines & monitors technical priorities to meet cost, schedule & performance for the entire program', 'Establishes and maintains the program technical baseline, ensuring the product is optimized to meet the contractual needs and can be executed within program budget and schedule', 'Monitor and trend staffing against planned work; proactively engage with Engineering functions to ensure adequate resource assignment.', 'Ensure effective use of independent reviews and achieve on-time completion of all Program Engineering reviews', 'Responsible for the Earned Value and/or financial management of the engineering content on a program.', 'Ensures proper Engineering Risk and Opportunity management (ensures Eng risks are captured, mitigation plans in place across IPTs)', 'Provide cross-IPT technical leadership and coordination - Ensure Engineering leads assigned to program are engaged in all aspects of their program', 'Encourage a diverse workforce by promoting diverse opinions and thought processes and through staffing', 'Minimum 10 years of experience in Systems, Software or Hardware engineering', 'Minimum 5 years demonstrated Engineering Leadership experience and proven track record', 'Working knowledge of Earned Value Management System (EVMS), IMS, & IMP tools or equivalent for managing programs', 'Demonstrated ability to interact effectively with multidisciplinary teams of system design professionals including electrical, mechanical, software and logistics engineers', 'U.S. Citizenship status as this position requires an active DoD Secret U.S. Security Clearance day one of employment and will require the ability to access US only data systems', 'Engineering experience on development or integration programs', 'Capability in leading an IPT or cross-function teams in program execution', 'Strong knowledge in proposal development, particularly Basis of Estimate development, and other contract deliverable artifacts', 'Skilled presenter with prior responsibility for dealing with customers, management, technical staff, and internal / external organizations', 'Experience with accountability; responsibility for prioritizing work tasks and customer requirements across multiple teams', 'Team building and motivational skills - training and developing team in disciplined engineering processes,', 'Proven leadership skills and behaviors', 'Self-motivated and capable of performing tasks with minimal oversight.', 'Strong communication, time management, and interpersonal skills', 'Risk and opportunity management, scope management,', 'Knowledge of Raytheon Intelligence and Space (RIS) Engineering products, technologies, and processes', 'Active DOD Secret security clearance', 'Bachelor of Science degree in Science, Technology, Engineering or Mathematics (STEM) from an accredited educational institution (i.e. Engineering, Physics, Mathematics, etc.)', 'Master of Science degree in Science, Technology, Engineering or Mathematics (STEM) from an accredited educational institution (i.e. Engineering, Physics, Mathematics, etc.)']",2020-12-30 23:48:10
Industrial Painter Helper,PCX Corporation,3.5 out of 5 from 22 employee ratings,"Clayton, NC 27520","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Prepare metal surfaces for painting using sandblast equipment, hand grinders, buffers or other abrasive equipment as required', 'Clean equipment regularly and maintain paint equipment in good condition', 'Operate overhead crane and forklifts in a safe manner to move material in and out of paint booth as required', 'Keep work area clean and adhere to good housekeeping in performance of job tasks', 'Follow all safety guidelines and requirements', '1-3 years of prior experience in related industry preferred', 'High school graduate or GED; Technical Certification preferred.', 'Ability to produce quality product in an efficient and productive manner to meet customer project schedules', '401(k)', 'Dental insurance', 'Disability insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Vision insurance', '10 hour shift', 'Manufacturing', 'Weekly', 'Dependable -- more reliable than spontaneous', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'A job for which military experienced candidates are encouraged to apply', 'pcxcorp.com', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-12-30 23:48:10
Automation Engineering Architect,Discover,"3.9 out of 5 from 2,822 employee ratings","Riverwoods, IL 60015","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Design and Develop overall architectural impact assessment and analysis for quality, on complex large scale pre-release, upgrades and current versions of software.', 'Enable iterative approach to quality during each phase of systems development prior to implementation', 'Implement quality engineering activities that generally impact multiple components / processes, work of own and possibly other teams. Typically assigned highly complex, and high-risk undertakings that require expert knowledge of technology solution, coding languages and regularly require the application of independent judgement and creativity', 'Provide technical expertise of system architecture, drive and recommend optimal testing strategies for various products and applications certifying customer quality. Design QA infrastructure, establish testing specifications to provide desired functionality to technology solutions', 'Collaborate with DevOps, Development and Product owners to verify the testability of the release and define strategies and best practices for all quality streams', 'Contribute in Value Stream PI events to measure, manage and progress on quality engineering roadmap and delivery outcomes', 'Develop a roadmap and detailed implementation plan for automation, functional, integration/E2E & performance quality engineering services for assigned SAFe value streams', 'Ability to evaluate and select automation, functional and performance engineering tools for different products and applications. Provide working prototypes to confirm the feasibility of technical solutions. Develop best practices, procedures and enable continuous improvement', 'Establish a strong partnership with architecture, software engineering/development, quality engineers and DevOps to enabling CI/CD delivery model which is scalable and merit quality', 'Provide training to Software Development Engineers, QA and architect resources on testing strategies, standards, tools and processes. Work closely with quality assurance teams and functions to help, grow and improve the test processes and skill set', 'Associates in n Computer Science or related technical field', '6+ years of experience in test management or related', 'Bachelor’s Degree and at least 10 years of experience in software development and quality engineering.', 'At least 2 years of experience as a software architect or technical product management', 'Experience working on multiple product delivery cycles simultaneously', 'Experience working in agile/iterative development methodology. SAFe experience is preferred', 'Ability to collaborate with application, technical and value stream architects and software development engineers to ensure design for quality practices and tooling are formulated and adhered', 'Ability to collaborate with sr. management for managing quality deliverables and outcomes', 'Experience with technology eco-system that supports end-to-end micro service architecture, such as, APIs, message queue, container, service registry/discovery etc.', 'Strong programming skills, primarily in Java. Experience in multiple programming language is preferred', 'Experience in using the automated tools for end-to-end product architecture and technology stack in a CI/CD setting', 'Detail oriented communication and documentation skills\\', 'Experience with browser or client side monitoring/analysis tools ( e.g. Gomez, Firebug, Web page test)', 'Exposure to applications developed on AWS, PCF or similar platforms', 'Ability to read and analyze application logs, GC logs, thread dumps, head dumps etc. Experience in JVM and SQL queries performance tuning', 'Ability to identify system bottlenecks and resource leaks with strong troubleshooting, problem solving & reasoning skills', 'Experienced with Service Virtualization using open source or commercial tools', 'Exposure to technologies Micro Services, Cloud Native development, Cloud powered data analytics.', 'Working knowledge of REST, RPC service patterns and web sockets and other client/server interaction models is a plus']",2020-12-30 23:48:10
Solution Architect – Managing Consultant,Guidehouse,3.4 out of 5 from 362 employee ratings,"Washington, DC 20006","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Deep understanding of application, data, and infrastructure architecture technologies', 'Knowledge of business drivers and emerging computing trends impacting technology investment decisions', '5+ years of experience in a solution architect or solution engineer role, with various infrastructure technologies', '7+ years of experience in a technical consulting, solution architect, or presales engineering role', '7+ years of experience with designing, implementation, or consulting with distributed applications', 'Understanding of the needs in leading IT modernization programs and managing senior clients through the journey', 'Experience with leadership, consensus building, and mentoring of technology resources', 'Experience with building, delivering, and managing Cloud IaaS environments using IaaS platforms, including', 'Understanding of Amazon Web Services (AWS), Azure, Google Cloud, and Oracle, and approach to “migrate” on premise workloads to the cloud', 'Experience with building, delivering, and managing hybrid Cloud IaaS environments using platforms', 'Currently hold or have the ability to obtain a security clearance.', ""Minimum Degree Required: Bachelor's degree, Master’s preferred."", 'Experience with advising senior IT executives on IT modernization programs in the Dept of Defense', 'Knowledge of FedRAMP, ATO, and other Federal governance and security standards and requirements', 'Experience with multi-threaded, and distributive Cloud architectures and frameworks', 'Experience with AWS, including EC2, Network, ELB, and S3; and Microsoft Azure Expert Certification and/or AWS Technical Professional Certification', 'Experience with Microsoft Identity Services, including Active Directory Domain Services, Federation Services and associated identity management tools a plus', 'The successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described.']",2020-12-30 23:48:10
Quality Auditor - Winchester,IWT Primary Manufacturing Plant,N/A,"Winchester, KY 40391","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Sample, inspect, and test products according to quality plan requirements', 'Quarantine and create hold tags for any non-conforming product from current and previous shifts when identified.', 'Inspect and sign off finished pallets of product', 'Investigate any non-conforming product', 'Assist production with disposition of product on hold', 'Work with production team on product quality throughout shift', 'Record data on forms and enter data into electronic files as required', 'Complete a daily shift report', 'Work with production and process engineers on product trials and projects', 'Maintain a clean work area', 'Assist in Quality Lab as needed', 'Assist Quality Manager as needed', 'Assist in maintaining ISO Compliance', 'Coverage for Quality Auditor responsibilities in multiple buildings when necessary.', 'Other duties assigned by management', 'High School Diploma or equivalent required', 'Basic computer skills (e-mail, spreadsheets, word processing and databases)', 'Good written and verbal communication skills', 'Must be able to lift 75 pounds', 'Must be able to climb stairs', 'Ability to follow written and oral instructions', 'Must have a good attitude and willingness to learn', 'Strongly oriented to teamwork']",2020-12-30 23:48:10
"Field Service Engineer 2, Diagnostic Imaging - Washington DC/ Baltimore",Philips,"4 out of 5 from 3,652 employee ratings",Remote,"['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Job', 'Company', 'The engineer must demonstrate ownership in difficult circumstances and show a sense of urgency to get things done according to expectations of Customer and Company.', 'Responsible for providing “World Class Service” and achieving “Highly Satisfied” Initial and Continuing Quality Scores.', 'Participates in the Regional Work Teams to maximize customer satisfaction consistent with Regional Business Objectives.', 'Adapts to varying needs and requirements of the customer and the business.', 'Develop and implement best practices.', 'Facilitates change; builds consensus and/or creates the need to work together to solve a common problem.', 'Seeks out opportunities to increase capability and capacity (cross-trains into multiple modalities, new tools).', 'Puts the team ahead of individual needs and displays a positive attitude.', 'Complete and understand all training assigned through Training Management System prior to due date.', 'Learn and adhere to Federal and State regulatory performance standards, registration, Quality Systems Regulations, EPA and OSHA regulations. Follow established quality and safety requirements (electrical & radiation safety, safe lifting practices, etc.).', 'Submit timesheets, expense reports and business receipts according to defined guidelines. Maintain documentation for vehicle operation and submit mileage reports per company policy.', 'Complete Planned Maintenance, Field Change Order, Corrective Maintenance and Installation SWOs and associated documentation within regulatory and company timeframes and requirements.', 'Understand customer contract entitlements and adhere to specified requirements.', 'Manage company assets effectively; including labor time, parts, tools, test equipment, Returned Materials Authorizations, customer purchase orders, company vehicle, laptop, cell phone, business expenditures, etc.']",2020-12-30 23:48:10
Lead Manufacturing Engineer - Lathe,Vickers Engineering Inc,N/A,"New Troy, MI 49119","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'CNC programming: 3 years (Required)Associate (Preferred)Fanuc: 3 years (Preferred)', '401(k)', '401(k) matching', 'Dental insurance', 'Disability insurance', 'Flexible schedule', 'Flexible spending account', 'Health insurance', 'Life insurance', 'Paid time off', 'Referral program', 'Retirement plan', 'Vision insurance', 'Day shift', 'Bonus pay', 'Signing bonus', 'Associate (Preferred)', 'CNC programming: 3 years (Required)', 'Fanuc: 3 years (Preferred)', 'One location', 'Innovative -- innovative and risk-taking', 'Aggressive -- competitive and growth-oriented', 'Outcome-oriented -- results-focused with strong performance culture', 'Team-oriented -- cooperative and collaborative', 'www.vickerseng.com', 'https://www.facebook.com/vickersengineering/', 'Waiting period may apply', 'Only full-time employees eligible', 'No', 'Personal protective equipment provided or required', 'Temperature screenings', 'Social distancing guidelines in place', 'Virtual meetings', 'Sanitizing, disinfecting, or cleaning procedures in place']",2020-12-30 23:48:10
Mid to Senior-Level GNC Engineer - Hypersonics (multi grade),RTX,4.8 out of 5 from 6 employee ratings,"Green Valley, AZ 85622","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Development of hypersonic systems architectures and requirements.', 'Knowledge of system engineering design methods including requirements analysis and flow down.', 'Concept development and execution of trade studies for hypersonic missile applications.', 'Development of overall system integration plan and subsystem strategy for design, analysis, and testing.', 'Assessing system interface and integration risks through simulation and flight test data analysis.', 'Development of systems models for use in high fidelity simulations.', 'Implementation of advanced guidance algorithms to maximize performance of hypersonic systems.', 'Coding of algorithms in higher order computer languages to support simulation development.', 'Performance analysis by simulation and flight test, including verification and validation techniques.', 'BS degree in Engineering or Bachelor’s degree in Computer Science, Mathematics, or Physics.', 'Six (6) years of Guidance, Navigation and Controls Engineering or Systems Engineering experience', 'Two (2) years of professional experience in hypersonic or supersonic aircraft or missile system design and analysis using high fidelity simulations.', 'Experience conducting trade studies to analyze and enhance system performance.', 'Experience developing or modifying code in higher level languages like FORTRAN, Ada, C++, and/or MATLAB to support embedded software development and/or hardware/software integration.', 'United States citizenship', 'MS or PhD in aforementioned disciplines. ABET is the preferred, although not required, accreditation standard', 'Prior experience performing analysis of hypersonic / supersonic air vehicle attributes in either simulation or flight test venues.', 'Research and/or applied experience in advanced hypersonics systems design techniques such as:Development of hypersonic guidance algorithm architectures and requirements.Optimal guidance theory, trajectory shaping, estimation theory, analysis of random processes, non-linear Kalman filters, and/or particle filters.Advanced control techniques such as adaptive control, nonlinear control, or integrated guidance and control.Development of hypersonic autopilot topologies and requirements.Development of hypersonic aerodynamic configurations and requirements.Conducting high-speed wind tunnel tests and CFD analysis to predict aerodynamic effects.Analyzing the effects of the high-speed environment on RADAR and RF systems.Demonstrated experience taking a hypersonic missile design from concept to flight test with expertise verifying subsystem performance from simulation and post-flight data analysis.', 'Experience in model development and testing with proven knowledge of fundamental concepts and a high level of analytical capability to drive technical solutions.', 'Concept development to generate the specifications and documentation necessary to support architecture design and integration of requirements into simulation and tactical applications.', 'Career development skills, including written and oral communication skills and the ability to work in a team environment.', 'Familiarity and knowledge of systems engineering and analysis for interfacing with multiple engineering disciplines.', 'Ability to operate independently with minimal supervision as well as part of a team.', 'Ability to communicate effectively with senior leadership and other engineering disciplines.', 'Coupled analysis, specifically aero/thermal/structural analysis', 'Experience leading a program focused development team, with understanding of how to balance and drive system performance and survivability.', 'Well known with established relationships in the defense community including the hypersonics technical domain, with patents and publications in applicable technical areas a plus.']",2020-12-30 23:48:10
Engineer,American Water,3.4 out of 5 from 295 employee ratings,"Plainfield, NJ","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Assist in the preparation of technical, bidding and contractual documents associated with delivery of capital investment projects.', 'Manage multiple projects and perform varied engineering assignments associated with planning, design or construction.', 'Ensure scope and quality of work achieve the intent of all Design Concepts and Company standards for capacity, performance, reliability, safety and regulatory compliance.', 'Develops technical information and concepts into feasible and effective engineering approaches.', 'Develop strategic and strong working relationships with engineering firms, vendors, and contractors.', 'Provide technical expertise on engineering and operational issues.', 'Supervises field and contract personnel to ensure timely completion of assignments, within budget and adherence to standards. Adhere to Engineering Standards, specifications and, equipment manufacturer recommendations to support Center of Excellence initiatives. Coordinate the pre-qualification and selection of consulting and construction organizations for projects using negotiation or competitive selection process. Establish project budget and cost. Contribute to effective communication by listening and providing constructive feedback; supporting the creation of an open and honest work environment; cascading and sharing knowledge and information relevant to other members of the team and colleagues across the business.', 'Demonstrated knowledge of engineering design theory and practice, project management, construction and contract management, water resources, water/wastewater facilities and utility operations.', 'Knowledge of current trends in water quality and treatment and other aspects of the regulated and non-regulated water industry.', 'General understanding of US regulations (commercial and environmental), legislation and trends impacting the water industry.', 'Sound business acumen and judgment.', 'Minimum 0 - 4 years experience in water resources design and project management. Utility experience is a plus.', 'Bachelor’s Degree in Engineering (Environmental or Civil preferred)', 'Analysis and Problem Solving - Analyzes and resolves business issues through the application of critical reasoning skills and general business experience.', 'Influencing - The ability to articulate an objective or idea in a compelling manner, so that others are persuaded to act on its merit.', 'Organizational Awareness - The knowledge and development of formal and informal business relationships with key stakeholders, internal and external to the organization, that enable business objectives to be accomplished.', 'Sharing Knowledge & Expertise - Drives business performance by developing and contributing specific technical or professional knowledge, skills and experience. Demonstrates a professional attitude.', 'Strategic Focus - Looks at the big picture, thinks about the business as a whole, both within its own environment and in the global marketplace, and creatively identifies new horizons.', 'Teamworking - Is committed to working collaboratively to achieve business goals, building cohesiveness and identity with a work group, and valuing individual perspectives and contributions.']",2020-12-30 23:48:10
Product Support Engineer - Semiconductor,TOSOH SMD INC,3.1 out of 5 from 19 employee ratings,"Grove City, OH 43123","['Find jobs', 'Company Reviews', 'Find salaries', 'Employers', 'Change country', 'Help Center', 'Provide PVD support to customers for performance issues which include deposition rate, voltage fluctuations, particle performance, thin film uniformity, and thin film resistivity.', 'Support the sales team as a resource for product sputter performance questions.', 'Lead cross-functional teams for troubleshooting and root cause analysis for PVD performance issues.', 'Perform PVD investigative analysis by establishing a detailed problem statement with the customer.', 'Collect, analyze, and interpret metallurgical and PVD data.', 'Summarize work in reports and presentations.', 'Other related duties.', 'BS degree required. Degree in engineering preferred.', 'Experience with product development, technical sales, or technical product support preferred.', 'Understanding of product development, engineering processes, and manufacturing processes required.', 'Hands on experience with thin film processes (semiconductor, FPD, solar) and/or PVD systems required.', 'Excellent interpersonal skills and the ability to effectively communicate and coordinate across organizational and cultural boundaries.', 'Ability to quickly and effectively assess, evaluate, and communicate product / process requirements and technical issues, including the ability to deliver high level presentations internally and externally.', 'Ability to effectively motivate, facilitate, and direct the activities of individuals and project teams.', 'Excellent organizational and resource management skills.', 'Ability to travel on a frequent and extended basis, domestically and internationally, sometimes with little notice. Up to 15% at times.']",2020-12-30 23:48:10
