job_title,company,location,date_posted,applicants,job_text,seniority_level,employment_type,job_function,industries,date_scraped
Data Engineer,Belcan,"Washington, DC",4 hours ago,Be among the first 25 applicants,"['', 'Create, Modify, and Utilize data quality methodologies and processes ', 'Work with a cross-functional team to review work and create solutions ', 'Create data integration routines and pipelines ', 'Data Engineers', 'Responsibilities', 'Apply data architecture principles and targeted solutions via supporting data models Create, Modify, and Utilize data quality methodologies and processes Create data integration routines and pipelines Work with a cross-functional team to review work and create solutions ', 'Requirements', 'Apply data architecture principles and targeted solutions via supporting data models ', 'Experience developing and deploying distributed data applications via open-source frameworks', 'DC Area', 'Active DoD Clearance ', 'Experience with cloud implementation(s) ', 'Active DoD Clearance Experience with cloud implementation(s) Able to utilize JavaScript, Node.JS and JSON efficiently Experience developing and deploying distributed data applications via open-source frameworks', 'Able to utilize JavaScript, Node.JS and JSON efficiently ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,TetraScience,"Boston, MA",5 hours ago,Be among the first 25 applicants,"['', 'Create and negotiate Statement of Work', 'Experience with tools like Spotfire, Tableau, Jupyter notebook (any of them)', 'Benefits', 'Professional development fund for you to gain relevant certificate such as AWS Solution Architect certificate and etc.', ' Elasticsearch, science background or experience with scientific instruments Experience with tools like Spotfire, Tableau, Jupyter notebook (any of them) Excellent communications skills, attention to details, and the confidence to take control of project delivery Ability to understand a highly technical product and communicate with the product management and engineering team effectively Strong project and account management skills Strong interpersonal and proactive problem-solving skills Ability to think creatively on how to solve projects risks without reducing quality Team player and ability to roll up your sleeves and do what it takes to make the team successfulBest, ', ' Take on larger projects that have a more complicated scope and continue to grow as a data engineer. Take on more platform and product features and continue to grow into a software engineer. Take on more responsibility in pre-sales as Solution Architect. In this role, you will Work closely with the sales to understand Life Sciences companies’ need for data collection, data integration, data management, and data science. Design and architect the solution using our Data Integration Platform. Create and negotiate Statement of Work Perform pre-sales demo for Life Science companies Perform pre-sales investigations and prototypes of data sources, data models ', 'Work with the customer to test and make sure the solution fulfills their requirements and solves their need', 'Requirements', 'Generous paid time off (PTO)', 'Comprehensive Medical, Dental and Vision coverage', 'Competitive salary and equity and in a fast-growing company', 'Take on more platform and product features and continue to grow into a software engineer.', ' Proficient with Python Proficient with SQL Passionate about science and building solutions to make the data more accessible to the end users ', 'Open office environment for maximum collaboration', 'Ability to think creatively on how to solve projects risks without reducing quality', 'Proficient with SQL', 'Build visualization, report and dashboards using Spotfire, Tableau, Jupyter notebook and etc.', 'Design and build data pipelines, unit tests, integration tests, utility functions using Python', 'Proficient with Python', 'Facilitate internal project post-mortems to identify areas of improvement on the next implementation', 'Research and prototype data acquisition strategy for scientific instruments used in the lab', 'Work closely with the sales to understand Life Sciences companies’ need for data collection, data integration, data management, and data science.', 'Strong interpersonal and proactive problem-solving skills', 'Design and build data models for scientific instruments and CRO/CDMO reports', 'Perform pre-sales demo for Life Science companies', ' Research and prototype data acquisition strategy for scientific instruments used in the lab Research and prototype file parsers for instrument output files (excel, pdf, sometimes vendor-specific binary formats) Design and build data models for scientific instruments and CRO/CDMO reports Design and build data pipelines, unit tests, integration tests, utility functions using Python Build visualization, report and dashboards using Spotfire, Tableau, Jupyter notebook and etc. Work with the customer to test and make sure the solution fulfills their requirements and solves their need Coordinate project kickoff meetings; manage the customer relationship throughout the project; and conduct formal project closeout meetings Facilitate internal project post-mortems to identify areas of improvement on the next implementation ', 'Strong project and account management skills', 'Catered team lunch every Wednesday and a variety of free snacks', 'Team player and ability to roll up your sleeves and do what it takes to make the team successfulBest,', 'Passionate about science and building solutions to make the data more accessible to the end users', 'Ability to understand a highly technical product and communicate with the product management and engineering team effectively', 'Ability to choose and craft the next step in your career path as a Data Engineer, Software Engineer or Solution architect. Room for you to explore your interest, establish your skillset and tailor your direction based on your passion and interest.', 'Design and architect the solution using our Data Integration Platform.', 'Perform pre-sales investigations and prototypes of data sources, data models', 'Elasticsearch, science background or experience with scientific instruments', 'Take on larger projects that have a more complicated scope and continue to grow as a data engineer.', 'Take on more responsibility in pre-sales as Solution Architect. In this role, you will', 'Research and prototype file parsers for instrument output files (excel, pdf, sometimes vendor-specific binary formats)', 'Convenient location in Boston Downtown Crossing area; close to the T (red/orange/green/blue line) and South Station', ' Ability to choose and craft the next step in your career path as a Data Engineer, Software Engineer or Solution architect. Room for you to explore your interest, establish your skillset and tailor your direction based on your passion and interest. Professional development fund for you to gain relevant certificate such as AWS Solution Architect certificate and etc. Competitive salary and equity and in a fast-growing company Comprehensive Medical, Dental and Vision coverage Generous paid time off (PTO) Catered team lunch every Wednesday and a variety of free snacks Convenient location in Boston Downtown Crossing area; close to the T (red/orange/green/blue line) and South Station Open office environment for maximum collaboration', 'Excellent communications skills, attention to details, and the confidence to take control of project delivery', 'Coordinate project kickoff meetings; manage the customer relationship throughout the project; and conduct formal project closeout meetings']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Data Infrastructure Engineer,GitHub,"Washington, DC",16 hours ago,Be among the first 25 applicants,"['', 'Use data to understand the availability, reliability, and sustainability of our infrastructure', 'Build services and systems that empathetically and pragmatically meet real operability needs of GitHub developers', 'You have developed and scaled services in Go.', 'Build services and systems that empathetically and pragmatically meet real operability needs of GitHub developersUse data to understand the availability, reliability, and sustainability of our infrastructureYou will respond to the needs of users and of other developers at GitHub.Work closely with other teams from across the organization', 'Work closely with other teams from across the organization', 'Experience diagnosing and resolving complex multi-system performance problems.', 'You take a pragmatic approach to decision making and design choices.', 'Experience building and deploying large, complex distributed systems with an eye toward reliability.Proficiency in Golang, Python, and/or Ruby.You take a pragmatic approach to decision making and design choices.', 'Proficiency in Golang, Python, and/or Ruby.', 'Experience building highly available services at scale.', 'Minimum Qualifications:', 'Experience building and deploying large, complex distributed systems with an eye toward reliability.', 'Experience with Docker and container orchestration systems.', 'Who We Are:', 'Why You Should Join:', 'Experience building highly available services at scale.You have developed and scaled services in Go.Experience diagnosing and resolving complex multi-system performance problems.Experience with Docker and container orchestration systems.', 'Responsibilities:', 'You will respond to the needs of users and of other developers at GitHub.', 'Preferred Qualifications:', 'Leadership Principles:']",Associate,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
Data Engineer,Austin Fraser,"Austin, Texas Metropolitan Area",,N/A,"['', 'Grow, learn and lead on this team! ', 'Use your python programming ability to interact with third-party APIs as data sources ', 'Opportunity to work on interesting projects and stay up to date with the latest technology ', '$110k - $130k Base Salary ', '2+ years as a Data Engineer Python, SQL, AWS and CI/CD ', 'Python, SQL, AWS and CI/CD ', 'What You Get:\xa0 ', 'Requirements: ', 'Be a key contributor to a cloud-based data pipeline creation & orchestration ', 'Competitive Bonus Package ', 'Location: Austin or San Antonio ', 'In this role you will:', 'In this role you will: ', 'Collaborate with Data Scientists to find requirements and then source the data ', 'Build the infrastructure to capture large amounts of company data Collaborate with Data Scientists to find requirements and then source the data Use your python programming ability to interact with third-party APIs as data sources Be a key contributor to a cloud-based data pipeline creation & orchestration ', '2+ years as a Data Engineer ', '\xa0 ', 'Location: ', 'Build the infrastructure to capture large amounts of company data ', 'Requirements:', ""As a Data Engineer, you will heavily assist with moving data through the organization's infrastructure. Your support will allow the continued development of innovative analytic tools and data sets that allow customers to make data-driven decisions. "", 'What You Get:', '$110k - $130k Base Salary Competitive Bonus Package Organization heavily investing in their Data Department Opportunity to work on interesting projects and stay up to date with the latest technology ', 'For further details please submit a resume. ', 'Austin Fraser Inc is acting as an employment business in relation to this advert. As a professional company, we gladly welcome applications from persons of any age and background and do not intend to discriminate with advert text and terminology.', ' ', 'Organization heavily investing in their Data Department ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer - REMOTE,Optello,"Remote, OR",5 hours ago,Be among the first 25 applicants,"['', ' Strong verbal and written communication experience', ' 7+ years of Java programming experience 5+ years of Python programming experience 5+ years of SQL database experience Strong verbal and written communication experience RESTful API and server-side API integration experience', ' Fully stocked snacks', ' Build upon existing data service architecture to support internal and external applications', ' 5+ years of SQL database experience', 'Optello is proud to be an Equal Opportunity Employer', ' Experience with Maria databases', 'Your Right to Work', ' Build scalable pipelines capable of processing massive amounts of data Build upon existing data service architecture to support internal and external applications Work supporting ETL pipelines, real time streams, and data warehouses Design and implement process improvements, automate manual processes, and redesign infrastructure Build upon on the infrastructure required to optimize the extraction, transformation, and loading of data using Java, Python, SQL Working in a remote setting with virtual team meetings on a regular basis Collaborate with business intelligence and analytics teams to optimize Tableau report queries', ' Catered breakfast and lunch each week', ' 7+ years of Java programming experience', ' Amazing healthcare benefits', ' Salesforce integration experience', ' Competitive starting salary Amazing healthcare benefits 401k + match Generous PTO Equipment provided Stipend for workspace', 'Job Title:', 'Job Duration:', ' Experience with Cassandra databases', ' Childcare assistance', 'Email Your Resume In Word To', ' Experience with Cassandra databases Additional NoSQL database experience Experience with Maria databases Salesforce integration experience', ' Catered breakfast and lunch each week Fully stocked snacks Pet-friendly office Childcare assistance', ' Design and implement process improvements, automate manual processes, and redesign infrastructure', 'Must Have Skills', ' Stipend for workspace', ' Pet-friendly office', 'Requirements:', ' Equipment provided', ' Work supporting ETL pipelines, real time streams, and data warehouses', ' Additional NoSQL database experience', ' 401k + match', ' Build scalable pipelines capable of processing massive amounts of data', ' RESTful API and server-side API integration experience', ' Generous PTO', ' 5+ years of Python programming experience', ' Working in a remote setting with virtual team meetings on a regular basis', ' Competitive starting salary', ' Collaborate with business intelligence and analytics teams to optimize Tableau report queries', 'Bonus Skills', ' Build upon on the infrastructure required to optimize the extraction, transformation, and loading of data using Java, Python, SQL', 'Job Location:', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : TB10-1597099 -- in the email subject line for your application to be considered.***']",Entry level,Full-time,Information Technology,Construction,2020-10-20 12:01:24
Data Engineer,Qlarion,"Richmond, VA",,N/A,"['To be considered, all candidates must meet or exceed these requirements. ', 'A Demonstrated working knowledge of database schema,      objection management, data modeling & architecture, and data warehouse      design. ', 'Knowledge of Structured Query Language (SQL) and      Transact-SQL (T-SQL) ', 'Applicants should be prepared to provide experience examples for the requirements above ', ' Analytical skills and a general business understanding  Knowledge of Structured Query Language (SQL) and      Transact-SQL (T-SQL)  Experience defining/implementing an Enterprise Data      Warehouse using best practices  Experience working directly with clients to define      their requirements, document them, and to support and troubleshoot issues      as they arise', 'Qlarion seeks Data Engineer for our Richmond, VA area ', ' U.S. Citizenship or Green Card Holder.  Our U.S. Govt. clients contractually require us to hire      ONLY U.S. Citizens or Green Card Holders for their projects.  A clear concise Resume NOT more than 5 pages long  Education: BS Computer Science or BS Engineering or a      BS Degree in a related field  At least 4 years of experience using Talend Data      Integration, Informatica Power Center or similar ETL tool as a developer  Preferred at least 1 year experience using Tableau Prep  At least 1 year experience      defining/modeling/implementing an Enterprise Data Warehouse using best      practices  Experience using ETL tools in a data analyses, data      engineering or similar role.  A Demonstrated working knowledge of database schema,      objection management, data modeling & architecture, and data warehouse      design.  Excellent written or oral communication skills  ', 'MUST HAVE REQUIREMENTS: ', 'At least 4 years of experience using Talend Data      Integration, Informatica Power Center or similar ETL tool as a developer ', 'Preferred Skills, Knowledge & Experience ', 'Excellent written or oral communication skills ', 'Analytical skills and a general business understanding ', 'Experience defining/implementing an Enterprise Data      Warehouse using best practices ', 'At least 1 year experience      defining/modeling/implementing an Enterprise Data Warehouse using best      practices ', 'Education: BS Computer Science or BS Engineering or a      BS Degree in a related field ', 'Experience using ETL tools in a data analyses, data      engineering or similar role. ', 'A clear concise Resume NOT more than 5 pages long ', 'Our U.S. Govt. clients contractually require us to hire      ONLY U.S. Citizens or Green Card Holders for their projects. ', 'U.S. Citizenship or Green Card Holder. ', 'Preferred at least 1 year experience using Tableau Prep ', 'Experience working directly with clients to define      their requirements, document them, and to support and troubleshoot issues      as they arise']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Casper,"New York, NY",7 hours ago,Over 200 applicants,"['', 'A full gifted bed set when you join and product discounts for friends and family!', 'Advance modern, agile software development practices and help build a culture of great engineering and organizational practices', ' AWS Redshift Looker dbt Airflow Kubernetes Presto Postgres and Oracle databases ', 'Looker', 'Free snacks and coffee, including a huge breakfast selection (10 types of cereal anyone?)', 'You appreciate the business context that drives the need for data solutions and love working on projects to support those efforts', ' You will develop data workflows to ingest, validate, and model data to support analytics and business operations needs Be accountable for technical delivery and work with your team and stakeholders on strategy and execution Collaborate with other engineers and product managers in solving interesting and challenging problems across our systems Advance modern, agile software development practices and help build a culture of great engineering and organizational practices Learn. Learn from the team and on your own what you might not know about data infrastructure, business operations, and open source tooling to make you a stronger asset to the team ', 'Looking for a job to get you out of bed?', 'Catered lunches twice a week to give you time to catch up with your teammate', 'The syrup on your waffles...', ' Participation in our HQ bonus program for some splurging and equity so that you’re part of the Casper family. Medical, vision, and dental insurance to help you with those coughs or cavities (too many waffles...).. Wellness programs like cash incentives for tracking sleep and fitness, credits for your favorite studios and in-office activities Unlimited vacation policy. If you need time off just take it; we trust you! Catered lunches twice a week to give you time to catch up with your teammate Free snacks and coffee, including a huge breakfast selection (10 types of cereal anyone?) A full gifted bed set when you join and product discounts for friends and family! ', 'You have experience working with a diverse set of stakeholders and helping them understand the trade-offs to different product and technical decisions', ' Python and SQL expertise Experience working with data modeling (star schema) and validation dbt and Looker experience a plus MuleSoft or AWS Lambda experience a plus Cloud platform & containerization experience (we use EKS on AWS) Experience writing Spark ETL jobs a plus ', 'Medical, vision, and dental insurance to help you with those coughs or cavities (too many waffles...)..', 'Collaborative, independent-thinking, and detail-oriented in how you approach projects', 'Unlimited vacation policy. If you need time off just take it; we trust you!', ' You have the following technical capabilities: Python and SQL expertise Experience working with data modeling (star schema) and validation dbt and Looker experience a plus MuleSoft or AWS Lambda experience a plus Cloud platform & containerization experience (we use EKS on AWS) Experience writing Spark ETL jobs a plus   Collaborative, independent-thinking, and detail-oriented in how you approach projects You appreciate the business context that drives the need for data solutions and love working on projects to support those efforts You have experience delivering timely, high quality data products and models You have a proven engineering background with experience developing data workflows and a good operational understanding of data operations, including processing, storage, quality and management (ML and streaming infra a plus) You have experience working with a diverse set of stakeholders and helping them understand the trade-offs to different product and technical decisions You care deeply about agile software processes, data-driven development, reliability, and efficiency ', 'Experience writing Spark ETL jobs a plus', 'Our dream candidate...', 'MuleSoft or AWS Lambda experience a plus', 'You have experience delivering timely, high quality data products and models', 'You will develop data workflows to ingest, validate, and model data to support analytics and business operations needs', 'Cloud platform & containerization experience (we use EKS on AWS)', 'Be accountable for technical delivery and work with your team and stakeholders on strategy and execution', 'Our Stack includes...', 'Python and SQL expertise', 'You care deeply about agile software processes, data-driven development, reliability, and efficiency', 'Kubernetes', 'Experience working with data modeling (star schema) and validation', 'You have the following technical capabilities: Python and SQL expertise Experience working with data modeling (star schema) and validation dbt and Looker experience a plus MuleSoft or AWS Lambda experience a plus Cloud platform & containerization experience (we use EKS on AWS) Experience writing Spark ETL jobs a plus  ', 'dbt and Looker experience a plus', 'Presto', 'dbt', 'Wellness programs like cash incentives for tracking sleep and fitness, credits for your favorite studios and in-office activities', 'AWS Redshift', 'Learn. Learn from the team and on your own what you might not know about data infrastructure, business operations, and open source tooling to make you a stronger asset to the team', 'Airflow', 'Postgres and Oracle databases', 'When you’re not catching zzz’s, this is what you’ll do...', 'You have a proven engineering background with experience developing data workflows and a good operational understanding of data operations, including processing, storage, quality and management (ML and streaming infra a plus)', 'Participation in our HQ bonus program for some splurging and equity so that you’re part of the Casper family.', 'Collaborate with other engineers and product managers in solving interesting and challenging problems across our systems']",Entry level,Full-time,Information Technology,Retail,2020-10-20 12:01:24
Data Engineer,DocuSign,"Chicago, IL",9 hours ago,Be among the first 25 applicants,"['', 'Experience with Github and JIRA/Confluence', 'Bachelor’s Degree or equivalent in Computer Science, Engineering, Information Systems, or other quantitative fields', 'The team', 'About DocuSign', 'Proficiency and 2+ years of relevant experience with Python', 'Engineering @DocuSign', 'Experience with ElasticSearch and Cassandra', 'Our agreement with employees ', ' Design and manage scalable workflows for extracting and shifting data from multiple data centers and back-end systems into a centralized analytics environment Work with Product Data Science and Engineering to assess the quality and reliability of new and existing sources of product telemetry data, and advise when those sources need to be supplemented with new instrumentation or additional feeds Develop a deep understanding of the relevant application and data systems architecture, and use that expertise to provide technical guidance in the development of product metrics and data models Drive improvements in data quality assurance, by integrating tools for monitoring and alerting into the data pipelines, and providing insights and solutions around gaps or bottlenecks ', '5 years of professional experience with building and managing data pipelines that integrate multiple systems (SQL/NoSQL databases, log analytics systems, message queues, etc), including batch and real-time extraction, designing for scale, data transformations, job scheduling, and strategies for handling errors and outages', 'Drive improvements in data quality assurance, by integrating tools for monitoring and alerting into the data pipelines, and providing insights and solutions around gaps or bottlenecks', 'Data Engineer ', 'Proficiency in other programming languages such as Java or Scala', 'Experience with Change Data Capture (CDC) approach to data integration and merge and sync operations into a big data environment', ' Masters in Computer Science, Engineering, Information Systems, or other quantitative fields Experience with Change Data Capture (CDC) approach to data integration and merge and sync operations into a big data environment Experience with ElasticSearch and Cassandra Experience managing tables and jobs in Snowflake data warehouse Experience with Log Analytics Systems such as Kusto, Splunk, DataDog, etc. Experience with workflow automation tools like Apache Airflow Proficiency in other programming languages such as Java or Scala Experience with software development lifecycle/agile methodology Experience with Github and JIRA/Confluence ', 'Preferred Qualifications', 'Experience managing tables and jobs in Snowflake data warehouse', 'This position', 'Design and manage scalable workflows for extracting and shifting data from multiple data centers and back-end systems into a centralized analytics environment', 'Experience with software development lifecycle/agile methodology', 'Responsibilities', 'Masters in Computer Science, Engineering, Information Systems, or other quantitative fields', 'Develop a deep understanding of the relevant application and data systems architecture, and use that expertise to provide technical guidance in the development of product metrics and data models', 'Experience with Log Analytics Systems such as Kusto, Splunk, DataDog, etc.', 'Proficiency and 3+ years of relevant experience with doing complex data manipulation in SQL (e.g. joins, pivots, analytic functions, nested and array fields)', ' Bachelor’s Degree or equivalent in Computer Science, Engineering, Information Systems, or other quantitative fields 5 years of professional experience with building and managing data pipelines that integrate multiple systems (SQL/NoSQL databases, log analytics systems, message queues, etc), including batch and real-time extraction, designing for scale, data transformations, job scheduling, and strategies for handling errors and outages Proficiency and 3+ years of relevant experience with doing complex data manipulation in SQL (e.g. joins, pivots, analytic functions, nested and array fields) Proficiency and 2+ years of relevant experience with Python ', 'Experience with workflow automation tools like Apache Airflow', 'Work with Product Data Science and Engineering to assess the quality and reliability of new and existing sources of product telemetry data, and advise when those sources need to be supplemented with new instrumentation or additional feeds', 'Basic Qualifications']",Entry level,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
Data Engineer,"NBCUniversal Media, LLC","Seattle, WA",21 hours ago,34 applicants,"['', 'State/Province', 'Qualifications/Requirements', 'City', ' Passion for media and news', ' Possess an in-depth understanding of the data structures and governance ', ' Proficient with Linux environment', 'Country', ' Experience with distributed data technologies (e.g.', ' Experience with Serverless cloud platforms a plus', 'Notices', 'Career Level', ' Familiarity with Presto and SQL', 'About Us', ' Possess an in-depth understanding of the data structures and governance  Fundamental knowledge of of modern cloud computing platforms and concepts  Work with modern schema-less big data storage solutions  Work closely with machine learning and data science teams to create scale and efficiency  Demonstrate critical thinking for potential roadblocks; comprehend a bigger picture of the business and effectively communicate these issues to stakeholders  Work closely with internal stakeholders to implement solutions that adhere to solution designs and schema ', ' Work closely with internal stakeholders to implement solutions that adhere to solution designs and schema ', 'Responsibilities', ' Work closely with machine learning and data science teams to create scale and efficiency ', ' Demonstrate critical thinking for potential roadblocks; comprehend a bigger picture of the business and effectively communicate these issues to stakeholders ', ' Proficient with Javascript and Python', 'Sub-Business', ' Work with modern schema-less big data storage solutions ', ' B.S. degree in Computer Science, Information', ' 2-3 years experience in a developer role', ' Fundamental knowledge of of modern cloud computing platforms and concepts ']",Not Applicable,Full-time,Information Technology,Broadcast Media,2020-10-20 12:01:24
Data Engineer,Big Cloud,Atlanta Metropolitan Area,,N/A,"['', 'Are you an experienced data engineer? Are you available for an initial 6-month contract?', '\xa0', 'Proficiency in data modelling, database technologies (both SQL and NoSQL)', 'One of the worlds biggest healthcare companies is seeking to recruit a Data Engineer for an initial 6-month contract.', 'Works closely with other data scientists and engineers to develop a strategy for long term data platform architecture', 'As a Data Engineer, you’ll be designing developing and maintaining scalable data models and pipelines, collaborating across all analytics teams to develop efficient end products and building data architecture.', 'You’ll need:', 'Data Architecture and data pipeline design experience\xa0', 'Strong experience in Python', 'Other responsibilities:', 'Cloud experience – ideally Azure or Google Cloud', 'Writes unit/integration tests, contributes to engineering wiki, and documents work.', 'Collaborate and actively contribute in discussions to help define technology and development approach within the team', '2+ years data engineering experience', 'Minimum bachelors degree', 'Contribute to project planning and implementation to ensure that solutions are delivered on time and on requirements', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes', '2+ years data engineering experienceMinimum bachelors degreeStrong experience in PythonCloud experience – ideally Azure or Google CloudProficiency in data modelling, database technologies (both SQL and NoSQL)Data Architecture and data pipeline design experience\xa0', 'Supporting issue analysis and fix activities during test phases, as well as production issue resolution.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processesWrites unit/integration tests, contributes to engineering wiki, and documents work.Works closely with other data scientists and engineers to develop a strategy for long term data platform architectureSupporting issue analysis and fix activities during test phases, as well as production issue resolution.Contribute to project planning and implementation to ensure that solutions are delivered on time and on requirementsCollaborate and actively contribute in discussions to help define technology and development approach within the team']",Mid-Senior level,Contract,Information Technology,Hospital & Health Care,2020-10-20 12:01:24
Data Engineer,DURLSTON PARTNERS,New York City Metropolitan Area,,N/A,"['', 'Is able to build and maintain large scale data pipelines for machine learning modelsIs excited about ensuring high reliability and scalability for data infrastructure, supporting millions of usersLoves working as part of a team, learning every day and shipping constantlyHas experience with Python, ETL and SQLIs looking for a role in a fast-paced startup', 'Has experience with Python, ETL and SQL', 'Durlston Partners is working in partnership with a machine learning and natural language processing startup building technology to create realistic conversational experiences for consumers.', 'Is able to build and maintain large scale data pipelines for machine learning models', ""Then we'd love to hear from you"", ""If you're someone who:"", 'Monthly Gym or fitness classes allowance', 'Is looking for a role in a fast-paced startup', '401k', 'Unlimited vacation', 'Loves working as part of a team, learning every day and shipping constantly', 'Competitive Salary (up to $165k) and stock options', 'Benefits include:', '100% medical, dental and vision', 'Flexible working', 'Is excited about ensuring high reliability and scalability for data infrastructure, supporting millions of users', ""Competitive Salary (up to $165k) and stock options100% medical, dental and vision401kUnlimited vacationMonthly Gym or fitness classes allowanceFlexible workingRelocation package (whilst we're all working remotely, for now, they would love the new joiner to be in their offices in New York, once it's safe to do so)"", ""Relocation package (whilst we're all working remotely, for now, they would love the new joiner to be in their offices in New York, once it's safe to do so)"", 'This firm has tripled in size this year and revenues are doubling every month. Due to huge client demand, they are looking to hire a data engineer who will work on building their data infrastructure as a 24/7 availability service. The product is already being used by thousands of people every day, so this is a really important role for the firm. Reporting directly to the VP of Engineering.']",Associate,Full-time,Engineering,Computer Software,2020-10-20 12:01:24
Data Engineer,Capital Group,"Seattle, WA",21 hours ago,Be among the first 25 applicants,"['', 'You have a background in data and software engineering and a passion to learn. ', 'You believe that a team is strongest when it is diverse and includes multiple perspectives.', 'Interest and curiosity in emerging technologies on the web like GraphQL, web assembly, Lambda functions, MLaaS etc', 'Travel required', 'Relocation benefits offered', 'Other location(s)', ""You've made mistakes in the past and have learned a lot from them. You apply this learning regularly."", 'BS in Computer Science or related field, or an equivalent in relevant work experience.', ""You are able to put yourself into your customer's shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them."", ' Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like AWS. Design, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems. Design data schema and operate cloud-based data warehouses and SQL/NoSQL/temporal database systems. Write Extract-Transform-Load (ETL) jobs and Spark/Hadoop jobs. Own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions. Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions. Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area. ', '“I can apply in less than 4 minutes.”', 'Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.', 'Your Background And Who You Are', '“I can lead a full life.”', 'What You’ll Be Doing', ' BS in Computer Science or related field, or an equivalent in relevant work experience. Experience implementing big data processing technology Hadoop, Apache Spark, etc. 3+ years of Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.). Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets. 3+ years experience in cloud-first design, preferably AWS (VPC, Serverless databases and functions, dynamic autoscaling, container orchestration, etc.). Experience in data architecture, databases (e.g., MySQL, Oracle, PostgreSQL), SQL and DDD/ER/ORM design. Interest and curiosity in emerging technologies on the web like GraphQL, web assembly, Lambda functions, MLaaS etc Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. ', 'Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions.', 'Req ID', 'Own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.', 'Receive 2-for-1 matching gifts for your charitable contributions and the opportunity to secure annual grants for the organizations you love', 'Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area.', 'Access on-demand professional development resources that allow you to hone existing skills and learn new ones', '3+ years of Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.).', 'You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you.', '“I Can Learn More About Capital Group.”', 'Enjoy generous time-away and health benefits from day one, with the opportunity for flexible work options', 'Location', 'Write Extract-Transform-Load (ETL) jobs and Spark/Hadoop jobs.', "" You have a background in data and software engineering and a passion to learn.  You've made mistakes in the past and have learned a lot from them. You apply this learning regularly. You believe there are generally multiple ways to solve a technical problem, each with different trade-offs. You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you. You believe that a team is strongest when it is diverse and includes multiple perspectives. You are able to put yourself into your customer's shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them. "", 'Design, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems.', 'Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like AWS.', 'You believe there are generally multiple ways to solve a technical problem, each with different trade-offs.', '3+ years experience in cloud-first design, preferably AWS (VPC, Serverless databases and functions, dynamic autoscaling, container orchestration, etc.).', 'Experience in data architecture, databases (e.g., MySQL, Oracle, PostgreSQL), SQL and DDD/ER/ORM design.', ' Enjoy generous time-away and health benefits from day one, with the opportunity for flexible work options Receive 2-for-1 matching gifts for your charitable contributions and the opportunity to secure annual grants for the organizations you love Access on-demand professional development resources that allow you to hone existing skills and learn new ones ', 'Qualifications', 'Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets.', 'COVID-19 HIRING Our recruiting and onboarding activities are virtual during the pandemic and we’ve transitioned to a work-from-home environment until further notice. We are offering generous work-from-home benefits to improve our associate’s ability to work remotely.', '“I can be myself at work.”', '“I can influence my income.”', 'Experience implementing big data processing technology Hadoop, Apache Spark, etc.', 'Design data schema and operate cloud-based data warehouses and SQL/NoSQL/temporal database systems.']",Not Applicable,Full-time,Information Technology,Financial Services,2020-10-20 12:01:24
Data Engineer,MantraMinds Inc,"Detroit, MI",22 hours ago,28 applicants,[''],Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Cloudbeds,"Boston, MA",23 hours ago,43 applicants,"['', 'Location:\xa0', 'Code ETL data transformations in PySpark/Spark.', 'Bachelor’s degree in computer science or related field, or equivalent experience.', 'Develop a framework for future extensions through standardized modern workflows.', 'Exceptional written and verbal communication in English.', 'Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)', 'Ability to take a consultative approach to data strategy.', '\ufeffYou’ll Succeed With:', 'Connect MIP Award (Technology)', 'The right candidate will be very experienced using Amazon Web Services (AWS) tools enabling data lake, warehousing, and processing capabilities. As a Data Engineer at Cloudbeds, you will have endless opportunities to innovate and drive the industry leading, comprehensive, and global data experience for travel.', 'Start-Ups to Watch in 2018 | Forbes', 'Design and manage processing pipelines via AWS Glue and/or EMR clusters.', 'Inc. 500 Fastest Growing Companies (2018 & 2019)\xa0', '3+ years experience as a Data Engineer.', 'As a Data Engineer at Cloudbeds, you will implement our company-wide data strategy across all teams and departments to deliver a best in class data experience to our customers and partners in over 150 countries, as well as internally within Cloudbeds. You will work closely with our Business Intelligence, Reporting, and Infrastructure teams to progress and optimize our data lake architecture and drive the data transformation lifecycle to process terabytes of platform and industry data from multiple databases and origins in an automated and serverless fashion.\xa0', 'Cloudbeds is a travel SaaS technology company that works to make the world a more welcoming place. We build advanced cloud-based hospitality software for hotels, hostels, vacation rentals, and groups that manages reservations and guests, distributes room availability, sells inventory, and collects payments. Our hundreds of team members are globally distributed across over 40 countries and, altogether, we speak 20+ languages. ', 'Best Places to Work | HotelTechReport (2018, 2019, 2020)', 'How do we do it? On a #remotefirst platform that allows every member of our team to work from wherever they are around the globe. We’re looking for people who want to disrupt the travel industry and love to travel as much as we do.', 'Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.', 'Inc. Best Places to Work (2017 & 2018)\xa0', 'Best Places to Work | Inc Magazine (2017 & 2018)', 'Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.', 'Ability to work in an Agile Scrum environment.', 'What You Will Do:', '2+ years experience working with Amazon Web Services.', 'Experience with performance optimization for processing and storage via data partitioning and indexing techniques.', 'Location:\xa0Europe (Remote)', 'Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.', 'Bachelor’s degree in computer science or related field, or equivalent experience.3+ years experience as a Data Engineer.2+ years experience working with Amazon Web Services.Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.Strong knowledge of how to compose and implement structural data models.Experience molding fresh environments into efficient mature data platforms.Experience with performance optimization for processing and storage via data partitioning and indexing techniques.Ability to take a consultative approach to data strategy.Ability to work in an Agile Scrum environment.Ability to thrive in a fast-paced environment.Ability to work remotely and manage your own time in an international team.Exceptional written and verbal communication in English.', 'Our company culture supports flexible working schedules with an open vacation policy, personal and professional development for individual growth, and the opportunity to travel and work remotely with great people. If you think you have the skills and passion, we’ll give you the support and opportunity to grow your career. If you would like to be considered for the role, we would love to hear from you!', 'Strong knowledge of how to compose and implement structural data models.', 'Experience molding fresh environments into efficient mature data platforms.', 'Ability to work remotely and manage your own time in an international team.', 'Code ETL data transformations in PySpark/Spark.Design and manage processing pipelines via AWS Glue and/or EMR clusters.Manage ingestion and replication via DBMS from cloud MySQL databases.Process external sources like Salesforce via Appflow or kaggle datasets.Manage AWS Athena views and endpoints for consumption.Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)Implement logging and debugging approaches in a standardized fashion.Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.Develop a framework for future extensions through standardized modern workflows.', 'Implement logging and debugging approaches in a standardized fashion.', 'Manage ingestion and replication via DBMS from cloud MySQL databases.', 'Process external sources like Salesforce via Appflow or kaggle datasets.', 'Deloitte’s North America Technology Fast 500 (2019)', 'Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.', 'Company Awards to Check Out!\xa0', 'Manage AWS Athena views and endpoints for consumption.', 'Best Startup Employers in 2020 | Forbes', 'Ability to thrive in a fast-paced environment.', 'Best Startup Employers in 2020 | ForbesBest Places to Work | HotelTechReport (2018, 2019, 2020)Deloitte’s North America Technology Fast 500 (2019)Inc. 500 Fastest Growing Companies (2018 & 2019)\xa0Inc. Best Places to Work (2017 & 2018)\xa0Best Places to Work | Inc Magazine (2017 & 2018)Start-Ups to Watch in 2018 | ForbesConnect MIP Award (Technology)']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
Data Engineer,Mosaic Learning,"Columbia, MD",16 hours ago,Over 200 applicants,"['', 'The Data Engineer\xa0will strive for efficiency by aligning data systems with business goals. To succeed in this data engineering position, you should have strong\xa0logical\xa0skills and the ability to combine data from different sources.\xa0', 'Organize raw data\xa0', 'Research and implement cutting edge solutions to solve challenges related to ETL\xa0and\xa0data processing\xa0', '\xa0', 'Ability to work on multiple projects simultaneously\xa0with a strong attention to detail\xa0', 'Follow CI/CD best practices for\xa0related\xa0code build and deployments\xa0', 'Communicate clearly and accurately\xa0', 'We are searching for an accountable, multi-talented Data Engineer to\xa0augment\xa0our\xa0software development\xa0and product\xa0markets.\xa0The Data Engineer will use various methods to transform raw data into useful data systems.\xa0This includes identifying interesting data our customers may want to see, and authoring reports.\xa0During various aspects of this process, you\xa0will\xa0collaborate with coworkers to ensure that your approach meets the needs of each project.\xa0', 'Work with AWS\xa0resources to accomplish most tasks\xa0', 'Build data systems and pipelines\xa0', 'Participate in daily\xa0meetings and support\xa0the\xa0development team\xa0', 'Solid understanding of\xa0set theory\xa0', 'Identify opportunities for data acquisition\xa0', 'Understanding integration\xa0of multiple data sources and databases\xa0', 'Evaluate business needs and objectives\xa0', 'Technical expertise with data models, data mining, and segmentation techniques\xa0', 'Experience with\xa0AWS products\xa0', 'Occasionally work with\xa0Linux servers,\xa0including the review or management of log files, crontab, security configuration, etc.\xa0', 'Combine raw information from different sources\xa0', 'Ability to prepare data for prescriptive and predictive modeling\xa0', 'The following skills and experience are not\xa0required but\xa0may\xa0be considered additionally:', 'Maintain\xa0a thorough\xa0security conscience\xa0for all aspects of this role\xa0', 'Ability to write intermediate to advanced SQL\xa0and code\xa0for data ingestion and processing\xa0', 'Possess a\xa0knack for benchmarking and optimization\xa0', 'Experience with\xa0Agile methodologies and short release cycles\xa0', 'Organize raw data\xa0Build data systems and pipelines\xa0Evaluate business needs and objectives\xa0Conduct complex data analysis and report on results\xa0Combine raw information from different sources\xa0Explore ways to enhance data quality and reliability\xa0Identify opportunities for data acquisition\xa0Collaborate with developers\xa0and architects on several projects\xa0Support existing,\xa0and develop new,\xa0data flows as needed by\xa0creating\xa0processes that verify, standardize, and scale data input,\xa0transformation,\xa0and storage\xa0Ability to write intermediate to advanced SQL\xa0and code\xa0for data ingestion and processing\xa0Develop techniques to work with structured (tabular/hierarchical)\xa0and\xa0unstructured data\xa0Research and implement cutting edge solutions to solve challenges related to ETL\xa0and\xa0data processing\xa0Ability to debug complex data issues without frequent guidance from senior team members\xa0Occasionally work with\xa0Linux servers,\xa0including the review or management of log files, crontab, security configuration, etc.\xa0Collaborate with product\xa0owners\xa0and other engineers to implement and document complex and evolving requirements\xa0Provide database design, development,\xa0and implementation support\xa0Participate in daily\xa0meetings and support\xa0the\xa0development team\xa0Work with customers and team members in an Agile development environment\xa0Follow CI/CD best practices for\xa0related\xa0code build and deployments\xa0Develop SQL\xa0and\xa0ETL scripts to support\xa0reporting, migrations, etc.\xa0Document database design and develop optimum data ingestion\xa0techniques from multiple data sources\xa0Work with AWS\xa0resources to accomplish most tasks\xa0Maintain\xa0a thorough\xa0security conscience\xa0for all aspects of this role\xa0', 'Conduct complex data analysis and report on results\xa0', 'Experience working with various database systems (including RDBMS, NoSQL, etc.)\xa0', 'Proficiency\xa0with\xa0code versioning tools, such as Git\xa0', 'Strong sense of team and group collaboration\xa0', 'Experience programming in various languages and SQL\xa0', 'Bonus Skills and Experience:', 'Collaborate with developers\xa0and architects on several projects\xa0', 'Requirements & Qualifications:', 'Numerical and analytical skills\xa0', 'Development of\xa0analytical tools and programs\xa0', 'Extraordinary ethics and compassion for your colleagues\xa0', 'Numerical and analytical skills\xa0Development of\xa0analytical tools and programs\xa0Interpretation of\xa0trends and patterns\xa0Ability to prepare data for prescriptive and predictive modeling\xa0Employment of\xa0machine learning techniques\xa0', 'Previous experience as a data engineer or a similar role\xa0Experience with\xa0AWS products\xa0Experience working with various database systems (including RDBMS, NoSQL, etc.)\xa0Experience with\xa0Agile methodologies and short release cycles\xa0Experience programming in various languages and SQL\xa0Technical expertise with data models, data mining, and segmentation techniques\xa0Solid understanding of\xa0set theory\xa0Hands-on experience with database design\xa0Experience working together with teams from several departments to facilitate the orderly execution of a proposed project plan\xa0Strong sense of team and group collaboration\xa0Current understanding of best practices regarding system security measures\xa0Extraordinary ethics and compassion for your colleagues\xa0Ability to work on multiple projects simultaneously\xa0with a strong attention to detail\xa0Communicate clearly and accurately\xa0Basic understanding of security compliance\xa0Understanding integration\xa0of multiple data sources and databases\xa0Proficiency\xa0with\xa0code versioning tools, such as Git\xa0Possess a\xa0knack for benchmarking and optimization\xa0', 'Interpretation of\xa0trends and patterns\xa0', 'Work with customers and team members in an Agile development environment\xa0', 'Role & Responsibility:', 'Explore ways to enhance data quality and reliability\xa0', 'Develop techniques to work with structured (tabular/hierarchical)\xa0and\xa0unstructured data\xa0', 'Document database design and develop optimum data ingestion\xa0techniques from multiple data sources\xa0', 'Previous experience as a data engineer or a similar role\xa0', 'Experience working together with teams from several departments to facilitate the orderly execution of a proposed project plan\xa0', 'Provide database design, development,\xa0and implementation support\xa0', 'Basic understanding of security compliance\xa0', 'Ability to debug complex data issues without frequent guidance from senior team members\xa0', 'Employment of\xa0machine learning techniques\xa0', 'Hands-on experience with database design\xa0', 'To ensure success as a Data Engineer, you should demonstrate flexibility, creativity, and the capacity to receive and utilize constructive criticism. A formidable Data Engineer will\xa0display\xa0unsatiated curiosity and outstanding interpersonal skills.\xa0', 'Support existing,\xa0and develop new,\xa0data flows as needed by\xa0creating\xa0processes that verify, standardize, and scale data input,\xa0transformation,\xa0and storage\xa0', 'Develop SQL\xa0and\xa0ETL scripts to support\xa0reporting, migrations, etc.\xa0', 'Current understanding of best practices regarding system security measures\xa0', 'Collaborate with product\xa0owners\xa0and other engineers to implement and document complex and evolving requirements\xa0']",Mid-Senior level,Full-time,Information Technology,E-Learning,2020-10-20 12:01:24
Data Engineer,Havas Edge,"San Diego County, CA",20 hours ago,64 applicants,"['', 'Demonstrated experience with BI database design; knowledge of BI and query tools such as Tableau and PowerBI', 'Strong understanding and knowledge of ETL and data warehouse principles', 'Ability to present complex ideas in user-friendly language', 'Minimum 2-3 years of experience developing large scale complex database solutionsMinimum 2 years’ experience with SQL including writing SQL queries and ability to tune queriesMinimum 2 years’ of ETL experience; python programming ETL and analyzing data setsStrong understanding and knowledge of ETL and data warehouse principlesExperience in data modeling and working with large data sets Thorough knowledge of database structures, theories, principles, and practicesDemonstrated experience with BI database design; knowledge of BI and query tools such as Tableau and PowerBIAbility to track and resolve database related incidents as well as requests', 'Tools heavily utilized within the role, but not limited to: SQL Server/SSIS; Unix/Linux; Python/Java; Web Analytics Platforms – Google, Adobe, etc.; Cloud Technogies – AWS, Azure, Google ', 'The Data Engineer is responsible for developing and supporting data warehouse solutions built on the Microsoft SQL Server and AWS technology stacks. These solutions include ETL, data modeling, data quality assessment and data delivery. S/he will play a critical role in the development of data warehouse/data lake solutions utilized by internal and external clients.', 'We are a full-service, direct response agency, headquartered in Carlsbad, CA with offices and affiliated offices in Boston, MA; London, UK; Los Angeles, CA; New York, NY; and Paris, FR.', 'Strong interpersonal communication skills; both written and verbal ', 'Minimum 2 years’ experience with SQL including writing SQL queries and ability to tune queries', 'Performance tuning and optimization of ETL, SQL and database structures', 'We are actively looking for a Data Engineer to join our team in Carlsbad, CA. S/he will work alongside engineers and developers and will directly report to our Enterprise Data Architect. ', 'Thorough knowledge of database structures, theories, principles, and practices', '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0', 'Experience with JSON, XML, ORC, AVRO and Parquet file formats', 'Design data models for enterprise-wide data integration incorporating: Structured and unstructured data; real time, on-demand, batch and varying timing schedules', 'Manage data warehouse structure and file storage rules', 'Experience in data modeling and working with large data sets ', 'Able to prioritize and execute tasks in a high-pressure work environment', 'WHO WE ARE', 'At Havas Edge we influence people to act by combining multi-channel marketing and commerce plus the creative and technology that powers them. Our work results in profitable growth and lasting relationships between customers and our client’s brands.\xa0', 'Build data flow automation to retrieve, transform and load data', 'Create high performance data warehouse and ETL solutions using SSIS, Python and SparkBuild data flow automation to retrieve, transform and load dataDesign and develop tables, views, triggers, indexes, constraints and stored proceduresPerformance tuning and optimization of ETL, SQL and database structuresMonitor long running transactions and can optimize query executions using best practices and methodologiesManage data warehouse structure and file storage rulesMaintain best practices for handling, storing and using dataData management functions including: Metadata management; Create, alter, delete, grant permissions, indexing, updating; Query tuningDesign data models for enterprise-wide data integration incorporating: Structured and unstructured data; real time, on-demand, batch and varying timing schedulesTools heavily utilized within the role, but not limited to: SQL Server/SSIS; Unix/Linux; Python/Java; Web Analytics Platforms – Google, Adobe, etc.; Cloud Technogies – AWS, Azure, Google ', 'Havas Edge is also part of the Edge Performance Network, a full-service, global performance marketing network.\xa0The Edge Performance Network offers clients expertise in all aspects of performance marketing, from analytics to strategy, creative and production, media planning and buying across all channels, as well as the industry’s best attribution and modeling capabilities. ', 'Bachelor’s Degree in Computer Science, Information Systems, Applied Mathematics, Statistics, Data Science, Big Data, or related field of study', 'Java, C# or R experience ', 'Minimum 2-3 years of experience developing large scale complex database solutions', 'Create high performance data warehouse and ETL solutions using SSIS, Python and Spark', 'Bachelor’s Degree in Computer Science, Information Systems, Applied Mathematics, Statistics, Data Science, Big Data, or related field of studyExperience with Web and Digital marketing data Experience with AWS S3, Athena and GLUEExperience with JSON, XML, ORC, AVRO and Parquet file formatsExperience with REST API callsJava, C# or R experience Strong interpersonal communication skills; both written and verbal Ability to present complex ideas in user-friendly languageTechnical documentation skillsAble to prioritize and execute tasks in a high-pressure work environmentSelf-motivated and directed, with keen attention to detailExperience working in a team-oriented, collaborative environment', 'Design and develop tables, views, triggers, indexes, constraints and stored procedures', 'WHAT WE NEED', 'WHAT YOU’LL DO', 'WHO YOU ARE', 'Build the Business. Build the Brand.', 'Data management functions including: Metadata management; Create, alter, delete, grant permissions, indexing, updating; Query tuning', 'Self-motivated and directed, with keen attention to detail', 'Maintain best practices for handling, storing and using data', 'Ability to track and resolve database related incidents as well as requests', 'Experience working in a team-oriented, collaborative environment', 'Monitor long running transactions and can optimize query executions using best practices and methodologies', 'Experience with AWS S3, Athena and GLUE', 'Experience with Web and Digital marketing data ', 'Experience with REST API calls', 'Minimum Requirements:', ""Havas Edge is an award-winning international performance marketing agency with a proven track record of helping clients succeed. We're an integrated agency that embraces every media channel, a creative powerhouse that loves data and analytics, and a passionate partner committed to giving clients more for less. With expertise across all digital, broadcast and media domains, we help our clients build their businesses and brands - in that order.\xa0"", 'Technical documentation skills', 'Minimum 2 years’ of ETL experience; python programming ETL and analyzing data sets', 'Preferred Education, Skills and Experience:']",Mid-Senior level,Full-time,Information Technology,Marketing and Advertising,2020-10-20 12:01:24
Data Engineer,Amazon,"Seattle, WA",7 hours ago,35 applicants,"['', ' Experience working with AWS with an understanding of Redshift, EMR, Athena, Aurora, DynamoDB, Kinesis, Lambda, S3, EC2, etc.', ' Bachelor’s degree in Computer Science, Engineering, Mathematics, or a related field 4+ Years of Data Warehouse Experience with Oracle, Redshift, PostgreSQL, etc Demonstrated strength in SQL, data modeling, ETL development, and data warehousing Experience working with AWS with an understanding of Redshift, EMR, Athena, Aurora, DynamoDB, Kinesis, Lambda, S3, EC2, etc. Experience in maintaining data warehouse systems and working on large scale data transformation using EMR, Hadoop, Hive, or other Big Data technologies Experience mentoring other Data Engineers', 'Company', ' Extensive Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)', ' Strong interpersonal skills and the ability to communicate complex technology solutions to senior leadership, gain alignment, and drive progress', ' Experience mentoring other Data Engineers', ' Experience with hardware provisioning, and forecasting hardware usage', 'Description', ' Extensive Experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.) Strong interpersonal skills and the ability to communicate complex technology solutions to senior leadership, gain alignment, and drive progress Experience with hardware provisioning, and forecasting hardware usage Extensive experience working with AWS with an understanding of Redshift, EMR, Athena, Aurora, DynamoDB, Kinesis, Lambda, S3, EC2, etc.', ' Bachelor’s degree in Computer Science, Engineering, Mathematics, or a related field', ' Experience in maintaining data warehouse systems and working on large scale data transformation using EMR, Hadoop, Hive, or other Big Data technologies', 'Preferred Qualifications', ' 4+ Years of Data Warehouse Experience with Oracle, Redshift, PostgreSQL, etc Demonstrated strength in SQL, data modeling, ETL development, and data warehousing', ' Extensive experience working with AWS with an understanding of Redshift, EMR, Athena, Aurora, DynamoDB, Kinesis, Lambda, S3, EC2, etc.', 'Basic Qualifications']",Not Applicable,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
Data Engineer - Work From Home,Alight Solutions,"Texas, United States",6 hours ago,Be among the first 25 applicants,"['', 'Proficiency in one of the scripting languages such as Shell/Python/Scala/Java. ', 'Comfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve. Comfortable presenting findings to leadership', 'Understands best practices in software engineering, data management, data storage, data compute, and distributed systems', ""Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline"", 'Disclaimer', 'Experience on data platform re-architecture projects or handling operational excellence in DW via automation', '4+ years of experience in Data Platform Administration/Engineering, Hands on experience with AWS based solutions such as EMR, S3, RDS, Lambda, Dynamodb, Redshift, EC2., Experience and tools/frameworks within the big Data ecosystem, Experienced in Agile methodologies.Proficiency in one of the scripting languages such as Shell/Python/Scala/Java. Good understanding of Big Data technology trends, with knowledge of technologies such as Kinesis, Kafka, Spark, Hive, pySpark. Experience in version control systems such as Git, GitLab, etc. Ability to work in a fast-paced, rapidly changing environment. 1+ years of experience using Cloud technologies and AWS Cloud Services certificationExperience with Analytical/Reporting Solutions like Alteryx, Tableau, PowerBI ', '4+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT, reporting/analytic tools and extracting value from large datasets', 'Education', 'Apply cloud-based AWS services to solve challenging problems around: big data processing, data warehouse design, and BI self-service', 'Collaborate with Engineers and Scientists in the organization to construct complex data sources for algorithms and machine learning models', 'Experience in version control systems such as Git, GitLab, etc. ', 'Good understanding of Big Data technology trends, with knowledge of technologies such as Kinesis, Kafka, Spark, Hive, pySpark. ', 'Keep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architecture', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Ability to work in a fast-paced, rapidly changing environment. 1+ years of experience using Cloud technologies and AWS Cloud Services certification', 'Build, analyze and present actionable data to drive marketing business development and product management decisions', '4+ years of experience in Data Platform Administration/Engineering, Hands on experience with AWS based solutions such as EMR, S3, RDS, Lambda, Dynamodb, Redshift, EC2., Experience and tools/frameworks within the big Data ecosystem, Experienced in Agile methodologies.', 'Adopt next-generation data architecture strategies, proposing both data flows and storage solutions', '4+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT, reporting/analytic tools and extracting value from large datasetsExperience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and solutions in AWS/AzureProficiency in Python or other similar languagesStrong understanding of scaling, performance and scheduling, batch and streaming data architectureKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsExperience on data platform re-architecture projects or handling operational excellence in DW via automationExperience communicating with management as well as with colleagues from engineering, analytics, and business backgroundsStrong technical and analytical aptitude; Excellent oral and written communication skills', 'Overall ', 'Design, develop, and operate highly-scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms with AWS/cloud technologies', 'Strong technical and analytical aptitude; Excellent oral and written communication skills', 'Focuses on automation and optimization for all areas of DW/ETL maintenance and deployment', 'Experience with Analytical/Reporting Solutions like Alteryx, Tableau, PowerBI ', 'Collaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'High Level Requirements', 'Qualifications', 'Strong understanding of scaling, performance and scheduling, batch and streaming data architecture', 'Experience communicating with management as well as with colleagues from engineering, analytics, and business backgrounds', 'Understands best practices in software engineering, data management, data storage, data compute, and distributed systemsApply cloud-based AWS services to solve challenging problems around: big data processing, data warehouse design, and BI self-serviceFocuses on automation and optimization for all areas of DW/ETL maintenance and deploymentComfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve. Comfortable presenting findings to leadershipDesign, develop, and operate highly-scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms with AWS/cloud technologiesAdopt next-generation data architecture strategies, proposing both data flows and storage solutionsCollaborate with Engineers and Scientists in the organization to construct complex data sources for algorithms and machine learning modelsBuild, analyze and present actionable data to drive marketing business development and product management decisionsKeep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architectureCollaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'Experience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and solutions in AWS/Azure', 'Proficiency in Python or other similar languages']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Toptal,United States,55 minutes ago,Be among the first 25 applicants,"['', 'Technical expertise with Python and PySpark', 'This position is fully remote, with a preference that talent be located within the United States, and is a full-time, 6-12 month contract with room for extension.', '        projects.', '\xa0', 'Experience\xa0with performance\xa0tuning of complex SQL\xa0queries, Indexing\xa0strategies and', 'Nice to have skills:', 'Coordinates on-call support and ensures effective monitoring of system.\xa0', ' Proficient\xa0in Data Analysis, Data Modeling, Data profiling, ETL concepts\xa0and\xa0relational concepts.', 'Owns the change request process and may coordinate with other teams as necessary.\xa0', 'Ability to translate the business requirements/user stories into technical solutions.', ""Toptal is an elite network of the world's top talent, connecting the best and brightest in business, design, and technology with top organizations around the world."", 'Develops and defines application scope and objectives and prepares technical and/or functional specifications from with programs will be written.\xa0', 'RESPONSIBILITIES:', 'Mentors others and may lead multiple or small to medium sized projects.\xa0', 'Experience with\xa0automation and\xa0scheduling of\xa0components through scheduling\xa0toolsExperience with designing, development and deploy the solutions for small/medium scale', 'Experience with\xa0automation and\xa0scheduling of\xa0components through scheduling\xa0tools', 'Supports vendor evaluation.\xa0\xa0', '        Informatica\xa0solution.', ' Healthcare\xa0experience a plus.', 'Maintains active relationships with customers to determine business requirements and leads requirements gathering meetings.\xa0', 'Must Have skills:', 'Ensures unit test is completed and meets the test plan requirements, system testing is completed and system is implemented according to plan.\xa0', 'Technical expertise with Python and PySparkAbility to translate the business requirements/user stories into technical solutions. Proficient\xa0in Data Analysis, Data Modeling, Data profiling, ETL concepts\xa0and\xa0relational concepts.Experience with design and\xa0development of\xa0SQL objects, writing complex SQL queries using\xa0Microsoft T-SQL and\xa0advanced\xa0functions.Experience in design,\xa0development and\xa0implementation of\xa0complex ETL solutionsHave\xa0experience with generating\xa0JSON outputs or other\xa0file extracts\xa0in\xa0different formatsAgile Scrum methodology experience and use of JIRA', 'Have\xa0experience with generating\xa0JSON outputs or other\xa0file extracts\xa0in\xa0different formats', 'Facilitates group sessions to elicit complex information on requirements clarification, design sessions, code reviews and troubleshooting issues.\xa0', 'Experience with designing, development and deploy the solutions for small/medium scale', 'Experience with design and\xa0development of\xa0SQL objects, writing complex SQL queries using\xa0Microsoft T-SQL and\xa0advanced\xa0functions.', 'Assesses current status and supports data information planning.\xa0', 'Maintains active relationships with customers to determine business requirements and leads requirements gathering meetings.\xa0Owns the change request process and may coordinate with other teams as necessary.\xa0Develops and owns list of final enhancements.\xa0Develops and defines application scope and objectives and prepares technical and/or functional specifications from with programs will be written.\xa0Performs technical design reviews and code reviews.\xa0Ensures unit test is completed and meets the test plan requirements, system testing is completed and system is implemented according to plan.\xa0Assesses current status and supports data information planning.\xa0Coordinates on-call support and ensures effective monitoring of system.\xa0Maintains technical development environment.\xa0Mentors others and may lead multiple or small to medium sized projects.\xa0Facilitates group sessions to elicit complex information on requirements clarification, design sessions, code reviews and troubleshooting issues.\xa0Supports vendor evaluation.\xa0\xa0', 'Please apply to learn more about this opportunity and Toptal in general', 'Agile Scrum methodology experience and use of JIRA', 'Performs technical design reviews and code reviews.\xa0', 'Develops and owns list of final enhancements.\xa0', 'Maintains technical development environment.\xa0', ""Our client is looking for Solutions Engineer that is responsible for programming on specific application subsets of the company's application portfolio, participating in all phases of the development and maintenance life cycle, typically for an assigned business unit, client program, or corporate department and utilizing various customer technology platforms."", 'Experience in design,\xa0development and\xa0implementation of\xa0complex ETL solutions']",Mid-Senior level,Contract,Engineering,Internet,2020-10-20 12:01:24
Data Engineer,Synergis,Atlanta Metropolitan Area,2 hours ago,32 applicants,"['', 'SKILLS:', '\xa0', 'Hands-on experience developing and supporting Python based AI/ML solutions.', 'Experience in Data Governance processes and tools such as Informatica Data Catalog', 'Is telecommuting an option?\xa0\xa0\xa0Partial, yes\xa0\xa0There will be times when coming to the office may be necessary.', 'Hands-on experience developing solutions with big data technologies such as Hadoop, HIVE and Spark.', '1-2 year contract', '3+ years hands on experience designing, developing, testing, deploying and supporting data engineering and analytics solutions using Microsoft cloud-based tools such as Azure Data Lake, Azure Data Factory, Azure Databricks, Python, Azure Synapse, Azure Key Vault and Power BI.', 'Is telecommuting an option?\xa0\xa0\xa0', '8+ years hands-on experience with full life-cycle implementation and support of DW/BI solutions.', 'Is travel required?\xa0', 'What does the day to day look like?', 'Experience with Agile as well as DevOps, CI/CD methodologies', 'Hands-on experience designing and developing solutions involving data sourcing, enrichment and delivery using APIs & Web Services.', 'The Data Engineer, Analytics will work with stakeholders – both business and IT to review functional and non-functional requirements, design, develop and support business and artificial intelligence solutions involving Big Data and Microsoft Azure technologies that align with and support the business and Technology Organization strategy and standards.', 'Data Engineer', 'Please contact Christy.Cifreo@Synergishr.com or 770-346-7211', 'What\xa0are the nice to have skills?', 'Is travel required?\xa0Yes, occasionally to attend in-person workshops', 'Experience in creating functional and technical designs for data engineering and analytics solutions.', 'Atlanta, GA or Naperville, IL (mostly remote though)', 'Experience with Containerization methodologies – Docker, OpenShift etc.,', '8+ years hands-on experience with full life-cycle implementation and support of DW/BI solutions.5+ years hands on experience designing, developing, testing, deploying and supporting data engineering and analytics solutions using on-premises tools such as, MSBI (SSIS/SSAS), Informatica, Oracle Golden Gate, SQL, Oracle and SQL Server.3+ years hands on experience designing, developing, testing, deploying and supporting data engineering and analytics solutions using Microsoft cloud-based tools such as Azure Data Lake, Azure Data Factory, Azure Databricks, Python, Azure Synapse, Azure Key Vault and Power BI.Experience in creating functional and technical designs for data engineering and analytics solutions.Experience to implement data models of different schemas and working with diverse data source types.Hands-on experience developing solutions with big data technologies such as Hadoop, HIVE and Spark.Hands-on experience developing and supporting Python based AI/ML solutions.Hands-on experience developing automation solutions using tools such as Autosys.Experience with Containerization methodologies – Docker, OpenShift etc.,Experience with Agile as well as DevOps, CI/CD methodologiesExperience with designing re-usable solution components and perform code-reviews.Experience working in a medium to large enterprise setting and collaborating with multiple cross-functional teamsExperience working on concurrent assignments on multiple projects.', 'Experience in Data Quality processes and tools such as DQS', 'Microsoft Azure Data Engineer CertificationExperience in Utilities, Preferably GasExperience in Data Governance processes and tools such as Informatica Data CatalogExperience in Data Quality processes and tools such as DQSHands-on experience designing and developing solutions involving data sourcing, enrichment and delivery using APIs & Web Services.Experience with Agile methodology and tools such as JIRA', 'Experience with Agile methodology and tools such as JIRA', '5+ years hands on experience designing, developing, testing, deploying and supporting data engineering and analytics solutions using on-premises tools such as, MSBI (SSIS/SSAS), Informatica, Oracle Golden Gate, SQL, Oracle and SQL Server.', 'To design, develop, test and deploy hybrid data engineering and analytics solutions using on-premises and cloud-based tools as well as support them.', 'Job Description:', 'Attend requirements sessions, create and review functional and technical designs, develop the designed solution, optimize performance, support test efforts, plan and execute deployments as well as resolve technical issues.\xa0Additionally, assist the Analytics team with impact analysis, effort estimates, support planning and participate in after-hours production support call out rotation.', 'Microsoft Azure Data Engineer Certification', 'This position will be focused on supporting existing data integration and analytics solutions as well as designing and developing new solutions.\xa0\xa0Additionally, the Data Engineer is expected to participate in knowledge sharing and own technical issue resolution.', 'Experience working on concurrent assignments on multiple projects.', 'Experience with designing re-usable solution components and perform code-reviews.', 'Hands-on experience developing automation solutions using tools such as Autosys.', 'The Data Engineer, Analytics will work with stakeholders – both business and IT to review functional and non-functional requirements, design, develop and support business and artificial intelligence solutions involving Big Data and Microsoft Azure technologies that align with and support the business and Technology Organization strategy and standards. Additionally, this position will be responsible for management and alignment of solutions across all technology platforms working closely with Architects, data and infrastructure teams to optimize application code, ensuring data integrity, security, stability, resiliency, sustainability, growth and performance.', '\ufeffPlease provide a short summary job description - provide just the highlights?', 'How will the contractor be using their technical skills?', 'Experience to implement data models of different schemas and working with diverse data source types.', 'Experience in Utilities, Preferably Gas', 'Experience working in a medium to large enterprise setting and collaborating with multiple cross-functional teams']",Mid-Senior level,Contract,Information Technology,Oil & Energy,2020-10-20 12:01:24
Data Engineer,Sequoia Consulting Group,"San Mateo, CA",19 hours ago,77 applicants,"['', 'Lead all aspects of the migration of data from legacy systems to new solutions', 'Extensive hands-on experience working with SQL and Python for the purposes of data modeling and ETL', 'As an integral member of our Business Intelligence and Analytics\xa0Team, the\xa0Data\xa0Engineer\xa0will\xa0be responsible for the design, architecture, development, implementation, and support of critical enterprise E2E Business Intelligence EDW solutions in MySQL or Snowflake\xa0as well as\xa0sourcing data from MySQL, Snowflake, Salesforce (SFDC),\xa0and other data sources.\xa0', '• Promise-centric', '• Growth oriented', 'Advanced working knowledge and ability to write complex SQL queries in MySQL, Snowflake, and Salesforce (SFDC) environmentsExtensive hands-on experience working with SQL and Python for the purposes of data modeling and ETLStrong familiarity with Kimball, OLAP, and EDW data design methodologies, especially for healthcare and benefits datasets2+ years’ experience in data modeling and architecting, ETL, data engineering, or BI fields with concentration on data transformations and data modeling ', 'Optimize new and current database systems', 'Prepare accurate database design and architecture reports for management and executive teams', 'Recommend solutions to improve new and existing database systems ', '• Focused on relationship building', 'Sequoia’s Culture – Our most important asset:', 'Install and organize information systems to guarantee company functionality', 'Assess database implementation procedures to ensure they follow internal and external regulations', 'Design conceptual and logical data models and flowcharts', '• Integrity', 'Advanced working knowledge and ability to write complex SQL queries in MySQL, Snowflake, and Salesforce (SFDC) environments', 'Strong familiarity with Kimball, OLAP, and EDW data design methodologies, especially for healthcare and benefits datasets', 'What You Get To Do', 'Design conceptual and logical data models and flowchartsDesign and implement effective database solutions and models to store and retrieve company dataExamine and identify database structural necessities by evaluating client operations, applications, and programmingOptimize new and current database systemsAssess database implementation procedures to ensure they follow internal and external regulationsInstall and organize information systems to guarantee company functionalityPrepare accurate database design and architecture reports for management and executive teamsLead all aspects of the migration of data from legacy systems to new solutionsMonitor the system performance by performing regular tests, fixing, and integrating new featuresRecommend solutions to improve new and existing database systems ', 'Monitor the system performance by performing regular tests, fixing, and integrating new features', '• Passion for service', 'Data\xa0Engineer\xa0', ""You will handle the product's or project’s conception, design initial product specifications and lead scheduling, estimate\xa0and secure\xa0resources, as well as provide technical guidance to other internal and external teams. You will\xa0help train new employees and stay ahead of industry trends and issues.\xa0"", 'Qualifications', 'Design and implement effective database solutions and models to store and retrieve company data', '2+ years’ experience in data modeling and architecting, ETL, data engineering, or BI fields with concentration on data transformations and data modeling ', '• Caring for others', 'Examine and identify database structural necessities by evaluating client operations, applications, and programming', '• Innovative']",Mid-Senior level,Full-time,Engineering,Human Resources,2020-10-20 12:01:24
Data Engineer,Rational,United States,16 hours ago,Be among the first 25 applicants,"['', ""Be a leader in Business Intelligence and Reporting efforts. Mentor and provide input to team members and other analysts to execute on the team's vision, design and execute projects from start-to-finish, inform technical direction, and support reporting of accomplishments."", 'The initial project for this role will be developing a commercial field sales report for deployment through a mobile device. An existing PowerShell app is currently being refined to expand and adapt to the new needs.', '\ufeffRational\xa0is committed to ensuring\xa0all candidates have an equal opportunity to be considered for employment.\xa0Please let us know if you need any reasonable accommodation to participate in the job application or interview process.', 'Build collaboration among stakeholders, working across our clients to bring consensus to achieve objectives. Become a sought-out subject matter expert by consistently producing high-quality results.', ""7+ years' experience with SQL Server and PowerShell"", 'Who you are:', 'Interface with Architects to recommend new technology opportunities that will have an impact on BI systems', 'Experience participating in workstream planning process including inception, technical design, development, testing and delivery of BI solutions.', 'Strong professional experience analyzing business and functional requirements and translating these requirements into robust, scalable, operable solutions.', ""Rational is a customer experience (CX) solutions firm that pairs the capabilities of a strategic consultancy with the creativity of a full-service digital agency. We design and activate compelling experiences that create strong connections between people and brands. We put humans at the center of business and partner with our clients to deliver meaningful experiences that help their customers while driving business success. Customer satisfaction at every level is our ultimate metric, and it's what drives our mindset, skillset, and company culture."", 'Adaptable. Change happens at lightning speed;\xa0you are flexible, enjoy challenge, and get behind new ideas\xa0', 'Experience implementing data structures using best practices in data modeling, processes, and technologies.', 'Demonstrated ability in selecting, developing, and applying data modeling tools and processes with proven business utility', 'Proactive', 'Create and maintain documentation(s) for implemented business intelligence processes', 'Creates scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation.', 'Working knowledge of modern large-scale data systems and architectures; ability to manage and manipulate large disparate data sets', 'Support eDW team and Developers to build data warehousing systems for business intelligence, reporting and analytics.', 'Support the development of business intelligence standards to meet business goals.', 'Visionary.\u202fAbility to see ""the whole picture"" and simultaneously remain slightly obsessed with the details\u202f\xa0', 'Assist in business report generation', 'As an integral member of our report delivery team, the Data Engineer role works closely with customers and BI Analysts to turn data into critical information and knowledge that can be used to make sound business decisions. They provide data that is accurate, congruent and reliable and is easily accessible.', 'Incredible people are our non-negotiable. Our experienced team of consultants spans the globe. We love what we do, and who we do it with – let’s begin our next chapter together.\u202f', 'Knowledge of implementing tools and frameworks for automating report generation, identification of data-quality issues, and data governance.', 'Recommend enhancements and modifications to optimize business intelligence processes.', 'Adaptable', 'Analyze and test new releases/versions of software.', 'What you will do: ', 'Proven experience exploring the data and discovers patterns, meaningful relationships, anomalies, and trends.', 'Works on highly complex and cross-functional BI solutions.', 'Data Lover.\u202fYou know your numbers and value the metrics behind the buyer story.', 'Data Lover.', 'Identify valuable data sources and automate collection processes', 'Experience collecting, analyzing, and sharing data to help business teams drive improvement in key business metrics, customer experience, and business results.', 'Propose solutions and strategies to address operational business challenges', 'Visionary.', 'Collaborative to the Core.', 'Conduct research and makes recommendations on BI products and services.', 'The Data Engineer is responsible for the full life cycle development, implementation, production support, and performance tuning of the Enterprise Data Warehouse, Data Mart, and Business Intelligence Reporting environments, and support the integration of those systems with other applications. They design and implement reporting and analytical solutions, including both the design of table structures and the processes used to populate those structures with data from internal and external sources.\xa0', 'Track and report out on issues and enhancement request for the business in a timely manner.', 'Rational is growing, and we need amazing talent to join our team. If you have an entrepreneurial attitude with a deep spirit of service and killer subject expertise, we want to talk to you. We are always looking for the next great consultant to raise the bar and push Rational to be better than we were yesterday. Staying hungry, curious, and looking forward to what’s next is part of our DNA.', 'Work closely with customers and BI Analysts to create ad hoc reports to support timely business decisions and project work.', 'Snowflake experience is highly-valued, but not required', 'Coordinate with customers, Business Analysts and DW Architects to implement business data reporting and analysis requirements.', 'Ensure adherence to process, policies, and standards', 'Ability to lead the integration efforts for merging BI platforms with enterprise systems and applications.', ""Coordinate with customers, Business Analysts and DW Architects to implement business data reporting and analysis requirements.Assist in business report generationSupport eDW team and Developers to build data warehousing systems for business intelligence, reporting and analytics.Assist in data administration, modeling and integration activities using data warehouse systems in the reporting layer.Implement business intelligence solutions to achieve data reporting and analysis goals.Support the development of business intelligence standards to meet business goals.Support Analysts with new data requirements, analysis strategies and reporting mechanisms.Recommend enhancements and modifications to optimize business intelligence processes.Address business intelligence queries and issues in a timely fashion.Create and maintain documentation(s) for implemented business intelligence processesPropose solutions and strategies to address operational business challengesIdentify valuable data sources and automate collection processesBe a leader in Business Intelligence and Reporting efforts. Mentor and provide input to team members and other analysts to execute on the team's vision, design and execute projects from start-to-finish, inform technical direction, and support reporting of accomplishments.Build collaboration among stakeholders, working across our clients to bring consensus to achieve objectives. Become a sought-out subject matter expert by consistently producing high-quality results.Creates scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation.Document standards and policies for the form, structure, and attributes of the BI tools and systems.Ensure adherence to process, policies, and standardsTrack and report out on issues and enhancement request for the business in a timely manner.Work closely with customers and BI Analysts to create ad hoc reports to support timely business decisions and project work.Analyze and test new releases/versions of software.Conduct research and makes recommendations on BI products and services.Interface with vendors to keep abreast of new technologies, pricing, and customer applicability.Interface with Architects to recommend new technology opportunities that will have an impact on BI systems"", 'What you will bring:', 'Support Analysts with new data requirements, analysis strategies and reporting mechanisms.', 'These Engineers also interact with various development teams, project managers, internal and external customers, senior management, and external vendors. They must have an in-depth understanding of the business environment, and strong analytical and communication skills. Individuals must work well within a team environment. These reports will be done in adherence to reporting Standards and Guidelines at Seattle Genetics.', 'Address business intelligence queries and issues in a timely fashion.', 'Document standards and policies for the form, structure, and attributes of the BI tools and systems.', 'Experience developing work plans and reviewing other work plan timelines and manages workflows to meet timeframes.', 'Collaborative to the Core.\xa0Demonstrated ability to work in a team environment, as a leader and member.\xa0', 'Assist in data administration, modeling and integration activities using data warehouse systems in the reporting layer.', 'Proactive. You are always thinking ahead about what is best for the Client.\xa0Adaptable. Change happens at lightning speed;\xa0you are flexible, enjoy challenge, and get behind new ideas\xa0Visionary.\u202fAbility to see ""the whole picture"" and simultaneously remain slightly obsessed with the details\u202f\xa0Collaborative to the Core.\xa0Demonstrated ability to work in a team environment, as a leader and member.\xa0Data Lover.\u202fYou know your numbers and value the metrics behind the buyer story.', 'Implement business intelligence solutions to achieve data reporting and analysis goals.', ""7+ years' experience with SQL Server and PowerShellSnowflake experience is highly-valued, but not requiredDemonstrated ability in selecting, developing, and applying data modeling tools and processes with proven business utilityWorking knowledge of modern large-scale data systems and architectures; ability to manage and manipulate large disparate data setsWorks on highly complex and cross-functional BI solutions.Experience participating in workstream planning process including inception, technical design, development, testing and delivery of BI solutions.Experience developing work plans and reviewing other work plan timelines and manages workflows to meet timeframes.Strong professional experience analyzing business and functional requirements and translating these requirements into robust, scalable, operable solutions.Experience collecting, analyzing, and sharing data to help business teams drive improvement in key business metrics, customer experience, and business results.Experience implementing data structures using best practices in data modeling, processes, and technologies.Knowledge of implementing tools and frameworks for automating report generation, identification of data-quality issues, and data governance.Ability to lead the integration efforts for merging BI platforms with enterprise systems and applications.Proven experience exploring the data and discovers patterns, meaningful relationships, anomalies, and trends."", 'Proactive. You are always thinking ahead about what is best for the Client.\xa0', 'Interface with vendors to keep abreast of new technologies, pricing, and customer applicability.']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Maven,"Columbus, Ohio Metropolitan Area",19 hours ago,36 applicants,"['', 'Design and develop data structures', 'Experience working with ETL, SQL, Python, Big Data and Hadoop', 'Strong communicator and someone who is adaptable', '5+ years of experience as a Data Engineer or Software Engineer', 'The successful candidate:', '5+ years of experience as a Data Engineer or Software EngineerStrong communicator and someone who is adaptable', 'Key responsibilities:', 'Experience working in an Agile environment, providing code reviews and issue tracking', 'We have an opening for a Data Engineer role here in Columbus, OH. This role will start out being remote, however the client would like to have a candidate who is open to returning to the office.', 'Design and develop data structuresExperience working with ETL, SQL, Python, Big Data and HadoopExperience working in an Agile environment, providing code reviews and issue tracking']",Associate,Full-time,Information Technology,Information Services,2020-10-20 12:01:24
"Data Scientist / Software Engineer, Planner",Waymo,"Mountain View, CA",9 hours ago,Be among the first 25 applicants,"['', ' PhD in Computer Science, Robotics, Statistics, Physics, Math or another quantitative area Comfort with writing production code in C++ Experience in robotics or with spatial data in another field  ', 'Problem-oriented mindset instead of only a solutions-oriented approach', 'Design creative uses of simulation to measure those signals', 'MS in Computer Science, Robotics, Statistics, Physics, Math or another quantitative area', 'Experience with machine learning or large scale statistical analysis', ""Develop signals to describe the quality of our self driving car's behavior, using a range of techniques including machine learning, statistics, math, and physics"", 'Experience in robotics or with spatial data in another field ', 'PhD in Computer Science, Robotics, Statistics, Physics, Math or another quantitative area', ' MS in Computer Science, Robotics, Statistics, Physics, Math or another quantitative area 3 years of industry experience  Python especially for modeling and/or statistical computing  Experience with tools for manipulating big data Experience with machine learning or large scale statistical analysis Problem-oriented mindset instead of only a solutions-oriented approach ', 'Comfort with writing production code in C++', 'Work closely with statisticians, machine learning engineers, and roboticists to develop novel solutions to open problems', 'Experience with tools for manipulating big data', '3 years of industry experience ', "" Develop signals to describe the quality of our self driving car's behavior, using a range of techniques including machine learning, statistics, math, and physics Design creative uses of simulation to measure those signals Work closely with statisticians, machine learning engineers, and roboticists to develop novel solutions to open problems "", 'In This Hybrid Role, You Will', ""We'd Like You To Have"", ""It's Preferred If You Have"", 'Python especially for modeling and/or statistical computing ']",Mid-Senior level,Full-time,Research,Computer Software,2020-10-20 12:01:24
Data Engineer,Cloudbeds,"Boston, MA",23 hours ago,43 applicants,"['', 'Location:\xa0', 'Code ETL data transformations in PySpark/Spark.', 'Bachelor’s degree in computer science or related field, or equivalent experience.', 'Develop a framework for future extensions through standardized modern workflows.', 'Exceptional written and verbal communication in English.', 'Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)', 'Ability to take a consultative approach to data strategy.', '\ufeffYou’ll Succeed With:', 'Connect MIP Award (Technology)', 'The right candidate will be very experienced using Amazon Web Services (AWS) tools enabling data lake, warehousing, and processing capabilities. As a Data Engineer at Cloudbeds, you will have endless opportunities to innovate and drive the industry leading, comprehensive, and global data experience for travel.', 'Start-Ups to Watch in 2018 | Forbes', 'Design and manage processing pipelines via AWS Glue and/or EMR clusters.', 'Inc. 500 Fastest Growing Companies (2018 & 2019)\xa0', '3+ years experience as a Data Engineer.', 'As a Data Engineer at Cloudbeds, you will implement our company-wide data strategy across all teams and departments to deliver a best in class data experience to our customers and partners in over 150 countries, as well as internally within Cloudbeds. You will work closely with our Business Intelligence, Reporting, and Infrastructure teams to progress and optimize our data lake architecture and drive the data transformation lifecycle to process terabytes of platform and industry data from multiple databases and origins in an automated and serverless fashion.\xa0', 'Cloudbeds is a travel SaaS technology company that works to make the world a more welcoming place. We build advanced cloud-based hospitality software for hotels, hostels, vacation rentals, and groups that manages reservations and guests, distributes room availability, sells inventory, and collects payments. Our hundreds of team members are globally distributed across over 40 countries and, altogether, we speak 20+ languages. ', 'Best Places to Work | HotelTechReport (2018, 2019, 2020)', 'How do we do it? On a #remotefirst platform that allows every member of our team to work from wherever they are around the globe. We’re looking for people who want to disrupt the travel industry and love to travel as much as we do.', 'Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.', 'Inc. Best Places to Work (2017 & 2018)\xa0', 'Best Places to Work | Inc Magazine (2017 & 2018)', 'Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.', 'Ability to work in an Agile Scrum environment.', 'What You Will Do:', '2+ years experience working with Amazon Web Services.', 'Experience with performance optimization for processing and storage via data partitioning and indexing techniques.', 'Location:\xa0Europe (Remote)', 'Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.', 'Bachelor’s degree in computer science or related field, or equivalent experience.3+ years experience as a Data Engineer.2+ years experience working with Amazon Web Services.Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.Strong knowledge of how to compose and implement structural data models.Experience molding fresh environments into efficient mature data platforms.Experience with performance optimization for processing and storage via data partitioning and indexing techniques.Ability to take a consultative approach to data strategy.Ability to work in an Agile Scrum environment.Ability to thrive in a fast-paced environment.Ability to work remotely and manage your own time in an international team.Exceptional written and verbal communication in English.', 'Our company culture supports flexible working schedules with an open vacation policy, personal and professional development for individual growth, and the opportunity to travel and work remotely with great people. If you think you have the skills and passion, we’ll give you the support and opportunity to grow your career. If you would like to be considered for the role, we would love to hear from you!', 'Strong knowledge of how to compose and implement structural data models.', 'Experience molding fresh environments into efficient mature data platforms.', 'Ability to work remotely and manage your own time in an international team.', 'Code ETL data transformations in PySpark/Spark.Design and manage processing pipelines via AWS Glue and/or EMR clusters.Manage ingestion and replication via DBMS from cloud MySQL databases.Process external sources like Salesforce via Appflow or kaggle datasets.Manage AWS Athena views and endpoints for consumption.Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)Implement logging and debugging approaches in a standardized fashion.Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.Develop a framework for future extensions through standardized modern workflows.', 'Implement logging and debugging approaches in a standardized fashion.', 'Manage ingestion and replication via DBMS from cloud MySQL databases.', 'Process external sources like Salesforce via Appflow or kaggle datasets.', 'Deloitte’s North America Technology Fast 500 (2019)', 'Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.', 'Company Awards to Check Out!\xa0', 'Manage AWS Athena views and endpoints for consumption.', 'Best Startup Employers in 2020 | Forbes', 'Ability to thrive in a fast-paced environment.', 'Best Startup Employers in 2020 | ForbesBest Places to Work | HotelTechReport (2018, 2019, 2020)Deloitte’s North America Technology Fast 500 (2019)Inc. 500 Fastest Growing Companies (2018 & 2019)\xa0Inc. Best Places to Work (2017 & 2018)\xa0Best Places to Work | Inc Magazine (2017 & 2018)Start-Ups to Watch in 2018 | ForbesConnect MIP Award (Technology)']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
Data Engineer,Sequoia Consulting Group,"San Mateo, CA",19 hours ago,77 applicants,"['', 'Lead all aspects of the migration of data from legacy systems to new solutions', 'Extensive hands-on experience working with SQL and Python for the purposes of data modeling and ETL', 'As an integral member of our Business Intelligence and Analytics\xa0Team, the\xa0Data\xa0Engineer\xa0will\xa0be responsible for the design, architecture, development, implementation, and support of critical enterprise E2E Business Intelligence EDW solutions in MySQL or Snowflake\xa0as well as\xa0sourcing data from MySQL, Snowflake, Salesforce (SFDC),\xa0and other data sources.\xa0', '• Promise-centric', '• Growth oriented', 'Advanced working knowledge and ability to write complex SQL queries in MySQL, Snowflake, and Salesforce (SFDC) environmentsExtensive hands-on experience working with SQL and Python for the purposes of data modeling and ETLStrong familiarity with Kimball, OLAP, and EDW data design methodologies, especially for healthcare and benefits datasets2+ years’ experience in data modeling and architecting, ETL, data engineering, or BI fields with concentration on data transformations and data modeling ', 'Optimize new and current database systems', 'Prepare accurate database design and architecture reports for management and executive teams', 'Recommend solutions to improve new and existing database systems ', '• Focused on relationship building', 'Sequoia’s Culture – Our most important asset:', 'Install and organize information systems to guarantee company functionality', 'Assess database implementation procedures to ensure they follow internal and external regulations', 'Design conceptual and logical data models and flowcharts', '• Integrity', 'Advanced working knowledge and ability to write complex SQL queries in MySQL, Snowflake, and Salesforce (SFDC) environments', 'Strong familiarity with Kimball, OLAP, and EDW data design methodologies, especially for healthcare and benefits datasets', 'What You Get To Do', 'Design conceptual and logical data models and flowchartsDesign and implement effective database solutions and models to store and retrieve company dataExamine and identify database structural necessities by evaluating client operations, applications, and programmingOptimize new and current database systemsAssess database implementation procedures to ensure they follow internal and external regulationsInstall and organize information systems to guarantee company functionalityPrepare accurate database design and architecture reports for management and executive teamsLead all aspects of the migration of data from legacy systems to new solutionsMonitor the system performance by performing regular tests, fixing, and integrating new featuresRecommend solutions to improve new and existing database systems ', 'Monitor the system performance by performing regular tests, fixing, and integrating new features', '• Passion for service', 'Data\xa0Engineer\xa0', ""You will handle the product's or project’s conception, design initial product specifications and lead scheduling, estimate\xa0and secure\xa0resources, as well as provide technical guidance to other internal and external teams. You will\xa0help train new employees and stay ahead of industry trends and issues.\xa0"", 'Qualifications', 'Design and implement effective database solutions and models to store and retrieve company data', '2+ years’ experience in data modeling and architecting, ETL, data engineering, or BI fields with concentration on data transformations and data modeling ', '• Caring for others', 'Examine and identify database structural necessities by evaluating client operations, applications, and programming', '• Innovative']",Mid-Senior level,Full-time,Engineering,Human Resources,2020-10-20 12:01:24
Data Engineer,Turnberry Solutions,"Philadelphia, PA",19 hours ago,Be among the first 25 applicants,"['', 'Developing REST APIs utilizing AWS lambda and API Gateway.', 'Data Engineer in Philadelphia, PA 19103', 'Additional Preferred Skills', 'Proficiency in testing frameworks and writing unit/integration tests', '2+ years working within an enterprise data lake/warehouse environment or big data architecture.', 'Excellent programming skills with experience in at least one of Python, Scala, Java, Node.js.', 'You will collaborate with a diverse set of professionals ranging from software engineers whose software integrates with analytics services, network architects and engineers who are tasked with evolving the network, service delivery engineers who provide support for our products, data analysts and data scientists distilling key insights from massive amounts of raw data, operational stakeholders with all manner of information needs,\u202fand executives who rely on\u202fdata\u202ffor fact-based decision making.\u202f\u202f', 'Caching Frameworks (ElasticCache/Redis)', ' Programming Languages (Python, Scala, Golang, Node.js) Build Environment: GitHub Enterprise, Concourse CI, Jira, Serverless, SAM Cloud Computing (AWS Lambda, EC2, ECS) Spark\u202f(AWS EMR, Databricks) Stream Data Platforms: Kinesis, Kafka Databases: S3, MySQL, Oracle,\u202fMongoDB, DynamoDB Caching Frameworks (ElasticCache/Redis) ', 'Job Description', 'Cloud Computing (AWS Lambda, EC2, ECS)', 'Spark\u202f(AWS EMR, Databricks)', 'Experience with NoSQL databases, such as DynamoDB, MongoDB, Redis,\u202fCassandra, or HBase', 'The Data Science and Engineering team\u202fis acquiring, studying, simulating, and modeling to enable data as a key driver and core functional component toward better understanding, predicting, and dynamically optimizing the access network to improve overall user experience. Success in this role is best enabled by a broad mix of skills and interests ranging from traditional distributed systems software engineering prowess to the multidisciplinary field of data science.\u202f\u202f', 'Developing Spark streaming and batch jobs to clean and transform data.', 'Project Description', ' The Data Science and Engineering team\u202fis acquiring, studying, simulating, and modeling to enable data as a key driver and core functional component toward better understanding, predicting, and dynamically optimizing the access network to improve overall user experience. Success in this role is best enabled by a broad mix of skills and interests ranging from traditional distributed systems software engineering prowess to the multidisciplinary field of data science.\u202f\u202f ', 'Programming Languages (Python, Scala, Golang, Node.js)', 'Required Skills Set', 'Interview Logistics', 'Develop large scale, cloud based data pipelines for the collection and processing\u202fof device telemetry and network events, providing both a real time and historical view into the operation of our products and services.\u202fWork on high performance, real time data stores and a massive historical data sets using\u202fbest-of-breed and industry leading technology. Expose services over REST APIs. Work closely with various engineering teams to solve key optimization, insight and access network data challenges.\u202f', 'Writing build automation to deploy and manage cloud resources.', 'Writing unit and integration tests.', 'Stream Data Platforms: Kinesis, Kafka', 'Experience with monitoring and visualization tools such as Grafana, Prometheus, Data Dog, and Cloudwatch.', 'Education Required: ', 'Proficiency in Unix-based operating systems and bash scripts.', 'Experience with working in Spark', ' Experience with working in Spark Experience with AWS Experience with monitoring and visualization tools such as Grafana, Prometheus, Data Dog, and Cloudwatch. Experience with NoSQL databases, such as DynamoDB, MongoDB, Redis,\u202fCassandra, or HBase ', ' You will collaborate with a diverse set of professionals ranging from software engineers whose software integrates with analytics services, network architects and engineers who are tasked with evolving the network, service delivery engineers who provide support for our products, data analysts and data scientists distilling key insights from massive amounts of raw data, operational stakeholders with all manner of information needs,\u202fand executives who rely on\u202fdata\u202ffor fact-based decision making.\u202f\u202f ', 'Developing large scale data pipelines exposing data sources within the company to our team of data analysts and data scientists.', 'Databases: S3, MySQL, Oracle,\u202fMongoDB, DynamoDB', ' Develop large scale, cloud based data pipelines for the collection and processing\u202fof device telemetry and network events, providing both a real time and historical view into the operation of our products and services.\u202fWork on high performance, real time data stores and a massive historical data sets using\u202fbest-of-breed and industry leading technology. Expose services over REST APIs. Work closely with various engineering teams to solve key optimization, insight and access network data challenges.\u202f ', ' Developing large scale data pipelines exposing data sources within the company to our team of data analysts and data scientists. Developing REST APIs utilizing AWS lambda and API Gateway. Developing Spark streaming and batch jobs to clean and transform data. Writing build automation to deploy and manage cloud resources. Writing unit and integration tests. ', 'Build Environment: GitHub Enterprise, Concourse CI, Jira, Serverless, SAM', 'Experience with AWS', '4+ years working as a software engineer.', 'Years of Experience: ', ' BS/MS degree in Computer Science, Mathematics, or other relevant science and engineering discipline. 4+ years working as a software engineer. 2+ years working within an enterprise data lake/warehouse environment or big data architecture. Excellent programming skills with experience in at least one of Python, Scala, Java, Node.js. Great communication skills. Proficiency in testing frameworks and writing unit/integration tests Proficiency in Unix-based operating systems and bash scripts. ', 'BS/MS degree in Computer Science, Mathematics, or other relevant science and engineering discipline.', 'Physical Environment And Working Conditions', 'Great communication skills.']",Mid-Senior level,Full-time,Other,Information Technology and Services,2020-10-20 12:01:24
Cloud Data Engineer,Randstad USA,"Bethesda, MD",11 hours ago,Be among the first 25 applicants,"['', 'Git version control system', 'Troubleshooting architecture issues', 'Requirements', 'ETL tools (AWS Data Pipeline, Glue)', 'Relational databases (MySQL, PostgreSQL, SQL Server)', 'Planning, analyzing, and designing data-centric solutions', 'AWS Athena, Redshift, Lake formation', ' At least five years of data architecture development and engineering experience', 'Introducing and providing support for artificial intelligence and machine learning models which support BI initiatives', 'At least five years of data architecture development and engineering experience', 'Streaming data', 'Creating architecture for data marts and data warehouses', 'SQL Server and PostgreSQL production', ' Creating architecture for data marts and data warehousesDesigning and developing ETL processes from data stores into managed data lakes and data warehousesPlanning, analyzing, and designing data-centric solutionsIntroducing and providing support for artificial intelligence and machine learning models which support BI initiativesTroubleshooting architecture issues', 'Testing and debugging', 'Responsibilities', 'Designing and developing ETL processes from data stores into managed data lakes and data warehouses', 'Apache Spark', 'Agile methodology', 'Creating and updating AI/ML models for large data sets', 'NoSQL databases (Cassandra, DynamoDB, MongoDB, etc.)', 'Qualifications', 'Education And Experience', ' Relational databases (MySQL, PostgreSQL, SQL Server)SQL Server and PostgreSQL productionNoSQL databases (Cassandra, DynamoDB, MongoDB, etc.)Testing and debuggingETL tools (AWS Data Pipeline, Glue)Apache SparkAWS Athena, Redshift, Lake formationGit version control systemStreaming dataCreating and updating AI/ML models for large data setsAgile methodology', 'Job Summary']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer - Work From Home,Alight Solutions,"Texas, United States",6 hours ago,Be among the first 25 applicants,"['', 'Proficiency in one of the scripting languages such as Shell/Python/Scala/Java. ', 'Comfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve. Comfortable presenting findings to leadership', 'Understands best practices in software engineering, data management, data storage, data compute, and distributed systems', ""Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline"", 'Disclaimer', 'Experience on data platform re-architecture projects or handling operational excellence in DW via automation', '4+ years of experience in Data Platform Administration/Engineering, Hands on experience with AWS based solutions such as EMR, S3, RDS, Lambda, Dynamodb, Redshift, EC2., Experience and tools/frameworks within the big Data ecosystem, Experienced in Agile methodologies.Proficiency in one of the scripting languages such as Shell/Python/Scala/Java. Good understanding of Big Data technology trends, with knowledge of technologies such as Kinesis, Kafka, Spark, Hive, pySpark. Experience in version control systems such as Git, GitLab, etc. Ability to work in a fast-paced, rapidly changing environment. 1+ years of experience using Cloud technologies and AWS Cloud Services certificationExperience with Analytical/Reporting Solutions like Alteryx, Tableau, PowerBI ', '4+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT, reporting/analytic tools and extracting value from large datasets', 'Education', 'Apply cloud-based AWS services to solve challenging problems around: big data processing, data warehouse design, and BI self-service', 'Collaborate with Engineers and Scientists in the organization to construct complex data sources for algorithms and machine learning models', 'Experience in version control systems such as Git, GitLab, etc. ', 'Good understanding of Big Data technology trends, with knowledge of technologies such as Kinesis, Kafka, Spark, Hive, pySpark. ', 'Keep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architecture', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Ability to work in a fast-paced, rapidly changing environment. 1+ years of experience using Cloud technologies and AWS Cloud Services certification', 'Build, analyze and present actionable data to drive marketing business development and product management decisions', '4+ years of experience in Data Platform Administration/Engineering, Hands on experience with AWS based solutions such as EMR, S3, RDS, Lambda, Dynamodb, Redshift, EC2., Experience and tools/frameworks within the big Data ecosystem, Experienced in Agile methodologies.', 'Adopt next-generation data architecture strategies, proposing both data flows and storage solutions', '4+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT, reporting/analytic tools and extracting value from large datasetsExperience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and solutions in AWS/AzureProficiency in Python or other similar languagesStrong understanding of scaling, performance and scheduling, batch and streaming data architectureKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operationsExperience on data platform re-architecture projects or handling operational excellence in DW via automationExperience communicating with management as well as with colleagues from engineering, analytics, and business backgroundsStrong technical and analytical aptitude; Excellent oral and written communication skills', 'Overall ', 'Design, develop, and operate highly-scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms with AWS/cloud technologies', 'Strong technical and analytical aptitude; Excellent oral and written communication skills', 'Focuses on automation and optimization for all areas of DW/ETL maintenance and deployment', 'Experience with Analytical/Reporting Solutions like Alteryx, Tableau, PowerBI ', 'Collaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'High Level Requirements', 'Qualifications', 'Strong understanding of scaling, performance and scheduling, batch and streaming data architecture', 'Experience communicating with management as well as with colleagues from engineering, analytics, and business backgrounds', 'Understands best practices in software engineering, data management, data storage, data compute, and distributed systemsApply cloud-based AWS services to solve challenging problems around: big data processing, data warehouse design, and BI self-serviceFocuses on automation and optimization for all areas of DW/ETL maintenance and deploymentComfortable with a degree of ambiguity and willing to develop quick proof of concepts, iterate and improve. Comfortable presenting findings to leadershipDesign, develop, and operate highly-scalable, high-performance, low-cost, and accurate data pipelines in distributed data processing platforms with AWS/cloud technologiesAdopt next-generation data architecture strategies, proposing both data flows and storage solutionsCollaborate with Engineers and Scientists in the organization to construct complex data sources for algorithms and machine learning modelsBuild, analyze and present actionable data to drive marketing business development and product management decisionsKeep up to date with big data technologies, evaluate and make decisions around the use of new or existing software products to design the data architectureCollaborate with Business Intelligence Engineers to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'Experience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and solutions in AWS/Azure', 'Proficiency in Python or other similar languages']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Platform Data Engineer,Square,"San Francisco, CA",9 hours ago,Be among the first 25 applicants,"['', 'Create and maintain our real-time data pipelineBuild ELTs to consume data from multiple sources, including relational databases, event streams, and third-party data, all populating our data warehouse and other data storesWork with various infrastructure and operations teams to maintain our data infrastructureHelp build and maintain services and tooling to ensure resiliency, fix data discrepancies, and enhance the customer experienceMonitor daily execution, diagnose and log issues, and fix pipelines to ensure SLAs are met with internal stakeholders', 'Kafka and Confluent platform', 'Strong experience at least one of Python or Java', 'Perks', 'Bonus: Experience with asyncio Python', 'Healthcare coverageRetirement PlansEmployee Stock Purchase ProgramWellness perksPaid parental leavePaid time offLearning and Development resources', '3+ years experience writing complex SQL and ETL development, processing large datasets with cloud-based warehouses like Snowflake, Google BigQuery, and Amazon Redshift', 'Snowflake and MySQL', 'Build ELTs to consume data from multiple sources, including relational databases, event streams, and third-party data, all populating our data warehouse and other data stores', 'Technologies We Use And Teach', 'SQL and PythonKafka and Confluent platformSnowflake and MySQLAirflowKubernetes, Docker, Helm, and TerraformAWS, GCP', 'Job Description', 'Experience working with task scheduling frameworks like Airflow and Luigi', '3+ years experience working with relational databases', 'Paid parental leave', 'Paid time off', 'Learning and Development resources', 'Create and maintain our real-time data pipeline', '3+ years experience in Data Engineering, Software Engineering, or similar role', 'Employee Stock Purchase Program', 'Help build and maintain services and tooling to ensure resiliency, fix data discrepancies, and enhance the customer experience', 'Monitor daily execution, diagnose and log issues, and fix pipelines to ensure SLAs are met with internal stakeholders', 'AWS, GCP', 'Healthcare coverage', 'Company Description', 'You Will', 'Experience with message queues (such as Kafka, Kinesis)', 'Work with various infrastructure and operations teams to maintain our data infrastructure', 'Retirement Plans', 'Qualifications', 'Wellness perks', 'Kubernetes, Docker, Helm, and Terraform', 'SQL and Python', 'Experience with container deployment platforms and tools, such as Kubernetes, Docker, Helm, and Terraform', 'Airflow', '3+ years experience in Data Engineering, Software Engineering, or similar role3+ years experience writing complex SQL and ETL development, processing large datasets with cloud-based warehouses like Snowflake, Google BigQuery, and Amazon Redshift3+ years experience working with relational databasesStrong experience at least one of Python or JavaExperience with message queues (such as Kafka, Kinesis)Experience working in and deploying to cloud environments, like AWS, GCPExperience working with task scheduling frameworks like Airflow and LuigiExperience with container deployment platforms and tools, such as Kubernetes, Docker, Helm, and TerraformBonus: Experience with asyncio PythonBonus: Experience with Javascript / Vue', 'Bonus: Experience with Javascript / Vue', 'Experience working in and deploying to cloud environments, like AWS, GCP']",Entry level,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
Data Engineer,OneThree Biotech,"New York, NY",21 hours ago,127 applicants,"['', 'At OneThree Biotech we’re working to change this using biology-driven AI. Founded after members of our team lost family members to rare cancer, the team at OneThree has spent the last 5+ years researching how we can combine AI with systems biology to stop this from happening to anyone else. We’re building a platform to not only predict new potential therapeutics, but also to pinpoint the mechanisms driving efficacy, and we pride ourselves on building a new form of biology-driven AI that values interpretability as much as accuracy. After raising a multi-million round of funding, we’re looking for a Data Engineer to join our interdisciplinary team as we look to ramp up external partnerships and internal development.\xa0', '●\t3+ years experience as a backend software engineer, ideally where your focus was on processing data.\xa0', 'Benefits:\xa0', '●\t401K', '●\tSnacks and refreshments available in-office (monthly budget available for remote employees)', '●\tComprehensive Healthcare, Dental, and Vision (30+ plan options)', '●\tGoogle Cloud', 'Our Stack:', 'Data is core to OneThree’s strategy and business. You will work directly with our Chief Data Scientist, Lead Data Engineer, and founding team to help develop a backend data infrastructure to both support OneThree’s internal AI scientists and platform as well as external-facing partnerships. You will have the opportunity to work with cutting edge data tools and be part of a team working on the bleeding edge of machine learning + biology (based on years of peer-reviewed research and partnerships with leading medical centers).\xa0', 'OneThree Biotech is a VC backed startup working to change how new medicines are discovered using biology-driven AI. We all know someone who’s been affected by cancer, and we’ve proven that our technology can help get life-saving treatments to patients faster (https://people.com/health/teacher-brain-tumor-week-to-live-now-thriving/). Having already signed a set of Fortune 500 paying clients we’re ramping up for our next phase of growth and are looking for a bold and self-motivated engineer to join us as we change healthcare for the better.', 'Responsibilities:\xa0', 'How to stand out:', '●\tWork with an interdisciplinary team consisting of computational biologists and machine learning scientists to make sure ingested data is easily accessible and usable for downstream machine learning methods.', '●\tOur platform is just getting started, and you will regularly participate in discussions as we improve it to take advantage of new opportunities!', '●\tProfessional experience with a scripting language, Python strongly preferred', '●\t25 days PTO\xa0', '●      Space available for remote employees for their in-office visits', '●\tBiology or healthcare experience (definitely not required)', '●\tExperience in version control\xa0', '●\tUnderstanding of modern engineering design principles (distributed systems, stateless processes, etc)', '●\tSQL (both Postgres and BigQuery)', '●\tTell us about the most interesting or intricate data problem you solved, and how you solved it.', '●\tWe expect to add a compiled language in the future. Our platform is still in its early days, and you will have an opportunity to influence our future architectural choices.', '●      Flexible work environment', 'Currently developing a single new drug can take over $1B and 15 years, with over 99% of drugs failing along the way. This is why over 70% of all known diseases have no treatments and millions of patients are left with no viable treatment options.', 'More about us:\xa0', '●\tExperience with Google Cloud (e.g. BigQuery)', '●\tGood command of SQL', '●\tExperience processing relatively large data sets (tens of gigabytes or higher)', '●\tExperience solving intricate problems related to data modeling, cleaning, merging, debugging, or extraction. Tell us about it in your note!', '●\tHelp solve challenging problems in data modeling (for example ensuring that our mapping and merging logic is valid and helpful).', 'Requirements:', '●\tHelp solve challenging problems related to data scale (we are already processing tens of terabytes of biological data, and we’re just getting started).', '●\tExperience building ETL pipelines (experience with an orchestration system like Airflow or Luigi preferred but not required)', '●\tAirflow', 'The ideal candidate will have an entrepreneurial mindset, be comfortable with creative problem solving, and will be excited to work on building a data processing pipeline from the ground-up in a flexible, fast-paced environment. This is a rare opportunity to get in at the early stage and have a real impact on both product and strategy. If working on challenging problems that have a real positive impact excites you, then OneThree is the place for you!', '●\tPython', '●\tOffice at the exclusive Grand Central Tech hub, directly across from Grand Central Station', '●\tBuild efficient data ingress pipelines for both existing data assets and newly identified data sources.\xa0', 'About the Role:\xa0', 'Nice To Have:', '●\tPast working experience in a start-up environment\xa0']",Entry level,Full-time,Information Technology,Biotechnology,2020-10-20 12:01:24
"Data Engineer III, Technology",Walmart,"Dallas, TX",4 hours ago,Be among the first 25 applicants,"['', 'Data Governance: Supports the documentation of data governance processes. Supports the implementation of data governance practices.', ""Problem Formulation: Identifies possible options to address the business problems within one's discipline through analytics, big data analytics, and automation."", 'Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. ', 'Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function.', 'Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current data science and analytics trends.', ""Problem Formulation: Identifies possible options to address the business problems within one's discipline through analytics, big data analytics, and automation.Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues.Data Governance: Supports the documentation of data governance processes. Supports the implementation of data governance practices.Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function.Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current data science and analytics trends.Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.Data Modeling: Analyzes complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyzes data-related system integration challenges and proposes appropriate solutions.Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports.Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates.Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales.Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities.Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices."", 'Demonstrates up-to-date expertise and applies this to the development, execution, and improvement of action plans by providing expert advice and guidance to others in the application of information and best practices; supporting and aligning efforts to meet customer and business needs; and building commitment for perspectives and rationales.', 'Provides and supports the implementation of business solutions by building relationships and partnerships with key stakeholders; identifying business needs; determining and carrying out necessary processes and practices; monitoring progress and results; recognizing and capitalizing on improvement opportunities; and adapting to competing demands, organizational changes, and new responsibilities.', 'Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. ', ' Strong Development Experience in Hadoop, Hive, Kafka, Relational Databases and No-SQL Databases', 'Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports.', ' Strong Development Experience in at least one scripting language', 'Minimum Qualifications...', ""What You'll Do"", ' Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.  ', 'Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates.', 'Models compliance with company policies and procedures and supports company mission, values, and standards of ethics and integrity by incorporating these into the development and implementation of business plans; using the Open Door Policy; and demonstrating and assisting others with how to apply these in executing business processes and practices.', 'Our Ideal Candidate Must Have', 'Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data.', 'Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues.', 'Data Modeling: Analyzes complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyzes data-related system integration challenges and proposes appropriate solutions.']",Associate,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,"NBCUniversal Media, LLC","Seattle, WA",21 hours ago,34 applicants,"['', 'State/Province', 'Qualifications/Requirements', 'City', ' Passion for media and news', ' Possess an in-depth understanding of the data structures and governance ', ' Proficient with Linux environment', 'Country', ' Experience with distributed data technologies (e.g.', ' Experience with Serverless cloud platforms a plus', 'Notices', 'Career Level', ' Familiarity with Presto and SQL', 'About Us', ' Possess an in-depth understanding of the data structures and governance  Fundamental knowledge of of modern cloud computing platforms and concepts  Work with modern schema-less big data storage solutions  Work closely with machine learning and data science teams to create scale and efficiency  Demonstrate critical thinking for potential roadblocks; comprehend a bigger picture of the business and effectively communicate these issues to stakeholders  Work closely with internal stakeholders to implement solutions that adhere to solution designs and schema ', ' Work closely with internal stakeholders to implement solutions that adhere to solution designs and schema ', 'Responsibilities', ' Work closely with machine learning and data science teams to create scale and efficiency ', ' Demonstrate critical thinking for potential roadblocks; comprehend a bigger picture of the business and effectively communicate these issues to stakeholders ', ' Proficient with Javascript and Python', 'Sub-Business', ' Work with modern schema-less big data storage solutions ', ' B.S. degree in Computer Science, Information', ' 2-3 years experience in a developer role', ' Fundamental knowledge of of modern cloud computing platforms and concepts ']",Not Applicable,Full-time,Information Technology,Broadcast Media,2020-10-20 12:01:24
Data Engineer,Creative Circle,"San Jose, CA",6 hours ago,Be among the first 25 applicants,"['', 'Develop and automate data pipelines that support machine learning models.Build and automate processes which introspect on production models, creating tools to help the team manage deployment of current, and new models.Document and socialize technical best practices.', '2+ years working on large software projects leveraging version control systems', '1+ years’ experience with developing technical documentation', 'Fluency in SQL', 'Top Responsibilities', 'Fluency in Unix command line environment, automation', 'A bachelor’s degree in Computer Science or equivalent technical field (Physics, Engineering, etc)Fluency in SQLFluency in Unix command line environment, automation2+ years working on large software projects leveraging version control systems1+ years’ experience with developing technical documentation3+ years’ experience in at least one programming language (Python, C++, Java, Go)', 'Develop and automate data pipelines that support machine learning models.', '3+ years’ experience in at least one programming language (Python, C++, Java, Go)', 'Build and automate processes which introspect on production models, creating tools to help the team manage deployment of current, and new models.', 'Ideal Qualifications', 'Document and socialize technical best practices.', 'A bachelor’s degree in Computer Science or equivalent technical field (Physics, Engineering, etc)']",Entry level,Full-time,Information Technology,Marketing and Advertising,2020-10-20 12:01:24
Data Engineer,Big Cloud,Atlanta Metropolitan Area,,N/A,"['', 'Are you an experienced data engineer? Are you available for an initial 6-month contract?', '\xa0', 'Proficiency in data modelling, database technologies (both SQL and NoSQL)', 'One of the worlds biggest healthcare companies is seeking to recruit a Data Engineer for an initial 6-month contract.', 'Works closely with other data scientists and engineers to develop a strategy for long term data platform architecture', 'As a Data Engineer, you’ll be designing developing and maintaining scalable data models and pipelines, collaborating across all analytics teams to develop efficient end products and building data architecture.', 'You’ll need:', 'Data Architecture and data pipeline design experience\xa0', 'Strong experience in Python', 'Other responsibilities:', 'Cloud experience – ideally Azure or Google Cloud', 'Writes unit/integration tests, contributes to engineering wiki, and documents work.', 'Collaborate and actively contribute in discussions to help define technology and development approach within the team', '2+ years data engineering experience', 'Minimum bachelors degree', 'Contribute to project planning and implementation to ensure that solutions are delivered on time and on requirements', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes', '2+ years data engineering experienceMinimum bachelors degreeStrong experience in PythonCloud experience – ideally Azure or Google CloudProficiency in data modelling, database technologies (both SQL and NoSQL)Data Architecture and data pipeline design experience\xa0', 'Supporting issue analysis and fix activities during test phases, as well as production issue resolution.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processesWrites unit/integration tests, contributes to engineering wiki, and documents work.Works closely with other data scientists and engineers to develop a strategy for long term data platform architectureSupporting issue analysis and fix activities during test phases, as well as production issue resolution.Contribute to project planning and implementation to ensure that solutions are delivered on time and on requirementsCollaborate and actively contribute in discussions to help define technology and development approach within the team']",Mid-Senior level,Contract,Information Technology,Hospital & Health Care,2020-10-20 12:01:24
Database Engineer,"Medisolv, Inc.","Maryland, United States",3 hours ago,Be among the first 25 applicants,"['', 'Optimizing databases via standard practices, e.g. adding indexes, building additional collections, generating statistics, and optimizing execution plans ', 'As a Database Engineer, you will be responsible for aiding in the design, implementation, and operation of Medisolv’s application databases. Specifically, this job will be working with Medisolv’s electronic clinical quality measure tool, which uses both MS-SQL and MongoDB databases. ', 'Excellent      communication skills ', '\xa0', 'Microsoft Azure Technologies ', 'A      willingness and ability to learn new technologies and work hands-on ', 'Debugging issues with client systems, both in the cloud and on-premises installations ', 'Healthcare data and data standards (Standard code systems, quality reporting, etc.) ', 'Experience      working with ETL processes and procedures ', ' 3+      years of experience working with Microsoft SQL Server (or other SQL      technology)  3+      years of experience working with MongoDB (or other NoSQL technology)  Experience      performing data analysis and calculations within a database environment  Experience      working with ETL processes and procedures  Ability      to work as an independent component within a larger team  Ability      to manage multiple project initiatives simultaneously  Excellent      communication skills  A      willingness and ability to learn new technologies and work hands-on  Bachelor’s      degree in a technology related discipline or equivalent experience  ', 'Writing SQL procedures, scripts, and queries to select, insert, update, delete and report data out to a variety of endpoints Optimizing databases via standard practices, e.g. adding indexes, building additional collections, generating statistics, and optimizing execution plans Interfacing with team members to ensure data work is in-line with needs, expectations, and security practices Debugging issues with client systems, both in the cloud and on-premises installations Assisting with general schema maintenance activities, and supporting developers and quality assurance during development, testing and release activities. ', 'Requirements: ', 'Preferred Experience: ', 'Ability      to manage multiple project initiatives simultaneously ', 'Preferred Experience:', 'PostgreSQL ', 'Responsibilities:', '3+      years of experience working with MongoDB (or other NoSQL technology) ', 'Bachelor’s      degree in a technology related discipline or equivalent experience ', 'Writing SQL procedures, scripts, and queries to select, insert, update, delete and report data out to a variety of endpoints ', 'Interfacing with team members to ensure data work is in-line with needs, expectations, and security practices ', 'Electronic Health Record systems (Meditech, EPIC, Cerner, etc.) Healthcare data and data standards (Standard code systems, quality reporting, etc.) PostgreSQL Microsoft Azure Technologies ', 'Requirements:', 'Ability      to work as an independent component within a larger team ', '3+      years of experience working with Microsoft SQL Server (or other SQL      technology) ', 'Responsibilities: ', 'Assisting with general schema maintenance activities, and supporting developers and quality assurance during development, testing and release activities. ', 'Electronic Health Record systems (Meditech, EPIC, Cerner, etc.) ', 'Experience      performing data analysis and calculations within a database environment ']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Software Engineer,Motion Recruitment,"Reston, VA",20 hours ago,38 applicants,"['', '\xa0', '***This is a 1 year initial contract with a possibility for extension or conversion***', 'Software Engineer', 'Dulles, VA!', 'Collaborate with other talented developers and designers to help maintain and deliver features in our Payment Portal, maintain and migrate away tech debt, and share responsibilities like app architecture/design reviews, code reviews, writing unit tests, and performance tuning.\xa0 ', 'Work closely with graphic designers, product owners, and engineers and create a that reach a potentially massive-scale audience, that are of prime importance to the company. Collaborate with other talented developers and designers to help maintain and deliver features in our Payment Portal, maintain and migrate away tech debt, and share responsibilities like app architecture/design reviews, code reviews, writing unit tests, and performance tuning.\xa0 You will own and deliver – from the small must-do tasks to large, complex projects with many moving parts.\xa0 ', 'Responsibilities ', 'a world leading online media company', 'Experience with calls to back-end data repositories, and have a very good understanding of responsive design techniques for desktop and mobile. ', 'Our client, a world leading online media company,\xa0is actively looking for a Software Engineer\xa0to join their team in Dulles, VA! ', '3-5 years experience developing websites and web-services.\xa0 ', '***This is a 1 year initial contract with a possibility for extension or conversion*** ', 'You will own and deliver – from the small must-do tasks to large, complex projects with many moving parts.\xa0 ', 'Desired Skills & Experience ', 'Work closely with graphic designers, product owners, and engineers and create a that reach a potentially massive-scale audience, that are of prime importance to the company. ', 'Responsibilities', 'Desired Skills & Experience', '**Local Candidates Only**Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.Motion Recruitment Partners is parent company to Jobspring Partners and Workbridge Associates, leading providers of IT Staffing Solutions (Contract, Contract-to-Hire, and Direct Hire) in major North American markets. Our unique expertise in today’s highest demand tech skill sets, paired with our deep networks and knowledge of our local technology markets, results in an exemplary track record with candidates and clients.', 'Bachelors degree in Computer Science or Engineering\xa0 ', 'HTML, CSS, Javascript (React) ', ' ', 'Bachelors degree in Computer Science or Engineering\xa0 3-5 years experience developing websites and web-services.\xa0 HTML, CSS, Javascript (React) Experience with calls to back-end data repositories, and have a very good understanding of responsive design techniques for desktop and mobile. Some backend experience is a nice-to-have but not required ', 'Some backend experience is a nice-to-have but not required ']",Associate,Contract,Information Technology,Online Media,2020-10-20 12:01:24
Data Engineer,Toptal,United States,55 minutes ago,Be among the first 25 applicants,"['', 'Technical expertise with Python and PySpark', 'This position is fully remote, with a preference that talent be located within the United States, and is a full-time, 6-12 month contract with room for extension.', '        projects.', '\xa0', 'Experience\xa0with performance\xa0tuning of complex SQL\xa0queries, Indexing\xa0strategies and', 'Nice to have skills:', 'Coordinates on-call support and ensures effective monitoring of system.\xa0', ' Proficient\xa0in Data Analysis, Data Modeling, Data profiling, ETL concepts\xa0and\xa0relational concepts.', 'Owns the change request process and may coordinate with other teams as necessary.\xa0', 'Ability to translate the business requirements/user stories into technical solutions.', ""Toptal is an elite network of the world's top talent, connecting the best and brightest in business, design, and technology with top organizations around the world."", 'Develops and defines application scope and objectives and prepares technical and/or functional specifications from with programs will be written.\xa0', 'RESPONSIBILITIES:', 'Mentors others and may lead multiple or small to medium sized projects.\xa0', 'Experience with\xa0automation and\xa0scheduling of\xa0components through scheduling\xa0toolsExperience with designing, development and deploy the solutions for small/medium scale', 'Experience with\xa0automation and\xa0scheduling of\xa0components through scheduling\xa0tools', 'Supports vendor evaluation.\xa0\xa0', '        Informatica\xa0solution.', ' Healthcare\xa0experience a plus.', 'Maintains active relationships with customers to determine business requirements and leads requirements gathering meetings.\xa0', 'Must Have skills:', 'Ensures unit test is completed and meets the test plan requirements, system testing is completed and system is implemented according to plan.\xa0', 'Technical expertise with Python and PySparkAbility to translate the business requirements/user stories into technical solutions. Proficient\xa0in Data Analysis, Data Modeling, Data profiling, ETL concepts\xa0and\xa0relational concepts.Experience with design and\xa0development of\xa0SQL objects, writing complex SQL queries using\xa0Microsoft T-SQL and\xa0advanced\xa0functions.Experience in design,\xa0development and\xa0implementation of\xa0complex ETL solutionsHave\xa0experience with generating\xa0JSON outputs or other\xa0file extracts\xa0in\xa0different formatsAgile Scrum methodology experience and use of JIRA', 'Have\xa0experience with generating\xa0JSON outputs or other\xa0file extracts\xa0in\xa0different formats', 'Facilitates group sessions to elicit complex information on requirements clarification, design sessions, code reviews and troubleshooting issues.\xa0', 'Experience with designing, development and deploy the solutions for small/medium scale', 'Experience with design and\xa0development of\xa0SQL objects, writing complex SQL queries using\xa0Microsoft T-SQL and\xa0advanced\xa0functions.', 'Assesses current status and supports data information planning.\xa0', 'Maintains active relationships with customers to determine business requirements and leads requirements gathering meetings.\xa0Owns the change request process and may coordinate with other teams as necessary.\xa0Develops and owns list of final enhancements.\xa0Develops and defines application scope and objectives and prepares technical and/or functional specifications from with programs will be written.\xa0Performs technical design reviews and code reviews.\xa0Ensures unit test is completed and meets the test plan requirements, system testing is completed and system is implemented according to plan.\xa0Assesses current status and supports data information planning.\xa0Coordinates on-call support and ensures effective monitoring of system.\xa0Maintains technical development environment.\xa0Mentors others and may lead multiple or small to medium sized projects.\xa0Facilitates group sessions to elicit complex information on requirements clarification, design sessions, code reviews and troubleshooting issues.\xa0Supports vendor evaluation.\xa0\xa0', 'Please apply to learn more about this opportunity and Toptal in general', 'Agile Scrum methodology experience and use of JIRA', 'Performs technical design reviews and code reviews.\xa0', 'Develops and owns list of final enhancements.\xa0', 'Maintains technical development environment.\xa0', ""Our client is looking for Solutions Engineer that is responsible for programming on specific application subsets of the company's application portfolio, participating in all phases of the development and maintenance life cycle, typically for an assigned business unit, client program, or corporate department and utilizing various customer technology platforms."", 'Experience in design,\xa0development and\xa0implementation of\xa0complex ETL solutions']",Mid-Senior level,Contract,Engineering,Internet,2020-10-20 12:01:24
Data Scientist,Burtch Works,"Washington, DC",24 hours ago,Over 200 applicants,"['', 'Compensation will be commensurate on experience, up to around $100k.', 'Keywords: data science, predictive analytics, Python, R, SQL, machine learning, statistical modeling, artificial intelligence, statistics', 'Solid understanding of statistics and machine learning methodologies', 'Desire to work in a collaborative, fast-paced environment', '\xa0', 'Qualifications include:', 'An advanced degree in a quantitative field2+ years of prior analytics experienceSolid understanding of statistics and machine learning methodologiesExpert usage of tools like Python, R, and SQLStrong communication skills and ability to explain complex topics to non-technical audiencesDesire to work in a collaborative, fast-paced environment', 'Strong communication skills and ability to explain complex topics to non-technical audiences', 'Keywords', 'Exciting opportunity with our client in downtown Washington, DC! Unfortunately, only US Citizens and Permanent Residents can be considered for this role.', 'Unfortunately, only US Citizens and Permanent Residents can be considered for this role.', 'This is a great opportunity to join an exciting, established team that is experiencing huge growth. ', 'Expert usage of tools like Python, R, and SQL', 'Our client, a software company building advanced AI tools for a variety of companies, is looking to bring a Data Scientist on to their team. The ideal candidate will have a strong blend of predictive analytics and experience with other data science applications – you will use your statistical knowledge to help optimize and build predictive models to answer various business questions, while also getting involved with other data science projects utilizing AI and other technologies.', 'An advanced degree in a quantitative field', '2+ years of prior analytics experience']",Associate,Full-time,Analyst,Computer Software,2020-10-20 12:01:24
Data Engineer,Amazon,"Seattle, WA",1 hour ago,Be among the first 25 applicants,"['', 'Company', ' Able to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL)', ""Some Problem Spaces We'll Be Working On"", ' Able to write optimize SQL scripts and build scalable data pipelines', 'Description', ' BS or MS in a quantitative field such as Mathematics, Statistics, Physics, Engineering, Computer Science or Economics Industry experience as a Data Engineer or related specialty (e.g. Software Engineer or Data Scientist) with extensive professional experience and a proven track record in a role focused on understanding, manipulating, processing and extracting value from large datasets. Experience processing, filtering, and presenting large quantities (Trillions of rows) of data Able to write optimize SQL scripts and build scalable data pipelines Excellent communication skills and the ability to work well in a team. Effective analytical, troubleshooting and problem-solving skills.', 'About You', ' Experience processing, filtering, and presenting large quantities (Trillions of rows) of data', ' Excellent communication skills and the ability to work well in a team.', ' Effective analytical, troubleshooting and problem-solving skills.', ' Experience in Statistical Software such as R, SAS, SPSS, MINITAB', 'Preferred Qualifications', ' Industry experience as a Data Engineer or related specialty (e.g. Software Engineer or Data Scientist) with extensive professional experience and a proven track record in a role focused on understanding, manipulating, processing and extracting value from large datasets.', 'About Us Together', ' BS or MS in a quantitative field such as Mathematics, Statistics, Physics, Engineering, Computer Science or Economics', ' Experience in Statistical Software such as R, SAS, SPSS, MINITAB Able to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL) Experience using one or more or: Python, VBA, MATLAB, Java, C++', ' Experience using one or more or: Python, VBA, MATLAB, Java, C++', 'Basic Qualifications']",Not Applicable,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
Data Engineer,Synergis,Atlanta Metropolitan Area,2 hours ago,32 applicants,"['', 'SKILLS:', '\xa0', 'Hands-on experience developing and supporting Python based AI/ML solutions.', 'Experience in Data Governance processes and tools such as Informatica Data Catalog', 'Is telecommuting an option?\xa0\xa0\xa0Partial, yes\xa0\xa0There will be times when coming to the office may be necessary.', 'Hands-on experience developing solutions with big data technologies such as Hadoop, HIVE and Spark.', '1-2 year contract', '3+ years hands on experience designing, developing, testing, deploying and supporting data engineering and analytics solutions using Microsoft cloud-based tools such as Azure Data Lake, Azure Data Factory, Azure Databricks, Python, Azure Synapse, Azure Key Vault and Power BI.', 'Is telecommuting an option?\xa0\xa0\xa0', '8+ years hands-on experience with full life-cycle implementation and support of DW/BI solutions.', 'Is travel required?\xa0', 'What does the day to day look like?', 'Experience with Agile as well as DevOps, CI/CD methodologies', 'Hands-on experience designing and developing solutions involving data sourcing, enrichment and delivery using APIs & Web Services.', 'The Data Engineer, Analytics will work with stakeholders – both business and IT to review functional and non-functional requirements, design, develop and support business and artificial intelligence solutions involving Big Data and Microsoft Azure technologies that align with and support the business and Technology Organization strategy and standards.', 'Data Engineer', 'Please contact Christy.Cifreo@Synergishr.com or 770-346-7211', 'What\xa0are the nice to have skills?', 'Is travel required?\xa0Yes, occasionally to attend in-person workshops', 'Experience in creating functional and technical designs for data engineering and analytics solutions.', 'Atlanta, GA or Naperville, IL (mostly remote though)', 'Experience with Containerization methodologies – Docker, OpenShift etc.,', '8+ years hands-on experience with full life-cycle implementation and support of DW/BI solutions.5+ years hands on experience designing, developing, testing, deploying and supporting data engineering and analytics solutions using on-premises tools such as, MSBI (SSIS/SSAS), Informatica, Oracle Golden Gate, SQL, Oracle and SQL Server.3+ years hands on experience designing, developing, testing, deploying and supporting data engineering and analytics solutions using Microsoft cloud-based tools such as Azure Data Lake, Azure Data Factory, Azure Databricks, Python, Azure Synapse, Azure Key Vault and Power BI.Experience in creating functional and technical designs for data engineering and analytics solutions.Experience to implement data models of different schemas and working with diverse data source types.Hands-on experience developing solutions with big data technologies such as Hadoop, HIVE and Spark.Hands-on experience developing and supporting Python based AI/ML solutions.Hands-on experience developing automation solutions using tools such as Autosys.Experience with Containerization methodologies – Docker, OpenShift etc.,Experience with Agile as well as DevOps, CI/CD methodologiesExperience with designing re-usable solution components and perform code-reviews.Experience working in a medium to large enterprise setting and collaborating with multiple cross-functional teamsExperience working on concurrent assignments on multiple projects.', 'Experience in Data Quality processes and tools such as DQS', 'Microsoft Azure Data Engineer CertificationExperience in Utilities, Preferably GasExperience in Data Governance processes and tools such as Informatica Data CatalogExperience in Data Quality processes and tools such as DQSHands-on experience designing and developing solutions involving data sourcing, enrichment and delivery using APIs & Web Services.Experience with Agile methodology and tools such as JIRA', 'Experience with Agile methodology and tools such as JIRA', '5+ years hands on experience designing, developing, testing, deploying and supporting data engineering and analytics solutions using on-premises tools such as, MSBI (SSIS/SSAS), Informatica, Oracle Golden Gate, SQL, Oracle and SQL Server.', 'To design, develop, test and deploy hybrid data engineering and analytics solutions using on-premises and cloud-based tools as well as support them.', 'Job Description:', 'Attend requirements sessions, create and review functional and technical designs, develop the designed solution, optimize performance, support test efforts, plan and execute deployments as well as resolve technical issues.\xa0Additionally, assist the Analytics team with impact analysis, effort estimates, support planning and participate in after-hours production support call out rotation.', 'Microsoft Azure Data Engineer Certification', 'This position will be focused on supporting existing data integration and analytics solutions as well as designing and developing new solutions.\xa0\xa0Additionally, the Data Engineer is expected to participate in knowledge sharing and own technical issue resolution.', 'Experience working on concurrent assignments on multiple projects.', 'Experience with designing re-usable solution components and perform code-reviews.', 'Hands-on experience developing automation solutions using tools such as Autosys.', 'The Data Engineer, Analytics will work with stakeholders – both business and IT to review functional and non-functional requirements, design, develop and support business and artificial intelligence solutions involving Big Data and Microsoft Azure technologies that align with and support the business and Technology Organization strategy and standards. Additionally, this position will be responsible for management and alignment of solutions across all technology platforms working closely with Architects, data and infrastructure teams to optimize application code, ensuring data integrity, security, stability, resiliency, sustainability, growth and performance.', '\ufeffPlease provide a short summary job description - provide just the highlights?', 'How will the contractor be using their technical skills?', 'Experience to implement data models of different schemas and working with diverse data source types.', 'Experience in Utilities, Preferably Gas', 'Experience working in a medium to large enterprise setting and collaborating with multiple cross-functional teams']",Mid-Senior level,Contract,Information Technology,Oil & Energy,2020-10-20 12:01:24
Software Engineer I,Parsons Corporation,"Centreville, VA",14 hours ago,Be among the first 25 applicants,"['', 'Must have a Bachelor of Science in Software Engineering, Computer Science, Computer Engineering, Computer Security or related field', 'Experience using multi-threaded and real-time programming techniques', 'Required Qualifications', 'Experience working in a Linux command line environment', 'Overview', 'Must have a Bachelor of Science in Software Engineering, Computer Science, Computer Engineering, Computer Security or related fieldMust have a GPA 3.0 or above (out of 4.0 scale)Experience working in a Linux command line environmentKnowledge of Linux or other embedded SystemsExperience with Python, BASH, or C/C++ programmingUnderstanding of network protocolsProof of US citizenshipAbility to obtain and maintain a security clearance', 'Minimum Clearance Required To Start', 'Must have a GPA 3.0 or above (out of 4.0 scale)', 'Ability to communicate with technical team members, managers, and customers', 'Strong ability to grasp new technologies and acquire new skills through independent study, professional training, and interaction with other team membersAbility to communicate with technical team members, managers, and customersExperience using multi-threaded and real-time programming techniquesKnowledge of computer and network security practicesExperience using virtualization technologies', 'Job Description:', 'Strong ability to grasp new technologies and acquire new skills through independent study, professional training, and interaction with other team members', 'Proof of US citizenship', 'Experience using virtualization technologies', 'Knowledge of computer and network security practices', 'Understanding of network protocols', 'Ability to obtain and maintain a security clearance', 'Experience with Python, BASH, or C/C++ programming', 'Knowledge of Linux or other embedded Systems']",Not Applicable,Full-time,Information Technology,Civil Engineering,2020-10-20 12:01:24
Data Engineer,Optello,"San Mateo, CA",5 hours ago,Be among the first 25 applicants,"['', ' Strong verbal and written communication experience', ' 7+ years of Java programming experience 5+ years of Python programming experience 5+ years of SQL database experience Strong verbal and written communication experience RESTful API and server-side API integration experience', ' Fully stocked snacks', ' Build upon existing data service architecture to support internal and external applications', ' 5+ years of SQL database experience', 'Optello is proud to be an Equal Opportunity Employer', ' Experience with Maria databases', 'Your Right to Work', ' Build scalable pipelines capable of processing massive amounts of data Build upon existing data service architecture to support internal and external applications Work supporting ETL pipelines, real time streams, and data warehouses Design and implement process improvements, automate manual processes, and redesign infrastructure Build upon on the infrastructure required to optimize the extraction, transformation, and loading of data using Java, Python, SQL Working in a remote setting with virtual team meetings on a regular basis Collaborate with business intelligence and analytics teams to optimize Tableau report queries', ' Catered breakfast and lunch each week', ' 7+ years of Java programming experience', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : TB10-1596981 -- in the email subject line for your application to be considered.***', ' Amazing healthcare benefits', ' Salesforce integration experience', ' Competitive starting salary Amazing healthcare benefits 401k + match Generous PTO Equipment provided Stipend for workspace', 'Job Title:', 'Job Duration:', ' Experience with Cassandra databases', ' Childcare assistance', 'Email Your Resume In Word To', ' Experience with Cassandra databases Additional NoSQL database experience Experience with Maria databases Salesforce integration experience', ' Catered breakfast and lunch each week Fully stocked snacks Pet-friendly office Childcare assistance', ' Design and implement process improvements, automate manual processes, and redesign infrastructure', 'Must Have Skills', ' Stipend for workspace', ' Pet-friendly office', 'Requirements:', ' Equipment provided', ' Work supporting ETL pipelines, real time streams, and data warehouses', ' Additional NoSQL database experience', ' 401k + match', ' Build scalable pipelines capable of processing massive amounts of data', ' RESTful API and server-side API integration experience', ' Generous PTO', ' 5+ years of Python programming experience', ' Working in a remote setting with virtual team meetings on a regular basis', ' Competitive starting salary', ' Collaborate with business intelligence and analytics teams to optimize Tableau report queries', 'Bonus Skills', ' Build upon on the infrastructure required to optimize the extraction, transformation, and loading of data using Java, Python, SQL', 'Job Location:']",Entry level,Full-time,Information Technology,Construction,2020-10-20 12:01:24
Data Scientist,Jobot,"Arlington, VA",7 hours ago,Be among the first 25 applicants,"['', ' Apply machine learning techniques including deep learning, to protect networks and devices from cyber threats  Implement supervised and unsupervised algorithms for data fusion, predictive analytics, and anomaly detection tasks in cybersecurity Implement graph-theoretic algorithms and machine learning models for graphs Analyze and build systems that use multiple sources of data, including cybersecurity logs, network traffic, PCAP, and OSINT Implement algorithms for natural language processing, information extraction, and vector space models Read/author research papers, white papers, proposals, and presentations', ' Full Benefits + 100% Paid Premiums ', 'Why join us?', ' BS/MS in quantitative field  Proficiency in one or more data science programming language Python, R, Java, Scala, etc. Experience with deep learning frameworks, distributed computing and/or productionizing data science workflows  Ability to get and maintain TS/SCI security clearance***', ' Proficiency in one or more data science programming language Python, R, Java, Scala, etc.', ' 401k + Match ', 'Job Details', ' Experience with deep learning frameworks, distributed computing and/or productionizing data science workflows ', ' Competitive Salary + Bonuses  Generous PTO/Vacation  Full Benefits + 100% Paid Premiums  401k + Match  Commuting/Transit Benefits + Allowances', ' Competitive Salary + Bonuses ', ' Read/author research papers, white papers, proposals, and presentations', ' Ability to get and maintain TS/SCI security clearance***', ' Implement supervised and unsupervised algorithms for data fusion, predictive analytics, and anomaly detection tasks in cybersecurity', ' Implement graph-theoretic algorithms and machine learning models for graphs', ' Implement algorithms for natural language processing, information extraction, and vector space models', ' BS/MS in quantitative field ', ' Generous PTO/Vacation ', 'A Bit About Us', 'Qualifications', ' Analyze and build systems that use multiple sources of data, including cybersecurity logs, network traffic, PCAP, and OSINT', ' Apply machine learning techniques including deep learning, to protect networks and devices from cyber threats ', ' Commuting/Transit Benefits + Allowances']",Mid-Senior level,Full-time,Engineering,Computer & Network Security,2020-10-20 12:01:24
System Engineer,The Consulting Experts,"Annapolis, MD",1 hour ago,Be among the first 25 applicants,"['', 'Multi-team collaboration and support', '\xa0', 'Experience networking (switch/routing), boarder defense and enterprise implementation', 'Bachelor’s Degree in Systems Engineering, Computer Science, Information Assurance, Information Security or related discipline with 14 years of System Engineering experience', 'It wou’d be a great fit if…\xa0', 'Experience with UCS Director (Cisco UCS Platforms)', 'Implements comprehensive SOA solutions', 'You’ve spent 2-5 years working in', 'Prior project management and risk management experience', 'Four years of additional Systems Engineering experience may be substituted for degree', 'Strong understanding of virtualization and orchestration.Experience networking (switch/routing), boarder defense and enterprise implementationMulti-team collaboration and supportImplements comprehensive SOA solutionsDesired: Metrics and data analysis for predicting future behaviorsPrior project management and risk management experience', 'Desired: Metrics and data analysis for predicting future behaviors', 'Strong understanding of virtualization and orchestration.', 'Have VMWare expertise (vMotion, vRA, vRO)', 'Experience administrating HP Operations Manager, Network Node Manager, and/or Sitescope”', 'It’d be even better if you…\xa0', 'Linux Experience', 'Bachelor’s Degree in Systems Engineering, Computer Science, Information Assurance, Information Security or related discipline with 14 years of System Engineering experienceFour years of additional Systems Engineering experience may be substituted for degreeExperience with UCS Director (Cisco UCS Platforms)Have VMWare expertise (vMotion, vRA, vRO)Linux ExperienceHP/Microfocus monitoring tool experienceExperience administrating HP Operations Manager, Network Node Manager, and/or Sitescope”Lean six-sigma, process improvement, and quality assessment experienceYou’ve spent 2-5 years working in', 'Lean six-sigma, process improvement, and quality assessment experience', 'HP/Microfocus monitoring tool experience']",Associate,Full-time,Information Technology,Information Services,2020-10-20 12:01:24
Software Engineer,SparkPost,"Columbia, MD",2 hours ago,Be among the first 25 applicants,"['', 'Equipment includes MacBook Pro', 'Must think critically, be outcome-oriented, and constantly strive to improve how the team reliably delivers high-quality software.', 'Work from home / remote options', '3+ years experience building, testing, and deploying high quality, highly reliable, scalable web applications, APIs, and user interfaces in a team environment.', 'Automation of development, build, testing, and deployment & operations processes.', 'Operational support of team services, including building, managing, monitoring and supporting infrastructure necessary for team services.', 'Experience with JS tooling such as NPM.', 'Experience with Amazon Web Services including EC2, S3, Dynamo, Redis, SNS/SQS, and Lambda.', '401k Matching', 'SparkPost unifies email delivery with analytics, leveraging the world’s largest commercial email delivery data footprint. Customers rely on SparkPost’s infrastructure and insights to execute data-driven email programs that meet and exceed their business objectives.\xa0Our software sends nearly 40% of the world’s commercial email--that’s 4.4 trillion emails a year--for some of the world’s most sophisticated email senders, including Salesforce, Oracle, Adobe, Capital One, Zillow, Pinterest, and Twitter.', 'Team Building activities', 'Hackathons', 'We are currently seeking a Software Engineer to join our team remotely. The ideal candidate must be an energetic, organized and detail oriented team player and will be an integral part of our growing enterprise software company.', 'Responsibilities', 'Experience in server-side development and operations with Node.js, nginx, Containers (Docker), and microservices.', 'Passion for quality-oriented software development best practices including unit and functional testing, automation, CI/CD, monitoring and low-dependency architectures.', 'SparkPost Perks', 'Desired Experience and Qualifications', 'Experience with modern database technologies like PostgreSQL and Dynamo.', 'Strong ability to collaborate with peers on best practices, testing, and building in quality.', 'Excellent analytical, problem solving and debugging skills.', ""Bachelor's degree in Computer Science (or related field) from an accredited college or university… Master’s degree in Computer Science (or related field) is a plus"", ""Bachelor's degree in Computer Science (or related field) from an accredited college or university… Master’s degree in Computer Science (or related field) is a plus3+ years experience building, testing, and deploying high quality, highly reliable, scalable web applications, APIs, and user interfaces in a team environment.Strong ability to collaborate with peers on best practices, testing, and building in quality.Experience in server-side development and operations with Node.js, nginx, Containers (Docker), and microservices.Experience with modern database technologies like PostgreSQL and Dynamo.Experience with Amazon Web Services including EC2, S3, Dynamo, Redis, SNS/SQS, and Lambda.DevOps eExperience in cloud infrastructure management with tool like CloudFormation, terraform, and ansibleExperience with JS tooling such as NPM.Passion for quality-oriented software development best practices including unit and functional testing, automation, CI/CD, monitoring and low-dependency architectures.Must think critically, be outcome-oriented, and constantly strive to improve how the team reliably delivers high-quality software.Excellent analytical, problem solving and debugging skills.Comfortable working with git and GitHub for version control, including opening/reviewing pull requests and distributed branching models."", '\xa0Desired Experience and Qualifications', 'Flexible hoursWork from home / remote optionsMedical, Dental & Vision Benefits401k MatchingHackathonsTeam Building activitiesEquipment includes MacBook Pro', 'Comfortable working with git and GitHub for version control, including opening/reviewing pull requests and distributed branching models.', 'Medical, Dental & Vision Benefits', 'You will work within an agile software engineering team to create software applications that delight our customers. Software development includes: Server-Side, Database Development, REST APIs. Collaboration within the team and with our partners is essential (Product, Project Management, other teams) for all activities: requirements analysis, R&D and prototyping, architecture, estimates, documentation, coding, and testing. Unit, functional, and performance testing.', 'Flexible hours', 'DevOps eExperience in cloud infrastructure management with tool like CloudFormation, terraform, and ansible']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Rational,United States,16 hours ago,Be among the first 25 applicants,"['', ""Be a leader in Business Intelligence and Reporting efforts. Mentor and provide input to team members and other analysts to execute on the team's vision, design and execute projects from start-to-finish, inform technical direction, and support reporting of accomplishments."", 'The initial project for this role will be developing a commercial field sales report for deployment through a mobile device. An existing PowerShell app is currently being refined to expand and adapt to the new needs.', '\ufeffRational\xa0is committed to ensuring\xa0all candidates have an equal opportunity to be considered for employment.\xa0Please let us know if you need any reasonable accommodation to participate in the job application or interview process.', 'Build collaboration among stakeholders, working across our clients to bring consensus to achieve objectives. Become a sought-out subject matter expert by consistently producing high-quality results.', ""7+ years' experience with SQL Server and PowerShell"", 'Who you are:', 'Interface with Architects to recommend new technology opportunities that will have an impact on BI systems', 'Experience participating in workstream planning process including inception, technical design, development, testing and delivery of BI solutions.', 'Strong professional experience analyzing business and functional requirements and translating these requirements into robust, scalable, operable solutions.', ""Rational is a customer experience (CX) solutions firm that pairs the capabilities of a strategic consultancy with the creativity of a full-service digital agency. We design and activate compelling experiences that create strong connections between people and brands. We put humans at the center of business and partner with our clients to deliver meaningful experiences that help their customers while driving business success. Customer satisfaction at every level is our ultimate metric, and it's what drives our mindset, skillset, and company culture."", 'Adaptable. Change happens at lightning speed;\xa0you are flexible, enjoy challenge, and get behind new ideas\xa0', 'Experience implementing data structures using best practices in data modeling, processes, and technologies.', 'Demonstrated ability in selecting, developing, and applying data modeling tools and processes with proven business utility', 'Proactive', 'Create and maintain documentation(s) for implemented business intelligence processes', 'Creates scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation.', 'Working knowledge of modern large-scale data systems and architectures; ability to manage and manipulate large disparate data sets', 'Support eDW team and Developers to build data warehousing systems for business intelligence, reporting and analytics.', 'Support the development of business intelligence standards to meet business goals.', 'Visionary.\u202fAbility to see ""the whole picture"" and simultaneously remain slightly obsessed with the details\u202f\xa0', 'Assist in business report generation', 'As an integral member of our report delivery team, the Data Engineer role works closely with customers and BI Analysts to turn data into critical information and knowledge that can be used to make sound business decisions. They provide data that is accurate, congruent and reliable and is easily accessible.', 'Incredible people are our non-negotiable. Our experienced team of consultants spans the globe. We love what we do, and who we do it with – let’s begin our next chapter together.\u202f', 'Knowledge of implementing tools and frameworks for automating report generation, identification of data-quality issues, and data governance.', 'Recommend enhancements and modifications to optimize business intelligence processes.', 'Adaptable', 'Analyze and test new releases/versions of software.', 'What you will do: ', 'Proven experience exploring the data and discovers patterns, meaningful relationships, anomalies, and trends.', 'Works on highly complex and cross-functional BI solutions.', 'Data Lover.\u202fYou know your numbers and value the metrics behind the buyer story.', 'Data Lover.', 'Identify valuable data sources and automate collection processes', 'Experience collecting, analyzing, and sharing data to help business teams drive improvement in key business metrics, customer experience, and business results.', 'Propose solutions and strategies to address operational business challenges', 'Visionary.', 'Collaborative to the Core.', 'Conduct research and makes recommendations on BI products and services.', 'The Data Engineer is responsible for the full life cycle development, implementation, production support, and performance tuning of the Enterprise Data Warehouse, Data Mart, and Business Intelligence Reporting environments, and support the integration of those systems with other applications. They design and implement reporting and analytical solutions, including both the design of table structures and the processes used to populate those structures with data from internal and external sources.\xa0', 'Track and report out on issues and enhancement request for the business in a timely manner.', 'Rational is growing, and we need amazing talent to join our team. If you have an entrepreneurial attitude with a deep spirit of service and killer subject expertise, we want to talk to you. We are always looking for the next great consultant to raise the bar and push Rational to be better than we were yesterday. Staying hungry, curious, and looking forward to what’s next is part of our DNA.', 'Work closely with customers and BI Analysts to create ad hoc reports to support timely business decisions and project work.', 'Snowflake experience is highly-valued, but not required', 'Coordinate with customers, Business Analysts and DW Architects to implement business data reporting and analysis requirements.', 'Ensure adherence to process, policies, and standards', 'Ability to lead the integration efforts for merging BI platforms with enterprise systems and applications.', ""Coordinate with customers, Business Analysts and DW Architects to implement business data reporting and analysis requirements.Assist in business report generationSupport eDW team and Developers to build data warehousing systems for business intelligence, reporting and analytics.Assist in data administration, modeling and integration activities using data warehouse systems in the reporting layer.Implement business intelligence solutions to achieve data reporting and analysis goals.Support the development of business intelligence standards to meet business goals.Support Analysts with new data requirements, analysis strategies and reporting mechanisms.Recommend enhancements and modifications to optimize business intelligence processes.Address business intelligence queries and issues in a timely fashion.Create and maintain documentation(s) for implemented business intelligence processesPropose solutions and strategies to address operational business challengesIdentify valuable data sources and automate collection processesBe a leader in Business Intelligence and Reporting efforts. Mentor and provide input to team members and other analysts to execute on the team's vision, design and execute projects from start-to-finish, inform technical direction, and support reporting of accomplishments.Build collaboration among stakeholders, working across our clients to bring consensus to achieve objectives. Become a sought-out subject matter expert by consistently producing high-quality results.Creates scalable, efficient, automated processes for large scale data analyses, model development, model validation, and model implementation.Document standards and policies for the form, structure, and attributes of the BI tools and systems.Ensure adherence to process, policies, and standardsTrack and report out on issues and enhancement request for the business in a timely manner.Work closely with customers and BI Analysts to create ad hoc reports to support timely business decisions and project work.Analyze and test new releases/versions of software.Conduct research and makes recommendations on BI products and services.Interface with vendors to keep abreast of new technologies, pricing, and customer applicability.Interface with Architects to recommend new technology opportunities that will have an impact on BI systems"", 'What you will bring:', 'Support Analysts with new data requirements, analysis strategies and reporting mechanisms.', 'These Engineers also interact with various development teams, project managers, internal and external customers, senior management, and external vendors. They must have an in-depth understanding of the business environment, and strong analytical and communication skills. Individuals must work well within a team environment. These reports will be done in adherence to reporting Standards and Guidelines at Seattle Genetics.', 'Address business intelligence queries and issues in a timely fashion.', 'Document standards and policies for the form, structure, and attributes of the BI tools and systems.', 'Experience developing work plans and reviewing other work plan timelines and manages workflows to meet timeframes.', 'Collaborative to the Core.\xa0Demonstrated ability to work in a team environment, as a leader and member.\xa0', 'Assist in data administration, modeling and integration activities using data warehouse systems in the reporting layer.', 'Proactive. You are always thinking ahead about what is best for the Client.\xa0Adaptable. Change happens at lightning speed;\xa0you are flexible, enjoy challenge, and get behind new ideas\xa0Visionary.\u202fAbility to see ""the whole picture"" and simultaneously remain slightly obsessed with the details\u202f\xa0Collaborative to the Core.\xa0Demonstrated ability to work in a team environment, as a leader and member.\xa0Data Lover.\u202fYou know your numbers and value the metrics behind the buyer story.', 'Implement business intelligence solutions to achieve data reporting and analysis goals.', ""7+ years' experience with SQL Server and PowerShellSnowflake experience is highly-valued, but not requiredDemonstrated ability in selecting, developing, and applying data modeling tools and processes with proven business utilityWorking knowledge of modern large-scale data systems and architectures; ability to manage and manipulate large disparate data setsWorks on highly complex and cross-functional BI solutions.Experience participating in workstream planning process including inception, technical design, development, testing and delivery of BI solutions.Experience developing work plans and reviewing other work plan timelines and manages workflows to meet timeframes.Strong professional experience analyzing business and functional requirements and translating these requirements into robust, scalable, operable solutions.Experience collecting, analyzing, and sharing data to help business teams drive improvement in key business metrics, customer experience, and business results.Experience implementing data structures using best practices in data modeling, processes, and technologies.Knowledge of implementing tools and frameworks for automating report generation, identification of data-quality issues, and data governance.Ability to lead the integration efforts for merging BI platforms with enterprise systems and applications.Proven experience exploring the data and discovers patterns, meaningful relationships, anomalies, and trends."", 'Proactive. You are always thinking ahead about what is best for the Client.\xa0', 'Interface with vendors to keep abreast of new technologies, pricing, and customer applicability.']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Data Scientist,Nintendo,"Redmond, WA",9 hours ago,Be among the first 25 applicants,"['', 'Continuously identify new data sources; explore, consolidate unstructured and diverse data, and incorporate into analyses and models. Work with engineering colleagues to onboard data as needed', 'Ability to speak and write fluent Japanese a strong plus, but not required', '2 - 4 years of experience working in an industry setting in a data-driven centric role1+ year hands-on experience building predictive models on real-world dataSolid understanding in statistical modeling (regression, sampling, MLE, etc.)Proficient with utilizing statistical learning algorithms from open source software (e.g. R, Python, etc.); should be able to write own code as needed to customize solutionsComfortable getting and preparing data; this includes using SQL as well as dealing with unstructured data that might require calling APIs, or writing custom scriptsTake ownership of work and operate under minimal supervisionExperience working in digital marketing, CRM, or related domain is highly desirablePassion and depth of knowledge for video games, technology, and entertainment marketExperience utilizing cloud computing platforms to handle Big Data preferredExpertise in causal inference preferred Ability to speak and write fluent Japanese a strong plus, but not requiredGraduate degree (or equivalent knowledge) in a quantitative field requiredMasters or PhD preferred', 'Gain deep insight into player behavior and business impact; present findings to internal stakeholders', 'We are an equal opportunity employer of individuals with disabilities and protected veterans....valuing diversity…celebrating strengths.', 'Transition proof of concept models into scalable productionalized solutions for consumer facing experiences', 'Experience utilizing cloud computing platforms to handle Big Data preferred', 'Summary Of Requirements', '1+ year hands-on experience building predictive models on real-world data', 'Expertise in causal inference preferred ', 'Graduate degree (or equivalent knowledge) in a quantitative field required', 'Masters or PhD preferred', 'Description Of Duties', '2 - 4 years of experience working in an industry setting in a data-driven centric role', 'Solid understanding in statistical modeling (regression, sampling, MLE, etc.)', 'Experience working in digital marketing, CRM, or related domain is highly desirable', 'Nintendo of America Inc.', 'Take ownership of work and operate under minimal supervision', 'Comfortable getting and preparing data; this includes using SQL as well as dealing with unstructured data that might require calling APIs, or writing custom scripts', 'Passion and depth of knowledge for video games, technology, and entertainment market', 'Interacts with product, marketing, and service teams to identify questions and issues for data analysis and experiments.', 'Develop and refine models to predict consumer behavior and help prescribe actions to improve forecasting, personalization, customer engagement, and monetization ', 'Develop and refine models to predict consumer behavior and help prescribe actions to improve forecasting, personalization, customer engagement, and monetization Continuously identify new data sources; explore, consolidate unstructured and diverse data, and incorporate into analyses and models. Work with engineering colleagues to onboard data as neededTransition proof of concept models into scalable productionalized solutions for consumer facing experiencesGain deep insight into player behavior and business impact; present findings to internal stakeholdersSupport exploration of new technologies and analysis methods to identify growth / efficiency opportunities Interacts with product, marketing, and service teams to identify questions and issues for data analysis and experiments.Help educate, influence, and inspire adoption of data science best practices', 'Support exploration of new technologies and analysis methods to identify growth / efficiency opportunities ', 'Help educate, influence, and inspire adoption of data science best practices', 'Proficient with utilizing statistical learning algorithms from open source software (e.g. R, Python, etc.); should be able to write own code as needed to customize solutions']",Not Applicable,Full-time,Business Development,Computer Games,2020-10-20 12:01:24
Data Engineer,Wood Mackenzie,"Houston, TX",13 hours ago,Be among the first 25 applicants,"['', 'About The Role', 'Proven experience with data warehousing, data ingestion, and data profiling', 'Working knowledge of statistical models and machine learning algorithms', 'Additional Information', 'Job Description', 'Understand the application of signal processing', 'Experience in big data development on Hadoop or Spark frameworks. In depth knowledge of building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.', 'Desired Education And/or Certification', 'Forbes', 'Familiar with the software development life cycle including architect review, unit test, software deployment and maintenance.Strong object-oriented programming skills and proficient in Python.Some experience with container-based application development and deployment.Experience working with AWS technologies (ECS, Redshift, EMR, S3, Glue, Athena etc.).Proven experience with data warehousing, data ingestion, and data profilingProficient in relational databases.Experience in big data development on Hadoop or Spark frameworks. In depth knowledge of building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.Working knowledge of statistical models and machine learning algorithms', 'Preferred (or Nice To Have) Qualifications/skills', 'Company Description', 'Familiarity with deep learning and reinforcement learning', 'Familiarity with deep learning and reinforcement learningUnderstand the application of signal processing', 'Qualifications', 'Proficient in relational databases.', 'Master or higher in computer science/computer engineering, or equivalent industry experience', 'Strong object-oriented programming skills and proficient in Python.', 'Some experience with container-based application development and deployment.', 'Experience working with AWS technologies (ECS, Redshift, EMR, S3, Glue, Athena etc.).', 'Consumer Privacy Notice', 'Familiar with the software development life cycle including architect review, unit test, software deployment and maintenance.', 'Required (or Must Have) Qualifications/skills']",Associate,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Database Engineer,i360,"Arlington, VA",6 hours ago,Be among the first 25 applicants,"['', 'Salary And Benefits Commensurate With Experience.', 'Experience in Java with JDBC and concurrent processing', '5+ years of experience in Java with JDBC and concurrent processing ', 'Experience with NoSQL technologies such as Elasticsearch, MongoDB, Cassandra, and HBase', 'Description', ""BA/BS or Master's degree in Computer Science, Computer Engineering or Statistics5+ years' of experience and strong understanding of RDBMS concepts, query optimization5+ years of experience in Java with JDBC and concurrent processing "", 'Resolve technical issues through debugging, research, and investigation. Relies on experience and judgment to plan and accomplish goals.', 'Experience with Cloud system architecture and design, large scale streaming data processing', 'Excellent problem solving and analytical thinking skills ', 'Experience building, scaling and maintaining high volume systems', 'Experience with Spring framework, AOP, JPA and REST ', 'Experience coding in C#, Python, R, GO, Rust etc. ', 'Experience with building RESTful web services', 'Familiarity with Linux/Unix work environment ', 'Preferred Qualifications', 'To be considered, candidates must be creative, passionate about process improvement, and strong technical ability in the following areas:', 'Strong understanding of RDBMS concepts and query optimization', 'Code applications that adhere to enterprise design patterns.Load and process disparate data sets using appropriate technologies including but not limited to SQL Server, Elasticsearch, Spark, Java and Kafka.Resolve technical issues through debugging, research, and investigation. Relies on experience and judgment to plan and accomplish goals.', 'Code applications that adhere to enterprise design patterns.', 'Load and process disparate data sets using appropriate technologies including but not limited to SQL Server, Elasticsearch, Spark, Java and Kafka.', 'Experience in automation area for database technologies using Chef or Puppet', 'The Experience You Will Bring ', 'Strong understanding of RDBMS concepts and query optimizationExperience in Java with JDBC and concurrent processingExperience with NoSQL technologies such as Elasticsearch, MongoDB, Cassandra, and HBaseExperience building, scaling and maintaining high volume systemsExperience in working with Kafka, RabbitMQ or other messaging technologiesKnowledge of version control software’s like Git, SVN, and TFS Familiarity with Linux/Unix work environment Strong computer science fundamentals in object-oriented design, data structures, algorithm design, problem solving, and complexity analysisExcellent communication and collaboration skillsExcellent problem solving and analytical thinking skills ', ""BA/BS or Master's degree in Computer Science, Computer Engineering or Statistics"", 'Experience with Spring framework, AOP, JPA and REST Experience with building RESTful web servicesExperience with Cloud system architecture and design, large scale streaming data processingExperience in automation area for database technologies using Chef or PuppetExperience coding in C#, Python, R, GO, Rust etc. ', ""5+ years' of experience and strong understanding of RDBMS concepts, query optimization"", 'Experience in working with Kafka, RabbitMQ or other messaging technologies', 'What You Will Do In Your Role', 'Excellent communication and collaboration skills', 'Strong computer science fundamentals in object-oriented design, data structures, algorithm design, problem solving, and complexity analysis', 'Knowledge of version control software’s like Git, SVN, and TFS ', 'Basic Qualifications']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Software Engineer,ECS,"Fairfax, VA",8 hours ago,Be among the first 25 applicants,"['', 'A self-motivated, self-starter that enthusiastically embraces pushing imaginative solutions to hard operational problems', 'Software Engineer', 'US Citizen', 'Experience utilizing big data and cloud tools and technologies', 'Experience utilizing containerization technologies (e.g. Docker)', 'Ability to travel (10%) to mostly CONUS locations', 'The Software Engineer has prior experience in designing/architecting enterprise scale systems incorporating a variety of components (COTS, Open Source) and supporting integration. This individual performs in a multidisciplinary team environment with tight deadlines. The successful candidate is highly motivated, eager to implement new technologies, and thrives leading a team of scientists and engineers.', 'Job Description', 'Required Skills', ' The Software Engineer has prior experience in designing/architecting enterprise scale systems incorporating a variety of components (COTS, Open Source) and supporting integration. This individual performs in a multidisciplinary team environment with tight deadlines. The successful candidate is highly motivated, eager to implement new technologies, and thrives leading a team of scientists and engineers. The Senior Software Engineer has prior experience in designing/architecting enterprise scale systems incorporating a variety of components (COTS, Open Source) and supporting integration. This individual performs in a multidisciplinary team environment with tight deadlines. The successful candidate is highly motivated, eager to implement new technologies, and thrives leading a team of scientists and engineers. ', 'Desired Skills', 'Active Secret clearance', 'Fairfax, VA', ' US Citizen BA/BS degree in Computer Science/Engineering or Computer/Electrical/Mechanical Engineering Active Secret clearance 3-5 years of experience designing, deploying, and supporting enterprise level systems Experience working with C++, Python, orchestration frameworks (Kubernetes), cloud technologies (AWS, Azure, GCP) Experience utilizing containerization technologies (e.g. Docker) Demonstrated cross-functional team collaboration skills in a rapidly changing, high intensity, mission-oriented work environment Experience developing Architecture and Data Flow Diagrams using graphing programs (e.g. Visio) A skilled, intelligent, articulate individual who possesses excellent technical writing and presentation skills Familiarity with Linux operating systems Ability to work in a fast-paced environment Ability to travel (10%) to mostly CONUS locations Ability to quickly grasp and implement new technologies A self-motivated, self-starter that enthusiastically embraces pushing imaginative solutions to hard operational problems ', 'Ability to work in a fast-paced environment', 'Deep learning algorithms, NLP, ML tools and packages', ' Active Top-Secret clearance ', 'The Senior Software Engineer has prior experience in designing/architecting enterprise scale systems incorporating a variety of components (COTS, Open Source) and supporting integration. This individual performs in a multidisciplinary team environment with tight deadlines. The successful candidate is highly motivated, eager to implement new technologies, and thrives leading a team of scientists and engineers.', ""  Master's degree in Computer Science or a related technical field   Active Top-Secret clearance  Experience utilizing big data and cloud tools and technologies Ability to deploy to OCONUS and hardship locations for short periods (2 weeks) a plus Deep learning algorithms, NLP, ML tools and packages Experience working with Department of Defense organizations or performers. "", 'Experience developing Architecture and Data Flow Diagrams using graphing programs (e.g. Visio)', '3-5 years of experience designing, deploying, and supporting enterprise level systems', 'BA/BS degree in Computer Science/Engineering or Computer/Electrical/Mechanical Engineering', 'Familiarity with Linux operating systems', 'Ability to deploy to OCONUS and hardship locations for short periods (2 weeks) a plus', 'Active Top-Secret clearance', 'Experience working with Department of Defense organizations or performers.', 'Demonstrated cross-functional team collaboration skills in a rapidly changing, high intensity, mission-oriented work environment', 'Experience working with C++, Python, orchestration frameworks (Kubernetes), cloud technologies (AWS, Azure, GCP)', "" Master's degree in Computer Science or a related technical field "", 'A skilled, intelligent, articulate individual who possesses excellent technical writing and presentation skills', 'Ability to quickly grasp and implement new technologies', ""Master's degree in Computer Science or a related technical field""]",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Capital Group,"Seattle, WA",21 hours ago,Be among the first 25 applicants,"['', 'You have a background in data and software engineering and a passion to learn. ', 'You believe that a team is strongest when it is diverse and includes multiple perspectives.', 'Interest and curiosity in emerging technologies on the web like GraphQL, web assembly, Lambda functions, MLaaS etc', 'Travel required', 'Relocation benefits offered', 'Other location(s)', ""You've made mistakes in the past and have learned a lot from them. You apply this learning regularly."", 'BS in Computer Science or related field, or an equivalent in relevant work experience.', ""You are able to put yourself into your customer's shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them."", ' Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like AWS. Design, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems. Design data schema and operate cloud-based data warehouses and SQL/NoSQL/temporal database systems. Write Extract-Transform-Load (ETL) jobs and Spark/Hadoop jobs. Own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions. Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions. Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area. ', '“I can apply in less than 4 minutes.”', 'Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.', 'Your Background And Who You Are', '“I can lead a full life.”', 'What You’ll Be Doing', ' BS in Computer Science or related field, or an equivalent in relevant work experience. Experience implementing big data processing technology Hadoop, Apache Spark, etc. 3+ years of Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.). Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets. 3+ years experience in cloud-first design, preferably AWS (VPC, Serverless databases and functions, dynamic autoscaling, container orchestration, etc.). Experience in data architecture, databases (e.g., MySQL, Oracle, PostgreSQL), SQL and DDD/ER/ORM design. Interest and curiosity in emerging technologies on the web like GraphQL, web assembly, Lambda functions, MLaaS etc Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. ', 'Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions.', 'Req ID', 'Own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.', 'Receive 2-for-1 matching gifts for your charitable contributions and the opportunity to secure annual grants for the organizations you love', 'Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area.', 'Access on-demand professional development resources that allow you to hone existing skills and learn new ones', '3+ years of Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.).', 'You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you.', '“I Can Learn More About Capital Group.”', 'Enjoy generous time-away and health benefits from day one, with the opportunity for flexible work options', 'Location', 'Write Extract-Transform-Load (ETL) jobs and Spark/Hadoop jobs.', "" You have a background in data and software engineering and a passion to learn.  You've made mistakes in the past and have learned a lot from them. You apply this learning regularly. You believe there are generally multiple ways to solve a technical problem, each with different trade-offs. You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you. You believe that a team is strongest when it is diverse and includes multiple perspectives. You are able to put yourself into your customer's shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them. "", 'Design, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems.', 'Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like AWS.', 'You believe there are generally multiple ways to solve a technical problem, each with different trade-offs.', '3+ years experience in cloud-first design, preferably AWS (VPC, Serverless databases and functions, dynamic autoscaling, container orchestration, etc.).', 'Experience in data architecture, databases (e.g., MySQL, Oracle, PostgreSQL), SQL and DDD/ER/ORM design.', ' Enjoy generous time-away and health benefits from day one, with the opportunity for flexible work options Receive 2-for-1 matching gifts for your charitable contributions and the opportunity to secure annual grants for the organizations you love Access on-demand professional development resources that allow you to hone existing skills and learn new ones ', 'Qualifications', 'Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets.', 'COVID-19 HIRING Our recruiting and onboarding activities are virtual during the pandemic and we’ve transitioned to a work-from-home environment until further notice. We are offering generous work-from-home benefits to improve our associate’s ability to work remotely.', '“I can be myself at work.”', '“I can influence my income.”', 'Experience implementing big data processing technology Hadoop, Apache Spark, etc.', 'Design data schema and operate cloud-based data warehouses and SQL/NoSQL/temporal database systems.']",Not Applicable,Full-time,Information Technology,Financial Services,2020-10-20 12:01:24
Data Engineer,Schulte Hospitality Group,"Louisville, KY",19 hours ago,Be among the first 25 applicants,"['', 'Position is based in Louisville, Kentucky, at the Schulte Companies Headquarters', 'Minimum Qualifications', 'Responsibilities', 'Qualifications']",Associate,Full-time,Information Technology,Hospitality,2020-10-20 12:01:24
Junior Software Engineer,El Camino Health,"Boise, ID",23 hours ago,170 applicants,"['The ideal candidate would be a self-starter and results oriented engineer, We’re looking for someone who asks the right questions, challenges the status quo, and makes us better. The Engineer is attentive to the needs of the quality feedback loop, from report to resolution; ability to take ideas and requirements from concept to completion and engage those who are crucial to the project’s success. We empower our team members to make smart decisions and to get creative when solving difficult and ambiguous problems. This means we value both independent work as well as collaboration. Job Responsibility:Perform software development activities including planning, estimating and coding, Demonstrate the ability to mentor others in best practices. Improve our data systems’ performance and reliability against steadily increasing loads and varieties of work, Help construct and optimize systems to aggregate, transform and process large amounts of data, Comply with project plans and industry standards Required Qualifications and Skills:Demonstrate 1+ years’ experience in full-stack web development, Bachelor’s degree in Computer Science/Engineering, Entrepreneurial in thinking, outlook, and creative problem-solving, Strong verbal and written communication skills, Familiarity with Microsoft Technologies, Strong analytical and problem-solving skill, Strong creative and design skills, Demonstrates tenacity and willingness to get projects doneEducation:Bachelor degree or Technical Training in Computer Science, Cybersecurity, Network Design or related field preferred.', 'Job Responsibility:', 'Required Qualifications and Skills:', 'Education:']",Entry level,Full-time,Engineering,Hospital & Health Care,2020-10-20 12:01:24
Senior Software Engineer,Hamilton Porter,"McLean, VA",,N/A,"['', 'Looking for an ambitious Senior Software Engineer interested in supporting a Series A startup offering a Mobile/SaaS heavy data analytics-based product offering. The company has a highly strategic business model that is looking to unlock some legal and driver side issues currently plaguing reputable industry market leaders such as Uber and Lyft. You would be an asset to a company looking to enhance an already proven product offering, but with a better business model designed to bypass the legal ramifications that are currently getting the Uber’s and Lyft’s vetoed from many regions while also empowering the drivers and users with more rights.', 'Strong technical leadership experience, having managed or lead a small team of developers or interns.', 'Bonus points for any prior experience with Event Driven Programming or Architectures and messaging systems (Kafka, RabbitMQ)', 'Joined a talented and senior team of Engineering Professionals', 'Competitive Base Salary ($120,000 - $170,000 DOE)Early Stage Equity! (Series-A)Comprehensive Benefits Package (Medical, Dental, Vision)Opportunity to join a culture that empowers interesting challenges, fast growth, and collaboration amongst fellow talented Engineers - you will accomplish great thingsExpect to work with a great deal of autonomy, having the chance to own and run with projects as your expertise sees fitJoined a talented and senior team of Engineering Professionals', 'Familiar with database technology such as MySQL, Cassandra, or MongoDB', 'McLean, VA', ""Hamilton Porter is a boutique technical recruiting firm that partners with a variety of companies ranging from up and coming startups to reputable Fortune 500's. We are actively partnered with a growth mode technology start-up, located in a beautiful large office space in McLean, VA."", 'Seeking a Backend focused Senior Software Engineer ideally someone interested in supporting a modern technical environment in serverless architecture, supporting event-driven programming in either C# or Python. Targeting a hands-on, problem-solving engineer, great for lead or senior developers that feel their current project has grown a bit stagnant and are motivated to solve interesting new problems. Prepare to\xa0be impactful and influential right away as we host\xa0a startup culture in which opinions are wanted and valued and we want every engineer to join with substantial early stage equity and untapped product potential.', '4-10+ years of Software Engineering experience ideally having supported a SaaS, PaaS, or FaaS, or heavy Data Analytics styled platform or Mobile product offering.Computer Science degree or equivalent from a reputable UniversityExpertise with Python OR C# (preferred) or other commonly used OOP languages such as NodeJS/JavaExperience with designing and developing backend REST APIs to be consumed by frontend applicationsComfortable with Cloud environments such as AWS, GCP, AzureFamiliar with database technology such as MySQL, Cassandra, or MongoDBStrong technical leadership experience, having managed or lead a small team of developers or interns.Bonus points for any prior experience with Event Driven Programming or Architectures and messaging systems (Kafka, RabbitMQ)Bonus points for experience working with geo-location services (Google Maps, Openstreet Maps) as well as familiarity working with spatial data types.', 'Backend focused Senior Software Engineer', 'Computer Science degree or equivalent from a reputable University', 'Experience with designing and developing backend REST APIs to be consumed by frontend applications', '4-10+ years of Software Engineering experience ideally having supported a SaaS, PaaS, or FaaS, or heavy Data Analytics styled platform or Mobile product offering.', 'Senior Software Engineer', 'Series A startup', 'Comprehensive Benefits Package (Medical, Dental, Vision)', 'This role could be either 100% Remote or onsite in McLean, VA.', 'Bonus points for experience working with geo-location services (Google Maps, Openstreet Maps) as well as familiarity working with spatial data types.', 'Expect to work with a great deal of autonomy, having the chance to own and run with projects as your expertise sees fit', 'Expertise with Python OR C# (preferred) or other commonly used OOP languages such as NodeJS/Java', 'Comfortable with Cloud environments such as AWS, GCP, Azure', 'Qualifications:', 'Early Stage Equity! (Series-A)', 'We Offer:', 'Opportunity to join a culture that empowers interesting challenges, fast growth, and collaboration amongst fellow talented Engineers - you will accomplish great things', 'Apply today we move quickly!', 'Competitive Base Salary ($120,000 - $170,000 DOE)', 'Hamilton Porter']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-10-20 12:01:24
"Software Engineer, Distributed Systems",Tesla,"Palo Alto, CA",18 hours ago,105 applicants,"['', 'Back-up childcare and employee discounts', ' Provide technical leadership and foster collaboration.', ' Test the performance, scalability, and reliability of software systems at scale, including developing the services to support this testing.', 'As a full time Tesla employee you will receive full benefits from day 1 for you and your dependents. Kaiser and UnitedHealthcare PPO and HSA plans (including infertility coverage)3 medical plan choices with $0 paycheck contribution Vision & dental plans (including orthodontic coverage)Company paid Life, AD&D, short-term and long-term disability 401(k), Employee Stock Purchase Plans, and other financial benefits Employee Assistance Program, Paid Time Off, and Paid HolidaysBack-up childcare and employee discounts', 'Company paid Life, AD&D, short-term and long-term disability ', ' Maintain the high quality standards of the team.', 'Responsibilities', 'Role', 'As a full time Tesla employee you will receive full benefits from day 1 for you and your dependents. ', 'Vision & dental plans (including orthodontic coverage)', ' Characterize complex problems related to the scalability, reliability, performance, and security of production systems.', '3 medical plan choices with $0 paycheck contribution ', 'Employee Assistance Program, Paid Time Off, and Paid Holidays', ' Design, develop, and maintain distributed software systems that incorporate real-time and streaming data for monitoring, aggregation, and control.', 'Kaiser and UnitedHealthcare PPO and HSA plans (including infertility coverage)', '401(k), Employee Stock Purchase Plans, and other financial benefits ']",Entry level,Full-time,Engineering,Automotive,2020-10-20 12:01:24
Data Engineer,MantraMinds Inc,"Detroit, MI",22 hours ago,28 applicants,[''],Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Rekruiters,"Houston, TX",21 hours ago,Over 200 applicants,"['', 'We offer benefits such as weekly pay, health insurance, 401k and even profit sharing to our consultants.', '- Has worked directly with business teams to understand needs and engineer solutions.', '@rekruiters.com – Twitter', '- Has worked on streaming architectures and moving large amounts of data.', 'Location: Houston, Area', '_________________________________________________________________', 'https://www.rekruiters.com – Main Site', '________________________________________________________', 'Corporate:', 'Requirements:', '4yrs+ experience with Python using the data processing packages like Pandas, NumPy', 'Specific needs for project:', '- 4yrs+ experienced with databases, both relational and non-relational', 'https://www.facebook.com/rekruiters/ – Facebook', 'For more information on this job visit: https://rekruiters.com/jobs/', '- 2yrs+ experience with containerization (Docker or Kubernetes) -', '- 3yrs+ experience with APIs and has a good understanding of them.', 'Rekruiters has been named by business journals as one of the best places to work.', 'MUST HAVE EXPERIENCE WITH SQL AND PYTHON']",Mid-Senior level,Contract,Information Technology,Oil & Energy,2020-10-20 12:01:24
Data Engineer,Edelman,"Atlanta, GA",1 hour ago,Be among the first 25 applicants,"['', 'Experience with Business Intelligence tools such as Tableau, PowerBI and/or Looker. ', 'Experience designing, building, and maintaining data processing systems', 'Expert in cloud-based platforms, such as AWS and GCP Knowledge of best practices and IT operations Excellent problem solving and troubleshooting skills Process oriented with great documentation skills BS or MS degree in Computer Science or a related technical field 4+ years of Python development experience 4+ years of SQL experience (No-SQL experience is a plus) 4+ years of experience with schema design and dimensional data modeling Ability in managing and communicating data warehouse plans to internal clients Experience with data warehouse services such as Redshift, Snowflake and/or Hive. Experience with Business Intelligence tools such as Tableau, PowerBI and/or Looker. Experience with collaborative data analytics services such as databricks. Experience designing, building, and maintaining data processing systems', 'Designs data integrations and data quality framework. ', 'Ability in managing and communicating data warehouse plans to internal clients ', 'Excellent problem solving and troubleshooting skills ', 'Experience with collaborative data analytics services such as databricks. ', 'BS or MS degree in Computer Science or a related technical field ', 'Process oriented with great documentation skills ', '4+ years of experience with schema design and dimensional data modeling ', 'Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity. ', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it. ', '4+ years of Python development experience ', 'Responsibilities', 'Works closely with a team of product managers, and analysts. ', 'Expert in cloud-based platforms, such as AWS and GCP ', '4+ years of SQL experience (No-SQL experience is a plus) ', 'Qualifications', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. ', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture. ', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization. ', 'Designs and evaluates open source and vendor tools for data lineage. ', 'Knowledge of best practices and IT operations ', 'Writes unit/integration tests and documents work. ', 'Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity. Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization. Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it. Writes unit/integration tests and documents work. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Works closely with a team of product managers, and analysts. Designs data integrations and data quality framework. Designs and evaluates open source and vendor tools for data lineage. Works closely with all business units and engineering teams to develop strategy for long term data platform architecture. ', 'Experience with data warehouse services such as Redshift, Snowflake and/or Hive. ']",Entry level,Full-time,Research,Public Relations and Communications,2020-10-20 12:01:24
Jr. Software Engineer,Innovative Defense Technologies (IDT),"Arlington, VA",51 minutes ago,Be among the first 25 applicants,"['', 'Ability to develop software tests for software written in Java, JS, C++, or PythonAbility to document requirements and defectsExperience with software testing and configuration managementFamiliarity with distributed systems, DevOps, and software design patternsUnderstand the Software Development Life Cycle (SDLC)Familiarity with software CM/QA process to maintain and track SW changesExperience with various software configuration management standardsSoftware team development experienceProficient working with version control software like SVN, Git, and complex software development environmentsProficient working with different SW development tools (Jenkins, Maven, Gradle, and Nexus, etc.)Ability to travel approximately 15%', 'Proficient working with different SW development tools (Jenkins, Maven, Gradle, and Nexus, etc.)', 'Ability to travel approximately 15%', 'Ability to perform many concurrent assignments and determine the need for changing prioritiesSolid analytical abilities, coupled with a strong sense of ownership, urgency and drive\xa0Problem-solving skills with the ability to navigate ambiguous situationsExcellence in oral, written, and technical communication with peers and non-technical cohortsInitiative, creativity, reliability, teamworkStrong organization and planning skills, including attention to detail', 'Familiar with methodology to perform SW CM and QA', 'Ensure that system development projects and changes to existing systems are conducted in compliance with the CM process', 'EEO Statement:', 'Solid analytical abilities, coupled with a strong sense of ownership, urgency and drive\xa0', 'Ability to document requirements and defects', 'Experience working with software system and applications', 'Ability to develop software tests for software written in Java, JS, C++, or Python', 'Support development of the validation strategy and effort, from planning through retirement, of Quality-relevant systems and tools, including interfaces to and from the systemProvide software quality assurance support in design and development of software solutions and facilitate the application of controls and risk management by reviewing and approving IT change-control requests submitted by cross-functional project teams to assess potential quality system impactProvide software quality assurance support when evaluating Off the Shelf Software validation to determine the validation strategy required to properly implement the software in the most effective and timely manner possible within the organizationEnsure that system development projects and changes to existing systems are conducted in compliance with the CM processWork alongside other validation professionals to gather data, plan activities, and obtain reviews and approvals of documentation including approving documentation with respect to software development life cycle policies and proceduresAssist in developing user, functional, and technical requirements for IT systemsTrack system life cycle deliverables and activities to ensure that regulations, protocols, procedures, and methodologies are followed, and that appropriate and complete documentation is captured and reported to support validation activitiesRepresent Quality & Regulatory Compliance and Control on cross-functional teams in support of SDLM activities', 'Innovative Defense Technologies\xa0(IDT), provider of automated software testing, data analysis, and cybersecurity solutions for complex, mission-critical systems in the US Department of Defense (DOD), is seeking a Junior Software Engineer to be based in our Arlington, VA office. S/he will work with senior leadership and a fast-paced team of mission-focused engineers to implement and maintain a robust automated software testing pipeline. Initiative, creativity, reliability, and efficient teamwork will be required to successfully deliver innovative solutions in this role.', 'Software team development experience', 'System integration and test experience for software applicationsExperience programming in one or more of Java, C++, JS, PythonExperience working with software system and applicationsExperience in testing software and test automationFamiliar with methodology to perform SW CM and QA', 'Overview:', 'Experience with various software configuration management standards', 'All applicants must currently possess an active U.S. Security Clearance', 'IDT is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, protected Veteran status, or any other basis protected by federal, state, or local law.\xa0\xa0', 'Excellence in oral, written, and technical communication with peers and non-technical cohorts', 'Initiative, creativity, reliability, teamwork', 'Minimum Required Qualifications:', 'Proficient working with version control software like SVN, Git, and complex software development environments', 'Experience programming in one or more of Java, C++, JS, Python', 'Track system life cycle deliverables and activities to ensure that regulations, protocols, procedures, and methodologies are followed, and that appropriate and complete documentation is captured and reported to support validation activities', 'Experience with software testing and configuration management', 'Familiarity with software CM/QA process to maintain and track SW changes', 'Understand the Software Development Life Cycle (SDLC)', 'Required Skills:', 'Provide software quality assurance support in design and development of software solutions and facilitate the application of controls and risk management by reviewing and approving IT change-control requests submitted by cross-functional project teams to assess potential quality system impact', 'Problem-solving skills with the ability to navigate ambiguous situations', 'At least 2 years’ experience in engineering', 'System integration and test experience for software applications', 'Preferred Skills:', 'Ability to perform many concurrent assignments and determine the need for changing priorities', 'Experience in testing software and test automation', 'Assist in developing user, functional, and technical requirements for IT systems', 'Strong organization and planning skills, including attention to detail', 'Represent Quality & Regulatory Compliance and Control on cross-functional teams in support of SDLM activities', 'Work alongside other validation professionals to gather data, plan activities, and obtain reviews and approvals of documentation including approving documentation with respect to software development life cycle policies and procedures', 'Support development of the validation strategy and effort, from planning through retirement, of Quality-relevant systems and tools, including interfaces to and from the system', 'Familiarity with distributed systems, DevOps, and software design patterns', 'We are looking to add an experienced Software Engineer who can ensure regulated automated tools used in the Quality System are appropriately validated and controlled through their life cycle through development, deployment, and change control. This includes ensuring project teams adhere to processes and control mechanisms for software, hardware, and data to meet regulatory requirements.', 'All applicants must currently possess an active U.S. Security Clearance.', 'Responsibilities:', 'At least 2 years’ experience in engineeringB.S. in software engineering, computer science, or related field', 'Competencies:', 'B.S. in software engineering, computer science, or related field', 'Background Information:', 'Provide software quality assurance support when evaluating Off the Shelf Software validation to determine the validation strategy required to properly implement the software in the most effective and timely manner possible within the organization']",Associate,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Warehouse Engineer,Knock,"Seattle, WA",23 hours ago,33 applicants,"['', 'Stock options', 'Independently analyze, solve, and correct issues, providing system monitoring and problem resolution', 'We like to do fun things together! (Virtual for now!) Conferences, off site retreats, and happy hours.', 'Five years later, we have helped our property management customers find apartments for millions of renters. We’ve developed an industry-defining SaaS platform, an intelligent front office platform providing the productivity and business intelligence tools needed to maximize occupancy, rent growth, and customer satisfaction at every community. Our customers trust us to deliver the consumer experiences and business applications that are essential to their bottom line. The proof is in our 10x revenue growth over the past two years, in addition to our numerous industry awards.', 'Build, monitor and maintain data and ETL pipelines to process data from many disparate sources into a data warehouse\xa0Design data schemas and structures for reporting through Tableau and other toolsValidate data accuracy and timeliness throughout processIndependently analyze, solve, and correct issues, providing system monitoring and problem resolutionWork with various APIs [Google Analytics, SaaSOptics, Salesforce] to extract data into a relational schemaWork with technical and business teams to evaluate data requirements and implement themEvaluate new technologies and tools and make recommendations based on usefulness, opportunity and cost', '3+ years experience with Python and SQL', 'Gym membership at LA Fitness Signature Clubs (Currently on hold due to COVID-19)', 'We are looking for a talented Data Warehouse Engineer to help build out our analytics platform. You will work closely with the product team and engineering teams to deliver timely and accurate data to our customers.', 'Working knowledge of message queuing, stream processing', 'In January 2020 we were honored to receive recognition as one of Seattle’s Best Small Companies to Work by BuiltIn Seattle:\xa0https://www.builtinseattle.com/companies/best-small-places-to-work-seattle-2020', 'Parental leave program', 'Evaluate new technologies and tools and make recommendations based on usefulness, opportunity and cost', 'Day - to - Day', 'To be successful and recognized as a high performer at Knock, you should naturally encompass our core values: Determination, Excellence, Trust and Community. We take these behaviors seriously and expect everyone to bring a positive Knockstar attitude with them to work every day.', '100% medical, dental, and vision coverage for full-time employees.Flexible time off & paid holiday401k to help you save for the futureOption to work from home 2x a week (normally!)Stock optionsGym membership at LA Fitness Signature Clubs (Currently on hold due to COVID-19)We like to do fun things together! (Virtual for now!) Conferences, off site retreats, and happy hours.Parental leave programWhatever mode of transportation you use - we got you covered!Employee referral bonuses to encourage the addition of great new people to the Knock teamPlus free lunch on Fridays! (When back in the office!)', 'At Knock we don’t discriminate on the basis of race, religion, color, nationality, gender, sexual orientation, age, marital status, veteran status, or disability status. We welcome all types!', 'In May 2020 we announced we raised a $12m Series B round to continue on the path of growth, led by Madrona Venture Group, with partners from Lead Edge Capital and Seven Peaks Ventures:https://www.geekwire.com/2020/product-built-times-like-seattle-startup-knock-raises-12m/', 'Work with technical and business teams to evaluate data requirements and implement them', 'Validate data accuracy and timeliness throughout process', 'We started Knock to solve problems we faced ourselves. One of those problems was that the process for renting an apartment hadn’t evolved at the same pace as technology. It was disorganized, time consuming, and frustrating. It seemed landlords were stuck in the past and didn’t understand how to use technology to their advantage. But the problems and solutions seemed obvious to us, and we had a vision for what a better experience should be. After validating our insights with a few early customers (who became investors) we got to work partnering with real estate companies to deliver on turning that vision into reality.', 'At Knock, we have a #oneteam philosophy. A big part of bringing new capabilities to life is to continue to bring in exceptional talent that works together toward a common goal. We’ve been incredibly fortunate to build an amazing team that delivers real value to our customers each and every day. We can’t wait to hear from you!', '100% medical, dental, and vision coverage for full-time employees.', 'Option to work from home 2x a week (normally!)', 'Experience designing and implementing data pipeline testing and monitoring solutions', 'Employee referral bonuses to encourage the addition of great new people to the Knock team', 'Design data schemas and structures for reporting through Tableau and other tools', 'Experience using AWS, Redshift, PostgreSQL or Elasticsearch a plus', 'In March of 2019 we announced we raised a $10m Series A round to continue to accelerate growth and product development, led by Madrona Venture Group:\xa0https://www.geekwire.com/2019/madrona-leads-10m-round-knock-crm-communications-service-apartment-landlords/\xa0', 'Plus free lunch on Fridays! (When back in the office!)', 'The Role', 'Our Values', 'Flexible time off & paid holiday', 'The Company', ""Why You'll Love It Here"", 'The Engineering and Product teams consist of 40 talented and passionate team members, working to make Knock the premier software product in the Multifamily real estate industry.\xa0', 'Whatever mode of transportation you use - we got you covered!', 'The Team', 'Work with various APIs [Google Analytics, SaaSOptics, Salesforce] to extract data into a relational schema', 'Build, monitor and maintain data and ETL pipelines to process data from many disparate sources into a data warehouse\xa0', '401k to help you save for the future', 'Advanced SQL knowledge and experience working with relational databases', '3+ years experience with Python and SQLAdvanced SQL knowledge and experience working with relational databasesExperience designing and implementing data pipeline testing and monitoring solutionsWorking knowledge of message queuing, stream processingExperience using AWS, Redshift, PostgreSQL or Elasticsearch a plus', 'Basic Qualifications']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-10-20 12:01:24
Data Engineer,Maven,"Columbus, Ohio Metropolitan Area",19 hours ago,36 applicants,"['', 'Design and develop data structures', 'Experience working with ETL, SQL, Python, Big Data and Hadoop', 'Strong communicator and someone who is adaptable', '5+ years of experience as a Data Engineer or Software Engineer', 'The successful candidate:', '5+ years of experience as a Data Engineer or Software EngineerStrong communicator and someone who is adaptable', 'Key responsibilities:', 'Experience working in an Agile environment, providing code reviews and issue tracking', 'We have an opening for a Data Engineer role here in Columbus, OH. This role will start out being remote, however the client would like to have a candidate who is open to returning to the office.', 'Design and develop data structuresExperience working with ETL, SQL, Python, Big Data and HadoopExperience working in an Agile environment, providing code reviews and issue tracking']",Associate,Full-time,Information Technology,Information Services,2020-10-20 12:01:24
"Software Engineer, i18n Infrastructure",Airbnb,"San Francisco, CA",9 hours ago,Be among the first 25 applicants,"['', ' Building a scalable infrastructure to manage and deliver localized content on all Airbnb product surfaces Building the next generation of machine-driven translation workflows for dynamic user-generated content Helping Airbnb engineers to seamlessly integrate internationalization capabilities in their code ', 'Benefits', 'Want to tackle projects with large open-ended scope and drive significant business impact', 'Build intuitive workflows and tools to serve the needs of Airbnb engineers as well as Airbnb’s Localization Program Managers', 'Work cross-functionally with partners in Globalization, Data Science, product teams and external vendors', 'Flexible Spending Accounts', 'Experience with modern JavaScript libraries and tooling (e.g. React)', 'Exposure to architectural patterns of a high-scale web applications, such as well-designed APIs, data pipelines and efficient algorithms', 'Who We Are Looking For', 'Are motivated to improve their teammates’ productivity', 'Bachelor’s and/or Master’s degree, preferably in CS, or equivalent experience', 'Company sponsored tech talks and happy hours', ' Want to tackle projects with large open-ended scope and drive significant business impact Love collaborating via product reviews, code reviews and architecture discussions Are motivated to improve their teammates’ productivity Will be owners and stewards of Airbnb’s multilingual capabilities ', 'Paid time off', ' Build scalable systems supporting high qps realtime translation requests and efficient retrieval of translated content Build intuitive workflows and tools to serve the needs of Airbnb engineers as well as Airbnb’s Localization Program Managers Drive down costs and land performance wins via impactful optimizations and infrastructure upgrades Work cross-functionally with partners in Globalization, Data Science, product teams and external vendors Be part of an impactful infrastructure team while contributing to and learning industry best practices on internationalization ', 'Building a scalable infrastructure to manage and deliver localized content on all Airbnb product surfaces', 'Drive down costs and land performance wins via impactful optimizations and infrastructure upgrades', 'Build scalable systems supporting high qps realtime translation requests and efficient retrieval of translated content', 'Love collaborating via product reviews, code reviews and architecture discussions', 'Stock', 'Some of the focus areas for the i18n team are:', 'What will an engineer on i18n Infra do?', 'Community Involvement (4 hours per month to give back to the community)', 'Commuter Subsidies', 'Much more…', 'Quarterly employee travel coupon', ' 3+ years industry experience Bachelor’s and/or Master’s degree, preferably in CS, or equivalent experience Proficiency in one or more back-end server languages (Java/Ruby/Go/C++/etc.) Fluency in HTML, CSS, JavaScript and related web technologies Experience with modern JavaScript libraries and tooling (e.g. React) Exposure to architectural patterns of a high-scale web applications, such as well-designed APIs, data pipelines and efficient algorithms Experience or desire to work collaboratively in cross-functional teams with design, product and data science partners ', 'We’re Looking For Engineers Who', 'Building the next generation of machine-driven translation workflows for dynamic user-generated content', 'Helping Airbnb engineers to seamlessly integrate internationalization capabilities in their code', 'Will be owners and stewards of Airbnb’s multilingual capabilities', 'Apple equipment', 'Fluency in HTML, CSS, JavaScript and related web technologies', '401K', 'Life insurance and disability benefits', ' Stock Competitive salaries Quarterly employee travel coupon Paid time off Medical, dental, & vision insurance Life insurance and disability benefits Fitness Discounts 401K Flexible Spending Accounts Apple equipment Commuter Subsidies Community Involvement (4 hours per month to give back to the community) Company sponsored tech talks and happy hours Much more…', 'Fitness Discounts', 'Be part of an impactful infrastructure team while contributing to and learning industry best practices on internationalization', 'Medical, dental, & vision insurance', 'Internationalization (i18n)', 'Proficiency in one or more back-end server languages (Java/Ruby/Go/C++/etc.)', 'Competitive salaries', 'In This Role, You Will Have An Opportunity To', '3+ years industry experience', 'Experience or desire to work collaboratively in cross-functional teams with design, product and data science partners']",Not Applicable,Full-time,Research,Hospitality,2020-10-20 12:01:24
"Data Engineer, People Operations",Carvana,"Phoenix, AZ",18 hours ago,Be among the first 25 applicants,"['', 'Learn new languages that can be used to create more extensible ETL solutions, such as Python.', 'Get familiar with newer cloud and data platform technologies like S3, Spark, and Redshift to create robust data pipelines to and from our on-premise data stores.', ' Interact with GUI components to easily customize loan length, down payment, and monthly payment. Generate, upload, and eSign all documents online (no ink necessary). Schedule front door delivery or pick up at one of our vending machines. Trade-in their existing vehicle or just sell it to Carvana (no purchase necessary). ', 'Help architect, design, and prototype solutions to support business strategies and deliver business value.', 'Must be able to read, write, speak and understand English.', '401K with company match.', 'Search and browse our inventory of over 20,000 vehicles that we own and certify.', 'Generate, upload, and eSign all documents online (no ink necessary).', 'What You Should Have', 'A multitude of perks including student loan payments, discounts on vehicles, benefits for your pets, and much more.', 'A great wellness program to keep you healthy and happy both physically and mentally.', 'What We’ll Offer In Return', ' Grow your toolset by working with tools like SSDT and Tableau across multiple versions of SQL Server including 2016, 2017, and Azure SQL Database. Get familiar with newer cloud and data platform technologies like S3, Spark, and Redshift to create robust data pipelines to and from our on-premise data stores. Become familiar with the multitude of ways data flows through our systems in order to contribute creative and scalable problem-solving solutions, as well as to ensure the data integrity among various data stores and ETLs. Learn new languages that can be used to create more extensible ETL solutions, such as Python. Utilize dev, test, and production environments, adhering to change management requirements for system implementations. Participate in team lunch and learns, design sessions, and code reviews. Work with People Operations team members to understand and deliver data so that non-technical resources can understand/respond as needed. Take part in cross-functional project teams with data scientists, analysts, executives, and talent leaders. Work with leaders and users to define business intelligence needs and translate them into functional requirements to the technical team. Work with end-users and other IT teams to resolve operational issues and mitigate risks as applicable. Help architect, design, and prototype solutions to support business strategies and deliver business value. Influence across the People Operations team on how data should be collected, communicated, and visualized. You’ll have the chance to drive decisions that touch every single employee and team in the company. Other duties as assigned. ', 'Experience working with various relational database models as well as the concepts of normalization and referential integrity.', 'Excitement toward working on performance tuning and process streamlining (woo!).', 'Trade-in their existing vehicle or just sell it to Carvana (no purchase necessary).', 'Work with People Operations team members to understand and deliver data so that non-technical resources can understand/respond as needed.', 'An undergraduate degree in Management Information Systems, Computer Science, etc. or equivalent experience in the field.', 'Full-Time Salary Position with a competitive salary.', 'A company culture of promotions from within, with a start-up atmosphere allowing for varied and rapid career development.', 'The ability to work cross-functionally with engineering, data science, and business teams and communicate across them in a clear and concise manner understood by all. ', 'What You’ll Be Doing', 'Access to opportunities to expand your skill set and share your knowledge with others across the organization.', 'Other duties as assigned.', 'Become familiar with the multitude of ways data flows through our systems in order to contribute creative and scalable problem-solving solutions, as well as to ensure the data integrity among various data stores and ETLs.', 'Work with end-users and other IT teams to resolve operational issues and mitigate risks as applicable.', 'Proven ability to know what a query plan is and how to view one, the purpose of primary, foreign, and unique keys, and understand the difference between DML and DDL.', ' Secure financing in minutes using Carvana’s in-house service or their own bank. ', 'Medical, Dental, and Vision benefits.', 'Participate in team lunch and learns, design sessions, and code reviews.', 'You have the flexibility to move and shake with competing and changing priorities. ', 'At least 5 years of experience working with database development in SQL Server.', ' An undergraduate degree in Management Information Systems, Computer Science, etc. or equivalent experience in the field. At least 5 years of experience working with database development in SQL Server. Experience working with various relational database models as well as the concepts of normalization and referential integrity. Proven ability to know what a query plan is and how to view one, the purpose of primary, foreign, and unique keys, and understand the difference between DML and DDL. Understanding of basic indexing concepts, like the difference between clustered/non-clustered. Excitement toward working on performance tuning and process streamlining (woo!). Track record of working in industry best practices and implementing processes accordingly. The ability to work cross-functionally with engineering, data science, and business teams and communicate across them in a clear and concise manner understood by all.  You have the flexibility to move and shake with competing and changing priorities.  ', 'Schedule front door delivery or pick up at one of our vending machines.', 'Utilize dev, test, and production environments, adhering to change management requirements for system implementations.', 'View vehicle details, Carfax reports, and 360 rotating studio images for every vehicle.', 'Work with leaders and users to define business intelligence needs and translate them into functional requirements to the technical team.', 'A seat in one of the fastest-growing companies in the country.', ' Must be able to read, write, speak and understand English. ', ' Full-Time Salary Position with a competitive salary. Medical, Dental, and Vision benefits. 401K with company match. A multitude of perks including student loan payments, discounts on vehicles, benefits for your pets, and much more. A great wellness program to keep you healthy and happy both physically and mentally. Access to opportunities to expand your skill set and share your knowledge with others across the organization. A company culture of promotions from within, with a start-up atmosphere allowing for varied and rapid career development. A seat in one of the fastest-growing companies in the country. ', 'Understanding of basic indexing concepts, like the difference between clustered/non-clustered.', 'Take part in cross-functional project teams with data scientists, analysts, executives, and talent leaders.', 'Legal stuff', 'Secure financing in minutes using Carvana’s in-house service or their own bank.', 'Track record of working in industry best practices and implementing processes accordingly.', ' Search and browse our inventory of over 20,000 vehicles that we own and certify. Narrow down search results using highly intelligent filtering tools/components. View vehicle details, Carfax reports, and 360 rotating studio images for every vehicle. ', 'About Carvana', 'Narrow down search results using highly intelligent filtering tools/components.', 'About The Team And Position', 'Interact with GUI components to easily customize loan length, down payment, and monthly payment.', 'Other Requirements', 'Grow your toolset by working with tools like SSDT and Tableau across multiple versions of SQL Server including 2016, 2017, and Azure SQL Database.', 'Influence across the People Operations team on how data should be collected, communicated, and visualized. You’ll have the chance to drive decisions that touch every single employee and team in the company.']",Entry level,Full-time,Information Technology,Construction,2020-10-20 12:01:24
Software Engineer,Quantitative Systems,"Arlington, VA",19 hours ago,82 applicants,"['', 'Requires US citizenship (clearance eligible), prefers active TS/SCI clearanceBS or MS degree, or equivalent experience in a quantitative field (physics, mathematics, bioinformatics, computer science, operations research, etc.)3+ years of experience as a software developer on enterprise-scale software projects3+ years of experience of commercial or other production-level software projectsSome experience with one or more of the following: data science, machine learning, computer vision, geospatial workflows, image processing, security/IA assessmentDedication to continuous integration and automated testingHands-on, production experience with cloud-based systems using AWS or AzureExperience with Docker and Kubernetes strongly preferredExperience working within C2S or similar classified networksExcellent communication and mentoring skillsStrong background in agile, and ability to mentor others in its use a major plus', '\xa0', 'Provide software design and perform software implementation for enterprise-scale, mission-critical, production software in areas such as web services, databases, user interfaces, user management, API design, and more', 'Participate in customer meetings to present and discuss technical plans and milestones', 'Participate in, and possibly lead, small and tactical development teams using agile development principles, including release planning, sprint planning, product and sprint backlog grooming, and standups', 'Experience working within C2S or similar classified networks', '3+ years of experience of commercial or other production-level software projects', 'This position requires US citizenship (clearance eligible), prefers active TS/SCI clearance', 'Dedication to continuous integration and automated testing', '3+ years of experience as a software developer on enterprise-scale software projects', 'Experience with Docker and Kubernetes strongly preferred', 'Collaborate with others across the company, such as our machine learning or devops teams, and with other partner organizations', 'If all this sounds interesting to you, we’d love to meet you.', 'Participate in, and possibly lead, all technical aspects of a project, from customer needs assessments and technical requirements to software architecture and implementation to deployment and maintenanceParticipate in customer meetings to present and discuss technical plans and milestonesCollaborate with others across the company, such as our machine learning or devops teams, and with other partner organizationsProvide software design and perform software implementation for enterprise-scale, mission-critical, production software in areas such as web services, databases, user interfaces, user management, API design, and moreParticipate in, and possibly lead, small and tactical development teams using agile development principles, including release planning, sprint planning, product and sprint backlog grooming, and standups', 'BS or MS degree, or equivalent experience in a quantitative field (physics, mathematics, bioinformatics, computer science, operations research, etc.)', 'Excellent communication and mentoring skills', 'Qualifications:', 'Some experience with one or more of the following: data science, machine learning, computer vision, geospatial workflows, image processing, security/IA assessment', 'Participate in, and possibly lead, all technical aspects of a project, from customer needs assessments and technical requirements to software architecture and implementation to deployment and maintenance', 'Hands-on, production experience with cloud-based systems using AWS or Azure', 'This position will be based in our Arlington, Virginia office but may require some work at customer sites in the DC area. Occasional travel to corporate headquarters in Palo Alto, California may be required.', 'Requires US citizenship (clearance eligible), prefers active TS/SCI clearance', 'Strong background in agile, and ability to mentor others in its use a major plus', 'As a member of our technical staff, you’ll be working on our cloud-based systems that ingest a wide variety of data, run advanced machine learning algorithms on that data, use data science techniques to discover trends and detect anomalies, and allow users to ask questions and get answers – and do it all at scale with ever-increasing amounts of data.', 'Responsibilities:', 'We value experienced engineers who already have a breadth of experience in multiple areas -- databases, devops, machine learning, API design, and more -- and are eager to learn new areas and new technologies.']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
XCTest Software Engineer,Apple,"Cupertino, CA",7 hours ago,Be among the first 25 applicants,"['', 'Education & Experience', 'Description', 'Key Qualifications', 'Summary']",Not Applicable,Full-time,Engineering,Consumer Electronics,2020-10-20 12:01:24
Data Engineer,RealREPP,"Irvine, CA",19 hours ago,46 applicants,"['', 'Oversee various tools/resources such as Redshift and EMR', 'Ability to work well in fast-paced IT environment', "" Bachelor's Degree in Engineering, Computer Science, Statistics, or any other related field Masters in any related quantitative field preferred  3+ years' experience with SQL, database engineering, scripting Prior experience with the full cycle of projects from start to finish Working knowledge of coding requirements and standards Ability to communicate with others well Ability to work well in fast-paced IT environment Prior experience with big data, budgeting, asset management Leadership and interpersonal skills "", 'Requirements', 'Provide recommendations to improve efficiency of data', 'Job Responsibilities', 'Provide expertise and knowledge of SQL database design ', 'Analyze raw data and identify trends', "" Manage the design and implementation of Business Intelligence (BI) Oversee various tools/resources such as Redshift and EMR Work alongside fellow data scientists in constructing high quality data Implement and update the reporting processes  Ensure data accuracy and reliability  Develop/test architectures and ensure they align with company's business requirements Provide recommendations to improve efficiency of data Analyze raw data and identify trends Provide expertise and knowledge of SQL database design  "", 'Ensure data accuracy and reliability ', 'Manage the design and implementation of Business Intelligence (BI)', 'Work alongside fellow data scientists in constructing high quality data', 'Prior experience with big data, budgeting, asset management', 'Leadership and interpersonal skills', 'Ability to communicate with others well', ""3+ years' experience with SQL, database engineering, scripting"", ""Develop/test architectures and ensure they align with company's business requirements"", 'Masters in any related quantitative field preferred ', 'Working knowledge of coding requirements and standards', 'Prior experience with the full cycle of projects from start to finish', ""Bachelor's Degree in Engineering, Computer Science, Statistics, or any other related field"", 'Implement and update the reporting processes ']",Entry level,Full-time,Information Technology,Construction,2020-10-20 12:01:24
Data Engineer,RealREPP,"Irvine, CA",19 hours ago,46 applicants,[],Entry level,Full-time,Information Technology,Construction,2020-10-20 12:01:24
"Senior Data Engineer, Product Analytics",Netflix,"Los Gatos, CA",12 hours ago,Be among the first 25 applicants,"['', 'About The Role', 'You have a strong background in distributed data processing & software engineering and can build high-quality, scalable data products.4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc) for building efficient, large-scale data pipelines.You have strong knowledge of data architectures, databases, data modeling and data infrastructure ecosystem.Experience with Relational databases (such as MySQL, Postgres) and analytics databases (such as Druid, Apache Pinot). Strong Software Engineering experience and proficiency in at least one high-level programming language (Java, Scala, Python or equivalent).You are a creative & strategic thinker, a strong problem solver with meticulous attention to detail and can tackle loosely defined problems.You have an analytical mindset and have a passion for solving business problems using data.You have the ability to initiate and drive projects to completion with minimal guidance in a fast-paced dynamic environment.You have the ability to communicate in a clear and effective manner and the skills to engage broadly with cross-functional teams of diverse skills & mindsets to influence the overall strategy of the product.You understand the value of partnerships within teams and interact effectively with others.The Netflix culture resonates with you.MS or BS in Computer Science, Engineering, Mathematics, Statistics, Bioinformatics or a related field OR equivalent practical experience in Data Engineering.', 'Strong Software Engineering experience and proficiency in at least one high-level programming language (Java, Scala, Python or equivalent).', ""The Netflix culture is unique, and we live by our values, so it's worth learning more about it."", 'We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.', 'proficiency', 'You might also want to know', 'Bonus Points', 'Who We Are Looking For', 'You have an analytical mindset and have a passion for solving business problems using data.', ""The Netflix culture is unique, and we live by our values, so it's worth learning more about it.We support a healthy work-life balance, but we also seek individuals who are truly passionate about their work. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."", 'The Netflix culture resonates with you.', 'Experience building distributed, high-volume data services.', 'high-level programming language', 'You are a creative & strategic thinker, a strong problem solver with meticulous attention to detail and can tackle loosely defined problems.', 'You have strong knowledge of data architectures, databases, data modeling and data infrastructure ecosystem.', 'About The Company', 'stream-processing applications ', 'Experience with Cloud Computing platforms like Amazon AWS, Google Cloud.Experience with building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others.Experience with Search systems (such as ElasticSearch, Solr), NoSQL datastores (such as HBase, Cassandra, MongoDB).Experience building distributed, high-volume data services.', 'You have a strong background in distributed data processing & software engineering and can build high-quality, scalable data products.', 'Experience with Search systems (such as ElasticSearch, Solr), NoSQL datastores (such as HBase, Cassandra, MongoDB).', 'Experience with Cloud Computing platforms like Amazon AWS, Google Cloud.', '4+ years of industry experience working with distributed data technologies (e.g. Hadoop, MapReduce, Spark, etc) for building efficient, large-scale data pipelines.', 'efficient, large-scale data pipelines', 'You have the ability to communicate in a clear and effective manner and the skills to engage broadly with cross-functional teams of diverse skills & mindsets to influence the overall strategy of the product.', 'You understand the value of partnerships within teams and interact effectively with others.', 'MS or BS in Computer Science, Engineering, Mathematics, Statistics, Bioinformatics or a related field OR equivalent practical experience in Data Engineering.', 'distributed data technologies', 'We support a healthy work-life balance, but we also seek individuals who are truly passionate about their work. ', 'Experience with building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others.', 'You have the ability to initiate and drive projects to completion with minimal guidance in a fast-paced dynamic environment.', 'Experience with Relational databases (such as MySQL, Postgres) and analytics databases (such as Druid, Apache Pinot). ']",Not Applicable,Full-time,Information Technology,Entertainment,2020-10-20 12:01:24
Data Engineer,Horizontal Talent,"Madison, NJ",6 hours ago,Be among the first 25 applicants,"['', 'Experience/Knowledge in Cloud data warehouse solutions like Snowflake, Redshift , etc.', 'Migrate complex data processing from SQL Server to Snowflake using Spark, Python/Scala , AWS Glue, and Snowpipe.', '5+ years of of experience working in the BI/Data space', ' 5+ years of of experience working in the BI/Data space Good understanding and experience in the core AWS Cloud services. Strong Technical hands-on experience in programming languages - Python/Scala, Spark, Lambda, JavaScript Experience planning, designing, developing and documenting migration plans from on-premise to cloud. Migrate complex data processing from SQL Server to Snowflake using Spark, Python/Scala , AWS Glue, and Snowpipe. Experience in using GIT/AWS code repository. Experience/Knowledge in Cloud data warehouse solutions like Snowflake, Redshift , etc. Ability to develop ETL pipelines in and out of data warehouse using combination of AWS tools/Python(or Scala) and Snowflakes SnowSQL/JavaScript stored procedures ', 'Experience/Qualifications', 'Experience planning, designing, developing and documenting migration plans from on-premise to cloud.', 'Ability to develop ETL pipelines in and out of data warehouse using combination of AWS tools/Python(or Scala) and Snowflakes SnowSQL/JavaScript stored procedures', 'Experience in using GIT/AWS code repository.', 'Good understanding and experience in the core AWS Cloud services. Strong Technical hands-on experience in programming languages - Python/Scala, Spark, Lambda, JavaScript']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Scientist,Chewy,"Dania, FL",6 hours ago,Be among the first 25 applicants,"['', 'Our Opportunity', 'Ability to understand and apply advanced mathematics', 'Predict, simulate and optimize Supply Chain operations', 'Bonus', 'Work with IT and Data Warehousing teams to develop and enhance systems', 'Experience working with Predictive Models (Time Series and Regression), Linear Programming, and Classification', ' An advanced degree (M.S., PhD, or equivalent experience) in Operations Research, Statistics, Applied Mathematics, Engineering, Computer Science or related field or 5+ years’ experience designing optimization and machine learning solutions for large scale applications Ability to understand and apply advanced mathematics R or Python mastery Experience working with Predictive Models (Time Series and Regression), Linear Programming, and Classification Ability to translate complex data sets and research into simple business recommendations Ability to manage multiple projects Ability to use collaborative programming tools (Git, Confluence, etc.), and assist and support junior colleague’s use of those tools Position may require travel  ', 'Ability to translate complex data sets and research into simple business recommendations', 'Strong leadership skills and outgoing', 'Ability to manage multiple projects', 'R or Python mastery', 'Implement process improvement initiatives that drive improvements to the metrics and streamline the Supply Chain', 'Be a subject matter expert for Supply Chain Analytics', ""What You'll Need"", 'Ability to use collaborative programming tools (Git, Confluence, etc.), and assist and support junior colleague’s use of those tools', 'Position may require travel ', 'E-com, Retail or startup experience is a plus', ""What You'll Do"", 'Ability to effectively operate both independently and as part of a team', ' Deep dive big Supply Chain data to explain change, find hidden opportunity, and provide recommendations Predict, simulate and optimize Supply Chain operations Partner with Supply Chain’s functional areas (with Demand Planning, S&OP, Transportation, and Supply Planning) to develop to optimize our Supply Chain across the board Work with IT and Data Warehousing teams to develop and enhance systems Be a subject matter expert for Supply Chain Analytics Implement process improvement initiatives that drive improvements to the metrics and streamline the Supply Chain ', 'An advanced degree (M.S., PhD, or equivalent experience) in Operations Research, Statistics, Applied Mathematics, Engineering, Computer Science or related field or 5+ years’ experience designing optimization and machine learning solutions for large scale applications', ' Data Scientist ', ' Strong leadership skills and outgoing Ability to effectively operate both independently and as part of a team E-com, Retail or startup experience is a plus ', 'Partner with Supply Chain’s functional areas (with Demand Planning, S&OP, Transportation, and Supply Planning) to develop to optimize our Supply Chain across the board', 'Deep dive big Supply Chain data to explain change, find hidden opportunity, and provide recommendations']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-10-20 12:01:24
Data Scientist,Chewy,"Dania, FL",6 hours ago,Be among the first 25 applicants,"['', 'Our Opportunity', 'Ability to understand and apply advanced mathematics', 'Predict, simulate and optimize Supply Chain operations', 'Bonus', 'Work with IT and Data Warehousing teams to develop and enhance systems', 'Experience working with Predictive Models (Time Series and Regression), Linear Programming, and Classification', ' An advanced degree (M.S., PhD, or equivalent experience) in Operations Research, Statistics, Applied Mathematics, Engineering, Computer Science or related field or 5+ years’ experience designing optimization and machine learning solutions for large scale applications Ability to understand and apply advanced mathematics R or Python mastery Experience working with Predictive Models (Time Series and Regression), Linear Programming, and Classification Ability to translate complex data sets and research into simple business recommendations Ability to manage multiple projects Ability to use collaborative programming tools (Git, Confluence, etc.), and assist and support junior colleague’s use of those tools Position may require travel  ', 'Ability to translate complex data sets and research into simple business recommendations', 'Strong leadership skills and outgoing', 'Ability to manage multiple projects', 'R or Python mastery', 'Implement process improvement initiatives that drive improvements to the metrics and streamline the Supply Chain', 'Be a subject matter expert for Supply Chain Analytics', ""What You'll Need"", 'Ability to use collaborative programming tools (Git, Confluence, etc.), and assist and support junior colleague’s use of those tools', 'Position may require travel ', 'E-com, Retail or startup experience is a plus', ""What You'll Do"", 'Ability to effectively operate both independently and as part of a team', ' Deep dive big Supply Chain data to explain change, find hidden opportunity, and provide recommendations Predict, simulate and optimize Supply Chain operations Partner with Supply Chain’s functional areas (with Demand Planning, S&OP, Transportation, and Supply Planning) to develop to optimize our Supply Chain across the board Work with IT and Data Warehousing teams to develop and enhance systems Be a subject matter expert for Supply Chain Analytics Implement process improvement initiatives that drive improvements to the metrics and streamline the Supply Chain ', 'An advanced degree (M.S., PhD, or equivalent experience) in Operations Research, Statistics, Applied Mathematics, Engineering, Computer Science or related field or 5+ years’ experience designing optimization and machine learning solutions for large scale applications', ' Data Scientist ', ' Strong leadership skills and outgoing Ability to effectively operate both independently and as part of a team E-com, Retail or startup experience is a plus ', 'Partner with Supply Chain’s functional areas (with Demand Planning, S&OP, Transportation, and Supply Planning) to develop to optimize our Supply Chain across the board', 'Deep dive big Supply Chain data to explain change, find hidden opportunity, and provide recommendations']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-10-20 12:01:24
Sr. Data Engineer,"Resolution Technologies, Inc.","Pittsburgh, PA",20 hours ago,110 applicants,"['', '5-7+ years of experience in a cloud computing environment.Familiarity and strong understanding of working in the Linux operating environment.Familiarity and experience executing several software development methodologies and life cycles preferred.', 'A Data Engineer III is responsible for coding and continuous testing of complex modules and applications in support of the company’s platform. This person will also be charged with understanding and the interpretation of requirements to contribute to the technical architecture and related design documents.', 'Familiarity and experience executing several software development methodologies and life cycles preferred.', '3+ years with document databases (e.g. MongoDB, Accumulo, etc.)', 'Strong analytical skills and the ability to work with end users to transform requests into robust solutions.', 'SR. DATA ENGINEER EDUCATION', ""Bachelor's computer information technology, computer science, management required"", 'Provide mentorship and support for junior level engineers', '5+ years of SQL', 'Good software development and Object Oriented programming skills.', 'SR. DATA ENGINEER PRIMARY DUTIES AND RESPONSIBILITIES', 'Familiarity with test automation (Selenium, SoapUI, etc.)', '7+ years of developing software using object-oriented or functional language experience5+ years of SQL7+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.)3+ years with document databases (e.g. MongoDB, Accumulo, etc.)3+ years of experience using Agile development processes (e.g. developing and estimating user stories, sprint planning, sprint retrospectives, etc.)2+ years of distributed version control system (e.g. git)3+ years of experience in cloud-based development and deliveryFamiliarity with distributed computing patterns, techniques, and technologies (e.g. ESB)Familiarity with continuous delivery technologies (e.g. Puppet, Chef, Ansible, Docker, Vagrant, etc.)Familiarity with build automation and continuous integration tools (e.g. Maven, Jenkins, Bamboo, etc.)Familiarity with Agile process management tools (e.g. Atlassian Jira)Familiarity with test automation (Selenium, SoapUI, etc.)Good software development and Object Oriented programming skills.Strong analytical skills and the ability to work with end users to transform requests into robust solutions.Excellent oral and written communication skills.Initiative and self-motivation to work independently on projects.', '3+ years of experience in cloud-based development and delivery', ""Master's preferred"", '5-7+ years of experience in a cloud computing environment.', '7+ years of developing software using object-oriented or functional language experience', 'Familiarity with continuous delivery technologies (e.g. Puppet, Chef, Ansible, Docker, Vagrant, etc.)', 'SR. DATA ENGINEER EXPERIENCE', ""Bachelor's computer information technology, computer science, management requiredMaster's preferred"", '7+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.)', '3+ years of experience using Agile development processes (e.g. developing and estimating user stories, sprint planning, sprint retrospectives, etc.)', 'Familiarity and strong understanding of working in the Linux operating environment.', '2+ years of distributed version control system (e.g. git)', 'Familiarity with distributed computing patterns, techniques, and technologies (e.g. ESB)', '\ufeffSR. DATA ENGINEER SKILLS', 'Excellent oral and written communication skills.', 'Utilize domain driven techniques and design patterns to build and contribute to technical design.', 'As an agile team member, participate in code reviews, design reviews, etc.', 'Writing, debugging, unit testing, and performance test code in the data access layer in accordance with company standards.As an agile team member, participate in code reviews, design reviews, etc.Utilize domain driven techniques and design patterns to build and contribute to technical design.Develop and maintain strong knowledge of implemented requirements and detailed application behaviors.Provide mentorship and support for junior level engineers', 'Develop and maintain strong knowledge of implemented requirements and detailed application behaviors.', 'Initiative and self-motivation to work independently on projects.', 'Familiarity with build automation and continuous integration tools (e.g. Maven, Jenkins, Bamboo, etc.)', 'Familiarity with Agile process management tools (e.g. Atlassian Jira)', 'SR. DATA ENGINEER', 'SR. DATA ENGINEER JOB SUMMARY', 'Writing, debugging, unit testing, and performance test code in the data access layer in accordance with company standards.']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Dice,"Redmond, WA",16 hours ago,Be among the first 25 applicants,[''],Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Software Engineer,Brain Gain Recruiting,"Owings Mills, MD",22 hours ago,27 applicants,"['', 'All candidates must be US Citizens All candidates who receive and accept  an offer must complete a background check. Location: Owings Mills, MD.  You will work onsite 2 days/ week.', 'Very strong experience in low-level C++ software development ', 'All candidates must be US Citizens', 'Experience developing software within the system hierarchy (physical, kernel, user) ', 'All candidates must be US Citizens ', 'Job Description', 'Bachelor’s degree in Computer Science or a related field. ', 'Job Description ', 'We are looking for a talented, bright, and curious Software Engineer  to join our team. You will work on a variety of security and forensics projects. ', ' Additional Information', 'Qualifications', 'Bachelor’s degree in Computer Science or a related field. At least 3 years of professional experience Very strong experience in low-level C++ software development Experience developing software within the system hierarchy (physical, kernel, user) Solid knowledge of  Linux Networking, Concurrent Programming,  and Multithreading Desire and ability to learn new skills and assume project ownership ', 'Solid knowledge of  Linux Networking, Concurrent Programming,  and Multithreading ', 'Location: Owings Mills, MD.  You will work onsite 2 days/ week.', 'At least 3 years of professional experience ', ' ', 'You will own your projects and will be expected to design and develop robust code, \xa0provide comprehensive tests, document your work, and assemble product demos. ', 'Desire and ability to learn new skills and assume project ownership ', 'All candidates who receive and accept  an offer must complete a background check. ']",Mid-Senior level,Full-time,Information Technology,Research,2020-10-20 12:01:24
Data Engineer,B12,United States,19 hours ago,Over 200 applicants,"['', 'You have strong written and verbal communication skills in English.', 'We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.', 'You are fluent in SQL and Python.You have experience building and using data infrastructure, including systems like Postgres and Redshift.You’ve used reporting tools like Metabase, Tableau, or Looker in the past.You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.You’ve contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse.\xa0You feel comfortable managing your time and deciding amongst competing priorities.You have worked with non-engineering teams and are comfortable explaining technical solutions to them.You are passionate about the future of work.You enjoy learning and teaching.You have strong written and verbal communication skills in English.', 'We value sharing our work with the outside world. Our team has\xa0published papers\xa0on forming expert flash teams and machine-mediated worker hierarchies. We’ve baked our research into\xa0Orchestra, the system that coordinates our expert and machine teams, and released Orchestra into open source to contribute our software back to the community.', 'You’ve used reporting tools like Metabase, Tableau, or Looker in the past.', 'You feel comfortable managing your time and deciding amongst competing priorities.', 'We like to move fast and support point-in-time recovery :).', 'You have worked with non-engineering teams and are comfortable explaining technical solutions to them.', 'We build our product on Python/Django and JavaScript/React.We store blobs in Amazon’s S3, munch on them in Amazon’s EC2, develop in Docker, and deploy containers to Amazon’s Elastic Beanstalk.We believe Postgres should be the first system you consider when you think about persisting structured data.We religiously clean and centralize data in Amazon’s Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.We set up continuous integration and deployment because, while this model comes with its own pains, we’ve disliked being on fixed release schedules on previous projects.We like to move fast and support point-in-time recovery :).', ""B12's engineering team views software as a craft, but improving the world as the reason to practice it. Our engineers are responsible for prioritizing, conceptualizing, co-designing, building, testing, and engaging users for any concept we are building out. We’re generalists in encouraging each other to experience the full stack, but we’re also aware of each other’s preferences in the stack. We mentor and teach where we can, both inside and outside of the company."", 'As a Data Engineer, you will', 'You enjoy learning and teaching.', 'We build our product on Python/Django and JavaScript/React.', 'Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.', 'You have experience building and using data infrastructure, including systems like Postgres and Redshift.', 'We religiously clean and centralize data in Amazon’s Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!', 'B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.', 'Collaborate with operational teams including sales, marketing, and customer success.Contribute to infrastructure that enables and informs B12’s analytical efforts.Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.', 'You’ve contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse.\xa0', 'You are passionate about the future of work.', 'Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.', 'We believe Postgres should be the first system you consider when you think about persisting structured data.', 'We’re looking for a Data Engineer to help us answer critical questions our business faces while improving our data systems and architecture to support greater variety, volume, and velocity of data and data sources. We hope our engineers have more longevity than any one tool we use, but here is a sampling of our current thoughts about technology:', 'Collaborate with operational teams including sales, marketing, and customer success.', 'Data Engineering at B12', 'Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.', 'You are fluent in SQL and Python.', 'Some candidates may see this list and feel discouraged because they don’t match all the items. Please apply anyway: there’s a good chance you’re more wonderful than you think you are.\xa0', 'We set up continuous integration and deployment because, while this model comes with its own pains, we’ve disliked being on fixed release schedules on previous projects.', 'Contribute to infrastructure that enables and informs B12’s analytical efforts.', 'You’d be a good fit if', 'We store blobs in Amazon’s S3, munch on them in Amazon’s EC2, develop in Docker, and deploy containers to Amazon’s Elastic Beanstalk.', ""Don't fear"", 'Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.', 'You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.', ""We don't have a minimum number of years of experience for this role. We highly favor talent and interest.Some candidates may see this list and feel discouraged because they don’t match all the items. Please apply anyway: there’s a good chance you’re more wonderful than you think you are.\xa0B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community."", ""We don't have a minimum number of years of experience for this role. We highly favor talent and interest.""]",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
"Software Engineer, Data Platform",Lyft,"San Francisco, CA",16 hours ago,25 applicants,"['', 'Benefits', 'Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)', '401(k) plan to help save for your future', 'Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth at Lyft', 'Lyft is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. Lyft does not make hiring or employment decisions on the basis of race, color, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender-identity, sexual orientation, disability, age, military or veteran status, or any other basis protected by applicable local, state, or federal laws or prohibited by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Pursuant to the San Francisco Fair Chance Ordinance and other similar state laws and local ordinances, and its internal policy, Lyft will also consider for employment qualified applicants with arrest and conviction records.', 'Great medical, dental, and vision insurance options', 'Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program', 'Evolve data model and data schema based on business and engineering needs', 'Mental health benefits', 'Experience', ""Comfortable working directly with data analytics to bridge Lyft's business goals with data engineering"", 'Responsibilities', 'Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)', 'In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off', 'Develop tools supporting self-service data pipeline management (ETL)', '18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible', '2+ years of relevant professional experience', 'Pre-tax commuter benefits', 'Good understanding of SQL Engine and able to conduct advanced performance tuning', 'SQL and MapReduce job tuning to improve data processing performance', 'Strong skills in scripting language (Python, Ruby, Bash)', ' Great medical, dental, and vision insurance options Mental health benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program ', 'Implement systems tracking data quality and consistency', 'Experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, Parquet)', ' Owner of the core company data pipeline, responsible for scaling up data processing flow to meet the rapid data growth at Lyft Evolve data model and data schema based on business and engineering needs Implement systems tracking data quality and consistency Develop tools supporting self-service data pipeline management (ETL) SQL and MapReduce job tuning to improve data processing performance ', "" 2+ years of relevant professional experience Experience with Hadoop (or similar) Ecosystem (MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, Parquet) Proficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle) Good understanding of SQL Engine and able to conduct advanced performance tuning Strong skills in scripting language (Python, Ruby, Bash) Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4) Comfortable working directly with data analytics to bridge Lyft's business goals with data engineering ""]",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Data Engineer,Kforce Inc,"Beaverton, OR",22 hours ago,Be among the first 25 applicants,"['', ' Big Data Analytics', ' Languages: English (Speak, Read, Write)', '  Database Management  Databases  Maintenance  Prototype  Prototypes  Quality Assurance  Switch Capacity  User Interface  Languages: English (Speak, Read, Write)  Typical Office: This is a typical office job, with no special physical requirements or unusual work environment ', 'Additional', ' Documents and communicates database design', 'Requirements', "" Bachelor's degree"", ' Database', ' Hadoop Hive', ' Typical Office: This is a typical office job, with no special physical requirements or unusual work environment', ' Prototypes', ' Codes complex programs and derives logical processes on technical platforms', ' Builds windows, screens and reports', ' Provides expertise in devising, negotiating and defending the tables and fields provided in the database', ' Participates in quality assurance and develops test application code in client server environment', ""  Bachelor's degree  Hadoop Hive  Big Data Analytics  Database Design  Database  Conceptual Design "", ' Database Management', ' Switch Capacity', ' Database Design', ' Adapts business requirements, developed by modeling/development staff and systems engineers, and develops the data, database specifications, and table and element attributes for an application', "" At more experienced levels, helps to develop an understanding of client's original data and storage mechanisms"", ' Quality Assurance', ' Assists in the design of user interface and business application prototypes', ' Establishes database management systems, standards, guidelines and quality assurance for database deliverables, such as conceptual design, logical database, capacity planning, external data interface specification, data loading plan, data maintenance plan and security policy', ' Determines how tables relate to each other and how fields interact within the tables for a relational model', ""  Establishes database management systems, standards, guidelines and quality assurance for database deliverables, such as conceptual design, logical database, capacity planning, external data interface specification, data loading plan, data maintenance plan and security policy  Documents and communicates database design  Evaluates and installs database management systems  Codes complex programs and derives logical processes on technical platforms  Builds windows, screens and reports  Assists in the design of user interface and business application prototypes  Participates in quality assurance and develops test application code in client server environment  Provides expertise in devising, negotiating and defending the tables and fields provided in the database  Adapts business requirements, developed by modeling/development staff and systems engineers, and develops the data, database specifications, and table and element attributes for an application  At more experienced levels, helps to develop an understanding of client's original data and storage mechanisms  Determines appropriateness of data for storage and optimum storage organization  Determines how tables relate to each other and how fields interact within the tables for a relational model "", 'Responsibilities', ' Maintenance', ' Determines appropriateness of data for storage and optimum storage organization', ' Evaluates and installs database management systems', ' Conceptual Design', ' Databases', ' Prototype', ' User Interface']",Associate,Contract,Information Technology,Consumer Electronics,2020-10-20 12:01:24
Software & Data Engineer,Scouted,"Orange County, CA",24 hours ago,Over 200 applicants,"['', '_________________________', 'The hiring process for this role is managed by Scouted, a job-matching platform focused on early-career talent. In order to be considered, click the ‘Apply’ button. If you have an\xa0urgent\xa0question, email scouted@scouted.io.', 'Please\xa0do\xa0NOT\xa0use InMail. You will not get a response.', 'What will you do?', 'Data is a core part of our business and our data-focused software developers are among our most valued resources. This role is mission-critical, so we’re searching for an uncommonly reliable professional who enjoys coding, working with and analyzing data, and providing support for production systems. In addition to programming and data analysis, this position is likely to involve interaction with external resources such as data providers, brokers, dealers, and software vendors.', 'Applications: experience designing, developing, and maintaining software applications', 'What are you like?', 'System tools: experience with scripting languages (Perl, Python, shell scripts, etc.), and Unix-based operating systems (especially Linux)', 'Vendor interaction: working with external resources to solve problems, acquire data, and improve relationships.', 'Successful candidates will have experience in a number of the following general areas:\xa0', 'Programming: strong experience with Python, Java, SQL, and/or similar languages', 'Large data sets: experience developing programs to parse, process, clean, organize, and analyze large data sets', 'Programming: strong experience with Python, Java, SQL, and/or similar languagesLarge data sets: experience developing programs to parse, process, clean, organize, and analyze large data setsApplications: experience designing, developing, and maintaining software applicationsVendor interaction: working with external resources to solve problems, acquire data, and improve relationships.System tools: experience with scripting languages (Perl, Python, shell scripts, etc.), and Unix-based operating systems (especially Linux)', 'Role Overview', 'For over two decades, our team has built quantitative trading systems that have produced exceptional results across a range of financial markets. We use scientific methods and engineering discipline to solve challenging problems and develop technology solutions. Our Irvine office is as unique as our Southern California location, combining elements of high tech, finance, and applied research in a collegial atmosphere and beautiful workspace.']",Associate,Full-time,Engineering,Investment Management,2020-10-20 12:01:24
Data Scientist/ML Engineer,PA Consulting,"New York, NY",10 hours ago,Be among the first 25 applicants,"['', 'Benefits', '15 days paid vacation days with the opportunity to buy five additional days', 'Health Savings Account with company match', ""What We're Looking For"", 'Company and Voluntary income protection benefits', 'Experience building scalable data pipelines with data/feature engineering', 'Long term care plan', 'Experience working with big data distributed programming languages and ecosystems (e.g. S3, EC2, Hadoop/MapReduce, Pig, Hive, Spark)', 'Expertise in Machine Learning algorithms and methods', 'Pet and legal insurance Plans', 'Experience with front end (UI), HTML5, JavaScript, CSS, R Shiny, Tableau preferred', '10 paid Holidays plus 10 paid sick days', 'Group dental insurance', 'Become part of the team', 'Group medical insurance', 'Employee Assistance Plan', ""Master's degree from top tier university in Computer Science, Statistics, Economics, Physics, Engineering, Mathematics or similar field"", 'Teladoc and informed Nurse line resources', 'Experience Webscraping leveraging Beaituflsoup, Selenium, Scrappy etc preferred', '401(k) Savings Plan with company profit sharing contribution', 'About Us', 'Vision plan', 'Experience writing production level code in one of the following: Python, Java, C++, C', 'Strong understanding and application of statistical methods', 'Experience with database systems preferred', ' Group medical insurance Health Savings Account with company match Teladoc and informed Nurse line resources Long term care plan Group dental insurance Vision plan 401(k) Savings Plan with company profit sharing contribution Commuter and Parking tax-savings benefit 15 days paid vacation days with the opportunity to buy five additional days 10 paid Holidays plus 10 paid sick days Company and Voluntary income protection benefits Gym and health incentive reimbursement Pet and legal insurance Plans Employee Assistance Plan Annual performance-based bonus ', ""2-5 years' professional experience as a data scientist, software engineer or statistical modeler"", 'Gym and health incentive reimbursement', 'Commuter and Parking tax-savings benefit', 'Annual performance-based bonus', "" 2-5 years' professional experience as a data scientist, software engineer or statistical modeler Master's degree from top tier university in Computer Science, Statistics, Economics, Physics, Engineering, Mathematics or similar field Expertise in Machine Learning algorithms and methods Strong understanding and application of statistical methods Experience writing production level code in one of the following: Python, Java, C++, C Experience with database systems preferred Experience working with big data distributed programming languages and ecosystems (e.g. S3, EC2, Hadoop/MapReduce, Pig, Hive, Spark) Experience building scalable data pipelines with data/feature engineering Experience Webscraping leveraging Beaituflsoup, Selenium, Scrappy etc preferred Experience with front end (UI), HTML5, JavaScript, CSS, R Shiny, Tableau preferred "", 'Inclusion & Diversity']",Entry level,Full-time,Engineering,Management Consulting,2020-10-20 12:01:24
Big Data Software Engineer,JPMorgan Chase & Co.,"Wilmington, DE",23 hours ago,Be among the first 25 applicants,"['', 'Understanding of architecture and design across all systems ', 'BS/BA degree or equivalent experience', 'Ability to collaborate with high-performing teams and individuals throughout the firm to accomplish common goals', 'Working proficiency in developmental toolsets', 'Understanding of software skills such as business analysis, development, maintenance and software improvement', '7+ years IT experience and exposure to tools ETL/Data warehousing technology (Experience in Ab Initio technologies including, but not limited to Ab Initio graph development, EME, Co-Op, BRE, Continuous flow)', '3+ years IT experience and exposure with big data tools & platform such as Hadoop, Data Lakes, Spark, Hive, Cassandra', 'The candidate must have 5+ years of experience of running projects and teams using the agile methodology as well as an ability to lead and influence others', 'The ideal candidate is one with proven ability to drive agile adoption in various organizations, dealing with teams with a mix of low to none to and intermediate agile awareness and maturity.', ""Demonstrated meet and enforce ability to deadlines while dealing with competing priorities, motivated by a positive 'can do' attitude"", 'Advanced knowledge of application, data and infrastructure architecture disciplines', 'Minimum of 5 years of experience as a Scrum Master and Business Analysis using tools that aid the Agile development process, e.g., JIRA', ""BS/BA degree or equivalent experience Advanced knowledge of application, data and infrastructure architecture disciplines Understanding of architecture and design across all systems  Working proficiency in developmental toolsets Ability to collaborate with high-performing teams and individuals throughout the firm to accomplish common goals Understanding of software skills such as business analysis, development, maintenance and software improvement Minimum of 5 years of experience as a Scrum Master and Business Analysis using tools that aid the Agile development process, e.g., JIRA 7+ years IT experience and exposure to tools ETL/Data warehousing technology (Experience in Ab Initio technologies including, but not limited to Ab Initio graph development, EME, Co-Op, BRE, Continuous flow) 3+ years IT experience and exposure with big data tools & platform such as Hadoop, Data Lakes, Spark, Hive, Cassandra The candidate must have 5+ years of experience of running projects and teams using the agile methodology as well as an ability to lead and influence others The ideal candidate is one with proven ability to drive agile adoption in various organizations, dealing with teams with a mix of low to none to and intermediate agile awareness and maturity. Demonstrated meet and enforce ability to deadlines while dealing with competing priorities, motivated by a positive 'can do' attitude ""]",Entry level,Full-time,Information Technology,Banking,2020-10-20 12:01:24
Software Engineer,"TAD PGS, Inc.","Baltimore, MD",2 hours ago,Be among the first 25 applicants,"['', 'Experience with managing Cron related work', 'Enhance & support core components of DoublePositive’s Linux based systems.', '\xa0', 'Work with the technology team in the planning, engineering, optimization, and support of DoublePositive’s systems.', 'Software Engineer', 'Be the key resource on all MySql databases', 'Job Responsibilities:', '5+ years MySql Experience', 'Bachelor’s degree in the relevant area of study', '5+ years MySql ExperienceExperience with MariaDB and Percona preferredProficient with SQL CRUD operations, Stored Procedures, Triggers, and FunctionsProficient in LAMP stacks in an HA environment2+ years of PHP experience or other programming languageExperience with managing Cron related workExperience with source controlExperience with Object-Oriented ProgrammingDemonstrated ability to collaborate with othersTeam oriented experience including sharing knowledge and challenging others in the spirit of team improvementBachelor’s degree in the relevant area of study', 'Demonstrated ability to collaborate with others', 'Work with the technology team in the planning, engineering, optimization, and support of DoublePositive’s systems.Enhance & support core components of DoublePositive’s Linux based systems.Be the key resource on all MySql databasesHandle multiple active projects with varying deadlines and priorities.', 'Experience with MariaDB and Percona preferred', 'Experience with Object-Oriented Programming', '2+ years of PHP experience or other programming language', 'Baltimore, MD', 'Experience with source control', 'Handle multiple active projects with varying deadlines and priorities.', 'Proficient in LAMP stacks in an HA environment', 'Team oriented experience including sharing knowledge and challenging others in the spirit of team improvement', 'Basic Hiring Criteria:', 'Proficient with SQL CRUD operations, Stored Procedures, Triggers, and Functions', 'We have an outstanding career for opportunity for a\xa0Software Engineer\xa0to join a leading Company located in the\xa0Baltimore, MD\xa0surrounding area.']",Associate,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Engineer - CIMD Technology,Goldman Sachs,"Richardson, TX",7 hours ago,Over 200 applicants,"['', ' 3+ years academic or industry experience  Strong data warehousing concepts, especially in the ETL space  Experience with any one ETL tool  Strong in data structures and algorithms  Programming experience in either python or java.  Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases  Experience building and optimizing ‘big data’ data pipelines, architectures and data sets ', ' Work with data and analytics experts to strive for greater functionality in our data systems ', ' Advanced SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases ', 'How You Will Fulfill Your Potential', ' 3+ years academic or industry experience ', ' Experience building and optimizing ‘big data’ data pipelines, architectures and data sets ', ' Design, develop and enhance the Marcus Data Platform ', ' Programming experience in either python or java. ', 'CONSUMER (MARCUS BY GOLDMAN SACHS)', 'About Goldman Sachs', ' ABOUT GOLDMAN SACHS ', ' Conduct POC to help define the components for the Big Data platform ', ' Create data tools for analytics and data scientist team members that can assist them in building and optimizing our product into an innovative industry leader ', 'Responsibilities And Qualifications', ' Strong in data structures and algorithms ', ' GS.com/careers ', 'Qualifications', ' Strong data warehousing concepts, especially in the ETL space ', ' Experience with any one ETL tool ', ' https:// www.goldmansachs.com/careers/footer/disability-statement.html ', ' Design, develop and enhance the Marcus Data Platform  Develop data flows and pipelines in python and spark to support business needs  Create data tools for analytics and data scientist team members that can assist them in building and optimizing our product into an innovative industry leader  Work with data and analytics experts to strive for greater functionality in our data systems  Conduct POC to help define the components for the Big Data platform ', ' Develop data flows and pipelines in python and spark to support business needs ']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Federal - Data Scientist,Accenture Federal Services,"Washington, DC",5 hours ago,Be among the first 25 applicants,"['', ' You have experience with visualization (e.g. Power BI, Tableau, MicroStrategy, d3.js) ', ' Experience with Python and/or R Programming Language ', ' Experience with SQL or similar database language ', ' Accenture Federal Services is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'You are:\u202f ', 'This role requires US Citizenship with no dual Citizenship accepted.', ' Bonus points:', ' Experience with analytics, statistical modeling, optimization, machine learning, and/or artificial intelligence ', ' Work with large data sets to solve complex problems ', ' Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration. ', ' Apply statistical methods to develop analytic models', ' Experience in consulting or similar field requiring client collaboration, presentation, and delivery ', ' Drive the exploration of data sources and analytic techniques to create new modeling approaches ', ' An active security clearance or the ability to obtain one may be required for this role.', 'The work:', ' You have experience with Agile Methodology', ' Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture Federal Services. ', ' Work with clients to create questions and define technology opportunities ', ""Here's what you need: "", 'Locations:', ' You have experience with RDBMS (MariaDB, PostgreSQL, Oracle) ', ' You have experience with machine learning frameworks (e.g. TensorFlow, Scikit-Learn, Spark) ', ' Accenture Federal Services is committed to providing veteran employment opportunities to our service men and women. ', 'Important information ', 'Organization:', ' Equal Employment Opportunity: All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. ', ' Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process. ', ' Experience extracting, aggregating, and structuring data along different dimensions  Bonus points:', 'We are:\u202f\u202f']",Entry level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Data Engineer - Reporting,William Hill,"Jersey City, NJ",15 hours ago,Be among the first 25 applicants,"['', 'What You Will Do', 'What You Will Need', 'Perform ad hoc analysis and create ad- hoc reports.', 'Interpret data, analyze results to find discrepancies in ongoing reports.', '5+ years of experience in data, analytics, BI reporting or a related function.', 'Cloud experience is a plus.', 'Experience with data wrangling to calculate desired KPI’s from large volumes of data. Experience in conducting gap analysis.', 'Great project management skills and the ability to prioritize work based on critical needs.', 'Own and maintain ongoing reporting requirements, and ad hoc requests from the organization.', 'Experience in conducting and facilitating UAT.', 'Must be able to type and talk on the phone for extended periods of time ', 'Expertise in creating BI reports using Power BI or similar tool', 'Acquire data from primary or secondary data sources and create canned reports.', 'Technical expertise regarding data models and joins.', 'Must have experience with agile and scrum.', 'When we say cutting edge, we mean it. Here, you can work on highly reliable systems with low latency, much like the transactional systems of the best financial institutions, but…with the fun included. ', 'Communicate with marketing, operations, finance and other business teams to understand reporting needs.', 'Proficiency in using SQL.', 'Adept at queries, report writing and presenting findings.', 'Work with management to prioritize reporting and information needs.', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.', 'Use data to calculate metrics and KPIs.', ' Must be able to sit for extended periods of time  Must be able to type and talk on the phone for extended periods of time  Regular attendance in the office ', 'You will have access to ', 'Create automation in report delivery.', 'Must be able to sit for extended periods of time ', 'Experience with data visualization/reporting tools is a must.', 'Essential Functions/Exposures', 'Data-oriented personality, great communication skills, and an excellent eye for details.', ' Acquire data from primary or secondary data sources and create canned reports. Perform ad hoc analysis and create ad- hoc reports. Create automation in report delivery. Interpret data, analyze results to find discrepancies in ongoing reports. Communicate with marketing, operations, finance and other business teams to understand reporting needs. Use data to calculate metrics and KPIs. Own and maintain ongoing reporting requirements, and ad hoc requests from the organization. Work with management to prioritize reporting and information needs. ', 'Regular attendance in the office', ' 5+ years of experience in data, analytics, BI reporting or a related function. Expertise in creating BI reports using Power BI or similar tool Experience with data wrangling to calculate desired KPI’s from large volumes of data. Experience in conducting gap analysis. Experience in conducting and facilitating UAT. Technical expertise regarding data models and joins. Must have experience with agile and scrum. Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy. Proficiency in using SQL. Experience with data visualization/reporting tools is a must. Cloud experience is a plus. Great project management skills and the ability to prioritize work based on critical needs. Adept at queries, report writing and presenting findings. Data-oriented personality, great communication skills, and an excellent eye for details. ']",Entry level,Full-time,Information Technology,Gambling & Casinos,2020-10-20 12:01:24
Software Engineer,Braintree,"Bellevue, WA",9 hours ago,Be among the first 25 applicants,"['', '5+ years experience building software or web applications with object oriented or functional programming languages. Doesn’t matter what language, just a focus on writing clean, well designed and scalable code.', 'The Engineering Team:', 'perspectives', 'Open dev days: every two weeks we spend a day working on projects that interest us and help us expand our skills and knowledge.', 'Interest in TDD and specific experiences using a test heavy approach to solve problems and create solutions.', ""Communication is key to our process, and we don't want to hinder it with walls. Many teams program in pairs, which means you always have another set of eyes to help you."", 'Ability and desire to work in our collaborative environment: open team room, pair programming and fluid interactions with all products and operations teams.', 'unique', 'We keep the team in sync with daily stand-ups and have regular retrospectives to discuss things that are going well and opportunities for improvements.', 'Job Description Summary:', 'Participation in the technology community: we help cover travel and attendance costs for conferences, and we offer opportunities and tools for speaking.', 'Types of projects we work on:', 'Communication', 'test-driven development', 'Job Description:', 'We value unique perspectives brought by diverse backgrounds and experiences. A broad range of ideas and perspectives help us to create the best possible product.', 'About Us:', 'Focus on building solutions utilizing an agile approach: close relationships with Product Managers, communicating and digesting real time feedback, and working smart to build story cards on daily basis.', 'retrospectives', 'Check out our Careers page for more company perks.', 'Perks:', 'stand-ups', 'We practice test-driven development and believe that it helps us deliver simple solutions focused on real customer needs. We have no QA department – developers test, release and monitor their own code.', 'What we look for in you:']",Not Applicable,Full-time,Engineering,Computer Software,2020-10-20 12:01:24
"Associate, Data Visualization Engineer/Designer",CCC Information Services,"Chicago, IL",10 hours ago,Be among the first 25 applicants,"['', 'Source data from a variety of Big Data sources including Oracle, Hive and RedshiftWork with a development team to create exciting visual insights into tough business problems for both internal and external clientsWork with various stakeholders to understand business requirements and translate them into creative solutionsCollaborate with data engineers to understand the data architecture, gaps and logic, which you will translate into dashboard solutions', 'Visual design, visualizing information and UX aesthetics skillsAdobe Photoshop and Illustrator a plus', 'Understanding of design principles i.e. color theory or composition theory', 'Work with a development team to create exciting visual insights into tough business problems for both internal and external clients', 'Collaborate with data engineers to understand the data architecture, gaps and logic, which you will translate into dashboard solutions', 'Source data from a variety of Big Data sources including Oracle, Hive and Redshift', 'Job Description Summary', 'Pursing or completing a Master’s Degree a plusVisual design, visualizing information and UX aesthetics skillsAdobe Photoshop and Illustrator a plusUnderstanding of design principles i.e. color theory or composition theoryFundamental knowledge of Tableau (preferred) or MicroStrategyTableau Desktop and Tableau Server a plusPassing knowledge of SQL and database schemasSQL and Excel development a plus', 'Job Duties', 'Fundamental knowledge of Tableau (preferred) or MicroStrategyTableau Desktop and Tableau Server a plus', 'Adobe Photoshop and Illustrator a plus', 'SQL and Excel development a plus', 'Pursing or completing a Master’s Degree a plus', 'Passing knowledge of SQL and database schemasSQL and Excel development a plus', 'Qualifications', 'Work with various stakeholders to understand business requirements and translate them into creative solutions', 'Tableau Desktop and Tableau Server a plus', 'About CCC']",Associate,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Scientist,Sophos,Dallas-Fort Worth Metroplex,52 minutes ago,Be among the first 25 applicants,"['', '· Ability to visualize data in the most effective way possible for a given project or study', '· Creates and deploys advanced statistical models and analyses from multiple data sources to power initiatives and programs', '· Understanding of machine learning techniques, predictive models and algorithms', '· Upgrade and performance tune analytical dashboards', '· Experience in SQL, R or Python (preferably Python)', '· Strong math skills (e.g. statistics)', '· 5+ years’ experience in an analytical role, preferably channel-driven, environment', '· Analytical Toolkit – ability to exercise different problem-solving approaches to analyze results, including but not limited to time series analysis, experimental design and data visualization', '· Experience in data mining', '· Drive business results with analysis and insights from data-based models, working with stakeholders to improve business outcomes', '· Self-motivated, driven individual who is comfortable working in a fast-paced environment', 'The Data Science contributor must be incredibly curious about gathering accurate, insightful information to make clear, data-driven business decisions. This person will design data modeling processes, develop predictive models to extract the data the business needs, and help analyze the data and share insights. The successful candidate will have significant experience in Analytics/ Data science domain with a passion for machine-learning and research. The position will report to Manager, Business Intelligence.', '· Strong business and technical aptitude with an attitude to solve complex problems', '· Excellent verbal and written communication', '· Data Fluency – ability to leverage data to help organization better understand performance and progress to goal(s)', 'Duties and responsibilities:', '· Strong organizational and follow-up skills, as well as attention to detail', '· Design and build data science solutions to drive revenue growth, customer retention, sales targeting and support strategic decision making', 'Data Scientist', 'Qualifications', '· Strong team orientation and collaborative style. Flexible demeanor and an ability to get involved in the details while maintain a wider view', 'Job purpose', '· Mine and analyze large amounts of information to discover trends and patterns', '· BS / MS in Computer Science, Engineering or relevant field; graduate degree in Data Science or another quantitative field is preferred', '· Executed and deployed at least one predictive analytics project from start to end in a business environment', '· Present technical findings in a summarized form to non-technical audiences; translates complex quantitative data into succinct actionable insights']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-10-20 12:01:24
Data Scientist,Collabera Inc.,"Philadelphia, PA",4 hours ago,Be among the first 25 applicants,"['', 'Required - SQL Server TSQL - Views, Stored Procedures, Triggers, Queries ', 'May also assist in the designing and implementation of systems to analyze and report findings.', 'Provides statistical data trends to business partners such as medical management and underwriting.', 'Required - Informatica ETL', 'Responsible for the research, extraction and analysis of data. Evaluates and writes reports.', 'Looking for a Data Scientist with 5-8+ years of experience.Provides advanced professional input to complex Data Science and ETL assignments/projects. Responsible for the research, extraction and analysis of data. Evaluates and writes reports.Provides statistical data trends to business partners such as medical management and underwriting.May also assist in the designing and implementation of systems to analyze and report findings.Utilizes in-depth professional knowledge and acumen to develop models and procedures, and monitor trends, within Data ScienceRequired - MS SSIS Packages for ETLRequired - SQL Server TSQL - Views, Stored Procedures, Triggers, Queries Required - Informatica ETL', 'Utilizes in-depth professional knowledge and acumen to develop models and procedures, and monitor trends, within Data Science', 'Provides advanced professional input to complex Data Science and ETL assignments/projects. ', 'Looking for a Data Scientist with 5-8+ years of experience.', 'Required - MS SSIS Packages for ETL']",Mid-Senior level,Full-time,Engineering,Hospital & Health Care,2020-10-20 12:01:24
"Senior Data Engineer, Kafka",Interos Inc,"Arlington, VA",23 hours ago,Be among the first 25 applicants,"['', 'Benefits', 'Comprehensive Health & Wellness package (Medical, Dental and Vision)', ' Comfortable working with Docker and Kubernetes Experience with cloud services in general and AWS in particular ', 'Company Events (Sports Games, Fitness Competitions, Birthday Celebrations, Contests, Happy Hours)', 'Employee Referral Program', 'Strong Python coding skills', 'Write Kafka producers and consumers in Python', 'Experience with cloud services in general and AWS in particular', ""Minimum education level: Bachelor's Degree, Computer Science or related field or equivalent"", 'Career advancement opportunities', '10 Paid Holiday Days Off', 'Accrued Paid Time Off (PTO)', 'Experience with Kafka streams', 'Minimum years of relevant experience: 5+ years software engineering experience', 'Guide data and machine learning engineers on best practices regarding Kafka', 'Own Kafka message schema evolution', 'Experience with Kafka topic topology design', ' Lead Kafka topic topology design Own Kafka message schema evolution Write Kafka producers and consumers in Python Guide data and machine learning engineers on best practices regarding Kafka Design and build near real-time data analytics pipelines Pitch in wherever needed to meet team goals and deliver a quality product ', 'On-site gym and dedicated Peloton room at headquarters', 'Casual Dress', 'Stock Options', 'Ability to communicate clearly and willingness to share knowledge and collaborate', 'Minimum Qualifications:', ' Comprehensive Health & Wellness package (Medical, Dental and Vision) 10 Paid Holiday Days Off Accrued Paid Time Off (PTO) 401(k) Employer Matching Stock Options Career advancement opportunities Casual Dress On-site gym and dedicated Peloton room at headquarters Company Events (Sports Games, Fitness Competitions, Birthday Celebrations, Contests, Happy Hours) Annual company party Employee Referral Program ', 'Real world experience with production Kafka event streaming pipeline', '401(k) Employer Matching', 'Design and build near real-time data analytics pipelines', 'The Opportunity:', 'Essential Functions/duties:', 'Annual company party', 'Lead Kafka topic topology design', "" Strong Python coding skills Real world experience with production Kafka event streaming pipeline Experience with Kafka topic topology design Experience with Kafka streams Ability to communicate clearly and willingness to share knowledge and collaborate Minimum years of relevant experience: 5+ years software engineering experience Minimum education level: Bachelor's Degree, Computer Science or related field or equivalent "", 'Pitch in wherever needed to meet team goals and deliver a quality product', 'Comfortable working with Docker and Kubernetes', 'Preferred Qualifications:']",Associate,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
"Analyst, Data Engineer",Horizon Next,New York City Metropolitan Area,20 hours ago,169 applicants,"['', '20% - Enhance Engineering codebase to fix bugs, and add and document features', 'Horizon Next', 'Excellent written and verbal communication with both technical and non-technical audiences', '\xa0', 'Accomplished go-getters who balance their need for flawless execution with the need to meet client deadlines.', 'The statements herein are intended to describe the general nature and level of work being performed by employees and are not to be construed as an exhaustive list of responsibilities, duties and skills required of personnel so classified. Furthermore, they do not establish a contract for employment and are subject to change at the discretion of the employer.', 'Who We Are', 'Methodical developers who are obsessed with attention to the smallest details.Accomplished go-getters who balance their need for flawless execution with the need to meet client deadlines.Team players who enjoy working with others to design and implement robust solutions for challenging real-world problems.Passionate coders who enjoy devising the most efficient ways to tackle business problems through algorithms and coding best practicesCritical thinkers who thrive when working with a variety of coding and programming languages across multiple systems.Ingenious architects whose understanding of data engineering fundamentals enables them to conceptualize manual processes, generate coding and create systems to reduce human dependency.A supporter of and advocate for diversity, equity and inclusion', '20% - Collaborate with data scientists and BI analysts to understand data models and data ingestion requirements', '2+ years of experience using SQL for data warehousing and ETL development', 'Who We Are \xa0', 'Critical thinkers who thrive when working with a variety of coding and programming languages across multiple systems.', '2+ years of experience using Python and knowledge of a second object-oriented programming language', 'Physical Activity and Work Environment', 'Prefer candidate who can work east-coast hours.\xa0No other requirements for physical activity and work environment.', 'Certificates, Licenses and Registrations ', 'Must have a good balance of resourcefulness', '5%\xa0\xa0- Participate in planning meetings', 'Our simple recipe for success? We hire talented people (thinkers, doers, dreamers, makers), challenge them and give them every opportunity to grow. This position is on the Analytics team. We are a close nit highly efficient and driven team, who enjoy building innovative solutions for our clients and ourselves. Analytics has been a leading source contributing to growth, in the ability to demonstrate value for our clients.', ' What You’ll Do ', 'Exposure to cloud services like Google Cloud Platform, Azure or AWS – AWS highly preferred (S3, Redshift, EC2, and etc.)', 'A supporter of and advocate for diversity, equity and inclusion', 'Certificates, Licenses and Registrations', '30% - Build and maintain data pipelines using Python code base', 'Preferred Skills & Experience', 'Who We Are ', 'No requirements for certificates, licenses and registrations.', '30% - Build and maintain data pipelines using Python code base25% - Troubleshoot data quality issues and perform the necessary fixes/backfills20% - Collaborate with data scientists and BI analysts to understand data models and data ingestion requirements20% - Enhance Engineering codebase to fix bugs, and add and document features5%\xa0\xa0- Participate in planning meetings', 'At Horizon Next, we understand the value that different perspectives can bring to our clients and culture, so we strive for an environment where our employees feel welcomed, safe and empowered. We value YOU and believe that your authentic voice and unique perspective allows us to create a more rewarding culture, and experience, together. ', 'Ingenious architects whose understanding of data engineering fundamentals enables them to conceptualize manual processes, generate coding and create systems to reduce human dependency.', 'Working knowledge of Linux environments, Git, and Shell scripting – must be able to perform simple navigation of Unix-like operating systems (manipulating files, logging on to other systems using terminal, etc.)', 'Understanding of object-oriented programming – classes, methods, inheritance, method overriding, etc.', 'High level knowledge of designing/building/deploying production-level data pipelines on scalable, distributed systems or multi-node database paradigms', '25% - Troubleshoot data quality issues and perform the necessary fixes/backfills', 'What You’ll Do', 'Passionate coders who enjoy devising the most efficient ways to tackle business problems through algorithms and coding best practices', ""Horizon Next is one of the industry's most innovative and data-driven marketing organizations and sits at the intersection of three constantly changing landscapes: people, data, and media. Our business provides strategic leadership to accelerate growth for our clients through brand strategy, media planning and investment, and best in class analytics across all channels. As the leader in innovative business solutions, we are always pushing ourselves to understand what’s next: our next innovation, our next advancement in analytics, the market’s next media evolution, and your next breakthrough idea. Horizon Next operates with the single goal that tomorrow must outperform today.\xa0"", 'Who You Are', 'Methodical developers who are obsessed with attention to the smallest details.', 'Bachelor’s degree in technical field, computer science/engineering, or mathematics', 'What You’ll Do ', 'Bachelor’s degree in technical field, computer science/engineering, or mathematicsExposure to cloud services like Google Cloud Platform, Azure or AWS – AWS highly preferred (S3, Redshift, EC2, and etc.)Understanding of object-oriented programming – classes, methods, inheritance, method overriding, etc.2+ years of experience using Python and knowledge of a second object-oriented programming language2+ years of experience using SQL for data warehousing and ETL developmentHigh level knowledge of designing/building/deploying production-level data pipelines on scalable, distributed systems or multi-node database paradigmsWorking knowledge of Linux environments, Git, and Shell scripting – must be able to perform simple navigation of Unix-like operating systems (manipulating files, logging on to other systems using terminal, etc.)Excellent written and verbal communication with both technical and non-technical audiencesMust have a good balance of resourcefulness', 'Team players who enjoy working with others to design and implement robust solutions for challenging real-world problems.']",Associate,Full-time,Analyst,Marketing and Advertising,2020-10-20 12:01:24
Data Scientist - Network Analytics,ClearedJobs.Net,"Herndon, VA",20 hours ago,Be among the first 25 applicants,"['', 'Ability to write complex SQL scripts, stored procedures, algorithms independently', 'Knowledge of Data Management systems, data sources and data architectures.Experience developing Analytics/Dashboards /Reports/Visualizations Upgrade experienceExperience installing data analytic tools including application configuration, security, and administrationData Warehouse, Data Modeling, Data Mart experienceExperience with Oracle, SQL server databasesAbility to write complex SQL scripts, stored procedures, algorithms independentlyExperience implementing AI/ML-enabled Predictive AnalyticsStrong troubleshooting skills, analytical problem-solving ability, and organizational skills.', 'Experience working with Splunk.', 'Experience implementing AI/ML-enabled Predictive Analytics', 'These Qualifications Would Be Nice To Have', ' We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.', ' For over 55 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.', 'Job Description', 'Experience with Oracle, SQL server databases', 'More About The Role', 'Experience working with Splunk.Understanding of Network performance managementExperience working with wide area and local area network data.Experience working in Amazon Web Services and the analytical tools available in AWS.', 'What You’ll Get To Do', 'Experience developing Analytics/Dashboards /Reports/Visualizations Upgrade experience', ' We offer competitive benefits and learning and development opportunities.', 'Data Warehouse, Data Modeling, Data Mart experience', 'Understanding of Network performance management', 'Experience working in Amazon Web Services and the analytical tools available in AWS.', 'Job Location', 'Knowledge of Data Management systems, data sources and data architectures.', 'What We Can Offer You', ""You'll Bring These Qualifications"", ' Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.', 'Strong troubleshooting skills, analytical problem-solving ability, and organizational skills.', 'Experience installing data analytic tools including application configuration, security, and administration', ' We’ve been named a Best Place to Work by the Washington Post.', 'Experience working with wide area and local area network data.']",Entry level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Software Engineer - Commerce Platform,Evernote,"San Diego, CA",15 hours ago,92 applicants,"['', 'Preferred Qualifications', 'Past experience with Billing platforms and services (Zuora, Braintree, PayPal), multi-currency, payment processing, subscription ', 'Consistently delivered high-quality software in a timely manner', 'About The Team', 'Improve engineering standards, tooling, and processes', 'BS in Computer Science or related field of study.', ' Designed and built microservices with a focus on scale, reliability, availability Familiarity with containerization using Docker or similar technologies  Past experience with Billing platforms and services (Zuora, Braintree, PayPal), multi-currency, payment processing, subscription  Deployed software in Google, AWS, Azure, or similar cloud-native technologies ', '3+ years of experience programming in Java, C#, or other modern programming languages ', 'Familiarity with containerization using Docker or similar technologies ', 'Actively own features and/or systems and define their long term health', 'Designed and built microservices with a focus on scale, reliability, availability', 'Deployed software in Google, AWS, Azure, or similar cloud-native technologies', ' BS in Computer Science or related field of study. 3+ years of experience programming in Java, C#, or other modern programming languages  Consistently delivered high-quality software in a timely manner ', 'Work closely with Product Managers and Client Teams to build features that make payments easy, seamless, and secure for our customers', ' Work closely with Product Managers and Client Teams to build features that make payments easy, seamless, and secure for our customers Actively own features and/or systems and define their long term health Improve engineering standards, tooling, and processes ', ""What You'll Do"", 'Basic Qualifications']",Entry level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
"Software Engineer, Mapping",DoorDash,"San Francisco, CA",3 hours ago,Be among the first 25 applicants,"['', 'Improve performance, reliability, scalability and security for our frontend and backend systems', 'doers', 'Nice To Haves', 'We are all DoorDash', 'Experience building large scale, real-time applications', ""What We're Looking For"", '5+ years of industry experience', 'Understanding of modern web stacks and architecture (HTTP, REST)', 'We are ', 'We are learners', 'Why You’ll Love Working at DoorDash', 'We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day. ', ' B.S., M.S., or PhD. in Computer Science or equivalent 5+ years of industry experience Prior experience working with backend tech stacks Able to analyze and improve efficiency, scalability, and stability of various system resources Experience with service oriented architecture, writing REST API’s, unit testing, and architectural design Understanding of modern web stacks and architecture (HTTP, REST) Experience with SQL and NoSQL databases and other technologies (e.g. Postgres, Redis, Elasticsearch, RabbitMQ) ', 'Experience with SQL and NoSQL databases and other technologies (e.g. Postgres, Redis, Elasticsearch, RabbitMQ)', ' Build an ETA platform that powers all of our real-time ETAs across every vertical Make DoorDash the highest quality and most efficient platform when it comes to doing deliveries Build internal tools to allow for everyone in DoorDash to make sense of geo-spatial data and to help us make better decisions ', ' Experience building large scale, real-time applications Experience with Java/Kotlin Contributor to open source projects ', 'Here are some potential projects you’d work on', 'Prior experience working with backend tech stacks', 'We are customer obsessed', 'We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.', 'Our Commitment to Diversity and Inclusion', 'Build internal tools to allow for everyone in DoorDash to make sense of geo-spatial data and to help us make better decisions', ' We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies. We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.  We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute. We are customer obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility. We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.  We offer great compensation packages and comprehensive health benefits. ', 'About DoorDash', 'A deep understanding of mapping tech and domain', 'We offer great compensation packages and comprehensive health benefits.', 'Build an ETA platform that powers all of our real-time ETAs across every vertical', 'Use technology to make a huge impact to the business', 'Experience with Java/Kotlin', 'B.S., M.S., or PhD. in Computer Science or equivalent', 'Able to analyze and improve efficiency, scalability, and stability of various system resources', ' A deep understanding of mapping tech and domain Develop and define the architecture and tech stack for a product area Improve performance, reliability, scalability and security for our frontend and backend systems Use technology to make a huge impact to the business ', 'Develop and define the architecture and tech stack for a product area', 'We are learners - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.', 'What You’ll Achieve', 'Contributor to open source projects', 'Experience with service oriented architecture, writing REST API’s, unit testing, and architectural design', 'Make DoorDash the highest quality and most efficient platform when it comes to doing deliveries', 'We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights. ', 'We are leaders', 'We are customer obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.']",Not Applicable,Full-time,Engineering,Marketing and Advertising,2020-10-20 12:01:24
Manager - Advanced Analytics (Data Scientist),Lidl US,"Arlington, VA",13 hours ago,Be among the first 25 applicants,"['', 'Required Knowledge, Skills, Abilities ', 'Lidl US, LLC & Affiliates provides equal employment opportunities (EEO) to all employees and applicants without regard to, including but not limited to, race, sex, color, religion, gender, sexual orientation or preference, gender identity or expression, national origin or ethnicity, age, marital status, pregnancy, genetic information, disability, or veteran status, in accordance with applicable federal, state and local laws.', 'Preferred', 'Understand complex problems and scenarios, and analyzing them in detail', 'Perform all other duties as assigned', 'Knowledge of Azure Databricks, Azure ML, SQL/Hive and Spark as well as visualization tools like Power-BI or similar', 'Support the transfer from current Excel-based analysis tools to advanced analytics products or innovative machine learning models to solve diverse challenges and opportunities ', 'This position commutes between stores, regional offices and/or distribution centers less than 25% of the time', ' Bachelor’s Degree in data science, mathematics/statistics, computer science, physics, or a related subject 3+ years of experience in related field in corresponding subjects or related fields ', 'Required', 'Partner with internal business units to understand their business problems and help them define, develop, and implement complex data products that are integrated into business processes and generate added business value', ' Knowledge in big-data technologies (SQL, Hadoop, Hive, Spark) Knowledge of machine learning, optimization, and data mining methods (e.g. using Python, R, or Analytics-tools like Alteryx, KNIME, RapidMiner) Statistical knowledge, predictive modelling Knowledge of applying time-series / regression analysis, clustering-methods, effectiveness testing (A-/B-hypotheses testing) to solve diverse business problems Understand complex problems and scenarios, and analyzing them in detail Ability to work to tight deadlines and to deliver accurate results Excellent communication skills and ability to work well in a team  Ability to work on projects and solve problems independently ', 'Ability to work on projects and solve problems independently', 'Cross-analyze data from different sources in order to create new insights to the business to solve real-world business problem ', 'Ability to operate machinery and/or equipment that requires the constant use of hands/fingers/wrists', 'Ability to identify and distinguish between colors more than half the time', 'Job Title:', 'Reports To: ', 'Full lifecycle development from analyzing current processes, providing functional specifications, designing and developing solutions, and testing and providing on-going support', 'Excellent communication skills and ability to work well in a team ', 'German language skills ', 'Physical Job Requirements', ' This position commutes between stores, regional offices and/or distribution centers less than 25% of the time This position requires overnight domestic travel less than 25% of the time  This position requires overnight international travel less than 25% of the time Anticipated travel will be by car, air, and/or train ', 'Bachelor’s Degree in data science, mathematics/statistics, computer science, physics, or a related subject', 'Knowledge of machine learning, optimization, and data mining methods (e.g. using Python, R, or Analytics-tools like Alteryx, KNIME, RapidMiner)', 'Business Unit:', 'Supervisory Role:', 'Department: ', 'Job Summary', 'Travel Requirements', 'Ability to remain in a stationary position (standing and/or seated) more than half the time', 'Ability to maneuver cases of product (lift, move, carry, slide, etc.) up to 30 lbs. ', 'Anticipated travel will be by car, air, and/or train', '3+ years of experience in related field in corresponding subjects or related fields', 'This position requires overnight domestic travel less than 25% of the time ', 'FLSA Status:', 'Statistical knowledge, predictive modelling', 'Ability to spend more than half the time viewing computer monitors', 'Knowledge in big-data technologies (SQL, Hadoop, Hive, Spark)', ' Ability to work a variety of shifts including nights, weekends, and holidays as needed Ability to work in a fast-paced working environment, including the store(s), distribution center(s), warehouse(s), and/or corporate office(s) with the capability to switch job functions/roles quickly Ability to remain in a stationary position (standing and/or seated) more than half the time Ability to maneuver cases of product (lift, move, carry, slide, etc.) up to 30 lbs.  Ability to operate machinery and/or equipment that requires the constant use of hands/fingers/wrists Ability to spend more than half the time viewing computer monitors Ability to identify and distinguish between colors more than half the time ', 'Essential Functions', 'Help to integrate the developed models into productive software', 'Leverage predictive and prescriptive methods by using modern machine learning techniques to optimize business processes ', 'This position requires overnight international travel less than 25% of the time', 'Upskill colleagues by creating a culture of experience exchange with the aim of improving understanding and efficiency of the department’s processes and products', 'Ability to work in a fast-paced working environment, including the store(s), distribution center(s), warehouse(s), and/or corporate office(s) with the capability to switch job functions/roles quickly', 'Ability to work a variety of shifts including nights, weekends, and holidays as needed', ' Partner with internal business units to understand their business problems and help them define, develop, and implement complex data products that are integrated into business processes and generate added business value Full lifecycle development from analyzing current processes, providing functional specifications, designing and developing solutions, and testing and providing on-going support Leverage predictive and prescriptive methods by using modern machine learning techniques to optimize business processes  Support the transfer from current Excel-based analysis tools to advanced analytics products or innovative machine learning models to solve diverse challenges and opportunities  Cross-analyze data from different sources in order to create new insights to the business to solve real-world business problem  Help to integrate the developed models into productive software Upskill colleagues by creating a culture of experience exchange with the aim of improving understanding and efficiency of the department’s processes and products Perform all other duties as assigned ', ' German language skills  Knowledge of Azure Databricks, Azure ML, SQL/Hive and Spark as well as visualization tools like Power-BI or similar ', 'Knowledge of applying time-series / regression analysis, clustering-methods, effectiveness testing (A-/B-hypotheses testing) to solve diverse business problems', 'Ability to work to tight deadlines and to deliver accurate results', 'Preferred Knowledge, Skills, Abilities', 'Required Education, Certifications/ Licenses, Related Experience']",Mid-Senior level,Full-time,Business Development,Construction,2020-10-20 12:01:24
Machine Learning & Data Engineer,Levelset,"Austin, Texas Metropolitan Area",22 hours ago,50 applicants,"['Offer solutions to business problems from a data engineering perspective, help drive the business forward ', 'At least 5 years of experience in data analysis and/or management in an enterprise cloud environment (AWS preferred) Excellent in SQL skills Ability to learn and eventually write Cypher code and understanding of Graph Databases Experience with one or more languages Python, R, SQL (advanced), Cypher, C#, Scala, Java, Postgres, Go Database development experience with Relational or MPP/distributed systems such as Oracle/Teradata/Vertica/Hadoop Experience in designing and developing production grade ETL data pipelines to input / export data across systems (RDBMS, NoSQL, Columnar, or Graph) and applications Experience developing complex efficient queries, designing and building logical data models, and working with large datasets on various database systems (nosql, rdbms, graph) Passion for data structures, data quality, and data interoperability Analytical mindset with the ability to structure and process qualitative data and draw insightful conclusions Problem solver able to take a complex business request and transform it into a clean, simple data solution Quick learner and open to new ideas and technologies, and willing to offer creative solutions Must be an intellectually curious self-starter and motivated to continually learn ', '\xa0', 'Benefits ', 'Database development experience with Relational or MPP/distributed systems such as Oracle/Teradata/Vertica/Hadoop ', 'Analytical mindset with the ability to structure and process qualitative data and draw insightful conclusions ', 'We’re a rapidly growing team working on interesting and worthwhile problems With a newly distributed workforce, we make engagement and employee wellness even more of a priority. We want you to love your job! We believe professional growth (i.e. building your skills) is essential. Working here provides the opportunity for increased responsibility, continuous learning, and more. We have a very welcoming culture that starts at the top with our CEO. Nothing is a secret here, we think honesty and transparency create a productive workplace. Recognition for hard work and demonstrating our core values is important to us. ', ""Learning and Development Opportunities: In the spirit of our core value to Learn Enough, we offer a book reimbursement program. If you share what you learned from a book with the team, we'll reimburse you for it. We also provide ample room for learning and development opportunities through Coursera online courses, outside speakers, and opportunities to learn skills from your colleagues. "", 'With a newly distributed workforce, we make engagement and employee wellness even more of a priority. We want you to love your job! ', 'We have a very welcoming culture that starts at the top with our CEO. ', 'Experience with one or more languages Python, R, SQL (advanced), Cypher, C#, Scala, Java, Postgres, Go ', 'Competitive health benefits, including mental, emotional, and behavioral health benefits and an easy to use Employee Assistance Program. ', 'We’re a rapidly growing team working on interesting and worthwhile problems ', 'welcoming culture', 'Collaboration and Strategic Decision Making ', 'Why Levelset', 'Develop standard release readiness and data deployment / change management processes ', 'Build the infrastructure required for optimal extraction, transformation, and loading of data on AWS ', 'A Machine Learning Engineer at Levelset is responsible for assembling, transforming, and loading large data sets about US contractors, sub-contractors, suppliers, projects, payment documents, etc... across various internal and external sources (i.e. Saas applications and data systems, US County Clerk data). You will be translating and building advanced models into production grade data pipelines across our stack which currently consists of technologies like MySQL, PHP, Neo4J, Redis, Kafka, Python, AWS,  and other modern tools in a highly scalable microservices architecture. \xa0 ', 'Build and design architecture for managing data history from a variety of sources through data updates and data transformations ', 'Equity', 'We believe professional growth (i.e. building your skills) is essential. Working here provides the opportunity for increased responsibility, continuous learning, and more. ', ""Build Appropriate ML Data Models and Data Schema's for Business Use Cases "", 'If you read the below description and feel this position excites you, but your experience does not add up 100%, we encourage you to still apply and tell us why!', 'Passion for data structures, data quality, and data interoperability ', 'honesty and transparency', 'Open vacation policy without a cap on the number of days-off.  We do require employees to take a minimum of 5 days off in a row each year. ', 'Experience developing complex efficient queries, designing and building logical data models, and working with large datasets on various database systems (nosql, rdbms, graph) ', 'interesting and worthwhile problems', 'Join us as a Machine Learning Engineer in our Austin office, and be instrumental in helping achieve our vision to change behavior and revolutionize payment in the gigantic and increasingly tech-savvy construction industry. ', 'Why Levelset ', 'Job Duties (but not limited to): ', ""We are committed to fighting injustice throughout the construction industry, and fairness is key to our company's purpose. We are an equal opportunity employer and value diversity at our company. We do not discriminate."", ' ', ""Competitive health benefits, including mental, emotional, and behavioral health benefits and an easy to use Employee Assistance Program. Flexible sick & personal leave policy needed for health, family, and parenting during this tough time. Open vacation policy without a cap on the number of days-off.  We do require employees to take a minimum of 5 days off in a row each year. Subsidized International Travel: We subsidize international travel starting at 6 months, and increasing each year Equity, per company’s general stock grant plan 401k account through Betterment which allows you to seamlessly save money for retirement directly from your paycheck Learning and Development Opportunities: In the spirit of our core value to Learn Enough, we offer a book reimbursement program. If you share what you learned from a book with the team, we'll reimburse you for it. We also provide ample room for learning and development opportunities through Coursera online courses, outside speakers, and opportunities to learn skills from your colleagues. Potential H1-B Visa sponsorship opportunities (as needed) "", 'Operationalize ML trained models with MLOps ', 'If you read the below description and feel this position excites you, but your experience does not add up 100%, we encourage you to still apply and tell us why! We look forward to learning what makes you passionate and purposeful. Potential H1-B Visa sponsorship opportunities (as needed) ', '401k account through Betterment which allows you to seamlessly save money for retirement directly from your paycheck ', 'Open vacation policy ', 'Learning and Development Opportunities:', 'Ability to learn and eventually write Cypher code and understanding of Graph Databases ', 'Building Production Grade Data Pipelines, Processes, and Cloud Architecture ', 'Problem solver able to take a complex business request and transform it into a clean, simple data solution ', 'Collaborate with product, engineering, software development and other teams to come up with solutions that will work for the business Offer solutions to business problems from a data engineering perspective, help drive the business forward Explain and offer architecture and data process design solutions that will best support the business and product ', 'What You Bring ', 'Subsidized International Travel:', 'Levelset has been named one of the ""Best Places to Work"" by New Orleans CityBusiness three years in a row for our mission-driven culture and commitment to internal and external growth. Backed by venture funding, we are growing rapidly and looking for new exciting team members to add their unique talents to our mission. We empower contractors to always get what they earn, and our software platform makes lien rights, payment paperwork, and compliance in the construction industry simple and stress-free, so contractors and suppliers can get paid faster, have easier access to capital, and less surprises. ', 'Potential H1-B Visa sponsorship opportunities (as needed) ', 'Competitive health benefits', 'Build and assemble large, complex data sets with multi-dimensional relationships that meet both functional and non-functional requirements from business stakeholder ', 'Excellent in SQL skills ', '\xa0 ', 'Identify, design, and implement internal data pipeline jobs / processes improvements using machine learning (and other modern techniques): automating manual processes, optimizing data delivery, re-designing infrastructure for scalability, etc. ', 'About Levelset ', 'Potential H1-B Visa sponsorship opportunities (as needed)', 'Recognition for hard work and demonstrating our core values is important to us. ', ' engagement and employee wellness', 'professional growth', 'Potential H1-B Visa', 'Flexible sick & personal leave ', 'Experience in designing and developing production grade ETL data pipelines to input / export data across systems (RDBMS, NoSQL, Columnar, or Graph) and applications ', 'Must be an intellectually curious self-starter and motivated to continually learn ', 'Nothing is a secret here, we think honesty and transparency create a productive workplace. ', 'Benefits', 'Collaborate with product, engineering, software development and other teams to come up with solutions that will work for the business ', 'Levelset is venture-backed by Horizons Ventures, S3 Ventures, Altos Ventures, and Brick & Mortar Ventures. Levelset is headquartered in New Orleans, Louisiana, with offices in Austin, Texas, and Cairo, Egypt, and is about 200 employees strong. ', ""Build Appropriate ML Data Models and Data Schema's for Business Use Cases Build and assemble large, complex data sets with multi-dimensional relationships that meet both functional and non-functional requirements from business stakeholder Develop and maintain a formal description of the data and data structures, data definitions and data models Operationalize ML trained models with MLOps "", 'Perform Analysis ', 'Quick learner and open to new ideas and technologies, and willing to offer creative solutions ', 'Subsidized International Travel: We subsidize international travel starting at 6 months, and increasing each year ', 'Explain and offer architecture and data process design solutions that will best support the business and product ', 'At least 5 years of experience in data analysis and/or management in an enterprise cloud environment (AWS preferred) ', 'Flexible sick & personal leave policy needed for health, family, and parenting during this tough time. ', 'Develop and maintain a formal description of the data and data structures, data definitions and data models ', 'Troubleshoot data jobs / processes in production to fix data quality bugs or pipeline performance issues ', 'Perform detailed data and clustering analysis using ML and other techniques (i.e. determine the data composition, content, and quality of the data through examination of contributing sources and data samples) ', 'Implement data quality controls, monitoring systems, and processes to maintain high data integrity using machine learning and other modern techniques ', 'Job Duties (but not limited to):  ', 'What You Bring', 'Recognition for hard work', 'Equity, per company’s general stock grant plan ', 'About Levelset', 'Troubleshoot data jobs / processes in production to fix data quality bugs or pipeline performance issues Implement data quality controls, monitoring systems, and processes to maintain high data integrity using machine learning and other modern techniques Build the infrastructure required for optimal extraction, transformation, and loading of data on AWS Build and design architecture for managing data history from a variety of sources through data updates and data transformations Identify, design, and implement internal data pipeline jobs / processes improvements using machine learning (and other modern techniques): automating manual processes, optimizing data delivery, re-designing infrastructure for scalability, etc. ', '401k account ']",Associate,Full-time,Engineering,Computer Software,2020-10-20 12:01:24
Software Engineer,Microsoft,"Redmond, WA",14 hours ago,Be among the first 25 applicants,"['', ' Develop, deploy, and operate new services powered by ML Employ machine learning to detect and correlate problems Build models, simulation, scalable and automated analytical systems Drive improvements to the product design and architecture, leading to increased customer satisfaction Lead and collaborate with experts from across the company to advance data science best practices Educate and train others on modern application design Learn how to build and sustain engagement from all levels of an organization', ' Build models, simulation, scalable and automated analytical systems', ' 3 or more years of experience using data/ML/AI to impact critical product or business decisions', ' Learn how to build and sustain engagement from all levels of an organization', ' Lead and collaborate with experts from across the company to advance data science best practices', ' 3 or more years of experience using data/ML/AI to impact critical product or business decisions A proven track record of collaborating across organizational boundaries and delivering great results Familiarity with software development, database design, and online service development A Masters or higher degree in computer science, machine learning, statistics, math, economics, business or other scientific or quant-focused field. Nice to have: Experience with NLP and the handling of unstructured text', ' Drive improvements to the product design and architecture, leading to increased customer satisfaction', ' A Masters or higher degree in computer science, machine learning, statistics, math, economics, business or other scientific or quant-focused field.', 'Responsibilities', ' Develop, deploy, and operate new services powered by ML', ' Nice to have: Experience with NLP and the handling of unstructured text', ' Educate and train others on modern application design', ' A proven track record of collaborating across organizational boundaries and delivering great results', ' Familiarity with software development, database design, and online service development', ' Employ machine learning to detect and correlate problems', 'Qualifications']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-10-20 12:01:24
Data Engineer,"CapTech Ventures, Inc","Columbus, OH",7 hours ago,28 applicants,"['', 'Specific Responsibilities For The Data Engineer, Analytics Position Include', 'Short-Term and Long-Term disability', 'Matching 401(k)', 'Communicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customers', 'Minimum of 3 years experience designing, developing, and testing software aligned with defined requirements', 'Write and refine code to ensure performance and reliability of data extraction and processing.', 'Competitive Paid Time Off', 'Design, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc)Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insightsDesign, develop, and implement data processing pipelines at scalePresent programming documentation and design to team members and convey complex information in a clear and concise manner.Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes.Write and refine code to ensure performance and reliability of data extraction and processing.Communicate with all levels of stakeholders as appropriate, including executives, data modelers, application developers, business users, and customersParticipate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.Collaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.Some of our technologies might include: HDFS, Cassandra, Spark, Java, Scala, Informatica, SQL Server, Oracle, Ab Initio, Kafka.', 'Partner with clients to fully understand business philosophy and IT Strategy; recommend process improvements to increase efficiency and reliability in ETL development.', 'Development experience with Unix tools and shell scripts', 'Single and Family Health Insurance plans, including Dental coverage', 'Development experience with at least two different programming languages (Python, Java, C, etc.)', ""Bachelor's degree in Computer Science, Software Engineering, MIS or equivalent combination of education and experience Minimum of 3 years experience designing, developing, and testing software aligned with defined requirementsDevelopment experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating systemStrong SQL development skillsDevelopment experience with at least two different programming languages (Python, Java, C, etc.)Development experience with Unix tools and shell scriptsDevelopment experience with at least two different database platforms (Teradata, Oracle, MySQL, MS SQL, etc.)Experience tuning SQL queries to ensure performance and reliabilitySoftware engineering best-practices, including version control (Git, TFS, JIRA, etc.) and test driven developmentExposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc."", 'Design, develop, and implement data processing pipelines at scale', 'Development experience building ETL graphs using the Ab Initio GDE, EME and Co-Operating system', 'Experience tuning SQL queries to ensure performance and reliability', 'Job Description', 'Development experience with at least two different database platforms (Teradata, Oracle, MySQL, MS SQL, etc.)', 'Exposure to Business Intelligence tools such as Business Objects, Informatica, SSRS, Cognos, MicroStrategy, Tableau, QlikView, SpotFire, etc.', 'Mentor program to help you develop your career', 'Team building and social activities', 'Participate in requirements gathering sessions with business and technical staff to distill technical requirements from business requests.', 'Software engineering best-practices, including version control (Git, TFS, JIRA, etc.) and test driven development', 'Strong SQL development skills', 'Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes.', 'Design, develop, document, and test advanced data systems that bring together data from disparate sources, making it available to data scientists, analysts, and other users using scripting and/or programming languages (Python, Java, C, etc)', 'Competitive salary with performance-based bonus opportunities', ""Bachelor's degree in Computer Science, Software Engineering, MIS or equivalent combination of education and experience "", 'Company Description', 'Competitive salary with performance-based bonus opportunitiesSingle and Family Health Insurance plans, including Dental coverageShort-Term and Long-Term disabilityMatching 401(k)Competitive Paid Time OffTraining and Certification opportunities eligible for expense reimbursementTeam building and social activitiesMentor program to help you develop your career', 'Qualifications', 'Present programming documentation and design to team members and convey complex information in a clear and concise manner.', 'Some of our technologies might include: HDFS, Cassandra, Spark, Java, Scala, Informatica, SQL Server, Oracle, Ab Initio, Kafka.', 'CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace.', 'Collaborate with Quality Assurance resources to debug code and ensure the timely delivery of products.', 'Training and Certification opportunities eligible for expense reimbursement', 'Evaluate structured and unstructured datasets utilizing statistics, data mining, and predictive analytics to gain additional business insights']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Analytics Engineer,Peloton Interactive,"New York, NY",7 hours ago,Over 200 applicants,"['', ""Crain's New York Business"", 'Excellent communication skills, both written and verbal, and the ability to communicate effectively with key stakeholders and technology team', 'High level of precision and attention to detail', '3+ years of full-time work experience as an analytics engineer, data analyst, data engineer or similar', 'Fast Company', 'Experience with system design (e.g. design schemas and tables in data warehouse)', 'Experience with statistical modeling ', 'Identify gaps in data collection and collaborate with product and data engineering on data capture specifications ', 'Define and align KPIs across multiple functional groups (marketing, retail, operations) and business objectives (acquisition, sales, engagement, retention, digital)', 'Highly skilled in SQL, templating languages (such as Jinja), and manipulating multiple data formats (XML, JSON)', 'Hands-on experience with data model development and reporting in data visualization tools such as Looker, Tableau, and familiar with spreadsheet software (Excel, Sheets) ', ' Build Looker data models and modify views / explores to support reporting and analysis Incorporate business logic into query building to transform data and build downstream tables for business analysis; setting up and maintaining the jobs to populate these tables Enhance data pipelines and dashboards to ensure highly accurate and reliable business reporting; make data model and ETL enhancements to improve pipeline efficiency and data quality Identify gaps in data collection and collaborate with product and data engineering on data capture specifications  Diagnose and fix data discrepancies and maintain transparent code to ensure business requirements and consistent ETL logic Work with business partners to define and create reporting dashboards Define and align KPIs across multiple functional groups (marketing, retail, operations) and business objectives (acquisition, sales, engagement, retention, digital) Stay up to date with the latest technologies and trends in data engineering and analytics to improve our existing technology stack ', '.', 'We will ensure that qualified individuals with disabilities are provided a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment', ' 3+ years of full-time work experience as an analytics engineer, data analyst, data engineer or similar Highly skilled in SQL, templating languages (such as Jinja), and manipulating multiple data formats (XML, JSON) Experience with ETL processes to transform data, set up and schedule jobs (DBT, Python, cron) Hands-on experience working with very large datasets, including statistical analyses, data visualization, data mining, and data cleansing/transformation Hands-on experience with data model development and reporting in data visualization tools such as Looker, Tableau, and familiar with spreadsheet software (Excel, Sheets)  Understanding of the strengths and limitations of various analytics tools (Google Analytics, Amplitude, etc.) and how those tools can complement our in-house analytics. You should know when not to reinvent the wheel on reports that can be easily created using external tools Excellent communication skills, both written and verbal, and the ability to communicate effectively with key stakeholders and technology team High level of precision and attention to detail Proactive, self-motivated, and can work independently with strong organizational and time management skills Have familiarity developing, debugging, and deploying infrastructure within AWS or a similar cloud environment Understanding of best practices around marketing, e-commerce and subscription retention KPIs Experience with system design (e.g. design schemas and tables in data warehouse) Experience in data development in one of the following areas: marketing analytics, customer and subscription data modeling, sales and e-commerce, or mobile apps Experience with statistical modeling  ', 'Stay up to date with the latest technologies and trends in data engineering and analytics to improve our existing technology stack', 'Build Looker data models and modify views / explores to support reporting and analysis', 'Responsibilities', 'Understanding of the strengths and limitations of various analytics tools (Google Analytics, Amplitude, etc.) and how those tools can complement our in-house analytics. You should know when not to reinvent the wheel on reports that can be easily created using external tools', 'Have familiarity developing, debugging, and deploying infrastructure within AWS or a similar cloud environment', 'Work with business partners to define and create reporting dashboards', 'Enhance data pipelines and dashboards to ensure highly accurate and reliable business reporting; make data model and ETL enhancements to improve pipeline efficiency and data quality', 'Qualifications', 'About Peloton', 'Understanding of best practices around marketing, e-commerce and subscription retention KPIs', 'Experience in data development in one of the following areas: marketing analytics, customer and subscription data modeling, sales and e-commerce, or mobile apps', 'Hands-on experience working with very large datasets, including statistical analyses, data visualization, data mining, and data cleansing/transformation', 'Incorporate business logic into query building to transform data and build downstream tables for business analysis; setting up and maintaining the jobs to populate these tables', 'Diagnose and fix data discrepancies and maintain transparent code to ensure business requirements and consistent ETL logic', 'Peloton is building the best place for team members from every walk of life to grow their careers. Peloton is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, marital or caregiver, or veteran status. ', 'TIME', 'Experience with ETL processes to transform data, set up and schedule jobs (DBT, Python, cron)', 'Proactive, self-motivated, and can work independently with strong organizational and time management skills']",Entry level,Full-time,Information Technology,"Health, Wellness and Fitness",2020-10-20 12:01:24
Data Engineer - Metrics,Datadog,"Boston, MA",2 hours ago,Be among the first 25 applicants,"['', 'Requirements', 'You are fluent in several programming languages (JVM & otherwise)', 'You enjoy wrangling huge amounts of data and exploring new data sets', ' Build distributed, high-volume data pipelines that power the core Datadog product Do it with Spark, Luigi, Kafka and other open-source technologies Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more Join a tightly knit team solving hard problems the right way Own meaningful parts of our service, have an impact, grow with the company ', 'Do it with Spark, Luigi, Kafka and other open-source technologies', 'Bonus Points', 'You’ve built your own data pipelines from scratch, know what goes wrong, and have ideas for how to fix it', ' You are deeply familiar with Spark and/or Hadoop In addition to data pipelines, you’re also quite good with Kubernetes and cloud technology You’ve built applications that run on AWS You’ve built your own data pipelines from scratch, know what goes wrong, and have ideas for how to fix it ', 'Own meaningful parts of our service, have an impact, grow with the company', ' You have a BS/MS/PhD in a scientific field or equivalent experience You have built and operated data pipelines for real customers in production systems You are fluent in several programming languages (JVM & otherwise) You enjoy wrangling huge amounts of data and exploring new data sets You value code simplicity and performance You want to work in a fast, high growth startup environment that respects its engineers and customers ', 'You want to work in a fast, high growth startup environment that respects its engineers and customers', 'You are deeply familiar with Spark and/or Hadoop', 'About Datadog', 'You Will', 'Build distributed, high-volume data pipelines that power the core Datadog product', 'Join a tightly knit team solving hard problems the right way', 'You have a BS/MS/PhD in a scientific field or equivalent experience', 'You’ve built applications that run on AWS', 'You have built and operated data pipelines for real customers in production systems', 'You value code simplicity and performance', 'Work all over the stack, moving fluidly between programming languages: Scala, Java, Python, Go, and more', 'In addition to data pipelines, you’re also quite good with Kubernetes and cloud technology']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Data Scientist,EvolveAI,New York City Metropolitan Area,8 hours ago,77 applicants,"['', '3+ years experience applying Machine Learning using either Python or R within a commercial environment ', 'Experience with cloud platforms (AWS, Azure, GCP), or Big Data tools (Spark, Hadoop etc.) would be advantageous', ""Bachelor's degree to higher in Mathematics, Computer Science, Statistics or a similar, quantitative discipline"", 'New York', 'Insurance ', ""We're currently working on behalf of a leading insurance company who are looking to expand their Data Science team in New York. In this role, the candidate will apply both classical statistics and Machine Learning across multiple business units. "", 'Full-time ', 'Experience with a number of predictive modelling techniques including logistic regression, time series, forecasting, and optimization ', 'Requirements', 'Experience working within Insurance would be a significant advantage ', ' ', 'Data Scientist ', ""Bachelor's degree to higher in Mathematics, Computer Science, Statistics or a similar, quantitative discipline3+ years experience applying Machine Learning using either Python or R within a commercial environment Experience with a number of predictive modelling techniques including logistic regression, time series, forecasting, and optimization Experience working within Insurance would be a significant advantage Experience with cloud platforms (AWS, Azure, GCP), or Big Data tools (Spark, Hadoop etc.) would be advantageous""]",Mid-Senior level,Full-time,Engineering,Staffing and Recruiting,2020-10-20 12:01:24
Backend Software Engineer,Superpedestrian,"Cambridge, MA",11 hours ago,Be among the first 25 applicants,"['', '3+ years of industry experience building scalable backend services Experience with Python or other scripting languageExperience with Django, Rails, Node or similar web frameworkExperience with RESTful web services, JSONWorking knowledge of database systems such as PostgreSQL, NoSQL (MongoDB)', 'What you can expect in return:', 'Work on improving application performance and bug fixes', 'Experience with RESTful web services, JSON', 'Flexible working hours, casual dress code and unlimited paid vacation.', 'Contribute across the stack on developing web applications, data layers, and back end services. ', 'What you’ll do:', 'Participate in cross-team peer code reviews', 'What we’re looking for:', 'The chance to have your voice heard and help shape Superpedestrian’s future.', '3+ years of industry experience building scalable backend services ', 'A team of awesome, like-minded, driven people that support each other, and mentors from across the top echelons of industry.', 'Experience with Django, Rails, Node or similar web framework', 'Experience with Python or other scripting language', 'Working knowledge of database systems such as PostgreSQL, NoSQL (MongoDB)', 'A team of awesome, like-minded, driven people that support each other, and mentors from across the top echelons of industry.The chance to have your voice heard and help shape Superpedestrian’s future.Flexible working hours, casual dress code and unlimited paid vacation.', 'Unit-test code for robustness, including edge cases, usability and general reliability', 'Experience storing and indexing large scale location data', 'Experience storing and indexing large scale location dataAbility to identify technology that will grow our big data processing capabilitiesExperience working with a developer communityPassion for improving company wide processes leveraging software solutions', 'Participate in Agile Scrum sprint and release planning', 'Experience working with a developer community', 'Even better:', 'Passion for improving company wide processes leveraging software solutions', ' Software Engineer', 'Maintain a database-backed API backend Collaborate with cross-functional teams to define, design and ship new features.Contribute across the stack on developing web applications, data layers, and back end services. Unit-test code for robustness, including edge cases, usability and general reliabilityWork on improving application performance and bug fixesContinuously discover, evaluate, and implement new technologies to maximize development efficiency and application performanceParticipate in cross-team peer code reviewsParticipate in Agile Scrum sprint and release planning', 'Continuously discover, evaluate, and implement new technologies to maximize development efficiency and application performance', 'Collaborate with cross-functional teams to define, design and ship new features.', 'Ability to identify technology that will grow our big data processing capabilities', 'Maintain a database-backed API backend ']",Entry level,Full-time,Engineering,Electrical/Electronic Manufacturing,2020-10-20 12:01:24
"Data Scientist, Analytics",Next Insurance,"Palo Alto, CA",21 hours ago,Over 200 applicants,"['', 'Want to shape the future of insurance through data science? We are looking for a Data Scientist to join the growing data org that has a dedication to diving into data and thinking statistically about business problems and user behaviors. The ideal candidate is excited to own company objectives and guide their team towards success through data-driven decisions. If you have the intuition to identify important analytical questions, the technical ability for complex deep-dives, and the communication skills to help the team turn ideas into action - you belong here!\xa0', 'Work with cross-functional partners to determine the mission of their team, and design the right metrics and targets to communicate this mission', ""One of our core values is 'Play as a Team'; this means making sure everyone has an equal chance to participate and make a difference. We win by playing together. Next Insurance is an equal opportunity employer and prioritizes building a diverse and inclusive workplace. We provide equal employment opportunities to all employees and applicants of any type and do not discriminate based on race, color, religion, national origin, gender, age, sexual orientation, physical or mental disability, genetic information or characteristic, gender identity and expression, veteran status, or other non-job related characteristics or other prohibited grounds specified in applicable federal, state, and local laws. Next's policy is to comply with all applicable laws related to nondiscrimination and equal opportunity and will not tolerate discrimination or harassment based on any of these characteristics. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\xa0"", 'Experience designing experiments, with knowledge of statistics a plus', '\xa0', 'Professional experience in a quantitative analysis role', 'Identify and help prioritize opportunities', 'Ability to communicate clearly and effectively to cross functional partners of varying technical levels', 'Guide the team on experiment design and interpretation', 'What You’ll Do:\xa0', 'Professional experience in a quantitative analysis roleExperience influencing the strategy of a product through analysesComfortable in SQL and some experience with a programming language like Python a plusExperience building clear and easy to understand dashboardsAbility to communicate clearly and effectively to cross functional partners of varying technical levelsAbility to define relevant metrics that can guide and influence stakeholders to the appropriate and accurate insightsExperience designing experiments, with knowledge of statistics a plus', 'Next Insurance is looking for explorers who are filled with curiosity, have the desire to travel the unbeaten path, and realize new heights in providing small business owners with the peace of mind to run their businesses. If you move fast, customer-focused, and willing to challenge the status quo, Next Insurance might just be your next journey.', 'What We Need:\xa0', 'Experience influencing the strategy of a product through analyses', 'Experience building clear and easy to understand dashboards', 'Work with cross-functional partners to determine the mission of their team, and design the right metrics and targets to communicate this missionCreate deep-dive analyses to understand customer, operations, or funnel behaviorIdentify and help prioritize opportunitiesCreate a clear, compelling, and actionable narrative that is based on data-driven insightsBe the connecting link to data engineering to design the right data model, logging, and data-pipeline foundationsDevelop dashboards to track metric progress, understand metric drivers, and answer common business questionsGuide the team on experiment design and interpretation', 'Ability to define relevant metrics that can guide and influence stakeholders to the appropriate and accurate insights', 'Develop dashboards to track metric progress, understand metric drivers, and answer common business questions', 'Be the connecting link to data engineering to design the right data model, logging, and data-pipeline foundations', 'Create deep-dive analyses to understand customer, operations, or funnel behavior', 'Next Insurance is a fast-growing 350+ person startup based in Silicon Valley and is led by a team of experienced entrepreneurs with a history of successful outcomes. Our mission is to transform insurance for small businesses by combining world-class technology and phenomenal customer service to offer better insurance at a lower price. Next has raised over $630 million from top tier investors and is the valley’s latest unicorn, valued at over $2 billion.', 'Comfortable in SQL and some experience with a programming language like Python a plus', 'Create a clear, compelling, and actionable narrative that is based on data-driven insights']",Associate,Full-time,Analyst,Insurance,2020-10-20 12:01:24
"Lead Data Engineer, Analytics",Duetto,"New York, NY",22 hours ago,Be among the first 25 applicants,"['', 'Experience with cloud services from at least one of the major public cloud providers (AWS, GCP, Azure, etc) and knowledge of the role and value each of the multitude of services provide in building a modern data pipeline. ', 'About Duetto', 'Collaborate with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', ' Design and implement the architecture to train, validate and deploy AI/ML pipelines and models at scale. Build the infrastructure required for extraction, transformation, and loading of data from a wide variety of data sources using technologies such as Athena, SQS, parquet files, etc. Build and maintain scalable web services to power real-time responses to analytical queries around forecasting and pricing.  Collaborate closely with data scientists and analysts to automate the processes around cleansing and validating data.  Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Collaborate with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. ', ' BS degree in Computer Science or related technical field 10+ years experience building enterprise grade scalable applications including 3+ years building modern data pipelines and productionizing machine learning models Experience with cloud services from at least one of the major public cloud providers (AWS, GCP, Azure, etc) and knowledge of the role and value each of the multitude of services provide in building a modern data pipeline.  Experience and familiarity of ML/AI pipelines, tools, and architectures that enable the training, validation and deployment at scale of AI based technologies.  Advanced SQL knowledge and experience working with both relational and NoSQL databases such as MongoDB Expert in server side programming languages such as Java and Python.  Strong analytical skills related to working with unstructured datasets. Experience supporting and working with cross-functional teams in a dynamic environment. ', 'Strong analytical skills related to working with unstructured datasets.', 'BS degree in Computer Science or related technical field', 'Desired Skills & Expertise', 'Advanced SQL knowledge and experience working with both relational and NoSQL databases such as MongoDB', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Build the infrastructure required for extraction, transformation, and loading of data from a wide variety of data sources using technologies such as Athena, SQS, parquet files, etc.', '10+ years experience building enterprise grade scalable applications including 3+ years building modern data pipelines and productionizing machine learning models', 'Expert in server side programming languages such as Java and Python. ', 'Collaborate closely with data scientists and analysts to automate the processes around cleansing and validating data. ', 'Design and implement the architecture to train, validate and deploy AI/ML pipelines and models at scale.', 'Experience and familiarity of ML/AI pipelines, tools, and architectures that enable the training, validation and deployment at scale of AI based technologies. ', 'Build and maintain scalable web services to power real-time responses to analytical queries around forecasting and pricing. ']",Associate,Full-time,Information Technology,Information Technology and Services,2020-10-20 12:01:24
Back-end Software Engineer,Ace Info Solutions LLC,"Reston, VA",12 hours ago,Be among the first 25 applicants,"['', ' Highly experienced leading agile projects ', ' Experience working directly with DHS and/or TSA ', 'Requirements', ' 1+ years with OAuth and REST security protocols ', ' Work closely with engineering and QA to manage and improve the development pipeline. ', ' 2+ years with database technologies and modeling ', ' Successful candidates must be a US Citizen and eligible for a Public Trust clearance. ', 'Additional Requirement', ' Develop high quality, shippable code in short increments. ', ' Highly experience with Git source repository use ', ' 1+ years with OpenAPI / Swagger ', ' Ability to communicate ideas in a variety of formats ', ' Define and implement unit and integration tests. ', 'Required Qualifications', ' Design, develop and test enterprise web services API’s and backend services.  Work with product management to translate requirements into technical design and provide LOE estimates.  Define and implement unit and integration tests.  Develop high quality, shippable code in short increments.  Work closely with engineering and QA to manage and improve the development pipeline.  Work closely with security to meet required security controls.  Mentor Junior Developers in Agile and Software Development.  Meet the functional requirements and reduce post-deployment defects and technical debt.  Meets accessibility (Section 508) and performance requirements.  Develop, create, and modify general computer applications software or specialized utility programs.  Analyze user needs and develop software solutions.  Design software or customize software for client use with the aim of optimizing operational efficiency.  May analyze and design databases within an application area, working individually or coordinating database development as part of a team.  Possesses and applies a comprehensive knowledge across key tasks and high impact assignments.  Plans and leads major technology assignments.  Evaluates performance results and recommends major changes affecting short- term project growth and success. ', ' Ability to analyze someone else’s code and assume ownership ', ' 5+ years OO Development, with a strong focus on microservices and enterprise Java applications ', ' DevOps CI/CD pripelines using Jenkins and/or Azure DevOps ', ' Develop, create, and modify general computer applications software or specialized utility programs. ', ' Perform code reviews & create unit tests ', ' Work closely with security to meet required security controls. ', ' Mentor Junior Developers in Agile and Software Development. ', 'Preferred Qualifications', ' 1+ years with Containers/Docker ', ' Work with product management to translate requirements into technical design and provide LOE estimates. ', ' Highly experienced with integration of React framework and backend services ', ' 1+ years experience with cloud based deployment (Azure) ', ' Meet the functional requirements and reduce post-deployment defects and technical debt. ', 'Duties & Responsibilities', ' Meets accessibility (Section 508) and performance requirements. ', ' Design, develop and test enterprise web services API’s and backend services. ', ' 2+ years with Agile development / Scrum ', ' Possesses and applies a comprehensive knowledge across key tasks and high impact assignments. ', ' Experience working directly with DHS and/or TSA  Bachelor’s or advanced degree, preferably in Computer Science or Engineering disciplines  5+ years OO Development, with a strong focus on microservices and enterprise Java applications  2+ years with database technologies and modeling  2+ years with Agile development / Scrum  1+ years with OAuth and REST security protocols  1+ years with OpenAPI / Swagger  1+ years with Containers/Docker  1+ years experience with cloud based deployment (Azure)  DevOps CI/CD pripelines using Jenkins and/or Azure DevOps  Eclipse, IntelliJ or similar IDE ', ' Design software or customize software for client use with the aim of optimizing operational efficiency. ', ' Bachelor’s or advanced degree, preferably in Computer Science or Engineering disciplines ', ' Plans and leads major technology assignments. ', ' Ability to manage multiple tasks with varying priorities ', ' Highly experienced with Java, Spring Boot, REST, microservices, JSON/XML, Apache Maven  Highly experienced with integration of React framework and backend services  Highly experienced leading agile projects  Highly experience with Git source repository use  Ability to analyze someone else’s code and assume ownership  Perform code reviews & create unit tests  Discipline to document your own code  Ability to manage multiple tasks with varying priorities  Ability to communicate ideas in a variety of formats ', ' Analyze user needs and develop software solutions. ', ' Highly experienced with Java, Spring Boot, REST, microservices, JSON/XML, Apache Maven ', ' Evaluates performance results and recommends major changes affecting short- term project growth and success. ', ' Eclipse, IntelliJ or similar IDE ', ' Discipline to document your own code ', ' May analyze and design databases within an application area, working individually or coordinating database development as part of a team. ']",Entry level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
Senior Software Engineer,Association of American Medical Colleges (AAMC),"Washington, DC",18 hours ago,Be among the first 25 applicants,"['', 'Identify, develop and maintain reusable application platform level componentsSet governance and provide guidance to the managed services provider.', ""A Bachelor's degree in Computer Science, Information Systems Management, or related field is required; a Master's degree is preferred."", 'Experience in a highly collaborative team culture following Agile Methodology', 'Proven experience working with technologies such as Java/J2EE, Spring MVC Framework and JPA / Hibernate, Angular, AngularJS, Oracle RDBMS, Maven, JUnit, Git, JIRA and Atlassian Bamboo, SOAP and JSON and RESTful web services', 'Experience working in a tool agnostic environment with the ability to transition between multiple technologies to accomplish tasks', 'Who We Are', 'The Association of American Medical Colleges (AAMC) is an Equal Opportunity/Affirmative Action Employer. The AAMC is committed to the policy of an equal employment opportunity in recruitment, hiring, career advancement, and all other personnel practices. The AAMC will not discriminate on the basis of race, color, sex, national origin, religion, age, marital status, personal appearance, sexual orientation, gender identity or expression, family responsibilities, matriculation, political affiliation, genetic information, disability, past or current military service, or any other legally protected characteristic.', 'Contribute to the technical leadership and direction for AAMC application development team ', 'Provide technical and business explanation and justification for architectural, design, and coding approaches', ""A Bachelor's degree in Computer Science, Information Systems Management, or related field is required; a Master's degree is preferred.5-7 year’s work experienceProven experience working with technologies such as Java/J2EE, Spring MVC Framework and JPA / Hibernate, Angular, AngularJS, Oracle RDBMS, Maven, JUnit, Git, JIRA and Atlassian Bamboo, SOAP and JSON and RESTful web servicesGood understanding of microservice architecture, messaging service/integration-patterns (RESTful/SOAP APIs, JMS/SQS) Experience with: Java/J2EEExperience working in a Linux environmentExperience working in a tool agnostic environment with the ability to transition between multiple technologies to accomplish tasksExperience in a highly collaborative team culture following Agile MethodologyShowcase a problem-solving attitude with a strong work ethicExperience with Messaging queues such as AMQ, Splunk, New Relic monitoring, AWS RDS, Postgres is highly desired"", ' Investigate customer support escalation issues', 'Good understanding of microservice architecture, messaging service/integration-patterns (RESTful/SOAP APIs, JMS/SQS) ', 'Please attach a resume as part of the application process. It is important that files DO NOT include periods ( . ) within the file name.', 'Provide development estimates outlining business and technical risks.', 'Experience with Messaging queues such as AMQ, Splunk, New Relic monitoring, AWS RDS, Postgres is highly desired', 'Provide technical support during key AAMC operational eventsAssess all network devices in the environment and data center, and determine if upgrades are required to software and/or hardware in order to be compliant and standard across the environments.', 'If a bachelor’s degree is required, related work experience may be substituted in some positions. One year of college course work at an accredited institution is equivalent to one year of related work experience.', 'Determine and develop integrated solutions to support, maintain and enhance continuing operations of business systems', 'Provide technical leadership and mentoring for junior team members', '5-7 year’s work experience', 'How will you make an impact?', 'Experience with: Java/J2EE', 'What will you bring?', 'Provide development estimates outlining business and technical risks.Provide technical and business explanation and justification for architectural, design, and coding approachesProvide technical leadership and mentoring for junior team membersDetermine and develop integrated solutions to support, maintain and enhance continuing operations of business systemsDevelopment/maintenance and defect resolution of code. Identify, develop and maintain reusable application platform level componentsSet governance and provide guidance to the managed services provider. Investigate customer support escalation issuesProvide technical support during key AAMC operational eventsAssess all network devices in the environment and data center, and determine if upgrades are required to software and/or hardware in order to be compliant and standard across the environments.Collaborate heavily with fellow architects, business analysts, developers, designers and analysts to solve problems . Contribute to the technical leadership and direction for AAMC application development team ', 'BROWSER REQUIREMENTS: Applications must be submitted using Chrome, Mozilla Firefox, Safari, or Internet Explorer v.10 or higher.', 'Showcase a problem-solving attitude with a strong work ethic', 'Development/maintenance and defect resolution of code. ', 'Experience working in a Linux environment', 'Collaborate heavily with fellow architects, business analysts, developers, designers and analysts to solve problems . ']",Associate,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
"C++ Software Engineer, Trading Platform (Fixed Income)",Thurn Partners,"New York, United States",7 hours ago,Be among the first 25 applicants,"['', 'Improve execution by working collaboratively with high-caliber front office traders and strategists.', 'Proven proficiency in programming and problem solving in C++ for Linux.Undergraduate or Advanced STEM Degree.Knowledge of end to end software and the best practices of SDLC.Excellent analytical and problem-solving skills.Outstanding communication and teamwork skills in order to relate to Engineers, Traders, Quantitative Analysts.Ambition in order to manage (and enjoy managing) multiple projects in a fast-paced environment.', ""Please do not apply if you're looking for a contract."", '\xa0', 'Knowledge of end to end software and the best practices of SDLC.', 'Your application is subject to our privacy policy, found here: https://www.thurnpartners.com/privacy-policy', 'Ambition in order to manage (and enjoy managing) multiple projects in a fast-paced environment.', ""Shape the end to end design and implement trading, order management and execution management systems for fixed income products and in doing so improve the company's cost efficiency."", 'Undergraduate or Advanced STEM Degree.', ""Shape the end to end design and implement trading, order management and execution management systems for fixed income products and in doing so improve the company's cost efficiency.Create your very own Rates and FX execution algorithms to reduce trade cost and improve Profit and Loss, whilst also sustaining pre-existing algorithms.Improve execution by working collaboratively with high-caliber front office traders and strategists.Grow real-time trading system components to support new products and untried execution styles."", 'Please ensure you meet the required experience section prior to applying.', ""Please do not apply if you're looking for a contract.You must be eligible to live and work in the US, without requiring sponsorship.Please ensure you meet the required experience section prior to applying.Allow 1-5 working days for a response to any job enquiry.Your application is subject to our privacy policy, found here: https://www.thurnpartners.com/privacy-policy"", 'Required Experience/Skills:', 'Further Context:', 'Create your very own Rates and FX execution algorithms to reduce trade cost and improve Profit and Loss, whilst also sustaining pre-existing algorithms.', ""The company's values of teamwork and collaboration results in a close-nit team who constantly challenge one another in positive ways."", 'Grow real-time trading system components to support new products and untried execution styles.', 'The company is sustained by its culture of excellence – they aim to improve and learn constantly, forever trying to streamline and better their investment processes for more ambitious returns.', 'Excellent analytical and problem-solving skills.', 'Outstanding communication and teamwork skills in order to relate to Engineers, Traders, Quantitative Analysts.', 'You must be eligible to live and work in the US, without requiring sponsorship.', 'Proven proficiency in programming and problem solving in C++ for Linux.', ""The company is sustained by its culture of excellence – they aim to improve and learn constantly, forever trying to streamline and better their investment processes for more ambitious returns.The company's values of teamwork and collaboration results in a close-nit team who constantly challenge one another in positive ways.If you are up to the challenge, a highly competitive salary and a comprehensive benefits package awaits you. Please enquire for more details."", 'Pre-Application:', 'Company Insight:', 'Allow 1-5 working days for a response to any job enquiry.', 'If you are up to the challenge, a highly competitive salary and a comprehensive benefits package awaits you. Please enquire for more details.', 'The company is a world leading multi-strategy hedge fund which practices unique and highly profitable strategies in the US and European markets. It combines extraordinary research, predictive analytics and cutting-edge technology to produce unrivalled investment returns for its investment partners. It exercises an exceptional, cohesive investment process across strategies leveraging quantitative analytics, economic analysis, and algorithm construction techniques. As it continues to grow its impressive investment reputation, the company is looking to enhance the efficiency and competency of its trading systems.', 'Your Role:']",Director,Full-time,Finance,Capital Markets,2020-10-20 12:01:24
Software Engineer,Oracle,"Seattle, WA",18 hours ago,100 applicants,"['', '2+ years experience delivering and operating large scale, highly available distributed systems.', 'Job', 'Work across teams to engineer the best system (both for operations and for customers) regardless of org boundaries or ownership.', 'Software Engineer, Oracle Container Engine Department Description', 'History of working in large codebases in C/C++, C#, Java, or Go, and experience with scripting languages such as Python, Perl, etc.', 'Experience building multi-tenant, virtualized infrastructure a strong plus.', 'Position Overview', 'Debug, maintain and improve existing systems, with a focus especially for reducing operational burden and on performance.', 'Oracle is an Affirmative Action-Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veterans status, age, or any other characteristic protected by law.', 'Location', 'Strong knowledge of data structures, algorithms, operating systems, and distributed systems fundamentals.', 'Responsibilities', ' Qualifications ', 'Job Type', ' BS degree in Computer Science or related technical field involving coding or equivalent practical experience. 2+ years experience delivering and operating large scale, highly available distributed systems. History of working in large codebases in C/C++, C#, Java, or Go, and experience with scripting languages such as Python, Perl, etc. Strong knowledge of data structures, algorithms, operating systems, and distributed systems fundamentals. Systematic problem-solving approach, strong communication skills, a sense of ownership and drive. Experience building multi-tenant, virtualized infrastructure a strong plus. ', 'Scale our systems by building tooling and automation.', 'Architect and design new features and systems for our customers.', 'Travel', 'Organization', 'BS degree in Computer Science or related technical field involving coding or equivalent practical experience.', 'Work with partner teams outside our org and external to Oracle.', ' Architect and design new features and systems for our customers. Work across teams to engineer the best system (both for operations and for customers) regardless of org boundaries or ownership. Debug, maintain and improve existing systems, with a focus especially for reducing operational burden and on performance. Be a generalist, able to debug issues across a wide breadth of our stack. Scale our systems by building tooling and automation. Work with partner teams outside our org and external to Oracle. ', 'Be a generalist, able to debug issues across a wide breadth of our stack.', 'Other Locations', 'Systematic problem-solving approach, strong communication skills, a sense of ownership and drive.']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-10-20 12:01:24
Python Data Engineer | Elite Hedge Fund,Selby Jennings,"New York, NY",,N/A,"['', 'Salary: $150,000 – $300,000+ ', '2+ years of experience in Data/Software Engineering, Data Science, or a related field\xa0 Solid understanding of computer science fundamentals, data structures, algorithms, distributed systems, etc. Strong programming background with Python ideally Experience with Big Data/Data Pipelining technologies (ex: Spark, Airflow, Kafka, etc.) Strong problem solving and communication skills Interest in working in a fast-paced/high-impact environment BS, MS, or PhD in Computer Science or related field', '2+ years of experience in Data/Software Engineering, Data Science, or a related field\xa0 ', 'Partner with Traders, Quants, Researchers, and Data Scientists to solve their critical data problems ', 'Strong problem solving and communication skills ', 'Python Data Engineer |  Elite Hedge Fund  ', 'Salary: ', 'Strong programming background with Python ideally ', 'Build/own the firms data pipelines Build data processing/analytics tools for research and trading Partner with Traders, Quants, Researchers, and Data Scientists to solve their critical data problems ', 'BS, MS, or PhD in Computer Science or related field', 'Solid understanding of computer science fundamentals, data structures, algorithms, distributed systems, etc. ', 'Experience with Big Data/Data Pipelining technologies (ex: Spark, Airflow, Kafka, etc.) ', 'Build data processing/analytics tools for research and trading ', '\xa0 ', 'Build/own the firms data pipelines ', 'NYC Based Hedge Fund is looking for Data Engineers to join their team ', 'Interest in working in a fast-paced/high-impact environment ', 'Responsibilities: ', ' ']",Mid-Senior level,Full-time,Information Technology,Financial Services,2020-10-20 12:01:24
"Data Engineer - San Francisco, CA or Cupertino, CA",U.S. Bank,"San Francisco, CA",10 hours ago,Be among the first 25 applicants,"['', ' Contributing back to open source community on the new features', 'Job', ' Strong in theoretical foundations and practical knowledge analytical & SQL engines such as Presto, Druid, SparkSQL, Blazing SQL, Dremio and Apache Arrow', ' Familiarity with visualization tools', ' Full Stack development experience – CI/CD process, Automated testing etc.', ' Familiarity on authentication, authorization and hive metastore', ' Leading complex technology performance testing & architecture evaluations & driving complex technology programs in cutting edge domains', ' Familiarity with open-source software development and community', 'Preferred Skills/Experience', 'Shift', ' Familiarity with increasing the performance of database systems with hardware enhancements – GPU, memory etc.', ' Solid experience in programming languages – Java, Python', ' Solid experience in programming languages – Java, Python Experience in creating REST API using Spring Framework Strong background in database systems – SQL engine, Strong background in distributed systems and cloud concepts (Kubernetes Full Stack development experience – CI/CD process, Automated testing etc. Strong in theoretical foundations and practical knowledge analytical & SQL engines such as Presto, Druid, SparkSQL, Blazing SQL, Dremio and Apache Arrow Familiarity on authentication, authorization and hive metastore Familiarity with high performance storage systems (cloud, open source etc.) Familiarity with open-source software development and community Familiarity with increasing the performance of database systems with hardware enhancements – GPU, memory etc. Familiarity with visualization tools At least bachelors in computer science from reputed university and masters preferred', ' Contribute towards enhancing the performance of database systems in terms on response time, throughput, CPU utilization etc.', ' Contribute towards elastically scaling the database systems in the public cloud', ' Three to five years of relevant experience', ' Making significant contributions in delivering the engineering build-out of SQL, OLAP (database systems) and visualization engines Leading complex technology performance testing & architecture evaluations & driving complex technology programs in cutting edge domains Contribute towards elastically scaling the database systems in the public cloud Contribute towards enhancing the performance of database systems in terms on response time, throughput, CPU utilization etc. Contributing back to open source community on the new features', 'Responsibilities', "" Bachelor's degree, or equivalent work experience"", 'Average Hours Per Week', ' Strong background in distributed systems and cloud concepts (Kubernetes', ' At least bachelors in computer science from reputed university and masters preferred', ' Making significant contributions in delivering the engineering build-out of SQL, OLAP (database systems) and visualization engines', 'Travel', ' Experience in creating REST API using Spring Framework', ' Strong background in database systems – SQL engine,', 'Primary Location', "" Bachelor's degree, or equivalent work experience Three to five years of relevant experience"", ' Familiarity with high performance storage systems (cloud, open source etc.)', 'Other Locations', 'Basic Qualifications']",Entry level,Full-time,Information Technology,Staffing and Recruiting,2020-10-20 12:01:24
Java Software Engineer ,Eaton,"Rockville, MD",13 hours ago,Be among the first 25 applicants,"['', 'Required (Basic) Qualifications: ', 'Travel: Yes, 10 % of the Time', 'Full range of development including new features, bug fixes, refactoring, optimization, and testing.', 'Bachelor’s degree or higher from an accredited institution to be completed by December 2020. ', 'Job: Engineering', 'Experience/coursework in Java technologies', 'Experience with Spring MVC, ActiveMQ, IPv6, DNS, and SQL preferred.', 'Must be able to work in the United States without corporate sponsorship now and in the future', 'Work closely with all team members (including software, firmware, QA, customer service, and marketing).', 'Experience translating business requirements into technical design.', 'Contribute to our product’s continuous improvement by building great solutions and engaging in code reviews and technical discussions with entire development team.', 'Schedule: Full-time', 'Job Level: Individual Contributor', 'In This Function You Will', 'Understanding of typical software architectures, object-oriented programming, and best practices for software development.', ' Experience translating business requirements into technical design. Understanding of typical software architectures, object-oriented programming, and best practices for software development. Experience with Spring MVC, ActiveMQ, IPv6, DNS, and SQL preferred. Experience with standard development tools and libraries preferred (Eclipse, Subversion or Git, SQL Server, Oracle, Spring, Tomcat, Jenkins, JIRA, BitBucket, vSphere). Ability to communicate with multiple groups including marketing, product management, and quality. Knowledge and implementation experience on energy or industrial automation solutions a plus. ', 'Ability to communicate with multiple groups including marketing, product management, and quality.', 'Experience with standard development tools and libraries preferred (Eclipse, Subversion or Git, SQL Server, Oracle, Spring, Tomcat, Jenkins, JIRA, BitBucket, vSphere).', ' Ability to travel up to 10% Ability to work with geographically dispersed teams. Proven analytical and problem-solving skills. Effective oral and written communication skills as well as planning and organizational skills. ', 'Preferred Qualifications', 'Position Overview', 'Develop enterprise software solutions in a Java/J2EE environment primarily using Spring Core, Spring MVC.', 'Proven analytical and problem-solving skills.', 'Effective oral and written communication skills as well as planning and organizational skills.', 'No relocation benefit is being offered for this position. Only candidates within a 50-mile radius of Rockville, MD will be considered. Active Duty Military Service member candidates are exempt from the geographical area limitation.', 'Is remote work (i.e. working from home or another Eaton facility) allowed for this position?: No', 'Position Criteria', 'Develop enterprise software solutions in a Java/J2EE environment primarily using Spring Core, Spring MVC.Full range of development including new features, bug fixes, refactoring, optimization, and testing.Work on a fast-paced and dynamic scrum team following Agile design framework (sprints, stand-ups, time estimation, work breakdown).Utilize experience and research to implement best-practices, determine appropriate technologies and design patterns, and identify/mitigate risksContribute to our product’s continuous improvement by building great solutions and engaging in code reviews and technical discussions with entire development team.Investigate critical customer support issues and propose creative solutions. Analyze Java Heap dumps, memory allocation, deadlocks, and threading.Work closely with all team members (including software, firmware, QA, customer service, and marketing).', 'Does this position offer relocation?: No', 'Qualifications', 'Ability to work with geographically dispersed teams.', 'Work on a fast-paced and dynamic scrum team following Agile design framework (sprints, stand-ups, time estimation, work breakdown).', 'Minimum of an internship/coop completed during undergrad', ' Bachelor’s degree or higher from an accredited institution to be completed by December 2020.  Minimum of an internship/coop completed during undergrad Experience/coursework in Java technologies Must be able to work in the United States without corporate sponsorship now and in the future No relocation benefit is being offered for this position. Only candidates within a 50-mile radius of Rockville, MD will be considered. Active Duty Military Service member candidates are exempt from the geographical area limitation. ', 'Region: North America – US/Puerto Rico', 'Investigate critical customer support issues and propose creative solutions. Analyze Java Heap dumps, memory allocation, deadlocks, and threading.', 'Ability to travel up to 10%', 'Organization: EPG EAS Electrical Automation Solutions', 'Knowledge and implementation experience on energy or industrial automation solutions a plus.', 'Utilize experience and research to implement best-practices, determine appropriate technologies and design patterns, and identify/mitigate risks', 'Eaton’s Electrical Automation Solutions Division is currently seeking a Java Software Engineer to join our team. This position is based at our Rockville, MD site. ']",Mid-Senior level,Full-time,Engineering,Electrical/Electronic Manufacturing,2020-10-20 12:01:24
Data Engineer,RingCentral,"Belmont, CA",22 hours ago,Be among the first 25 applicants,"['', 'Now, a little more about us... We:', 'RingCentral is headquartered in Belmont, California and has offices around the world.', 'Data Engineer: (Belmont, Denver, or remote)', 'Programming ( Java, Python, Groovy )\xa0', 'Experience with Kubernetes, Docker, Kafka, Redis, Hazelcast', ""As a member of the RingCentral Cloud Operations Data Operations Team, you'll will be part of the team that is responsible for building out the architecture for data ingestion. You will take responsibility for all things related to system maintenance, application support, deployment and pipeline engineering and support."", '\xa0', 'What we’re looking for', 'Architecting, Design, Building, Supporting systems for data ingestion\xa0', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Qualifications for a Data Engineer', 'B.S in\xa0 Computer Science etc. plus\xa0 2-3\xa0 years of experienceExperience with\xa0 management data pipelines/big data tools:\xa0 StreamSets, Airflow, ELK etcExperience with one of AWS/Google public cloudsProgramming experience (at least one): Python, Java, etcNice to have devops experience: Ansible, Jenkins, Chef etcNice to have Anomaly Detection/Machine Learning experience\xa0Nice to have Telecom backgroundAbility to work in very diverse multicultural environmentGood communication skillsGood team player with self-starter ability', 'RingCentral surrounds you with world-class technology and talent, in a people-first environment built from the ground up to help you do the best work of your career. We’re not just changing the nature of communication and teamwork. We’re winning, together.', 'RingCentral is an equal opportunity employer that truly values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.', 'Ability to create and maintain data pipelines', 'The RingCentral environment is fast paced, high octane, success driven, team oriented, and is committed to growing the business in a virtually untapped market. We’re looking for awesome individuals like you to join us!\xa0', ""RingCentral's cloud-based communications platform connects more than 2 million users around the world, in ways that bring people, ideas, companies and customers together."", 'Nice to have Anomaly Detection/Machine Learning experience\xa0', 'Nice to have Telecom background', 'Architecting, Design, Building, Supporting systems for data ingestion\xa0Work with a cross functional team of engineers, analysts and scientist to understand business requirementsDesign and build data pipelines from various sources to data warehouse.\xa0Documenting architecture, systems, and pipelines.\xa0Documenting database design including data modeling, metadata and process flow diagrams.', 'What if you had the freedom of a startup and the resources of a global enterprise?', 'Work with a cross functional team of engineers, analysts and scientist to understand business requirements', 'Programming experience (at least one): Python, Java, etc', 'Responsibilities for Data Engineer', 'We’re as proud of our working environment as we are of our market success. You’ll find all the training, opportunity and resources you could ever want here - with all the work/life benefits you expect, and none of the micromanagement. RingCentral regularly brings home Best Place To Work awards from locations all over the world, and outstanding company ratings on Glassdoor and Comparably!', 'Good team player with self-starter ability', '4+ years of Application Administration experience', 'Good communication skills', 'Has experience with NOSQL ( Elastic, Clickhouse )\xa0', 'That’s exactly the kind of environment we’re building together at RingCentral.', 'We are looking to hire a Data Engineer to join our Data Operations team. You will be part of the team that is responsible for building out the architecture for ingestion. You will take responsibility for all things related to system maintenance, application support, deployment and pipeline engineering and support. This includes learning and understanding upstream processes, pipelines and source systems. The role will work in conjunction with other cross functional teams to help derive analytics and dashboards. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.', 'Experience with\xa0 management data pipelines/big data tools:\xa0 StreamSets, Airflow, ELK etc', 'Experience with one of AWS/Google public clouds', '·', 'Ability to work in very diverse multicultural environment', 'Are a high energy with a great mix of experienced entrepreneurs, talented engineers, dynamic sales and operations and marketing professionals.', 'Has experience with ANSI SQL\xa0', 'RingCentral', 'You’d break new ground. Raise the bar for performance. And do career-defining work.\xa0', 'RingCentral is an Equal Opportunity Employer.', 'Nice to have devops experience: Ansible, Jenkins, Chef etc', 'About RingCentral', 'RingCentral is the worldwide leader in cloud-based communications. Our software communications platform delivers phone, group chat, mobile communications, video calls, videoconference, contact center and AI-driven digital engagement. It’s a powerful, global presence that allows businesses to communicate anywhere, anytime with anyone.', '4+ years Systems Administration experience4+ years of Application Administration experienceExperience with Kubernetes, Docker, Kafka, Redis, HazelcastProgramming ( Java, Python, Groovy )\xa0Has experience with ANSI SQL\xa0Has experience with NOSQL ( Elastic, Clickhouse )\xa0Ability to create and maintain data pipelinesBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sourcesParticipate in on-call rotation to support data pipelines and tools', 'Are gurus at multi-tasking and work in a very fast-paced environment.Are a high energy with a great mix of experienced entrepreneurs, talented engineers, dynamic sales and operations and marketing professionals.We don’t do laundry or provide house-cleaning services as we promote work-life balance but we do stock the kitchen with complimentary beverages, snacks, and provide lunch and breakfast goodies.', 'Design and build data pipelines from various sources to data warehouse.\xa0', ' RingCentral Cloud Operations Data Operations Team', 'Documenting architecture, systems, and pipelines.\xa0', '4+ years Systems Administration experience', 'What if you could support the solutions that will change the way the world communicates?\xa0', 'Are gurus at multi-tasking and work in a very fast-paced environment.', 'B.S in\xa0 Computer Science etc. plus\xa0 2-3\xa0 years of experience', 'We don’t do laundry or provide house-cleaning services as we promote work-life balance but we do stock the kitchen with complimentary beverages, snacks, and provide lunch and breakfast goodies.', 'Participate in on-call rotation to support data pipelines and tools', 'Documenting database design including data modeling, metadata and process flow diagrams.']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-10-20 12:01:24
"Data Engineer Developer/Sr Developer , IT Applications",American Airlines,"Fort Worth, TX",9 hours ago,Be among the first 25 applicants,"['', 'Feel Free to be yourself at American', 'Strong problem-solving ability with a positive ""can-do"" attitude', "" Master's degree in Computer Science, Computer Engineering, Technology, Information Systems (CIS/MIS), Engineering or related technical discipline, or equivalent experience/training5yrs of experience in data warehouse development including framework and application solutions leveraging DataStage and TeradataExperience in Big Data development including Python, Spark, Scala, ParquetExperience in Cloud; IBM or AzureAirline Industry experience"", 'Preferred Qualifications- Education & Prior Job Experience', 'Health Benefits: On day one, you’ll have access to your health, dental, prescription and vision benefits to help you stay well. And that’s just the start, we also offer virtual doctor visits, flexible spending accounts and more. ', 'Interact with business and technologies peers', "" Bachelor's degree in Computer Science, Computer Engineering, Technology, Information Systems (CIS/MIS), Engineering or related technical discipline, or equivalent experience/training"", 'Success in this role is defined by the ability to leverage strong data application skills to open new capabilities being defined by our business community. You will collaborate with our business partners, fellow developers, and platform architects to achieve these', 'Experience in Cloud; IBM or Azure', 'Airline Industry experience', ""All you'll need for success"", 'Experience in Agile methodologies, such as SCRUM', 'Experience delivering data solutions for, or within, an analytic or business intelligence environment', 'Contribute to continuous improvement of On Premise Datawarehouse and BigData applications and the Cloud applications', 'DevOps CI/CD using Jenkins or other competing tools in the market', 'Experience in DevOps Toolchain methodologies, including Continuous Integration and Continuous Deployment', 'Additional Benefits: Other great benefits include our Employee Assistance Program, pet insurance and discounts on hotels, cars, cruises and more', "" Bachelor's degree in Computer Science, Computer Engineering, Technology, Information Systems (CIS/MIS), Engineering or related technical discipline, or equivalent experience/training3 years of SQL experienceExperience delivering data solutions for, or within, an analytic or business intelligence environmentGood Unix scripting skillsSource code management in Git or Subversion"", 'Develop, code, test, and implement data solutions according to business requirements', ""Why you'll love this job"", 'Design job/jobstream flows via scheduling tool, ensuring proper dependencies within enterprise schedules', ""What You'll Get"", '5yrs of experience in data warehouse development including framework and application solutions leveraging DataStage and Teradata', 'Demonstrated achievement in developing analytical data layers/applications with large data volume', 'A passion for technology, continuous improvement, quality and helping others grow', 'Experience in Big Data development including Python, Spark, Scala, Parquet', 'Wellness Programs: We want you to be the best version of yourself - that’s why our wellness programs provide you with all the right tools, resources and support you need.', 'Minimum Qualifications- Education & Prior Job Experience', 'The role of the Developer, IT Applications will be to translate business requirements into solutions enabling business value in areas which may include analytics, data pipelines, and complex batch processing of airline commercial data. ', '3 years of SQL experience', 'Source code management in Git or Subversion', 'Be accountable for application performance monitoring and tuning', 'Provide assistance and resolution for any production related issues', 'Skills, Licenses & Certifications', 'Provide appropriate estimates on development tasks and capacity requirements', 'Proficiency in object-oriented design techniques and principles', 'Complete source to target mappings', ""What You'll Do"", 'Interpret business data and data access requirements', 'Intro', 'This position is a member of the Information Technology Team, within the RPT Commercial Data Engineering & Business Analytics group supporting Revenue Management Product.The role of the Developer, IT Applications will be to translate business requirements into solutions enabling business value in areas which may include analytics, data pipelines, and complex batch processing of airline commercial data. Success in this role is defined by the ability to leverage strong data application skills to open new capabilities being defined by our business community. You will collaborate with our business partners, fellow developers, and platform architects to achieve these', 'This position is a member of the Information Technology Team, within the RPT Commercial Data Engineering & Business Analytics group supporting Revenue Management Product.', 'Proficiency in Microsoft Office Tools (Project, Excel, Word, PowerPoint, etc.)', "" Master's degree in Computer Science, Computer Engineering, Technology, Information Systems (CIS/MIS), Engineering or related technical discipline, or equivalent experience/training"", 'Works in conjunction with Product Owner and Agile team', 'Travel Perks: Ready to explore the world? You, your family and your friends can reach 365 destinations on more than 6,800 daily flights across our global network.', 'Works in conjunction with Product Owner and Agile teamInteract with business and technologies peersInterpret business data and data access requirementsProvide appropriate estimates on development tasks and capacity requirementsComplete source to target mappingsDevelop, code, test, and implement data solutions according to business requirementsDesign job/jobstream flows via scheduling tool, ensuring proper dependencies within enterprise schedulesProvide assistance and resolution for any production related issuesBe accountable for application performance monitoring and tuningContribute to continuous improvement of On Premise Datawarehouse and BigData applications and the Cloud applicationsDevelop POC’s when necessary', '401(k) Program: Available upon hire and, depending on the workgroup, employer contributions to your 401(k) program are available after one year.', 'Demonstrated achievement in developing analytical data layers/applications with large data volumeStrong problem-solving ability with a positive ""can-do"" attitudeDevOps CI/CD using Jenkins or other competing tools in the marketA passion for technology, continuous improvement, quality and helping others growProficiency in object-oriented design techniques and principlesProficiency in Microsoft Office Tools (Project, Excel, Word, PowerPoint, etc.)Experience in Agile methodologies, such as SCRUMExperience in DevOps Toolchain methodologies, including Continuous Integration and Continuous Deployment', 'Good Unix scripting skills', 'Develop POC’s when necessary', 'Travel Perks: Ready to explore the world? You, your family and your friends can reach 365 destinations on more than 6,800 daily flights across our global network.Health Benefits: On day one, you’ll have access to your health, dental, prescription and vision benefits to help you stay well. And that’s just the start, we also offer virtual doctor visits, flexible spending accounts and more. Wellness Programs: We want you to be the best version of yourself - that’s why our wellness programs provide you with all the right tools, resources and support you need.401(k) Program: Available upon hire and, depending on the workgroup, employer contributions to your 401(k) program are available after one year.Additional Benefits: Other great benefits include our Employee Assistance Program, pet insurance and discounts on hotels, cars, cruises and more']",Not Applicable,Full-time,Information Technology,Airlines/Aviation,2020-10-20 12:01:24
Business Intelligence / Data Visualization Engineer #160306,Credit Suisse,"Raleigh, NC",20 hours ago,Be among the first 25 applicants,"['Client facing experience who can quickly trouble shoot and adopt standard practices to positively impact customer experience', 'We Offer', ' Detailed understanding of Architectural concepts (ie Scaling, caching, etc) and how to interpret and turn functional and non-functional specifications into design solutions ', ' Good in writing/tuning medium to complex SQL queries on any database preferably Oracle/ Sybase. ', 'Experience with any of the following NPrinting, VizLib, Narrative Science', 'Preferred', 'You Offer', ' Experience with any of the following NPrinting, VizLib, Narrative Science ', ' Familiar operating and delivering within a DevOps framework ', 'Detailed understanding of Architectural concepts (ie Scaling, caching, etc) and how to interpret and turn functional and non-functional specifications into design solutions', 'Experience with Unix, Python, and/or Javascript/Angular JS', 'Manage the strategic visualization platforms assisting with client onboarding and configurations.', 'Practical experience designing intuitive, interactive, and effective reports, dashboards, and visualizations', ' Experience configuring reports to support real time reporting requirements  ', 'Understands the value of diversity in the workplace and is dedicated to fostering an inclusive culture in all aspects of working life so that people from all backgrounds receive equal treatment, realize their full potential and can bring their full, authentic selves to work. This should be further elaborated on in your application.', ' Agile Certified and working experience in Agile Projects  ', 'Exposure to various business areas within the bank and opportunity to assist in innovations and POCs.', 'Coordinate closely with business analysts or users, working in an agile process, to manage the visualization (reports, dashboards, etc.) requirements, defining goals and deliver solutions.', 'Experience with Hadoop or similar distributed data platforms', ' Practical experience designing intuitive, interactive, and effective reports, dashboards, and visualizations ', 'Familiar operating and delivering within a DevOps framework', ' Experience with Hadoop or similar distributed data platforms ', 'Essential', ' Experience with Unix, Python, and/or Javascript/Angular JS Hand on experience with visualization tools like Qlik Sense or Tableau ', ' 5-10 years of experience working with Business Intelligence/data visualization tools is essential  ', 'Experience configuring reports to support real time reporting requirements ', 'Understands data analysis, data profiling and documenting/population of a data sources ', 'Hand on experience with visualization tools like Qlik Sense or Tableau', 'Agile Certified and working experience in Agile Projects ', 'Good in writing/tuning medium to complex SQL queries on any database preferably Oracle/ Sybase.', ' Client facing experience who can quickly trouble shoot and adopt standard practices to positively impact customer experience ', ' Understands data analysis, data profiling and documenting/population of a data sources  ', ' Understands the value of diversity in the workplace and is dedicated to fostering an inclusive culture in all aspects of working life so that people from all backgrounds receive equal treatment, realize their full potential and can bring their full, authentic selves to work. This should be further elaborated on in your application. ', '5-10 years of experience working with Business Intelligence/data visualization tools is essential ', 'This role is for a Business Intelligence / Data Visualization engineer.', 'A department which values Diversity and Inclusion (D&I) and is committed to realizing the firm’s D&I ambition which is an integral part of our global Conduct and Ethics Standards', 'Work as part of the CFO division providing development and advisory services to internal business and IT users.']",Not Applicable,Full-time,Information Technology,Banking,2020-10-20 12:01:24
Data Scientist,"Trifecta, Inc.","Sacramento, CA",3 hours ago,Be among the first 25 applicants,"['', 'Lead efforts around pricing experimentation for a variety of products', ' Comprehensive health benefits (medical, dental, vision) Paid Time Off Stock Options 401k plan Stocked kitchen – healthy snacks, cold brew, and kombucha on tap Dog Friendly Office   ', 'Incorporate new statistical modeling, machine learning, and experimental methods in support of our financial goals', ' Comprehensive health benefits (medical, dental, vision) Paid Time Off Stock Options 401k plan Stocked kitchen – healthy snacks, cold brew, and kombucha on tap Dog Friendly Office ', 'Prototype, deploy and text predictive algorithms that ', 'Significant experience with Python and SQL', 'Requirements', 'Mine our rich database of customer data in order to obtain significant insights that support strategic decision-making ', 'Contribute to the development of Trifecta’s forecasting infrastructure', 'Work in a collaborative, production-facing codebase that has close coupling with engineering systems', '401k plan', 'Paid Time Off', 'Location: Sacramento, CA (Required)', 'You are interested in both collaborative ownership of a code-base as well as self-ownership of a capability', 'You have 3+ years of experience implementing/designing machine learning algorithms', 'Conduct experiments to show causal impact of new ideas or implementations', 'lindsey.stauffer@trifectanutrition.com', 'Produce regular forecasts that drive decision-making for business, product, engineering, and leadership teams across Trifecta', ' You have 3+ years of experience implementing/designing machine learning algorithms You have experience with coding/algorithm implementation You have a creative, problem-solving mindset Significant experience with Python and SQL You are able to work with both technical and non-technical partners (presentations, expectation management, getting people on-board with ideas) You are interested in both collaborative ownership of a code-base as well as self-ownership of a capability Location: Sacramento, CA (Required) Work authorization: United States (Required) ', 'You are able to work with both technical and non-technical partners (presentations, expectation management, getting people on-board with ideas)', 'Work authorization: United States (Required)', ' Comprehensive health benefits (medical, dental, vision) Paid Time Off Stock Options 401k plan Stocked kitchen – healthy snacks, cold brew, and kombucha on tap Dog Friendly Office    ', 'Stock Options', 'Responsibilities', 'You have experience with coding/algorithm implementation', 'Dog Friendly Office', 'Effectively communicate and share results with both technical and non-technical cross-functional partners', 'Comprehensive health benefits (medical, dental, vision)', 'Stocked kitchen – healthy snacks, cold brew, and kombucha on tap', 'You have a creative, problem-solving mindset', ' Comprehensive health benefits (medical, dental, vision) Paid Time Off Stock Options 401k plan Stocked kitchen – healthy snacks, cold brew, and kombucha on tap Dog Friendly Office  ', 'Act as an embedded partner to the Finance & Strategy team', ' Mine our rich database of customer data in order to obtain significant insights that support strategic decision-making  Prototype, deploy and text predictive algorithms that  Work in a collaborative, production-facing codebase that has close coupling with engineering systems Conduct experiments to show causal impact of new ideas or implementations Effectively communicate and share results with both technical and non-technical cross-functional partners Act as an embedded partner to the Finance & Strategy team Produce regular forecasts that drive decision-making for business, product, engineering, and leadership teams across Trifecta Lead efforts around pricing experimentation for a variety of products Incorporate new statistical modeling, machine learning, and experimental methods in support of our financial goals Contribute to the development of Trifecta’s forecasting infrastructure ']",Entry level,Full-time,Engineering,Consumer Services,2020-10-20 12:01:24
ASSOCIATE DATA SCIENTIST SPACE OPTIMIZATION,The Home Depot,"Atlanta, GA",17 hours ago,32 applicants,"['', 'Nature And Scope', 'Strong communication and data presentation skills Ability to quickly adapt to new technologies, tools and techniques', 'Action Oriented - Taking on new opportunities and tough challenges with a sense of urgency, high energy, and enthusiasm', 'Collaborates - Building partnerships and working collaboratively with others to meet shared objectives', ""Master's degree preferred"", '50% - Model Preparation:Establish scalable, efficient processes for large scale data analyses, model development and model implementation', 'Working knowledge of analytical/statistics software (e.g., SPSS, SAS, R, Stata)', 'Manages Conflict - Handling conflict situations effectively with minimal noise', ""Master's degree preferredWorking knowledge of analytical/statistics software (e.g., SPSS, SAS, R, Stata)Ability to develop and apply advanced mathematical/statistical techniquesAbility to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiencesExcellent written and verbal communication skillsAbility to build scalable systems that analyze huge data sets and make actionable recommendationsStrong communication and data presentation skills Ability to quickly adapt to new technologies, tools and techniquesFlexible and responsive able to perform in a fast paced, dynamic work environment and meet aggressive deadlinesAbility to work with technical and non-technical team members "", 'Ability to convey complex or technical ideas and processes in easy-to-understand terms to diverse audiences', 'Years of Relevant Work Experience: ', 'Communicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences', 'Customer Focus - Building strong customer relationships and delivering customer-centric solutions', 'Drives Results - Consistently achieving results, even under tough circumstances', 'Knowledge, Skills, Abilities And Competencies', '20% - Communication and Visualization: Present analysis and resulting recommendations to senior management; Leverage data to present a compelling business case to optimize investments and operations', 'Physical Requirements: ', '30% - Model Development and Deployment: Design and develop algorithms and models to use against large datasets to create business insights', 'Major Tasks, Responsibilities And Key Accountabilities', 'Preferred Qualifications', 'Excellent written and verbal communication skills', 'Nimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder', 'Environmental Job Requirements', 'Travel: ', 'Education Required: ', 'Minimum Qualifications', 'Flexible and responsive able to perform in a fast paced, dynamic work environment and meet aggressive deadlines', 'Ability to build scalable systems that analyze huge data sets and make actionable recommendations', 'Position Purpose', '50% - Model Preparation:Establish scalable, efficient processes for large scale data analyses, model development and model implementation30% - Model Development and Deployment: Design and develop algorithms and models to use against large datasets to create business insights20% - Communication and Visualization: Present analysis and resulting recommendations to senior management; Leverage data to present a compelling business case to optimize investments and operations', 'Environment: ', 'Ability to develop and apply advanced mathematical/statistical techniques', 'Action Oriented - Taking on new opportunities and tough challenges with a sense of urgency, high energy, and enthusiasmCollaborates - Building partnerships and working collaboratively with others to meet shared objectivesCommunicates Effectively - Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiencesCustomer Focus - Building strong customer relationships and delivering customer-centric solutionsDrives Results - Consistently achieving results, even under tough circumstancesManages Conflict - Handling conflict situations effectively with minimal noiseNimble Learning - Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder', 'Ability to work with technical and non-technical team members ']",Entry level,Full-time,Engineering,Construction,2020-10-20 12:01:24
Senior Data Engineer,KDR Recruitment USA,"New York, NY",,N/A,"['', '\xa0\xa0', '\xa0', 'Information retrieval', 'Experience of at least one RDBMS.', 'Some knowledge of statistical modelling and machine learning.', 'Spark / MapReduce', 'Python', 'Must haves:', 'Spark / MapReducePythonSCALANLPInformation retrievalNoSQL databases', 'Experience in Machine Learning', 'NLP', 'SCALA', 'Define and prototype new approaches to our existing data enrichment techniquesCreate entirely new kinds of data enrichment that add value to customer profilesDefine metrics for assessing the quality of the data we produceImplement validation frameworks and methodologies to regularly measure our data against these metricsFind & share insight from client dataResearch enrichment approachesAnalyse and model client data', 'Create entirely new kinds of data enrichment that add value to customer profiles', 'My client are partnered with some of the largest and most recognised brands in the world. Their mission; to be the AI brain behind all forms of contact between a business and a customer.', 'Proven track record of handling data at scale.', 'Find & share insight from client data', ' end customer data in a B2C enviroment', 'What about the opportunity and freedom to work with different technologies and be given the opportunity to learn new languages?', 'Due to continued growth they are recruiting for an experienced Senior Data Engineer who has worked with end customer data in a B2C enviroment.', 'A solid foundation in at least one programming language, preferably Scala or Python.Experience with end customer dataExperience in Machine LearningProven track record of handling data at scale.Experience of at least one RDBMS.Some knowledge of statistical modelling and machine learning.', 'Define and prototype new approaches to our existing data enrichment techniques', 'If this sounds like your next challenge click apply now!', 'As a Senior Data Engineer you will:', 'Would you like to join a well funded start up whose mission it is to leverage AI and Machine Learning technology to help organisation build a genuine relations with their customers.', 'Implement validation frameworks and methodologies to regularly measure our data against these metrics', 'Define metrics for assessing the quality of the data we produce', 'Research enrichment approaches', 'A solid foundation in at least one programming language, preferably Scala or Python.', 'Analyse and model client data', 'Experience with end customer data', 'Nice to haves:', 'Data Engineer | New York | $160K-£180K base + Bonus + Equity', 'NoSQL databases']",Mid-Senior level,Full-time,Information Technology,Staffing and Recruiting,2020-10-20 12:01:24
Data Engineer,NCSOFT,"Aliso Viejo, CA",23 hours ago,Over 200 applicants,"['', 'We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren’t shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.', 'Experience with object-oriented and functional programming languages: Python, Scala etc.', 'As a Data Engineer, you’ll be responsible for gathering and collecting data, storing it, doing batch processing or real-time processing on it, and serving it to data scientists and data analysts to easily query.', 'NCSOFT is a premiere digital entertainment company and global publisher with worldwide locations and more than 4,000 employees focused on bringing extraordinary games to life for millions of fans around the world. Established in 1997 and headquartered in Seoul, South Korea, we quickly became a key leader in online games. Best known for critically acclaimed franchises including Lineage, Aion, Guild Wars, and Blade & Soul, NCSOFT is also one of the world’s top mobile developers with Lineage 2M occupying the #1 grossing revenue slot on Google Play. Our core goal is making people in this world happier by delivering games that entertain a globally connected audience has remained the same. Our culture is innovative, creative, collaborative and impactful, and we are passionate about creating the best gaming experiences for our players.', 'Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)', 'Proficiency in general database administration concepts and efficient query writing', 'Experience with ETL and data integration tool : Airflow, Informatica PowerCenter', 'Understanding data source (10%)', 'Experience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.', 'BS in Computer Science or equivalent experience', '3+ years of day-to-day working experience as data engineer', 'WHO WE ARE', 'Understanding data source (10%)Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)Create large data warehouses by running some ETL (Extract, Transform and Load) that is used for analysis by the analyst/scientists (30%)Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)', 'WHY JOIN THE BUSINESS INTELLIGENCE PLATFORM TEAM?', 'Install continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses (20%)', 'We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.', 'This is a full time, on-site position at our office in Aliso Viejo, CA. A casual, friendly work environment, a comprehensive benefits package, a competitive salary, and more are all part of what makes NCSOFT West a great place to work.', 'Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)', 'Excellent verbal and written communication skills', 'WHAT YOU’LL NEED TO BE SUCCESSFUL', 'We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.We own the data platform, contributing to the design, implementation, and maintenance of these data services so we aren’t shy about experimenting with new tech. However, we take a measured approach in order to minimize introducing unnecessary technical debt.We collaborate with Analytics, Game Development, Platform and Publishing teams. Our data platform supports all kinds of data in an efficient environment that helps with analysis, customer care and company wide data-driven decisions.', 'We feel team members are most effective in working on what they are passionate about. We are all capable of working on any given project, and often shift tasks based on preference.', 'Develop data processes for construction, mining, and modeling that are delivered to the data analyst/science team (30%)', 'An eagerness to continually improve your skills, learn new technologies a willingness to take initiative beyond basic responsibilities', 'BS in Computer Science or equivalent experience3+ years of day-to-day working experience as data engineerExperience with object-oriented and functional programming languages: Python, Scala etc.Experience with RDBMS (MS-SQL, MYSQL etc.) and NoSQL (MongoDB, DynamoDB etc.)Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.Experience with ETL and data integration tool : Airflow, Informatica PowerCenterExperience with AWS cloud services: EC2, S3, EMR, Glue, RedShift, Athena etc.Proficiency in general database administration concepts and efficient query writingExcellent verbal and written communication skillsAn eagerness to continually improve your skills, learn new technologies a willingness to take initiative beyond basic responsibilities', 'Experience with Big Data query and application knowledge: Hive, Impala, Fluentd, Spark, Sqoop, Pig etc.', 'Develop, construct, test and maintain architectures such as databases and large-scale data processing systems (10%)', 'We are a passionate and positive team that is always working on new data engineering technology and exciting projects including new game launches.', ""WHAT YOU'LL DO""]",Mid-Senior level,Full-time,Engineering,Computer Games,2020-10-20 12:01:24
Software Engineer ,Edge Case Research,"Pittsburgh, PA",4 hours ago,Be among the first 25 applicants,"['', 'Docker', 'Helpful', 'precondition of employment', 'Health, Dental and Vision Insurance with majority of premiums covered\xa0Employee Stock Option Plan\xa0Paid Parental Leave\xa0Retirement Plan with Company Match\xa0Generous Paid Vacation and Sick Time\xa0Group Life Insurance\xa0Snacks and Coffee provided at Pittsburgh and Munich Offices\xa0Flexible Working Hours with Work from Home Options to support Work/Life balance\xa0', 'Experience with Vue, React or ther modern web frontend framework', 'Benefits & Perks:', '\xa0', ' PostgreSQL, MongoDB, Cassandara', 'Curious and motivated to learn new technologies', 'Software Engineer', 'We deliver the promise of autonomy', 'Experience writing\xa0Go,\xa0Python, Javascript', 'Flexible Working Hours with Work from Home Options to support Work/Life balance\xa0', 'Python', '0-3+ years\xa0', 'Snacks and Coffee provided at Pittsburgh and Munich Offices\xa0', 'Truthful', 'JavaScript', 'Health, Dental and Vision Insurance with majority of premiums covered\xa0', 'Edge Case Research is expanding our Product Development Team.\xa0 We are currently looking for software engineers with focus in frontend, full-stack, or backend development. If you are interested in working alongside the most experienced team in autonomous system safety, and you have a background in any of these areas, we are interested in hearing from you!', 'HelpfulFriendlyTruthful', 'At Edge Case Research, we enable our customers to assure the safety of autonomous systems for real world deployment. We are developing products that define and measure the safety of autonomous systems. Our client base spans diverse markets such as automotive, mining, defense, insurance, and aerospace. Edge Case is founded by the recognized world leaders in autonomous system safety and autonomous vehicle safety. Our experts are writing the standards and developing the products that will bring innovation safely into society.\xa0', 'Group Life Insurance\xa0', 'Employee Stock Option Plan\xa0', 'Go', 'Experience with databases like PostgreSQL, MongoDB, Cassandara', 'Contributing member of a growing team of engineersCollaborate closely with team members to create the best possible solutions for customersWrite robust, unit-tested code in\xa0Go,\xa0Python, and/or\xa0JavaScriptActive participation in scrum rituals', 'Paid Parental Leave\xa0', 'Bachelor’s in CS, CE, ECE, IT or equivalent experience in technical field', 'Background in software safety or self-driving cars industryExperience writing\xa0Go,\xa0Python, JavascriptExperience with Docker and KubernetesExperience with Vue, React or ther modern web frontend frameworkExperience with databases like PostgreSQL, MongoDB, CassandaraExperience with microservice architectures', 'Strong interest in software engineering patterns and principles', 'Collaborate closely with team members to create the best possible solutions for customers', 'Ability to adapt to different and changing languages and technologies', '0-3+ years\xa0of experience as a software engineer or relevant work experience', 'Python, Javascript', 'Friendly', 'Kubernetes', 'Requirements:', 'Write robust, unit-tested code in\xa0Go,\xa0Python, and/or\xa0JavaScript', 'Strong knowledge in programming structures, algorithms, and multithreading and parallelization concepts', 'Company Values:\xa0', 'Retirement Plan with Company Match\xa0', 'Active participation in scrum rituals', 'Experience with microservice architectures', 'Experience with Docker and Kubernetes', 'Authorization to work in the United States is a\xa0precondition of employment. The company will not consider candidates who require sponsorship for a work-authorized visa.Bachelor’s in CS, CE, ECE, IT or equivalent experience in technical field0-3+ years\xa0of experience as a software engineer or relevant work experienceCurious and motivated to learn new technologiesAbility to adapt to different and changing languages and technologiesStrong interest in software engineering patterns and principlesStrong knowledge in programming structures, algorithms, and multithreading and parallelization concepts', 'Background in software safety or self-driving cars industry', 'Nice To Have', 'Locations', 'Authorization to work in the United States is a\xa0precondition of employment. The company will not consider candidates who require sponsorship for a work-authorized visa.', 'Edge Case Research is headquartered in Pittsburgh, Pennsylvania with a European office in Munich Germany.\xa0 The reporting station for this position is PIttsburgh, Pennsylvania.', 'Contributing member of a growing team of engineers', 'Responsibilities:', 'Go,', 'Generous Paid Vacation and Sick Time\xa0']",Entry level,Full-time,Engineering,Information Technology and Services,2020-10-20 12:01:24
