job_title,company,location,date_posted,applicants,job_text,seniority_level,employment_type,job_function,industries,date_scraped
Data Engineer - REMOTE,Optello,"Remote, OR",24 hours ago,27 applicants,"['', ' Build upon existing data service architecture to support internal and external applications', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : TB10-1597099 -- in the email subject line for your application to be considered.***', 'Job Duration:', ' Experience with Cassandra databases', ' Amazing healthcare benefits', 'Bonus Skills', ' RESTful API and server-side API integration experience', ' Stipend for workspace', 'Requirements:', 'Optello is proud to be an Equal Opportunity Employer', ' Working in a remote setting with virtual team meetings on a regular basis', ' Competitive starting salary Amazing healthcare benefits 401k + match Generous PTO Equipment provided Stipend for workspace', ' 7+ years of Java programming experience 5+ years of Python programming experience 5+ years of SQL database experience Strong verbal and written communication experience RESTful API and server-side API integration experience', ' Childcare assistance', ' Experience with Cassandra databases Additional NoSQL database experience Experience with Maria databases Salesforce integration experience', ' Work supporting ETL pipelines, real time streams, and data warehouses', ' Design and implement process improvements, automate manual processes, and redesign infrastructure', ' Equipment provided', 'Job Location:', ' Build scalable pipelines capable of processing massive amounts of data', ' Generous PTO', 'Must Have Skills', 'Your Right to Work', ' Build scalable pipelines capable of processing massive amounts of data Build upon existing data service architecture to support internal and external applications Work supporting ETL pipelines, real time streams, and data warehouses Design and implement process improvements, automate manual processes, and redesign infrastructure Build upon on the infrastructure required to optimize the extraction, transformation, and loading of data using Java, Python, SQL Working in a remote setting with virtual team meetings on a regular basis Collaborate with business intelligence and analytics teams to optimize Tableau report queries', ' Collaborate with business intelligence and analytics teams to optimize Tableau report queries', ' Competitive starting salary', ' Catered breakfast and lunch each week', ' 5+ years of Python programming experience', ' Experience with Maria databases', ' Strong verbal and written communication experience', ' Additional NoSQL database experience', ' 401k + match', ' Catered breakfast and lunch each week Fully stocked snacks Pet-friendly office Childcare assistance', ' 7+ years of Java programming experience', 'Job Title:', ' Build upon on the infrastructure required to optimize the extraction, transformation, and loading of data using Java, Python, SQL', 'Email Your Resume In Word To', ' 5+ years of SQL database experience', ' Salesforce integration experience', ' Pet-friendly office', ' Fully stocked snacks']",Entry level,Full-time,Information Technology,Construction,2020-10-06 11:54:06
Data & Reporting Engineer,Nike,"Boston, MA",6 hours ago,34 applicants,"['', ' Interact with many types of data in both SQL and non-SQL based environments.', ' Solid SQL skills; ability to query data in a data warehouse and prepare data for reporting and insights automation needs. Experience with using Python/Pandas for data preparation/cleansing and analysis ideal but not required.', ' Experience working in an agile setting, working with developers to release in an iterative fashion.', ' Partner with stakeholders in Global Finance to identify key reports, business questions, hypotheses, and areas of exploration that will have a material impact on business decision-making, and translate these areas into requirements for insights, reports and data visualizations.', ' Strong SQL ability; able to write complex SQL queries against data warehouse/databases for the purposes of extracting required data and building data models for automated reporting and insights use case. Able to parse different types of data (JSON, parquet, excel/csv) for analysis using tools like R or Python. Able to quickly visualize and profile data in tools like Tableau, PowerPivot, etc.', ' Interact with many types of data in both SQL and non-SQL based environments. Parse data in common formats such as JSON, Parquet, excel/csv so that it can be usable for insights and analysis. Partner with the Converse Analytics Technology team to define data requirements and source data, either in terms of raw data or modeled data and logic to support insights, dashboard and report requirements.', 'Qualifications', ' Work as part of an agile team, delivering reports and insights in an iterative manner with a “progress over perfection” mindset.', ' Strong SQL ability; able to write complex SQL queries against data warehouse/databases for the purposes of extracting required data and building data models for automated reporting and insights use case.', ' Provide front-line support for data visualizations, dashboards and reports, answering user questions and resolving issues. Work with the Analytics Technology team to address back-end data or platform issues affecting reports.', ' Able to parse different types of data (JSON, parquet, excel/csv) for analysis using tools like R or Python.', ' Able to quickly visualize and profile data in tools like Tableau, PowerPivot, etc.', ' Automation mindset; Identify opportunities to automate insights generation work and ability to partner with Technology teams to implement solutions where possible.', ' Strong communication skills; Ability to engage with stakeholders on key business questions and hypotheses and tell compelling stories with data through visualization and reporting tools.', ' Experience working in a business setting; Experience working in a Corporate Finance and/or Controlling context and familiarity with key Finance terms, KPIs and typical reports strongly preferred.', ' Partner with the Converse Analytics Technology team to define data requirements and source data, either in terms of raw data or modeled data and logic to support insights, dashboard and report requirements.', ' Review, assess and automate the existing set of reports that are being run across Global Finance; Reports are run across a variety of tools, such as Business Objects, Excel and Tableau.', ' Partner with stakeholders in Global Finance to identify key reports, business questions, hypotheses, and areas of exploration that will have a material impact on business decision-making, and translate these areas into requirements for insights, reports and data visualizations. Review, assess and automate the existing set of reports that are being run across Global Finance; Reports are run across a variety of tools, such as Business Objects, Excel and Tableau. Provide front-line support for data visualizations, dashboards and reports, answering user questions and resolving issues. Work with the Analytics Technology team to address back-end data or platform issues affecting reports.', "" Bachelor's degree in Information Systems, Information Technology or Computer Science or equivalent professional experience; MBA or other graduate specialization in Finance and/or Accounting preferred Solid SQL skills; ability to query data in a data warehouse and prepare data for reporting and insights automation needs. Experience with using Python/Pandas for data preparation/cleansing and analysis ideal but not required. Experience with a variety of reporting and data visualization tools; Tableau, Business Objects, and PowerPivot preferred. Proven track record building and automating reports, data visualizations and dashboards in a business context for a variety of stakeholders, from leadership oriented summary dashboards to more granular and detailed analyses. Strong communication skills; Ability to engage with stakeholders on key business questions and hypotheses and tell compelling stories with data through visualization and reporting tools. Automation mindset; Identify opportunities to automate insights generation work and ability to partner with Technology teams to implement solutions where possible. Experience working in an agile setting, working with developers to release in an iterative fashion. Experience working in a business setting; Experience working in a Corporate Finance and/or Controlling context and familiarity with key Finance terms, KPIs and typical reports strongly preferred."", "" Bachelor's degree in Information Systems, Information Technology or Computer Science or equivalent professional experience; MBA or other graduate specialization in Finance and/or Accounting preferred"", ' Experience with a variety of reporting and data visualization tools; Tableau, Business Objects, and PowerPivot preferred. Proven track record building and automating reports, data visualizations and dashboards in a business context for a variety of stakeholders, from leadership oriented summary dashboards to more granular and detailed analyses.', ' Parse data in common formats such as JSON, Parquet, excel/csv so that it can be usable for insights and analysis.', ' Strong business analysis capabilities; Ability to ask go beyond reporting and ask “why”; Strong drive to drill into data and uncover root causes. Strong ability to “tell stories” with data to business stakeholders, particularly stakeholders within our Finance and Controlling organizations. Work as part of an agile team, delivering reports and insights in an iterative manner with a “progress over perfection” mindset.', ' Strong ability to “tell stories” with data to business stakeholders, particularly stakeholders within our Finance and Controlling organizations.', ' Strong business analysis capabilities; Ability to ask go beyond reporting and ask “why”; Strong drive to drill into data and uncover root causes.']",Entry level,Full-time,Information Technology,Apparel & Fashion,2020-10-06 11:54:06
Data Engineer,The Asbury Group Integrated Technologies,"Frederick, MD",15 hours ago,Be among the first 25 applicants,"['', ""Find purpose in your career!\xa0The Asbury Group Integrated Technologies is an IT consulting arm of Asbury Communities, Inc.\xa0completely focused on doing all the good we can for those we serve.\xa0When you join our family, you'll enjoy the personal fulfillment that comes from making a difference in someone's life every day.\xa0Asbury\xa0is honored to have earned certification as a Great Place to Work for three years in a row based on associate feedback\xa0to questions related to trust, culture, and the meaning they derive from their jobs."", 'We are currently seeking talented and highly motivated Data Scientists or Data Engineers to lead in the development of our discovery and support platform. The successful candidate will join a small, global team of data focused associates that have successfully built, and maintained a best of class traditional, Kimball based, SQL server founded, data warehouse.\xa0The successful candidate will lead the conversion of the existing data structure into an AWS focused, big data framework and assist in identifying and pipelining existing and augmented data sets into this environment.\xa0In addition, the successful candidate will assist leadership in growing the team required to complete the development of various computational algorithms associated with aging in place.\xa0The successful candidate can be either data engineering or science focused but must be able to lead and assist in architecting and constructing the AWS foundation and initial data ports.\xa0\xa0\xa0\xa0', 'Contact us to learn more about this fantastic opportunity!', 'Ensuring that we provide a safe and healthy environment for those who work and live at our communities is our highest priority.\xa0We are proud of the incredible work being done by our associates and grateful for the support we are receiving from our many residents and family members as we work through this pandemic together.\xa0We continue to aggressively work to minimize the risks of the COVID-19 virus for\xa0residents and associates in our communities.']",Associate,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer,Conduent,United States,7 hours ago,Be among the first 25 applicants,"['', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience in cloud-based ETL development processes.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Learn and develop new ETL techniques as required to keep up with contemporary technologies.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Worked in big data environments, cloud data stores, different RDBMS, and OLAP solutions.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Support presentations to Customers and Partners', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Advising on new technology trends and possible adoption to maintain a competitive advantage', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A BS or Masters degree in Computer Science or related technical discipline is required', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Excellent SQL coding experience with performance optimization for data queries.', '\xa0', 'Prior experience with application delivery using an Onshore/Offshore model', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa05+ years of related experience is required.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Develop/maintain efficient data collection systems and sound strategies for getting quality data from different sources', 'Demonstrated ability to have successfully completed multiple, complex technical projectsPrior experience with application delivery using an Onshore/Offshore modelExperience with business processes across multiple Master data domains in a services-based companyDemonstrates a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality.Demonstrates high standards of professional behavior in dealings with clients, colleagues and staff.Is able to make sound and far-reaching decisions alone on major issues and to take full responsibility for them on a technical basis.Strong written communication skills. Is effective and persuasive in both written and oral communication.Experience with gathering end-user requirements and writing technical documentationTime management and multitasking skills to effectively meet deadlines under time-to-market pressureRequires some travel (on average 10%-20%)', 'Experience with gathering end-user requirements and writing technical documentation', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Performs data management tasks, such as to conduct data profiling, assess data quality, and write SQL queries to extract and integrate data', 'Demonstrates a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience connecting to varied data sources', 'Time management and multitasking skills to effectively meet deadlines under time-to-market pressure', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Has a strong technical background and remains evergreen with technology and industry developments.', 'Additional Requirements', 'Demonstrates high standards of professional behavior in dealings with clients, colleagues and staff.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Collaborate in design reviews and code reviews to ensure standards are met. Recommend new standards for visualizations.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Is familiar with the principles and practices involved in development and maintenance of software solutions and architectures and service delivery.', 'Strong written communication skills. Is effective and persuasive in both written and oral communication.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Engineer and maintain a modern Cloud data pipeline to collect, organize, and process data from disparate sources.', 'Fulltime Remote position ', 'Responsibilities:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Consume and analyze data from the data pool to support inference, prediction, and recommendation of actionable insights to support business growth.', 'Experience Needed:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Design, develop, and maintain ETL processes using tools and scripting. Troubleshoot and debug ETL processes. Performance tuning and optimization of the ETL processes.', 'Is able to make sound and far-reaching decisions alone on major issues and to take full responsibility for them on a technical basis.', 'Experience with business processes across multiple Master data domains in a services-based company', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Provide support to new or existing applications while recommending best practices and leading projects to implement new functionality.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience in the deployment and maintenance of ETL Jobs.', 'Demonstrated ability to have successfully completed multiple, complex technical projects', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Understands different data models like normalized, de-normalied, stars, and snowflake models. Worked with transactional, temporal, time series, and structured and unstructured data.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Reviews the solution requirements and architecture to ensure the selection of appropriate technology, efficient use of resources, and integration of multiple systems and technology.', 'We are looking for a Data Engineer who will be part of our Analytics Practice and will be expected to actively work in a multi-disciplinary fast-paced environment. This role requires a broad range of skills and the ability to step into different roles depending on the size and scope of the project; its primary responsibility is the development and maintenance of data pipelines including acquisition, transformation, loading, and processing of data.\xa0', 'Data Engineer', 'Requires some travel (on average 10%-20%)', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0ETL experience with data integration to support data marts, extracts, and reporting']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer (Remote),Robert Half,"Dallas, TX",57 minutes ago,Be among the first 25 applicants,"['', 'Description', ' Experience implementing automated ETL workflows ', ' Experience in SQL queries, creating data models ', ' Experience with PythonRobert Half Technology matches IT professionals with some of the best companies on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the technology jobs that match your skills and priorities — fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets.From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNE’s “Most Admired Companies” list every year since 1998.Download our mobile app to take your job search on the go!Contact your local Robert Half Technology office at 888.490.4429 or visit www.roberthalf.com/jobs/technology to apply for this job now or find out more about other job opportunities.All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada.© 2020 Robert Half Technology. An Equal Opportunity Employer M/F/Disability/Veterans.', ' Bachelor’s degree or equivalent working experience ', 'Requirements']",Entry level,Temporary,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer,Facebook,"Menlo Park, CA",14 hours ago,Be among the first 25 applicants,"['', 'Experience working with cloud or on-prem Big Data/MPP analytics platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).', '3+ years experience with Data Modeling.', 'Partner with leadership, engineers, program managers and data scientists to understand data needs.', 'Experience with designing and implementing real-time pipelines.', '3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).', 'Partner with leadership, engineers, program managers and data scientists to understand data needs.Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.Communicate, at scale, through multiple mediums: Presentations, dashboards, company-wide datasets, bots and more.Educate your partners: Use your data and analytics experience to ‘see what’s missing’, identifying and addressing gaps in their existing logging and processes.Leverage data and business principles to solve large scale web, mobile and data infrastructure problems.Build data expertise and own data quality for your areas.', 'Communicate, at scale, through multiple mediums: Presentations, dashboards, company-wide datasets, bots and more.', 'Educate your partners: Use your data and analytics experience to ‘see what’s missing’, identifying and addressing gaps in their existing logging and processes.', 'Experience with Airflow.', 'Experience with more than one coding language.Experience with designing and implementing real-time pipelines.Experience with data quality and validation.Experience with SQL performance tuning and E2E process optimization.Experience with anomaly/outlier detection.Experience with notebook-based Data Science workflow.Experience with Airflow.Experience querying massive datasets using Spark, Presto, Hive, Impala, etc.', 'Experience with SQL performance tuning and E2E process optimization.', '5+ years of SQL experience.', 'Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.', '5+ years experience in custom ETL design, implementation and maintenance.', 'Experience analyzing data to discover opportunities and address gaps.', 'Build data expertise and own data quality for your areas.', 'Experience querying massive datasets using Spark, Presto, Hive, Impala, etc.', 'Leverage data and business principles to solve large scale web, mobile and data infrastructure problems.', 'Experience with anomaly/outlier detection.', 'Experience with data quality and validation.', '5+ years of Python development experience.5+ years of SQL experience.3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).3+ years experience with Data Modeling.Experience analyzing data to discover opportunities and address gaps.5+ years experience in custom ETL design, implementation and maintenance.Experience working with cloud or on-prem Big Data/MPP analytics platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).', '5+ years of Python development experience.', 'Experience with notebook-based Data Science workflow.', 'Experience with more than one coding language.']",Associate,Full-time,Information Technology,Internet,2020-10-06 11:54:06
Data Engineer,DISYS,"Richmond, VA",2 hours ago,Be among the first 25 applicants,"['', 'Preferred Qualifications:', 'TECHNICAL EXPERIENCE: At least 5 years experience with Java, Python, Spring, Kafka, Postgres ', 'Create and Manage Springs Data Pipeline - Take data from multiple disparate sources (Postgres, OneLake or Snowflake, CMS etc), transform and store them in a single place that represents the data uniformly as a single source of truth ', 'EDUCATION: Bachelors degree (any subject) or military experience ', 'AGILE DEVELOPMENT: Knowledge and experience in Agile development processes ', 'Job Description: ""Spring Data Infrastructure - Data Engineer\xa0 ', 'EDUCATION: Masters degree (any subject) ', 'Basic Qualifications: ', 'DATA EXPERIENCE: At least 5 years prior experience as a Data Engineer/Architect ', 'What you bring to the table:', '\xa0 ', 'Own Data Quality - Spearhead the identification of data issues and formulate solutions for data issues and bugs ', 'AGILE EXPERIENCE: At least 1 year demonstrable experience working in an Agile environment ', 'TECHNICAL EXPERIENCE: At least 3 years experience with Java, Python, Spring, Kafka, Postgres ', 'As a Data Engineer with our team, you would:', 'CREATIVE ANALYSIS: Flexible, adaptable, and creative analytical skills ', 'Participate in Feature development with Software Engineering team - Engage with Product and Data Analysis teams to groom out requirements for the data implications of new Feature development ', 'COLLABORATION: The ability to collaborate closely with key stakeholders, including business partners and engineering or development teams ', 'While not required, any of the following will be considered favorably and given extra weight in evaluating candidates for the role: ', 'DATA ENGINEER EXPERIENCE: Proven experience and success as a Data Evangelist; experience in working with diverse data systems and teams to deliver elegant and error-free data solutions ', 'As a Data Engineer with our team, you would: ', 'Basic Qualifications:', ' ', 'DATA EXPERIENCE: At least 7 years prior experience as a Data Engineer/Architect ', 'COMMUNICATION: Outstanding listening and presentation skills, honed by hearing customers and stakeholders, and sharing key communications with peers, management, and executives ', 'Preferred Qualifications: ', 'AGILE EXPERIENCE: At least 3 years demonstrable experience working with data in an Agile environment, plus familiarity with the work and collaboration tools used in an Agile environment  (such as Confluence, Jira, Rally, or other similar tools) ', 'Job Description: ""Spring Data Infrastructure - Data Engineer\xa0', 'DATA TRAINING/CERTIFICATION: Data Engineering training and/or certification, either as part of an undergraduate or masters-degree program, or as training gained while entering the data field', 'What you bring to the table: ']",Mid-Senior level,Contract,Information Technology,Banking,2020-10-06 11:54:06
Data Engineer,WeWork,"New York, NY",13 hours ago,Be among the first 25 applicants,"['', 'Develop tools supporting self-service data pipeline management (ETL)', 'You do what you love!', ""You have the flexibility to think outside the box.We don't do everything the traditional way, and are always looking to innovate and push the envelope.You have the ability to foresee and identify needs of the team.You take an innovator and creator’s approach to any issues that may arise.You take initiative and identify ways in which we can improve our data product and service."", 'You Will', 'Leading / managing full project lifecyclesSalesforce and related toolsWorkflow management tools (Airflow, Luigi, etc..)Working in a cloud environment (AWS, GCP, Snowflake, etc)KafkaDBTDistributed execution frameworks (Spark, Apache Beam, etc.)', 'Doer', 'Experience with modern BI tools (Looker, Tableau, etc)', 'Strong communication skills, empathy and initiative3+ years of experience in data engineeringStrong background in data warehouse concept and designProficient in at least one of the SQL dialects (Snowflake, MySQL, PostgreSQL, SqlServer, Oracle)Good understanding of SQL Engine and able to conduct advanced performance tuningFamiliar with at least one scripting language (Python, Ruby, Perl, Bash)Experience with Git and the pull request workflowExperience working closely with Analytics/Data Science teamsExperience with modern BI tools (Looker, Tableau, etc)', 'Strong background in data warehouse concept and design', 'Credibility is earned at WeWork through execution and getting things done.', 'You take initiative and identify ways in which we can improve our data product and service.', 'What You Will Do', 'You do what you love!Credibility is earned at WeWork through execution and getting things done.You are able to get into the details and deliver results under highest expectations on time and quality.Be ready to get hands-on with all aspects of the daily needs. The buck stops with you.Pragmatism and outcomes orientation are valued and lead to wins.Exceptional organizational and multitasking skills.You thrive in a fast-paced environment.You are resilient and can adapt to a changing environment.', 'You must present well and communicate clearly and effectively to upper management and internal departments.', 'Proficient in at least one of the SQL dialects (Snowflake, MySQL, PostgreSQL, SqlServer, Oracle)', 'You are able to get into the details and deliver results under highest expectations on time and quality.', 'Workflow management tools (Airflow, Luigi, etc..)', 'You’re excited to solve data challenges that combines digital and physical aspects, across multiple business verticals like Real Estate, Finance, Sales & Marketing, Social Media, and regions', 'You are resilient and can adapt to a changing environment.', ""You're motivated to enable and collaborate with engineering, analytics and product teams to tackle the most challenging business needs"", 'Experience working closely with Analytics/Data Science teams', 'There is no room for “I” at WeWork. Every role and individual is in the organization to serve We.Builds trust across the organization by being a good listener and inclusively soliciting input.You are open to new and innovative solutions.You must present well and communicate clearly and effectively to upper management and internal departments.You’re willing to adjust course when appropriate new ideas or objections are raised.You love working with people!', 'You love working with people!', ""We don't do everything the traditional way, and are always looking to innovate and push the envelope."", 'Distributed execution frameworks (Spark, Apache Beam, etc.)', 'Experience with Git and the pull request workflow', 'Working in a cloud environment (AWS, GCP, Snowflake, etc)', 'There is no room for “I” at WeWork. Every role and individual is in the organization to serve We.', 'DBT', 'Builds trust across the organization by being a good listener and inclusively soliciting input.', 'Salesforce and related tools', 'Kafka', 'Be ready to get hands-on with all aspects of the daily needs. The buck stops with you.', 'You thrive in a fast-paced environment.', 'You have the ability to foresee and identify needs of the team.', 'Leading / managing full project lifecycles', 'You are open to new and innovative solutions.', 'Collaborator', 'Develop centralized source of truth data sets to encourage a democratized, data-driven culture', 'You’re willing to adjust course when appropriate new ideas or objections are raised.', 'Requirements', 'Collaborate on improving efficiency and quality of internal data processes as well as stakeholder engagement, including implementation of system and model quality tracking ', 'Familiar with at least one scripting language (Python, Ruby, Perl, Bash)', 'Solution-centric', 'Pragmatism and outcomes orientation are valued and lead to wins.', 'Who You Are', 'Collaborate closely with data engineers, analysts,data scientists, ML Engineers, as well as cross-functional teams, to leverage huge amounts of WeWork data, for data-driven business and user behavior insights', 'You take an innovator and creator’s approach to any issues that may arise.', ""You’re excited to solve data challenges that combines digital and physical aspects, across multiple business verticals like Real Estate, Finance, Sales & Marketing, Social Media, and regionsYou're motivated to enable and collaborate with engineering, analytics and product teams to tackle the most challenging business needs"", 'Leverage data expertise to help build and evolve data models in various components of the data stackWork on architecting, building, and launching highly scalable and reliable data pipelines to support WeWorkCollaborate closely with data engineers, analysts,data scientists, ML Engineers, as well as cross-functional teams, to leverage huge amounts of WeWork data, for data-driven business and user behavior insightsCollaborate on improving efficiency and quality of internal data processes as well as stakeholder engagement, including implementation of system and model quality tracking Develop centralized source of truth data sets to encourage a democratized, data-driven culture', 'Strong communication skills, empathy and initiative', 'Bonus Points For Experience In', 'Exceptional organizational and multitasking skills.', 'Leverage data expertise to help build and evolve data models in various components of the data stack', 'Work on architecting, building, and launching highly scalable and reliable data pipelines to support WeWork', 'You have the flexibility to think outside the box.', '3+ years of experience in data engineering', 'Good understanding of SQL Engine and able to conduct advanced performance tuning']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-10-06 11:54:06
Data Engineer,Arthur,"New York, NY",12 hours ago,41 applicants,"['', 'What we can offer you:', 'A competitive salary', 'Competence writing production-ready code in Python', 'We’ll Want You to Have:', 'Arthur is looking for a Data Engineer to join our growing New York based team!\xa0 Arthur is an early-stage venture-backed startup shaking up the $64 Billion/year art market.\xa0 Our goal is to make the data around the art market more accessible to collectors, investors, dealers, and the artists themselves, giving more people the confidence to discover new art and invest in an informed manner.', 'Experience designing ETL pipelines using cloud computing tools such as Dataflow (we use GCP, but equivalent experience with AWS or Azure is great, too)', 'It’d Be Nice if You Have:', 'Significant equity in the company, so we all share in Arthur’s success', 'Roughly 3-5 years of professional experience in Data Engineering, Data Science, and/or Data Analytics', 'Worked with commercial or open-source tools and toolkits for natural language processing, such as Google Cloud Natural Language, NLTK, or spaCyExperience extracting data from unstructured sources', 'Health/dental/vision insurance, at low cost to employees', 'Four weeks of paid vacation, as well as paid holidays', 'Opportunities for rapid career growth and leadership as Arthur grows', 'Primarily remote work to start, with flexible WFH as conditions normalize', 'Experience extracting data from unstructured sources', 'A Bachelor’s degree in a relevant field:\xa0 Computer Science, Statistics, Economics, Mathematics, or equivalent', 'A Bachelor’s degree in a relevant field:\xa0 Computer Science, Statistics, Economics, Mathematics, or equivalentRoughly 3-5 years of professional experience in Data Engineering, Data Science, and/or Data AnalyticsExperience designing ETL pipelines using cloud computing tools such as Dataflow (we use GCP, but equivalent experience with AWS or Azure is great, too)Competence writing production-ready code in PythonQuality verbal and written communication skillsA sincere desire to learn and grow - we’re still quite small, so the desire to learn and grow as the company grows is essential!', 'Worked with commercial or open-source tools and toolkits for natural language processing, such as Google Cloud Natural Language, NLTK, or spaCy', 'A sincere desire to learn and grow - we’re still quite small, so the desire to learn and grow as the company grows is essential!', 'Quality verbal and written communication skills', 'A competitive salarySignificant equity in the company, so we all share in Arthur’s successFour weeks of paid vacation, as well as paid holidaysPrimarily remote work to start, with flexible WFH as conditions normalizeHealth/dental/vision insurance, at low cost to employeesOpportunities for rapid career growth and leadership as Arthur grows']",Mid-Senior level,Full-time,Information Technology,Internet,2020-10-06 11:54:06
Data Engineer,Nomi Health,"Austin, TX",19 hours ago,65 applicants,"['', 'OK, HOW ABOUT A FEW SPECIFIC RESPONSIBILITIES?', 'Must have AWS or Azure experience. (Snowflake, Databricks, S3 desirable)', 'Familiarity of system concepts and tools within an enterprise architecture framework.', 'Contribute to the development of the ML capabilities for the Nomi HealthDevelop and implement data models to guide business decisionsMapping data sources, including descriptions of the business meaning of the data, its uses, its quality, the applications that maintain it and the database technology in which it is stored. Documentation of a data source must describe the semantics of the data so that the occasional subtle differences in meaning are understood.Documenting interfaces and data movement by recording how mapped data is moved around the virtual enterprise. This includes the frequency of movement, the source and destination of each step, how the data is transformed as it moves, and any aggregation or calculations.Designing the movement of data through the enterprise, including sources of data and how the data is moved around in order to be improved.Defining integrative views of data to draw together data from across the enterprise. Some views will use a database of extracted data and others will bring together data in near real time, considering data currency, availability, response times and data volumes. Designing canonical data views to limit technical debt as data flows from point-to-point transformation.Defining technical standards and guidelines. Assess and document when and how to use the architected producers and consumers, the technologies to be used for various purposes, and models of selected entities, objects and processes. The guidelines should encourage reuse of existing data stores, as well as address issues of security, timeliness and quality.Investigate and participate in emerging technologies and new release Proofs of Concept (PoCs).Leveraging existing [core] data assets.Managing related metadata to include business descriptions of the data, details of any calculations or summaries, descriptions of the sources of the data, and indications of data quality and currency.Communicating the data architecture across the enterprise.Ensuring a focus on data quality by working effectively with data stewards so they can understand data semantics and identify opportunities for improving data quality.', 'Documenting interfaces and data movement by recording how mapped data is moved around the virtual enterprise. This includes the frequency of movement, the source and destination of each step, how the data is transformed as it moves, and any aggregation or calculations.', 'A minimum of 2-3 years experience in a similar role.', 'Excellent organizational and analytical abilities.', 'Must have coding experience (python, JAVA, R),\xa0', 'WHICH LEADER IS RESPONSIBLE FOR YOUR GROWTH AND DEVELOPMENT?', ""Nomi Health is led by Mark Newman (Founder/CEO) , Josh Walker (Co-Founder, COO) and Boe Hartman (Co-Founder, CTO). Both Mark, Josh and Boe have a proven track record in the HR Tech, Health Tech, Health plans, Pharmacy and Financial Service industries. Mark, previously Founder/CEO of HireVue where he scaled the company from 0 to $40m ARR with a successful exit of over $500M. Josh, comes with 18+ years of experience in healthcare as COO at Imagine Health, Upwell and OptumInsight where he has first-hand experience in international and domestic healthcare markets leading and expanding business growth. Boe has served in multiple senior positions across global banking for over 25 years.\xa0Most recently, at Goldman Sachs as a Partner, where he led the firm’s launch of it’s digital consumer bank; Marcus By Goldman Sachs and the firm's entry into the consumer credit card market."", 'Data Science Engineer requirements are:', 'Chief Technology Officer', 'Health, Dental, Vision, 401k with match, Commuter benefits with Great Pay, plus Equity.', 'Investigate and participate in emerging technologies and new release Proofs of Concept (PoCs).', 'Communicating the data architecture across the enterprise.', 'Benefits', 'Mapping data sources, including descriptions of the business meaning of the data, its uses, its quality, the applications that maintain it and the database technology in which it is stored. Documentation of a data source must describe the semantics of the data so that the occasional subtle differences in meaning are understood.', 'Defining integrative views of data to draw together data from across the enterprise. Some views will use a database of extracted data and others will bring together data in near real time, considering data currency, availability, response times and data volumes. Designing canonical data views to limit technical debt as data flows from point-to-point transformation.', 'Knowledge of various modern data formats, tools, and methodologies. (Infomatics desirable)', '\ufeffNomi Health is offering a highly competitive compensation package with an attractive base salary as well as a significant equity stake into the company at an early stage.', ""Bachelor's degree in Computer Science, Computer Engineering or relevant field.A minimum of 2-3 years experience in a similar role.Must have AWS or Azure experience. (Snowflake, Databricks, S3 desirable)Must have ELT/ETL experience (Talend, MDM, other ETL/ELT tools)Must have coding experience (python, JAVA, R),\xa0Familiarity of system concepts and tools within an enterprise architecture framework.Knowledge of various modern data formats, tools, and methodologies. (Infomatics desirable)Excellent organizational and analytical abilities.Outstanding problem solver.Good written and verbal communication skills."", 'Contribute to the development of the ML capabilities for the Nomi Health', 'Defining technical standards and guidelines. Assess and document when and how to use the architected producers and consumers, the technologies to be used for various purposes, and models of selected entities, objects and processes. The guidelines should encourage reuse of existing data stores, as well as address issues of security, timeliness and quality.', 'Requirements', 'Nomi Health is the modern payment system for employee healthcare. We sidestep the middlemen, and connect employers providers and families directly at scale to cut healthcare costs by 30% across America. We will do this by eliminating high cost “out of network” charges, making the process all digital with easy access to real data and understandable actions.\xa0', 'Develop and implement data models to guide business decisions', 'We are looking for a Data Science Engineer who can help pave the way for more work in the data field and start by analyzing our current needs and use data to generate value with Nomi Health’s end goal in mind. From this goal, you will design the architecture and the analytics pipelines while taking into account appropriate time frames, and costs.', 'Ensuring a focus on data quality by working effectively with data stewards so they can understand data semantics and identify opportunities for improving data quality.', 'As a Data Science Engineer you will provide technical and domain subject knowledge to the company and future customers. You should be able to know how to examine new data systems requirements and implement migration models. You will also spend a good deal of time problem solving, analyzing architecture and assessing architect models, reviewing data migrations, selecting platforms and on-boarding of data management solutions that meet the technical and operational needs of the business.\xa0You must be hands-on with tools and code.', 'Since we are early in our journey and we will be soon dealing with a lot of data, this person will set the stage for future work of data scientists and data engineers.\xa0', 'WHO ARE WE?\xa0', 'Leveraging existing [core] data assets.', 'WHAT IS A DAY IN THE LIFE?', 'Outstanding problem solver.', 'WHY IS THIS ROLE CRITICAL?', 'Designing the movement of data through the enterprise, including sources of data and how the data is moved around in order to be improved.', 'Must have ELT/ETL experience (Talend, MDM, other ETL/ELT tools)', ""Bachelor's degree in Computer Science, Computer Engineering or relevant field."", 'Managing related metadata to include business descriptions of the data, details of any calculations or summaries, descriptions of the sources of the data, and indications of data quality and currency.', 'Good written and verbal communication skills.', 'The company is in stealth mode right now and has raised over $10M in seed funding which will be used to hire and develop the product, technology and go-to-market team.\xa0']",Associate,Full-time,Engineering,Computer Software,2020-10-06 11:54:06
Data Engineer,ServiceTitan,"Atlanta, GA",6 hours ago,64 applicants,"['', 'Map data', 'Contribute material input to go/no-go/continue decisions upon test completion', 'Vertical SaaS experience is highly desirable', ' Health & Wellness: ', 'Results and solution oriented - we want to know how we can win, not why we can’t', 'Equal Opportunity Employer', ' Work/Life Balance: ', '2-5 years of experience with SQL Server 2008/2012/2014/2016', ' Enrichment: ongoing learning culture with access to Linkedin Learning and professional development workshops, diversity charter groups, orientation program, career pathing opportunities, mentorship programs', 'Strong analytical thinking skills', ' Family-Friendly Benefits:', 'Contribute', 'Advanced knowledge and experience in T-SQL, complex ETL tools and operations, and SSIS', ' Family-Friendly Benefits: extended parental leave, pregnancy support, 20k in adoption reimbursement, Snoo Smart Sleeper, back-up childcare credits, legal benefit, discounted pet insurance', 'As Our Data Engineer, You Will', 'Establish quality working relationships with internal stakeholders', ' Work/Life Balance: flexible work schedule, flexible PTO', 'Develop', 'Given the experimental nature of this job, we will require very tight compliance when it comes to data - we need to focus on learning', 'Map data from various legacy databases into the ServiceTitan platform, subsequently developing SQL scripts that will extract the information efficiently and accurately', ' Health & Wellness: company-paid medical/vision/dental/life insurance/disability, employer HSA contribution, free One Medical membership, care coordination support, 401(k) with company match, stipend for home office equipment/supplies, gym discounts, monthly cell phone stipend', 'Develop automated scripts to validate legacy database values and identify previously unmapped fields prior to loading them into the ServiceTitan platform', 'About ServiceTitan', 'Establish', 'Apply feedback from customers and internal stakeholders on data import quality into previously developed extraction scripts', 'Ability to work independently and cross functionally', ' 2-5 years of experience with SQL Server 2008/2012/2014/2016 Advanced knowledge and experience in T-SQL, complex ETL tools and operations, and SSIS Given the experimental nature of this job, we will require very tight compliance when it comes to data - we need to focus on learning Strong analytical thinking skills Expert level understanding of database and data model concepts Vertical SaaS experience is highly desirable Results and solution oriented - we want to know how we can win, not why we can’t Ability to work independently and cross functionally ', ""To Be Successful In This Role, You'll Need"", 'Perks & Benefits', 'CCPA Notice for CA Residents applying to Jobs at ServiceTitan', ' Map data from various legacy databases into the ServiceTitan platform, subsequently developing SQL scripts that will extract the information efficiently and accurately Develop automated scripts to validate legacy database values and identify previously unmapped fields prior to loading them into the ServiceTitan platform Apply feedback from customers and internal stakeholders on data import quality into previously developed extraction scripts Discover opportunities to leverage information from legacy databases into the implementation process to avoid inquiring for additional information from customers Establish quality working relationships with internal stakeholders Contribute material input to go/no-go/continue decisions upon test completion ', 'Apply ', 'Discover ', 'Life at ServiceTitan ', 'Expert level understanding of database and data model concepts', 'Enrichment: ', 'Discover opportunities to leverage information from legacy databases into the implementation process to avoid inquiring for additional information from customers']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer,iHeartMedia,"San Antonio, TX",7 hours ago,Be among the first 25 applicants,"['', 'Assemble large, complex data sets that meet functional and non-functional business requirements', 'Experience writing automated tests', 'Strong understanding of ETL processes', 'Proven programming skills in Python or similar programming language', 'Experience with Apache Airflow', 'Current employees and contingent workers click here to apply and search by the Job Posting Title. ', 'Experience supporting and working with cross-functional teams in a dynamic environment', '5+ years of experience in data or software engineering', 'Experience with AWS and/or GCP', 'Communicate complex solutions and ideas to a variety of stakeholders (other team members, IT leadership, and business leaders) in easily understandable language', 'Hands-on knowledge of SQL and experience with both relational and distributed databases', 'Responsibilities', 'Utilize and stay current in programming languages and software technology', 'Job Summary', 'Working knowledge of CI/CD processes and Git source control', 'Experience with AWS tools and services such as Redshift, Athena, Lambda Functions, Step Functions', 'Experience with AWS and/or GCPExperience with Apache AirflowExperience with AWS tools and services such as Redshift, Athena, Lambda Functions, Step FunctionsExperience building data pipelines using PythonExperience with big data tools: Hadoop, Spark, Kafka, etc.5+ years of experience in data or software engineering', 'Minimum Qualifications', 'Bachelor’s Degree in Computer Science, Information Technology, Informatics, or Applied Math', 'Assemble large, complex data sets that meet functional and non-functional business requirementsBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sourcesDevelop and maintain standards for administration and operation including the scheduling, running, monitoring, logging, error management, failure recovery, and output validationIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Work with cross functional teams to strive for greater functionality in our data systems, and recommend and implement ways to improve data reliability, efficiency, and qualityContribute to the project planning process by estimating tasks and deliverablesCommunicate complex solutions and ideas to a variety of stakeholders (other team members, IT leadership, and business leaders) in easily understandable languageUtilize and stay current in programming languages and software technology', 'Experience building data pipelines using Python', '3-5 years of commercial experience in a data engineering role with a proven record of manipulating, processing and extracting value from large disconnected datasets', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Develop and maintain standards for administration and operation including the scheduling, running, monitoring, logging, error management, failure recovery, and output validation', 'Bachelor’s Degree in Computer Science, Information Technology, Informatics, or Applied Math3-5 years of commercial experience in a data engineering role with a proven record of manipulating, processing and extracting value from large disconnected datasetsStrong understanding of ETL processesHands-on knowledge of SQL and experience with both relational and distributed databasesProven programming skills in Python or similar programming languageWorking knowledge of CI/CD processes and Git source controlExperience writing automated testsExperience working with REST APIsStrong organizational, communication, and presentation skillsExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementExperience supporting and working with cross-functional teams in a dynamic environment', 'Strong organizational, communication, and presentation skills', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Contribute to the project planning process by estimating tasks and deliverables', 'Work with cross functional teams to strive for greater functionality in our data systems, and recommend and implement ways to improve data reliability, efficiency, and quality', 'Preferred Qualifications', 'Experience working with REST APIs', 'Location']",Entry level,Full-time,Information Technology,Marketing and Advertising,2020-10-06 11:54:06
Data Engineer,OmniData,"Portland, OR",7 hours ago,Be among the first 25 applicants,"['We operate according to a methodology we call the Modern Data Estate Framework.', '1+ years of experience in Analytics and Data Warehousing, with Azure knowledge a plus.  ', 'A technical mindset and strong business acumen.', 'OmniData is offering you the opportunity to work with the entire lifecycle of large Data Projects, focused on cloud-based data warehousing, with surface points to Analytics, Machine Learning and AI. You will get to work closely with very experienced consultants who will be able to provide mentorship and career guidance. ', 'Responsibilities and Duties', 'You will work on various Big Data, Data Warehouse Automation, and Data Analytics projects for our world class clients, analyzing requirements, building data architecture and implementing state-of-the-art Data Warehouse projects using Microsoft platform and tools.  Deep knowledge of Azure Cloud is a plus.', 'Qualifications and Skills', 'Salary and benefits commensurate with experience.  High growth potential for those with an entrepreneurial spirit.', 'Data Warehousing and Data Warehouse AutomationAzure, SQL Server, SSASPower BI, DAXRequirements Analysis and Project Delivery methodology', 'Job Summary', ""You must be humble, hungry and a fast learner.  OmniData and our clients place a high value on inventiveness.1+ years of experience in Analytics and Data Warehousing, with Azure knowledge a plus.  A technical mindset and strong business acumen.Willingness to travel and work with a consultant's diligence.The position will report directly to a founding partner of the company.  As a consultant, you are also responsible to our clients.We operate according to a methodology we call the Modern Data Estate Framework.SQL Experience is required and Microsoft Azure experience is a plus."", 'SQL Experience is required and Microsoft Azure experience is a plus.', 'Power BI, DAX', ""Willingness to travel and work with a consultant's diligence."", 'Requirements Analysis and Project Delivery methodology', 'You must be humble, hungry and a fast learner.  OmniData and our clients place a high value on inventiveness.', 'Data Warehousing and Data Warehouse Automation', 'OmniData', 'Azure, SQL Server, SSAS', 'High growth potential for those with an entrepreneurial spirit.', 'Salary and benefits commensurate with experience.  ', 'OmniData is a US-based Data and Analytics consulting firm. We have deep experience in Data Architecture and Business Analytics, and we help organizations build their Modern Data Estates, designed to serve their needs well for many years to come.  We simplify the complex, and we are Microsoft Gold Data Partners in both Analytics and Data Platform.  Are you a Microsoft Certified Azure Data Engineer?  Do you feel that you could be?  How are your PowerBI skills?', 'The position will report directly to a founding partner of the company.  As a consultant, you are also responsible to our clients.', 'You need to have solid experience working with data and analytics, a strong technical aptitude, and be a quick learner.  In return, we offer an exciting position at a young startup experiencing rapid growth, deep mentorship and the opportunity to be part of creating a consulting firm that makes a difference for our clients every day we are with them.  ', 'Benefits and Perks']",Entry level,Full-time,Information Technology,Computer Software,2020-10-06 11:54:06
Data Engineer - Mid Level,Strategic Staffing Solutions,Washington DC-Baltimore Area,3 hours ago,Be among the first 25 applicants,"['', 'Design, document, build, test and deploy data pipelines that assemble large complex datasets from various sources and integrate them into a unified view.', 'Design, build, and manage analytics infrastructure that can be utilized by data analysts, data scientists, and non-technical data consumers, which enables functions of the big data platform for Analytics.', '\xa0', 'Develop, construct, test, and maintain architectures, such as databases and large-scale processing systems that help analyze and process data in the way the Analytics organization requires.', 'No C2C. We can offer a partner fee but no C2C. Remote then onsite in Charlotte, NC. Ideally looking for OPT, H4, GC or USC.', 'Scalability Experience', 'Big Data Experience', 'SQL', 'Degree in Computer Science, Engineering, or related fields.3-5 years of experienceDesign, build, and manage analytics infrastructure that can be utilized by data analysts, data scientists, and non-technical data consumers, which enables functions of the big data platform for Analytics.Develop, construct, test, and maintain architectures, such as databases and large-scale processing systems that help analyze and process data in the way the Analytics organization requires.Develop highly scalable data management interfaces, as well as software components by employing programming languages and tools.Design, document, build, test and deploy data pipelines that assemble large complex datasets from various sources and integrate them into a unified view.Identify, design, and implement operational improvements: automating manual processes, data quality checks, error handling and recovery, re-designing infrastructure as needed.Create data models that will allow analytics and business teams to derive insights about customer behaviorsBuild new data pipelines, identify existing data gaps and provide automated solutions to deliver analytical capabilities and enriched data to applications.Responsible for obtaining data from the System of Record and establishing batch or real-time data feed to provide analysis in an automated fashion.', 'Must Have:', 'Identify, design, and implement operational improvements: automating manual processes, data quality checks, error handling and recovery, re-designing infrastructure as needed.', 'Build new data pipelines, identify existing data gaps and provide automated solutions to deliver analytical capabilities and enriched data to applications.', '3-5 years of experience', 'Degree in Computer Science, Engineering, or related fields.', 'Mongo DB', 'NoSQL', 'SQLNoSQLMongo DBBig Data ExperienceScalability ExperienceETL Pipelines', 'Responsible for obtaining data from the System of Record and establishing batch or real-time data feed to provide analysis in an automated fashion.', 'Develop highly scalable data management interfaces, as well as software components by employing programming languages and tools.', 'ETL Pipelines', 'Create data models that will allow analytics and business teams to derive insights about customer behaviors']",Mid-Senior level,Contract,Engineering,Information Technology and Services,2020-10-06 11:54:06
Software Data Engineer,Garmin,"Olathe, KS",18 hours ago,25 applicants,"['', 'Build and architect big data architecture in software development cycle', 'Develop cloud-like self-service solutions', 'Communicate in written and verbal form effectively', 'Learn new data technologies and practices proactively', 'Ability to write scripts as needed to interact with big data clusters', 'Thoroughly document work in an organized manner', 'Ability to prioritize and multi-task independently in a flexible, fast paced and challenging environment', 'Must be detail-orientated and have the ability to work proactively and effectively with minimal supervision', 'Identify and resolve problems proactively', 'Data Engineer ', 'Build and architect big data architecture in software development cycle Ability to write scripts as needed to interact with big data clusters Develop cloud-like self-service solutions Learn new data technologies and practices proactively Identify and resolve problems proactively Analyze existing data solutions and recommend improvements Thoroughly document work in an organized manner Communicate in written and verbal form effectively Must be detail-orientated and have the ability to work proactively and effectively with minimal supervision Ability to prioritize and multi-task independently in a flexible, fast paced and challenging environment ', 'Analyze existing data solutions and recommend improvements']",Entry level,Full-time,Information Technology,Consumer Goods,2020-10-06 11:54:06
Data Engineer,Randstad USA,"Cockeysville, MD",11 hours ago,Be among the first 25 applicants,"['', 'Technical algorithms', 'Network and hardware topology', 'SSIS', 'Object-oriented programming languages (Java, JavaScript, Python, C#)', 'Data governance', 'PowerBI', 'Designing ELT/ETL procedures to transfer data between internal and external sources via ETL, APIs', ' REST API conceptsPowershellT-SQL (SQL Server)PowerBISSIS', 'Responsibilities', 'Qualifications', 'Modern cloud data platforms Preferably Azure Data Lake (Storage and Analytics), Data Factory, Data Warehouse, Data Bricks, Amazon Redshift, Synapse Analytics, Logic AppsAWS experience acceptable ', 'Job Summary', 'Ensuring accuracy of data collections', 'Communicating with stakeholders to gather data requirements', 'Data visualization and reporting tools (Tableau, SSRS, Data Studio, Cognos, Qlik)', 'Preferably Azure Data Lake (Storage and Analytics), Data Factory, Data Warehouse, Data Bricks, Amazon Redshift, Synapse Analytics, Logic Apps', 'Data lakes and catalogs', 'Sensitive data and PII best practices, guidelines, and other governance', 'Powershell', 'Database warehousing, design, and architecture', ' Preferably Azure Data Lake (Storage and Analytics), Data Factory, Data Warehouse, Data Bricks, Amazon Redshift, Synapse Analytics, Logic AppsAWS experience acceptable', ' Communicating with stakeholders to gather data requirementsDesigning ELT/ETL procedures to transfer data between internal and external sources via ETL, APIsEnsuring accuracy of data collectionsNetwork and hardware topologyObject-oriented programming languages (Java, JavaScript, Python, C#)Modern cloud data platforms Preferably Azure Data Lake (Storage and Analytics), Data Factory, Data Warehouse, Data Bricks, Amazon Redshift, Synapse Analytics, Logic AppsAWS experience acceptable Data lakes and catalogsDatabase warehousing, design, and architectureData visualization and reporting tools (Tableau, SSRS, Data Studio, Cognos, Qlik)Sensitive data and PII best practices, guidelines, and other governanceData governanceTechnical algorithms', 'AWS experience acceptable', 'REST API concepts', 'T-SQL (SQL Server)']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer (Data Visualization Engineer),Innosoft Corporation,"Baltimore, MD",,Be among the first 25 applicants,"['', 'Develop and extend web presentation layer for user portals.', 'Experience in presenting business critical insights to a large audience', ""Bachelor's Degree/Master's Degree in Math, Applied Math, Statistics, Computer Science, related field."", 'Qualification: ', 'Capable of and professionally experienced with coming up with designs combining large volumes of relevant data across different businesses/departments', 'Responsibilities: ', '5 years relevant work experience in data visualization and data analytics.', 'Work with large healthcare and financial datasets to provide clear insights via metrics, trendlines, interactive graphs and other presentation techniques.', 'Make large and/or complex data more accessible, understandable and usable.Deliver data in a useful and appealing way to users.Work with large healthcare and financial datasets to provide clear insights via metrics, trendlines, interactive graphs and other presentation techniques.Develop and extend web presentation layer for user portals.Investigate, rationalize, and recommend optimal approaches for architecting performant web presentation layer, evaluating data handling across app layers.', 'Experience with D3.js.', 'Innosoft is looking for a Data Visualization Engineer to join our growing team of software professionals delivering phenomenal results to various government agencies. You will be working with senior software developers, business analysts and other stakeholders for better user experience on a government website improvement project.\xa0', 'Investigate, rationalize, and recommend optimal approaches for architecting performant web presentation layer, evaluating data handling across app layers.', 'Make large and/or complex data more accessible, understandable and usable.', ""Bachelor's Degree/Master's Degree in Math, Applied Math, Statistics, Computer Science, related field.5 years relevant work experience in data visualization and data analytics.Experience with D3.js.Experience in presenting business critical insights to a large audienceCapable of and professionally experienced with coming up with designs combining large volumes of relevant data across different businesses/departments"", 'Deliver data in a useful and appealing way to users.']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer,LTI - Larsen & Toubro Infotech,"San Jose, CA",2 hours ago,Be among the first 25 applicants,"['', '·\xa0\xa0Rewards and recognition programs', 'A little about us...', ""What's in it for you? "", '·\xa0We provide our employees with a learning environment that promotes growth and creativity.', 'Java / API skills are nice to have', '·\xa0\xa0Commuter benefits', 'L&T Infotech is one of the largest global technology consulting and digital solutions company -holding an annual revenue of $1.4 bn. We were founded 20 years ago as the information technology arm of the Larsen & Toubro group. We are currently partnered with more than 350 clients (66 of which are Fortune 500 companies). We operate in 28 countries - employing over 28,000 employees world-wide!', 'Strong Python based Data Science experience.Good skills / exposure to Mongo DBJava / API skills are nice to haveStrong communication and analytical skillsExposure to Subscription / SaaS domain is an advantage\xa0', '·\xa0We lead in providing the best experiences for our clients and their customers.', '·\xa0Our role-based workshop helps us groom future leaders for LTI', '·\xa0Role-based Training programs', '·\xa0We encourage you to acquire various beneficial international certifications, with costs s reimbursed', '·\xa0Continuing Education Programs (CEP) to enhance your knowledge, skills, and attitude as a professional', '·\xa0\xa0Certification reimbursement', 'How will you grow?', 'Good skills / exposure to Mongo DB', '·\xa0\xa0Excellent growth and advancement opportunities', 'How will you grow? ', 'Strong Python based Data Science experience.', 'Exposure to Subscription / SaaS domain is an advantage\xa0', 'Job Description –', 'To learn more please visit us at www.lntinfotech.com follow us on Twitter @LTI_Global.', '·\xa0\xa0Excellent benefits plan: medical, dental, vision, life, FSA, & PTO', '·\xa0\xa0Innovative and collaborative company culture', 'We are an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, sexual orientation, disability status, protected veteran status, or any other characteristic protected by law.', ' ', ""What's in it for you?"", '·\xa0\xa0Roll over vacation days', 'Strong communication and analytical skills']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Backend/Data Engineer - Fully Remote (USA) - FinTech Start Up,Huxley,New York City Metropolitan Area,,Be among the first 25 applicants,"['', 'You take pride in developing ETL and data pipelines that are optimized for performance, reliability, and scale. ', '2-5 years of hands on development experience in (Java, Kotlin or Scala) and ideally with Python as well ', 'Desire to work in a fast-paced start up environment. Previous startup experience is a plus. ', '2-5 years of hands on development experience in (Java, Kotlin or Scala) and ideally with Python as well Desire to work in a fast-paced start up environment. Previous startup experience is a plus. Experience with NoSQL is a plus: DynamoDB / BigTable, Elasticsearch, Redis', 'Experience with NoSQL is a plus: DynamoDB / BigTable, Elasticsearch, Redis', 'You might be a great fit if:', 'Requirements: ', 'You get excited learning about bleeding-edge technologies and are not afraid to experiment with them on the job. Quickly translating what you learn into prototypes and production applications. ', 'You take pride in writing well documented, well-rationalized microservices conforming OpenAPI specifications, then letting teams and users consume your APIs using auto-generated SDKs. ', 'You enjoy using a modern technology stack to build services that communicate with each other over REST or gRPC backed by modern technologies such as Kubernetes, DynamoDB, and Elasticsearch. ', 'You take pride in developing ETL and data pipelines that are optimized for performance, reliability, and scale. You enjoy using a modern technology stack to build services that communicate with each other over REST or gRPC backed by modern technologies such as Kubernetes, DynamoDB, and Elasticsearch. You take pride in writing well documented, well-rationalized microservices conforming OpenAPI specifications, then letting teams and users consume your APIs using auto-generated SDKs. You get excited learning about bleeding-edge technologies and are not afraid to experiment with them on the job. Quickly translating what you learn into prototypes and production applications. ']",Associate,Full-time,Engineering,Computer Software,2020-10-06 11:54:06
Data Engineer,Cognizant,"Wilmington, DE",13 hours ago,Be among the first 25 applicants,"['', ' Delaware, New Jersey, PA, VA.', 'You must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.', 'About Cognizant', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big data’ technologies.', ' Experience with stream-processing systems: Storm, Spark-Streaming, etc. (Nice to have)', ' 3+ years of experience (Mid-level) Experience with big data tools: Hadoop, Apache Spark, Kafka, etc', ' 3+ years of experience (Mid-level) Strong Programming experience with object-oriented/object function scripting languages: Python/Scala, Spark.', 'Responsibilities', 'Qualifications', ' Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Create and maintain optimal data pipeline architecture, Assemble large, sophisticated data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big data’ technologies.Build analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency and other key business performance metrics.Work with partners including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with partners including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', ' 1+ Years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra. Cognizant will not be able to provide sponsorship for this role. Candidates have the option of working remotely.', 'Build analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency and other key business performance metrics.', ' 1+ years of experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift', 'Create and maintain optimal data pipeline architecture, Assemble large, sophisticated data sets that meet functional / non-functional business requirements.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer - Remote,Dice,"Lilburn, GA",4 hours ago,Be among the first 25 applicants,"['', 'Required Experience']",Entry level,Full-time,Information Technology,Internet,2020-10-06 11:54:06
Data Engineer,Cogito Corp,"Boston, MA",14 hours ago,Be among the first 25 applicants,"['', 'Exploratory data analysis and data interpretation.', 'Be comfortable working in agile sprints methodology to co-discover the best approach with our stakeholders.', 'Modern Big Data ETL toolsPython Docker and KubernetesSQLAirFlow/Jenkins preferredDataOps methodologyAbility to collaborate with fellow CogiciansAbility to multi-task and work in a fast-paced start-up cultureKnowledge of git and code repository methods ', ' Your choice of comprehensive benefits for you and your family’s health, dental, vision, disability, and life insurance', ' Office Optional policy where Cogician’s choose where they work either primarily remote, primarily in office or hybrid', 'AirFlow/Jenkins preferred', 'Minimum Masters degree in advanced technical field, or business analytics, or related prior work experience. ', 'You Will', 'Knowledge of git and code repository methods ', ' 20 days vacation time, 5 days sick time, 2 floating holidays and 11 company holidays (yes, Patriot’s Day is a holiday)', ' Casual and inclusive office atmosphere', ' Stock options via equity grants', 'Equal Opportunity Employer', 'Love being a part of a high-performing analytics team.', 'Build and maintain robust and resilient data pipelines (ETL).', ' Frequent catered lunch and live product demos', 'Python ', 'Docker and Kubernetes', 'SQL', 'Ability to multi-task and work in a fast-paced start-up culture', 'Benefits', 'Responsibilities', 'Work collaboratively with our fellow Cogicians.', ' Company paid parental leave upon hire', 'Build and maintain robust and resilient data pipelines (ETL).Exploratory data analysis and data interpretation.Lead with best practices in DataOps to scale our team efficiently.Work collaboratively with our fellow Cogicians.', ' Ability to support Cogician’s anywhere in the US through our Office Optional policy', ' 2 ""Be Gentle"" personal days', 'Modern Big Data ETL tools', 'DataOps methodology', 'Be passionate about DataOps best practices to work smarter, not harder, to ensure baked in quality and efficiency in our data pipelines.', 'Authorization to Work', 'Love working with very large data; exploring data and mining it for insights.', 'Skills', ' Competitive pay, stock options, and annual bonus eligibility', ' Eligibility for annual bonus for all non commissioned employees', 'Requirements', 'Ability to collaborate with fellow Cogicians', ' Ongoing professional development and cross-training', 'Build and maintain robust and resilient data pipelines that enable complex analysis by data science and business intelligence reporting.', 'Lead with best practices in DataOps to scale our team efficiently.', ' 401(k) retirement plan options', 'Be intellectually curious and enjoy learning, teaching yourself and others the latest big data tools.']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-10-06 11:54:06
Data Engineer,IRIS Consulting Corporation,"Minnesota, United States",22 hours ago,53 applicants,"['', 'Location: Plymouth, MN', 'Minimum 3+ year experience on Data Warehousing using Microsoft Sql Server SSIS, SSAS (MDX, DAX), SSRS and Azure for Data and Analytics solutions (Functions, Data Factory, Data Lake, Data Warehouse, Analysis Services) 2+ years', 'Data & Analytics team works with business leaders across the enterprise to drive optimized strategy using data.\xa0This position contributes to company’s success by building cloud-based data services for analytic solutions. You will build data pipelines that are scalable, repeatable, secure and adhere to data quality standards. Responsibilities also include evangelizing data on cloud solutions with customers, leading business and IT stakeholders through designing a robust, secure and optimized Azure architecture, and delivering the target solution. This role will involve working with customers and collaborating with internal engineering teams, development of new application functionality, as well as maintenance and support of source code for existing Azure data platforms using the Azure data services', 'Microsoft Sql Server SSIS, SSAS (MDX, DAX), SSRS and Azure for Data and Analytics solutions (Functions, Data Factory, Data Lake, Data Warehouse, Analysis Services)', 'Overall Data Engineering experience 3+ year', 'Bachelor’s degree in computer science, management information systems, or related, or equivalent experienceMinimum 3+ year experience on Data Warehousing using Microsoft Sql Server SSIS, SSAS (MDX, DAX), SSRS and Azure for Data and Analytics solutions (Functions, Data Factory, Data Lake, Data Warehouse, Analysis Services) 2+ yearsOverall Data Engineering experience 3+ yearOn Prem to Cloud (Azure) Migration experience\xa0is preferred.', 'Translate business requirements into technical requirements to ensure solutions meet business needs', 'Support and execute on Enterprise Data Warehouse migration to Azure Cloud and Cloud Data Warehouse (Snowflake)', 'Analyze, design, build, query, troubleshoot and maintain data pipelines (SSIS, ADF, Snowflake)', 'Translate business requirements into technical requirements to ensure solutions meet business needsAnalyze, design, build, query, troubleshoot and maintain data pipelines (SSIS, ADF, Snowflake)Support On Prem EDW and resolve incidents covering both data analysis and data development requests.Support and execute on Enterprise Data Warehouse migration to Azure Cloud and Cloud Data Warehouse (Snowflake)Ability to multitask on different domains and technologies and faster resolution time of tickets.', 'Bachelor’s degree in computer science, management information systems, or related, or equivalent experience', 'Qualifications:', 'Experience working directly with key business leaders providing data to help them create value. Experience executing migration of on-prem data warehouses to cloud solutions. Experience in an Agile fast-paced environment with continuously evolving priorities.', 'Duration: 6 Months+', 'Responsibilities:', 'On Prem to Cloud (Azure) Migration experience\xa0is preferred.', 'Support On Prem EDW and resolve incidents covering both data analysis and data development requests.', 'Ability to multitask on different domains and technologies and faster resolution time of tickets.']",Mid-Senior level,Contract,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer,Lab49,"New York, NY",1 day ago,27 applicants,"['', 'Profile Requirements', 'The successful candidate will:', '\xa0', 'Expertise with Scala, Java or Python languages', 'Design and develop high-quality software solutions for Risk platformCreate new modules & data flows to meet regulatory requirements (FRTB, GMETH)Use Scala, Java or Python programming languages to build required functionalityImplement data pipelines using Big Data/Cloud technologies: Apache Spark, Hadoop, Microsoft Azure Cloud (Data Lake, Data Factory, Batch), and DatabricksDesign and develop Microservices using Spring Boot and Azure Kubernetes Service (PKS) cluster', 'Spark Developer certification is an added advantageAzure Data Factory, Azure Batch\xa0Expertise in Financial Services industry', 'Experience with any of the Big-3 Cloud platforms - Azure (preferred), AWS or Google', 'Experience building data lakes and data pipelines in the cloud', 'Role & Responsibilities', 'Spark Developer certification is an added advantage', 'Expertise with Scala, Java or Python languagesExperience with Spark, Hadoop, and Databricks (a must-have)Experience with any of the Big-3 Cloud platforms - Azure (preferred), AWS or GoogleExperience building data lakes and data pipelines in the cloudExperience designing high-performance, high-load systemsUnderstanding of the distributed Agile SDLC model', 'Design and develop high-quality software solutions for Risk platform', 'Create new modules & data flows to meet regulatory requirements (FRTB, GMETH)', 'Preferred Experience', 'Understanding of the distributed Agile SDLC model', 'Expertise in Financial Services industry', 'Experience designing high-performance, high-load systems', 'Lab49 is currently looking for a Data Engineer to build a strategic Risk calculation engine and associated workflows. The candidate will participate in the design and development of the platform, interacting with globally distributed Risk Officers (Market Risk, Credit Risk), Quants and IT Dev/QA team.', 'Use Scala, Java or Python programming languages to build required functionality', 'Azure Data Factory, Azure Batch\xa0', 'Design and develop Microservices using Spring Boot and Azure Kubernetes Service (PKS) cluster', 'Experience with Spark, Hadoop, and Databricks (a must-have)', 'Implement data pipelines using Big Data/Cloud technologies: Apache Spark, Hadoop, Microsoft Azure Cloud (Data Lake, Data Factory, Batch), and Databricks']",Mid-Senior level,Full-time,Information Technology,Financial Services,2020-10-06 11:54:06
Data Engineer,Rekruiters,"Houston, TX",19 hours ago,Over 200 applicants,"['', 'https://www.facebook.com/rekruiters/ – Facebook', '- 3yrs+ experience with APIs and has a good understanding of them.', '- Has worked directly with business teams to understand needs and engineer solutions.', '- Has worked on streaming architectures and moving large amounts of data.', 'Requirements:', 'MUST HAVE EXPERIENCE WITH SQL AND PYTHON', '_________________________________________________________________', '________________________________________________________', 'Specific needs for project:', 'Rekruiters has been named by business journals as one of the best places to work.', 'For more information on this job visit: https://rekruiters.com/jobs/', '- 2yrs+ experience with containerization (Docker or Kubernetes) -', '4yrs+ experience with Python using the data processing packages like Pandas, NumPy', 'https://www.rekruiters.com – Main Site', '- 4yrs+ experienced with databases, both relational and non-relational', 'Location: Houston, Area', 'Corporate:', '@rekruiters.com – Twitter', 'We offer benefits such as weekly pay, health insurance, 401k and even profit sharing to our consultants.']",Mid-Senior level,Contract,Information Technology,Oil & Energy,2020-10-06 11:54:06
Data Engineer,OmniData,"Portland, OR",7 hours ago,Be among the first 25 applicants,"['We operate according to a methodology we call the Modern Data Estate Framework.', '1+ years of experience in Analytics and Data Warehousing, with Azure knowledge a plus.  ', 'A technical mindset and strong business acumen.', 'OmniData is offering you the opportunity to work with the entire lifecycle of large Data Projects, focused on cloud-based data warehousing, with surface points to Analytics, Machine Learning and AI. You will get to work closely with very experienced consultants who will be able to provide mentorship and career guidance. ', 'Responsibilities and Duties', 'You will work on various Big Data, Data Warehouse Automation, and Data Analytics projects for our world class clients, analyzing requirements, building data architecture and implementing state-of-the-art Data Warehouse projects using Microsoft platform and tools.  Deep knowledge of Azure Cloud is a plus.', 'Qualifications and Skills', 'Salary and benefits commensurate with experience.  High growth potential for those with an entrepreneurial spirit.', 'Data Warehousing and Data Warehouse AutomationAzure, SQL Server, SSASPower BI, DAXRequirements Analysis and Project Delivery methodology', 'Job Summary', ""You must be humble, hungry and a fast learner.  OmniData and our clients place a high value on inventiveness.1+ years of experience in Analytics and Data Warehousing, with Azure knowledge a plus.  A technical mindset and strong business acumen.Willingness to travel and work with a consultant's diligence.The position will report directly to a founding partner of the company.  As a consultant, you are also responsible to our clients.We operate according to a methodology we call the Modern Data Estate Framework.SQL Experience is required and Microsoft Azure experience is a plus."", 'SQL Experience is required and Microsoft Azure experience is a plus.', 'Power BI, DAX', ""Willingness to travel and work with a consultant's diligence."", 'Requirements Analysis and Project Delivery methodology', 'You must be humble, hungry and a fast learner.  OmniData and our clients place a high value on inventiveness.', 'Data Warehousing and Data Warehouse Automation', 'OmniData', 'Azure, SQL Server, SSAS', 'High growth potential for those with an entrepreneurial spirit.', 'Salary and benefits commensurate with experience.  ', 'OmniData is a US-based Data and Analytics consulting firm. We have deep experience in Data Architecture and Business Analytics, and we help organizations build their Modern Data Estates, designed to serve their needs well for many years to come.  We simplify the complex, and we are Microsoft Gold Data Partners in both Analytics and Data Platform.  Are you a Microsoft Certified Azure Data Engineer?  Do you feel that you could be?  How are your PowerBI skills?', 'The position will report directly to a founding partner of the company.  As a consultant, you are also responsible to our clients.', 'You need to have solid experience working with data and analytics, a strong technical aptitude, and be a quick learner.  In return, we offer an exciting position at a young startup experiencing rapid growth, deep mentorship and the opportunity to be part of creating a consulting firm that makes a difference for our clients every day we are with them.  ', 'Benefits and Perks']",Entry level,Full-time,Information Technology,Computer Software,2020-10-06 11:54:06
"Senior Data Engineer, Production Management, Data Science & Engineering",Netflix,"Los Angeles, CA",14 hours ago,Be among the first 25 applicants,"['', 'Be the glue between engineering and analysis work with Studio Product Engineering to capture data that helps us analyze effectiveness and engagement across a wide array of products that support studio and production crew users Architect the data we use to calculate new product metrics and enable experimentation across the Studio product ecosystem Partner closely with Analytics Engineers, Data Scientists, and Product Managers to identify and ingest data from new sources & systems to discover product opportunities. Some of this data may be messy or not yet exist!Own, strengthen, and expand foundational Studio data models', 'Experience with sourcing and modeling data from application APIs', 'Own, strengthen, and expand foundational Studio data models', 'As a Senior Data Engineer in this space, you will…', 'Enthusiasm about innovating and learning in a fast paced environment', 'Strong communication; able to own and deepen direct relationships with our Engineering and Product Management partners', 'Expertise in data modeling and establishing data architecture across multiple systems', 'Architect the data we use to calculate new product metrics and enable experimentation across the Studio product ecosystem ', 'What You Bring To The Role', 'Hands-on experience building production data pipelines using one or more frameworks such as Spark, Flink or Hive/HadoopExpertise in data modeling and establishing data architecture across multiple systemsProficiency in Python and comfort working in a variety of tech stacks. A working knowledge of front-end development is a plus but not requiredExperience with sourcing and modeling data from application APIsStrong communication; able to own and deepen direct relationships with our Engineering and Product Management partnersEnthusiasm about innovating and learning in a fast paced environmentComfort with ambiguity; able to thrive with minimal oversight and process', 'Comfort with ambiguity; able to thrive with minimal oversight and process', 'Proficiency in Python and comfort working in a variety of tech stacks. A working knowledge of front-end development is a plus but not required', 'Culture', 'Partner closely with Analytics Engineers, Data Scientists, and Product Managers to identify and ingest data from new sources & systems to discover product opportunities. Some of this data may be messy or not yet exist!', 'Be the glue between engineering and analysis work with Studio Product Engineering to capture data that helps us analyze effectiveness and engagement across a wide array of products that support studio and production crew users ', 'Hands-on experience building production data pipelines using one or more frameworks such as Spark, Flink or Hive/Hadoop']",Not Applicable,Full-time,Information Technology,Entertainment,2020-10-06 11:54:06
Junior Data Scientist,Dice,"Fort Belvoir, VA",4 hours ago,Be among the first 25 applicants,"['', 'Qualifications', 'Full Time With Outstanding Benefits Compensation Open']",Entry level,Full-time,Engineering,Internet,2020-10-06 11:54:06
Data Engineer,Hudson Data,New York City Metropolitan Area,14 hours ago,Be among the first 25 applicants,"['', 'You are energized working in a fast-paced, highly collaborative and ambitious startup work environment.', 'Have exceptional communication skills to work with project managers and clients.', 'Expertise in Python, SQL, shell scripting, and databases.', 'You’ve been responsible for provisioning and configuring production infrastructure on a common cloud provider such as AWS or GCP.', 'Analytical mind and problem-solving aptitude.', 'You’re knowledgeable about graph theory and have previously worked with graph algorithms and data structures.', 'Requirements:', 'Work location: Virtual', 'Knowledge in Database systems technologies such as\xa0NoSQL DB ,Cache DB and Graph DB.', 'Comfortable working in Scrum.', '5+ years of applied software engineering experience.', 'You’ve worked with data scientists to put machine learning models into production', 'Work location', 'Team player and motivated to learn.', '5+ years of applied software engineering experience.You possess a BS or advanced degree in Computer Science, Math, Statistics or another quantitative field.Expertise in Python, SQL, shell scripting, and databases.Great communication skills (written/verbal).You’ve been responsible for provisioning and configuring production infrastructure on a common cloud provider such as AWS or GCP.Familiarity with our stack (Kubernetes, Docker, Kafka, Redshift, Airflow, Hive, Data Studio) and with different modeling techniques such as data vault.You’ve worked with data scientists to put machine learning models into productionYou’re knowledgeable about graph theory and have previously worked with graph algorithms and data structures.You have experience leveraging Spark (DataFrames, Query/Job Optimization, Building ETL Pipelines) or an analogous framework.Knowledge in Database systems technologies such as\xa0NoSQL DB ,Cache DB and Graph DB.You are energized working in a fast-paced, highly collaborative and ambitious startup work environment.Team player and motivated to learn.Comfortable working in Scrum.Analytical mind and problem-solving aptitude.Have exceptional communication skills to work with project managers and clients.', 'Great communication skills (written/verbal).', 'Familiarity with our stack (Kubernetes, Docker, Kafka, Redshift, Airflow, Hive, Data Studio) and with different modeling techniques such as data vault.', 'You possess a BS or advanced degree in Computer Science, Math, Statistics or another quantitative field.', 'You have experience leveraging Spark (DataFrames, Query/Job Optimization, Building ETL Pipelines) or an analogous framework.']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-10-06 11:54:06
Data Engineer,ServiceTitan,"Atlanta, GA",6 hours ago,64 applicants,"['', 'Map data', 'Contribute material input to go/no-go/continue decisions upon test completion', 'Vertical SaaS experience is highly desirable', ' Health & Wellness: ', 'Results and solution oriented - we want to know how we can win, not why we can’t', 'Equal Opportunity Employer', ' Work/Life Balance: ', '2-5 years of experience with SQL Server 2008/2012/2014/2016', ' Enrichment: ongoing learning culture with access to Linkedin Learning and professional development workshops, diversity charter groups, orientation program, career pathing opportunities, mentorship programs', 'Strong analytical thinking skills', ' Family-Friendly Benefits:', 'Contribute', 'Advanced knowledge and experience in T-SQL, complex ETL tools and operations, and SSIS', ' Family-Friendly Benefits: extended parental leave, pregnancy support, 20k in adoption reimbursement, Snoo Smart Sleeper, back-up childcare credits, legal benefit, discounted pet insurance', 'As Our Data Engineer, You Will', 'Establish quality working relationships with internal stakeholders', ' Work/Life Balance: flexible work schedule, flexible PTO', 'Develop', 'Given the experimental nature of this job, we will require very tight compliance when it comes to data - we need to focus on learning', 'Map data from various legacy databases into the ServiceTitan platform, subsequently developing SQL scripts that will extract the information efficiently and accurately', ' Health & Wellness: company-paid medical/vision/dental/life insurance/disability, employer HSA contribution, free One Medical membership, care coordination support, 401(k) with company match, stipend for home office equipment/supplies, gym discounts, monthly cell phone stipend', 'Develop automated scripts to validate legacy database values and identify previously unmapped fields prior to loading them into the ServiceTitan platform', 'About ServiceTitan', 'Establish', 'Apply feedback from customers and internal stakeholders on data import quality into previously developed extraction scripts', 'Ability to work independently and cross functionally', ' 2-5 years of experience with SQL Server 2008/2012/2014/2016 Advanced knowledge and experience in T-SQL, complex ETL tools and operations, and SSIS Given the experimental nature of this job, we will require very tight compliance when it comes to data - we need to focus on learning Strong analytical thinking skills Expert level understanding of database and data model concepts Vertical SaaS experience is highly desirable Results and solution oriented - we want to know how we can win, not why we can’t Ability to work independently and cross functionally ', ""To Be Successful In This Role, You'll Need"", 'Perks & Benefits', 'CCPA Notice for CA Residents applying to Jobs at ServiceTitan', ' Map data from various legacy databases into the ServiceTitan platform, subsequently developing SQL scripts that will extract the information efficiently and accurately Develop automated scripts to validate legacy database values and identify previously unmapped fields prior to loading them into the ServiceTitan platform Apply feedback from customers and internal stakeholders on data import quality into previously developed extraction scripts Discover opportunities to leverage information from legacy databases into the implementation process to avoid inquiring for additional information from customers Establish quality working relationships with internal stakeholders Contribute material input to go/no-go/continue decisions upon test completion ', 'Apply ', 'Discover ', 'Life at ServiceTitan ', 'Expert level understanding of database and data model concepts', 'Enrichment: ', 'Discover opportunities to leverage information from legacy databases into the implementation process to avoid inquiring for additional information from customers']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer,Open Systems Technologies,"Princeton, NJ",33 minutes ago,93 applicants,"['', 'Familiarity with Amazon Web Services (S3, RDS, Red Shift etc.) or Microsoft Azure ecosystems ', 'Develop detailed Technical design documentation, User Guides and Release Notes for all development efforts ', 'Responsible for ongoing software development for a business line interfacing with users and management in the planning of major functionality, analyzing business functional requirements to determine the scope of work, evaluating available application alternatives to support business needs, and managing the deliverables to completion ', 'Develop Data Integration Platforms – Transactional & Warehouses using ETL Tools, Data Quality Scorecards, Data Cleansing functions, Validated Integrations etc. with high availability/ scalability & performance ', 'Performance tuning SQL Queries using different tools. Clear understanding of query plan ', 'Responsibilities', 'Qualifications', 'A publishing company is seeking a Data Engineer\xa0to join their team in Princeton, NJ. ', 'Expertise in developing and maintaining tables, views, stored procedures, user-defined functions, complex queries using Microsoft SQL Server Management Studio (T-SQL) ', 'Design, implement, and support Data Models, Integration processes that provide timely access to large datasets ', 'Excellent communication and collaboration skills ', 'Ability to work independently and as a key contributor in a distributed team environment ', '5+ years of related work experience in Data Engineering BS/BA in technical field, Computer Science, Mathematics preferred or related work experience Expertise in developing and maintaining tables, views, stored procedures, user-defined functions, complex queries using Microsoft SQL Server Management Studio (T-SQL) Performance tuning SQL Queries using different tools. Clear understanding of query plan Experience in building Data Pipelines (using SSIS or equivalent) against disparate data sources such as flat files, databases, xml files and/or unstructured data & web services Experience with building front end dashboards utilizing C#/.NET framework is a plus Familiarity with Amazon Web Services (S3, RDS, Red Shift etc.) or Microsoft Azure ecosystems Excellent communication and collaboration skills Ability to work independently and as a key contributor in a distributed team environment ', 'BH 136687', 'Responsible for ongoing software development for a business line interfacing with users and management in the planning of major functionality, analyzing business functional requirements to determine the scope of work, evaluating available application alternatives to support business needs, and managing the deliverables to completion Design, implement, and support Data Models, Integration processes that provide timely access to large datasets Build fault tolerant, self-healing, adaptive and highly accurate Data platforms Develop Data Integration Platforms – Transactional & Warehouses using ETL Tools, Data Quality Scorecards, Data Cleansing functions, Validated Integrations etc. with high availability/ scalability & performance Develop detailed Technical design documentation, User Guides and Release Notes for all development efforts ', 'Responsibilities ', '5+ years of related work experience in Data Engineering ', 'Qualifications ', ' ', 'Experience with building front end dashboards utilizing C#/.NET framework is a plus ', 'BS/BA in technical field, Computer Science, Mathematics preferred or related work experience ', 'Build fault tolerant, self-healing, adaptive and highly accurate Data platforms ', 'Data Engineer', 'Experience in building Data Pipelines (using SSIS or equivalent) against disparate data sources such as flat files, databases, xml files and/or unstructured data & web services ']",Mid-Senior level,Full-time,Information Technology,Publishing,2020-10-06 11:54:06
Data Engineer,Lab49,"New York, NY",1 day ago,27 applicants,"['', 'Profile Requirements', 'The successful candidate will:', '\xa0', 'Expertise with Scala, Java or Python languages', 'Design and develop high-quality software solutions for Risk platformCreate new modules & data flows to meet regulatory requirements (FRTB, GMETH)Use Scala, Java or Python programming languages to build required functionalityImplement data pipelines using Big Data/Cloud technologies: Apache Spark, Hadoop, Microsoft Azure Cloud (Data Lake, Data Factory, Batch), and DatabricksDesign and develop Microservices using Spring Boot and Azure Kubernetes Service (PKS) cluster', 'Spark Developer certification is an added advantageAzure Data Factory, Azure Batch\xa0Expertise in Financial Services industry', 'Experience with any of the Big-3 Cloud platforms - Azure (preferred), AWS or Google', 'Experience building data lakes and data pipelines in the cloud', 'Role & Responsibilities', 'Spark Developer certification is an added advantage', 'Expertise with Scala, Java or Python languagesExperience with Spark, Hadoop, and Databricks (a must-have)Experience with any of the Big-3 Cloud platforms - Azure (preferred), AWS or GoogleExperience building data lakes and data pipelines in the cloudExperience designing high-performance, high-load systemsUnderstanding of the distributed Agile SDLC model', 'Design and develop high-quality software solutions for Risk platform', 'Create new modules & data flows to meet regulatory requirements (FRTB, GMETH)', 'Preferred Experience', 'Understanding of the distributed Agile SDLC model', 'Expertise in Financial Services industry', 'Experience designing high-performance, high-load systems', 'Lab49 is currently looking for a Data Engineer to build a strategic Risk calculation engine and associated workflows. The candidate will participate in the design and development of the platform, interacting with globally distributed Risk Officers (Market Risk, Credit Risk), Quants and IT Dev/QA team.', 'Use Scala, Java or Python programming languages to build required functionality', 'Azure Data Factory, Azure Batch\xa0', 'Design and develop Microservices using Spring Boot and Azure Kubernetes Service (PKS) cluster', 'Experience with Spark, Hadoop, and Databricks (a must-have)', 'Implement data pipelines using Big Data/Cloud technologies: Apache Spark, Hadoop, Microsoft Azure Cloud (Data Lake, Data Factory, Batch), and Databricks']",Mid-Senior level,Full-time,Information Technology,Financial Services,2020-10-06 11:54:06
Software Engineer,"Mettler-Toledo International, Inc","Columbia, MD",23 hours ago,Be among the first 25 applicants,"['', 'Equal Opportunity Employment', 'Experience with Microsoft Visual Studio and Team Foundation\xa0Server a plus', 'Performing software testing using formal test cases as well as ad-hoc tests.', 'Mettler Toledo endeavors to make www.mt.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at EEO@mt.com.', 'We are an equal opportunity employer and value diversity at our company. We give consideration for employment without regard to race, color, religion, sex, age, national origin, disability, sexual orientation, gender identity, genetic information, protected veteran status, or any other protected classification. If you’d like more information about your EEO rights as an applicant under the law, please click here.', 'A bachelor’s degree in Computer Science, Engineering, or related field or equivalent combination of education and experience.', 'A bachelor’s degree in Computer Science, Engineering, or related field or equivalent combination of education and experience.Two (2) to five (5) years of experience in the design, development, and support of software productsThe ability to work both independently and in a team environment utilizing a state-of-the-art product development lifecycle management framework and supporting toolsExcellent organizational skills and attention to detailExperience with Microsoft Visual Studio and Team Foundation\xa0Server a plusExperience with Object-Oriented design and C# a plusExperience with the development of process instrumentation software a plus', 'Our products help develop profitable, green, and safe scientific processes.', 'Our Opening and Your Responsibilities', 'Our instruments increase the efficiency and effectiveness of chemists and engineers.Our products help develop profitable, green, and safe scientific processes.We help keep you healthy. Our instruments make it possible for scientists to develop new drugs and bring life-saving medicines to the world.', 'Parental and caregiver leave programs', 'Designing, implementing, and unit testing software.', 'All the usual benefits such as paid time off, flexible spending, short-and long-term disability, basic life insurance, business travel insurance, EmployeeAssistance Program, and domestic partner benefits', 'Experience with Object-Oriented design and C# a plus', 'Global market strength and worldwide leadership in precision instrumentation', 'Designing, implementing, and unit testing software.Analyzing and solving technical problems including software defects and develop and test software bug fixes.Participating in requirements engineering activities for new software productsPerforming software testing using formal test cases as well as ad-hoc tests.Developing and/or reviewing formal test cases for software products.Performing end user support, including onsite support, phone support, and interactive web sessions.Developing software development project documents', 'About Mettler Toledo', 'Working at METTLER TOLEDO AutoChem Inc. (www.mt.com/autochem) means you are impacting the world in important ways. Our process analytical technology and automated synthesis reactors provide scientists in the pharmaceutical, biotechnology, and chemical industries the information they need to deliver life-changing products.\xa0 As a strategic business unit within Mettler Toledo, AutoChem develops, manufactures, sells, and services instruments that modernize chemical synthesis, provide insight to every chemical reaction, and provide process knowledge to eliminate scale-up and safety incidents.\xa0', 'Your responsibilities would include:', 'A brand name that is identified worldwide with precision, quality, and innovation', 'Our instruments increase the efficiency and effectiveness of chemists and engineers.', 'Two (2) to five (5) years of experience in the design, development, and support of software products', 'Performing end user support, including onsite support, phone support, and interactive web sessions.', 'Thousands of patents, design and innovation awards across Mettler Toledo ', 'What You Need to Succeed', 'Developing and/or reviewing formal test cases for software products.', 'Developing software development project documents', 'Medical, dental and vision care coverage and a 401(k) savings plan with company matching – all starting on date of hireTuition reimbursement,\xa0perks, and discountsParental and caregiver leave programsAll the usual benefits such as paid time off, flexible spending, short-and long-term disability, basic life insurance, business travel insurance, EmployeeAssistance Program, and domestic partner benefitsGlobal market strength and worldwide leadership in precision instrumentationA brand name that is identified worldwide with precision, quality, and innovationThousands of patents, design and innovation awards across Mettler Toledo Global recognition for the quality of our products and services', 'The ability to work both independently and in a team environment utilizing a state-of-the-art product development lifecycle management framework and supporting tools', 'Our Software Development team is currently searching for a Software Engineer. You will be responsible for software development, software testing, end user support, software defect resolution, software project documentation, while maintaining compliance with the Software Quality Management System.', 'Our Offer to You', ' ', 'Analyzing and solving technical problems including software defects and develop and test software bug fixes.', 'Experience with the development of process instrumentation software a plus', 'Tuition reimbursement,\xa0perks, and discounts', 'We help keep you healthy. Our instruments make it possible for scientists to develop new drugs and bring life-saving medicines to the world.', 'Participating in requirements engineering activities for new software products', 'About Mettler Toledo ', 'Medical, dental and vision care coverage and a 401(k) savings plan with company matching – all starting on date of hire', 'Excellent organizational skills and attention to detail', 'Global recognition for the quality of our products and services']",Entry level,Full-time,Engineering,Mechanical or Industrial Engineering,2020-10-06 11:54:06
Big Data Engineer - Wallet & Apple Pay - NYC,Apple,"New York, NY",59 minutes ago,Be among the first 25 applicants,"['', 'Key Qualifications', 'Description', 'Summary', 'Education & Experience']",Not Applicable,Full-time,Engineering,Consumer Electronics,2020-10-06 11:54:06
Data Engineer,Putnam Recruiting Group,Los Angeles Metropolitan Area,17 hours ago,50 applicants,"['', 'Proficiency with Python', 'Experience with SQL, AWS Glue and Airflow', ""If you have subscription company or content company experience, that's a plus!"", '4+ years of relevant data engineering work experience', 'Build ETLs, data pipelines, data infrastructure, SQL queries and conduct some data analysis to support other teams', ""4+ years of relevant data engineering work experienceExperience with SQL, AWS Glue and AirflowProficiency with PythonWorked at small to medium sized companies and are accustomed to wearing many hatsIf you have subscription company or content company experience, that's a plus!"", '\xa0The Role', 'This is an opportunity to join a talented team with a truly awesome, collaborative culture!', 'Worked at small to medium sized companies and are accustomed to wearing many hats', 'This company is a fitness tech company offering a streaming service through their online platform, which boasts thousands of professionally-filmed classes for a small monthly subscription. They are also expanding their fitness program portfolio and are completely self-funded!', 'You Have']",Mid-Senior level,Full-time,Engineering,Staffing and Recruiting,2020-10-06 11:54:06
Data Engineer,VLink Inc,"New York, NY",1 hour ago,Be among the first 25 applicants,"['', ' Excellent problem solving skills and Strong communication skills.', ' Demonstrate technical capabilities to support existing systems while demonstrating the independent drive to build new features.', ' Able to manage multiple assignments concurrently adjusting easily as business needs change and acquiring necessary new working knowledge quickly.', ' Experience in one scripting language Python or Scala For client interview the associate may be asked to code and providing a solution Sense of ownership.', 'Are you serious about your career change? ', ' Experience: 6-8 years', ' Data Engineer who directly interact with customer.', ' Creative and inquisitive professional with excellent interpersonal and cross functional divisional collaboration skills.', ' Specialized knowledge required: Python, Snowflake, SQL', ' Quick learner be able to quickly understand complex business.', 'Job Description', ' Ability to own lead production deployments and support.', ' Exposure on AWS including S3 EC2 EMR Lambda is added advantage Experience in writing SQL.', ' Specialized knowledge required: Python, Snowflake, SQL Experience: 6-8 years Excellent problem solving skills and Strong communication skills. Data Engineer who directly interact with customer. Creative and inquisitive professional with excellent interpersonal and cross functional divisional collaboration skills. Able to manage multiple assignments concurrently adjusting easily as business needs change and acquiring necessary new working knowledge quickly. Demonstrate technical capabilities to support existing systems while demonstrating the independent drive to build new features. Exposure on AWS including S3 EC2 EMR Lambda is added advantage Experience in writing SQL. Experience in one scripting language Python or Scala For client interview the associate may be asked to code and providing a solution Sense of ownership. Ability to own lead production deployments and support. Good communication Ability to communicate with the management and users independently. Quick learner be able to quickly understand complex business.', ' Good communication Ability to communicate with the management and users independently.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer,Conduent,United States,7 hours ago,Be among the first 25 applicants,"['', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience in cloud-based ETL development processes.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Learn and develop new ETL techniques as required to keep up with contemporary technologies.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Worked in big data environments, cloud data stores, different RDBMS, and OLAP solutions.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Support presentations to Customers and Partners', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Advising on new technology trends and possible adoption to maintain a competitive advantage', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A BS or Masters degree in Computer Science or related technical discipline is required', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Excellent SQL coding experience with performance optimization for data queries.', '\xa0', 'Prior experience with application delivery using an Onshore/Offshore model', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa05+ years of related experience is required.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Develop/maintain efficient data collection systems and sound strategies for getting quality data from different sources', 'Demonstrated ability to have successfully completed multiple, complex technical projectsPrior experience with application delivery using an Onshore/Offshore modelExperience with business processes across multiple Master data domains in a services-based companyDemonstrates a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality.Demonstrates high standards of professional behavior in dealings with clients, colleagues and staff.Is able to make sound and far-reaching decisions alone on major issues and to take full responsibility for them on a technical basis.Strong written communication skills. Is effective and persuasive in both written and oral communication.Experience with gathering end-user requirements and writing technical documentationTime management and multitasking skills to effectively meet deadlines under time-to-market pressureRequires some travel (on average 10%-20%)', 'Experience with gathering end-user requirements and writing technical documentation', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Performs data management tasks, such as to conduct data profiling, assess data quality, and write SQL queries to extract and integrate data', 'Demonstrates a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience connecting to varied data sources', 'Time management and multitasking skills to effectively meet deadlines under time-to-market pressure', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Has a strong technical background and remains evergreen with technology and industry developments.', 'Additional Requirements', 'Demonstrates high standards of professional behavior in dealings with clients, colleagues and staff.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Collaborate in design reviews and code reviews to ensure standards are met. Recommend new standards for visualizations.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Is familiar with the principles and practices involved in development and maintenance of software solutions and architectures and service delivery.', 'Strong written communication skills. Is effective and persuasive in both written and oral communication.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Engineer and maintain a modern Cloud data pipeline to collect, organize, and process data from disparate sources.', 'Fulltime Remote position ', 'Responsibilities:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Consume and analyze data from the data pool to support inference, prediction, and recommendation of actionable insights to support business growth.', 'Experience Needed:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Design, develop, and maintain ETL processes using tools and scripting. Troubleshoot and debug ETL processes. Performance tuning and optimization of the ETL processes.', 'Is able to make sound and far-reaching decisions alone on major issues and to take full responsibility for them on a technical basis.', 'Experience with business processes across multiple Master data domains in a services-based company', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Provide support to new or existing applications while recommending best practices and leading projects to implement new functionality.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience in the deployment and maintenance of ETL Jobs.', 'Demonstrated ability to have successfully completed multiple, complex technical projects', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Understands different data models like normalized, de-normalied, stars, and snowflake models. Worked with transactional, temporal, time series, and structured and unstructured data.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Reviews the solution requirements and architecture to ensure the selection of appropriate technology, efficient use of resources, and integration of multiple systems and technology.', 'We are looking for a Data Engineer who will be part of our Analytics Practice and will be expected to actively work in a multi-disciplinary fast-paced environment. This role requires a broad range of skills and the ability to step into different roles depending on the size and scope of the project; its primary responsibility is the development and maintenance of data pipelines including acquisition, transformation, loading, and processing of data.\xa0', 'Data Engineer', 'Requires some travel (on average 10%-20%)', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0ETL experience with data integration to support data marts, extracts, and reporting']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
" Data Engineer, eCommerce",Anheuser-Busch InBev,"New York, NY",,Be among the first 25 applicants,"['', 'Have experience\xa0working in a central analytics or data strategy role within a large enterprise\xa0environment', 'About the Job', 'Lead from the front – not afraid to get hands dirty in troubleshooting a problem or chasing a data quality issue through resolution', 'The Global Manager of eCommerce Data Engineering will create, oversee and maintain commercial and external data pipelines working closely with our commercial, product and technology leads to standardize our commercial and external data. This person should have experience building data integrations to sales and ERP systems such as SAP, maintaining centralized data warehouses and data dictionaries for multiple commercial stakeholders.', 'Desired/Required\xa0Qualifications\xa0', 'BA/BS degree (Computer Science, Software/Computer Engineering, Information Systems, Statistics, or similar technical field)\xa0', 'A creative thinker – Enjoys challenges and has a passion for solving complex problems and generating multi-functional solutions', 'You Will', 'Live and breathe data – providing the best, most correct data is your obsession', 'A self-starter who can lead strategic projects and deliver results in a fast-paced environment', 'Leadership Style', 'Execute, and maintain the strategy for our data warehousing and pipelines to cater to specific business objectives, from implementation to maintenance', 'Take ownership of understanding the business and operational problems at hand and how to best solve them through a data-driven approach', 'Have strong communication skills: able to\xa0clearly understand business objectives\xa0and translate them to an end to end data strategy and execution\xa0Have experience\xa0working in a central analytics or data strategy role within a large enterprise\xa0environmentHave experience operating in a production level data warehouse and/or data lakeLive and breathe data – providing the best, most correct data is your obsessionHave extensive working knowledge of SQL and relational databasesBuild ETL pipelines from a variety of data sources using cloud (AWS, GCP, Azure) technologies.Experience with Python, R and modelling a plusHave experience\xa0working with\xa0both\xa0highly technical\xa0and non-technical profiles on a day-to-day basis\xa0', 'Prioritize and find the most efficient path towards solving complex, ambiguous business problems with data, keeping a mindset of simplicity, robustness and speed above all', 'Proven results in building highly impactful data warehousing systems that serve multiple functions.', 'Experience structuring data from unstructured data sources and maintaining SLAs for delivery.', 'About the Team', 'Main stakeholders will include sales functions (commercial reporting, promo analytics, and sales algorithms) and customer data product leadership.\xa0', 'Have experience operating in a production level data warehouse and/or data lake', 'Have experience\xa0working with\xa0both\xa0highly technical\xa0and non-technical profiles on a day-to-day basis\xa0', 'We’re rethinking the way AB InBev does business with its retail customers and creating digital experiences to serve them. You will be joining a new digital organization within AB InBev consisting of digital strategy,\xa0product, design, analytics, operations and engineering. This organization is responsible for building the products and platforms that transform our traditional sales operations across the world.', 'Be a key leader in our global organization, working fluidly across ABI’s global and local teams and functions (sales, finance, marketing, product, IT, etc.) to make data-driven initiatives successful in an efficient way', 'Experience with Python, R and modelling a plus', 'About You\xa0', 'About the Job\xa0', 'Desired/Required\xa0Qualifications', 'Create and maintain optimal data pipeline architecture, – own all data sources (transactional, internal and external data\xa0within our e-commerce organization) and ensure their accuracy to maintain commercial functions in our digital platformsTake ownership of understanding the business and operational problems at hand and how to best solve them through a data-driven approachExecute, and maintain the strategy for our data warehousing and pipelines to cater to specific business objectives, from implementation to maintenanceBe a key leader in our global organization, working fluidly across ABI’s global and local teams and functions (sales, finance, marketing, product, IT, etc.) to make data-driven initiatives successful in an efficient wayPrioritize and find the most efficient path towards solving complex, ambiguous business problems with data, keeping a mindset of simplicity, robustness and speed above all', 'ABI Digital is a digital organization within AB InBev building a platform to improve the ways retailers run their businesses and interact with the world’s largest brewer. We provide transactional and educational resources to SMB retailers across the world to help reduce the overhead of their day-to-day operations and make their businesses more profitable. Today more than 700,000 SMB retailers across 18 countries use the ABI Digital platform to transact with the AB InBev and manage their business.\xa0', 'About ABI Digital\xa0', 'BA/BS degree (Computer Science, Software/Computer Engineering, Information Systems, Statistics, or similar technical field)\xa0Experience with Data Warehouses such as Google Big Query, Snowflake, AWS, or Azure in an international organizationExperience structuring data from unstructured data sources and maintaining SLAs for delivery.Experience managing the full end-to-end pipeline for data warehousing and data pipelines of commercial data for multiple analytics and BI stakeholdersExperience working in a full Data Engineering team with direct reports: QA, Data Engineers, Data Analysts, DBAs, etc.', 'Have extensive working knowledge of SQL and relational databases', 'Build ETL pipelines from a variety of data sources using cloud (AWS, GCP, Azure) technologies.', 'Experience working in a full Data Engineering team with direct reports: QA, Data Engineers, Data Analysts, DBAs, etc.', 'Experience with Data Warehouses such as Google Big Query, Snowflake, AWS, or Azure in an international organization', 'Experience managing the full end-to-end pipeline for data warehousing and data pipelines of commercial data for multiple analytics and BI stakeholders', 'About ABI Digital', 'Create and maintain optimal data pipeline architecture, – own all data sources (transactional, internal and external data\xa0within our e-commerce organization) and ensure their accuracy to maintain commercial functions in our digital platforms', 'Our team is in search of a\xa0Global Manager, eCommerce Data Engineering to\xa0be a leader in our Global Revenue Management & Commercial organization and\xa0help build, and maintain our data engineering infrastructure geared towards solving business problems and provide commercial value for ABI.\xa0This position reports directly to the Global Director of eCommerce Data Engineering.', 'About You', 'Proven results in building highly impactful data warehousing systems that serve multiple functions.A self-starter who can lead strategic projects and deliver results in a fast-paced environmentLead from the front – not afraid to get hands dirty in troubleshooting a problem or chasing a data quality issue through resolutionA creative thinker – Enjoys challenges and has a passion for solving complex problems and generating multi-functional solutions', 'Have strong communication skills: able to\xa0clearly understand business objectives\xa0and translate them to an end to end data strategy and execution\xa0']",Mid-Senior level,Full-time,Engineering,Consumer Goods,2020-10-06 11:54:06
Data Engineer,TriStaff Group of Companies,"San Diego, CA",22 hours ago,35 applicants,"['What You Get To Do: ', 'Familiarity with Microsoft Azure services (Azure SQL, Data Factory, Data Lake Store, Power BI) ', 'Analytical and problem-solving skills ', 'Computer Skills', 'Education and/or Experience ', 'Mentors software engineers on best practices related to data access and management ', 'Prior experience in PBM, pharmaceutical or managed health care industry preferred ', 'Ability to work in a fast-paced and dynamic environment Requirements gathering and analysis Proven experience promoting process improvement Familiarity with software development fundamentals ', 'The Perks: ', 'Understanding of web applications and/or other distributed application architectures ', 'Using industry best practices for data architecture and management, the Data Engineer plans, designs, and optimizes custom application databases. Such activities involve understanding of the business processes the application data supports, interacting with development teams and end-users to determine application data access requirements, transaction rates, volume analysis, data modification/transformation needs, and other pertinent data required to maintain integrated databases and support business processes. Designs data access methodologies for optimal use of the data environments. Makes recommendations on and implements data-driven tuning exercises. \xa0 ', 'Education and/or Experience', 'Travel - This position may require occasional domestic travel and attendance maybe required at various local conferences and meetings. ', '\xa0', 'To perform this job successfully, an individual must have: ', 'Knowledge of HIPAA standards ', 'Computer Skills ', 'Serves as database subject matter expert (SME); assists developers and analytics staff with SQL Queries as well as stored procedures ', 'Supports data cataloging and data governance activities ', 'Working knowledge of database and data-access concepts Proficiency in identifying data patterns, trends and anomalies Understanding of web applications and/or other distributed application architectures ', '\xa0 ', 'Creates conceptual, logical, and physical data models ', 'Working knowledge of database and data-access concepts ', ""For consideration, candidates will need a Bachelor's degree (or equivalent combination of education and experience) along with at least eight (8) plus years’ related experience "", 'Experience with healthcare data (drug information, formulary, etc.) Knowledge of HIPAA standards ', 'Hands on experience developing complex SQL queries and stored procedures (T-SQL) ', 'Our direct client here in the San Diego area is seeking a Data Engineer on a full time basis. No sponsorship at this time. ', 'Good verbal/writing communication as well as interpersonal skills ', 'Azure Data Engineer Associate certification is highly desired ', 'Paid Time Off / Company Paid Holidays ', 'Establishes data standards and ensure data quality ', '401K with Company match ', 'What You Need: ', 'Other Skills and Abilities ', 'Analyzes, designs and develops enterprise data and information architecture ', 'Medical / Dental / Vision / Wellness Programs ', 'Travel ', 'Experience developing data ingestion and processing solutions (ETL using SSIS) ', 'Employee Referral Bonus', 'Requirements gathering and analysis ', 'Certificates, Licenses, Registrations', 'Proficiency in identifying data patterns, trends and anomalies ', ' ', 'Develops ETL processes to automate data ingestion and processing ', 'Knowledge of Microsoft SQL Server best practices ', 'Organizes data and tune data environments for optimal performance while managing cloud compute and storage costs ', 'Works within Azure Cloud environment ', 'Certificates, Licenses, Registrations ', 'Tuition Reimbursement ', 'Familiarity with software development fundamentals ', 'Other Skills and Abilities', 'Life and Disability Insurance ', 'Ability to work in a fast-paced and dynamic environment ', 'Proven experience promoting process improvement ', 'Experience creating conceptual, logical, and physical data models ', 'None required ', 'Experience with healthcare data (drug information, formulary, etc.) ', 'Knowledge of SQL Server performance tuning, key configuration parameters, and version features ']",Mid-Senior level,Full-time,Information Technology,Consumer Services,2020-10-06 11:54:06
Data Scientist,Jobot,"Arlington, VA",6 hours ago,Be among the first 25 applicants,"['', 'A Bit About Us', ' Apply machine learning techniques including deep learning, to protect networks and devices from cyber threats ', ' Commuting/Transit Benefits + Allowances', ' Generous PTO/Vacation ', ' Read/author research papers, white papers, proposals, and presentations', ' Implement graph-theoretic algorithms and machine learning models for graphs', ' Full Benefits + 100% Paid Premiums ', ' Implement supervised and unsupervised algorithms for data fusion, predictive analytics, and anomaly detection tasks in cybersecurity', 'Qualifications', ' Apply machine learning techniques including deep learning, to protect networks and devices from cyber threats  Implement supervised and unsupervised algorithms for data fusion, predictive analytics, and anomaly detection tasks in cybersecurity Implement graph-theoretic algorithms and machine learning models for graphs Analyze and build systems that use multiple sources of data, including cybersecurity logs, network traffic, PCAP, and OSINT Implement algorithms for natural language processing, information extraction, and vector space models Read/author research papers, white papers, proposals, and presentations', ' Ability to get and maintain TS/SCI security clearance***', ' Analyze and build systems that use multiple sources of data, including cybersecurity logs, network traffic, PCAP, and OSINT', 'Why join us?', ' BS/MS in quantitative field  Proficiency in one or more data science programming language Python, R, Java, Scala, etc. Experience with deep learning frameworks, distributed computing and/or productionizing data science workflows  Ability to get and maintain TS/SCI security clearance***', ' Proficiency in one or more data science programming language Python, R, Java, Scala, etc.', ' Competitive Salary + Bonuses  Generous PTO/Vacation  Full Benefits + 100% Paid Premiums  401k + Match  Commuting/Transit Benefits + Allowances', ' Experience with deep learning frameworks, distributed computing and/or productionizing data science workflows ', ' BS/MS in quantitative field ', ' 401k + Match ', ' Implement algorithms for natural language processing, information extraction, and vector space models', 'Job Details', ' Competitive Salary + Bonuses ']",Mid-Senior level,Full-time,Engineering,Computer & Network Security,2020-10-06 11:54:06
Vehicle Data Engineer,General Motors,"Warren, MI",10 hours ago,Be among the first 25 applicants,"['', 'a seamless interaction with back office servers and applications using state of the art protocols', 'the collection of vehicle data based on dynamic data requests from back office serversthe secure in-vehicle pre-processing of datathe cost-efficient exchange of data between the vehicle and the back officea seamless interaction with back office servers and applications using state of the art protocolsin-vehicle features to leverage these data collection, processing and offloading mechanisms for the in-vehicle features data needs.The Vehicle Data Engineer’s role doesn’t end at with the development of requirements and specifications, but extends into supporting DFMEAs, supporting the coordination of the seamless implementation and execution of the specified mechanism in cross functional teams, the support of bench work and the development of data collection scripts', 'in-vehicle features to leverage these data collection, processing and offloading mechanisms for the in-vehicle features data needs.', ' Global recognition program for peers and leaders to recognize and be recognized for results and behaviors that reflect our company values;', 'About GM', '8+ years of experience in a job related area', 'Desired Skills', 'In-vehicle electrical architectures (networks consisting of ECUs, Sensors, Gateways, Switches, Routers etc.)', 'Design/Development of time and/or safety critical Systems/Components', 'Experience in working in / leading cross functional teams', 'Experience in performing system and component level DFMEAs / DFMEA training', 'Project Management Experience, Strong communication skills', 'Software architecture / Software systems / Programming languages(While software development is not the focus of this position, the role of the Vehicle Data Engineer does require the ability to develop code (e.g. script for data collection purposes). Furthermore, the role does require a solid understanding of software-based systems, prior hands-on experience with software development and programming languages for embedded and non-embedded systems, knowledge of data structures, data exchange formats, hypervisors, efficient algorithms and state of the art middleware and software architectures)', 'In-vehicle communication systems (automotive communication protocols such as CAN or automotive Ethernet, publish/subscribe mechanisms, inter-process communication mechanisms, diagnostic communication mechanisms)', 'DFSS Certification', 'The Vehicle Data Engineer’s role doesn’t end at with the development of requirements and specifications, but extends into supporting DFMEAs, supporting the coordination of the seamless implementation and execution of the specified mechanism in cross functional teams, the support of bench work and the development of data collection scripts', 'The Role ', 'Responsibilities', 'The Vehicle Data Engineer Responsible For And Contributes To The Development Of The Requirements And Specifications Of In-vehicle Mechanisms That Enable', 'This role is open to 6th and 7th level employees', '2-5 years minimum of experience in several of the areas of expertise outlined above', 'High level of oral and written communication skills', 'Experience in agile software development', 'GM Employees Only: ', 'Strong communication skills (verbal and in writing). Ability to express complex ideas and systems in clear and concise terms', 'Systems Engineering background (Sys. Eng. principles and practices. Sys. Eng. tools such as e.g. Doors Next Generation and Rational Team Concert. Experience in developing system designs / requirements and specifications.)', ' Tuition assistance and student loan refinancing;', 'MS in Computer Science or Electrical Engineering; or equivalent8+ years of experience in a job related areaStrong Systems Engineering background and experienceExperience in performing system and component level DFMEAs / DFMEA trainingProject Management Experience, Strong communication skillsDFSS CertificationSoftware coding experience in relevant / modern programming languagesExperience in agile software developmentDesign/Development of time and/or safety critical Systems/Components', ' Discount on GM vehicles for you, your family and friends.', 'Demonstrated technical and professional skills in job-related area', 'BS in Engineering, Physics, Math, Computer Science, Information Technology or Chemistry2-5 years minimum of experience in several of the areas of expertise outlined aboveHigh level of analytical ability where problems are unusual and difficultHigh level of interpersonal skills to work independently and effectively with othersDemonstrated technical and professional skills in job-related areaHigh level of oral and written communication skillsResults driven individual with high levels of initiative', 'This role of the Vehicle Data Systems Engineering strongly focuses on the development and analysis of the requirements and specifications of the previously mentioned in-vehicle enablers.', 'Job Description', ' Paid time off including vacation days, holidays, and parental leave for mothers, fathers and adoptive parents;', 'Experience in working in / leading cross functional teamsStrong communication skills (verbal and in writing). Ability to express complex ideas and systems in clear and concise termsSystems Engineering background (Sys. Eng. principles and practices. Sys. Eng. tools such as e.g. Doors Next Generation and Rational Team Concert. Experience in developing system designs / requirements and specifications.)In-vehicle electrical architectures (networks consisting of ECUs, Sensors, Gateways, Switches, Routers etc.)In-vehicle communication systems (automotive communication protocols such as CAN or automotive Ethernet, publish/subscribe mechanisms, inter-process communication mechanisms, diagnostic communication mechanisms)Software architecture / Software systems / Programming languages(While software development is not the focus of this position, the role of the Vehicle Data Engineer does require the ability to develop code (e.g. script for data collection purposes). Furthermore, the role does require a solid understanding of software-based systems, prior hands-on experience with software development and programming languages for embedded and non-embedded systems, knowledge of data structures, data exchange formats, hypervisors, efficient algorithms and state of the art middleware and software architectures)Embedded systems (ECUs, microcontrollers, embedded systems, automotive middleware, real-time systems)Communication protocols / Cloud protocols / IoT protocols (Solid theoretical background and practical experience communication/ cloud and IoT protocols. TCP/IP protocol family, publish/subscribe protocols, IoT protocols, protocol at different layers in the ISO-OSI reference model)This role of the Vehicle Data Systems Engineering strongly focuses on the development and analysis of the requirements and specifications of the previously mentioned in-vehicle enablers.', 'the cost-efficient exchange of data between the vehicle and the back office', 'Requirements', 'Strong Systems Engineering background and experience', 'High level of interpersonal skills to work independently and effectively with others', 'MS in Computer Science or Electrical Engineering; or equivalent', 'Benefits Overview', ' Company and matching contributions to 401K savings plan to help you save for retirement;', 'the secure in-vehicle pre-processing of data', 'Embedded systems (ECUs, microcontrollers, embedded systems, automotive middleware, real-time systems)', 'BS in Engineering, Physics, Math, Computer Science, Information Technology or Chemistry', 'Results driven individual with high levels of initiative', 'Communication protocols / Cloud protocols / IoT protocols (Solid theoretical background and practical experience communication/ cloud and IoT protocols. TCP/IP protocol family, publish/subscribe protocols, IoT protocols, protocol at different layers in the ISO-OSI reference model)', 'High level of analytical ability where problems are unusual and difficult', 'Software coding experience in relevant / modern programming languages', 'the collection of vehicle data based on dynamic data requests from back office servers', ' Healthcare (including a triple tax advantaged health savings account and wellness incentive), dental, vision and life insurance plans to cover you and your family;']",Not Applicable,Full-time,Project Management,Automotive,2020-10-06 11:54:06
"AWS, Big Data Engineer","The Consortium, Inc. ","Rockville, MD",1 hour ago,Be among the first 25 applicants,"['', 'Provide creative solutions to problems', 'Engage in performance tuning and scalability engineering', 'Experience with Spark', '\xa0', 'Analyze system requirements and design responsive algorithms and solutions', 'Experience with cloud based Big Data technologiesProficiency in Hive / Spark SQLExperience with SparkExperience with one or more programming languages like Scala, Python, and/or JavaAbility to push the frontier of technology and independently pursue better alternatives\u200b', 'Experience with one or more programming languages like Scala, Python, and/or Java', 'Use big data and cloud technologies to produce production quality code', 'Perform related SDLC engineering activities like sprint planning and estimation', 'Ability to push the frontier of technology and independently pursue better alternatives\u200b', 'Job Functions:', 'Work with team, peers and management to identify objectives and set priorities', 'Identify opportunities for improvement and execute', 'Analyze system requirements and design responsive algorithms and solutionsUse big data and cloud technologies to produce production quality codeEngage in performance tuning and scalability engineeringWork with team, peers and management to identify objectives and set prioritiesPerform related SDLC engineering activities like sprint planning and estimationWork effectively in small agile teamsProvide creative solutions to problemsIdentify opportunities for improvement and execute', 'Proficiency in Hive / Spark SQL', 'Work effectively in small agile teams', 'Essential skills:', 'Experience with cloud based Big Data technologies']",Mid-Senior level,Full-time,Marketing,Information Technology and Services,2020-10-06 11:54:06
Data Engineer / OCR Specialist,"ASR Analytics, LLC",Washington DC-Baltimore Area,16 minutes ago,Be among the first 25 applicants,"['', 'Balance efficiency and accuracy on assigned projects and tasks.', 'Achieve goals in a timely manner, overcoming obstacles by organizing and prioritizing assigned tasks.', 'Leverage established tools, assets, or techniques in support of project and product delivery.', '\xa0', 'Bachelor’s in Economics, Statistics, Mathematics, Computer Science or related field, or equivalent experience.1-5 years’ experience, preferred.Experience with Tesseract, PyOCR, or other open source OCR toolsExperience with iPro, DataCap, or other commercial OCR tools.Experience with SQL Programming.Experience with a statistical software package such as Python or R.Ability to work well in a team environment.Superior problem-solving skills.Excellent communication skills (writing, speaking, and presenting)Ability to work independently, be self-motivated, and innovative.Experience working with government agencies preferred.', 'ASR Analytics is looking for a Data Engineer / OCR Specialist to join our growing and dynamic team.\xa0The ideal candidate will have experience managing and administering both open source optical character recognition (OCR) software (e.g., Tesseract, PyOCR) and commercial tools (e.g., iPro, DataCap) to complete OCR tasks in a Linux environment.\xa0The Data Engineer / OCR Specialist will provide data engineering and analysis support to clients; identify and resolve issues and risks on own assignments; perform quality control of their assigned deliverables and work products; present project findings and results to senior staff; and contribute to business development initiatives based on direction of senior staff.', 'Contribute to the development of reusable intellectual capital and assets, such as: processes, documentation, training material, software/code, templates, etc.', 'Ability to work independently, be self-motivated, and innovative.', 'Provide technical and analytical consulting services to clients as part of an integrated team that includes government personnel', 'Excellent communication skills (writing, speaking, and presenting)', '1-5 years’ experience, preferred.', 'Experience with a statistical software package such as Python or R.', 'Respond promptly to client requests or inquiries.', 'Qualifications and Skills:', 'Experience with iPro, DataCap, or other commercial OCR tools.', 'Experience working with government agencies preferred.', 'Requirements', 'Experience with Tesseract, PyOCR, or other open source OCR tools', 'Demonstrate sound decision-making and make recommendations on a regular basis; communicate these decisions clearly to colleagues.', 'Bachelor’s in Economics, Statistics, Mathematics, Computer Science or related field, or equivalent experience.', 'Ability to work well in a team environment.', 'Superior problem-solving skills.', 'Use OCR software to convert image files in various formats (e.g., TIFF, PDF, JPEG) into machine-readable data.Build OCR templates and design OCR batch processesProvide technical and analytical consulting services to clients as part of an integrated team that includes government personnelDeliver work products throughout the project lifecycle, consistently meeting or exceeding client expectations.Leverage established tools, assets, or techniques in support of project and product delivery.Demonstrate sound decision-making and make recommendations on a regular basis; communicate these decisions clearly to colleagues.Assist in execution of an approach to solving complex client problems.Achieve goals in a timely manner, overcoming obstacles by organizing and prioritizing assigned tasks.Balance efficiency and accuracy on assigned projects and tasks.Contribute to the development of reusable intellectual capital and assets, such as: processes, documentation, training material, software/code, templates, etc.Respond promptly to client requests or inquiries.', 'Assist in execution of an approach to solving complex client problems.', 'Experience with SQL Programming.', 'Use OCR software to convert image files in various formats (e.g., TIFF, PDF, JPEG) into machine-readable data.', 'Deliver work products throughout the project lifecycle, consistently meeting or exceeding client expectations.', 'Build OCR templates and design OCR batch processes']",Mid-Senior level,Full-time,Consulting,Management Consulting,2020-10-06 11:54:06
Data Engineer,Saggezza,"Chicago, IL",20 hours ago,Over 200 applicants,"['', 'We welcome innovators with entrepreneurial spirits to grow with our team.\xa0', 'Diverse culture, experiences, and skills.Our nurturing and supportive environment fosters collaboration across the entire organization.We are not hierarchical but operate as a flat surface where every opinion matters, ideas are cultivated and innovation is encouraged.At Saggezza, we are fortunate to have a strong mentorship program that provides every one of our employees the ability to thrive professionally and personally.We are only as good as our people. Saggezza, Italian for wisdom, is rooted from the perspective that knowledge is power. We create thought-leaders who are constantly exposed and trained in different technologies in the ever-evolving world of software development.We welcome innovators with entrepreneurial spirits to grow with our team.\xa0Consulting Magazine - Fastest Growing Firms 2019Built-In Top Places to Work in Chicago 2020Best and Brightest Companies in the Nation 2019 and 2020, Best and Brightest Companies in Milwaukee 2020 and Best and Brightest Companies in Chicago 20202020 Inc. 5000 List - Honored as one of the fastest-growing private companies in America\xa0', '\xa0', 'Drive: Our team sets ambitious goals and seeks energetic professionals, enjoy a fast pace environment, and thrive in taking on responsibility.', ""A Bachelor's in Computer Science, Information Technology, Mathematics, Engineering or an equivalent field."", 'Helping clients reach solutions by utilizing data management & operations, data quality & governance, cloud transformation, self-service analytics & visualization, and data intelligence.\xa0', 'Entrepreneurial spirit:', 'An understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.', 'Experience with analytic modeling in a scripting language (Python, R, etc.).An understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc (Depending on specific project requirements).Cloud certification, or any certification related to database or BI Tools.', 'you’re the right person for the job.', 'Saggezza is an Equal Employment Opportunity Employer: We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.', 'Cleaning and preparing data for analysis and processing', 'We are only as good as our people. Saggezza, Italian for wisdom, is rooted from the perspective that knowledge is power. We create thought-leaders who are constantly exposed and trained in different technologies in the ever-evolving world of software development.', '3+ years of practical hands-on experience working within data modeling, data extraction, data manipulation, and data warehousing concepts.', 'Saggezza is an Equal Employment Opportunity Employer:', 'Building, developing and maintaining reporting systems that support key business decisions.\xa0', 'Cloud certification, or any certification related to database or BI Tools.', 'Diverse culture, experiences, and skills.', 'Our nurturing and supportive environment fosters collaboration across the entire organization.', 'Problem-solving skills: Individuals at our company have well-honed analytical skills coupled with business acumen to structure problems, deliver solutions, and communicate insights.', 'Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc (Depending on specific project requirements).', 'Great communication and data-oriented personality with strong problem-solving skills.', 'Consulting Magazine - Fastest Growing Firms 2019', 'Best and Brightest Companies in the Nation 2019 and 2020, Best and Brightest Companies in Milwaukee 2020 and Best and Brightest Companies in Chicago 2020', 'Working across multiple clients and industries to add value and strategic insights within data & analytics.Cleaning and preparing data for analysis and processingProviding proficiency in analyzing data and formulating insights/conclusions.\xa0Building, developing and maintaining reporting systems that support key business decisions.\xa0Helping clients reach solutions by utilizing data management & operations, data quality & governance, cloud transformation, self-service analytics & visualization, and data intelligence.\xa0Working hands-on with SQL/SQL server & Python to deliver analytics to clients.\xa0Examining and reporting results to stakeholders in leadership, technology, marketing, sales, and product teams.', 'Entrepreneurial spirit: We seek individuals who enjoy contributing to the growth of an organization and who show commitment to the success of their team.', 'Proficiency in modern data tools and cloud technologies would be advantageous, including but not limited to Spark, Hadoop, Tableau, AWS, Azure, Kafka, GCP & IBM Cloud.', 'At Saggezza, we are fortunate to have a strong mentorship program that provides every one of our employees the ability to thrive professionally and personally.', 'Why Join Our Team?', 'Working across multiple clients and industries to add value and strategic insights within data & analytics.', 'Strong understanding of data modeling and entity-relationship diagrams', 'Providing proficiency in analyzing data and formulating insights/conclusions.\xa0', 'Working hands-on with SQL/SQL server & Python to deliver analytics to clients.\xa0', 'Demonstratable experience writing complex SQL queries, including but not limited to stored procedures, functions, views, and triggers.', 'Experience with analytic modeling in a scripting language (Python, R, etc.).', 'From a cultural perspective, we look for individuals who possess the following qualities that will contribute to our success and the success of our clients:', 'Problem-solving skills: ', 'What We’d Love to See', 'Don’t tick all the boxes? Don’t worry about it: we still want to hear from you if you think', 'Analytical mindset and business acumen. Self-motivated, individual contributor.', 'Drive: ', '2020 Inc. 5000 List - Honored as one of the fastest-growing private companies in America\xa0', 'Minimum of 2+ years of practical hands-on experience working with SQL/SQL Server and Python for analytics and data science purposes.\xa0', 'Built-In Top Places to Work in Chicago 2020', 'We provide strategic and innovative consulting services focused on digital experiences, engineering, automation, data and analytics, and salesforce solutions. Saggezza consultants work as part of a global team, and throughout their tenure, have the opportunity to work on a variety of different projects across various clients and industries. We are chartered to do one thing, and one thing only – to bring enabling technology to our clients that allow them to move their business forward.', 'Each project will be different, but you’ll always be responsible for:', ""A Bachelor's in Computer Science, Information Technology, Mathematics, Engineering or an equivalent field.3+ years of practical hands-on experience working within data modeling, data extraction, data manipulation, and data warehousing concepts.Minimum of 2+ years of practical hands-on experience working with SQL/SQL Server and Python for analytics and data science purposes.\xa0Strong understanding of data modeling and entity-relationship diagramsDemonstratable experience writing complex SQL queries, including but not limited to stored procedures, functions, views, and triggers.Knowledge of Indexes and how they can be used to enhance query performance.Proficiency in modern data tools and cloud technologies would be advantageous, including but not limited to Spark, Hadoop, Tableau, AWS, Azure, Kafka, GCP & IBM Cloud.Analytical mindset and business acumen. Self-motivated, individual contributor.Great communication and data-oriented personality with strong problem-solving skills."", 'Smarter Thinking. Real Results. Technology consulting has been our story for over 14 years. Companies from all industries partner with us for our innovative mindset to help them digitally transform to create market advantages, become resilient, and prepare for what’s next. With us, the possible becomes actual.\xa0\xa0', 'What You’ll Definitely Need', 'Data Engineer', 'Examining and reporting results to stakeholders in leadership, technology, marketing, sales, and product teams.', 'Knowledge of Indexes and how they can be used to enhance query performance.', 'We are currently looking to hire a Data Engineer to join our team.', 'We are not hierarchical but operate as a flat surface where every opinion matters, ideas are cultivated and innovation is encouraged.', 'Entrepreneurial spirit: We seek individuals who enjoy contributing to the growth of an organization and who show commitment to the success of their team.Problem-solving skills: Individuals at our company have well-honed analytical skills coupled with business acumen to structure problems, deliver solutions, and communicate insights.Drive: Our team sets ambitious goals and seeks energetic professionals, enjoy a fast pace environment, and thrive in taking on responsibility.']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Engineer (Remote),Robert Half,"Dallas, TX",58 minutes ago,Be among the first 25 applicants,"['', 'Description', ' Experience implementing automated ETL workflows ', ' Experience in SQL queries, creating data models ', ' Experience with PythonRobert Half Technology matches IT professionals with some of the best companies on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the technology jobs that match your skills and priorities — fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets.From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNE’s “Most Admired Companies” list every year since 1998.Download our mobile app to take your job search on the go!Contact your local Robert Half Technology office at 888.490.4429 or visit www.roberthalf.com/jobs/technology to apply for this job now or find out more about other job opportunities.All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada.© 2020 Robert Half Technology. An Equal Opportunity Employer M/F/Disability/Veterans.', ' Bachelor’s degree or equivalent working experience ', 'Requirements']",Entry level,Temporary,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Software Engineer (Solutions Engineering),STAQ,"Baltimore, MD",17 hours ago,Be among the first 25 applicants,"['', 'Learns Quickly. Some of our engineers have been doing this stuff for decades and are working with things they just picked up a couple months ago right now.', 'Curiosity. It kills the cat, but it makes for the best possible members of any engineering team.', 'Specific duties include ', 'Flexible paid time off', 'Paid Parking', 'Stock Options', 'Excellent Communication Skills. If anything, you might seem overeager to let everyone know what you\'ve been doing. Bonus points if you understand the concepts of ""plain language,"" ""readability,"" and ""managing up.""', 'Become a subject matter expert on at least one layer of the STAQ stack.', '401k', 'Benefits', 'Communicating and collaborating with other engineering and non-technical business teams to plan, design, implement, and support complex solutions.', 'WebMD', 'Medical, dental, and vision plans, with generous contribution from the company', 'Problem-Solving Skills. Solutions engineers need to be able to look at problem from different directions and not depend on documentation or other engineers to know the answers. At the same time, they need to know when to ask questions and bring in other resources to help get projects done on time.', 'Coding Experience. Most integrations are written in Ruby, so a willingness to learn and use Ruby is important. You should also have some experience with Git or another source control system. Bonus Experience in other languages, such as Python, Java, or JavaScript.', 'Participate in bi-weekly ""Demo Days"" and ""AdTech In The News"" events with the full engineering team, either as an active participant or an active member of the audience.', 'Relaxed working environment', ' Help the Solutions Engineering team build and maintain STAQ\'s integrations, which will include both API and data engineering work. Become a subject matter expert on at least one layer of the STAQ stack. Communicating and collaborating with other engineering and non-technical business teams to plan, design, implement, and support complex solutions. Participate in bi-weekly ""Demo Days"" and ""AdTech In The News"" events with the full engineering team, either as an active participant or an active member of the audience. ', ""Help the Solutions Engineering team build and maintain STAQ's integrations, which will include both API and data engineering work."", 'Requirements', 'Hulu', 'Ziff Davis, Politico, Roku', ' Coding Experience. Most integrations are written in Ruby, so a willingness to learn and use Ruby is important. You should also have some experience with Git or another source control system. Bonus Experience in other languages, such as Python, Java, or JavaScript. Curiosity. It kills the cat, but it makes for the best possible members of any engineering team. Problem-Solving Skills. Solutions engineers need to be able to look at problem from different directions and not depend on documentation or other engineers to know the answers. At the same time, they need to know when to ask questions and bring in other resources to help get projects done on time. Learns Quickly. Some of our engineers have been doing this stuff for decades and are working with things they just picked up a couple months ago right now. Excellent Communication Skills. If anything, you might seem overeager to let everyone know what you\'ve been doing. Bonus points if you understand the concepts of ""plain language,"" ""readability,"" and ""managing up."" ', ' Medical, dental, and vision plans, with generous contribution from the company Stock Options Flexible paid time off 401k Paid Parking Relaxed working environment', 'WarnerMedia, Conde Nast, and Xandr']",Associate,Full-time,Engineering,Marketing and Advertising,2020-10-06 11:54:06
Data Engineer,Gentis Solutions,"Boca Raton, FL",2 hours ago,Be among the first 25 applicants,"['', '\ufeffLead and participate in the design and implementation of large and/or architecturally significant applicationsChampion company standards and best practices; work to continuously improve software delivery processes and practicesBuild partnerships across the application, business and infrastructure teamsDevelop programming specifications; design, code and unit test application code using Software Development Life Cycle (SDLC) best practicesComplete estimates and work plans independently as appropriate for design, development, implementation and rollout tasksCreate technical system documentation and ensure that this documentation remains current throughout all phases of the SDLCCommunicate with the appropriate teams to ensure that assignments are managed appropriately and that completed assignments are of the highest qualitySupport and maintain applications utilizing required tools and technologies; provide support for applications, including involvement with the Support Center, NOC, Infrastructure teams, and vendors as appropriate, provide off-hours support (24 x 7) as requiredAssist other personnel on assignments including mentoring or providing on-the-job training to more junior associates; mentor team members in software development principles, patterns, processes and practicesMay direct the day-to-day work activities of other team membersMust be able to perform the essential functions of this position with or without reasonable accommodation', 'Build partnerships across the application, business and infrastructure teams', 'May direct the day-to-day work activities of other team members', 'Data Modeling\xa0', 'Experience with project planning', 'Bachelor’s degree in IS or related equivalent work experience in an Information Systems position5 + years of experience in systems analysis, design or programming and the associated development methodologies with large size or highly complex projectsPrior experience with project planning with large size or highly complex projects', 'SSRS', 'Create technical system documentation and ensure that this documentation remains current throughout all phases of the SDLC', 'SSIS', 'Ability to interact well in a team environment', 'SSAS', 'SQL', '\ufeff7 + years of experience in systems analysis, design or programming, and the associated development methodologies', 'Support and maintain applications utilizing required tools and technologies; provide support for applications, including involvement with the Support Center, NOC, Infrastructure teams, and vendors as appropriate, provide off-hours support (24 x 7) as required', 'Communicate with the appropriate teams to ensure that assignments are managed appropriately and that completed assignments are of the highest quality', '\ufeff7 + years of experience in systems analysis, design or programming, and the associated development methodologiesExperience with project planningProven communication and presentation skills to effectively communicate information to customers and to all levels within the organizationAbility to interact well in a team environment', '\ufeffLead and participate in the design and implementation of large and/or architecturally significant applications', '\ufeff', 'Position Duties:', 'Prior experience with project planning with large size or highly complex projects', 'Desired Previous Job Experience/Education:', '5 + years of experience in systems analysis, design or programming and the associated development methodologies with large size or highly complex projects', 'Complete estimates and work plans independently as appropriate for design, development, implementation and rollout tasks', 'Proven communication and presentation skills to effectively communicate information to customers and to all levels within the organization', 'Technologies:', 'Bachelor’s degree in IS or related equivalent work experience in an Information Systems position', 'Required Skills and Experience:', 'Champion company standards and best practices; work to continuously improve software delivery processes and practices', 'SSASSSISSQLSSRSData Modeling\xa0', 'Assist other personnel on assignments including mentoring or providing on-the-job training to more junior associates; mentor team members in software development principles, patterns, processes and practices', 'Must be able to perform the essential functions of this position with or without reasonable accommodation', 'Gentis Solutions is seeking a Digital Data Developer to lead and participate in the design and implementation of large and/or architecturally significant applications', 'Develop programming specifications; design, code and unit test application code using Software Development Life Cycle (SDLC) best practices']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
Data Scientist,Talkspace - Online Therapy,"New York, NY",17 hours ago,Over 200 applicants,"['', 'Quickly become an expert in multiple facets of the business, including marketing, product, and operations', 'Perform data analysis to make business recommendations (e.g. user journey and client lifecycle, impact analysis, and operations/financial forecasting)', 'Think critically, test hypotheses, and leverage data to test and iterate on new product features and business strategies', ' Deep dives in large-scale data to identify key insights for internal stakeholders A/B testing and causal modeling Defining how best to measure and monitor Talkspace products and features Effectively translating business questions into data experiments  ', ""BA/BS and/or Master's degree in a quantitative field such as statistics, computer science, mathematics, and/or data science"", 'A/B testing and causal modeling', 'Effectively translating business questions into data experiments ', 'Collaborate with stakeholders across the company to complete full-stack data science analysis, including designing experiments or observational analyses; data aggregation using SQL or other database tools; qualitative and quantitative analysis, including identifying potential discrepancies; creating new data warehousing (if necessary); and presenting insights to both the data science team and internal company stakeholders', 'Experience measuring customer engagement outcomes in technical products', 'Benefits', 'Experience (or strong interest) in working in a fast-paced startup environment', 'Build and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scale', 'About This Role', 'Passionate about improving customer experience by refining product through testing and optimization', 'Defining how best to measure and monitor Talkspace products and features', "" BA/BS and/or Master's degree in a quantitative field such as statistics, computer science, mathematics, and/or data science 3+ years of relevant working experience in an analytical role involving data extraction, analysis, and statistical modeling Proficiency in Python/R, SQL, git and common data science and machine learning libraries (pandas, sklearn, etc.) Experience measuring customer engagement outcomes in technical products Passionate about improving customer experience by refining product through testing and optimization Proven ability to clarify ambiguity, balance multiple priorities, and complete high-quality work on tight deadlines Experience distilling complex analyses into simplified insights and communicating those insights to non-data-scientist stakeholders At ease with ambiguity Experience (or strong interest) in working in a fast-paced startup environment "", 'At ease with ambiguity', 'Proven ability to clarify ambiguity, balance multiple priorities, and complete high-quality work on tight deadlines', 'Deep dives in large-scale data to identify key insights for internal stakeholders', 'Experience distilling complex analyses into simplified insights and communicating those insights to non-data-scientist stakeholders', 'Requirements', ' Perform data analysis to make business recommendations (e.g. user journey and client lifecycle, impact analysis, and operations/financial forecasting) Collaborate with stakeholders across the company to complete full-stack data science analysis, including designing experiments or observational analyses; data aggregation using SQL or other database tools; qualitative and quantitative analysis, including identifying potential discrepancies; creating new data warehousing (if necessary); and presenting insights to both the data science team and internal company stakeholders Build and automate reports, as well as iteratively develop and prototype dashboards to provide insights at scale Think critically, test hypotheses, and leverage data to test and iterate on new product features and business strategies Quickly become an expert in multiple facets of the business, including marketing, product, and operations ', '3+ years of relevant working experience in an analytical role involving data extraction, analysis, and statistical modeling', 'Proficiency in Python/R, SQL, git and common data science and machine learning libraries (pandas, sklearn, etc.)', 'About You']",Entry level,Full-time,Engineering,Information Technology and Services,2020-10-06 11:54:06
Data Engineer,Rekruiters,"Houston, TX",19 hours ago,Over 200 applicants,"['', 'https://www.facebook.com/rekruiters/ – Facebook', '- 3yrs+ experience with APIs and has a good understanding of them.', '- Has worked directly with business teams to understand needs and engineer solutions.', '- Has worked on streaming architectures and moving large amounts of data.', 'Requirements:', 'MUST HAVE EXPERIENCE WITH SQL AND PYTHON', '_________________________________________________________________', '________________________________________________________', 'Specific needs for project:', 'Rekruiters has been named by business journals as one of the best places to work.', 'For more information on this job visit: https://rekruiters.com/jobs/', '- 2yrs+ experience with containerization (Docker or Kubernetes) -', '4yrs+ experience with Python using the data processing packages like Pandas, NumPy', 'https://www.rekruiters.com – Main Site', '- 4yrs+ experienced with databases, both relational and non-relational', 'Location: Houston, Area', 'Corporate:', '@rekruiters.com – Twitter', 'We offer benefits such as weekly pay, health insurance, 401k and even profit sharing to our consultants.']",Mid-Senior level,Contract,Information Technology,Oil & Energy,2020-10-06 11:54:06
Data Engineer,Infinity Consulting Solutions,"New York, NY",,Over 200 applicants,"['Maintain and enhance Data Quality Score Dashboard.', 'Provide guidance to the functional area owners, IT leads and data stewards in resolving conflicts. i.e., choosing authoritative sources, business definitions, roles and responsibilities etc. ', 'Coordinate Data Quality activities and data remediation activities with the Data Governance team.', 'Work with CDO management to introduce tools and capabilities to enhance the Data Quality Program.', 'Strong Excel experience', 'Perform data quality activities including data quality rule creation, edit checks, identification of issues, root cause analysis, value case analysis, remediation planning and 2nd line of defense monitoring etc.', 'Strong experience in data related activities (data governance, metadata, data management, data standards, data structures, data aggregation, business requirements)', 'Perform complex analyses to support business decisions, as well as provide feedback and recommendations to the management regarding results.', 'Specific skills in visualization tool experience implementing Tableau, and SSRS highly desired', 'Responsibilities', 'Assist representing CDO on Internal Audit reviews for data quality audits.', 'Produce Data Quality Assessment reports through interaction with the business consumers.', ""Bachelor's Degree or above, Master's Degree preferred"", 'Provide data analytics expertise, demonstrate strength working with large data sets outside of Excel. Comfortable managing 200k records with over 200 columns plus across multiple data sets', 'Job Requirements', ""Become the team's technical expert for Data Quality report automation, identification, and data issue visualization."", '5+ years of professional work experience in the financial services industry focused on data', '5+ years of strong working knowledge using SQL and Data Quality tools', 'Prepare Data Quality Training material for data stewards, Data Quality team and general bank training.', "" Bachelor's Degree or above, Master's Degree preferred 5+ years of professional work experience in the financial services industry focused on data 5+ years of strong working knowledge using SQL and Data Quality tools Strong Excel experience 3+ years in Data Quality related leadership roles or Content-centric/ data-centric roles Python is a plus Strong experience in data related activities (data governance, metadata, data management, data standards, data structures, data aggregation, business requirements) Specific skills in visualization tool experience implementing Tableau, and SSRS highly desired"", 'Python is a plus', 'Drive improvements to maximize value of data quality (e.g. drive changes to have access to required metadata to maximize impact of data quality, quantify the cost/impact of poor data quality).', "" Produce Data Quality Assessment reports through interaction with the business consumers. Drive improvements to maximize value of data quality (e.g. drive changes to have access to required metadata to maximize impact of data quality, quantify the cost/impact of poor data quality). Perform data quality activities including data quality rule creation, edit checks, identification of issues, root cause analysis, value case analysis, remediation planning and 2nd line of defense monitoring etc. Perform complex analyses to support business decisions, as well as provide feedback and recommendations to the management regarding results. Maintain and enhance Data Quality Score Dashboard. Prepare Data Quality Training material for data stewards, Data Quality team and general bank training. Coordinate Data Quality activities and data remediation activities with the Data Governance team. Work with CDO management to introduce tools and capabilities to enhance the Data Quality Program. Assist representing CDO on Internal Audit reviews for data quality audits. Provide data analytics expertise, demonstrate strength working with large data sets outside of Excel. Comfortable managing 200k records with over 200 columns plus across multiple data sets Become the team's technical expert for Data Quality report automation, identification, and data issue visualization. Provide guidance to the functional area owners, IT leads and data stewards in resolving conflicts. i.e., choosing authoritative sources, business definitions, roles and responsibilities etc.  "", '3+ years in Data Quality related leadership roles or Content-centric/ data-centric roles']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-10-06 11:54:06
