job_title,company,company_rating,location,job_text,date
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:46:40
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:46:40
Data Engineer,Vanguard,3.8 out of 5,"Malvern, PA","['Minimum of five years data analytics, programming, database administration, or data management experience.', 'Undergraduate degree or equivalent combination of training and experience.']",2020-08-08 12:46:40
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:46:40
Data Engineer - Contract/Freelance,Seadata.io,N/A,"Atlanta, GA","['Programming in the following languages:', 'Python', 'Java', 'SQL', 'Use of data management services within one of the following:', 'AWS', 'Azure', 'GCP', 'Extracting data from:', 'API’s', 'MySQL/Postgres', 'Kafka clusters', 'Hadoop clusters', 'Cloud storage (ex. AWS s3)', 'Documenting data sources and processes', '401(k)', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Varies', 'Likely', 'Fully Remote', '10-19', '20-29', '30-39', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'Seadata.io']",2020-08-08 12:46:40
Data Engineer,Entech Consulting LLC,N/A,"Wilmington, DE 19805","['A passion for Data Engineering- an excitement and eagerness to learn and work with Database Architecture, Data Modeling and mining, statistical analysis', ""Bachelor’s degree with a focus on Computer Science or Engineering, Master's Degree preferred"", 'Basic coding fundamentals: Hands on experience (school, personal project or internship experience) Java, Python, SQL, R or other coding languages- must be able to demonstrate code', '3- 5 years professional experience', 'Ability to listen and learn- active listening, understanding full situations and proposing solutions', 'Creative thinking, excitement to share ideas, receive feedback and learn continuously', 'Ability to operate independently- after training and mentorship able to work at a problem independently, knowing when to elevate for leadership insights, and when to keep working to find a solution', 'Pandas', 'Scikit-Learn', 'Keras', 'Linux & Docker', 'Jupyter Notebooks', 'NumPy', 'SciPy', 'Seaborn', 'Building and designing large-scale applications', 'Database architecture and data warehousing', 'Data modeling and mining', 'Statistical modeling and regression analysis', 'Distributed computing and splitting algorithms to yield predictive accuracy', 'Proven communication and leadership skills.', 'Reviews and processes business requests to create, update or delete business data', 'Gathers data from content owner and transfers data into a standard format for systems', 'Understands business data standards, policies and procedures and applies them appropriately to data', 'Recognizes business data dependencies', 'Knowledgeable in the treatment of data dependencies', 'Knowledgeable in the operation of business application(s) utilized to process business data requests', 'Review data requests for requirements and outcomes', 'Identify data dependencies', 'Validate requests, data and any dependencies for compliance with established data standards, policies and procedures', 'Format data, as needed, to meet data standards, policies and procedures', 'Interact with requisite business application(s)', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Python: 2 years (Preferred)', 'One location', 'Yes: Immigrant visa sponsorship (e.g., green card sponsorship)', 'Temporarily due to COVID-19']",2020-08-08 12:46:40
Big Data Infrastructure Engineer,Comcast,3.7 out of 5,"West Chester, PA 19380","['A passion for teamwork and execution excellence', 'Excellent problem-solving skills and attitude', ""Sense of ownership and pride in your performance and its impact on the team's and company's success"", 'Interpersonal and communication skills', 'Drives database solution design and continuous refinements.', 'Independently plans, installs, integrates and validates systems software and hardware solutions.', 'Manages technical change implementation across environments.', 'Resolves issues and navigates obstacles to deliver work product.', 'Serves as a resource to less experienced team members on escalated issues of a routine nature.', 'Participates in the evaluation, development, implementation, integration and administration of internal and external business solutions that meet customer needs.', 'Perform system monitoring, daily check, diagnostic and corrective action, complex root cause analysis and implement corrective measures to prevent future service interruptions.', 'Be a member of a 24x7 on-call rotation to resolve service impairments, working with operations teams as a critical issue point.', 'Other duties and responsibilities as assigned.', 'Excellent understanding of database concepts and working experience with any NoSQL or directory database systems at a large scale in a distributed environment (tens-to-hundreds of millions of objects).', 'Excellent understanding of the internet protocols TCP/IP, UDP, LDAP/LDAPS, SSL/TLS, etc.', 'Experience working with database access controls, schema, syncing data between instances, performance testing etc.', 'Experience with Ping Identity LDAP server is a plus, but not required', 'Experience with AWS Dynamo DB is a plus, but not required', 'Proficient knowledge of systems administration skills, in Linux or Windows platforms.', 'Experience with shell scripting.', 'Clear written and verbal communication skills.', 'Participation in an on-call escalation path.', 'Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) as necessary.']",2020-08-08 12:46:40
"Business Intelligence Engineer, Accounting",Amazon.com Services LLC,3.6 out of 5,Remote,"['Bachelor’s degree in Engineering, Statistics, Computer Science, Mathematics or related field', '4+ years of relevant work experience with ETL development, data modeling, data warehousing and applying analytics', 'Experience with SQL using databases like MySQL, Redshift or similar', 'Experience in data visualization tools using Excel, Tableau, QuickSight, Power BI or similar', 'Excellent data presentation skills and demonstrated ability to successfully partner with business and technical teams', 'Experience in gathering requirements and formulating business metrics for reporting', '5+ years of relevant professional experience as a BIE, Data Engineer or related with a track record of manipulating, processing, and extracting from large datasets', 'Familiarity with AWS solutions such as EC2, Dynamo DB, S3, Redshift, and RDS', 'Expert in tuning SQL scripts', 'Experience with Python, R, VBA, or other automation-focused languages']",2020-08-08 12:46:40
Associate PL/SQL Data Engineer (REMOTE),CareCentrix,2.8 out of 5,Remote,"['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', 'Bachelor’s Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required', 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:46:40
Data Engineer II,Indeed,4.3 out of 5,"Austin, TX 78731","['Create, manage and own our data warehousing strategy', 'Leverage numerous internal and external APIs to build new data sources', 'Creating ETL pipelines using SQL, Python, Hive, and Spark to populate data models', 'Elicit and own requirements from a wide range of different teams.', 'Translate business requests into database designs.', 'You’ll work closely with stakeholders to deliver new insights that drive our business forward.', 'Work closely with stakeholders on the data supply side, including domain experts on source systems of the data.', 'Draw insights from Indeed’s data to deliver to business partners.', 'Contribute to the ongoing development of the data warehouse ecosystem across Indeed.', 'Develop and maintain a data dictionary for published data sources.', 'Develop and improve continuous release and testing processes.', 'Bachelor’s or foreign equivalent degree in Computer Science, Computer Engineering, a closely related engineering discipline, or a related field.', '5+ years of professional experience in: software development and/or data engineering; and in working with relational databases, including MySQL, Mongo, or a similar program.', 'Must include one year of experience using Python or Java.', 'Demonstrated knowledge of SQL.']",2020-08-08 12:46:40
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:46:40
Data Engineer,HASH,2.5 out of 5,Remote,[],2020-08-08 12:46:40
Data Engineer (Remote),Icon Fitness,3.8 out of 5,"Logan, UT","['Use an analytical, data-driven approach to drive a deep understanding of our business.', 'Build data pipelines and data models that will empower engineers and analysts to make data-driven decisions', 'Build data models to deliver insightful analytics', 'Deliver the highest standard in data integrity', 'Strong analytical skills with ability to analyze and project sales, subscriber, and engagement data. Performs competitive analysis, reviews industry information for current trends and opportunities. Works closely with analytics teams to develop comprehensive analytical reports to enable data-driven decisions to increase engagement and conversions of target customer segments.', 'Experience in business intelligence, analytics, or an equivalent analyst position with experience in SQL and an additional object-oriented programming language (e.g., Python, Java).', 'High level of expertise in data modeling.', 'Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders.', 'Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs.', 'Attention to detail and effective verbal/written communication skills.', 'Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, a related quantitative field, or equivalent practical experience.', '2-6 years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with experience in SQL and Python.', 'Ability to effectively and accurately present information to customers, coworkers, and managers.', 'Ability to define problems, collect data, establish facts, and draw valid conclusions.', 'The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. While performing the duties, the employee is regularly required to sit and talk or hear. The employee is frequently required to stand and walk. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include vision, and color vision.', 'The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. The noise level in the work environment is usually moderate. Typical office environment.', 'Excellent health, vision, dental insurance', '401k match', 'Excellent PTO', 'MacBook Pro and external monitor', 'A cell phone of your choice + monthly phone plan', 'Free piece of fitness equipment of your choice', 'Semi-annual team meet-ups', 'Continuing education opportunities', 'Highly competitive salary and compensation package', 'Yearly performance/pay evaluation', 'List of states we are able to hire in: AR, AK, AZ, CA CO, CT, FL, GA, ID, IL, IN, KS, MI, MD, MN, MO, NC, NH, NJ, OH, OR, PA, SC, TX, UT, VA, WA, WI.']",2020-08-08 12:46:40
Data Engineer,Aunalytics,N/A,"South Bend, IN 46601","['Build and own “one source of truth” data sets to facilitate consistency and efficiency in extracting and analyzing data from disparate data sources', 'Ensure data integrity by developing and executing necessary processes and controls around the flow of data', 'Innovate and improve efficiency of managing data to allow for greater speed and accuracy of producing analyses, metrics, and insights', 'Collaborate with internal and external teams to understand business needs/issues, troubleshoot problems, conduct root cause analysis, and develop cost effective resolutions for data anomalies', 'Provides input into data governance initiatives\u202fto enhance current systems, ensure development of efficient application systems, influence the development of data policy, and support overall corporate and business goals', 'Utilizes technology to analyze data from applicable systems to review data processes, identify issues, and determine actions to resolve or escalate problems that require data, system, or process improvement', 'Verifies accuracy of table changes and data transformation processes. Test changes prior to deployment as appropriate', 'Recommend and implement enhancements that standardize and streamline processes, assure data quality and reliability, and reduce processing time to meet client expectations', 'Communicate progress and completion to project team. Escalate roadblocks that may impact delivery schedule', 'Stay up-to-date on data engineering and data science trends and developments', 'Follow company policy and procedures which protect sensitive data and maintain compliance with established security standards and best practices', 'Additional duties as assigned to ensure client and company success', 'Bachelor’s degree in Computer Science, Computer Engineering, Mathematics, or related field, or 3 plus years of relevant work experience.', 'Experience working with relational database structures, SQL and/or flat files and performing table joins, web crawling, and web development.', 'Proficiency in one or more of the following programming languages: PHP, Java, or Python and a familiarity with Node.js', 'Natural curiosity about what’s hidden in the data through exploration, attention to detail, and ability to see the big picture – similar to putting together a 10,000-piece puzzle.', 'Resourceful in getting things done, self-starter, and productive working independently or collaboratively – ours is a fast-pace entrepreneurial environment with performance expectations and deadlines.', 'Ability to learn quickly and contribute ideas that make the team, processes, and solutions better', 'Ability to communicate your ideas (verbal and written) so that team members and clients can understand them', 'Ability to defend your professional decisions and organize proof that your ideas and processes are correct', 'Experience working in one of the following industries: healthcare, financial services, media, or manufacturing', 'Experience working with commercial relational database systems such as electronic medical records or other clinical systems, customer relationship management software, or accounting systems', 'Familiar with various data management methodologies, data exploration techniques, data quality assurance practices, and data discovery/ visualization tools', 'Prior experience supporting business intelligence operations, managing technical, business, and process metadata related to data warehousing', 'Experience working with NoSQL, Hive, MapReduce, and other Big Data technologies is preferred but not required; willing to train the right candidate', 'Experience working with distributed and/or parallel systems experience or knowledge of concepts', 'Share our values: growth, relationships, integrity, and passion', 'Opportunity to work in the booming field of data science, alongside some of the brightest minds in the industry', 'Opportunity to work with cutting-edge technology in a casual, fun environment', 'Opportunity to be a part of a local company committed to making a difference in our community', 'Chance to work with a rapidly expanding tech company', 'Flexible schedule and paid time off', 'Free snacks and an unlimited supply of coffee', 'Social events such as happy hours, game nights, holiday parties, birthday celebrations, movie days, ice cream sundae bars, fancy coffee carts, company softball team, etc.', 'Competitive salary and benefits package including health, vision, dental, and life insurance', 'Dental Insurance', 'Disability Insurance', 'Flexible Schedule', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Referral Program', 'Relocation Assistance', 'Vision Insurance', 'Monday to Friday', 'Bonuses', 'One location', 'People-oriented -- supportive and fairness-focused', 'www.aunalytics.com', 'Waiting period may apply', 'Yes']",2020-08-08 12:46:40
Junior/Returning Data Engineer,Princeton University,4.3 out of 5,"Princeton, NJ 08542","['Virginia House of Delegates map analysis to enhance racial fairness.', 'Columns by Sam Wang and his team on the way forward: N_ YT_ (Nov 2018, July 2019), Richmond T_imes-Dispatch, Raleigh  News and Observer_.', 'OpenPrecincts.org, a data resource to power redistricting analytics in all 50 states.', 'Published scholarship to support measures of fairness ( Election Law Journal) and theories for litigation ( U. Penn. J. Const. Law) .', 'In New Jersey, sponsored legislation for data transparency, passed into law in 2019, and worked to prevent unfair practices.', 'Analyses of best practices for reform in Michigan, Virginia, and New Jersey.', 'You are passionate about democracy and want to work with a team dedicated to achieving real reform.', 'You have the skills and experience to clean and validate data', 'You are interested in technical documentation and improving the efficiency of your work;', 'You can work hard to reach deadlines that are driven by real-world needs;', 'You are not afraid to take on new challenges and apply your unique skills to solve complex problems in innovative ways: you are a tenacious data detective!', 'You’re experienced with some of the following technologies:', 'Data Science/Scripting Language (Python, R, Stata, etc.)', 'GIS Software (QGIS, ArcGIS, etc.)', 'You have an understanding of how underrepresentation impacts policy decisions in the U.S.', 'You are collaborative, and know how to leverage the most of a cross-functional, interdisciplinary team', 'You have an understanding of web scraping, APIs, and other data acquisition processes.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'A good fit for applicants with gaps in their resume, or who have been out of the workforce for the past 6 months or more', 'A good job for someone just entering the workforce or returning to the workforce with limited experience and education', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'http://gerrymander.princeton.edu/', 'Temporarily due to COVID-19']",2020-08-08 12:46:40
Data Test Engineer (Python/Data/SQL),CompGain LLC,N/A,"Rockville, MD 20850","['Strong knowledge with RDMS concepts (tables, views, functions) , SQL query development (joins, union, minus, analytical functions) in Oracle/PostgreSQL and Unix/Linux Shell Scripting.', 'Debugging SQL queries.', 'Strong fundamentals in testing.', 'Experience with automated data testing.', 'Experience working with Java OR python OR Scala.', 'Experience in AWS - EC2, EMR, S3, PostgreSQL, Lambda expressions etc.', 'Experience with Hive, Spark', 'Temporarily due to COVID-19']",2020-08-08 12:47:24
Data Engineer (Remote),Icon Fitness,3.8 out of 5,"Logan, UT","['Use an analytical, data-driven approach to drive a deep understanding of our business.', 'Build data pipelines and data models that will empower engineers and analysts to make data-driven decisions', 'Build data models to deliver insightful analytics', 'Deliver the highest standard in data integrity', 'Strong analytical skills with ability to analyze and project sales, subscriber, and engagement data. Performs competitive analysis, reviews industry information for current trends and opportunities. Works closely with analytics teams to develop comprehensive analytical reports to enable data-driven decisions to increase engagement and conversions of target customer segments.', 'Experience in business intelligence, analytics, or an equivalent analyst position with experience in SQL and an additional object-oriented programming language (e.g., Python, Java).', 'High level of expertise in data modeling.', 'Effective problem solving and analytical skills. Ability to manage multiple projects and report simultaneously across different stakeholders.', 'Structured thinking with ability to easily break down ambiguous problems and propose impactful data modeling designs.', 'Attention to detail and effective verbal/written communication skills.', 'Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance, a related quantitative field, or equivalent practical experience.', '2-6 years of experience in consulting, business intelligence, analytics, or an equivalent analyst position with experience in SQL and Python.', 'Ability to effectively and accurately present information to customers, coworkers, and managers.', 'Ability to define problems, collect data, establish facts, and draw valid conclusions.', 'The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. While performing the duties, the employee is regularly required to sit and talk or hear. The employee is frequently required to stand and walk. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include vision, and color vision.', 'The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. The noise level in the work environment is usually moderate. Typical office environment.', 'Excellent health, vision, dental insurance', '401k match', 'Excellent PTO', 'MacBook Pro and external monitor', 'A cell phone of your choice + monthly phone plan', 'Free piece of fitness equipment of your choice', 'Semi-annual team meet-ups', 'Continuing education opportunities', 'Highly competitive salary and compensation package', 'Yearly performance/pay evaluation', 'List of states we are able to hire in: AR, AK, AZ, CA CO, CT, FL, GA, ID, IL, IN, KS, MI, MD, MN, MO, NC, NH, NJ, OH, OR, PA, SC, TX, UT, VA, WA, WI.']",2020-08-08 12:47:24
Remote Data Engineer - Data Mapping - Hadoop/Spark,C&G Consulting Services,N/A,"New York, NY 10005","['Monday to Friday', 'Fully Remote', 'Yes']",2020-08-08 12:47:24
Data Analytic Engineer,Integress Inc.,N/A,"Conshohocken, PA 19428","['Work with cross-functional teams to research, develop and deliver solutions, from concept to design and implementation', 'Creation of data pipelines and transformations (ELT – Matillion, Singer, DBT, etc. and/or ETL – Informatica, Talend, etc.)', 'Analysis of complex data sets to uncover insights and provide recommendations', 'Creation of visualizations using a Business Intelligence tool such as Tableau, PowerBI, Python Matplotlib, Sigma, etc.', 'Development, deployment and maintenance of Machine Learning (ML)/AI models to realize actionable insights.', 'Writing complex SQL queries, stored procedures, etc.', 'Building scalable data processes in an analytics platform such as Spark, Databricks etc.', 'Bachelor’s degree, or equivalent experience, in Computer Science, Data Science, Mathematics or a related field. Commensurate work experience will be considered in lieu of degree', 'Experience with AWS and/or Azure Cloud', 'Experience building scalable Cloud data solutions using MPP Data Warehouses (Snowflake, Redshift, or Azure Data Warehouse/Synapse), data storage (S3 or Azure Blob Storage) and analytics platforms (i.e. Spark, Databricks, etc.)', 'Demonstrated ability to communicate data insights and model results in business terms and articulate business value', 'Demonstrated understanding of typical data science techniques such as classification, regression, and optimization to solve business problems', '3+ years developing, and deploying scalable enterprise data solutions (Enterprise Data Warehouses, Data Marts, ETL/ELT workloads, etc.)', '3+ years of supporting business intelligence and analytic projects', '3+ years with Python/R/SAS and Jupyter Notebook, or other modeling tools', '2+ years visualization experience with Tableau, PowerBI, Sigma, or similar BI tool', 'Excellent written and oral communication skills', 'Experience working at a consulting company', 'Experience with Data Vault architecture', 'Good understanding of code repositories such as GIT', 'DevOps experience', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Schedule', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Referral Program', 'Monday to Friday', 'Bonus Pay', 'Jupyter Notebook: 3 years (Required)', 'Client Facing: 2 years (Required)', 'Python or R: 3 years (Required)', 'SQL: 5 years (Required)', 'One location', 'Yes: H-1B work authorization', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Aggressive -- competitive and growth-oriented', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.integress.com', 'https://www.linkedin.com/company/integress-inc./', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 12:47:24
Federal - Data Engineer,Accenture,4 out of 5,"Greenbelt, MD","[""Bachelor's Degree required with 8+ years of overall professional work experience (Quantitative degrees preferred)"", '3+ years experience with the following:ETL and data modeling', '2+ years experience with the following:Hadoop/HiveCloud Technologies (AWS preferred)At least one SQL language such as T-SQL or PL/SQL', '1+ year experience with the following:Real-time analytics applicationBatch processing technologiesProgramming and scripting languages like R, Python, and/or Java']",2020-08-08 12:47:24
Data Engineer,Piper Companies,4.4 out of 5,"Basking Ridge, NJ","['Define and prototype new approaches to our existing data enrichment techniques', 'Create entirely new kinds of data enrichment that add value to customer profiles', 'Define metrics for assessing the quality of the data we produce', 'Implement validation frameworks and methodologies to regularly measure data against these metrics', 'Find & share insight from client data', 'Research enrichment approaches', 'Analyze and model client data', 'Ensure seamless data ingestion and manage all new data feeds requests including streamlining data audit and QA work', 'Work closely with client and 3rd party stakeholders to support friction less integration of CIP data outputs into downstream systems', 'Solid understanding of at least one programming language, preferably Scala or Python', 'Ability to handle big data', 'Experience of at least one RDBMS', 'Some knowledge of statistical modeling and machine learning', 'Some experience at a CSP (Communication Service Provider), focusing on B2C big data customer analytics (ideally recent tools and techniques)', '$170,000/year W2, negotiable and commensurate with experience', 'Employer benefit package with Medical, Dental, Vision, 401k with match, PTO, Holidays', 'Remote due to COVID with normal expectancy of ~2 days onsite after']",2020-08-08 12:47:24
Data Warehouse Engineer,Piper Companies,4.4 out of 5,"Fort Washington, PA","['Partner with data analysts/data modeler to develop code from source to target mapping for the development of brand new data warehouse', 'Focus on low level security/column level security', '5+ years of Data Engineering experience', 'Heavy focus on data warehousing work using SQL Server, MySQL, NoSQL', 'Experience with AWS - Redshift, Kinesis, Snow Flake', 'Understanding of column level security', 'Knowledge of data modeling and data marts', 'Knowledge of SDLC and usage of PPM too (Jira, Rally, Azure DevOps)', 'Excellent presentation and interpersonal skills - communication is key', '$75-85/hr W2 (12+ months)', 'Comprehensive benefit package; Medical, Dental, Vision, 401k']",2020-08-08 12:47:24
Business Intelligence Engineer,Hiresigma,5 out of 5,Remote,"['Convert business requirements into Reporting Data layer design for Business Intelligence tools.', 'Provide technical requirements to data engineering team for conversion of business requirements to reporting data layer.', 'Develop reporting data layer for business intelligence tools like MicroStrategy and Tableau using big data platform databases / querying (like Impala, Hive, Kudu) as well as modern cloud data warehouse like Snowflake.', 'Perform data analysis, data modeling and data design tasks / transformation on complicated datasets with potentially complex data integration scenarios related to reporting.', 'Build data structures / database objects and data blending technologies to support data harmonization and provide data to MicroStrategy / Tableau and self-service reporting templates.', '8+ years database, data integration experience', '3+ years’ experience with Hadoop, SQL and Big Data solutions', '5+ years’ experience in designing and implementing the data structures (conceptual, logical, physical & dimensional models) for reporting tools like MicroStrategy, Tableau or any reporting tools', 'Supporting data enablement for enterprise Business Intelligence solutions using one or more of the following EDW platforms: Big Data Platforms / HANA / BW / Snowflake', 'Development experience in using Big Data solutions using open source technologies within the Hadoop ecosystem such as: Impala, Hive, Spark, Pig, etc.', 'Strong knowledge of scripting to support data requirements', 'Strong knowledge of reporting related data security principles', 'Proven track record working with complex, interrelated systems and bringing that data together on Big Data platforms.', 'Be knowledgeable in visualization tools data requirements for Microstrategy / Tableau', 'Heavy, In-Depth Database Knowledge – SQL and NoSQL.', 'Handle multiple priorities simultaneously', 'Work collaboratively with cross-functional teams', 'Establish and maintain a working environment conducive to positive morale, individual style, quality, creativity, and teamwork', 'Ability to work in a fast-paced, team environment', 'tableau, Microstartegy, SQL: 5 years (Required)', 'Data reporting: 5 years (Required)', 'cloud: 3 years (Required)', 'Big data hadoop, hive: 3 years (Required)']",2020-08-08 12:47:24
Cloud Data Engineer (Azure),Navy Federal Credit Union,4 out of 5,"Vienna, VA 22180","['FORTUNE 100 Best Companies to Work For®', 'Computerworld® Best Places to Work in IT', 'FORTUNE® Best Workplaces for Millennials', 'Forbes® America’s Best Employers', 'PEOPLE® Companies That Care', 'Provide Business Intelligence (BI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms', 'Evaluate and define functional requirements for BI and DW solutions', 'Define and build data integration processes to be used across the organization', 'Build conceptual and logical data models for stakeholders and management', 'Analyze and validate data accuracy of report results', 'Work directly with management understand requirement; and propose and develop best business solution that enables effective decision-making, and drive business objectives', 'Prepares realistic project implementation plans which highlight major milestones and deliverables leveraging standard methods and work planning tools', 'Recognizes potential issues and risks during the analytics project implementation and can suggest realistic mitigation strategies', 'Coaches and mentors project team members in carrying out analytics project implementation activities', 'Leads the preparation of high quality project deliverables that are valued by the business and presents them in such a manner that they are easily understood by project stakeholders', 'Interpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision making', 'Use of statistical practices to analyze current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events', 'The ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner', 'The ability to define and analyze models that predict the probability of an outcome', 'Offers improvements to the way in which analytics service the entire function', 'Communicating and owning the process in manipulating and merging large datasets', 'Ability to view and understand other project or functional areas in order to consolidate analytical needs and processes', 'Being a key point of contact between the data analyst/data scientist and the project/functional analytics leads', 'Perform other duties as assigned', ""Bachelor's degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience"", '5 years’ experience working in a cloud computing with Azure experience required', 'Experience with data migration to cloud based environment', 'Extensive 5 years of experience in providing data architecture solutions for Cloud applications', 'Knowledge of and the ability to perform basic statistical analysis such as measures of central tendency, normal distribution, variance, standard deviation, basic tests, correlation, and regression techniques', 'Experienced in the use of standard ETL tools and techniques', 'Experienced in sourcing, maintaining, and updating data', 'Understanding of data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage', 'Demonstrates functional knowledge of data visualization tools such as Microsoft Power BI, Tableau', 'Has working knowledge of various data structures and the ability to manipulate data within visualization tools', 'Ability to manipulate raw data into effective visualization dashboards', 'Ability to communicate end to end data outcomes visually', 'Demonstrates a deep understanding of multiple database concepts', 'Has a working knowledge of various data structures and the ability to extract data from various data sources (such as Cognos, Informatica)', 'Understands the concepts and application of data mapping and building requirements', 'Optimal understanding of SQL', 'Graduate education in Information Systems, Computer Science, Engineering, or related field', 'Knowledge of Navy Federal Credit Union instructions, standards, and procedures']",2020-08-08 12:47:24
Informatica Big Data Engineer,Accenture,4 out of 5,"Newark, DE","['Extract, Transform and Load data primarily in Informatica Powercenter and Big Data Management with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.', 'Demonstrate an understanding of technology and digital frameworks in the context of data integration utilizing Informatica.', 'Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.', 'Minimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Big Data Management', 'Bachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years', 'Experience in ETL Tools in addition to Informatica, including Business Objects Data Services (BODS), DataStage, Ab Initio, Talend, and Pentaho', 'Experience implementing or supporting Data Integration of Big Data with Sqoop or similar tools', 'Knowledge of Big Data Solutions such as Hadoop Ecosystem', 'Database experience (Teradata, Oracle, SQL Server, DB2, Azure SQL)', 'Strong knowledge and experience of SQL', 'Understanding of Entity relationship data models and Dimensional Models', 'Experience with development and production support', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).', 'Proven success in contributing to a team-oriented environment', 'Proven ability to work creatively and analytically in a problem-solving environment', 'Desire to work in an information systems environment', 'Excellent communication (written and oral) and interpersonal skills']",2020-08-08 12:47:24
Senior Data Engineer,Vanguard,3.8 out of 5,"Malvern, PA","['Transform data from multiple sources and formats into one required for reporting and analytics', 'Identify opportunities of internal data process improvements, and develop optimal data delivery infrastructure', 'Develop and optimize data pipeline architecture to organize data for ease of use', 'Productionize analytics/ML models for practical business decision makings', 'Minimum of five years data analytics, programming, database administration, or data management experience.', 'Undergraduate degree or equivalent combination of training and experience.']",2020-08-08 12:47:24
Snowflake Data Engineer (remote),Thrivent Financial,3.9 out of 5,"New York, NY 10001","['Lead the implementation, execution, and maintenance of Data Integration technology solutions', 'Lead work to advance and support information management practices within business processes, applications and technology that underpin the EIM discipline (e.g. establishing data quality processes, performing data analysis, participating in technology implementation planning and verification to ensure successful installation of software and/or projects, implementing data integration processes, administering content, etc.).', 'Provide leadership for Data Integration tasks supporting projects', ""Lead the Management and proactive improvement of Thrivent's data by analyzing the current systems environment, leveraging proven practices, applications, technology, tools and platforms to support and enhance the information landscape."", 'Revenue generated', 'Budget responsibilities', 'Leads the delivery, support and maintenance of solutions with one or more business and technology areas.', 'Organizational impact results from mid-large sized projects', 'Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field', '5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years prior lead experience.', 'Advanced in-depth knowledge of data integration concepts and tools', 'Strong organizational, analytical, critical thinking and leadership skills', 'Demonstrated leadership on mid-large-scale project impacting strategic partners']",2020-08-08 12:47:24
Data Engineer (Open to Remote Workers),Medidata Solutions,3.7 out of 5,"New York, NY 10003","['Be part of a team of data engineers responsible for data aggregation, transformation, modeling and delivery for both client usage and internal data science teams', 'Full-stack design, development, and operation of core data capabilities like data lake, data warehouse, data marts and data pipelines', ""Be part of owning the team's roadmap and project planning process, partnering with stakeholders to develop business objectives and translate those into action"", 'Accountability for one or more data assets', 'Work with data architects to develop data flows and align to platform integration standards', 'Build data flows for data acquisition, aggregation, and modeling, using both batch and streaming paradigms', 'Consolidate/join datasets to create easily consumable, consistent, holistic information', 'Empower other data teams, data scientists and data analysts to be as self-sufficient as possible by building core capabilities as services and developing reusable library code', 'Ensure efficiency, quality, resiliency of the core data platform', 'Data modeling and data governance experience or interest', 'Cloud-oriented with understanding of SaaS models', 'Experience operating in a secure networking environment, leveraging separate production support and SRE teams is a plus but not required', 'You have a bias towards automation, an Agile/Lean mindset and embrace the Devops culture', 'Exposure to AWS and other cloud technologies is a plus', 'Familiarity with streaming/messaging technologies like Kafka, Kinesis, Spark Streaming is nice to have.', 'Familiarity with visualizing data with Tableau, Business Objects, Quicksight, PowerBI and similar tools', 'Great customer focus and strong technical troubleshooting skills', 'Proficiency in statistics and data science is a nice-to-have, and interest in learning these is even better', 'Excellent technical documentation and writing skills', 'Ability to translate ideas into solutions based on user and business needs', 'Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar', '2+ years professional experience as a data engineer, software engineer, data analyst, data scientist, or related role', 'Experience with wide variety of data stores including Relational (eg Oracle, SQL, MySQL), NoSQL (eg MongoDB, Cassandra), Graph/Triple (eg Neo4j, Neptune), Key-Val (eg Dynamo, Redis), Full-Text Search (eg Elasticsearch, Solr), Message Queue (eg Kafka, Kinesis)', 'Analytically minded and detail-oriented: you actually like working with data, looking for patterns and outliers, establishing data models, and finding the best answers to business & technology problems', 'Experience or exposure to data engineering languages such as Java, Scala, Python', 'Experience with MySQL/Oracle is must.', 'Experience or exposure to building ETL and data pipelines, both with traditional ETL solutions like Pentaho, SSIS, Talend but also via code-oriented systems like Spark, Airflow or similar is must.']",2020-08-08 12:47:24
Data Engineer - Apprentice,"Simple Technology Solutions, Inc.",2.3 out of 5,"Washington, DC 20006","['Learn Data Migration, Data Transfer and SQL query script writing', 'Support efforts by the Data Science and Data Analytics teams', 'Learn ETL/ELT, data processing, and analytics', 'Gain skills in relevant languages such as Python, R', 'Profile and analyze data', 'Create or validate system context diagrams, logical data models, and integration designs.', 'Generate data flow diagrams (DFD)', 'Create or validate data mappings', 'Invest a minimum of 10 hours per week', 'Complete courses and certifications remotely', 'Train in a multi-cloud environment', 'Participate in regular meetings', 'Use our Sandbox and build Real Client Solutions', 'Demo your Solutions to Leadership, Mentor and Learning Group', 'Engage in Company Events/Networking', 'Have minimum of 5 years of work experience in any IT field', 'Preference will be given to candidates with college degrees in any field', 'Have an aptitude for a technology role of today', 'Enjoy a life-long learning environment', 'Must be a US citizen with the ability to obtain a Public Trust Clearance', 'Experience with modern data structure design and data engineering is nice to have', 'Understanding of various analytical methods, their abilities, and their limitations is nice to have']",2020-08-08 12:47:24
Data Engineer,"Herman Miller, Inc.",4 out of 5,United States,"['Assist end users in reporting and analysis tools.', 'Collaborate with Analytics and Business Teams to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.', 'Define company data assets (data models).', 'Design data integrations and data quality framework.', 'Develop and maintain scalable data pipelines and build out new API integrations to support continuing increases in data volume and complexity.', 'Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for the key stakeholders and business processes that depend on it.', 'Perform data analysis to troubleshoot data-related issues and assist in the resolution of data issues.', 'Work closely with a team of Application Developers, Architects, and Analysts.', 'Work closely with all Business Units and Software teams to develop strategy for long-term data platform architecture.', 'Write unit/integration tests and document work.', 'Perform additional responsibilities as requested to achieve business objectives.', ""A Bachelor's degree in Computer Science or a related technical field."", 'Fully proficient data engineering abilities, typically gained through five years of working with Python/Java, SQL, working schema design, and dimensional data modeling.', 'At least five years of experience, or and equivalent combination of education and experience.', 'Experience designing, building, and maintaining data processing systems.', 'Experience working with cloud services and cloud data warehouses.', 'Experience with retail and online retail data.', 'Experience with Snowflake, Matillion, Tableau, Business Objectives, and Net Suite (desirable).', 'The ability to manage and communicate data warehouse plans to internal clients.', 'Expert knowledge of best practices and IT operations in an always-up, always-available service.', 'Experience with or knowledge of Agile Software Development methodologies.', 'Advanced problem-solving and troubleshooting skills with the ability to identify and solve complex business needs.', 'The ability to be process-oriented with great documentation skills.', 'Excellent oral and written communication skills with a keen sense of customer service.', 'The ability to perform all essential job functions of the position with or without accommodations.']",2020-08-08 12:47:24
Data Engineer (Open to Remote Workers),Medidata Solutions,3.7 out of 5,"New York, NY 10003","['Be part of a team of data engineers responsible for data aggregation, transformation, modeling and delivery for both client usage and internal data science teams', 'Full-stack design, development, and operation of core data capabilities like data lake, data warehouse, data marts and data pipelines', ""Be part of owning the team's roadmap and project planning process, partnering with stakeholders to develop business objectives and translate those into action"", 'Accountability for one or more data assets', 'Work with data architects to develop data flows and align to platform integration standards', 'Build data flows for data acquisition, aggregation, and modeling, using both batch and streaming paradigms', 'Consolidate/join datasets to create easily consumable, consistent, holistic information', 'Empower other data teams, data scientists and data analysts to be as self-sufficient as possible by building core capabilities as services and developing reusable library code', 'Ensure efficiency, quality, resiliency of the core data platform', 'Data modeling and data governance experience or interest', 'Cloud-oriented with understanding of SaaS models', 'Experience operating in a secure networking environment, leveraging separate production support and SRE teams is a plus but not required', 'You have a bias towards automation, an Agile/Lean mindset and embrace the Devops culture', 'Exposure to AWS and other cloud technologies is a plus', 'Familiarity with streaming/messaging technologies like Kafka, Kinesis, Spark Streaming is nice to have.', 'Familiarity with visualizing data with Tableau, Business Objects, Quicksight, PowerBI and similar tools', 'Great customer focus and strong technical troubleshooting skills', 'Proficiency in statistics and data science is a nice-to-have, and interest in learning these is even better', 'Excellent technical documentation and writing skills', 'Ability to translate ideas into solutions based on user and business needs', 'Undergraduate or graduate degree in a technical or scientific field, such as Computer Science, Engineering, Mathematics, or similar', '2+ years professional experience as a data engineer, software engineer, data analyst, data scientist, or related role', 'Experience with wide variety of data stores including Relational (eg Oracle, SQL, MySQL), NoSQL (eg MongoDB, Cassandra), Graph/Triple (eg Neo4j, Neptune), Key-Val (eg Dynamo, Redis), Full-Text Search (eg Elasticsearch, Solr), Message Queue (eg Kafka, Kinesis)', 'Analytically minded and detail-oriented: you actually like working with data, looking for patterns and outliers, establishing data models, and finding the best answers to business & technology problems', 'Experience or exposure to data engineering languages such as Java, Scala, Python', 'Experience with MySQL/Oracle is must.', 'Experience or exposure to building ETL and data pipelines, both with traditional ETL solutions like Pentaho, SSIS, Talend but also via code-oriented systems like Spark, Airflow or similar is must.']",2020-08-08 12:48:06
Cloud Data Engineer (Azure),Navy Federal Credit Union,4 out of 5,"Vienna, VA 22180","['FORTUNE 100 Best Companies to Work For®', 'Computerworld® Best Places to Work in IT', 'FORTUNE® Best Workplaces for Millennials', 'Forbes® America’s Best Employers', 'PEOPLE® Companies That Care', 'Provide Business Intelligence (BI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms', 'Evaluate and define functional requirements for BI and DW solutions', 'Define and build data integration processes to be used across the organization', 'Build conceptual and logical data models for stakeholders and management', 'Analyze and validate data accuracy of report results', 'Work directly with management understand requirement; and propose and develop best business solution that enables effective decision-making, and drive business objectives', 'Prepares realistic project implementation plans which highlight major milestones and deliverables leveraging standard methods and work planning tools', 'Recognizes potential issues and risks during the analytics project implementation and can suggest realistic mitigation strategies', 'Coaches and mentors project team members in carrying out analytics project implementation activities', 'Leads the preparation of high quality project deliverables that are valued by the business and presents them in such a manner that they are easily understood by project stakeholders', 'Interpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision making', 'Use of statistical practices to analyze current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events', 'The ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner', 'The ability to define and analyze models that predict the probability of an outcome', 'Offers improvements to the way in which analytics service the entire function', 'Communicating and owning the process in manipulating and merging large datasets', 'Ability to view and understand other project or functional areas in order to consolidate analytical needs and processes', 'Being a key point of contact between the data analyst/data scientist and the project/functional analytics leads', 'Perform other duties as assigned', ""Bachelor's degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience"", '5 years’ experience working in a cloud computing with Azure experience required', 'Experience with data migration to cloud based environment', 'Extensive 5 years of experience in providing data architecture solutions for Cloud applications', 'Knowledge of and the ability to perform basic statistical analysis such as measures of central tendency, normal distribution, variance, standard deviation, basic tests, correlation, and regression techniques', 'Experienced in the use of standard ETL tools and techniques', 'Experienced in sourcing, maintaining, and updating data', 'Understanding of data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage', 'Demonstrates functional knowledge of data visualization tools such as Microsoft Power BI, Tableau', 'Has working knowledge of various data structures and the ability to manipulate data within visualization tools', 'Ability to manipulate raw data into effective visualization dashboards', 'Ability to communicate end to end data outcomes visually', 'Demonstrates a deep understanding of multiple database concepts', 'Has a working knowledge of various data structures and the ability to extract data from various data sources (such as Cognos, Informatica)', 'Understands the concepts and application of data mapping and building requirements', 'Optimal understanding of SQL', 'Graduate education in Information Systems, Computer Science, Engineering, or related field', 'Knowledge of Navy Federal Credit Union instructions, standards, and procedures']",2020-08-08 12:48:06
Data Engineer - Apprentice,"Simple Technology Solutions, Inc.",2.3 out of 5,"Washington, DC 20006","['Learn Data Migration, Data Transfer and SQL query script writing', 'Support efforts by the Data Science and Data Analytics teams', 'Learn ETL/ELT, data processing, and analytics', 'Gain skills in relevant languages such as Python, R', 'Profile and analyze data', 'Create or validate system context diagrams, logical data models, and integration designs.', 'Generate data flow diagrams (DFD)', 'Create or validate data mappings', 'Invest a minimum of 10 hours per week', 'Complete courses and certifications remotely', 'Train in a multi-cloud environment', 'Participate in regular meetings', 'Use our Sandbox and build Real Client Solutions', 'Demo your Solutions to Leadership, Mentor and Learning Group', 'Engage in Company Events/Networking', 'Have minimum of 5 years of work experience in any IT field', 'Preference will be given to candidates with college degrees in any field', 'Have an aptitude for a technology role of today', 'Enjoy a life-long learning environment', 'Must be a US citizen with the ability to obtain a Public Trust Clearance', 'Experience with modern data structure design and data engineering is nice to have', 'Understanding of various analytical methods, their abilities, and their limitations is nice to have']",2020-08-08 12:48:06
Data Engineer,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', 'Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets', 'Experience working with AWS big data technologies (EMR, Redshift, S3, Glue, Kinesis and Lambda for serverless ETL)', 'Demonstrated strength in data modeling, ETL development, and data warehousing', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Experience providing technical leadership and mentoring other engineers for best practices on data engineering', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations']",2020-08-08 12:48:06
Data Engineer,"Herman Miller, Inc.",4 out of 5,United States,"['Assist end users in reporting and analysis tools.', 'Collaborate with Analytics and Business Teams to improve data models that feed business intelligence tools, increase data accessibility, and foster data-driven decision making across the organization.', 'Define company data assets (data models).', 'Design data integrations and data quality framework.', 'Develop and maintain scalable data pipelines and build out new API integrations to support continuing increases in data volume and complexity.', 'Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for the key stakeholders and business processes that depend on it.', 'Perform data analysis to troubleshoot data-related issues and assist in the resolution of data issues.', 'Work closely with a team of Application Developers, Architects, and Analysts.', 'Work closely with all Business Units and Software teams to develop strategy for long-term data platform architecture.', 'Write unit/integration tests and document work.', 'Perform additional responsibilities as requested to achieve business objectives.', ""A Bachelor's degree in Computer Science or a related technical field."", 'Fully proficient data engineering abilities, typically gained through five years of working with Python/Java, SQL, working schema design, and dimensional data modeling.', 'At least five years of experience, or and equivalent combination of education and experience.', 'Experience designing, building, and maintaining data processing systems.', 'Experience working with cloud services and cloud data warehouses.', 'Experience with retail and online retail data.', 'Experience with Snowflake, Matillion, Tableau, Business Objectives, and Net Suite (desirable).', 'The ability to manage and communicate data warehouse plans to internal clients.', 'Expert knowledge of best practices and IT operations in an always-up, always-available service.', 'Experience with or knowledge of Agile Software Development methodologies.', 'Advanced problem-solving and troubleshooting skills with the ability to identify and solve complex business needs.', 'The ability to be process-oriented with great documentation skills.', 'Excellent oral and written communication skills with a keen sense of customer service.', 'The ability to perform all essential job functions of the position with or without accommodations.']",2020-08-08 12:48:06
Data Engineer,Warner Bros. Entertainment Group,4.2 out of 5,"Burbank, CA","['Develop and provide support for core data relationship, data ingest, data transformation services and search capabilities. Creates functional and technical specifications. Creates and executes against a plan to launch and maintain applications.', 'Review project objectives and determine best technology for implementation. Implement best practice standards for development, build and deployment automation.', 'Evaluate software products and vendors for WarnerMedia (WM) Technology and other divisions. Recommend action, develop and lead implementation of selected products/services.', 'Work with internal and external developers to ensure (WM) Technology code standards and best practices are performed for development of applications.', 'B.S. in Computer Science or equivalent experience.', 'AWS Developer Certification preferred.', 'AWS Database or Data Analytics Certification preferred.', '3+ years data engineering experience.', 'Demonstrated proficiency in data modeling and data structures.', 'Demonstrated experience implementing database technologies such as NoSQL, and Relational. Experience in graph databases a plus.', 'Demonstrated expertise and experience in ELK stack (elasticsearch, logstash, kibana).', 'Demonstrated expertise and experience in modern databases such as Mongo, Couchbase, Neptune, Neo4j, or equivalent. Experience in MarkLogic a plus.', 'Proficient in one or more modern query languages such as elasticsearch query DSL, cypher, gremlin, or graphql. xQuery preferred but not required.', 'Highly proficient in XML, JSON and YAML data exchange formats. Experience in XSDs and triple stores.', 'Proficient in API design and development, specifically REST APIs. Experience with Swagger 2.0 and AWS API gateway is highly preferred.', 'Demonstrated experience in data analytics tools such as Tableau, Kibana etc.', 'Experience in working with data streaming technologies such as Amazon Kinesis, Apache Kafka etc.', 'Experience in AWS at scale leveraging services such as elasticsearch, RDS, Redshift, Neptune and ec2.', 'Highly proficient in at least one modern programming language such python, java, or node.js. Bash experience preferred.', 'Demonstrated expertise and experience in deploying containerized application using Docker, Kubernetes or equivalent.', 'Experience with source code and knowledge repositories such as git, jira, or equivalent systems.', 'Proficient in a Linux environment.', 'Proficient in core DevOps principles.', 'Proficient in the SDLC in an agile environment.', 'Systems design and architecture.', 'Ability to work with outside vendors and clients under sometimes adverse circumstances and under time critical constraints.', 'Must be able communicate effectively and tactfully with all levels of personnel (in person, written, telephone).', 'Must be able to pay close attention to detail.', 'Must be able to handle multiple tasks in a fast-paced environment.', 'Must be able to organize and schedule work effectively.', 'Must be able to work flexible hours, including overtime, if and when necessary.', 'Must be able to respond to after-hours pager notifications to provide support for applications as necessary.']",2020-08-08 12:48:06
Data Engineer,Elder Research Inc,N/A,"Arlington, VA 22201","['Work collaboratively with data scientists, business consultants, and software engineers to create and deploy dynamic data applications that help our customers make meaningful business decisions.', 'Develop and deploy robust data pipelines and end-to-end systems', 'Participate in every stage of the engineering lifecycle, from ideation and requirements gathering through implementation, testing, deployment, and maintenance', 'Provide leadership and coordination for certain stages of the engineering lifecycle as needed', 'Perform other technical tasks as needed, including writing project reports, managing, implementing, and/or maintaining technical infrastructure, etc.', 'Ability and the willingness to tailor applications to a client’s business goals using an iterative methodology.', 'Ability to consider both long-term stability and scalability while taking a user-focused approach to development and deployment.', 'Communicate clearly both verbally and in writing to teammates and clients', 'Ability to work independently in a collaborative, dynamic, cross-functional environment', 'Travel to and work on-site at clients both local and non-local. Number of days at client site vary depending on project requirements', 'Eight (8) years relevant experience data architecture, Computer Science, Engineering, Information Systems or related technical discipline in applied data science research or big data analytics.', 'Bachelor’s Degree in Computer Science, Engineering, Information Systems or related technical discipline. A Master’s degree may be substituted for up to two (2) years of experience. A PhD may be substituted for up to five (5) years of experience.', 'Ability to perform functional and data requirements analysis, and implementation of data engineering projects, analyze customer requirements and provide solution recommendations.', 'Demonstrate knowledge of information engineering methodologies, process improvement, and performance measurement', 'Ability to support the development of organization-wide data models for use in designing and building integrated, shared software and database systems;', 'Must be able and willing to obtain a successful CBP Background investigation. A secret or higher clearance may be required in the future.', 'Previous experience supporting projects with US Customs and Border Protection', 'Data manipulation, SQL, relational databases, and/or NoSQL databases – experience as a DBA is a huge plus', 'Cloud platform development and SaaS', 'DevOps – infrastructure, continuous integration and automation, packaging and deployment', 'Consulting experience is a plus']",2020-08-08 12:48:06
Data Engineer,Chartbeat,4.3 out of 5,"New York, NY","['Strong programming abilities in Python and/or Java or Clojure (and the JVM)', 'Familiarity with architectural patterns used by different databases in large, high-scale applications (particular experience with Redshift, HBase, or PostgreSQL is a plus)', 'Interest in working with and building distributed systems (e.g. technologies like Zookeeper, Kafka)', 'Excellent verbal and written communication skills and a commitment to building an inclusive and collaborative working environment', 'An interest in designing technical solutions to open-ended product problems', 'Passion and enthusiasm about learning and teaching new technologies']",2020-08-08 12:48:06
Content Engineer - Arabic specialist,Amazon.com Services LLC,3.6 out of 5,Remote,"['Fluency in Arabic', 'Bachelor’s degree in a quantitative field, or equivalent experience', 'Proficiency in data retrieval and analysis (e.g. MySQL, Excel, Javascript, Python, etc.)', 'Expand and maintain the content search experience for Arabic content', 'Build and manage data pipelines', 'Work with and improve content cataloging technology (e.g. taxonomies/ontologies)', 'Apply Arabic-language expertise to improve the customer experience', 'Closely monitor specific KPIs, drive improvements in query success.', 'Ability to think critically and demonstrate a quantitative, systematic approach to solving problems', 'Excellent communication and team skills', 'Ability to work autonomously with minimal supervision']",2020-08-08 12:48:06
Data Engineer,Prospect 33,4.5 out of 5,"Philadelphia, PA",[],2020-08-08 12:48:06
Data Analytics Engineer – Junior,CACI,3.8 out of 5,"Washington, DC 20005","['The Data Analytics Engineer – Junior is responsible for providing junior-level back-end support for projects related to investigations and litigation cases.', 'This includes managing the design, modeling, and implementation of a variety of databases and applications. The Data Analytics Engineer – Junior will assist with the gathering of a wide variety of data types from primary and secondary sources through diverse channels using a combination of methods that will be populated into the appropriate analytical tools employed by the Data Analytics Management team.', 'Assisting Mid and Senior level Data Analytics Engineers with performing systems and database maintenance are key components of the work to include designing/implementing ETL pipelines, preservation of source data, performance optimization, monitoring, and suggesting improvements.', 'Assisting with the design, development, implementation, maintenance and optimization of a variety of databases and systems to include designing logical and physical database structures, partitioning of tables, data loading and validation, all aspects of security, monitoring, and performance tuning', 'Assists with maintaining database dictionaries, and monitoring standards and procedures', 'Provides technical guidance to management, or other team members in regards to implementation of highly advanced technical solutions', 'Supporting all dimensions of analysis including data transformations, sourcing, mapping, conversion and loading data', 'Collaborate across teams in order to quickly adapt to emerging and dependent technologies', 'Continually interact with teams to design and implement innovative data solutions that will provide key decision making abilities', 'Assist with establishing and maintaining documentation for all design, development, and maintenance activities to include database entity relationship diagrams, ETL processes, source code version control, and automated maintenance processes.', 'Perform routine source code reviews of ETL processes for defects, performance tuning, or changes in source data format', 'Deliver assignments by established deadlines. Keep management well-informed on a timely basis of progress, status and/or concerns for each assignment', 'Assist with developing and maintaining standards for database implementation, maintenance, and optimization', 'Assist with the implementation, maintenance, and testing of Disaster Recovery methodology for all production databases.', 'Reviews performance and capacity planning reports and makes recommendations to management', ""Bachelor's degree or equivalent, and 3 years of applicable experience."", 'Experience with the design, implementation, administration, and maintenance of a variety of highly complex databases (typically SQL Server, Teradata, DB2, Oracle, MySQL, or PostgreSQL) to include implementing security and access methods', 'Ability to work at OS level on Linux and Windows, writing scripts and configuring storage', 'Experience with ETL of large data sets using Python, Teradata, SSIS, or Talend to source, load, and verify data of various formats', 'Experience with automated tools for database design and implementation', 'Ability to embrace and lead technological change and development', 'Experience with developing procedures relating to database and application security including procedures by which access is authorized, enabled, changed and withdrawn', 'Experience with identifying and implementing enhancements to improve performance and reliability of existing database systems.', 'Experience with the implementation, testing, and maintenance of Disaster Recovery for various databases.', 'Experience with performing threshold forecasting, sizing, capacity planning, and trend analysis.', 'Experience with performance monitoring and summary table creation.', 'Experience working in AWS cloud environments', 'Experience with ETL and Database management in direct support of Tableau Server', 'Experience with schema development, ETL, and database management in IBM I2 Enterprise Insight Analysis (EIA) Opal w/ I2 Connect', 'Experience with litigation support, investigations, or administering Litigation Support tools', 'Normal demands associated with an office environment.', 'Ability to work on computer for long periods, and communicate with individuals by telephone, email and face to face.', 'Some travel may be required.', 'We’ve been named a Best Place to Work by the Washington Post.', 'Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.', 'We offer competitive benefits and learning and development opportunities.', 'We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.', 'For over 55 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.']",2020-08-08 12:48:06
Data Engineer,SIMON Markets LLC,N/A,"New York, NY","['Analyzing user behavior to maximize adoption of the platform', 'Ingesting external data sets into a computational research environment', 'Measuring performance of the platform to reduce operational cost', 'Experienced in at least 1 numeric research framework (python/pandas, R/Splus, Octave/Matlab)', 'Some background in probability/statistics', 'Familiarity with various database designs (Relational, Columnar, nosql)', 'Familiarity with AWS and infrastructure-as-code (terraform or cloud formation)', 'Understanding of machine learning techniques']",2020-08-08 12:48:06
Snowflake Data Engineer (remote),Thrivent,3.9 out of 5,"New York, NY","['Lead the implementation, execution, and maintenance of Data Integration technology solutions', 'Lead work to advance and support information management practices within business processes, applications and technology that underpin the EIM discipline (e.g. establishing data quality processes, performing data analysis, participating in technology implementation planning and verification to ensure successful installation of software and/or projects, implementing data integration processes, administering content, etc.).', 'Provide leadership for Data Integration tasks supporting projects', ""Lead the Management and proactive improvement of Thrivent's data by analyzing the current systems environment, leveraging proven practices, applications, technology, tools and platforms to support and enhance the information landscape."", 'Revenue generated', 'Budget responsibilities', 'Leads the delivery, support and maintenance of solutions with one or more business and technology areas.', 'Organizational impact results from mid-large sized projects', 'Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field', '5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years prior lead experience.', 'Advanced in-depth knowledge of data integration concepts and tools', 'Strong organizational, analytical, critical thinking and leadership skills', 'Demonstrated leadership on mid-large-scale project impacting strategic partners']",2020-08-08 12:48:06
Data Warehouse Engineer,i3infotek,N/A,"West Chester, PA","['SQL', 'Data Warehouse', 'SSIS', 'Dimensional Model Experience', 'SSAS', 'Azure Lake experience a plus', 'Azure Data Factory a plus', 'Azure Data Warehouse a plus.', 'Tableau a plus']",2020-08-08 12:48:06
Senior Data Engineer,Privia Health,2.6 out of 5,Remote,"['Lead projects end-to-end as an individual contributor', 'Design and develop high-volume, low-latency applications for mission-critical systems, delivering high-availability and performance', 'Is an activist for best practices and champions them on the team', 'Mentor junior developers and delegate work where appropriate', 'Contribute in all phases of the development lifecycle', 'Deliver timely, well written, well designed, testable, efficient code', 'Ensure designs are in compliance with specifications', 'Designs with a dev-ops mindset', 'Support continuous improvement by investigating alternatives and technologies and presenting these for architectural review', 'Perform other duties as assigned', '4+ years of experience implementing commercial data warehouses and data marts', '1+ years’ experience in Python', 'Experience working with APIs', 'Experience with cloud technologies (AWS, GC, Kafka, Spark, Kensis )', 'Hands-on proficiency with SQL, SSIS, and ETL jobs, including stored procedures', 'A track record of shipping quality software', 'A strong desire to learn new technologies', 'A strong belief in automated testing', 'Experience with Agile SDLC', 'Must comply with HIPAA rules and regulations', 'Must be willing and able to communicate with the team via webcam, webconf, and phone.', 'Must have access to private, quiet work space with high-speed internet to effectively work remotely', 'Ability to work collaboratively in a multi-location, cross-functional team with a wide range of experience levels', 'Excellent communication skills (verbal and written) necessary to effectively interact with data engineering staff, product owners, and stakeholders', 'Able to manage competing priorities', 'Excellent analytical and problem solving skills', 'Strong attention to detail and problem-solving skills', 'Adaptable and flexible', 'Slack', 'Video calls', 'Emails']",2020-08-08 12:48:06
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:48:48
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 12:48:48
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:48:48
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:48:48
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:48:48
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:48:48
Data Analytics Engineer – Junior,CACI,3.8 out of 5,"Washington, DC 20005","['The Data Analytics Engineer – Junior is responsible for providing junior-level back-end support for projects related to investigations and litigation cases.', 'This includes managing the design, modeling, and implementation of a variety of databases and applications. The Data Analytics Engineer – Junior will assist with the gathering of a wide variety of data types from primary and secondary sources through diverse channels using a combination of methods that will be populated into the appropriate analytical tools employed by the Data Analytics Management team.', 'Assisting Mid and Senior level Data Analytics Engineers with performing systems and database maintenance are key components of the work to include designing/implementing ETL pipelines, preservation of source data, performance optimization, monitoring, and suggesting improvements.', 'Assisting with the design, development, implementation, maintenance and optimization of a variety of databases and systems to include designing logical and physical database structures, partitioning of tables, data loading and validation, all aspects of security, monitoring, and performance tuning', 'Assists with maintaining database dictionaries, and monitoring standards and procedures', 'Provides technical guidance to management, or other team members in regards to implementation of highly advanced technical solutions', 'Supporting all dimensions of analysis including data transformations, sourcing, mapping, conversion and loading data', 'Collaborate across teams in order to quickly adapt to emerging and dependent technologies', 'Continually interact with teams to design and implement innovative data solutions that will provide key decision making abilities', 'Assist with establishing and maintaining documentation for all design, development, and maintenance activities to include database entity relationship diagrams, ETL processes, source code version control, and automated maintenance processes.', 'Perform routine source code reviews of ETL processes for defects, performance tuning, or changes in source data format', 'Deliver assignments by established deadlines. Keep management well-informed on a timely basis of progress, status and/or concerns for each assignment', 'Assist with developing and maintaining standards for database implementation, maintenance, and optimization', 'Assist with the implementation, maintenance, and testing of Disaster Recovery methodology for all production databases.', 'Reviews performance and capacity planning reports and makes recommendations to management', ""Bachelor's degree or equivalent, and 3 years of applicable experience."", 'Experience with the design, implementation, administration, and maintenance of a variety of highly complex databases (typically SQL Server, Teradata, DB2, Oracle, MySQL, or PostgreSQL) to include implementing security and access methods', 'Ability to work at OS level on Linux and Windows, writing scripts and configuring storage', 'Experience with ETL of large data sets using Python, Teradata, SSIS, or Talend to source, load, and verify data of various formats', 'Experience with automated tools for database design and implementation', 'Ability to embrace and lead technological change and development', 'Experience with developing procedures relating to database and application security including procedures by which access is authorized, enabled, changed and withdrawn', 'Experience with identifying and implementing enhancements to improve performance and reliability of existing database systems.', 'Experience with the implementation, testing, and maintenance of Disaster Recovery for various databases.', 'Experience with performing threshold forecasting, sizing, capacity planning, and trend analysis.', 'Experience with performance monitoring and summary table creation.', 'Experience working in AWS cloud environments', 'Experience with ETL and Database management in direct support of Tableau Server', 'Experience with schema development, ETL, and database management in IBM I2 Enterprise Insight Analysis (EIA) Opal w/ I2 Connect', 'Experience with litigation support, investigations, or administering Litigation Support tools', 'Normal demands associated with an office environment.', 'Ability to work on computer for long periods, and communicate with individuals by telephone, email and face to face.', 'Some travel may be required.', 'We’ve been named a Best Place to Work by the Washington Post.', 'Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.', 'We offer competitive benefits and learning and development opportunities.', 'We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.', 'For over 55 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.']",2020-08-08 12:48:48
Data Engineer,"YinzCam, Inc.",4 out of 5,"Pittsburgh, PA 15206","['Thinks nothing is impossible', 'Is a tinkerer and implementor of big-data systems', 'Has a knack for data visualization to derive insights', 'Is equally comfortable with database systems and machine-learning algorithms', 'Running analyses on terabytes of data that arise from digital assets', 'Applying machine-learning algorithms on data sets in order to cluster and segment them', 'Providing insights from the data, to understand user behavior, predict user behavior, identify anomalies, and identify patterns', 'Building, maintaining, and refining data dashboards', 'Driving new product development based on insights from the data', '2 years+ of machine-learning experience with giant data-sets', '2 years+ of experience in data visualization techniques and best practices', '2 years+ of experience in working with Hadoop, Hive, Spark, and other big-data platforms', '2 years+ of experience with SQL, relational databases, NoSQL databases, including Postgres and Cassandra', '2 years+ of experience with Google Analytics, Firebase', '2 years+ of experience with AWS cloud services, such as EC2, EMR, RDS, Redshift', '2 years+ of experience in Java/C++/Python programming', 'Expert programmer and tinkerer, comfortable around operating systems, cloud computing, network protocols', 'Willingness to work in a high energy, fast-paced environment', 'Strong desire to learn and grow career', 'Degree in Computer Science/Engineering, with a heavy focus on machine-learning, data science, data engineering.', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Relocation Assistance', 'Vision Insurance', 'Monday to Friday', 'Weekends', 'machine-learning: 2 years (Required)', 'SQL and relational database: 2 years (Required)', 'Tableau: 2 years (Required)', 'Hadoop/Hive: 2 years (Preferred)', 'Java programming: 2 years (Required)', ""Bachelor's (Required)"", 'Pittsburgh, PA 15206 (Required)', 'United States (Required)', 'What is the largest data-set you have analyzed? And what techniques did you use to analyze it?', 'One location', 'www.yinzcam.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 12:48:48
DATA ENGINEER APPRENTICE,Digital Creative Institute,5 out of 5,"Job, WV","['Associate degree or equivalent', 'Adventurers needed. You’ll have the opportunity to be placed in one of our partner company’s offices in Dallas, Charlotte, Seattle, Atlanta, or Chicago.', 'Strong computer skills, including experience with programming languages (Python, Java, SQL, R, etc.)', 'Experience with Microsoft Office tools, especially creating/ maintaining Excel spreadsheets', 'High level of attention to detail and problem-solving ability', 'Ability to accurately sort and analyze data', 'Ability to communicate ideas both verbally and in writing', 'Must be willing to learn additional data engineering and analytics toolsets', 'Architect, design and detail processes', 'Troubleshoot issues, document process, review checklists, and develop a reference implementation', 'Develop and implement databases, data collection systems, data analytics and other strategies that optimize efficiency and quality', 'Acquire data from primary or secondary data sources and maintain databases/data systems', 'Support technical team deployment with activities to ensure a smooth go-live of new processes, products, or systems', 'Understand the existing system and processes to document', 'Reverse knowledge transfer to document the process of support and maintenance']",2020-08-08 12:48:48
Data Center Operations Engineer,Facebook,4.2 out of 5,"Henrico County, VA","[""Work within Facebook's ticketing system in support of the health of Facebook's server fleet"", 'First point of contact for break fix technicians', 'Accountable for assisting with projects (new capacity as well as retrofits) and repairs throughout the data center', 'Understand and initial analysis to debug hardware, and Linux OS related issues', 'Demonstrate personal leadership Identifying and helping to create documentation for the global data center knowledge base', 'Assist with process improvements and best practices in data center operations', 'Participate in on-call rotation (once a month on call for a week after hours, first point of contact)', ""Bachelor's degree in a technical field or certification"", 'Knowledge of Linux and server hardware repairs', 'Experience modifying and developing in Python, SQL, and/or shell scripting', 'Working conceptual knowledge of technologies such as HTTP, DNS, RAID, and DHCP']",2020-08-08 12:48:48
Data Engineer,HealthVerity,N/A,"Philadelphia, PA 19103","[""Work with internal stakeholders to load data into HealthVerity's data warehouse"", 'Troubleshoot and resolve issues relating to data integrity', 'Help establish procedures and best practices for transforming and storing data', 'Lead requirements gathering around data pipeline automation improvements', 'Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin', 'Leverage distributed computing and serverless architecture such as AWS EMR & AWS Lambda, to develop pipelines for transforming data', 'Enjoy the peace that comes with working in a mature software development environment', 'Marvel at the speed with which your creation makes it into production', 'Research and implement new technologies with a team of developers to execute strategies and implement solutions', 'Produce peer reviewed quality software', 'Solve complex problems related to the real-time discovery of large data', 'Experienced in writing scalable applications on distributed architectures', 'Data driven, testing and measuring as much as you can', 'Eager to both review peer code and have your code reviewed', 'Comfortable on the command line and consider it an essential tool', 'Confident in SQL, you know it, write smart queries, it’s no big deal', '5+ years of work experience', '3+ years of experience with Python', '3+ years of experience with PySpark and Spark-SQL (writing, testing, debugging spark routines)', '1+ years of experience with AWS EMR, AWS S3 service. Comfortable using AWS CLI and boto3', 'Comfortable working in remote environments', 'Comfortable using *nix command line (shell scripting, AWK, SED)', 'Experience with MySQL and Postgres', 'Experience with Apache Airflow', 'Experience with Apache Zeppelin', 'Experience with healthcare data', 'Empowering clients with highly rewarding data discovery and licensing tools', 'Ingesting and managing billions of healthcare records from a wide variety of partners', 'Standardizing on common data models across data types', 'Orchestrating an industry-leading HIPAA privacy layer', 'Innovating our proprietary de-identification and data science algorithms', 'Building a culture that supports rapid iteration and new possibilities']",2020-08-08 12:48:48
Data Engineer I,Conde Nast,4 out of 5,"New York, NY 10007","['Build batch and streaming data pipelines using Spark, Airflow and AWS/GCP services', 'Build efficient code to transform raw data', 'Collaborate with other Data Engineers to implement a shared technical vision', 'Follow agile processes with a focus on delivering production-ready, testable deliverables, and automated code', 'Participate in the entire software development life cycle, from concept to release', 'Create new data models that are appropriately scalable, standardized, and reliable', 'BS, or equivalent industry experience in Computer Science, Software Engineering, or other related Science/Technology/Engineering/Math fields.', '1+ years experience working with data in a large enterprise', 'Experience in writing reusable/efficient code to automate analysis and data processes', 'Experience in processing structured and unstructured data into a form suitable for analysis and reporting with integration with a variety of data metric providers ranging from web analytics, consumer analytics, user behavior and advertising', 'Experience implementing scalable, distributed, and highly available systems using AWS services such Kinesis, DynamoDB, S3', 'Proficiency in Python/PySpark, Scala or Java', 'Proficiency in SQL', 'Experience with Spark, AWS ecosystem, Hadoop, Pig, Hive, Flink, or Beam.', 'Experience with orchestration tools such as Airflow', 'Experience with Git version control, and other software adjacent tools']",2020-08-08 12:48:48
Sr. Data Engineer,RX Staffing,N/A,Remote,"['Design systems that reliably and efficiently provide interactive query performance on large amounts of multi-modal data', 'Build systems that handle scale', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using SQL and AWS ‘big data’ technologies', 'Collect, parse, analyze, and visualize large sets of data', 'Turn data into insights', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product', 'Experience with large-scale data and query optimization techniques', 'Experience with ETL to data warehouse systems', 'Experience with AWS cloud services: EC2, RDS, Redshift, Aurora', 'Expert in SQL, NoSQL, and RDBMS', 'Knowledge in multiple scripting languages (e.g. Python)', 'Knowledge of cloud, distributed systems, and stream-processing systems', 'Passionate about learning new technologies and solving hard problems in a fast-paced environment', 'Has a Computer Science degree', 'Is a ""student of the game"" and thrives on new challenges', ""Enjoys learning from teammates, and isn't afraid to teach others at the same time"", 'Sees the glass half-full. This is a new industry space...your vision could make all the difference!', 'Wants to make a lasting impact and lifelong connections, this is not just another paycheck', 'AWS: 5 years (Preferred)', 'building SaaS products through data insights: 5 years (Preferred)', 'SQL: 5 years (Preferred)', 'Python: 5 years (Preferred)', 'Database Architecture: 1 year (Preferred)', ""Bachelor's (Preferred)"", 'United States (Preferred)', 'Yes']",2020-08-08 12:48:48
Data Engineer,Mondo,N/A,"Malvern, PA 19355",[],2020-08-08 12:48:48
Data Engineer,Warner Bros. Entertainment Group,4.2 out of 5,"Burbank, CA","['Develop and provide support for core data relationship, data ingest, data transformation services and search capabilities. Creates functional and technical specifications. Creates and executes against a plan to launch and maintain applications.', 'Review project objectives and determine best technology for implementation. Implement best practice standards for development, build and deployment automation.', 'Evaluate software products and vendors for WarnerMedia (WM) Technology and other divisions. Recommend action, develop and lead implementation of selected products/services.', 'Work with internal and external developers to ensure (WM) Technology code standards and best practices are performed for development of applications.', 'B.S. in Computer Science or equivalent experience.', 'AWS Developer Certification preferred.', 'AWS Database or Data Analytics Certification preferred.', '3+ years data engineering experience.', 'Demonstrated proficiency in data modeling and data structures.', 'Demonstrated experience implementing database technologies such as NoSQL, and Relational. Experience in graph databases a plus.', 'Demonstrated expertise and experience in ELK stack (elasticsearch, logstash, kibana).', 'Demonstrated expertise and experience in modern databases such as Mongo, Couchbase, Neptune, Neo4j, or equivalent. Experience in MarkLogic a plus.', 'Proficient in one or more modern query languages such as elasticsearch query DSL, cypher, gremlin, or graphql. xQuery preferred but not required.', 'Highly proficient in XML, JSON and YAML data exchange formats. Experience in XSDs and triple stores.', 'Proficient in API design and development, specifically REST APIs. Experience with Swagger 2.0 and AWS API gateway is highly preferred.', 'Demonstrated experience in data analytics tools such as Tableau, Kibana etc.', 'Experience in working with data streaming technologies such as Amazon Kinesis, Apache Kafka etc.', 'Experience in AWS at scale leveraging services such as elasticsearch, RDS, Redshift, Neptune and ec2.', 'Highly proficient in at least one modern programming language such python, java, or node.js. Bash experience preferred.', 'Demonstrated expertise and experience in deploying containerized application using Docker, Kubernetes or equivalent.', 'Experience with source code and knowledge repositories such as git, jira, or equivalent systems.', 'Proficient in a Linux environment.', 'Proficient in core DevOps principles.', 'Proficient in the SDLC in an agile environment.', 'Systems design and architecture.', 'Ability to work with outside vendors and clients under sometimes adverse circumstances and under time critical constraints.', 'Must be able communicate effectively and tactfully with all levels of personnel (in person, written, telephone).', 'Must be able to pay close attention to detail.', 'Must be able to handle multiple tasks in a fast-paced environment.', 'Must be able to organize and schedule work effectively.', 'Must be able to work flexible hours, including overtime, if and when necessary.', 'Must be able to respond to after-hours pager notifications to provide support for applications as necessary.']",2020-08-08 12:48:48
Data Engineer,Indiana Farmers Insurance,4.3 out of 5,"Indianapolis, IN 46290","['Collaborate with various departments to capture and document data points using technology platforms', 'Develop intuitive analytical tools to provide actionable insight into key business performance metrics', 'Communicate effectively and drive awareness of data and system functionality', 'Build infrastructure for optimal extraction, transformation and loading of data from various sources, using SQL and other ETL technologies.', 'Promote understanding of data-related technical issues and plans for process improvement', 'Optimize data delivery and automate manual processes', 'Bachelor’s degree in computer science or engineering', 'A positive attitude, team mentality, and the interpersonal skills essential for effective communication with cross-disciplined teams', 'Ability to perform root cause analysis on external and internal processes and identify opportunities for improvement and actionable insights', 'Solid understanding of SQL, ETL Technologies and Power BI', 'Excellent analytical skills associated with working on unstructured datasets', 'Ability to build processes that support data transformation, workload management, data structures, dependency, and metadata', 'Excellent written and verbal communication skills, including the ability to convey complex issues to individuals with various technical and non-technical backgrounds', '95% retention of our associates over the last 5 years even with a very competitive employment market.', 'Financially stable as shown by our A (Excellent) rating by AM Best.', 'Truly customer focused, as all mutual insurance companies are and', 'A strong legacy of excellent performance throughout our 143 years in business!', 'Health, dental, vision and life Insurance provided free of charge to associates', 'Opportunities for advancement', 'Work schedules that include remote workdays, as well as compressed schedules', 'An exceptional 401(k) Plan with a 2% match plus an 11% company contribution', 'Above average Paid Time Off days as well as paid holidays', 'A diverse workforce', 'A paid Day of Service to serve others at your favorite charitable organization', 'Matching funds of up to $100 annually for your favorite charitable organization', 'An on-site fitness center, complete with showers', 'Associate recognition awards and an annual Associate Recognition Luncheon', 'Educational Assistance Program', 'Casual attire', 'Free and convenient parking right next to our building, and', 'Smiles and camaraderie with your co-workers is free every day!']",2020-08-08 12:48:48
Junior GIS Data Engineer,Xentity Corporation,4.1 out of 5,"Golden, CO 80402","['Job', 'Company', 'GIS -Strong foundation in GIS Principles and experience working with and manipulating GIS data - 1 yr', 'Python for data management, Pandas, Requests, Data Cleaning, Understanding of Metadata and ETL/Data Pipelines', 'Cloud: BootCamp level or project experience in AWS, GCP, or other major clouds', 'We prefer more data processing experience in data feeds, geospatial data, and data scripts over management of information systems.', 'Demonstration of handling, manipulating data, records, feeds', 'General knowledge familiarity of use patterns in services, analytics, applications, dashboards and other use by data scientist', 'Data : Open and Public Data Experience, REST APIs for Data Services', 'Geospatial : ESRI ArcGIS Server, ArcGIS Online, Open Data Hub, QGIS, GDAL, ArcPy, GeoPandas', 'Programming Languages: NodeJs, ArcPy', 'Database Technology: PostgreSQL', 'Cloud Experience: AWS ECS, EC2, S3 hands-on experience, Kubernetes, Docker', 'Tools and Software: Power BI, Tableau, similar, GIT, JIRA', 'Bachelor’s Degree min. Education and 1 years min. experience', 'Must be able to pass basic NACI, background, drug and reference checks', 'Must be local. No Relocation Assistance.', 'Travel None to Rare/In-State', 'Ability to thrive in an energetic, fast-paced environment - learn and become productive quickly and meet team goals, can-do attitude, able to do what it takes to deliver.', 'Ability to work multiple, time-sensitive tasks - Able to rapidly context switch across subject matter, communication and architecture products, and stakeholder audiences.', 'Ability to work independently as well as as part of an integrated team.', 'Excellent oral and written communication skills.', 'Demonstrate strong analytical and critical thinking skills', 'Maintain a Public Data Catalog. Manage an ETL environment to maintain over 300 active dataset updates to a centralized portal, setup new ETL scripts for incoming datasets ~35/year, and manage associated documentation spreadsheets.', 'Assist State Agencies in Making Their Data Public. Work with a wide variety of State Agencies to provide them with the technical support required to keep datasets current on the centralized portal. Publish new datasets (as derived from any given tech stack) to a centralized portal and make them discoverable', 'Cultivate Dataset Back Stories. Curate metadata that conveys context to End Users of Public Data.', 'Data Storytelling, Dashboards, Data Visualizations. Create Public Data stories and demonstrations that show the value of Public Data. Generate content for users to better understand and utilize Public Data.', 'Public and Open Data Evangelism. Explore ways to build content on the benefits of Public Data to communities, and specifically the impact and status of the current state of Public Data in Colorado.', 'Technical Writing. Make updates to process documentation as new technologies are utilized and workflows are improved.', 'GIS Analysis and Tech. Geospatial knowledge required for some data transform work.', 'Assist Government programs with technical support to ETL/data pipeline data into catalog for primarily tabular and geospatial data - some unstructured occurs.', 'Maintain Public Self-service data catalog', 'Develop quality scripts to validate data for tabular and geospatial data.', 'Edit and Curate metadata to support public discovery', 'Provide End user support with data discovery, access, and use requests', 'Support prototyping of Data Storytelling, Dashboards, Data Visualizations for demonstrations', 'Maintain technical documentation of catalog and operations', 'You will be expected to rapidly ramp-up on client lingo, proactively make observations of patterns, anomalies, problems, and be customer service focused.', 'You will be expected to be highly self-motivated and understand you will be held accountable to commitments.', 'We look for decisive individuals able to rapidly respond to change requests and able to communicate, track, and escalate risk.', 'We expect you to be proactive, efficient, and ready to learn quickly in response to all client and team member needs. This is a bootcamp-type position setup for growth.', 'We want you to not only gain technical skills, but also grow your interactive and client facing skills.', 'We will require strong communication and interactive skills - oral, written, visual especially for triaging conflict, ideation barriers, mitigating risk, foster thought diversity and team environment.', 'We expect all our roles to focus on attaining a mastery of their technical level demonstrating fast learning at their role whether that be in architectural methods, languages, work products, consulting techniques, and client culture.', 'We emphasize a balance of work and life and target 40-50 hour weeks with ample time to refresh with great paid-time off.', 'Salary & Bonus Programs - Competitive Salary. Multiple Recognition and Rewards Bonus Programs (Performance Bonus plan reviewed twice annually - total ranging from 2-5% of salary and Business Development Bonus Plan, Employee Referral Bonus Plan, and Company Profit Sharing Plan).', 'Paid Time off - (10) Paid Holidays, (10) Personal Time Off, and (5) Sick Leave', 'Medical Insurance - Coverage for Major Medical and Surgical, Medical Health Care, Dependents’ Health Care with 100% of employee or 80% employee and 50% family. Options to enroll in Dental Insurance, Vision Discount Program, Prescription Discount Program, Group Term Life Insurance, Accidental Death & Dismemberment Insurance, and Professional insurance advisors to guide employees through these benefits as needed.', 'Solid, managed retirement savings plan including - Multiple 401(k) funds with traditional and Roth options, Company paid fees, Company Match, Third-party Trust Management with personalized retirement portfolio web analysis tools.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'GIS data engineer: 1 year (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'One location', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'careers.xentity.com', 'https://www.facebook.com/xentitycorp/', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-08-08 12:48:48
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:48:48
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:48:48
Data Engineer I,Conde Nast,4 out of 5,"New York, NY 10007","['Build batch and streaming data pipelines using Spark, Airflow and AWS/GCP services', 'Build efficient code to transform raw data', 'Collaborate with other Data Engineers to implement a shared technical vision', 'Follow agile processes with a focus on delivering production-ready, testable deliverables, and automated code', 'Participate in the entire software development life cycle, from concept to release', 'Create new data models that are appropriately scalable, standardized, and reliable', 'BS, or equivalent industry experience in Computer Science, Software Engineering, or other related Science/Technology/Engineering/Math fields.', '1+ years experience working with data in a large enterprise', 'Experience in writing reusable/efficient code to automate analysis and data processes', 'Experience in processing structured and unstructured data into a form suitable for analysis and reporting with integration with a variety of data metric providers ranging from web analytics, consumer analytics, user behavior and advertising', 'Experience implementing scalable, distributed, and highly available systems using AWS services such Kinesis, DynamoDB, S3', 'Proficiency in Python/PySpark, Scala or Java', 'Proficiency in SQL', 'Experience with Spark, AWS ecosystem, Hadoop, Pig, Hive, Flink, or Beam.', 'Experience with orchestration tools such as Airflow', 'Experience with Git version control, and other software adjacent tools']",2020-08-08 12:49:44
Data Engineer - AWS FinTech,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', '3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', 'Bachelor’s degree in CS or related technical field.', '5+ years of work experience with ETL, Data Modeling, and Data Architecture.', '3+ years experience using big data technologies (Parquet, Spark, Hadoop, Presto, EMR, etc.)', 'Excellent knowledge of SQL and Linux OS', 'Proficiency in at least one modern programming language such as Java, Scala, or Python', 'Excellent understanding of software development life cycle and/or agile development environment with emphasis on BI practices.', 'Design, implement, and support a platform providing secured access to large datasets.', 'Interface with tax, finance and accounting customers, gathering requirements and delivering complete BI solutions.', 'Model data and metadata to support ad-hoc and pre-built reporting.', 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.', 'Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.', 'Tune application and query performance using profiling tools and SQL.', 'Analyze and solve problems at their root, stepping back to understand the broader context.', 'Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.', 'Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.', 'Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.', 'Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.', 'Master’s degree in Information Systems or a related field.', 'Experience using business intelligence reporting tools (Tableau, Business Objects, Cognos, etc.)', 'Knowledge of data management fundamentals and data storage principles', 'Knowledge of distributed systems as it pertains to data storage and cloud computing', 'Strong problem-solving skills and ability to prioritize conflicting requirements.', 'Excellent written and verbal communication skills and ability to succinctly summarize key findings.', 'Experience working with AWS Big Data Technologies (EMR, Redshift, S3)', 'Strong organizational and multitasking skills with ability to balance multiple priorities.', 'Experience providing technical leadership and mentor other engineers for the best practices on the data engineering space.', 'An ability to work in a fast-paced environment where continuous innovation is occurring and ambiguity is the norm.']",2020-08-08 12:49:44
"Data Engineer, AIR BI, Amazon AIR",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', 'A desire to work in a collaborative, innovative, and inclusive environment.', 'Degree in Computer Science, Engineering, Mathematics, or a related field from an accredited university and 3+ years industry experience.', 'Must have 1 year of experience as a Data Engineer.', 'Developing and operating large-scale data structures for business intelligence using: ETL/ELT processes; OLAP technologies; data modeling; SQL.', 'Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQL.', 'Experience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark or Hadoop based big data solution.', 'Collect data and perform advanced modeling.', 'Map, document and recommend process improvements.', 'Support business development and help to create efficient designs and solution processes.', 'Decipher efficient utilization of resources.', 'Actively engage with internal partners throughout the organization to meet and exceed customer service levels & transport-related KPI’s.', 'Research and implement cost reduction opportunities.', 'Support the continued development of the business’s data infrastructure.', 'Excellent problem-solving, task prioritization, and follow-up skills', 'Ability to work well in a team environment.', 'Ability to work in an ambiguous environment with little guidance or supervision.', 'Ability to manage through conflict with a positive, flexible and professional attitude.', 'Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.', 'Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.', 'Experience building data products incrementally and integrating and managing datasets from multiple sources.', 'Query performance tuning skills using Unix profiling tools and SQL.', 'Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies.', 'Experience with AWS.', 'Able to work in a diverse team.']",2020-08-08 12:49:44
Data Engineer,Indiana Farmers Insurance,4.3 out of 5,"Indianapolis, IN 46290","['Collaborate with various departments to capture and document data points using technology platforms', 'Develop intuitive analytical tools to provide actionable insight into key business performance metrics', 'Communicate effectively and drive awareness of data and system functionality', 'Build infrastructure for optimal extraction, transformation and loading of data from various sources, using SQL and other ETL technologies.', 'Promote understanding of data-related technical issues and plans for process improvement', 'Optimize data delivery and automate manual processes', 'Bachelor’s degree in computer science or engineering', 'A positive attitude, team mentality, and the interpersonal skills essential for effective communication with cross-disciplined teams', 'Ability to perform root cause analysis on external and internal processes and identify opportunities for improvement and actionable insights', 'Solid understanding of SQL, ETL Technologies and Power BI', 'Excellent analytical skills associated with working on unstructured datasets', 'Ability to build processes that support data transformation, workload management, data structures, dependency, and metadata', 'Excellent written and verbal communication skills, including the ability to convey complex issues to individuals with various technical and non-technical backgrounds', '95% retention of our associates over the last 5 years even with a very competitive employment market.', 'Financially stable as shown by our A (Excellent) rating by AM Best.', 'Truly customer focused, as all mutual insurance companies are and', 'A strong legacy of excellent performance throughout our 143 years in business!', 'Health, dental, vision and life Insurance provided free of charge to associates', 'Opportunities for advancement', 'Work schedules that include remote workdays, as well as compressed schedules', 'An exceptional 401(k) Plan with a 2% match plus an 11% company contribution', 'Above average Paid Time Off days as well as paid holidays', 'A diverse workforce', 'A paid Day of Service to serve others at your favorite charitable organization', 'Matching funds of up to $100 annually for your favorite charitable organization', 'An on-site fitness center, complete with showers', 'Associate recognition awards and an annual Associate Recognition Luncheon', 'Educational Assistance Program', 'Casual attire', 'Free and convenient parking right next to our building, and', 'Smiles and camaraderie with your co-workers is free every day!']",2020-08-08 12:49:44
Data Center Operations Engineer,Facebook,4.2 out of 5,"Henrico County, VA","[""Work within Facebook's ticketing system in support of the health of Facebook's server fleet"", 'First point of contact for break fix technicians', 'Accountable for assisting with projects (new capacity as well as retrofits) and repairs throughout the data center', 'Understand and initial analysis to debug hardware, and Linux OS related issues', 'Demonstrate personal leadership Identifying and helping to create documentation for the global data center knowledge base', 'Assist with process improvements and best practices in data center operations', 'Participate in on-call rotation (once a month on call for a week after hours, first point of contact)', ""Bachelor's degree in a technical field or certification"", 'Knowledge of Linux and server hardware repairs', 'Experience modifying and developing in Python, SQL, and/or shell scripting', 'Working conceptual knowledge of technologies such as HTTP, DNS, RAID, and DHCP']",2020-08-08 12:49:44
Data Engineer,Anne Lewis Strategies,N/A,"Washington, DC","['Building data-intensive applications to extract, transform, and load massive data sets from a variety of internal, external, and public data sources;', 'Assembling large and complex data sets that meet project needs;', 'Developing processes for data mining, data modeling, and data production;', 'Using an array of technological languages and tools to connect systems;', 'Working toward constantly improving data reliability and quality;', 'Collaborating with cross-functional teams to support their data infrastructure needs.', 'Experience with one or more key data analytics tools: (Pandas, PySpark)', 'Experience extracting data from public APIs;', 'Ability to build and optimize data pipelines, architectures, and data sets;', 'Experience managing big data resources through Amazon Web Services or another cloud provider;', 'Experience with SQL;', 'Attention to detail;', 'Intellectual curiosity to innovate on ways to solve data management issues;', 'Passion, energy, and excitement for progressive and philanthropic causes and all things digital.', '1-3 years of professional experience;', 'Experience building data-intensive applications that collect data from diverse sources in the service of creating high-performance algorithms and predictive models;', 'Experience deploying deep-learning models;', 'Experience managing data warehouses and/or data lakes;', 'Experience working with cross-functional teams in a dynamic environment.']",2020-08-08 12:49:44
Data Engineer,Inflection,4 out of 5,Remote,"['Design, develop and maintain scalable data pipelines to integrate into Inflection’s products', 'Contribute to the design of new product offerings based on research, data experiments and data analytics', 'Recommend different ways to constantly improve data reliability and quality', 'Develop standards for testing the end-to-end data pipelines efficiently', 'Support software development life cycle for data integration into the products including requirements analysis, design, development, testing and deployment', 'Bachelor’s Degree in software engineering, Computer Science, Data Science or related field', '2+ years of experience in data engineering', 'Familiarity with building data solutions in a cloud-native environment (AWS preferred)', 'Experience with the design, implementation and debugging of applications in object oriented languages', 'Experience with standard development tools for bug tracking, version control, monitoring and cloud-based deployments', 'Experience with a variety of data technologies and structures that includes relational databases and NoSQL', 'Excellent analytical and problem-solving skills', 'Experience with building and maintaining service oriented architectures is a plus', 'Innovative, high growth products that customers love', 'Competitive compensation including equity options', 'Comprehensive insurance benefits package including medical, dental, vision, and life insurance', '401K', 'Track record of promoting and hiring internally', 'Startup environment with big opportunities for impact', 'High energy team with mix of experienced entrepreneurs, talented engineers, and successful Silicon Valley/Prairie veterans', 'Learning and Development funds to enhance and learn new skills', 'Diversity and Inclusion program', '3 days off per year to volunteer', 'Casual Dress environment']",2020-08-08 12:49:44
Data Engineer,HealthVerity,N/A,"Philadelphia, PA 19103","[""Work with internal stakeholders to load data into HealthVerity's data warehouse"", 'Troubleshoot and resolve issues relating to data integrity', 'Help establish procedures and best practices for transforming and storing data', 'Lead requirements gathering around data pipeline automation improvements', 'Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin', 'Leverage distributed computing and serverless architecture such as AWS EMR & AWS Lambda, to develop pipelines for transforming data', 'Enjoy the peace that comes with working in a mature software development environment', 'Marvel at the speed with which your creation makes it into production', 'Research and implement new technologies with a team of developers to execute strategies and implement solutions', 'Produce peer reviewed quality software', 'Solve complex problems related to the real-time discovery of large data', 'Experienced in writing scalable applications on distributed architectures', 'Data driven, testing and measuring as much as you can', 'Eager to both review peer code and have your code reviewed', 'Comfortable on the command line and consider it an essential tool', 'Confident in SQL, you know it, write smart queries, it’s no big deal', '5+ years of work experience', '3+ years of experience with Python', '3+ years of experience with PySpark and Spark-SQL (writing, testing, debugging spark routines)', '1+ years of experience with AWS EMR, AWS S3 service. Comfortable using AWS CLI and boto3', 'Comfortable working in remote environments', 'Comfortable using *nix command line (shell scripting, AWK, SED)', 'Experience with MySQL and Postgres', 'Experience with Apache Airflow', 'Experience with Apache Zeppelin', 'Experience with healthcare data', 'Empowering clients with highly rewarding data discovery and licensing tools', 'Ingesting and managing billions of healthcare records from a wide variety of partners', 'Standardizing on common data models across data types', 'Orchestrating an industry-leading HIPAA privacy layer', 'Innovating our proprietary de-identification and data science algorithms', 'Building a culture that supports rapid iteration and new possibilities']",2020-08-08 12:49:44
Data Engineer Level I,"Edutek, Ltd.",N/A,"White Plains, NY 10606","['Prepare source data for computer entry by compiling and sorting information; establishing entry priorities.', 'Processes customer data and account source documents by reviewing data for deficiencies; resolving discrepancies by using standard procedures or returning incomplete documents to the team leader for resolution.', 'Maintains data entry requirements by following data program techniques and procedures.', 'Verifies entered customer and account data by reviewing, correcting, deleting, or reentering data; combining data from both systems when account information is incomplete; purging files to eliminate duplication of data.', 'Tests customer and account system changes and upgrades by inputting new data; reviewing output.', 'Secures information by completing data base backups.', 'Maintains operations by following policies and procedures; reporting needed changes.', 'Maintains customer confidence and protects operations by keeping information confidential.', 'Ability to perform SQL queries and light scripting to provide basic data analysis.', 'Previous experience preferred.', 'Bachelor of Science Degree preferred but not required.', 'Note: Clients require fingerprinting and background checks. Candidates will have to comply.']",2020-08-08 12:49:44
Business Intelligence Engineer Data Engineer,Themesoft Inc,4.1 out of 5,"Media, PA","['Convert business requirements into Reporting Data layer design for Business Intelligence tools.', 'Provide technical requirements to data engineering team for conversion of business requirements to reporting data layer.', 'Develop reporting data layer for business intelligence tools like MicroStrategy and Tableau using big data platform databases / querying (like Impala, Hive, Kudu) as well as modern cloud data warehouse like Snowflake.', 'Perform data analysis, data modeling and data design tasks / transformation on complicated datasets with potentially complex data integration scenarios related to reporting.', 'Build data structures / database objects and data blending technologies to support data harmonization and provide data to MicroStrategy / Tableau and self-service reporting templates.', '8+ years database, data integration experience', '3+ years’ experience with Hadoop, SQL and Big Data solutions', '5+ years’ experience in designing and implementing the data structures (conceptual, logical, physical & dimensional models) for reporting tools like MicroStrategy, Tableau or any reporting tools', 'Supporting data enablement for enterprise Business Intelligence solutions using one or more of the following EDW platforms: Big Data Platforms / HANA / BW / Snowflake', 'Development experience in using Big Data solutions using open source technologies within the Hadoop ecosystem such as: Impala, Hive, Spark, Pig, etc.', 'Strong knowledge of scripting to support data requirements', 'Strong knowledge of reporting related data security principles', 'Proven track record working with complex, interrelated systems and bringing that data together on Big Data platforms.', 'Be knowledgeable in visualization tools data requirements for Microstrategy / Tableau', 'Heavy, In-Depth Database Knowledge – SQL and NoSQL.', 'Temporarily due to COVID-19']",2020-08-08 12:49:44
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 12:49:44
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:49:44
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:49:44
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:49:44
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:49:44
Sr. DDI Migration Engineer,"Efficient IP, Inc.",N/A,"Philadelphia, PA","['Lead technical design meetings with customers', 'Configure appliances', 'Migrate data from existing DDI solutions to Efficient IP [i.e. from Microsoft, ISC, BlueCat, Infoblox, etc]', 'Scripting and data manipulation for migration', 'Assist with support during escalation and level 3/4.', 'You’ll always be technically challenged working with customers in every business sector who are looking to consolidate their DDI infrastructure', 'As part of the onboarding, Efficient IP will provide hands-on training and you’ll become Certified in our SOLIDServer solution', 'You’ll serve as the DDI subject matter expert and be instrumental in deploying Efficient IP', 'Opportunity for growth', 'Strong technical experience with one or more of the following:', 'DNS, working and protocol [ISC, Microsoft]', 'DHCP, working and protocol.', 'TCP/IP, both IPv4 and IPv6.', 'Bonus points:', 'Familiar with scripting to automate tasks (Perl, Bash, PHP, etc).', 'Data migration experience', 'DDI vendor experience in a Professional Services capacity with Infoblox, BlueCat or similar', 'Must be inquisitive, have the technical aptitude, curiosity and passion to become an SME in the DDI industry', 'Must have worked in a customer-facing role', 'Strong communication, interpersonal and presentation skills', 'Strong technical problem-solving ability and troubleshooting skills', 'Must have strong attention to detail, be organized, self-motivated and able to handle multiple projects', 'Bachelor’s Degree preferred', 'Must be able to work in the US without any type of sponsorship', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Vision Insurance', 'Monday to Friday', 'DNS, DHCP, IPAM: 5 years (Preferred)', 'Philadelphia, PA (Preferred)', 'United States (Required)', '25% (Required)', 'Do you have any experience with data migrations?', 'Bonuses', 'Fully Remote', 'www.efficientip.com', 'Yes']",2020-08-08 12:49:44
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:49:44
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:49:44
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:49:44
Data Engineer Internship - Summer 2021 (US),Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Currently enrolled in or will receive a Bachelor’s or Master’s Degree in math/statistics/engineering or other equivalent quantitative discipline with a conferral date after September 2021', 'Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)', 'Experience with one or more scripting language (e.g., Python, KornShell)', 'Experience with data mining, data warehouse solutions, and ETL', 'Design, implement, and automate deployment of our distributed system for collecting and processing log events from multiple sources', 'Design data schema and operate internal data warehouses and SQL/NoSQL database systems', 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions', 'Monitor and troubleshoot operational or data issues in the data pipelines', 'Drive architectural plans and implementation for future data storage, reporting, and analytic solutions', 'Work collaboratively with Business Analysts, Data Scientists, and other internal partners to identify opportunities/problems', 'Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem', 'Master’s or advance technical degree', 'Proficient in at least one or more query language, schema definition language, and scripting language', 'Knowledge of writing and optimizing SQL queries in a business environment with large-scale, complex datasets', 'Experience with data visualization software (e.g., AWS QuickSight or Tableau) or open-source project', 'Experience with big data processing technology (e.g., Hadoop or ApacheSpark), data warehouse technical architecture, infrastructure components, ETL, and reporting/analytic tools and environments', 'Ability to deal with ambiguity in a fast-paced environment']",2020-08-08 12:50:33
Data Engineer,Chef Software,N/A,United States,"['Take ownership for designing, developing and maintaining scalable data pipelines and data models.', 'Lead the data engineering work of the platform architecture team, helping to define and guide the work of others.', 'Provide technical expertise and leadership as a member of the data engineering team.', 'Design, construct, install, test and maintain data management systems.', 'Develop data ingestion and integrations processes.', 'Ensure that all systems meet the business/company requirements as well as industry best practices.', 'Integrate up-and-coming data management and software engineering technologies into existing data structures.', 'Develop set processes for data mining, data modeling, data ingestion, and data production.', 'Contribute to the design of new product offerings based on data analytics.', 'Create custom software components and analytics applications.', 'Research new uses for existing data; design experiments and analysis to answer key business questions.', 'Employ an array of technologies, languages and tools to connect systems together.', 'Collaborate with members of your team (eg, architects and engineers) on project goals.', 'Recommend different ways to constantly improve data reliability and quality.', 'You have a minimum of a Bachelors’ degree in Computer Science, Data Science, or related field, plus 5 years of experience (or equivalent combination of education and experience). Masters degree in a relevant field is advantageous.', 'You have demonstrable software development skills in at least one language such as Rust, Go, C#, C++, Ruby or Java.', 'You have expertise in architecting, designing and implementing data solutions in a cloud-native environment (AWS preferred).', 'You have experience with a variety of data technologies and structures that includes relational databases, NoSQL and graph.', 'You’re well-versed in working with big data.', 'You have excellent analytical and problem-solving skills.', 'You like to dive in, learn new things, and want to build awesome products.', 'You have experience building and operating high-performance data systems.', 'Working experience with Containers and Container orchestration tools such as Docker and Kubernetes is a huge plus.', 'You’ve had experience working with APIs (graph, specifically).', 'You enjoy collaborating closely with product management and internal engineering teams to understand their complex issues, solve their problems and elicit frequent feedback on the solutions you provide', 'You believe quality is part of the development process and not an afterthought']",2020-08-08 12:50:33
Data Engineer,"YinzCam, Inc.",4 out of 5,"Pittsburgh, PA 15206","['Thinks nothing is impossible', 'Is a tinkerer and implementor of big-data systems', 'Has a knack for data visualization to derive insights', 'Is equally comfortable with database systems and machine-learning algorithms', 'Running analyses on terabytes of data that arise from digital assets', 'Applying machine-learning algorithms on data sets in order to cluster and segment them', 'Providing insights from the data, to understand user behavior, predict user behavior, identify anomalies, and identify patterns', 'Building, maintaining, and refining data dashboards', 'Driving new product development based on insights from the data', '2 years+ of machine-learning experience with giant data-sets', '2 years+ of experience in data visualization techniques and best practices', '2 years+ of experience in working with Hadoop, Hive, Spark, and other big-data platforms', '2 years+ of experience with SQL, relational databases, NoSQL databases, including Postgres and Cassandra', '2 years+ of experience with Google Analytics, Firebase', '2 years+ of experience with AWS cloud services, such as EC2, EMR, RDS, Redshift', '2 years+ of experience in Java/C++/Python programming', 'Expert programmer and tinkerer, comfortable around operating systems, cloud computing, network protocols', 'Willingness to work in a high energy, fast-paced environment', 'Strong desire to learn and grow career', 'Degree in Computer Science/Engineering, with a heavy focus on machine-learning, data science, data engineering.', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Relocation Assistance', 'Vision Insurance', 'Monday to Friday', 'Weekends', 'machine-learning: 2 years (Required)', 'SQL and relational database: 2 years (Required)', 'Tableau: 2 years (Required)', 'Hadoop/Hive: 2 years (Preferred)', 'Java programming: 2 years (Required)', ""Bachelor's (Required)"", 'Pittsburgh, PA 15206 (Required)', 'United States (Required)', 'What is the largest data-set you have analyzed? And what techniques did you use to analyze it?', 'One location', 'www.yinzcam.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 12:50:33
"Software Engineer, Data",Brex,N/A,"New York, NY","['Competitive compensation', 'Health, dental, and vision insurance', 'Basic life insurance, short-term disability, and long-term disability coverage', 'Generous vacation time', 'Parental leave', 'Daily lunches & snacks prepared by our food team', 'One time stipend to create your dream home office', 'Generous monthly stipend to make working from home comfortable', '401(k) (US only)', 'One Medical corporate membership (US only)', 'Build and maintain robust, observable data pipelines.', 'Build and own our data lake and data warehouse solutions.', 'Design and build user-friendly data platforms upon which data scientists can easily test and deploy models to production.', 'Scope, design and build tools for internal users to increase their efficiency ten-fold.', 'Design and implement customer facing data services and products from end to end.', 'Work closely with analysts and data scientists to deeply understand business problems and be a guiding voice in architecting the solutions.', 'Maintain a strong data driven culture within the company by interacting with diverse internal functions.', 'Experience with data pipelines and data warehousing, such as Big Query and Snowflake.', 'Low tolerance for system failures and a desire to build easily maintainable pipelines and services.', 'A level of independence that allows end-to-end ownership of the products and tools you build.', 'Keen product sense and customer empathy that leads to user-friendly products.', 'Desire to improve the engineering bar for the whole team.', 'Ability to devise creative workarounds to difficult project roadblocks.', 'Great sense of ownership and the desire to relentlessly chase down issues in systems you own.', 'Thriving in a collaborative environment, filled with a diverse group of people with different expertise and backgrounds (we currently have over 15 nationalities represented, with more than ½ the company working in a country different from the one they grew up in).', 'We work in an environment where it matters to make the right design decisions the first time, and as a result, take on less technical debt than other companies.', 'Product is a highly collaborative initiative across multiple teams. Data engineers are expected to understand the business and have input towards our long term vision.', 'We believe in two equal track career growths between senior individual contributors and managers. We want people to contribute where they feel most impactful.', 'We believe in small, accountable and autonomous teams of amazing people, eager to learn, teach and constantly improve our way of working.', 'People have a strong sense of ownership and accountability for what they’re building. What we build today will be the foundation for dozens of other systems in the future.', 'We are very frank on discussing technical matters. If one disagrees with how things are being done, we encourage them to speak up and help us get to the truth faster.']",2020-08-08 12:50:33
Data Engineer,Alldus,N/A,"New York, NY","['Work in a small team setting partnering with engineers and scientists to provide the infrastructure needed to support our products and product features', 'Build pipelines, frameworks, scripts, and libraries that enable and empower multiple development teams to build, deploy, and run a variety of applications in a continuous fashion', 'The role is expected to demonstrate a strong sense of urgency with regards to solving urgent issues', 'Keep up to date on emerging technology solutions, for continuous improvements in development operations', 'MS preferred in a quantitative science (e.g. data engineering, natural language processing, mathematics, computer science) is preferred.', '3+ years of industry experience working on data-related initiatives within healthcare.', 'Proficiency in manipulating data with Python', 'Strong SQL skills', 'Experience in EHR, EMR, and ETL Pipelining.', 'Highly communicative with collaborators and manager.']",2020-08-08 12:50:33
Data Engineer (Remote),The New York Times,4 out of 5,"New York, NY","['Python and Apache Airflow for ETL pipelines', 'PostgreSQL database and S3 data lake in AWS RDS', 'BigQuery analytics data', 'Looker BI tool', 'Help drive the optimization, testing, and tooling to improve data quality.', 'Write, debug, and test complex ETL processes for new or existing data pipelines.', 'Write and maintain database design and architecture documentation.', ""Maintain an understanding of Wirecutter's data platforms as well as the data platforms of our parent company, the New York Times"", 'Uncover dependencies and leverage features and tools from both the Wirecutter and New York Times', 'Collaborate with your squad leaders and stakeholders on the scoping, planning, prioritization, successful execution, and rollout of complex technical projects to provide the foundation for generating insights and address additional data for reporting needs.', 'Create new data models that are appropriately scalable, standardized, performant, and reliable.', 'Evolve our current data models from production services into readily consumable formats for all downstream data consumption.', 'Support and maintain the integrity and security of our internal data.', 'Provide insight into changing database storage and utilization requirements.', 'Recommend solutions that best align with our product and business goals, as well as the quality, reliability, and secure storage and replication of our data.', 'Improve our development workflow and infrastructure.', 'Share knowledge and problem solving with other members of your squad and the engineering team.', 'Contribute to engineering initiatives and culture as a member of Wirecutter’s engineering team.', 'You have 3+ years in software or data engineering and scaling large data sets.', 'You can design & optimize queries, data sets, and data pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.', 'You understand the challenges of reliable data replication, optimizing for a data warehouse, and maintaining the integrity of a data lake.', 'You have experience reliably integrating and handling data from multiple APIs.', 'You have experience building ETLs at scale on any major cloud provider (AWS, GCP: Cloud Composer, Kubernetes, etc.)', 'You are thoughtful, clear, and persuasive in writing and in person.', 'You have strong problem-solving skills and critical thinking abilities.', 'You have experience listening to analysts and other business users, and can translate their needs into actionable tasks.', 'You are excited to play a pivotal role in Wirecutter’s mission, innovation, and growth.', 'You are passionate and enthusiastic about what you do.', 'You have experience with version control, shell scripting, the Unix filesystem, and automating deployments.', 'Ideally, you have production experience with Python and Apache Airflow.', 'Ideally, you have experience with BI tools and managing data sets for BI tools.', 'Ideally, you have a basic understanding of statistics and sampling.', 'Ideally, you have experience working with Google Tag Manager and analytics data sets', 'Ideally, you’ve worked as a member of a distributed team.']",2020-08-08 12:50:33
Software Engineer - Data Engineering,realtor.com,3.5 out of 5,"Morgantown, WV","['Work collaboratively in teams composed of Product Managers, Designers, and Engineers', 'Implement new application features that delight our users', 'Develop reusable components and frameworks for ingestion, cleansing, and data quality', 'Develop and operationalize data pipelines, backend services and distributed systems using advanced data architectures deployed on Amazon Web Services', 'Optimize our developer toolchain to support instant provisioning of new services and infrastructure, fully automate deployment, and minimize development friction.', 'Work in a product development process that is primarily Agile/Scrum', 'A driven software engineer that is motivated to build great products and a great codebase in a fast-paced environment', '2+ years experience building data pipelines and platforms', 'Proficient in Python, experience with other object oriented programming language (e.g. Ruby, Go, Java, Node.js, Dart) and the eagerness to learn more', 'Exposure to build, test and deployment automation technologies', 'Familiarity with cloud technologies such as AWS ECS, S3, RDS, EMR, Redshift, Glue, Athena', 'Familiarity with technologies in the data engineering ecosystem tooling including EMR/Hadoop, Spark/PySpark, Kafka/Kinesis/Flume, and Airflow/luigi/AWS Data Pipeline a big plus.', 'Exposure to monitoring for SLAs, alerting, and remediating service disruptions', 'Understanding of computer science fundamentals, schema design, and best practices', ""Bachelor's degree in Computer Science/Engineering or related field, Master's degree a plus""]",2020-08-08 12:50:33
Data Engineer,Mondo,N/A,"Malvern, PA 19355",[],2020-08-08 12:50:33
Data Engineer,Root Insurance Company,3.6 out of 5,"Columbus, OH 43215","['Work with product, actuarial, and engineering teams to understand and scope new features for our environment', 'Design & develop data structures that support downstream analysis', 'Design & develop sustainable, fast ETL processes using SQL', 'Provide peer review for teammates on their change requests', 'Create processes to identify, prioritize, and illustrate data quality issues and remediation efforts.', 'Design solutions which help us to reach our overall goals', 'Help to ensure data quality and meet data delivery SLA’s', 'At least 3 years of experience in the insurance industry is strongly preferred', 'Experience using technologies listed above is preferred', 'Solid SQL skills. Ability to transform data without the use of an ETL tool.', 'Experience using version control tools like GIT', 'Familiarity with programming languages like Ruby or Python', 'Familiarity with DevOps & Agile processes']",2020-08-08 12:50:33
Data Engineer - Risk Intelligence,Microsoft,4.2 out of 5,"Redmond, WA","['Design, develop, and maintain data pipelines for real-time/batch analysis, reporting, optimization, data collection, and related functions.', 'Develop and implement solutions for data quality validation and continuous improvement.', 'Partner with PMs, engineers and business stakeholders to understand business and technical requirements, plan and execute projects, and communicate status, risks and issues.', 'Perform root cause analysis of system and data issues and develop solutions as required.', '3+ years relevant industry experience designing data warehouse models and ETL pipelines that are secure, testable, and modular.', 'Proficient in SQL queries and database architecture.', 'Proficient in Power BI', 'Proven track record of collaborative development in an agile team environment.', 'Experience with Azure Analytics stack, such as, Azure Data Lake, Stream Analytics, Azure Data Factory.', 'Experience working with a big data platform such as Azure Data Lake, Microsoft Cosmos, Hadoop, Spark.', 'Development expertise in at least one programming language such as C#, R, Python.', 'Ability to communicate well with users, partner teams and management to collect requirements, explain data presentation decisions and deliver against the data engineering strategy', 'BS or MS degree in Computer Science or a related technical field']",2020-08-08 12:50:33
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 12:50:33
Windows Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Five years or more of experience managing Active Directory for an enterprise.', 'Must be a Microsoft 365 Certified Expert or equivalent.', 'Knowledge of Solarwinds or equivalent network management tools is required.', 'Security+ certification or any DoD-accepted equivalent is required.', 'Experience with DoD cyber security is highly desirable.', 'U.S. citizenship is a requirement of our contract with the Navy', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 12:50:33
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:50:33
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:50:33
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:50:33
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:50:33
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:50:33
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:50:33
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:50:33
"Engineer, Trainee",Barry Callebaut,3.5 out of 5,"Eddystone, PA 19022","['Support the local factory management teams in achieving their overall goals related to safety, quality, costs, project execution, process optimization, yield improvements, and overall efficiency improvements.', 'Liaising with other process, corporate engineers, and plant engineers working on associated plants and projects.', 'Working closely with other specialists, including: personnel responsible for the quality control of raw materials, intermediates and finished products; engineers responsible for plant maintenance; commercial colleagues on product specifications and production schedules; and the production operatives.', 'Preparing reports, flow diagrams and charts; creating and updating operating procedures.', 'Making observations and taking measurements directly as well as collecting and interpreting data', 'This entry level position will support our pipeline of future factory and engineering managers as we continue to expand our operations.', ""Bachelor's Degree in Mechanical, Electrical, Automation, or Chemical Engineering"", '0 – 3 years technical experience in a manufacturing environment, preferably food processing', 'Experience with food processing equipment and the effect of processing conditions on food desired, but not required', 'Experience with HACCP, GMP and OSHA regulations a plus', 'Microsoft Access experience desired, not required', 'A desire to be hands on and involved in factory management', 'Strong leadership and supervisory skills', 'Ability to connect the dots and link financial benefits into operational performance', 'Possess strong analytical thinking – systematically identifies and understands problems', 'Possess strong initiative – take action before being requested', 'Ability to climb in overhead structures, to work beneath machines, and in close quarters performing analysis, repair, or installation.', 'Ability to freely move around the entire plant and office areas.', 'Should expect to be on the production floor to learn equipment processes']",2020-08-08 12:51:21
Associate Data Engineer,Pack Health,4 out of 5,"Birmingham, AL 35203","['Build and maintain data pipelines that feed reporting databases.', 'Create and maintain modeling layer for business intelligence reporting.', 'Work within an agile scrum team, contributing to an atmosphere of continuous improvement', 'Work under general direction of senior engineers with the ability to act independently as needed', 'Collaborate and communicate effectively with team members and other stakeholders throughout the organization', 'Learn the technologies, languages, and practices used by the team and project assigned', 'Trouble shoot and resolve issues in existing systems.', 'Bachelor’s Degree in Computer Science, a related field or equivalent work experience', 'Must have a solid understanding of relational database principles. Experience with PostgreSQL, Oracle, SQLServer a plus.', 'Must be able to understand and translate analytics questions into queries.', 'Must have experience with or strong interest in SQL and curiosity about data and large data sets.', 'Programming experience with ETL and stored procedures.', 'Familiarity with Business Intelligence tools such as Looker, Tableau.', 'Strong problem-solving skills', 'Outstanding communications and interpersonal skills', 'Strong organizational skills and ability to multi-task', 'Ability to track software issues to successful resolution', 'Ability to work in a collaborative fast paced environment', 'Ability to learn new development language quickly and apply that knowledge effectively', 'Immigration or work visa sponsorship will not be provided']",2020-08-08 12:51:21
Data Engineer (GS 11 Equivalent),"Credence Management Solutions, LLC",4.1 out of 5,"Washington, DC","['Production of sophisticated data analyses, data visualizations and maps to enhance information, communications, and demonstration of USAID’s technical expertise and programming impact through data-driven evidence;', 'Development and consistent use of data research protocols, reporting practices, organizational templates, enablement and adoption of analytics programs; and', 'Advanced technical and executive data literacy programs for USAID and implementing partner staff.', 'Build high-performance data workflows and algorithms using Tableau Prep, Alteryx, Python or R.', 'Research opportunities for data acquisition and new uses for existing data.', 'Develop data set processes for data modeling, mining and production.', 'Integrate new data management technologies and software engineering tools into existing structures and work processes.', 'Recommend ways to improve data reliability, efficiency, and quality.', 'Manipulating data from a number of sources, both from USAID and third parties, using advanced data management and transformation techniques.', 'Processing, cleaning, and verifying data integrity before analysis and prepare data for predictive and prescriptive modeling.', 'Collaborate with GH data scientists, data visualization experts, and IT team members on data analytics projects.', 'Organize or support efforts to build USAID’s in-house capacity to improve global health data management, analytics and visualization.', 'Participate in USAID and industry data science working groups and communities of practice and work collaboratively with USAID’s global health subject matter experts, engaging stakeholders in the development and prioritization of data analyses.', 'Participate in professional continuing education, skills training, and professional meetings to enhance relevant technical skills and career development.', 'Complete and execute and Individual Learning and Training Plan and Annual Work Plan.', 'Minimum of Master’s degree and 3 years of experience or Bachelor’s degree and 5 years of experience in computer science, software/computer engineering, applied mathematics, statistics or equivalent.', 'At least 3 years of professional experience with two or more technical disciplines such as (data science, research, ETL, UX/UE support and design, database management, etc.); job duties/responsibilities generally related to PD requirements.', 'Knowledge and experience of the following is required: data manipulation, databases, data structures, data management, best data engineering practices', 'Strong applied statistics skills preferred.', 'Extensive experience with common data science toolkits (R, Python, Tableau Prep, Alteryx).', 'Strong attention to detail and accuracy.', 'Intellectual curiosity to find new and unusual ways of how to solve data management issues.', 'Strong written and communication skills.', 'Ability to travel internationally up to 15% of time.', 'US citizenship with the ability to obtain and maintain secret security clearance required.']",2020-08-08 12:51:21
"Data Engineer, AIR BI, Amazon AIR",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['A desire to work in a collaborative, innovative, and inclusive environment.', 'Degree in Computer Science, Engineering, Mathematics, or a related field from an accredited university and 3+ years industry experience.', 'Must have 1 year of experience as a Data Engineer.', 'Developing and operating large-scale data structures for business intelligence using: ETL/ELT processes; OLAP technologies; data modeling; SQL.', 'Experience with at least one relational database technology such as Redshift, Oracle, MySQL or MS SQL.', 'Experience with at least one massively parallel processing data technology such as Redshift, Teradata, Netezza, Spark or Hadoop based big data solution.', 'Collect data and perform advanced modeling.', 'Map, document and recommend process improvements.', 'Support business development and help to create efficient designs and solution processes.', 'Decipher efficient utilization of resources.', 'Actively engage with internal partners throughout the organization to meet and exceed customer service levels & transport-related KPI’s.', 'Research and implement cost reduction opportunities.', 'Support the continued development of the business’s data infrastructure.', 'Excellent problem-solving, task prioritization, and follow-up skills', 'Ability to work well in a team environment.', 'Ability to work in an ambiguous environment with little guidance or supervision.', 'Ability to manage through conflict with a positive, flexible and professional attitude.', 'Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.', 'Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.', 'Experience building data products incrementally and integrating and managing datasets from multiple sources.', 'Query performance tuning skills using Unix profiling tools and SQL.', 'Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies.', 'Experience with AWS.', 'Able to work in a diverse team.']",2020-08-08 12:51:21
Data Engineer (Analyst),Hill Associates,N/A,"Washington, DC","['Serve as a subject matter expert to solve complex cybersecurity data requirements.', 'Utilize modern software tools and data management methodologies.', 'Apply your in-depth expertise in data engineering and data science to support Federal Information Security Management Act (FISMA) Level 4 (Managed and Measurable) IT controls for specified systems.', 'Define raw input requirements to support data models as well as final outputs required to ensure Department personnel are able to assess the security status of computing systems.', 'Develop data requirements, data descriptions, data formatting and all other aspects of data management required to ensure that security controls can be measured and managed.', 'Develop a dashboard or other automated data presentation designs.', 'Establish efficient and repeatable processes that capture system data, organize it, synthesize it, and structure it for reporting (visualization).', 'Develop a data catalog to support OCIO cyber security reporting processes. The data catalog might include data items such as: data item source, automated means of collection, data item format, and data item use case.', 'Provide data analysis to support response to security incidents that may occur with IT systems.', 'Maintain familiarity with the Treasury IT systems operated by the OCIO, as well as systems operated by other groups with the Treasury.', 'Provide recurring reports (weekly, monthly) on program status.', 'Ensure program performance meets Government contract requirements.', 'Work and thrive in a fast-paced team environment.', 'Interact with leadership and staff across the Agency and its Bureaus.', 'Minimum seven years’ experience in data analytics, development of data descriptions and metadata', 'Experience in data collection, formatting, presentation, and preservation.', 'Strong experience in the utilization of descriptions and metadata to allow for the ingest of data across a variety of applications and users', 'Experience in presentation of data requirements, solutions, and outputs to system owners and executive leadership', 'Ability to capture high level technical information in a clear, concise manner.', 'Strong passion to learn and desire to understand all aspects of Treasury computing infrastructure.', 'Strong communication skills to understand and communicate data scope, breadth and depth.', 'Ability to think creatively and adapt creative thinking to what works for the organization.', 'Ability to capture high level technical information in a clear, concise manner.', 'U.S. Citizen.', 'Ability to obtain and maintain public trust clearance level. Must have a favorably adjudicated T3 background investigation and maintain it for the life of the contract.', 'Bachelor’s degree in data science, data engineering, statistics, or related data-focused field of study', 'Exceptional organizational and time-management skills.', 'Experience working with senior level management and clients.', 'Experience managing Government projects desired.', 'Strong written, oral, and presentation skills.']",2020-08-08 12:51:21
Data Engineer,Greater New York Mutual Insurance Company,3.1 out of 5,"New York, NY 10016","['Develop, construct, test, and maintain architectures, such as databases and analytic environments and platform required for structured, semi-structured and unstructured data', 'Design and develop data pipelines that deliver accurate, consistent, and traceable datasets for data science projects', 'Support regular and ad-hoc data needs for data scientists', 'Provide recommendations and implement ways to improve data reliability, efficiency, and quality', 'Bachelor’s or Master’s degree obtained from an accredited institution preferably in Computer Science, Computer Engineering, and Software Engineering, Data Science, or a related field', '3-5 years of professional experience in data science or related field', 'Experience in database deployment and management and proficient in SQL', 'Experience in data warehousing and ETL (Extract, Transform, and Load)', 'Proficient in R, Python, VBA, Excel and Word', 'Excellent oral and written communication skills']",2020-08-08 12:51:21
Data Engineer,Anne Lewis Strategies,N/A,"Washington, DC","['Building data-intensive applications to extract, transform, and load massive data sets from a variety of internal, external, and public data sources;', 'Assembling large and complex data sets that meet project needs;', 'Developing processes for data mining, data modeling, and data production;', 'Using an array of technological languages and tools to connect systems;', 'Working toward constantly improving data reliability and quality;', 'Collaborating with cross-functional teams to support their data infrastructure needs.', 'Experience with one or more key data analytics tools: (Pandas, PySpark)', 'Experience extracting data from public APIs;', 'Ability to build and optimize data pipelines, architectures, and data sets;', 'Experience managing big data resources through Amazon Web Services or another cloud provider;', 'Experience with SQL;', 'Attention to detail;', 'Intellectual curiosity to innovate on ways to solve data management issues;', 'Passion, energy, and excitement for progressive and philanthropic causes and all things digital.', '1-3 years of professional experience;', 'Experience building data-intensive applications that collect data from diverse sources in the service of creating high-performance algorithms and predictive models;', 'Experience deploying deep-learning models;', 'Experience managing data warehouses and/or data lakes;', 'Experience working with cross-functional teams in a dynamic environment.']",2020-08-08 12:51:21
Data Warehouse Engineer,"Commoneo, LLC",N/A,"Washington, DC 20005","['Health Insurance', '8 Hour Shift', 'Weekends', 'Data Warehouse: 4 years (Required)', ""Master's (Required)"", 'Varies', 'No: Not providing sponsorship for this job', 'No']",2020-08-08 12:51:21
Data & API Engineer – Dimensions,Digital Science,N/A,Remote,"['Design, build and launch new API features based on our Dimensions Search Language (DSL)', 'Create scalable infrastructure solutions backing the API functionalities, in particular by leveraging Google Big Query functionalities.', 'Contribute to answering technical questions from customers, including the creation of data aggregations, data visualizations or other statistical analysis of large datasets.', 'Work with engineers, product managers and product analysts to understand data needs.', '2+ years full-time development experience with Python', 'Experience designing and implementing (REST) APIs', 'Experience with cloud-based architectures, AWS and Knative, Docker containers', 'Experience with or interest in building domain specific languages (DSL), for example using Antlr', 'Familiarity with ETL, data processing and/or data mining techniques', 'Python, Jupyter notebooks and data analytics libraries e.g. Pandas', 'SQL and noSQL search technologies, especially SOLR and Google Big Query', 'Web technologies, scripting languages and data visualization tools.', 'Proactive problem solver and data analyst, capable of prototyping solutions as well as presenting results to non-technical audiences', 'Capable of working autonomously and responsibly on projects and complete them effectively', 'Fluent in English, good communication and collaboration skills in particular in the context of a geographically distributed team', 'BA/BS degree or equivalent practical experience']",2020-08-08 12:51:21
Data Engineer - Risk Intelligence,Microsoft,4.2 out of 5,"Redmond, WA","['Design, develop, and maintain data pipelines for real-time/batch analysis, reporting, optimization, data collection, and related functions.', 'Develop and implement solutions for data quality validation and continuous improvement.', 'Partner with PMs, engineers and business stakeholders to understand business and technical requirements, plan and execute projects, and communicate status, risks and issues.', 'Perform root cause analysis of system and data issues and develop solutions as required.', '3+ years relevant industry experience designing data warehouse models and ETL pipelines that are secure, testable, and modular.', 'Proficient in SQL queries and database architecture.', 'Proficient in Power BI', 'Proven track record of collaborative development in an agile team environment.', 'Experience with Azure Analytics stack, such as, Azure Data Lake, Stream Analytics, Azure Data Factory.', 'Experience working with a big data platform such as Azure Data Lake, Microsoft Cosmos, Hadoop, Spark.', 'Development expertise in at least one programming language such as C#, R, Python.', 'Ability to communicate well with users, partner teams and management to collect requirements, explain data presentation decisions and deliver against the data engineering strategy', 'BS or MS degree in Computer Science or a related technical field']",2020-08-08 12:51:21
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 12:51:21
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:51:21
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:51:21
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:51:21
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 12:51:21
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:51:21
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:51:21
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:51:21
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:51:21
Data Engineer,GardenStar Group,N/A,"Short Hills, NJ","['Identify valuable data sources and automate collection processes', 'Undertake preprocessing of structured and unstructured data', 'Present information using data visualization techniques', 'A Bachelor’s degree in Computer Science, Engineering, or relevant field', 'Proficient in SQL and Python', 'Strong math skills (e.g. statistics, algebra)', 'Understanding of machine-learning', 'Strong work ethic and great communication and collaboration skills', 'Analytical mind and business acumen, and problem-solving aptitude', 'Ability to multitask with strict time constraints, budgets and business goals', 'Experience as a Data Scientist or Data Analyst', 'Experience in data mining', 'Familiarity with Scala, Java or C++', 'Excellent communication and presentation skills', '2020 Fall Internship Program will commence in late August', 'Less than 10 hours/week on-site required', 'Potential Full-time position available at the end of the internship', 'The application deadline is Aug 15th, 2020', 'Monday to Friday', ""Bachelor's (Required)"", 'Short Hills, NJ (Required)', 'United States (Required)', 'https://www.gardenstargroup.com', 'Temporarily due to COVID-19']",2020-08-08 12:52:09
Data Engineer,Virginia Tech,4.3 out of 5,"Blacksburg, VA","['Bachelor’s degree in Business Information Technology, Computer Science, Information Systems or related field or equivalent training and/or experience', 'Advanced experience with (ETL) technologies such as Talend', 'Extensive experience in relational databases, like Oracle, Postgres and Redshift including advanced SQL writing ability', 'Experience with cloud technologies such as AWS', 'Demonstrates skills in working effectively in a team environment. Strong communication, organization and interpersonal skills', 'Demonstrated experience in full system lifecycle development including requirements gathering, systems analysis and development of data services, testing and implementation of large enterprise systems', 'Extensive experience in data warehouse concepts and dynamic object architecture. Strong understanding in concepts and the features to maintain a well-structured and efficient database', 'Experience in cloud services. Ideally AWS services such as EMR, Glue, Athena, RDS and Redshift', 'Experience in an object-oriented programming language like Python or Java.', 'Experience with Business Intelligence tools such as MicroStrategy, Tableau or SAS', 'Experience in an enterprise environment with DevOps best practices and technologies such as Docker, Version Control (Git), and Jenkins', 'Experience with data lakes in a Hadoop or AWS environment', 'Exposure to web services and APIs']",2020-08-08 12:52:09
Sales Engineer,iPipeline,3.3 out of 5,"Exton, PA 19341","['Position Summary:An iPipeline Sales Engineer is a client-facing position that works closely with Sales Representatives to pursue sales opportunities. This position contributes to top line revenue generation and requires an individual who can self-start, learn quickly, communicate effectively and do what it takes to win business. Clients and prospects of iPipeline span the Life Insurance and Annuities industry and include Carriers, Distributors, Brokers, Wealth Management firms and individual Agents.These companies provide products and services to both agents and consumers through iPipeline’s Software-as-a-Service platform. This platform consists of over 20 functional modules, and the Sales Engineer is required to have a working knowledge of all of them. Once the desired level of expertise on our product offerings is achieved, Sales Engineers are required to participate in the sales process to help Sales Representatives qualify opportunities, provide demonstrations, answer requests for information/proposals, create content that describes our solutions and perform internal training.Position Responsibilities:Assist the Sales Representative in gathering information on qualification calls with clients and prospects.Work with Sales Representatives to create sales strategies to win opportunities in a competitive environment.Prepare for and provide Sales Demonstrations of iPipeline products according the client/prospect needs.Maintain and update demonstration environments and data to support compelling demonstrations.Work with the Sales Representative during demonstrations to lead the client through a discussion that enables you to show impactful functionality that meets their needs.Assist with post-demonstration follow ups, additional “deeper dive” demonstrations and workshops.Manage the process to get Requests for Proposals/Requests for Information (RFP’s/RFI’s) answered and sent back to clients and prospects. This requires the ability to take knowledge learned and craft answers, find and edit answers, and curate previous answers. This also includes the need to work with subject matter experts within iPipeline to get needed input and review.Research and understand competitive landscape, including competitor offerings and marketplace.Store key demonstration notes and RFI activities in Sharepoint.', 'Bachelors or better']",2020-08-08 12:52:09
ETL Informatica Engineer,Accenture,4 out of 5,"Newark, DE","['Drive innovation. People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward.', 'Learn and grow continuously: Follow personalized training to build skills, while expanding your experience defining and implementing solutions on complex client projects with a scope that is unsurpassed in industry.', 'Thrive in our inclusive environment: Bring your whole self to a company that aims to be the most diverse in the world and delivers real-time performance feedback based on individual strengths—not stats.', 'Extract, Transform and Load data primarily in Informatica with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.', 'Demonstrate an understanding of technology and digital frameworks in the context of data integration utilizing Informatica.', 'Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.', 'Minimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Data Quality', 'Bachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years', 'Experience in ETL Tools in addition to Informatica, including Business Objects Data Services (BODS), DataStage, Ab Initio, Talend, and Pentaho', 'Experience with a full life-cycle development from functional design to deployment', 'Database experience (Teradata, Oracle, SQL Server, DB2, Azure SQL)', 'Strong knowledge and experience of SQL', 'Understanding of Entity relationship data models and Dimensional Models', 'Experience with development and production support', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).', 'Proven success in contributing to a team-oriented environment', 'Proven ability to work creatively and analytically in a problem-solving environment', 'Desire to work in an information systems environment', 'Excellent communication (written and oral) and interpersonal skills']",2020-08-08 12:52:09
Data Engineer,The Hartford,3.7 out of 5,"Hartford, CT","['Understand sources of data within The Hartford, and work with SME’s to describe and understand data lineage and suitability for a use case.', 'Understand data classification, and adhere to the information protection and privacy restrictions on data.', 'Create summary statistics/reports from data warehouses, marts, and operational data stores.', 'Extract data from source systems, and data warehouses, and deliver in a pre-defined format using standard database query and parsing tools.', 'Work with The Hartford information protection group to get approvals and adhere to the processes for data privacy and loss prevention.', 'Understand ways to link or compare information already in our systems with new information.', 'Perform preliminary exploratory analysis to evaluate nulls, duplicates and other issues with data sources (internal or external).', 'Work with data scientists to understand the requirements and propose and identify data sources and alternatives.', 'Produce code artifacts and documentation for reproducibility, preferably utilizing Github, and hand-off to other data science teams.', 'Propose ways to improve and standardize processes to enable new data and capability assessment and to enable pivoting to new projects.', 'Act as a liaison and SME between business and IT resources.', 'Bachelor degree or equivalent experience in related field required', 'Experience accessing and retrieving data from disparate large data sources', 'Experience with data modeling, data warehousing tools and databases (e.g. Python, R, Hadoop, Spark/PySpark, ETL, Big Data, ORACLE, and Hive)', 'Ability to analyze source systems and provide technical solutions', 'Determine business recommendations and translate into actionable steps', 'Experience in creating and tuning SQL Queries', 'Experience with software engineering concepts such as object oriented programing.', 'Self-starter with a willingness to become a data expert.', 'Demonstrate a passion to both learn new skills and lead discovery of the data research', 'Results oriented with the ability to multi-task and adjust priorities when necessary', 'Ability to work both independently and in a team environment with internal customers', 'Ability to articulate and train technical concepts regarding data to both data scientists and partners']",2020-08-08 12:52:09
Data Engineer,Ken Info Systems,N/A,"Portland, OR","['Monday to Friday', 'Python: 1 year (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 12:52:09
Senior Data Engineer,Jobvite,3.9 out of 5,Remote,"['Translate business requirements into technical specifications.', 'Participate in all design reviews and requirement sessions, as required.', 'Understand database design, programming concepts, data modeling, and framework management.', 'Communicate ideas to both technical and non-technical people in all levels of the organization.', 'Create or update technical documentation for transition to support teams, including data flows and transformations.', 'Design, develop, and test data pipeline solutions and automate data loading processes.', 'Develop and implement an efficient migration process to move data pipeline objects from development to test and production environments.', 'Analyze data requirements, complex source data, and application data models, and determine the best methods for integrating data to support internal and external analytical needs.', 'Design and implement data models to support reporting, dashboarding, and integration needs.', 'Develop automated data audit, testing, and validation processes.', 'Stay up to date on ever evolving technologies and processes for managing data pipelines', '5+ years of data and/or software engineering experience.', 'Expert SQL skills.', 'Experience with designing and developing complex data flows.', 'Experience in creating data models based on complex business entities.', 'Experience with large scale, complex data migration efforts.', 'Experience with loading data from internal / external APIs.', 'Developing streaming data flows (i.e., w/ Kafka, Beam, AWS SQS, Spark Streaming)', 'Experience with public cloud solutioning (i.e., AWS, Azure, GCP).', 'Experience with public cloud analytical database solutions (i.e., Snowflake, Redshift).', 'Excellent Analytical skills required.', 'Experience with shell scripting required.', 'Flexibility/Adaptability is required, especially when working as a team.', 'Preferred Experience:Experience with Java, Ruby, PythonExperience with Machine Learning.Experience with BI and Reporting Tools (i.e., Looker, Tableau, PowerBI, Qlik).Experience in delivering solutions based on Agile principlesExperience with Kubernetes / containers']",2020-08-08 12:52:09
Senior Data Engineer,The Boston Consulting Group - Platinion,N/A,"New York, NY","['https://strike.chat/s/schedule-chat/bcg_platinion/data_engineering/e677c?src=indeed', 'Iterative. They are excited to prototype at all levels of fidelity—and have the humility to walk away from ideas when they fail.', 'Collaborative. They have the ability and enthusiasm to work with researchers, engineers, business consultants, and other designers who will challenge and support one another.', 'Comfortable with ambiguity. They know projects and businesses move fast. That means the path forward isn’t always well-defined. They are comfortable and collaborative through our process.', 'Interdisciplinary. They deliver data products for digital solutions, deploy analytical models into production, fix existing data platforms, or coach and enable other teams in best practices depending on need.', 'Working with a diverse set of clients across domains and industries', 'Implementing data orchestration pipelines, data sourcing, cleansing, and augmentation and quality', 'control processes', 'Deploying machine learning models in production', 'Supporting data architects in designing data architectures', 'Assisting in mentoring data engineers to further their personal and professional growth', 'Supporting project management operations of a project', 'Translating business needs into solutions', 'Contributing to overall solution, integration, and enterprise architecture', '2+ years of experience working on large scale, full lifecycle data implementation projects', 'BS/BA in data engineering, software engineering, data science, computer science, applied mathematics, or equivalent experience', '2+ years professional development experience with some of the AWS/Azure/GCP data stack: S3, Redshift, AWS glue, EMR, Azure Data Warehouse, Azure Blob Store, Google Big Query', 'A deep knowledge of performant SQL and understanding of relational database technology', 'Hands-on RDBMS experience (data modeling, analysis, programming, stored procedures)', 'Expertise in developing ETL/ELT workflows with one or more of the following: Python, Scala, Java', 'Deployment of data pipelines in the Cloud in at least AWS, Azure, or GCP', 'A deep understanding of relational and warehousing database technology,', 'working with at least one of the major databases platforms (Oracle, SQLServer, Teradata, MySQL, Postgres)', 'Experience working with Big Data technologies such as Spark, Hive, Impala, Druid, or Presto', 'A solid foundation in data structures, algorithms, and OO Design with fundamentally strong programming skills', 'Proven success working in and promoting a rapidly changing, collaborative, and iterative product development environment', 'Strong interpersonal and analytical skills', 'Intellectual curiosity and an ability to execute projects', 'An understanding of “big picture” business requirements that drive architecture', 'and design decisions', 'DevOps and DataOps skills including “infrastructure as code” systems like', 'CloudFormation or Terraform', 'Data system performance tuning', 'Implementation of predictive analytics and machine learning models (MLlib,', 'scikit-learn, etc)', 'Willingness to travel around the globe to work with clients and BCG teams. At', 'times, this role involves significant travel to client sites. The amount of travel will depend on client needs and nature of projects', 'https://strike.chat/s/schedule-chat/bcg_platinion/data_engineering/e677c?src=indeed', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Relocation Assistance', 'Retirement Plan', 'Vision Insurance']",2020-08-08 12:52:09
Big Data Engineer,Grenza Inc,N/A,"San Francisco, CA","['Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:52:09
"Data Engineer, Analytics",Facebook,4.2 out of 5,"Los Angeles, CA","['Manage data warehouse plans for a product or a group of products.', 'Interface with engineers, product managers and product analysts to understand data needs.', 'Build data expertise and own data quality for allocated areas of ownership.', 'Design, build and launch new data models in production.', 'Design, build and launch new data extraction, transformation and loading processes in production.', 'Support existing processes running in production.', 'Define and manage SLA for all data sets in allocated areas of ownership.', 'Work with data infrastructure to triage infra issues and drive to resolution.', '2+ years experience in the data warehouse space.', '2+ years experience in custom ETL design, implementation and maintenance.', '2+ years experience working with either a MapReduce or an MPP system.', '2+ years experience with object-oriented programming languages.', '2+ years experience with schema design and dimensional data modeling.', '2+ years experience in writing SQL statements.', 'Experience analyzing data to identify deliverables, gaps and inconsistencies.', 'Experience managing and communicating data warehouse plans to internal clients.']",2020-08-08 12:52:09
eDiscovery Data Engineer (Processing Specialist),"Contact Government Services, LLC",N/A,"Los Angeles, CA 90017","['Work closely with project management and other team members on completing complex projects in a fast pace, deadline driven environment', 'Learn and complete electronically stored information (ESI) processing and document productions in accordance with industry standards and client specifications', 'Consistently adhere to standard operating procedures', 'Perform quality checks on work product prior to delivering to the client', 'Assist in developing, documenting, and refining procedures to accomplish discovery process requirements', 'Additional duties assigned by manager including general IT functions', 'Prior experience in data processing (Relativity, Nuix Workstation, LAW Prediscovery, Venio One, iPro eCapture, etc.)', 'Familiarity with creation, development, and testing of SQL scripting', 'B.S. or B.A. degree, preferably information technology, computer science, or other related fields', 'Ability to communicate effectively and tactfully in both verbally and in written format', 'Ability to work extended hours when necessary to ensure client deadlines are met', 'Ability to demonstrate superior organizational skills with an acute attention to detail', 'Ability to work effectively under pressure in time sensitive situations', 'Ability to work well in a team environment, as well as independently', 'Ability to prioritize multiple projects with similar deadlines', 'Ability to troubleshoot/problem solve and communicate results to a team', 'Ability to innovate and develop current and new workflows and solutions', 'An understanding of digital forensic preservation functions and tools (Cellebrite UFED Physical Analyzer, AccessData FTK Imager, etc.)', 'Familiarity with scripting, programming, coding, and/or database languages (VB, HTML, Access)', 'Knowledgeable within all stages of the EDRM', 'Experience operating and troubleshooting general IT solutions across various operating systems']",2020-08-08 12:52:09
Data Engineer,DigitalOcean,4 out of 5,New York State,"['Develop and implement metrics and dimensions for powering analytical use cases across the company, incorporating a wide variety of data sources across the company at varying levels of complexity and scale', 'Focus on data quality of the data environment and data products being delivered to the business, and effectively communicate to internal user base regarding production status', 'Interface closely with data infrastructure, engineering and technical operations teams to ensure correctness and soundness of metrics built in the data environment and availability of data product services', 'Pioneer initiatives around data quality, integrity, security and governance', 'Work closely with data stakeholders across the company, both technical and non-technical, to understand evolving needs as more complex data models are introduced for reporting and data science', ""Bachelor's degree in Computer Science, Math, Statistics, Economics, or other quantitative field; or equivalent experience."", 'Experience in custom ETL design, implementation and maintenance', 'Track record of developing in complex data environments and intelligence platforms for business users', 'Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts', 'History of proactively identifying forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale', 'Extensive hands-on experience with schema design and dimensional data modeling', 'Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies', 'Experience with analytics databases like Snowflake, Redshift, or BigQuery.', 'Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling', 'Experience scripting in Go or Python or a similar scripting language.', 'Effective communication and interpersonal skills', 'Experience implementing dimensional modeling in a configuration tool like dbt or LookML a plus', 'Experience designing and building dashboards in BI tools like Looker, Tableau, or PowerBI a plus.', 'Experience with job schedulers (Airflow, Luigi, Azkaban, etc.) a plus', 'We value development. You will work with some of the smartest and most interesting people in the industry. We are a high-performance organization that is always challenging ourselves to continuously grow. We maintain a growth mindset in everything we do and invest deeply in employee development through formalized mentorship, LinkedIn Learning tracks, and other internal programs. We also provide all employees with reimbursement for relevant conferences, training, and education.', 'We care about your physical, financial and mental well-being. We offer competitive health, dental, and vision benefits for employees and their dependents, a monthly gym reimbursement to support your physical health, and a commute or internet allowance to make your trips to your office or your desk easier. We offer generous parental leave with transition time built-in upon return to work. We offer competitive compensation and a 401k plan with up to a 4% employer match.', ""We support our remote employee experience. While we have great office spaces in NYC, Cambridge and Palo Alto, we're very distributed—we use a number of communication tools to connect across the company—and all remote employees have the opportunity to visit our offices and meet their teams face-to-face at team offsites. We also have an annual company offsite, Shark Week, to get quality in-person time with the entire company at least once a year. We also allow employees to outfit their workstations to meet their needs—whether remote or in office."", 'We value diversity and inclusivity. We are an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.']",2020-08-08 12:52:09
Data Analytics Engineer,Warner Bros. Entertainment Group,4.2 out of 5,"Burbank, CA","['Lead selection, implementation, and integration of data visualization tools.', 'Guide adoption and planning of Tableau installation.', 'Work closely with business users to define and deliver effective data visualizations.', 'Create and maintain core internal dashboards that are cross-departmental.', 'Design and implement data security model to support flexible user access level.', 'Build aggregate datasets using ETL principles that underlay visualizations. Participate in the creation and support of BI development standards and best practices.', 'Continually research and improve new methods and technologies in the analytics and visualization space.', 'Apply your learnings to what you build.', 'Rapidly deliver on concepts through prototypes that can be presented for feedback', 'Train fellow employees on best practices for data visualization and help others be successful stewards of our tools.', 'Transform the way our business users consume data and insights through highly usable and visually stunning data products.', 'Enable everyone at Warner Bros. to be an analyst through the Self-Service BI model.', ""Bachelor's Degree in Computer Science, Engineer, Mathematics or similar required."", '3-4 years of relevant experience: Delivering business intelligence and dashboard solutions.', 'Expert in Tableau and data visualization design.', 'Analyzing, compiling, cleansing, interpreting, joining and staging data.', 'Working with an Enterprise Data Warehouse and Snowflake, Teradata, Oracle and/or SQL Server databases.', 'Demonstrable skills building responsive data visualizations.', 'Working in an Agile development environment.', 'Research product and technical data in order to recommend products, technologies, and processes for ongoing projects.', 'Proven ability to produce high-quality data visualizations in a fast-paced environment.', 'An expert who can tell a story with data, as well as visualize it with a variety of tools (Tableau, Looker etc).', 'Strong background in data relationships, modeling, semantic layer and mining.', 'Proficient in data wrangling technologies like SQL and Python.', 'Experience with Snowflake, Teradata or other parallel database.', 'Experience working with complex and large volumes of data.', 'Ability of filtering the signal from the noise in datasets.', 'Ability to work independently and problem solve with little to no direction.', 'Willingness and ability to learn in a fast-paced environment.', 'Ability to teach and train effectively.', 'Experience managing multiple, simultaneous projects.', 'Must be able to organize and schedule work effectively.', 'Must be able to work well under time constraints.', 'Must be able to handle multiple tasks with changing priorities, communicating changes in scope and schedule to all parties concerned.', 'Must be able to work flexible hours, including possible overtime, when necessary.', 'Must be able to maintain confidentiality.', 'Loves data and pays close attention to details - caring about the quality of the input data as well as how the processed data is ultimately interpreted and used.', ""Master's degree preferred."", 'Experience with R or SAS is a plus.']",2020-08-08 12:52:09
Data Engineer,Aretove,N/A,"New York, NY","['In consultation with the project leadership perform data collection from various upstream and downstream systems.', 'Build and optimize new and existing processes supporting data transformation, data structures, meta data, dependency and workload management.', 'Execute extract, transform and load (ETL) operations on large datasets including data identification, mapping, aggregation, cleansing and analyzing.', 'Create data pipeline by connecting to and ingesting data from third party databases and APIs.', 'Ability to clearly articulate and present data, deliver insights and recommendations to business stakeholders.', 'Bachelor’s degree or professional experience in a related field.', 'You enjoy wrangling huge amounts of data and exploring new data sets.', 'Strong analytic skills and ability to transform unstructured into structured data.', 'Proficient in writing SQL queries.', 'Ability to work independently, deal well with ambiguous and undefined problems.', 'Ability to work in a fast-paced and agile environment.']",2020-08-08 12:52:09
Data Engineer- Customer Data Platform,Warner Bros. Entertainment Group,4.2 out of 5,"Burbank, CA","['Work closely with the business and technical project manager to understand the business requirement and translate into technical specs.', 'Provide analysis reports and estimations.', 'Design, develop, install, test and maintain data integrations from a variety of formats including files, database extracts and external APIs into data stores (including Snowflake, Elastic, S3, etc) using ETL tools, techniques and programming languages like Python, Spark, SQL, etc.', 'Build high-performance data engineering algorithms and prototypes.', 'Create flexible data models, tune queries and ETL components.', 'Manage job orchestration using tools like Airflow.', 'Research possible customization for tuning, cost optimization, performance enhancements, data reliability and quality.', 'Ensure that all solutions meet the business/company requirements for solution data reliability, quality and disaster recovery.', 'Own the application/data end-to-end from requirements to post production working closely with other teams. Provide engineering leadership by actively advocating best practices and standards for software engineering.', 'Collaborate with other team members such as data architects, data scientists etc.', 'Consistently contribute into the project management practices using Agile method.', 'Present the prototype to the stakeholders and leadership.', 'Bachelor’s degree in Computer Science or related field.', 'Minimum of 5 years of data analytics/data engineering, complex ETL/ELT experience in database systems like Snowflake, Teradata, etc. using Python.', 'Minimum 5 years of experience in using SQL/NoSQL, JSON and XML data structures.', 'Minimum 5 years of big data technologies including Hadoop, Apache Spark, Snowflake and AWS Suite of technologies (S3, EMR, Lambda).', 'Minimum 3 years of Experience using Restful APIs for ETL purposes.', 'Expert problem solver with strong analytical skills.', 'Expert in SQL (Snowflake, Teradata) and Python.', 'Expert in ETL/ELT tools and techniques.', 'Experience using big data tools (Hadoop, Map-reduce, Elastic search, Kinesis, Kafka, Solr).', 'Experience using AWS technologies (EMR, S3, Kinesis, Lambda).', 'Experience using Restful APIs for ETL purposes.', 'Experience using Git or SVN and Jira.', 'Experience using Spark (Scala/Java), Spark SQL and Spark Streaming is a plus.', 'Experience in Segments, MParticle, Adobe Site Catalyst or any other similar digital analytics product products is a plus.', 'Experience in Tableau is a plus.', 'Strong communication skills and proficient in Excel, Word, PowerPoint, MS Project and MS Visio Snowflake.', 'Ability to work independently or collaboratively.', 'Detail oriented with strong organization and prioritization skills.', 'Entertainment and/or Social Media experience a plus.', 'Demonstrated ability to work well under time constraints.', 'Must be able to work flexible hours, including possible overtime, when necessary.', 'Must be able to maintain confidentiality.', 'Management has the right to add or change duties and job requirements at any time.']",2020-08-08 12:52:09
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:52:51
"Data Engineer, Analytics (Instagram Ecosystems)",Facebook,4.2 out of 5,"New York, NY","['Craft and own the optimal data processing architecture and systems for new data and ETL pipelines', 'Build canonical datasets as well as scalable and fault-tolerant pipelines', 'Build data anomaly detection, data quality checks, and optimize pipelines for ideal compute and storage', 'Define and own the data engineering roadmap for Ecosystems', 'Collaborate with Software Engineers and Data Scientists to design technical specification for logging and add logging to production code to generate metrics both online as well as offline', 'Work with different cross functional partners - Data Scientists, Infra Engineering, Logging Framework Infra Teams, Product Managers', 'Build visualizations to provide insights into the data & metrics generated', 'Work with data infrastructure teams to suggest improvements and influence their roadmap', 'Immerse yourself in all aspects of the product, understand the problems, and tie them back to data engineering solutions', 'Recommend improvements and modifications to existing data and ETL pipelines', 'Communicate and influence strategies and processes around data modeling and architecture to multi-functional groups and leadership', 'Drive internal process improvements and automating manual processes for data quality and SLA management', 'Provide ongoing proactive communication and collaboration throughout the organization', ""4+ years' experience in the data warehouse space"", ""4+ years' experience working with either a MapReduce or an MPP system"", ""7+ years' experience in writing complex SQL and ETL processes"", ""4+ years' experience with object-oriented programming languages"", ""7+ years' experience with schema design and dimensional data modeling""]",2020-08-08 12:52:51
Data Engineer,Q-Centrix,3.8 out of 5,Remote,"['Job', 'Company', 'Work closely with the Data Architect to create and maintain optimal data architecture', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies', 'Support the Product Development, Operations and Finance Teams in creating and analyzing reports both for our partners and internally', 'Envision and create reports that are translated from internal ideas, client feedback and competitive analysis', 'Partner with other disciplines within Q-Centrix to ensure project requirements are comprehensive and thoroughly planned and documented', 'Work with internal and market-facing stakeholders to validate suggested features and enhancements to Q-Apps', 'Be a vital contributor on a product development team accountable for building the industry’s only Healthcare Quality Information System', 'Have a Bachelor’s Degree in computer science, information technology, MIS, mathematics, or a related field', 'Have 2-5 years of experience in healthcare or a related field (basically, you’ve been in the game for a minute, but you’re not yet an expert)', 'Have 2-5 years of experience in at least two BI tools like Tableau, Business Objects, Power BI, or Qlikview', 'Have 2-5 years of experience in SQL with a common RDBMS like SQL Server, Oracle, Teradata, MySql', 'Are experienced with Visualization and Analytics in a BI platform like Birst, Tableau, GoodData, Power BI, Microstrategy or Business Objects', 'Understand how Database Management Systems work', 'Are comfortable implementing Business Intelligence systems for internal or customer-facing groups, including analysis, dashboards, reporting, performance management, KPIs', 'Have worked within the framework of common Project Management structures and practices including waterfall, agile, project planning, scope control, customer relationship management', 'Have had exposure to data modeling for data warehousing - star, snowflake schema designs', 'Have worked with ETL/data integration tools like Informatica, MSFT SSIS, Oracle Warehouse Builder, Data Integrator, Data Stage, Ab Initio', 'Have an appreciation for design-with an understanding of the interplay of color, shape and size', 'Brownie points if you’re experienced with PostgreSQL and have healthcare industry experience']",2020-08-08 12:52:51
Data Visualization Engineer,Thermo Fisher Scientific,3.5 out of 5,"New York, NY 10001","['Develop concepts and robust visualization solutions systems for helping our customers make data-driven decisions in collaborative, team-based environment.', 'Participate in every stage of the product development lifecycle, from ideation and requirements to wireframes, implementation, testing, deployment, and maintenance as part of a cross-functional mutually supportive goal-oriented team', 'Be a community leader, thought leader and mentor in visualization and data storytelling principles', 'Perform other tasks as needed, including executive presentations, data analysis, or project management in our cross-functional team that shares responsibilities and executive exposure', 'Bachelor’s or Master’s degree in Computer Science, data engineering or a related field, or equivalent experience', '5+ years’ experience building web based interactive data visualizations utilizing JavaScript, CSS, etc…', 'Data extraction, transformation, and analysis experience in SQL and Python required', 'Experience in broad set of data visualization tools and an advanced Power BI designer', 'Interpersonal skills: exceptional verbal / written communication to translate complex technical concepts', 'Proven track record of achieving desired results without direct report authority', 'Knowledge of working with Agile / Scrum methodology a plus', 'Knowledge and experience in finance industry and functions a plus', 'Minimal travel required &lt;10%']",2020-08-08 12:52:51
Data Engineer,Atos,3.5 out of 5,United States,[],2020-08-08 12:52:51
Data Engineer,GardenStar Group,N/A,"Short Hills, NJ","['Identify valuable data sources and automate collection processes', 'Undertake preprocessing of structured and unstructured data', 'Present information using data visualization techniques', 'A Bachelor’s degree in Computer Science, Engineering, or relevant field', 'Proficient in SQL and Python', 'Strong math skills (e.g. statistics, algebra)', 'Understanding of machine-learning', 'Strong work ethic and great communication and collaboration skills', 'Analytical mind and business acumen, and problem-solving aptitude', 'Ability to multitask with strict time constraints, budgets and business goals', 'Experience as a Data Scientist or Data Analyst', 'Experience in data mining', 'Familiarity with Scala, Java or C++', 'Excellent communication and presentation skills', '2020 Fall Internship Program will commence in late August', 'Less than 10 hours/week on-site required', 'Potential Full-time position available at the end of the internship', 'The application deadline is Aug 15th, 2020', 'Monday to Friday', ""Bachelor's (Required)"", 'Short Hills, NJ (Required)', 'United States (Required)', 'https://www.gardenstargroup.com', 'Temporarily due to COVID-19']",2020-08-08 12:52:51
Data Engineer,Virginia Tech,4.3 out of 5,"Blacksburg, VA","['Bachelor’s degree in Business Information Technology, Computer Science, Information Systems or related field or equivalent training and/or experience', 'Advanced experience with (ETL) technologies such as Talend', 'Extensive experience in relational databases, like Oracle, Postgres and Redshift including advanced SQL writing ability', 'Experience with cloud technologies such as AWS', 'Demonstrates skills in working effectively in a team environment. Strong communication, organization and interpersonal skills', 'Demonstrated experience in full system lifecycle development including requirements gathering, systems analysis and development of data services, testing and implementation of large enterprise systems', 'Extensive experience in data warehouse concepts and dynamic object architecture. Strong understanding in concepts and the features to maintain a well-structured and efficient database', 'Experience in cloud services. Ideally AWS services such as EMR, Glue, Athena, RDS and Redshift', 'Experience in an object-oriented programming language like Python or Java.', 'Experience with Business Intelligence tools such as MicroStrategy, Tableau or SAS', 'Experience in an enterprise environment with DevOps best practices and technologies such as Docker, Version Control (Git), and Jenkins', 'Experience with data lakes in a Hadoop or AWS environment', 'Exposure to web services and APIs']",2020-08-08 12:52:51
Sales Engineer,iPipeline,3.3 out of 5,"Exton, PA 19341","['Position Summary:An iPipeline Sales Engineer is a client-facing position that works closely with Sales Representatives to pursue sales opportunities. This position contributes to top line revenue generation and requires an individual who can self-start, learn quickly, communicate effectively and do what it takes to win business. Clients and prospects of iPipeline span the Life Insurance and Annuities industry and include Carriers, Distributors, Brokers, Wealth Management firms and individual Agents.These companies provide products and services to both agents and consumers through iPipeline’s Software-as-a-Service platform. This platform consists of over 20 functional modules, and the Sales Engineer is required to have a working knowledge of all of them. Once the desired level of expertise on our product offerings is achieved, Sales Engineers are required to participate in the sales process to help Sales Representatives qualify opportunities, provide demonstrations, answer requests for information/proposals, create content that describes our solutions and perform internal training.Position Responsibilities:Assist the Sales Representative in gathering information on qualification calls with clients and prospects.Work with Sales Representatives to create sales strategies to win opportunities in a competitive environment.Prepare for and provide Sales Demonstrations of iPipeline products according the client/prospect needs.Maintain and update demonstration environments and data to support compelling demonstrations.Work with the Sales Representative during demonstrations to lead the client through a discussion that enables you to show impactful functionality that meets their needs.Assist with post-demonstration follow ups, additional “deeper dive” demonstrations and workshops.Manage the process to get Requests for Proposals/Requests for Information (RFP’s/RFI’s) answered and sent back to clients and prospects. This requires the ability to take knowledge learned and craft answers, find and edit answers, and curate previous answers. This also includes the need to work with subject matter experts within iPipeline to get needed input and review.Research and understand competitive landscape, including competitor offerings and marketplace.Store key demonstration notes and RFI activities in Sharepoint.', 'Bachelors or better']",2020-08-08 12:52:51
ETL Informatica Engineer,Accenture,4 out of 5,"Newark, DE","['Job', 'Company', 'Drive innovation. People in our Client Delivery & Operations career track drive delivery and capability excellence through the design, development and/or delivery of a solution, service, capability or offering. They grow into delivery-focused roles, and can progress within their current role, laterally or upward.', 'Learn and grow continuously: Follow personalized training to build skills, while expanding your experience defining and implementing solutions on complex client projects with a scope that is unsurpassed in industry.', 'Thrive in our inclusive environment: Bring your whole self to a company that aims to be the most diverse in the world and delivers real-time performance feedback based on individual strengths—not stats.', 'Extract, Transform and Load data primarily in Informatica with an emphasis on advocacy toward end-users to produce high quality software designs that are well-documented.', 'Demonstrate an understanding of technology and digital frameworks in the context of data integration utilizing Informatica.', 'Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts.', 'Minimum 4 years of experience developing and implementing Informatica Powercenter or Informatica Data Quality', 'Bachelor’s Degree or Associate’s Degree with 6 years of work experience or equivalent work experience of 12 years', 'Experience in ETL Tools in addition to Informatica, including Business Objects Data Services (BODS), DataStage, Ab Initio, Talend, and Pentaho', 'Experience with a full life-cycle development from functional design to deployment', 'Database experience (Teradata, Oracle, SQL Server, DB2, Azure SQL)', 'Strong knowledge and experience of SQL', 'Understanding of Entity relationship data models and Dimensional Models', 'Experience with development and production support', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).', 'Proven success in contributing to a team-oriented environment', 'Proven ability to work creatively and analytically in a problem-solving environment', 'Desire to work in an information systems environment', 'Excellent communication (written and oral) and interpersonal skills']",2020-08-08 12:52:51
Data Engineer,The Hartford,3.7 out of 5,"Hartford, CT","['Job', 'Company', 'Understand sources of data within The Hartford, and work with SME’s to describe and understand data lineage and suitability for a use case.', 'Understand data classification, and adhere to the information protection and privacy restrictions on data.', 'Create summary statistics/reports from data warehouses, marts, and operational data stores.', 'Extract data from source systems, and data warehouses, and deliver in a pre-defined format using standard database query and parsing tools.', 'Work with The Hartford information protection group to get approvals and adhere to the processes for data privacy and loss prevention.', 'Understand ways to link or compare information already in our systems with new information.', 'Perform preliminary exploratory analysis to evaluate nulls, duplicates and other issues with data sources (internal or external).', 'Work with data scientists to understand the requirements and propose and identify data sources and alternatives.', 'Produce code artifacts and documentation for reproducibility, preferably utilizing Github, and hand-off to other data science teams.', 'Propose ways to improve and standardize processes to enable new data and capability assessment and to enable pivoting to new projects.', 'Act as a liaison and SME between business and IT resources.', 'Bachelor degree or equivalent experience in related field required', 'Experience accessing and retrieving data from disparate large data sources', 'Experience with data modeling, data warehousing tools and databases (e.g. Python, R, Hadoop, Spark/PySpark, ETL, Big Data, ORACLE, and Hive)', 'Ability to analyze source systems and provide technical solutions', 'Determine business recommendations and translate into actionable steps', 'Experience in creating and tuning SQL Queries', 'Experience with software engineering concepts such as object oriented programing.', 'Self-starter with a willingness to become a data expert.', 'Demonstrate a passion to both learn new skills and lead discovery of the data research', 'Results oriented with the ability to multi-task and adjust priorities when necessary', 'Ability to work both independently and in a team environment with internal customers', 'Ability to articulate and train technical concepts regarding data to both data scientists and partners']",2020-08-08 12:52:51
Data Engineer,Ken Info Systems,N/A,"Portland, OR","['Monday to Friday', 'Python: 1 year (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 12:52:51
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:52:51
Cost Engineer,Innovative Turnaround Controls (ITC),4.5 out of 5,"Toledo, OH","['Assessing risks', 'Doing cost estimates', 'Forecasting', 'Reviewing proposed schedules', 'Implementing bets practices', 'Performing cost control', 'Analyzing variances', 'Teamwork', 'Communication', 'Networking', 'Being detail oriented', 'Being focused', 'Being amenable', 'Resolving problems', 'Communication and presentation', 'Analyzing data', 'Leadership', 'Being analytical', 'Being self motivated', 'Being dependable', 'Day Shift', 'Holidays', 'Monday to Friday', 'Night Shift', 'Weekends']",2020-08-08 12:52:51
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:52:51
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:52:51
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:52:51
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:52:51
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 12:52:51
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:52:51
Senior Data Engineer,Jobvite,3.9 out of 5,Remote,"['Translate business requirements into technical specifications.', 'Participate in all design reviews and requirement sessions, as required.', 'Understand database design, programming concepts, data modeling, and framework management.', 'Communicate ideas to both technical and non-technical people in all levels of the organization.', 'Create or update technical documentation for transition to support teams, including data flows and transformations.', 'Design, develop, and test data pipeline solutions and automate data loading processes.', 'Develop and implement an efficient migration process to move data pipeline objects from development to test and production environments.', 'Analyze data requirements, complex source data, and application data models, and determine the best methods for integrating data to support internal and external analytical needs.', 'Design and implement data models to support reporting, dashboarding, and integration needs.', 'Develop automated data audit, testing, and validation processes.', 'Stay up to date on ever evolving technologies and processes for managing data pipelines', '5+ years of data and/or software engineering experience.', 'Expert SQL skills.', 'Experience with designing and developing complex data flows.', 'Experience in creating data models based on complex business entities.', 'Experience with large scale, complex data migration efforts.', 'Experience with loading data from internal / external APIs.', 'Developing streaming data flows (i.e., w/ Kafka, Beam, AWS SQS, Spark Streaming)', 'Experience with public cloud solutioning (i.e., AWS, Azure, GCP).', 'Experience with public cloud analytical database solutions (i.e., Snowflake, Redshift).', 'Excellent Analytical skills required.', 'Experience with shell scripting required.', 'Flexibility/Adaptability is required, especially when working as a team.', 'Preferred Experience:Experience with Java, Ruby, PythonExperience with Machine Learning.Experience with BI and Reporting Tools (i.e., Looker, Tableau, PowerBI, Qlik).Experience in delivering solutions based on Agile principlesExperience with Kubernetes / containers']",2020-08-08 12:53:41
Big Data Engineer,Grenza Inc,N/A,"San Francisco, CA","['Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:53:41
"Data Engineer, Analytics",Facebook,4.2 out of 5,"Los Angeles, CA","['Manage data warehouse plans for a product or a group of products.', 'Interface with engineers, product managers and product analysts to understand data needs.', 'Build data expertise and own data quality for allocated areas of ownership.', 'Design, build and launch new data models in production.', 'Design, build and launch new data extraction, transformation and loading processes in production.', 'Support existing processes running in production.', 'Define and manage SLA for all data sets in allocated areas of ownership.', 'Work with data infrastructure to triage infra issues and drive to resolution.', '2+ years experience in the data warehouse space.', '2+ years experience in custom ETL design, implementation and maintenance.', '2+ years experience working with either a MapReduce or an MPP system.', '2+ years experience with object-oriented programming languages.', '2+ years experience with schema design and dimensional data modeling.', '2+ years experience in writing SQL statements.', 'Experience analyzing data to identify deliverables, gaps and inconsistencies.', 'Experience managing and communicating data warehouse plans to internal clients.']",2020-08-08 12:53:41
eDiscovery Data Engineer (Processing Specialist),"Contact Government Services, LLC",N/A,"Los Angeles, CA 90017","['Work closely with project management and other team members on completing complex projects in a fast pace, deadline driven environment', 'Learn and complete electronically stored information (ESI) processing and document productions in accordance with industry standards and client specifications', 'Consistently adhere to standard operating procedures', 'Perform quality checks on work product prior to delivering to the client', 'Assist in developing, documenting, and refining procedures to accomplish discovery process requirements', 'Additional duties assigned by manager including general IT functions', 'Prior experience in data processing (Relativity, Nuix Workstation, LAW Prediscovery, Venio One, iPro eCapture, etc.)', 'Familiarity with creation, development, and testing of SQL scripting', 'B.S. or B.A. degree, preferably information technology, computer science, or other related fields', 'Ability to communicate effectively and tactfully in both verbally and in written format', 'Ability to work extended hours when necessary to ensure client deadlines are met', 'Ability to demonstrate superior organizational skills with an acute attention to detail', 'Ability to work effectively under pressure in time sensitive situations', 'Ability to work well in a team environment, as well as independently', 'Ability to prioritize multiple projects with similar deadlines', 'Ability to troubleshoot/problem solve and communicate results to a team', 'Ability to innovate and develop current and new workflows and solutions', 'An understanding of digital forensic preservation functions and tools (Cellebrite UFED Physical Analyzer, AccessData FTK Imager, etc.)', 'Familiarity with scripting, programming, coding, and/or database languages (VB, HTML, Access)', 'Knowledgeable within all stages of the EDRM', 'Experience operating and troubleshooting general IT solutions across various operating systems']",2020-08-08 12:53:41
Data Engineer,DigitalOcean,4 out of 5,New York State,"['Develop and implement metrics and dimensions for powering analytical use cases across the company, incorporating a wide variety of data sources across the company at varying levels of complexity and scale', 'Focus on data quality of the data environment and data products being delivered to the business, and effectively communicate to internal user base regarding production status', 'Interface closely with data infrastructure, engineering and technical operations teams to ensure correctness and soundness of metrics built in the data environment and availability of data product services', 'Pioneer initiatives around data quality, integrity, security and governance', 'Work closely with data stakeholders across the company, both technical and non-technical, to understand evolving needs as more complex data models are introduced for reporting and data science', ""Bachelor's degree in Computer Science, Math, Statistics, Economics, or other quantitative field; or equivalent experience."", 'Experience in custom ETL design, implementation and maintenance', 'Track record of developing in complex data environments and intelligence platforms for business users', 'Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts', 'History of proactively identifying forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale', 'Extensive hands-on experience with schema design and dimensional data modeling', 'Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies', 'Experience with analytics databases like Snowflake, Redshift, or BigQuery.', 'Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling', 'Experience scripting in Go or Python or a similar scripting language.', 'Effective communication and interpersonal skills', 'Experience implementing dimensional modeling in a configuration tool like dbt or LookML a plus', 'Experience designing and building dashboards in BI tools like Looker, Tableau, or PowerBI a plus.', 'Experience with job schedulers (Airflow, Luigi, Azkaban, etc.) a plus', 'We value development. You will work with some of the smartest and most interesting people in the industry. We are a high-performance organization that is always challenging ourselves to continuously grow. We maintain a growth mindset in everything we do and invest deeply in employee development through formalized mentorship, LinkedIn Learning tracks, and other internal programs. We also provide all employees with reimbursement for relevant conferences, training, and education.', 'We care about your physical, financial and mental well-being. We offer competitive health, dental, and vision benefits for employees and their dependents, a monthly gym reimbursement to support your physical health, and a commute or internet allowance to make your trips to your office or your desk easier. We offer generous parental leave with transition time built-in upon return to work. We offer competitive compensation and a 401k plan with up to a 4% employer match.', ""We support our remote employee experience. While we have great office spaces in NYC, Cambridge and Palo Alto, we're very distributed—we use a number of communication tools to connect across the company—and all remote employees have the opportunity to visit our offices and meet their teams face-to-face at team offsites. We also have an annual company offsite, Shark Week, to get quality in-person time with the entire company at least once a year. We also allow employees to outfit their workstations to meet their needs—whether remote or in office."", 'We value diversity and inclusivity. We are an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.']",2020-08-08 12:53:41
Data Analytics Engineer,Warner Bros. Entertainment Group,4.2 out of 5,"Burbank, CA","['Lead selection, implementation, and integration of data visualization tools.', 'Guide adoption and planning of Tableau installation.', 'Work closely with business users to define and deliver effective data visualizations.', 'Create and maintain core internal dashboards that are cross-departmental.', 'Design and implement data security model to support flexible user access level.', 'Build aggregate datasets using ETL principles that underlay visualizations. Participate in the creation and support of BI development standards and best practices.', 'Continually research and improve new methods and technologies in the analytics and visualization space.', 'Apply your learnings to what you build.', 'Rapidly deliver on concepts through prototypes that can be presented for feedback', 'Train fellow employees on best practices for data visualization and help others be successful stewards of our tools.', 'Transform the way our business users consume data and insights through highly usable and visually stunning data products.', 'Enable everyone at Warner Bros. to be an analyst through the Self-Service BI model.', ""Bachelor's Degree in Computer Science, Engineer, Mathematics or similar required."", '3-4 years of relevant experience: Delivering business intelligence and dashboard solutions.', 'Expert in Tableau and data visualization design.', 'Analyzing, compiling, cleansing, interpreting, joining and staging data.', 'Working with an Enterprise Data Warehouse and Snowflake, Teradata, Oracle and/or SQL Server databases.', 'Demonstrable skills building responsive data visualizations.', 'Working in an Agile development environment.', 'Research product and technical data in order to recommend products, technologies, and processes for ongoing projects.', 'Proven ability to produce high-quality data visualizations in a fast-paced environment.', 'An expert who can tell a story with data, as well as visualize it with a variety of tools (Tableau, Looker etc).', 'Strong background in data relationships, modeling, semantic layer and mining.', 'Proficient in data wrangling technologies like SQL and Python.', 'Experience with Snowflake, Teradata or other parallel database.', 'Experience working with complex and large volumes of data.', 'Ability of filtering the signal from the noise in datasets.', 'Ability to work independently and problem solve with little to no direction.', 'Willingness and ability to learn in a fast-paced environment.', 'Ability to teach and train effectively.', 'Experience managing multiple, simultaneous projects.', 'Must be able to organize and schedule work effectively.', 'Must be able to work well under time constraints.', 'Must be able to handle multiple tasks with changing priorities, communicating changes in scope and schedule to all parties concerned.', 'Must be able to work flexible hours, including possible overtime, when necessary.', 'Must be able to maintain confidentiality.', 'Loves data and pays close attention to details - caring about the quality of the input data as well as how the processed data is ultimately interpreted and used.', ""Master's degree preferred."", 'Experience with R or SAS is a plus.']",2020-08-08 12:53:41
Data Engineer,Aretove,N/A,"New York, NY","['In consultation with the project leadership perform data collection from various upstream and downstream systems.', 'Build and optimize new and existing processes supporting data transformation, data structures, meta data, dependency and workload management.', 'Execute extract, transform and load (ETL) operations on large datasets including data identification, mapping, aggregation, cleansing and analyzing.', 'Create data pipeline by connecting to and ingesting data from third party databases and APIs.', 'Ability to clearly articulate and present data, deliver insights and recommendations to business stakeholders.', 'Bachelor’s degree or professional experience in a related field.', 'You enjoy wrangling huge amounts of data and exploring new data sets.', 'Strong analytic skills and ability to transform unstructured into structured data.', 'Proficient in writing SQL queries.', 'Ability to work independently, deal well with ambiguous and undefined problems.', 'Ability to work in a fast-paced and agile environment.']",2020-08-08 12:53:41
Data Engineer- Customer Data Platform,Warner Bros. Entertainment Group,4.2 out of 5,"Burbank, CA","['Work closely with the business and technical project manager to understand the business requirement and translate into technical specs.', 'Provide analysis reports and estimations.', 'Design, develop, install, test and maintain data integrations from a variety of formats including files, database extracts and external APIs into data stores (including Snowflake, Elastic, S3, etc) using ETL tools, techniques and programming languages like Python, Spark, SQL, etc.', 'Build high-performance data engineering algorithms and prototypes.', 'Create flexible data models, tune queries and ETL components.', 'Manage job orchestration using tools like Airflow.', 'Research possible customization for tuning, cost optimization, performance enhancements, data reliability and quality.', 'Ensure that all solutions meet the business/company requirements for solution data reliability, quality and disaster recovery.', 'Own the application/data end-to-end from requirements to post production working closely with other teams. Provide engineering leadership by actively advocating best practices and standards for software engineering.', 'Collaborate with other team members such as data architects, data scientists etc.', 'Consistently contribute into the project management practices using Agile method.', 'Present the prototype to the stakeholders and leadership.', 'Bachelor’s degree in Computer Science or related field.', 'Minimum of 5 years of data analytics/data engineering, complex ETL/ELT experience in database systems like Snowflake, Teradata, etc. using Python.', 'Minimum 5 years of experience in using SQL/NoSQL, JSON and XML data structures.', 'Minimum 5 years of big data technologies including Hadoop, Apache Spark, Snowflake and AWS Suite of technologies (S3, EMR, Lambda).', 'Minimum 3 years of Experience using Restful APIs for ETL purposes.', 'Expert problem solver with strong analytical skills.', 'Expert in SQL (Snowflake, Teradata) and Python.', 'Expert in ETL/ELT tools and techniques.', 'Experience using big data tools (Hadoop, Map-reduce, Elastic search, Kinesis, Kafka, Solr).', 'Experience using AWS technologies (EMR, S3, Kinesis, Lambda).', 'Experience using Restful APIs for ETL purposes.', 'Experience using Git or SVN and Jira.', 'Experience using Spark (Scala/Java), Spark SQL and Spark Streaming is a plus.', 'Experience in Segments, MParticle, Adobe Site Catalyst or any other similar digital analytics product products is a plus.', 'Experience in Tableau is a plus.', 'Strong communication skills and proficient in Excel, Word, PowerPoint, MS Project and MS Visio Snowflake.', 'Ability to work independently or collaboratively.', 'Detail oriented with strong organization and prioritization skills.', 'Entertainment and/or Social Media experience a plus.', 'Demonstrated ability to work well under time constraints.', 'Must be able to work flexible hours, including possible overtime, when necessary.', 'Must be able to maintain confidentiality.', 'Management has the right to add or change duties and job requirements at any time.']",2020-08-08 12:53:41
Data Engineer,"Double Line, Inc.",N/A,"Austin, TX 78758","['Think creatively and help other data experts on the team figure out the solution to really tough data load or transformation problems', 'Leverage SQL, data mapping, and data modeling experience to manage and organize our customer education data', 'Be obsessed about continuously improving our approach and doing it better and faster the next time', 'Consultancy experience with a focus on Agile practices', 'AWS and Azure Cloud', 'Python or similar scripting languages', 'AWS Quicksight, Tableau, Power BI, or other visualization tools', 'Soak up knowledge from the existing team of experts in the first 30 days', 'Bring fresh eyes to our processes and techniques and bring new ideas to the table in the first 2 months', ""Grow your skills so much that you're ready to teach the next new hire by 2021"", 'A mission-driven company with a long-term focus on helping the world by untangling the technical messes that hold back education in our country', 'A home where your voice matters, and you can effect real change', ""A company who cares about you, makes sure you're engaged with exciting work and provides medical benefits, 401k, and a great culture.""]",2020-08-08 12:53:41
Data Engineer,Saama Technologies Inc,3.5 out of 5,"Phoenix, AZ","['Design and develop modern data platform', 'Hands on experience on databases such as Snowflake, S3 and Oracle', 'Experience in programming languages like Python, Spark, Java', 'Experience working in an Agile time, basic knowledge of Agile/Scrum is a must have', 'Strong Analytical skill and Critical thinking.', 'Knowledge of streaming tools such as StreamSets', 'Assists with development of requirements and design specifications for new projects.', 'Contributes to analyzing defects & product support for resolution.', 'Identify, analyze and present latest industry innovations and implementations in the workspace.', ""Bachelor's degree in related area (Computer Science, Information Systems, Engineering) or an equivalent combination of education and experience."", '4+ years Design, testing and applications development experience in Data management', '2+ years of experience building Data Hub solutions', 'Having an open mind set to learn new things and adopt to changing priorities', 'Strong communication skills']",2020-08-08 12:53:41
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 12:53:41
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:53:41
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:53:41
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:53:41
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 12:53:41
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:53:41
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:53:41
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:53:41
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:53:41
"Senior Data Engineer (Remote, USA, Full-Time)",4 Mile Analytics,N/A,Remote,"['Curious minds who are inclined to ask, “Why?”', 'Strong problem-solvers who are comfortable in unfamiliar situations, and can view challenges through multiple perspectives', 'Driven to develop technical skills for oneself and team-mates', 'Ability to connect with clients and colleagues of different backgrounds and communication styles, through empathy and clear verbal, visual, and written communication', 'Equates professional achievement with happy end-users', 'A wide variety of data engineering projects, including:Building data pipelines (ETL and ELT)Data warehouse design and optimizationWorking with large-scale distributed systemsDeveloping and architecting highly-scalable solutions that integrate with RESTful API data sourcesImplementing SaaS platformsIntegrations-in numerous languages, frameworks, and cloud environments.', 'Turning raw and complex data from a variety of sources into robust data stories:Data cleansing and modelingExploration and visualization for business intelligenceProductionization of BI and predictive models.', 'Work alongside data analysts and business stakeholders to deliver secure, scalable, fault-tolerant and highly-performant solutions.', 'Work in collaborative teams across a variety of industries with unique data challenges, data structures, business needs, and security considerations to build new data platforms and customer experiences.', 'A diversity of project structures, from optimizing and enriching existing data stacks, to participating in the entire cycle of analytics development and maturity development, ideation to deployment.', '5+ years of experience with two or more development languages. Experience with Python or R is preferred; experience with Java, Javascript, Scala or Go is also great.', '5+ years of experience with SQL (development, databases, or analytical warehouses)', 'Experience developing data pipelines in an ETL or ELT framework', 'Ability to be a “data expert” in any layer of the analytics stack: data ingestion and processing, data warehousing and modeling, business intelligence, analytics and visualization', 'Experience exploring, cleansing, visualizing and reporting on business intelligence reports and/or analytical models.', 'Experience designing and optimizing data warehouses (e.g. Redshift, BigQuery, Snowflake, or on-premise)', 'Experience working with NoSQL databases (e.g. MongoDB, DynamoDB, HBase)', 'Ability to lead technical design and delivery of complex data projects, including the architectural design, security and data flow of a new analytics stack or optimizations to an existing stack.', 'Ability to work with product owners and business stakeholders to align technical solutions with business needs', 'Ability to mentor and guide junior data engineers and analysts', 'Significant experience building data stacks in at least one cloud environment (AWS, GCP, Azure)', 'Familiarity with Agile methods, such as Scrum and/or Kanban', 'Ability to work with a high degree of autonomy and self-direction']",2020-08-08 12:54:33
"Software Engineer, Data",Amazon.com Services LLC,3.6 out of 5,"Hawthorne, CA","['Job', 'Company', 'Bachelor’s degree in Computer Science or a related field', '2+ years of experience in Software Engineering / Data Engineering / Data Warehousing roles working in high traffic, fault tolerant, and highly available environments', '1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems', '2+ years of experience with Scala, Golang, Python, Java, Ruby or a similar programming language', '2+ years of experience with SQL skills', '2+ years of experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)', '1+ years of experience with Streaming platforms like Kafka or Kinesis', '2+ years of experience with Test Driven Development or writing unit tests', 'Work with engineering and business stakeholders to understand streaming and data requirements', 'Help shape the growth of transformative data pipelines and data collection', 'Implement and operate large, evolving, big data resources and capabilities', 'Evaluate and implement efficient distributed storage and query techniques', 'Interact and integrate with internal and external teams and systems to extract, transform, and load data from a wide variety of sources', 'Develop the next generation of automation tools for monitoring and measuring data quality, with associated user interfaces.', 'Implement secure and auditable data infrastructure as required', 'Be able to broaden your technical skills and work in an environment that thrives on creativity, efficient execution, and product innovation.', 'Experience with AWS', 'Having planned and/or participated in terabyte-scale data environments', 'Experience implementing solutions to comply with GDPR and/or other Data Privacy regulations', 'Experience designing and implementing Data Governance programs', 'Experience integrating NoSQL alongside RDBMS such as Postgres or MySQL in a multi-tiered, globally replicated environment']",2020-08-08 12:54:33
Data Engineer,DigitalOcean,4 out of 5,New York State,"['Develop and implement metrics and dimensions for powering analytical use cases across the company, incorporating a wide variety of data sources across the company at varying levels of complexity and scale', 'Focus on data quality of the data environment and data products being delivered to the business, and effectively communicate to internal user base regarding production status', 'Interface closely with data infrastructure, engineering and technical operations teams to ensure correctness and soundness of metrics built in the data environment and availability of data product services', 'Pioneer initiatives around data quality, integrity, security and governance', 'Work closely with data stakeholders across the company, both technical and non-technical, to understand evolving needs as more complex data models are introduced for reporting and data science', ""Bachelor's degree in Computer Science, Math, Statistics, Economics, or other quantitative field; or equivalent experience."", 'Experience in custom ETL design, implementation and maintenance', 'Track record of developing in complex data environments and intelligence platforms for business users', 'Demonstrable ability to relate high-level business requirements to technical ETL and data infrastructure needs, including underlying data models and scripts', 'History of proactively identifying forward-looking data engineering strategies, utilizing appropriate technologies, and implementing at scale', 'Extensive hands-on experience with schema design and dimensional data modeling', 'Experience interacting with key stakeholders in different fields, interpreting challenges and opportunities into actionable engineering strategies', 'Experience with analytics databases like Snowflake, Redshift, or BigQuery.', 'Advanced SQL and relational database knowledge (MySQL, PostgreSQL) in addition to warehousing and dimension modeling', 'Experience scripting in Go or Python or a similar scripting language.', 'Effective communication and interpersonal skills', 'Experience implementing dimensional modeling in a configuration tool like dbt or LookML a plus', 'Experience designing and building dashboards in BI tools like Looker, Tableau, or PowerBI a plus.', 'Experience with job schedulers (Airflow, Luigi, Azkaban, etc.) a plus', 'We value development. You will work with some of the smartest and most interesting people in the industry. We are a high-performance organization that is always challenging ourselves to continuously grow. We maintain a growth mindset in everything we do and invest deeply in employee development through formalized mentorship, LinkedIn Learning tracks, and other internal programs. We also provide all employees with reimbursement for relevant conferences, training, and education.', 'We care about your physical, financial and mental well-being. We offer competitive health, dental, and vision benefits for employees and their dependents, a monthly gym reimbursement to support your physical health, and a commute or internet allowance to make your trips to your office or your desk easier. We offer generous parental leave with transition time built-in upon return to work. We offer competitive compensation and a 401k plan with up to a 4% employer match.', ""We support our remote employee experience. While we have great office spaces in NYC, Cambridge and Palo Alto, we're very distributed—we use a number of communication tools to connect across the company—and all remote employees have the opportunity to visit our offices and meet their teams face-to-face at team offsites. We also have an annual company offsite, Shark Week, to get quality in-person time with the entire company at least once a year. We also allow employees to outfit their workstations to meet their needs—whether remote or in office."", 'We value diversity and inclusivity. We are an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.']",2020-08-08 12:54:33
Big Data Engineer Assistant (internship),INTLMAEC,N/A,"San Jose, CA","['Monday to Friday', 'Bonus Pay', 'Signing Bonus', 'One location', '20-29', '9AM', '6PM', 'Pay', 'Temporarily due to COVID-19']",2020-08-08 12:54:33
Senior Data Engineer,Mprogen Systems,N/A,"Dallas, TX","['Build and maintain large-scale batch and real-time ETL pipelines in a Google Cloud Platform architecture (BigQuery, Dataproc, Firestore, etc.).', 'Design and support Data Lakes and Marts in Google CloudStorage, BigQuery, and NoSQL (Google Firestore & MongoDB).', 'Implement high-quality test-driven code, ?participate in code reviews, and own the development of medium-size features.', 'Support business operational activities including generating marketing leads and helping ensure we are meeting our client’s expectations.', 'Collaborate with data scientists and business analysts to enable self-service analytics and reporting.', 'Support Production systems off hours.', '2+ years of industry experience in software development or data engineering.', '2+ years extracting insights from data.', '1+ years of hands-on experience manipulating data and building data pipelines.', 'Hands-on experience with relational and NoSQL databases.', 'Strong appreciation for test-driven development and developing code standards.', 'Strong understanding of Python or Scala. We use Python, Pyspark, and SQL.', 'Understanding of workflow orchestrators (ex. Airflow, Oozie, or Azkaban).', 'Understanding of test-driven development techniques.', 'Ability to proactively communicate and collaborate across a growing distributed team.', 'Help define and manage overall data quality objectives.', 'Implement high-quality source code that passes tests.', 'Achieve and maintain team defined quality thresholds that mitigate solution risks.', 'building large scale batch and real time ETL pipelines: 1 year (Required)', 'extracting insights from data: 2 years (Required)', 'designing and supporting data lakes: 3 years (Required)', 'software development or data engineering: 5 years (Required)', ""Bachelor's (Required)"", 'Yes']",2020-08-08 12:54:33
Data Engineer,Ken Info Systems,N/A,"Portland, OR","['Monday to Friday', 'Python: 1 year (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 12:54:33
About you.,Ken Info Systems,N/A,"Portland, OR","['Bachelor’s or foreign equivalent degree in Computer Science, Computer Engineering, a closely related engineering discipline, or a related field.', '5+ years of professional experience in: software development and/or data engineering; and in working with relational databases, including MySQL, Mongo, or a similar program.', 'Must include one year of experience using Python or Java.', 'Demonstrated knowledge of SQL.']",2020-08-08 12:54:33
Data Engineer,"Double Line, Inc.",N/A,"Austin, TX 78758","['Think creatively and help other data experts on the team figure out the solution to really tough data load or transformation problems', 'Leverage SQL, data mapping, and data modeling experience to manage and organize our customer education data', 'Be obsessed about continuously improving our approach and doing it better and faster the next time', 'Consultancy experience with a focus on Agile practices', 'AWS and Azure Cloud', 'Python or similar scripting languages', 'AWS Quicksight, Tableau, Power BI, or other visualization tools', 'Soak up knowledge from the existing team of experts in the first 30 days', 'Bring fresh eyes to our processes and techniques and bring new ideas to the table in the first 2 months', ""Grow your skills so much that you're ready to teach the next new hire by 2021"", 'A mission-driven company with a long-term focus on helping the world by untangling the technical messes that hold back education in our country', 'A home where your voice matters, and you can effect real change', ""A company who cares about you, makes sure you're engaged with exciting work and provides medical benefits, 401k, and a great culture.""]",2020-08-08 12:54:33
Data Engineer,Aretove,N/A,"New York, NY","['In consultation with the project leadership perform data collection from various upstream and downstream systems.', 'Build and optimize new and existing processes supporting data transformation, data structures, meta data, dependency and workload management.', 'Execute extract, transform and load (ETL) operations on large datasets including data identification, mapping, aggregation, cleansing and analyzing.', 'Create data pipeline by connecting to and ingesting data from third party databases and APIs.', 'Ability to clearly articulate and present data, deliver insights and recommendations to business stakeholders.', 'Bachelor’s degree or professional experience in a related field.', 'You enjoy wrangling huge amounts of data and exploring new data sets.', 'Strong analytic skills and ability to transform unstructured into structured data.', 'Proficient in writing SQL queries.', 'Ability to work independently, deal well with ambiguous and undefined problems.', 'Ability to work in a fast-paced and agile environment.']",2020-08-08 12:54:33
Senior Data Engineer,Funded.club,N/A,Remote,"['Experience with setting up and operating data pipelines and data wrangling procedures using Python and/or SQL', 'Collaborate with engineers and business customers to understand data needs (batch and real time), capture requirements and deliver complete BI solutions', 'Design and build data extraction, transformation, and loading processes by writing custom data pipelines', 'Design, implement and support a platform that can provide ad-hoc access to large datasets and unstructured data', 'Model data and metadata to support ad hoc and pre-built reporting', 'Tune application and query performance using performance profiling tools and SQL', 'Build data expertise and own data quality for assigned areas of ownership', '7+ years of experience in using SQL and databases in a business environment', '6+ years of experience in cloud environment, distributed systems, system automation, and real-time platform', '5 + years production experience with cloud technologies such as Google Cloud Platform (GCP), Azure and Amazon Web Services Redshift (AWS)', '5+ years of experience in custom ETL design, implementation, and maintenance', '5+ years of experience with data warehouse schema design and data modeling', 'Production level experience with Python, SQL, and shell scripting', 'Experience with cloud databases.', 'Experience with batch and stream processing', 'Experience with building large scale data processing systems', 'Solid understanding of data design patterns and best practices', 'Working knowledge of data visualization tools such as Tableau and Power BI', 'Experience in analyzing data to identify deliverables, gaps, and inconsistencies', 'Familiarity with agile software development practices and drive to ship quickly', 'Experience leading change, taking initiative, and driving results', 'Effective communication skills and strong problem-solving skills', 'Proven ability and desire to mentor others in a team environment', ""Bachelor's degree from four-year College or university in Computer Science or related field"", 'Experience with Apache Kafka (with Confluent a plus)', 'Experience with microservice platforms, API development, and containers.', 'Experience with Apache Airflow', 'Retail vertical production experience']",2020-08-08 12:54:33
Junior GIS Data Engineer,Xentity Corporation,4.1 out of 5,"Golden, CO 80402","['Job', 'Company', 'GIS -Strong foundation in GIS Principles and experience working with and manipulating GIS data - 1 yr', 'Python for data management, Pandas, Requests, Data Cleaning, Understanding of Metadata and ETL/Data Pipelines', 'Cloud: BootCamp level or project experience in AWS, GCP, or other major clouds', 'We prefer more data processing experience in data feeds, geospatial data, and data scripts over management of information systems.', 'Demonstration of handling, manipulating data, records, feeds', 'General knowledge familiarity of use patterns in services, analytics, applications, dashboards and other use by data scientist', 'Data : Open and Public Data Experience, REST APIs for Data Services', 'Geospatial : ESRI ArcGIS Server, ArcGIS Online, Open Data Hub, QGIS, GDAL, ArcPy, GeoPandas', 'Programming Languages: NodeJs, ArcPy', 'Database Technology: PostgreSQL', 'Cloud Experience: AWS ECS, EC2, S3 hands-on experience, Kubernetes, Docker', 'Tools and Software: Power BI, Tableau, similar, GIT, JIRA', 'Bachelor’s Degree min. Education and 1 years min. experience', 'Must be able to pass basic NACI, background, drug and reference checks', 'Must be local. No Relocation Assistance.', 'Travel None to Rare/In-State', 'Ability to thrive in an energetic, fast-paced environment - learn and become productive quickly and meet team goals, can-do attitude, able to do what it takes to deliver.', 'Ability to work multiple, time-sensitive tasks - Able to rapidly context switch across subject matter, communication and architecture products, and stakeholder audiences.', 'Ability to work independently as well as as part of an integrated team.', 'Excellent oral and written communication skills.', 'Demonstrate strong analytical and critical thinking skills', 'Maintain a Public Data Catalog. Manage an ETL environment to maintain over 300 active dataset updates to a centralized portal, setup new ETL scripts for incoming datasets ~35/year, and manage associated documentation spreadsheets.', 'Assist State Agencies in Making Their Data Public. Work with a wide variety of State Agencies to provide them with the technical support required to keep datasets current on the centralized portal. Publish new datasets (as derived from any given tech stack) to a centralized portal and make them discoverable', 'Cultivate Dataset Back Stories. Curate metadata that conveys context to End Users of Public Data.', 'Data Storytelling, Dashboards, Data Visualizations. Create Public Data stories and demonstrations that show the value of Public Data. Generate content for users to better understand and utilize Public Data.', 'Public and Open Data Evangelism. Explore ways to build content on the benefits of Public Data to communities, and specifically the impact and status of the current state of Public Data in Colorado.', 'Technical Writing. Make updates to process documentation as new technologies are utilized and workflows are improved.', 'GIS Analysis and Tech. Geospatial knowledge required for some data transform work.', 'Assist Government programs with technical support to ETL/data pipeline data into catalog for primarily tabular and geospatial data - some unstructured occurs.', 'Maintain Public Self-service data catalog', 'Develop quality scripts to validate data for tabular and geospatial data.', 'Edit and Curate metadata to support public discovery', 'Provide End user support with data discovery, access, and use requests', 'Support prototyping of Data Storytelling, Dashboards, Data Visualizations for demonstrations', 'Maintain technical documentation of catalog and operations', 'You will be expected to rapidly ramp-up on client lingo, proactively make observations of patterns, anomalies, problems, and be customer service focused.', 'You will be expected to be highly self-motivated and understand you will be held accountable to commitments.', 'We look for decisive individuals able to rapidly respond to change requests and able to communicate, track, and escalate risk.', 'We expect you to be proactive, efficient, and ready to learn quickly in response to all client and team member needs. This is a bootcamp-type position setup for growth.', 'We want you to not only gain technical skills, but also grow your interactive and client facing skills.', 'We will require strong communication and interactive skills - oral, written, visual especially for triaging conflict, ideation barriers, mitigating risk, foster thought diversity and team environment.', 'We expect all our roles to focus on attaining a mastery of their technical level demonstrating fast learning at their role whether that be in architectural methods, languages, work products, consulting techniques, and client culture.', 'We emphasize a balance of work and life and target 40-50 hour weeks with ample time to refresh with great paid-time off.', 'Salary & Bonus Programs - Competitive Salary. Multiple Recognition and Rewards Bonus Programs (Performance Bonus plan reviewed twice annually - total ranging from 2-5% of salary and Business Development Bonus Plan, Employee Referral Bonus Plan, and Company Profit Sharing Plan).', 'Paid Time off - (10) Paid Holidays, (10) Personal Time Off, and (5) Sick Leave', 'Medical Insurance - Coverage for Major Medical and Surgical, Medical Health Care, Dependents’ Health Care with 100% of employee or 80% employee and 50% family. Options to enroll in Dental Insurance, Vision Discount Program, Prescription Discount Program, Group Term Life Insurance, Accidental Death & Dismemberment Insurance, and Professional insurance advisors to guide employees through these benefits as needed.', 'Solid, managed retirement savings plan including - Multiple 401(k) funds with traditional and Roth options, Company paid fees, Company Match, Third-party Trust Management with personalized retirement portfolio web analysis tools.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'GIS data engineer: 1 year (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'One location', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'careers.xentity.com', 'https://www.facebook.com/xentitycorp/', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-08-08 12:54:33
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 12:54:33
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:54:33
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:54:33
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:54:33
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:54:33
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:54:33
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:54:33
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:54:33
Big Data Engineer,"Hierarch Soft Technologies Inc,",N/A,"Franklin Lakes, NJ",[],2020-08-08 12:55:25
Data Engineer,WELL Health Inc.,N/A,California,"['Contribute to the system architecture and infrastructure decision making processes', 'Hands on management of ELT and data stream processes', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies', 'Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', ""Bachelor's degree in Computer Science, Engineering, Mathematics, or a related field"", '2+ Years of Data Warehouse Experience with Oracle, Redshift, PostgreSQL, etc.', 'At least 1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', 'Demonstrated strength in SQL, data modeling, ETL development, and data warehousing', 'Coding proficiency in at least one modern programming language (Python, Ruby, Scala, Java, etc.)', 'Experience with Linux/UNIX', 'Strong interpersonal skills and the ability to communicate complex technology solutions to senior leadership to ensure alignment and drive progress', 'Extensive experience working with AWS with a strong understanding of Redshift, EMR, Athena, Aurora, DynamoDB, Kinesis, Lambda, S3, EC2, etc.', 'Experience with Looker and/or Tableau', 'Experience with NLP', 'Experience with Matillion and/or AWS Glue']",2020-08-08 12:55:25
Big Data Engineer Assistant (internship),INTLMAEC,N/A,"San Jose, CA","['Monday to Friday', 'Bonus Pay', 'Signing Bonus', 'One location', '20-29', '9AM', '6PM', 'Pay', 'Temporarily due to COVID-19']",2020-08-08 12:55:25
Data Engineer,Capital One - US,3.9 out of 5,"McLean, VA","['Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies (Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', ""Master's Degree"", '3+ years of experience in application development', '1+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '1+ years of experience with Ansible / Terraform', '2+ years of experience with Agile engineering practices', '1+ years in-depth experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)', '1+ years of experience with NoSQL implementation (Mongo, Cassandra)', '2+ years of experience developing Java based software solutions', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, Shell)', '2+ years of experience developing software solutions to solve complex business problems', '2+ years of experience with UNIX/Linux including basic commands and shell scripting']",2020-08-08 12:55:25
Data Engineer,Getty Images,3.9 out of 5,"New York, NY","['You have prior experience working as a Data Engineer, preferably in a product or customer-focused organization.', 'You are extremely comfortable working with Python and have a working knowledge of Cloud services and Tools, as well as standard engineering tools such as Git, Linux and SQL.', 'You have experience building streaming and batch data pipelines and are comfortable working within a large-scale distributed environment with open source tools such as Hadoop, Hive, Airflow and Spark.', 'You can independently execute on a project, from ideation to delivery to stakeholders, and can pro-actively interact with other engineers at Getty Images to access necessary resources or data.', 'You understand, or have interest learning about, the real-world advantages and drawbacks of various Machine Learning techniques, and have applied those to a variety of datasets.', 'A M.S. or PhD. in computer science, statistics, economics/econometrics, natural science or any other equivalent quantitative project is preferred. If you are self-taught and believe you are a good fit for this role, or have significant work experience, we would love to hear from you as well.', 'Previous experience in an analytical role, and experience working with teams of Data Scientists and Data Analysts.', 'Experience having managed or contributed to the use of Business Intelligence platforms such as Looker and Snowflake.', 'Experience with Marketing platforms such as Google Analytics and SA 360.', 'Talking with and/or listening to and/or signaling people to convey or exchange information; includes giving/receiving assignments and/or directions.', 'Dealing with individuals with a range of moods and behaviors in a tactful, congenial, personal manner so as not to alienate or antagonize them.', 'Exert up to 20 lbs. of force occasionally, and/or up to 10 lbs. of force frequently.', 'Requires walking or standing to a significant degree.', 'Must be able to remain in a stationary position for long periods of time.', 'Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine, and computer printer.']",2020-08-08 12:55:25
Senior Data Engineer,Mprogen Systems,N/A,"Dallas, TX","['Build and maintain large-scale batch and real-time ETL pipelines in a Google Cloud Platform architecture (BigQuery, Dataproc, Firestore, etc.).', 'Design and support Data Lakes and Marts in Google CloudStorage, BigQuery, and NoSQL (Google Firestore & MongoDB).', 'Implement high-quality test-driven code, ?participate in code reviews, and own the development of medium-size features.', 'Support business operational activities including generating marketing leads and helping ensure we are meeting our client’s expectations.', 'Collaborate with data scientists and business analysts to enable self-service analytics and reporting.', 'Support Production systems off hours.', '2+ years of industry experience in software development or data engineering.', '2+ years extracting insights from data.', '1+ years of hands-on experience manipulating data and building data pipelines.', 'Hands-on experience with relational and NoSQL databases.', 'Strong appreciation for test-driven development and developing code standards.', 'Strong understanding of Python or Scala. We use Python, Pyspark, and SQL.', 'Understanding of workflow orchestrators (ex. Airflow, Oozie, or Azkaban).', 'Understanding of test-driven development techniques.', 'Ability to proactively communicate and collaborate across a growing distributed team.', 'Help define and manage overall data quality objectives.', 'Implement high-quality source code that passes tests.', 'Achieve and maintain team defined quality thresholds that mitigate solution risks.', 'building large scale batch and real time ETL pipelines: 1 year (Required)', 'extracting insights from data: 2 years (Required)', 'designing and supporting data lakes: 3 years (Required)', 'software development or data engineering: 5 years (Required)', ""Bachelor's (Required)"", 'Yes']",2020-08-08 12:55:25
Data Engineer,Caserta,N/A,"New York, NY","['Develop Cloud enabled Data and Analytics solutions', 'Development of cloud-based and hybrid data warehouses & business intelligence platforms', 'Build Data Pipelines to ingest structured and unstructured Data.', 'Gain hands-on experience with new data platforms and programming languages', '3-5+ years of experience working in Data Engineering or Data Warehousing', 'Hands-on experience with leading commercial Cloud platforms, including AWS, Azure, or Google', 'Experience building data warehousing, data ingestion, and data profiling', 'SQL & Python skills', 'Strong aptitude for learning new technologies and analytics techniques', 'Highly self-motivated and able to work independently as well as in a team environment', 'Understanding of agile project approaches and methodologies', 'Experience working with Business Stakeholders to elicit business requirements', 'Experience building and migrating complex ETL pipelines', 'Bachelor’s degree in Business Analytics, Computer Science or a closely related field required']",2020-08-08 12:55:25
Data Engineer,Homesite Insurance,3.2 out of 5,"Boston, MA","['Develop, maintain, and enhance databases throughout the organization to support analytics projects', 'Understand corporate data structure to be able to draw data from transactional data tables existing in the company', 'Support the acquisition of external data sets, interpreting data layouts, structures, fields and values to incorporate new data into the core analytics data base', 'Analyze databases for performance optimization, including data normalization, indexing, and memory management', 'Assist in determining how image recognition techniques and artificial intelligence can be utilized to further the core business', 'Work closely with the Modeling and Data Science teams to determine where gaps and opportunities lie', 'Clearly communicate complex findings to colleagues and external customers', 'Monitor the results of statistical models through the use of dashboards and ad hoc analyses']",2020-08-08 12:55:25
Data Center Engineer I,"JPMorgan Chase Bank, N.A.",3.9 out of 5,"Totowa, NJ","['Job', 'Company', 'Ability to identify problems and clearly communicate strategic solutions to clients', 'Desire to develop a working knowledge of change management, corporate IT audit processes, IT risk management, technical problem resolution, operations systems, and data sources knowledge', 'Strong initiative and desire to learn', 'Ability to effectively collaborate with team members and clients to achieve common goals', 'Good knowledge of Windows/MAC OS with the ability to carry out root cause analysis', 'Working knowledge of Microsoft Office products', 'Strong analytical and problem resolution skills', 'Understanding of information technology concepts in a working or academic environment', 'General knowledge of a physical IT infrastructure (server, networking, storage)', 'Some understanding of network concepts (switching, routing, perimeter security)', 'Some understanding of operating systems (Windows, Linux, AIX)']",2020-08-08 12:55:25
Data Engineer,Novu LLC,4.5 out of 5,"Saint Louis Park, MN 55416","['Health care industry experience, including integration and claims/grouped file processing a plus', 'Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift, Glue, Lambda', 'Prior experience with traditional ETL tools like Talend Open Studio, Pentaho or similar is a plus', 'Work with Data Scientists, Business Intelligence developers, and Product Owners to understand business requirements and specific data related issues', 'Experience with APIs and bulk-load patterns to capture data from multiple data sources', 'Analyze and implement automated data quality certification processes as part of the ETL framework', 'Ability to develop new skills and evolve within an entrepreneurial organization', 'Exposure to big data processing with Spark or other big data tools is a plus', 'Exemplify High Value Behaviors', 'Other duties as assigned', '4+ years experience in a technical role with experience in Data Ingestion, ETL development and engineering in a Cloud-based infrastructure', 'Exceptional SQL skills', 'Experience with database management, modeling and data warehouse operations', 'Ability to use programming/scripting languages such as Java/Python/Scala to import, export, and manage data', 'Maintain data warehouse and data lake operations through automated workflows, monitoring, and reporting tools', 'Basic Linux skills and understanding of open source software', 'Experience with Agile development teams and SaaS platforms', 'Ability to effectively communicate and engage with all service stakeholders, both internal and external, to understand business requirements and specific data-related issues', 'Abide by and enhance security practices within Data Warehouse operations', '100% company paid Medical AND Dental insurance with low deductibles ($500 singles, $1,500 family)', '401k program with a 35% company match, uncapped, and 100% vested upon enrollment', 'Optional FSA, Pet insurance, Disability, Vision, and more', 'Equal paternity and maternity leave', 'Onsite wellness coach committed to helping our employees live their healthiest lifestyle', 'Work-life balance', '$5,000 employee referral bonus program', 'A multi-award winning office culture', 'The list goes on, apply to learn more!']",2020-08-08 12:55:25
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 12:55:25
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:55:25
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 12:55:25
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:55:25
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:55:25
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:55:25
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:55:25
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:55:25
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:55:25
Senior Data Engineer II,Auth0,N/A,Remote,"['Contributing at a senior-level to the data platform design by implementing a solid, robust, extensible design that supports key business flows.', 'Performing all of the necessary data transformations to populate data lake.', 'Establishing efficient design and programming patterns that beat SLAs and help easily manage the data platform.', 'Designing, integrating and documenting technical components for seamless data extraction and analysis.', 'Adopting best practices in our data systems and shared across teams.', 'Contributing to innovations and data insights that fuel Auth0’s mission.', 'Working in a team environment, interacting with multiple groups on a daily basis (very strong communication skills).+ BA/BS in Computer Science, related technical field or equivalent practical experience.', 'At least 3 years of relevant work experienceAbility to write, analyze, and debug SQL queries.', 'Exceptional Problem solving and analytical skills.', 'Experience with Data Warehouse design, ETL (Extraction, Transformation & Load), architecting efficient software designs for DW platform.', 'Hands-on experience in Python, R, Apache Spark in production environments.', 'Strong skills in Apache Airflow, Luigi or similar tools.', 'Experience in Tableau, Apache SuperSet, Looker or similar BI tools.', 'Knowledge of AWS Redshift, Snowflake or similar databases']",2020-08-08 12:56:15
Azure Data Engineer,Expedite Technologies Solutions,N/A,"Dayton, OH","['8 Hour Shift', 'Spark Cluster: 3 years (Required)', 'Data Lake: 3 years (Required)', 'HDinsight: 2 years (Required)', 'Data Bricks: 3 years (Required)', '1 year', 'More than 1 year', 'Varies', 'Likely', 'Yes']",2020-08-08 12:56:15
Data Specialist,Construction Journal,N/A,Remote,"['Heavy outbound calling to owners, architects, engineers, and general contractors to obtain specific construction project information.', 'Developing relationships with Construction Managers, Architects, and Engineers to obtain notice of construction projects in conception and planning phases.', 'Collect, process, and input information provided from public offices of zoning notices, site plan approvals, newspaper articles for potential construction projects being considered.', 'Obtaining, plans, specifications, and bidders/plan holders list on out to bid projects.', 'Computer Proficiency with ability to type 55 WPM.', 'Professional work ethic and can-do attitude.', 'Excellent written and verbal communication skills.', 'Strong organizational skills with the ability to meet daily and weekly deadlines.', 'Ability to work independently in a fast-paced environment that also requires strong team work.', 'Advanced education preferred or previous industry work experience.', 'Knowledge in the construction industry is a plus, but is not a requirement.']",2020-08-08 12:56:15
"Data Engineer, CX Journeys (Tysons Corner)","Medallia, Inc.",4.2 out of 5,"Tysons Corner, VA","['Architect, implement, and deploy new data models and data processes in production', 'Perform data analysis to generate business insights', 'Interface with Engineers and Product Managers to understand product goals and data needs', 'Build data expertise and own data quality for allocated areas of ownership', 'Support critical data processes running in production', 'Collaborate with customers in assembling large, complex data sets that meet functional business requirements', ""Bachelor's degree in CS, EE or MIS; or equivalent experience"", 'Strong Software Engineering skills', 'Programming knowledge in Python or R', 'Knowledge of SQL', 'Knowledge of database systems', 'A team player, fast learner, with a focus on getting things done', '2+ years experience in custom ETL design, implementation and maintenance.', '2+ years experience in writing SQL statements', 'Experience with Linux', 'Experience with JavaScript, JSON']",2020-08-08 12:56:15
Azure Data Engineer,Infotree Global,N/A,"Seattle, WA","['7+ years’ development experience on end to end BI development – Backend Data Engineering + Reporting using Power BI', '5+ of SQL Server development experience writing complex stored procedures, triggers, views, etc.', 'Strong understanding of BI areas. Ability to work in large, complex development BI projects', 'Strong experience on Big Data Technologies especially on Azure – Azure Databricks, ADWH / ADL, Spark, Cosmos (Microsoft) with strong foundation in SQL', 'Knowledge of at least one programming language (e.g. Python, C#)', 'Strong Analytical and troubleshooting skills', 'Excellent coding and debugging skills.', 'Able to work independently to implement a solution with minimal guidance', 'Ability to communicate with Business and developers accordingly.', 'Strong communication skills in both written and spoken English.', 'Excellent communication skills and ability to work under continual deadline constraints are necessary, show agility towards meeting business needs', 'BI Development : 7 years (Required)', 'Power BI : 2 years (Required)', 'Azure experience: 4 years (Required)', 'Big Data : 2 years (Required)', 'Sql Server: 10 years (Required)', 'What is your work authorization in US?', 'Yes']",2020-08-08 12:56:15
Kafka Data Engineer (remote),Thrivent Financial,3.9 out of 5,"Boston, MA 02108","['Partner on the design, deployment, and persistence of our new streaming platform unifies the data across organization, using Confluent Kafka.', 'As the senior level Engineer, you will be leading a group of engineers.', 'Design, Develop, Release & Support containerized microservices (OpenShift / Spring Boot) to transform and enrich topic data.', 'Lead reusable design and patterns for services and data processes within the platform.', 'Partner on setting standards, implementing tools, and creating documentation for self-serve data pipeline services supporting core engineering and professional services use cases.', 'Work with existing engineering teams to become data producers and consumers to and from Confluent Kafka.', 'Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.', 'Apply business knowledge and experience to effectively advise others on technology as an enabler.', 'Lead efforts to analyze IT industry and market trends and determine potential impacts.', 'Develop concepts and constructs necessary to create technology-enabled business systems.', 'Influence technology direction.', 'Provides thought leadership and execution to large complex efforts.', 'Utilize breadth of technical understanding and dive deep when necessary.', 'Consult on and manage initiatives to ensure alignment across multiple business and IT areas.', 'Proactively mitigate risks across multiple assets, information domains, technologies & platforms.', 'Provide leadership, mentoring and technical guidance to others to drive initiatives.', 'Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.', 'Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.', 'Act as a change agent to continuously improve and move the organization forward.', 'Accountable to provide leadership to successfully deliver the right results on initiatives in a timely and effective manner.', 'Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.', 'Ability to work within a diverse team of skillsets and experience levels to deliver results.', 'Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field.', '5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years of lead experience.', 'Strong experience with event streaming such as (Kafka or Amazon Kinesis).', 'Experience with SQL and NoSQL databases (PostgreSQL, MongoDB, etc).', 'Proficient delivering services within AWS.', 'Experience with Confluent Kafka, OpenShift / SpringBoot is preferred.', 'Demonstrated ability to develop containerized microservices (Docker with Kubernetes) is preferred.', 'The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences.', 'Desire to show ownership of problems you identify and proven ability to empower others to get more done.']",2020-08-08 12:56:15
Systems Engineer,"Amazon Web Services, Inc.",3.6 out of 5,Remote,"['3+ years of experience developing on AWS including setup, integration, and maintenance of AWS services (S3, Redshift, Glue, and SES)', '3+ years of experience writing and using advanced SQL', '3+ years of experience coding in Python including familiarity with Spark and Scala', '3+ years of experience querying and extracting data from APIs', 'Degree in Computer Science, , Data , Analytics, or a related field, or 4+ year’s equivalent hands-on industry experience', 'Position may be located virtual United States only.', 'Demonstrated ability to manage multiple competing priorities simultaneously and drive projects to completion', 'Able to influence decisions through effective verbal and written communication and logical reasoning', 'Proficiency with Tableau', 'Proficiency with Apache Airflow', 'Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets', 'Experience building data products incrementally and integrating and managing datasets from multiple sources', 'Experience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, etc.', 'Experience providing technical leadership and mentorship to other engineers for the best practices in the systems space', 'A desire to work in a collaborative, intellectually curious environment']",2020-08-08 12:56:15
"Software Engineer, Data",Springbuk Inc,N/A,Remote,"['Design and build high-quality features for the Springbuk health intelligence platform', 'Deliver code consistent with our standards and processes', 'Keep the code healthy, fix bugs, debug and troubleshoot', 'Write automated unit and integration tests', 'Participate in all scrum ceremonies with your team', 'Collaborate with your team to break down, refine, and estimate tasks', 'Learn from code review feedback', 'Review other engineers’ code and provide constructive feedback', 'Work in our stack of React, Ruby on Rails, Python, PostgreSQL, Redis, and Elasticsearch running on Amazon Web Services', 'Our Data Engineering team is responsible for building and operating the data pipeline that ingests and enriches healthcare data for our customers and partners.', 'Analyze healthcare data from a variety of sources and model that data in the Springbuk platform', 'Use Python and SQL to implement tools that transform source data into common format', 'Build and maintain the data pipeline framework that orchestrates ingestion, normalization, and enrichment of data', 'Build tools to automate and monitor data operations', 'Operate those tools to ensure data is properly transformed and loaded', 'Investigate, diagnose, and fix problems with customer data', 'Design and build improvements to our data pipeline to prevent errors', 'Experience developing software, either professionally or in an academic setting', 'Excellent problem solving and critical thinking skills', 'Excellent communication skills with technical and non-technical teammates', 'Fundamental understanding of web applications', 'Understanding of working with data and relational databases', 'Ready to work on an agile team: short iterations, issue tracking, version control, QA, etc.', 'Ready to work in a continuous delivery environment', 'Ready to work at a dynamic scale-up company with a SaaS product']",2020-08-08 12:56:15
Data engineer // Pyspark,Akshaya Inc,N/A,"San Diego, CA 92121","['401(k)', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:56:15
Data Engineer II,SurveyMonkey,4.1 out of 5,"Portland, OR 97209","['Design, architect and build data pipes to support existing data models', 'Data quality: build quality checks in the end to end data pipelines', 'Build new Data models (fact vs dimension). Write performant/idempotent transformations in Snowflake sql.', 'Build data pipeline using Python scripting (in a modular/loop context) Write well-tested, production ready code in Python and/or Snowflake SQL', 'Hands-on experience implementing ETL (or ELT) best practices', 'Translate business requirements, to technical specifications, form project scope, and deliver deployable code.', 'Write complex data engineering Snowflake - SQL jobs that perform sophisticated queries on the entirety of our datasets', '5+ years experience in data engineering in Snowflake or SQL server', 'Experience in scheduling, automating and deploying production data pipelines using Airflow/Luigi, etc', 'Experience with tools such as dbt, matallion or other similar technologies', 'Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function', 'In depth knowledge of Datalakes, EDW concepts, data modeling (star, snowflake and galaxy schemas)', '3+ years writing code in any OOP capable language, ideally Python', 'Job scheduling and workload management tools (Airflow etc)', 'Experience with ETL tools (Talend, Informatica, Matillion, Fivetran, DBT etc.).']",2020-08-08 12:56:15
Senior Data Engineer,Crown Media Family Networks,3.5 out of 5,"Studio City, CA 91604","['Develop high quality, reliable and fault tolerant data solutions based on internal and external customers/users’ requirements, applying best practices and new trends/technologies all along the solution lifecycle. ETL tool of preference is Pentaho Data Integration (PDI).', 'Integration of external data into data warehouses using REST API and web services among others.', 'Delivery of data to internal customers and external vendors through different data formats (CSV, Excel, XML, JSON) and delivery methods (ex. Email, SFTP, S3, etc.), including REST API.', 'Provide daily monitoring, management, troubleshooting and issue resolution to existing and new data solutions and systems’ interfaces affected by them.', 'Follow and implement Agile Best Practices for Data Warehousing.', 'Support the Business Intelligence team through delivery of reliable and timely data.', 'University degree in computer science, college diploma, technical certification, equivalent relevant academic qualifications or a minimum of 5 years of professional experience.', 'Proficiency as an advanced SQL Programmer/Analyst/Data Warehouse practitioner, with experience in analysis, programing, technical documentation, unit testing and training.', 'Proficiency with SQL DML (Data Manipulation Language) with special focus on query tuning/performance.', 'Experience with AWS ecosystem (Data Lake Formation, Glue, Data Pipelines, EC2, Redshift, S3, Glacier, DynamoDB, Lambda, etc.)', 'Background on Data Modeling and Data Warehouse design (Methodologies: Kimball, OLAP, EDW).', 'Proficiency with ETL programming tools (preferably Pentaho PDI), jobs and scheduling management.', 'Experience with reporting, visualization and dashboarding solutions using Tableau or similar.', 'Experience with Version Control Systems. Tool of preference is git.', 'Experience with JSON, XML, CSV and other data formats. Experience with Python is a plus.', 'Experience with Project Management, SDLC & CI/CD methodologies.', 'Experience and ability to lead a team of Data Engineers/ETL Developers as well as work as a team-member and with minimal supervision.', 'Experience on NoSQL or non-relational DBMS is a plus.', 'Curious, self-motivated and autodidact, always keeping up to date with the latest ETL/BI tools and technologies.', 'Organized, meticulous and quality oriented.']",2020-08-08 12:56:15
"Data Engineer II, Amazon Fuse",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', ""Bachelor's degree or higher in a quantitative/technical field (e.g. Computer Science, Economics, Finance, Mathematics, Statistics, Engineering)."", '5+ years of relevant experience one of the following areas: data science, data engineering, business intelligence or business analytics.', 'Strong analytical and problem-solving skills.', 'Expertise in the design, creation and management of large datasets/data models.', 'Expert-level proficiency in writing complex, highly-optimized SQL queries across large datasets.', 'Ability to work with business owners to define key business requirements and convert to technical specifications.', 'Ability to manage competing priorities simultaneously and drive projects to completion.', 'Develop and maintain data sets to measure the performance of the program. This will include building metrics for High Value Actions, engagement, acquisition and landscape.', 'Build, maintain and optimize scalable self-service solutions that empower stakeholders to address their data needs.', 'Development of new Fuse back-end calculation engine to support invoicing and bounty payment automations.', 'Liaising with technology teams across Amazon to influence data model designs and data sharing. This may include writing papers to influence executive decisions.', 'Assist business stakeholders in creating and implementing business requirement documents to drive projects, working backward from customer needs.', 'Implement standardized, automated operational and quality control processes for difficult datasets to deliver accurate and timely data and reporting to meet or exceed SLAs', 'Communicate timely information to all stakeholders on current and future initiatives, prioritizing based on the organization’s needs', '7+ years of experience as a data engineer, BI Engineer, Business/Financial Analyst or Systems Analyst in an internet-based company with large, complex data sources.', 'Experience with AWS services including S3, Redshift, EMR and RDS.', 'Knowledge with statistical and/or econometric modeling.', 'Experience in BI/DW as a change leader providing strategic research, recommendations, and implementations.']",2020-08-08 12:56:15
Kafka Data Engineer (remote),Thrivent,3.9 out of 5,"Boston, MA","['Partner on the design, deployment, and persistence of our new streaming platform unifies the data across organization, using Confluent Kafka.', 'As the senior level Engineer, you will be leading a group of engineers.', 'Design, Develop, Release & Support containerized microservices (OpenShift / Spring Boot) to transform and enrich topic data.', 'Lead reusable design and patterns for services and data processes within the platform.', 'Partner on setting standards, implementing tools, and creating documentation for self-serve data pipeline services supporting core engineering and professional services use cases.', 'Work with existing engineering teams to become data producers and consumers to and from Confluent Kafka.', 'Oversee and direct efforts to identify information and technology solutions that enable business needs and strategies.', 'Apply business knowledge and experience to effectively advise others on technology as an enabler.', 'Lead efforts to analyze IT industry and market trends and determine potential impacts.', 'Develop concepts and constructs necessary to create technology-enabled business systems.', 'Influence technology direction.', 'Provides thought leadership and execution to large complex efforts.', 'Utilize breadth of technical understanding and dive deep when necessary.', 'Consult on and manage initiatives to ensure alignment across multiple business and IT areas.', 'Proactively mitigate risks across multiple assets, information domains, technologies & platforms.', 'Provide leadership, mentoring and technical guidance to others to drive initiatives.', 'Facilitate communications that involve obtaining cooperation and agreement on issues that may be complex or controversial.', 'Utilize negotiation and persuasion to come to agreement and to effectively form partnerships.', 'Act as a change agent to continuously improve and move the organization forward.', 'Accountable to provide leadership to successfully deliver the right results on initiatives in a timely and effective manner.', 'Direct the work of others to lead initiatives that cross multiple assets, technologies, platforms, departments and vendors.', 'Ability to work within a diverse team of skillsets and experience levels to deliver results.', 'Bachelor’s degree or equivalent experience in MIS, Computer Science, Mathematics, Business or related field.', '5+ years of experience in Technology related field including prior lead experience. For the senior level position require 8+ years of experience including 3+ years of lead experience.', 'Strong experience with event streaming such as (Kafka or Amazon Kinesis).', 'Experience with SQL and NoSQL databases (PostgreSQL, MongoDB, etc).', 'Proficient delivering services within AWS.', 'Experience with Confluent Kafka, OpenShift / SpringBoot is preferred.', 'Demonstrated ability to develop containerized microservices (Docker with Kubernetes) is preferred.', 'The ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences.', 'Desire to show ownership of problems you identify and proven ability to empower others to get more done.']",2020-08-08 12:56:15
"Data Engineer, SCPR",Southern California Public Radio,4.5 out of 5,"Pasadena, CA","['Architect and work to develop a data lake integrating member and contact data from Salesforce, our content management systems, audience acquisition databases and other internal systems.', 'Proactively identify opportunities to improve data integrations and data security.', 'Understand business and technology goals; present options and considerations in solution development and problem solving, being mindful of the cost/benefit prospect of developing quickly versus developing for long term sustainability.', 'Support and train non-technical personnel in editorial, events, marketing, underwriting and membership.', 'Other duties as assigned.', 'Bachelor’s Degree or equivalent work experience', '3+ years of work experience in a full-stack and/or CRM development capacity', 'Proven experience building integrations between disparate data platforms and CRMs', 'Experience with architecting, development and performance tuning of relational databases', 'Experience in working with large-scale, consumer-oriented websites', 'Experience working with content management systems', 'Experience with version control, code base maintenance and peer review', 'Expertise writing queries in SQL and NoSQL', 'Experience with relational, non-relational and columular databases', 'Experience building and consuming REST and SOAP APIs', 'Experience with cloud-based infrastructure (AWS and GCP prefered)', 'Excellent communication skills, especially around technical requirements', 'Ability to interpret user needs, draft requirements and provide accurate work estimates', 'Proven ability to work as an individual contributor', 'Experience writing object-oriented code, preferably in Ruby and/or PHP', 'Experience writing in scripting language, such as Python or JavaScript', 'You care about the details', 'You excel in an interdisciplinary team. You seek perpetual growth', 'You have a desire to understand and try out new technologies', 'You find working creatively with constraints around resources, time, and ambiguity exciting', 'Must be able to perform the essential duties of the position with or without reasonable accommodation.', 'Physical Demands:May be required to work from homeRequired to walk, sit, and stand; reach with hands and arms; balance, stoop, kneel, or crouchFrequent use of hands for data entry/keystrokes and simple grasping.Required to move about in an office environment and sit for extended periods of timeFrequent use of hands for data entry/keystrokes and simple grasping', 'Working Conditions:Moderate noise levelOccasional exposure to prevalent weather conditions']",2020-08-08 12:56:15
Sr. Data Engineer - HBO Max,HBO Max,N/A,"New York, NY","['Strong experience in developing, constructing, testing, and maintaining existing and new architectures.', 'Responsible for aligning architecture with business requirements.', 'Ability to identify ways to improve data reliability, efficiency, and quality.', 'Responsible for preparing data for predictive and prescriptive modeling.', 'Ability to deploy sophisticated analytics programs, machine learning and statistical methods.', 'Conduct research for industry and business questions that come up.', 'BS or MS degree in computer science or related field and direct experience in Data / Engineering / Application lifecycle.', 'Minimum of 4-5 years of experience in data science engineering, with big data tools like Hadoop and Spark.', 'Robust experience with relational SQL and NoSQL databases like MongoDB, DynamoDB, Redshift/PostGRE, mariaDB, etc.', 'Experience with data pipeline and workflow management tools like airflow or alternatives.', 'In depth experience and knowledge with AWS cloud services: S3, EC2, EMR, RDS, Redshift, Lambda, API-Gateway, AWS GLUE, etc.', 'Experience with stream-processing systems: Spark-Streaming, AWS Kinesis, Kinesis Firehose etc.', 'Must be experienced with object-oriented/object function scripting languages: Python, Java, Scala, etc.', 'Preferred experience of 3+ years of minimum experience with Python, Data Warehouse, Linux/Bash scripting development, Software Development Cycle and Data Modeling a must.', 'Exclusive WarnerMedia events and advance screenings', 'Paid time off every year to volunteer', 'Access to well-being tools, resources, and freebies', 'Access to in-house learning and development resources', 'Part of the WarnerMedia family of powerhouse brands']",2020-08-08 12:56:15
Senior Data Engineer,Funded.club,N/A,Remote,"['Experience with setting up and operating data pipelines and data wrangling procedures using Python and/or SQL', 'Collaborate with engineers and business customers to understand data needs (batch and real time), capture requirements and deliver complete BI solutions', 'Design and build data extraction, transformation, and loading processes by writing custom data pipelines', 'Design, implement and support a platform that can provide ad-hoc access to large datasets and unstructured data', 'Model data and metadata to support ad hoc and pre-built reporting', 'Tune application and query performance using performance profiling tools and SQL', 'Build data expertise and own data quality for assigned areas of ownership', '7+ years of experience in using SQL and databases in a business environment', '6+ years of experience in cloud environment, distributed systems, system automation, and real-time platform', '5 + years production experience with cloud technologies such as Google Cloud Platform (GCP), Azure and Amazon Web Services Redshift (AWS)', '5+ years of experience in custom ETL design, implementation, and maintenance', '5+ years of experience with data warehouse schema design and data modeling', 'Production level experience with Python, SQL, and shell scripting', 'Experience with cloud databases.', 'Experience with batch and stream processing', 'Experience with building large scale data processing systems', 'Solid understanding of data design patterns and best practices', 'Working knowledge of data visualization tools such as Tableau and Power BI', 'Experience in analyzing data to identify deliverables, gaps, and inconsistencies', 'Familiarity with agile software development practices and drive to ship quickly', 'Experience leading change, taking initiative, and driving results', 'Effective communication skills and strong problem-solving skills', 'Proven ability and desire to mentor others in a team environment', ""Bachelor's degree from four-year College or university in Computer Science or related field"", 'Experience with Apache Kafka (with Confluent a plus)', 'Experience with microservice platforms, API development, and containers.', 'Experience with Apache Airflow', 'Retail vertical production experience']",2020-08-08 12:56:56
Data Engineer,The Bail Project,N/A,"Marina del Rey, CA 90292","['Support with the development of data modeling strategy and design standards', 'Develop data pipelines to extract, transform, clean, and audit data from external systems into a cloud-based data warehouse', 'Monitor Extract-Transform-Load (ETL) jobs and troubleshoot operational or data issues in the data pipelines', 'Document analytical workflows and contribute to data dictionary', 'Prepare complex database queries to support research and advocacy initiatives', 'Excellent attention to detail and high concern for data quality', 'Commitment to working toward common goals in a small team setting', 'Proficiency with Python or similar programming languages', 'Proficiency with database query languages (e.g., SQL)', 'Demonstrated experience with ETL (Extraction, Transformation & Loading)', 'Familiarity with cloud platforms (e.g., AWS)', 'Why do you want to work for The Bail Project?', 'Share an example of a time when you learned a new technology to solve a data engineering problem']",2020-08-08 12:56:56
Cloud Big Data Engineer,Digital dhara,N/A,"McLean, VA","['AWS Certification : 3 years (Required)', 'Big Data : 10 years (Required)', ""Bachelor's (Preferred)""]",2020-08-08 12:56:56
Cloud/Data Engineer,Nasdaq,N/A,"New York, NY 10036","['Good understanding of Big data technologies – Spark SQL', 'Programming SPARK in Scala', 'Proficiency in SQL', 'Strong data analysis and troubleshooting skills', 'Regularly interacts with Business ,Data Vendors and Cloud DevOps Team', 'Domain knowledge of Capital Market is plus', 'Knowledge of shell scripts and other languages including Python, R, Java is plus', 'Unit testing/verification of new development', 'Work with QA Test analyst to ensure test coverage (Including Integration & Regression testing)', 'Develops new program logic and/or assembles standard logic modules to create new applications', 'At least 2 years of hands on experience on Big Data Engineering on AWS', 'Minimum 1 year experience with Spark, Scala', 'Must be able to write complex sql queries', 'Experience with RDB and sql server databases (Could be MS or Oracle…)', 'Experience with Large data sets', 'Excellent teamwork/collaboration skills', 'Excellent communication skills (Written & Oral)', 'Good knowledge of linux OS, shell scripting', 'Experience working on complex distributed information systems', 'Experience with version control systems, preferable SVN, GIT.', 'Strong work ethic in a mission-critical 24x7 diverse environment with multiple vendor/customer relationships.', 'AWS Certification is plus', 'Preferred – Experience with Financial Markets (options a plus)', 'Preferred – Working knowledge of various Financial Market data feeds', 'Beneficial having experience with log aggregation tools such as Elasticsearch, Splunk, Datadog, etc', 'Must be able to work Saturdays and rotational schedule', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'SQL: 2 years (Required)', 'Spark and Scala: 2 years (Required)', 'New York, NY 10036 (Required)', 'No: Not providing sponsorship for this job', 'Temporarily due to COVID-19']",2020-08-08 12:56:56
Production Assistant,Mishimoto,3.4 out of 5,"New Castle, DE","['Manage the planning and scheduling of identified product development projects.', 'Assist Project Managers in finding and scheduling donor vehicles for R&D.', 'Make updates and provide reports on a regular basis from TM2, the companies project management system.', 'Prepare agendas and take minutes of weekly production meetings.', 'Update department metrics.', 'Preparation and shipment of samples.', 'Pick up shop supplies at local auto-parts stores as needed.', 'Learn and administer all process around Patent applications and maintenance.', 'Carry out tasks as assigned by VP of Production. Examples of such tasks would include but are not limited to: Database and spreadsheet data entry, arrangements of domestic and international travel schedules as needed, market research, and analysis.', 'Other duties as assigned by the VP of Production.', 'Partner with the Office Manager to insure general maintenance of the garage and fabrication areas.', 'Occasional attendance at automotive events such as races, drift competitions and trade shows may be necessary', '4-year college degree with focus on business-related coursework, or equivalent mix of college and work experience', 'Previous experience working in a fast-paced office environment and/or experience with project management is preferred', 'Highly organized and able to balance multiple tasks effectively.', 'Proficient with Microsoft Word, Excel, and Powerpoint. Microsoft Access is a plus.', 'Ability to communicate project statuses, concerns, issues, delays, etc. in a clear and effective manner.', 'The ideal candidate is driven, enthusiastic, dynamic, and a positive influence.', 'Detail oriented and disciplined.', 'Demonstrated skill set as a team player.', 'Knowledge and passion for the aftermarket automotive industry is a plus, but not a requirement', 'Ability to lift 50 pounds.', 'Travel is less than 5%.', 'Must be able to drive, must have access to a vehicle for special projects as needed.']",2020-08-08 12:56:56
Data Engineer,Innovative Defense Technologies (IDT),N/A,"Mount Laurel, NJ","['Design, implement, deploy and maintain optimal data pipeline and data management architectures.', 'Assemble large, complex data sets that meet functional / non-functional project requirements', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, streaming and ‘big data’ technologies', 'Implement data pipelines to ingest data to the platform, standardize and transform the data', 'Support the development of analytics tools that utilize the data pipeline to provide actionable insights into the data and optimization of objectives.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Design and architect solutions with Big Data technologies (e.g Hadoop, Hive, Spark, Kafka)', 'Design and implement systems that run at scale leveraging containerized deployments', 'Design, build, and scale data pipelines across a variety of source systems and streams (internal, third-party, as well as cloud-based), distributed/elastic environments, and downstream applications and/or self-service solutions', 'Ability to travel up to 10%', 'Master’s Degree in Computer Science, Computer Engineering, Informatics, Information Systems or another quantitative field', '5+ years of experience in a Data Engineer role', 'Experience with big data tools: Hadoop, Spark, etc.', 'Experience with relational SQL and NoSQL databases, including Postgres', 'Experience with AWS cloud or remote services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Kafka, Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Julia, Java, C++, Scala, etc.', 'Experience with data encryption/security features applied to data-in-transit', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific questions and identify opportunities for improvement', 'Experience with development, management, and manipulation of large, complex datasets', 'Experience with database & ETL technologies', 'Demonstrated knowledge of data management competencies and implementation', 'Understands the Big Data related problems and requirements to identify the correct technical approach. Core understanding of Big Data principles and architectural patterns', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Experience with containerized deployment technologies (Kubernetes, Openshift, etc.)', 'Experience with instantiating and configuring Virtual Machines (VMware, VirtualBox, etc.)', 'Experience with Machine Learning algorithms and applications interfacing with data management solutions', 'Solid analytical abilities, coupled with a strong sense of ownership, urgency, and drive', 'Attention to detail', 'Initiative, creativity, reliability, teamwork', 'Ability to adapt to and thrive in a fast-paced environment']",2020-08-08 12:56:56
QA Data Engineer,Thrivent,3.9 out of 5,"New York, NY","['Job', 'Company', 'Develop, implement physical and virtual test data management and test environment solutions across the organization, to contribute towards the success of technology initiatives', 'Develop test data management strategies and plans relevant to each test environment (Dev, Sys and ITE) to provide right-sized, production-like, re-usable and secured test data per data requirements', 'Key responsibilities include source system data analysis, business & privacy data requirements definition, data discovery, profiling, masking & monitoring rules definition and overall data provisioning for setting up a test environment.', 'Works closely with application subject matter experts/business partners/testers to determine appropriate data sources and to define data provisioning mechanism based on the need for test data', 'Learn and contribute to the design of data management and any futuretransformation of the test environment landscape', 'Works very closely with Application Availability, Compliance and Support teams leads to maintain and support all test environments to maintain SLAs and applicable policies / standards', 'Participates in all phases of a solution delivery including test data and env requirements gathering and provisioning the required test data in the appropriate test environments', 'Conducts full lifecycle activities including requirements analysis and design, develop and deliver capabilities, and continuously monitor performance and quality control plans to identify improvements around Test Data and Test Env management process', 'Lead initiatives to design processes to capture and review test data requirements and test data provisioning techniques and plans', 'Lead work to advance and support information management practices within business processes, applications and technology that underpin the Test Data and Test Env management discipline (e.g. establishing quality processes, performing analysis, participating in technology implementation planning and verification to ensure successful installation of software and/or projects), implementing data provisioning processes, providing the right amount of data in an appropriately provisioned test environment', 'Provide leadership for Test Data & Test Env management related tasks in support of projects', ""Lead the Management and proactive improvement of Thrivent's Test Data & Test Env provisioning practice by analyzing the current systems environment, leveraging proven practices, applications, technology, tools and platforms to support and enhance the discipline"", 'Handle budget responsibilities', 'Leads the delivery, support and maintenance of solutions with one or more business and technology areas.', 'Organizational impact results from mid-large sized projects', 'Lead discussions with tool / product vendors in support of evaluating solutions for process improvements or future offerings', 'Lead set up of test data and virtual environment based on functional test requirements utilizing Enterprise standard tool sets', 'Bachelor’s degree or equivalent in MIS, Computer Science, Mathematics, Business or related field.', '5+ years of experience in Technology related field including prior lead experience. For the senior level position 8+ years of experience in Technology related field including 3+ years prior lead experience.', 'Advanced in-depth knowledge of Test Data and Test Env Management concepts and tools.', 'Strong organizational, analytical, critical thinking and leadership skills.', 'Demonstrated leadership on mid-large-scale project impacting strategic partners.', 'Advanced in-depth knowledge of data warehouse and BI systems design, streaming architecture, and architecting and implementing large business systems is desired.']",2020-08-08 12:56:56
"Software Engineer, Data",Amazon.com Services LLC,3.6 out of 5,"Hawthorne, CA","['Job', 'Company', 'Bachelor’s degree in Computer Science or a related field', '2+ years of experience in Software Engineering / Data Engineering / Data Warehousing roles working in high traffic, fault tolerant, and highly available environments', '1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems', '2+ years of experience with Scala, Golang, Python, Java, Ruby or a similar programming language', '2+ years of experience with SQL skills', '2+ years of experience with Big Data Technologies (Hadoop, Hive, Hbase, Pig, Spark, etc.)', '1+ years of experience with Streaming platforms like Kafka or Kinesis', '2+ years of experience with Test Driven Development or writing unit tests', 'Work with engineering and business stakeholders to understand streaming and data requirements', 'Help shape the growth of transformative data pipelines and data collection', 'Implement and operate large, evolving, big data resources and capabilities', 'Evaluate and implement efficient distributed storage and query techniques', 'Interact and integrate with internal and external teams and systems to extract, transform, and load data from a wide variety of sources', 'Develop the next generation of automation tools for monitoring and measuring data quality, with associated user interfaces.', 'Implement secure and auditable data infrastructure as required', 'Be able to broaden your technical skills and work in an environment that thrives on creativity, efficient execution, and product innovation.', 'Experience with AWS', 'Having planned and/or participated in terabyte-scale data environments', 'Experience implementing solutions to comply with GDPR and/or other Data Privacy regulations', 'Experience designing and implementing Data Governance programs', 'Experience integrating NoSQL alongside RDBMS such as Postgres or MySQL in a multi-tiered, globally replicated environment']",2020-08-08 12:56:56
Rust Engineer,HASH,2.5 out of 5,Remote,[],2020-08-08 12:56:56
Azure Data Engineer,Expedite Technologies Solutions,N/A,"Dayton, OH","['8 Hour Shift', 'Spark Cluster: 3 years (Required)', 'Data Lake: 3 years (Required)', 'HDinsight: 2 years (Required)', 'Data Bricks: 3 years (Required)', '1 year', 'More than 1 year', 'Varies', 'Likely', 'Yes']",2020-08-08 12:56:56
Cost Engineer,Innovative Turnaround Controls (ITC),4.5 out of 5,"Toledo, OH","['Assessing risks', 'Doing cost estimates', 'Forecasting', 'Reviewing proposed schedules', 'Implementing bets practices', 'Performing cost control', 'Analyzing variances', 'Teamwork', 'Communication', 'Networking', 'Being detail oriented', 'Being focused', 'Being amenable', 'Resolving problems', 'Communication and presentation', 'Analyzing data', 'Leadership', 'Being analytical', 'Being self motivated', 'Being dependable', 'Day Shift', 'Holidays', 'Monday to Friday', 'Night Shift', 'Weekends']",2020-08-08 12:56:56
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:56:56
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:56:56
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:56:56
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 12:56:56
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:56:56
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:56:56
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:56:56
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:56:56
Data Engineer - New York,GeniusRx,N/A,"Boca Raton, FL 33431","['Work within the existing data ecosystem to move and integrate data pipelines across warehouses, legacy platforms, and external partners', 'Work hand-in-hand with stakeholders from the data science, engineering, and product teams to understand how the data works, where it comes from, and where it needs to go', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and Azure big data technologies', 'Transform the data from raw data into actionable data layers for use across the organization powering not only our business intelligence capabilities but also help establish a base for machine learning applications', 'Establish a data platform, a single source of truth, for use across the organization', 'Work in a supportive, passionate team as we drive to bring a new level of medication savings and insight to our customers', 'Bachelor’s degree in computer science, engineering, mathematics, economics, or related discipline', '3+ years of experience in data engineering or business intelligence with a track record of manipulating, processing, and extracting valuable information from large datasets', 'Strong SQL skills', 'Experience using Python and its related data packages (Pandas, Numpy, SQLalchemy), experience using Spark-based platforms like Databricks, or azure synapse is a plus', 'Experience working with business intelligence tools such as Tableau, Excel', 'Knowledge of best practices related to data management and storage – healthcare experience is a plus', 'Knowledge of software engineering best practices including git, agile methods, coding standards and reviews, testing, and operations', 'Experience working in the Azure ecosystem a plus']",2020-08-08 12:57:44
Data Warehouse Engineer,Kount,3.3 out of 5,"Boise, ID 83702","['Extract use cases and requirements from data warehouse users.', 'Work with users to mock up dashboards and proof of concept data models.', 'Design dimensional data models that satisfy data requirements and address ease of use and performance.', 'Instantiate the dimensional data models on the Snowflake cloud platform.', 'Design and build out monitoring and support elements to ensure data quality and timeliness.', 'Bachelor’s degree in Computer Science, Information Systems, or equivalent experience.', 'Minimum of three years of experience implementing dimensional data models (star schemas).', 'Experience dimensional data modeling for data warehousing using star schemas or Snowflake schemas.', 'Deep experience with database optimizer paths and data warehouse performance features.', 'Experience with building data warehouses on cloud infrastructure preferred.']",2020-08-08 12:57:44
QA Data Engineer,Thrivent Financial,3.9 out of 5,"New York, NY 10001","['Job', 'Company', 'Develop, implement physical and virtual test data management and test environment solutions across the organization, to contribute towards the success of technology initiatives', 'Develop test data management strategies and plans relevant to each test environment (Dev, Sys and ITE) to provide right-sized, production-like, re-usable and secured test data per data requirements', 'Key responsibilities include source system data analysis, business & privacy data requirements definition, data discovery, profiling, masking & monitoring rules definition and overall data provisioning for setting up a test environment.', 'Works closely with application subject matter experts/business partners/testers to determine appropriate data sources and to define data provisioning mechanism based on the need for test data', 'Learn and contribute to the design of data management and any futuretransformation of the test environment landscape', 'Works very closely with Application Availability, Compliance and Support teams leads to maintain and support all test environments to maintain SLAs and applicable policies / standards', 'Participates in all phases of a solution delivery including test data and env requirements gathering and provisioning the required test data in the appropriate test environments', 'Conducts full lifecycle activities including requirements analysis and design, develop and deliver capabilities, and continuously monitor performance and quality control plans to identify improvements around Test Data and Test Env management process', 'Lead initiatives to design processes to capture and review test data requirements and test data provisioning techniques and plans', 'Lead work to advance and support information management practices within business processes, applications and technology that underpin the Test Data and Test Env management discipline (e.g. establishing quality processes, performing analysis, participating in technology implementation planning and verification to ensure successful installation of software and/or projects), implementing data provisioning processes, providing the right amount of data in an appropriately provisioned test environment', 'Provide leadership for Test Data & Test Env management related tasks in support of projects', ""Lead the Management and proactive improvement of Thrivent's Test Data & Test Env provisioning practice by analyzing the current systems environment, leveraging proven practices, applications, technology, tools and platforms to support and enhance the discipline"", 'Handle budget responsibilities', 'Leads the delivery, support and maintenance of solutions with one or more business and technology areas.', 'Organizational impact results from mid-large sized projects', 'Lead discussions with tool / product vendors in support of evaluating solutions for process improvements or future offerings', 'Lead set up of test data and virtual environment based on functional test requirements utilizing Enterprise standard tool sets', 'Bachelor’s degree or equivalent in MIS, Computer Science, Mathematics, Business or related field.', '5+ years of experience in Technology related field including prior lead experience. For the senior level position 8+ years of experience in Technology related field including 3+ years prior lead experience.', 'Advanced in-depth knowledge of Test Data and Test Env Management concepts and tools.', 'Strong organizational, analytical, critical thinking and leadership skills.', 'Demonstrated leadership on mid-large-scale project impacting strategic partners.', 'Advanced in-depth knowledge of data warehouse and BI systems design, streaming architecture, and architecting and implementing large business systems is desired.']",2020-08-08 12:57:44
"Data Engineer, CX Journeys (Tysons Corner)","Medallia, Inc.",4.2 out of 5,"Tysons Corner, VA","['Architect, implement, and deploy new data models and data processes in production', 'Perform data analysis to generate business insights', 'Interface with Engineers and Product Managers to understand product goals and data needs', 'Build data expertise and own data quality for allocated areas of ownership', 'Support critical data processes running in production', 'Collaborate with customers in assembling large, complex data sets that meet functional business requirements', ""Bachelor's degree in CS, EE or MIS; or equivalent experience"", 'Strong Software Engineering skills', 'Programming knowledge in Python or R', 'Knowledge of SQL', 'Knowledge of database systems', 'A team player, fast learner, with a focus on getting things done', '2+ years experience in custom ETL design, implementation and maintenance.', '2+ years experience in writing SQL statements', 'Experience with Linux', 'Experience with JavaScript, JSON']",2020-08-08 12:57:44
Data Science and Optimisation Engineer,GridBeyond,N/A,United States,"['Undergraduate degree in computer science, mathematics or another numerate / computational discipline (min 2.1).', 'Postgraduate degree (Masters/PhD) involving machine learning and/or optimization', 'at least two years industrial experience in a R&D role involving machine learning and/or optimization', 'Legally permitted to work in ROI', 'Strong software development skills as demonstrated through machine learning projects.', 'Practical experience and theoretical knowledge of reinforcement learning (preferably deep RL), machine learning and deep learning frameworks such as Tensorflow, PytTorch or any similar technology as listed below', 'Knowledge of Classification algorithms such as Decision Trees or Bayesian models', 'Knowledge of and practical experience using regression techniques', 'Excellent verbal and written communication', 'Self-motivated and able to meet project deadlines.', 'Knowledge of one or more of the following: forecasting, model predictive control, supervised machine learning, smart grids.', 'Experience/Familiarity with any of these technologies: Matlab/Octave, Tensorflow, PytTorch, python scikit-learn, python pandas, Accord.Net, ML.Net or similar. Modelling languages ( Pyomo, GAMS) and solvers (e.g. CBC, Gurobi)', 'Any of the following programming languages: Python, C#, C++, Java, R', 'Experience with .NET framework.']",2020-08-08 12:57:44
Data Engineer,Aspiration Partners,N/A,"Los Angeles, CA","['Build and extend a scalable and modern data analytical environment', 'Architect, design and develop end-to-end data pipelines across multiple data sources and systems of record', 'Develop, design data models, data structures for data acquisition and manipulation purposes', 'Build custom metadata-driven frameworks using programming languages as well as leveraging off-the-shelf integration tools, as appropriate', 'Create ETL/ELT processes based on mapping specification documents (STMs)', 'Ensure data quality, integrity, security and completeness throughout the data lifecycle', 'Perform ongoing monitoring, automation and refinement of data engineering solutions', 'Surface data in company chosen BI tool for self-service usage', 'Analytical infrastructure support and enhancement', 'Enable data science team by providing necessary infrastructure and tools', 'Interface closely with product, engineering and business divisions', 'Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability', 'Ability to interact with the business stakeholders to understand requirements and translate into technical solutions', 'Build and meet project timelines and manage delivery commitments with proper communication to management', '5+ years of experience with SQL', '5+ years of experience in ETL concepts/technologies and data modeling', 'Thorough understanding of relational and analytical databases', 'Strong technical, logical and problem-solving skills', 'Experience with working on multiple tasks/projects in parallel', 'Ability to manage multiple deliverables in a highly energized and fast-paced environment within a framework of constantly shifting deadlines and deliverables', 'Working experience in a fast-paced and agile environment', 'Ability to work well in a team environment and brainstorm ideas with other team members.', 'Flexibility to adapt to a change and willing to learn and develop new skill sets as applicable', 'Ability to learn new technologies without formal training', 'Experience with ETL/ELT tools, e.g. Matillion, Talend, Pentaho, SyncSort, SSIS is a big plus', 'Experience with BI tools, e.g. Looker, Tableau, MicroStrategy, Mode is a big plus', 'Experience in programming/scripting languages (c#/java/bash/powershell/ruby/python) is a big plus', 'Experience with Snowflake,Amazon Redshift, S3, Elastic MapReduce, Hive, and other AWS services, or equivalent technologies is a big plus', 'Experience ingesting and transforming data from APIs is a big plus', 'Experience with real-time data capture, processing, and storing using technologies like Kafka, AWS Kinesis.', 'Prior experience with MPP databases and maintaining a large amount of data processing is a big plus', 'Work for a mission-driven company to transform the lives of millions by building a better, values-oriented financial firm', 'Competitive Salary and Equity Incentives', 'Robust Healthcare Plans (medical, dental, vision)', '401K & Unlimited Vacation Time', 'Diverse & Inclusive Culture']",2020-08-08 12:57:44
Data Engineer,Sinclair Broadcast Group,2.9 out of 5,"Cockeysville, MD 21030","['Familiar with the modern cloud data platforms (Azure preferred but AWS is ok). In particular, experience in some of the following is preferred:Azure Data Lake (Analytics and Storage), Data Warehouse / Synapse Analytics / Amazon Redshift, Data Factory, Logic Apps, Data BricksOther preferred technologies include: Advanced T-SQL (SQL Server), REST API concepts, Powershell, SSIS, PowerBI', 'Experience in database design, architecture and warehousing', 'Experience creating ETL/ELT processes to move data between internal and external sources using APIs, ETL.', 'Fundamental understanding of Data Lakes, Data Catalogs, Hardware and Network Topology', 'Experience with Object-Oriented Programming Languages such as Python, JavaScript, Java, C#, etc.', 'Experience using data reporting and visualization tools (e.g. Cognos, SSRS, Qlik, Data Studio, Power BI, Tableau, etc.)', 'Algorithmic concepts from at least one information-centric discipline (e.g. statistics, machine learning, information processing, natural language processing, etc.)', 'Gathering data requirements from stakeholders', 'Evaluating data collection for accuracy', 'Data Governance concepts', 'Mindful of practices, procedures and legal guidelines that govern PII and other sensitive data', 'Ability to tackle complex problems with creative solutions when the path may not be clear.']",2020-08-08 12:57:44
Data Engineer Bachelor's (Intern) - United States,Cisco Systems,4.1 out of 5,"San Jose, CA",[],2020-08-08 12:57:44
Business Intelligence Engineer,Conde Nast,4 out of 5,"New York, NY 10007","['Provide team leadership and management for BI engineers and Business Partners on our Business Intelligence team to provide reporting, dashboards, insights and quantitative support for longer-term strategic projects', 'Build our client facing analytics solutions and works with vendors/ internal teams to architect a highly scalable solution', 'Manage curation and expansion of our centralized business intelligence platform ensuring a standardized and unified data modeling layer, and experience optimized for self-service of end users with basic data retrieval needs', 'Manage and align team and individual priorities, in order to most effectively support business objectives, while also maintaining bandwidth for interrupt-driven requests as well as proactive insight generation', 'Maintain strong relationships with stakeholders across the organization to drive consistent process for inbound requests, and a higher degree of action ability and impact resulting from reactive work.', 'Manage working relationship between BI team and Data Engineering team, ensuring short-term needs are met while helping craft long-term data warehousing objectives', 'Empower individual team members to both deepen and broaden their skills through growth opportunities that align with their goals', 'Bachelor’s degree in Computer Science, Engineering, Math, Statistics or other quantitative field', 'Strong data management skills including Excel, SQL, R, SAS or other Statistical Packages.', '5+ years of experience in BI tools like (Qlik , Business Objects , Power BI , Tableau etc.)', '5+ years’ experience working on relational databases as an architect or administrator', 'Understanding of server management and server sizing', 'Knowledge of ETL tools and data processing', 'Great relationship building qualities', 'Proven ability to manage multiple tasks while working independently', 'Strong attention to detail', 'A strong sense of urgency and commitment to get the job done quickly and with high quality', 'Excellent communication skills, both written and verbal, with people at all levels of an organization', 'Entrepreneurial nature']",2020-08-08 12:57:44
Cloud Data Engineer (Azure),Navy Federal Credit Union,4 out of 5,"Vienna, VA 22180","['Job', 'Company', 'FORTUNE 100 Best Companies to Work For®', 'Computerworld® Best Places to Work in IT', 'FORTUNE® Best Workplaces for Millennials', 'Forbes® America’s Best Employers', 'PEOPLE® Companies That Care', 'Provide Business Intelligence (BI) and Data Warehousing (DW) solutions and support by leveraging project standards and leading analytics platforms', 'Evaluate and define functional requirements for BI and DW solutions', 'Define and build data integration processes to be used across the organization', 'Build conceptual and logical data models for stakeholders and management', 'Analyze and validate data accuracy of report results', 'Work directly with management understand requirement; and propose and develop best business solution that enables effective decision-making, and drive business objectives', 'Prepares realistic project implementation plans which highlight major milestones and deliverables leveraging standard methods and work planning tools', 'Recognizes potential issues and risks during the analytics project implementation and can suggest realistic mitigation strategies', 'Coaches and mentors project team members in carrying out analytics project implementation activities', 'Leads the preparation of high quality project deliverables that are valued by the business and presents them in such a manner that they are easily understood by project stakeholders', 'Interpreting data presented in models, charts, and tables and transforming it into a format that is useful to the business and aids effective decision making', 'Use of statistical practices to analyze current and historical data to make predictions, identify risks, and opportunities enabling better decisions on planned/future events', 'The ability to understand the business problem and determine what aspects of it require optimization; articulate those aspects in a clear and concise manner', 'The ability to define and analyze models that predict the probability of an outcome', 'Offers improvements to the way in which analytics service the entire function', 'Communicating and owning the process in manipulating and merging large datasets', 'Ability to view and understand other project or functional areas in order to consolidate analytical needs and processes', 'Being a key point of contact between the data analyst/data scientist and the project/functional analytics leads', 'Perform other duties as assigned', ""Bachelor's degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience"", '5 years’ experience working in a cloud computing with Azure experience required', 'Experience with data migration to cloud based environment', 'Extensive 5 years of experience in providing data architecture solutions for Cloud applications', 'Knowledge of and the ability to perform basic statistical analysis such as measures of central tendency, normal distribution, variance, standard deviation, basic tests, correlation, and regression techniques', 'Experienced in the use of standard ETL tools and techniques', 'Experienced in sourcing, maintaining, and updating data', 'Understanding of data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage', 'Demonstrates functional knowledge of data visualization tools such as Microsoft Power BI, Tableau', 'Has working knowledge of various data structures and the ability to manipulate data within visualization tools', 'Ability to manipulate raw data into effective visualization dashboards', 'Ability to communicate end to end data outcomes visually', 'Demonstrates a deep understanding of multiple database concepts', 'Has a working knowledge of various data structures and the ability to extract data from various data sources (such as Cognos, Informatica)', 'Understands the concepts and application of data mapping and building requirements', 'Optimal understanding of SQL', 'Graduate education in Information Systems, Computer Science, Engineering, or related field', 'Knowledge of Navy Federal Credit Union instructions, standards, and procedures']",2020-08-08 12:57:44
Junior GIS Data Engineer,Xentity Corporation,4.1 out of 5,"Golden, CO 80402","['Job', 'Company', 'GIS -Strong foundation in GIS Principles and experience working with and manipulating GIS data - 1 yr', 'Python for data management, Pandas, Requests, Data Cleaning, Understanding of Metadata and ETL/Data Pipelines', 'Cloud: BootCamp level or project experience in AWS, GCP, or other major clouds', 'We prefer more data processing experience in data feeds, geospatial data, and data scripts over management of information systems.', 'Demonstration of handling, manipulating data, records, feeds', 'General knowledge familiarity of use patterns in services, analytics, applications, dashboards and other use by data scientist', 'Data : Open and Public Data Experience, REST APIs for Data Services', 'Geospatial : ESRI ArcGIS Server, ArcGIS Online, Open Data Hub, QGIS, GDAL, ArcPy, GeoPandas', 'Programming Languages: NodeJs, ArcPy', 'Database Technology: PostgreSQL', 'Cloud Experience: AWS ECS, EC2, S3 hands-on experience, Kubernetes, Docker', 'Tools and Software: Power BI, Tableau, similar, GIT, JIRA', 'Bachelor’s Degree min. Education and 1 years min. experience', 'Must be able to pass basic NACI, background, drug and reference checks', 'Must be local. No Relocation Assistance.', 'Travel None to Rare/In-State', 'Ability to thrive in an energetic, fast-paced environment - learn and become productive quickly and meet team goals, can-do attitude, able to do what it takes to deliver.', 'Ability to work multiple, time-sensitive tasks - Able to rapidly context switch across subject matter, communication and architecture products, and stakeholder audiences.', 'Ability to work independently as well as as part of an integrated team.', 'Excellent oral and written communication skills.', 'Demonstrate strong analytical and critical thinking skills', 'Maintain a Public Data Catalog. Manage an ETL environment to maintain over 300 active dataset updates to a centralized portal, setup new ETL scripts for incoming datasets ~35/year, and manage associated documentation spreadsheets.', 'Assist State Agencies in Making Their Data Public. Work with a wide variety of State Agencies to provide them with the technical support required to keep datasets current on the centralized portal. Publish new datasets (as derived from any given tech stack) to a centralized portal and make them discoverable', 'Cultivate Dataset Back Stories. Curate metadata that conveys context to End Users of Public Data.', 'Data Storytelling, Dashboards, Data Visualizations. Create Public Data stories and demonstrations that show the value of Public Data. Generate content for users to better understand and utilize Public Data.', 'Public and Open Data Evangelism. Explore ways to build content on the benefits of Public Data to communities, and specifically the impact and status of the current state of Public Data in Colorado.', 'Technical Writing. Make updates to process documentation as new technologies are utilized and workflows are improved.', 'GIS Analysis and Tech. Geospatial knowledge required for some data transform work.', 'Assist Government programs with technical support to ETL/data pipeline data into catalog for primarily tabular and geospatial data - some unstructured occurs.', 'Maintain Public Self-service data catalog', 'Develop quality scripts to validate data for tabular and geospatial data.', 'Edit and Curate metadata to support public discovery', 'Provide End user support with data discovery, access, and use requests', 'Support prototyping of Data Storytelling, Dashboards, Data Visualizations for demonstrations', 'Maintain technical documentation of catalog and operations', 'You will be expected to rapidly ramp-up on client lingo, proactively make observations of patterns, anomalies, problems, and be customer service focused.', 'You will be expected to be highly self-motivated and understand you will be held accountable to commitments.', 'We look for decisive individuals able to rapidly respond to change requests and able to communicate, track, and escalate risk.', 'We expect you to be proactive, efficient, and ready to learn quickly in response to all client and team member needs. This is a bootcamp-type position setup for growth.', 'We want you to not only gain technical skills, but also grow your interactive and client facing skills.', 'We will require strong communication and interactive skills - oral, written, visual especially for triaging conflict, ideation barriers, mitigating risk, foster thought diversity and team environment.', 'We expect all our roles to focus on attaining a mastery of their technical level demonstrating fast learning at their role whether that be in architectural methods, languages, work products, consulting techniques, and client culture.', 'We emphasize a balance of work and life and target 40-50 hour weeks with ample time to refresh with great paid-time off.', 'Salary & Bonus Programs - Competitive Salary. Multiple Recognition and Rewards Bonus Programs (Performance Bonus plan reviewed twice annually - total ranging from 2-5% of salary and Business Development Bonus Plan, Employee Referral Bonus Plan, and Company Profit Sharing Plan).', 'Paid Time off - (10) Paid Holidays, (10) Personal Time Off, and (5) Sick Leave', 'Medical Insurance - Coverage for Major Medical and Surgical, Medical Health Care, Dependents’ Health Care with 100% of employee or 80% employee and 50% family. Options to enroll in Dental Insurance, Vision Discount Program, Prescription Discount Program, Group Term Life Insurance, Accidental Death & Dismemberment Insurance, and Professional insurance advisors to guide employees through these benefits as needed.', 'Solid, managed retirement savings plan including - Multiple 401(k) funds with traditional and Roth options, Company paid fees, Company Match, Third-party Trust Management with personalized retirement portfolio web analysis tools.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'GIS data engineer: 1 year (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'One location', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'careers.xentity.com', 'https://www.facebook.com/xentitycorp/', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-08-08 12:57:44
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 12:57:44
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:57:44
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:57:44
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:57:44
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:57:44
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:57:44
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:57:44
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:57:44
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 12:58:38
"Data Center Facilities Engineering, Controls Engineer",Facebook,4.2 out of 5,"Washington, DC","['Serve as the principal liaison for all controls systems related issues, coordinating efforts of external activities necessary to support assigned site operations.', 'Develop and implement engineering standards/best practices.', 'Develop and generate specifications, RFPs, ROMs and SOWs for assigned projects.', 'Serve as the point of escalation for complex control system malfunctions.', 'Coordinating the associated troubleshooting and response.', 'Facilitate change control reviews activities for assigned projects.', 'Perform readiness review of assigned new build projects to inform overall building acceptance.', 'Travel to data center sites in support of pre-engineering, implementation, startup testing, and commissioning of projects at the assigned site.', '30% domestic and international travel.', '5+ years controls experience in programming development, start-up and commissioning of electrical monitoring systems, central plants, air handling units, evaporative cooling/humidification systems, or other industrial automation systems.', 'Associates in Engineering/Technical studies, Military Technical School, or equivalent working experience.', 'Working knowledge of mechanical, electrical and life safety systems associated with critical environments.', 'Experience auditing blueprints/CAD drawings and controls diagrams.', 'Communication and organizational experience.']",2020-08-08 12:58:38
AWS Big Data Engineer,Cool Minds LLC,N/A,"Tempe, AZ 85281","['Provide technical solution leadership in data engineering team, driving technology decisions, mentoring others, and contributing significantly on an individual level', 'Build frameworks to handle data at high scale using Apache Spark and data cataloging tools like Apache Hive, AWS Glue on top of a multi-tiered data lake storage', 'Use exploration and analytic tools like AWS Athena/Presto to probe and validate data', 'Build robust data processing pipelines using AWS Services and integrate with multiple data sources', 'Collaborate with product owners and stakeholders to plan and define requirements', 'AWS Services: RDS, AWS Lambda, AWS Glue, Apache Spark, Kafka, Hive, etc', 'SQL and NoSQL databases like MySQL, Postgres, Elasticsearch', 'AWS EMR', 'Familiarity with Spark programming paradigms (batch and stream-processing)', 'Strong programming skills in at least one of the following languages: Java, Scala. Familiarity with a scripting language like Python as well as Unix/Linux shells', 'AWS Athena', 'Strong analytical skills and advanced SQL knowledge, indexing, query optimization techniques.', 'Good to have ETL skills', 'Ability to translate data needs into detailed functional and technical designs for development, testing and implementation', 'Ability to serve as a liaison between technical, quality assurance and non-technical stakeholders throughout the development and deployment process', 'Monday to Friday', 'AWS: 10 years (Preferred)', 'Spark: 6 years (Preferred)', 'Hadoop: 4 years (Preferred)', 'Big Data: 9 years (Preferred)', 'More than 1 year', 'Temporarily due to COVID-19']",2020-08-08 12:58:38
Data Analytics Engineer,TechStyle Fashion Group,3.4 out of 5,"El Segundo, CA","['Design, build and maintain reporting structures for the media and web analytics teams (30%)', 'Design, build and maintain data integrations (10%)', 'Review data integrations from offshore team (20%)Review offshore team’s work and provide guidance and mentorshipHandle merge and deployment', 'Review code submitted by non-technical analysts (30%)Ensure processes are well-structured, organized well, efficient and ready for productionAct as mentor to less senior developers and analystsHandle merge and deployment', 'Production support (10%)Data integrationsReporting processes', 'Evaluate existing data and analytics pipelines with data engineering peers to ensure that analytics systems are performant', 'Collaborate with analysts and stakeholders in developing new data models and ETL design specifications based on analytics requirements (must be able to elicit and translate business requirements)', 'Proven ability to extend your scope into the Analytics domain and partner with that team to optimize the output of the Analytics function', 'Follow best practices for version control and centrali (this is covered in required skills)', 'Expert SQL skills, particularly in an analytics/reporting capacity. Significant experience creating and maintaining reporting processesAdvanced SQL skills requiredPrimary/foreign keys, indexes (when to use them)Joins and unionsTables and Views (How are they different? Pros and cons of using)Be able to describe differences between DML/DDL statementsWindow functionsScalar and aggregate functions', '2+ years of experience creating and managing data pipelines', '1 year experience with python or another scripting language', 'Strong command of git (1+ year)', 'Comfort working in linux-based python development', 'Traditional data warehousing (e.g. kimball)', 'Data engineering experience on cloud platforms (e.g. bigquery, redshift, snowflake, teradata, vertica)', 'Expertise in devops and CI/CD practices', 'Airflow infrastructure experience', 'Conversant in docker', 'Data Visualization tools: Tableau, SSRS, Looker etc.,', 'Experience working with large amounts of raw data (web logs, Click stream, data feeds)', 'Ability to create and interact with very large data processing pipelines, distributed data stores, and distributed file systems', 'E-commerce or retail or internet experience']",2020-08-08 12:58:38
Sr. Data Engineer - HBO Max,HBO Max,N/A,"New York, NY","['Strong experience in developing, constructing, testing, and maintaining existing and new architectures.', 'Responsible for aligning architecture with business requirements.', 'Ability to identify ways to improve data reliability, efficiency, and quality.', 'Responsible for preparing data for predictive and prescriptive modeling.', 'Ability to deploy sophisticated analytics programs, machine learning and statistical methods.', 'Conduct research for industry and business questions that come up.', 'BS or MS degree in computer science or related field and direct experience in Data / Engineering / Application lifecycle.', 'Minimum of 4-5 years of experience in data science engineering, with big data tools like Hadoop and Spark.', 'Robust experience with relational SQL and NoSQL databases like MongoDB, DynamoDB, Redshift/PostGRE, mariaDB, etc.', 'Experience with data pipeline and workflow management tools like airflow or alternatives.', 'In depth experience and knowledge with AWS cloud services: S3, EC2, EMR, RDS, Redshift, Lambda, API-Gateway, AWS GLUE, etc.', 'Experience with stream-processing systems: Spark-Streaming, AWS Kinesis, Kinesis Firehose etc.', 'Must be experienced with object-oriented/object function scripting languages: Python, Java, Scala, etc.', 'Preferred experience of 3+ years of minimum experience with Python, Data Warehouse, Linux/Bash scripting development, Software Development Cycle and Data Modeling a must.', 'Exclusive WarnerMedia events and advance screenings', 'Paid time off every year to volunteer', 'Access to well-being tools, resources, and freebies', 'Access to in-house learning and development resources', 'Part of the WarnerMedia family of powerhouse brands']",2020-08-08 12:58:38
Data Engineer ; AES,PPD,3.5 out of 5,"Horsham, PA","['Designs and develops components and services according to specifications within a team environment.', 'Prepares detailed system documentation including requirements, specifications, test plans and user manuals.', 'Performs unit and system tests and, as needed, validation testing.', 'Assists DBA with database design.', 'Strong SQL and Analytical skills to pull data from Snowflake/Oracle/SQL Server and perform usage analysis and/or data profiling.', 'Understanding of data warehousing and data modelling principles', 'Experience in understanding both logical and physical data models', 'Coordinates with Operations staff on deployment of applications.', 'Works with business partners to analyze and address support requests including training.', 'Provides support for existing systems and technologies, including second line application support during and after deployment.', 'Ensures all activities are performed with quality and compliance.', 'Design and implementation of ETL batches that meet the SLAs for the business’ Business Intelligence reporting.', 'Development of data collection, data staging, data movement, data quality and archiving strategies.', 'Plan and conduct ETL Unit and development tests, monitoring results and taking corrective action when necessary.', 'Design automation processes to control data access, transformation and movement and ensures source system data availability', ""Bachelor's degree or equivalent and relevant formal academic / vocational qualification"", 'Previous experience that provides the knowledge, skills, and abilities to perform the job (comparable to 3+ years’) or equivalent combination of education, training, and experience', 'Experienced in the use of the ETL tools (Talend/Informatica) and Cloud based database tools (Snowflake/Redshift/Google Cloud)', 'Client focused approach with strong interpersonal skills', 'Must be able to multitask and pay close attention to detail', 'Solid knowledge of basic relational database platforms (Snowflake, Oracle, SQL Server) and languages (PL/SQL, SQL)', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'Strong logic, analysis, and problem-solving skills', 'A good understanding of the concepts and best practices of data warehouse ETL design.', 'Ability to follow functional ETL specifications and challenge business logic and schema design where appropriate, as well as manage their time effectively', 'Have designed and developed ETL work packages on at least one data warehouse project.', 'Expertise with big data tools: Hadoop, Spark, Kafka, etc. is a plus', 'Expertise on any of the programming languages: Python or Scala', 'Experience in building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience with AWS cloud services: Snowflake, Redshift, S3, EC2, EMR']",2020-08-08 12:58:38
Data Engineer,KSM Consulting,4 out of 5,"Indianapolis, IN 46204","['Work closely with the solution leads, project managers, data architects, and data scientists on solution design, architecture, and implementation.', 'Performing extraction, transformation, and loading of data from a wide variety of data sources using various data engineering tools and methods.', 'Querying and processing large data sets and perform data quality checks.', 'Designing and implementing data solutions for operational and secure integration across systems.', 'Assist in creating database models and architecture design and documentation', 'Conduct research and development as well as contribute to the long-term positioning of and emerging technologies related to data sourcing, cleansing, and integration.', 'Documenting and demonstrating solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code.', 'Improving operations by conducting systems analysis; recommending changes in policies and procedures.', 'Involvement in client-facing project activities such as requirements gathering, solution reviews, and explaining technical complexities and business benefits in layperson terms.', 'Bachelor’s degree in Computer Science, Engineering or a similar field is required', '3+ years of data engineering, software engineer, or similar experience', '2+ hands-on industry experience working with SQL on various relational database platforms (Microsoft, Oracle, Hana, Postgres, etc.)', '2+ hands-on industry experience working with enterprise ETL/DW tools like Azure Data Factory, Snowflake, Redshift, Informatica, etc.', 'Hands-on experience with aspects of data engineering design and implementation including data sourcing, data modeling of warehouses/marts/repositories, data integration/transformation/ETL, APIs, reporting, business intelligence and analytics', 'Hands-on experience with modern programing languages like Python, C#, JavaScript, etc.', 'Hands-on experience with cloud platforms like AWS, Azure, GCP, etc.', 'Hands-on experience with NoSQL databases like MongoDB (preferred), CouchDB, Cosmos, etc. a plus', 'Hands-on experience with Graph databases like Neo4j (preferred), Cosmos DB, Neptune, etc. a plus', 'Experience with Docker for containerization and Kubernetes for orchestration a plus', 'Experience with “big data” and distributed tools like Hadoop, Spark, Cloudera, etc. a plus', 'Collaborative team player who is detailed oriented, focused on solution quality and execution', 'Progressive mindset particularly around deployment models and emerging technologies', 'Comfortable working across a wide range of project sizes and industries']",2020-08-08 12:58:38
Data Engineer,Toyota,4 out of 5,"Plano, TX 75023","['Develop, enhance, operate and maintain an Enterprise Data Platform comprised of, but not limited to, features such as Data Ingestion, Metadata driven development, Data Preparation/Aggregation and polyglot data delivery in a containerized Cloud based Kubernetes cluster with data services capability that can be leveraged for enterprise data consumption', 'Develop and support services and integration patterns such as API, Events and Batch between enterprise systems comprised of, but not limited to, Mainframe, Salesforce, SAP, Informatica in a cloud infrastructure', 'Program in Java Spring boot framework and microservices based data processing', 'Develop data processing framework using NiFi, Kafka Streaming, deployment using Jenkins, any NoSQL Document database, AWS S3 object store and codebase management using Git in a containerized Kubernetes platform', 'Drive opportunities for increased efficiencies of the Enterprise Data Platform to be fully operational, understanding means of automation, tuning and uplift of the data applications', 'Bachelor?s degree (or higher) in Computer Science, Information Systems or equivalent professional work experience', 'Experience as a Data Engineer', 'Experience developing time tracking solutions', 'Experience developing data extracts and reporting dashboards', 'Broad-based IT experience participating in projects and playing a key role toward successful implementation of the project', 'Experience in Data Integration', 'Expertise in DevOps toolchain leveraging Jenkins', 'Prior experience in ICP or equivalent cloud platform', 'Certification in AWS or any other Cloud platform', 'Certification in any Kubernetes based development', 'A work environment built on teamwork, flexibility and respect', 'Professional growth and development programs to help advance your career, as well as tuition reimbursement', 'Vehicle purchase & lease programs', 'Comprehensive health care and wellness plans for your entire family', 'Flextime and virtual work options (if applicable)', 'Toyota 401(k) Savings Plan featuring a company match, as well as an annual retirement contribution from Toyota regardless of whether you contribute', 'Paid holidays and paid time off', 'Referral services related to prenatal services, adoption, child care, schools and more', 'Flexible spending accounts', 'Relocation assistance (if applicable)']",2020-08-08 12:58:38
AWS Data Engineer -- Remote,Chabez Tech,N/A,"Chicago, IL","['Must have experience in Lambda; Amazon SQS; Python & Spark scala and Dynamo DB', 'Very strong communication skills and ability to handle critical projects', 'Skill set required', 'Cloud Technologies : Lambda; AWS; Amazon SQS', 'Python; Scala; Hadoop; Spark and other Big data technology', 'Strong AWS Background with minimum 10 years hands-on experience and implementation knowledge', 'Strong in AWS; LAMBDA; Amazon SQS; Python ; SPark Scala and Dynamo DB.', 'Sharp and balanced attitude who is willing to embrace newer technologies', 'Ability to understand business use cases and transform them towards application business components']",2020-08-08 12:58:38
Data Engineer,Shark Analytics,N/A,"Menlo Park, CA","['sql: 3 years (Required)', 'data engineer: 10 years (Required)', 'python: 3 years (Required)', 'tableau: 3 years (Required)']",2020-08-08 12:58:38
Data Operations Engineer,AppFolio,3.9 out of 5,"Santa Barbara, CA","['5+ years relevant work experience', 'Proficient in AWS & Snowflake', 'Advanced Python and SQL skills', 'Experience managing an analytics-facing or “business intelligence” platform']",2020-08-08 12:58:38
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 12:58:38
Cost Engineer,Innovative Turnaround Controls (ITC),4.5 out of 5,"Toledo, OH","['Assessing risks', 'Doing cost estimates', 'Forecasting', 'Reviewing proposed schedules', 'Implementing bets practices', 'Performing cost control', 'Analyzing variances', 'Teamwork', 'Communication', 'Networking', 'Being detail oriented', 'Being focused', 'Being amenable', 'Resolving problems', 'Communication and presentation', 'Analyzing data', 'Leadership', 'Being analytical', 'Being self motivated', 'Being dependable', 'Day Shift', 'Holidays', 'Monday to Friday', 'Night Shift', 'Weekends']",2020-08-08 12:58:38
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 12:58:38
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 12:58:38
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 12:58:38
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 12:58:38
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 12:58:38
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 12:58:38
Engineer Propulsion 2 or 3,Northrop Grumman,4 out of 5,"Elkton, MD","['Job', 'Company', 'Performs design of one or more moderately complex or portions of structural components and functional systems.', 'With limited supervision, applies theoretical knowledge and engineering techniques to the solution of more complex components, structures, and sub-assemblies.', 'Responds in a timely manner to all requests and explores all avenues within authority and makes appropriate referrals to other sources.', ""Makes thoughtful and valuable suggestions and recommendations for improving own work and/or group's work."", ""Makes thoughtful and valuable suggestions and recommendations for improving own work and/or group's work. Perform design, development, and/or analysis to support assigned projects."", 'Establish requirements for materials, structural components, and functional systems.', 'Release results as design data after review from other engineers.', 'Determine engineering tasks required for project planning and execution.', 'Develop original ideas on preliminary design concepts with other technical groups and make modifications necessary to achieve the most ideal design.', 'Document results of design activities.']",2020-08-08 12:59:28
Data Engineer - Analytics Warehouse,gettacar,2.6 out of 5,"Philadelphia, PA","['Structure, manage, and ensure accuracy of data in a SQL data warehouse environment to support various levels of analytics products using the latest ETL methods and technologies', 'Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization', 'Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, marketing, sales, operational efficiency and other key business performance metrics', 'Perform data analysis required to troubleshoot and resolve data related issues', '5+ years of data engineering experience', '5+ years of experience using SQL', 'Experience working with segment.io', 'Experience with R or Python a plus', 'Bachelor’s or Master’s degree in Computer Science, Information Systems or related field', 'Ability to develop/structure data to support analytical work, BI reporting, and data visualization', 'Ability to assess the best engineering approach and implement ETL, ELT, Transformations, Triggers, Stored Procedures, or other methods to support optimal SQL data warehouse structuring.', 'Experience managing Schemas, Tables, Views', 'Demonstrated experience ensuring accuracy and reliability of core data through sound data governance practices', 'Auto industry experience not required']",2020-08-08 12:59:28
Data Analyst,Democratic National Committee,4.1 out of 5,Remote,"['Strengthen and expand core DNC data products, with a focus on enhancing the integrity of our data, making our products more accessible, and encouraging wider adoption of DNC data products. Help us continue building upon and improving the data we provide, and create systems to get the right data into the hands of decision makers who are driving Democratic campaigns from the school board to the presidential level.', 'Identify opportunities to develop new datasets and products that help Democrats fully leverage data in their decision-making. Work on better understanding the end users of Democratic data and providing the support and resources that best meet their needs. Help us think about how we can make data, analytics, and data science products more impactful and accessible to the campaigns that rely on them.', 'Support acquisitions of new datasets to improve campaign targeting and decision making. Help us identify opportunities to augment our current data store with a focus on helping campaigns efficiently identify and reach target voters, and measure the effects of their programs.', 'Have experience working with data in a political context', 'Have experience building and/or maintaining ETL data pipelines', 'Are comfortable diving into new, messy datasets, and structuring them to allow quick analysis and insights', 'Are proficient in SQL', 'Feel comfortable with one or more of the following: Python, R, data visualization tools (e.g. Tableau, Periscope, Google Data Studio), workflow management tools (e.g. Airflow, Mistral YAML) or political CRMs (e.g. Votebuilder, NGP, BSD)', 'Have strong written and verbal communication skills, and experience explaining technical concepts to both technical and non-technical audiences', 'Are curious, collaborative, and humble – ready to work with a diverse, distributed team to solve interesting problems together']",2020-08-08 12:59:28
Big Data Engineer,iconvergence,N/A,"Seattle, WA","['Monday to Friday', 'AWS: 3 years (Preferred)', 'bigdata: 3 years (Preferred)', 'etl: 2 years (Preferred)', '1 year', 'No', 'Fully Remote']",2020-08-08 12:59:28
Junior Research Engineer/Data Scientist,Technica Corporation,3.7 out of 5,"Dulles, VA 20166","['Support a team of Developers and Data Scientists working on a variety of research and development projects as well as customer projects', 'Research and analyze cutting edge algorithms and technologies with a focus on Natural Language Processing and data visualization techniques', 'Effectively communicate results of research and analysis with teammates and senior management in the form of essays, whitepapers, and Powerpoint presentations', 'Design, Develop and Deploy:', 'Automated analytic software, techniques, and algorithms', 'Data-driven analytics; event-driven analytics', 'Bachelor’s in Computer Science, Mathematics, or relevant technical field', 'Experience with web frameworks (React, Flask, NodeJS)', 'Experience with Python', 'Eligible to obtain a U.S. Secret clearance', 'Experience using Linux as a development operating system', 'Experience using Natural Language Processing techniques', 'Experience with Docker and Singularity container platforms', 'Experience with Machine Learning toolkits such as Tensorflow, Pytorch', 'Experience with data visualization']",2020-08-08 12:59:28
Machine Learning Engineer (Intern),simplehuman,N/A,"Torrance, CA 90502","['Support the management, curation, and manipulation of large file-size data assets including audio, image, and video data on local machines and cloud-based data services.', 'Support the development and execution of multi-dimensional data array manipulation methods in Python and Numpy as part of ongoing dataset development efforts.', 'Assemble data from various public and private sources', 'Support the creation of datasets through recording video, taking pictures, recording audio as necessary.', 'Research and development of machine learning systems, from model development, training, to deployment on low power devices, as skills, interests, and needs align.', 'Python and Numpy (or other array manipulation package)', 'Reasoning about and working with multi dimensional data arrays', 'OpenCV, Librosa, Tensorflow, Keras, PyTorch', 'Machine learning projects involving image, video, or audio data', 'AWS S3, Linux', 'BS or MS Degree in Computer Science, Applied Mathematics, Physics, or related field', 'Tight-knit team with work hard, play hard tradition – we take pride in individual and team success and push boundaries to make the best products.', 'Cool office with full-court gym + fitness activities/classes (basketball, yoga, volleyball, badminton, krav maga, more) + weight room', 'Free Friday breakfasts + birthday celebrations + holiday parties/trips + juice club', 'Great Benefits + Competitive Compensation']",2020-08-08 12:59:28
Data Engineer,Proactive MD,3.3 out of 5,"Mauldin, SC","['Competitive wages with opportunities for performance-based increases', 'A chance to be part of a truly innovative healthcare company that believe in putting the patient first.', 'Research and deploy innovative statistical and scientific techniques to Proactive MD datasets.', 'Apply machine learning and deep learning methods (e.g. regression, neural networks, etc.) to enhance Proactive MD’s predictive analytics capabilities.', 'Develop data models to improve analytic performance and unlock new data insights.', 'Build and maintain data pipelines for the extract, transformation, and load of clinical data, medical and pharmaceutical claims, and other key data feeds.', 'Deliver and present analyses to internal and external customers as required.', 'Perform other duties as assigned by EVP, Health Data Science and/or executive leadership.', 'Act as a champion for our ""patient promise"" and mission, vision, and values and partner across the company to drive a high-performance work environment.', 'Bachelor’s degree or higher from an institution recognized by the Council for Higher Education Accreditation, with relevant coursework in advanced statistical methods, computer science, and mathematics.', 'Experience using data science and machine learning packages (e.g. Tensorflow, pandas, Healthcare.ai)', 'Experience using SQL for data management and query. Experience building or maintaining data pipelines with Microsoft SQL Server / Azure preferred.', 'Excellent verbal and written communication skills.', 'Excellent interpersonal, negotiation, and conflict resolution skills.', 'Excellent time management skills with the proven ability to meet deadlines.', 'Strong analytical and problem-solving skills.', 'Expert proficiency with Microsoft applications, including intermediate-to-advanced Microsoft Excel and Microsoft Access skills.', 'Proficiency with advanced statistical analysis packages (e.g. SAS, SPSS, or R)']",2020-08-08 12:59:28
Data Platform Engineer (Minneapolis or Remote),Branch,5 out of 5,"Minneapolis, MN","['Take ownership of the data warehouse and data pipelines to improve performance, consistency, and quality; includes monitoring, enhancement, and general maintenance of data pipelines', 'Partner with data science, engineering and product on schema design, event structure and data architecture to enable scalability', 'Drive improvements of SQL query performance through code reviews and appropriate changes to architecture', 'Create custom logic and scripts to automate manual data related tasks (including data science model pipeline)', 'Help build a strong data platform team and grow a strong data culture', '5+ years of experience designing, implementing and maintaining data pipelines and databases with', 'Deep experience of OLTP (MySQL, Postgres, etc…) and OLAP (BigQuery, Redshift) databases', 'Strong fundamental knowledge of designing, building and maintaining transactional databases and a data warehouse (star schema etc)', 'Experience with event driven architectures and streaming ETL', 'Fluent in SQL and experience with Python', 'BS in Computer Science or equivalent program', 'Bonus points for', 'Experience with Google Cloud Platform', 'Payments experience (or related industry)', 'Company-paid medical, dental, and vision', '401k', 'Stock Options', 'Flexible time off', 'Paid Holidays']",2020-08-08 12:59:28
Data Engineer,Texas Mutual Insurance Company,3.9 out of 5,"Austin, TX 78723","['Use data knowledge to identify, retrieve, prepare, manipulate, calculate, and exploit structured and unstructured data sets to create new data sets', 'Evaluate new data sets for use in data modeling and report building', 'Design and automate data pipelines and integrate different data sources', 'Maintain the data environment', 'Use data prep/modeling tools (e.g. WhereScape, Alteryx, or SSIS)', 'Use data visualization tools (e.g. Tableau)', 'Resolve data quality issues', 'Provide advanced technical expertise and consultation to others with regards to data, systems, tools, and key concepts', ""Bachelor's degree"", '5+ years of related data experience', 'Quantitative degree preferred (e.g. Computer Science, Mathematics)', 'Programming experience (Python/R)', 'Experience building data pipelines for machine learning', 'Experience managing cloud data assets', 'Experience with data preparation tools', 'Dimensional modeling knowledge', 'Insurance industry knowledge', 'Advanced SQL skills', 'Day one health, dental, and vision insurance', 'Performance bonus', '401k plan with 4% basic employer contribution and 100% employer match contribution up to 6%', 'Vacation, sick, holiday and volunteer time off', 'Life and disability insurance', 'Flexible spending account', 'Free on-site gym and fitness classes', 'Professional development', 'Tuition reimbursement', 'Pet insurance', 'Free identity theft protection', 'Company-sponsored social and philanthropy events']",2020-08-08 12:59:28
Data Engineer/ ETL Developer,SDH Systems,N/A,"Chicago, IL 60604","['Create and enhance datasolutions enabling seamless delivery of data and is responsible for collecting, parsing, managing and analyzing large sets of data across different domains for analysis.Works with various departments in collecting requirements and creates tables to load data based on business requirements. Manages data in Development, QA and PRODUCTION environments ensuring seamless delivery to the customers.', 'Use different Data warehousing concepts to build a Data warehouse for internal departments of the organization.Applies Data warehousing concepts such as star and snowflake schema approach while creating tables and maintaining data to ensure data integrity.', 'Designs and develops data pipelines, data ingestion and ETL processes that are scalable, repeatable and secure for stakeholder needs.Designs ETL Processes using Informatica tool to extract data from heterogeneous sources and transforms data using complex logic as per business needs and ingests it into our warehouse.', 'Build Data architecture to support data management strategies to support business intelligence efforts for various stakeholders.Ensures data stored in the warehouse can be used to create dynamic Business Intelligence reports for complex analysis helping in making business driven decisions.', 'Leads the design of the logical datamodel and implements the physical database structure and constructs and implements operational data stores and dataManages access to confidential data by creating database views and data marts for customers and ensures confidential data is shared using company policies.', 'Support deployed dataapplications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution Data Pipeline Management.Works with other team members in analyzing the data and advises on how to improve data quality and provide cleaner solutions to business stakeholders.', 'Develops real-time and batch ETL dataprocesses aligned with business needs, manages and augments data pipeline from raw OLTP databases to data solution structures.Builds complex ETL process using Informatica to transform the data as per business needs and automated the process capturing real time data and maintaining history for complex analysis.', 'Documents data flow diagrams, security access, data quality and data availability across all business systems.Documents all processes of every project using JIRA for reference by any other member on the team and ensures it is always secure.']",2020-08-08 12:59:28
Sr Data Engineer with Strong Python/SQL skills,Volto Consulting,N/A,"Santa Clara, CA","['Hard core data engineering experience in Python, SQL and Relational database, Datawarehouse/Data-Lake.', 'Experience in Big Data, Hadoop ecosystem.', 'Expert in writing, analysing and tuning complex SQL queries.', 'Experienced in extracting data from variety of sources, integrate them and prepare data model for optimal data delivery.', 'Strong functional and object-oriented experience in python.', 'Experience in creating and automate ETL pipelines and robust data workflow.', 'Experience in developing and using Restful APIs and able to integrate your application with other components using Python.', 'Expert in packaging python code for release and deployments using DevOps tools (Git, Jenkins).', 'Excellent written and verbal communication and interpersonal skills, able to effectively collaborate with technical and business partners.', 'Experience with Docker containerization and Kubernetes.', 'Experience in working with workflow schedulers like Airflow, Luigi, Oozie etc.', 'Monday to Friday', 'Big data, Hadoop: 5 years (Required)', 'SQL: 6 years (Required)', 'data warehousing, ETL: 7 years (Required)', 'Python: 7 years (Required)', 'Possible', 'One location', 'Temporarily due to COVID-19']",2020-08-08 12:59:28
Data Engineer/ETL Specialist,"Keypoint Intelligence, LLC",N/A,"Weymouth, MA 02189","['Data Intuition', 'Data Visualization & Communication', 'Data Wrangling', 'Data Warehousing', 'Statistics', 'Programming Skills - Low Code, Workflow, .NET', 'Knowledge in Machine Learning', 'DOMO (or other reporting platform, such as', 'KNIME (or other ETL/Worflow Automation platform)', 'SQL Server', 'VB or C#', 'Outsystems (or other low-code platform)']",2020-08-08 12:59:28
Lead Data Engineer,DLL,4.3 out of 5,"Wayne, PA","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and enabling data-driven decisions across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate, secure, and available for key stakeholders and business processes that depend on it.', 'Contributes to engineering communities of practice, and documents work.', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Works closely with a team of frontend and backend engineers, product managers, and analysts.', 'Defines company data models, uses ELT pipeline and data streaming tools to populate data models.', 'Designs data integrations and data quality framework.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'BS or MS degree in Computer Information Science or related technical field', '8-10 years of Information Technology experience with data management', '5+ years of software engineering experience in Python, Scala, Java, or .NET', '5+ years of experience with schema design, dimensional data modeling, and data storage technology', '5+ years of multiple kinds of database experience (SQL and No-SQL)', 'Proven ability in managing and communicating data warehouse plans to internal clients', 'Experience designing, building, and maintaining secure, reliable batch and real time data pipelines', 'Experience with cloud data ingestion, data lake, and modern warehouse solutions (Azure is a plus)', 'Experience with event streaming platforms like Kafka or Azure Event Hubs', 'Ability to provide data architecture and engineering thought leadership across business and technical dimensions solving complex business cases', 'Possesses a deep understanding of enterprise software patterns and how they may be leveraged in modern data management', 'Knowledge of best practices and IT operations in an always-up, always-available service', 'Experience with or knowledge of Agile Development methodologies (SAFe is a plus)', 'Excellent analytical problem solving and troubleshooting skills', 'Excellent oral and written communication skills with a keen sense of customer service', 'Excellent team player with proven ability to influence', 'Highly adaptable to a continuously changing environment', 'Able to give and receive open, honest feedback and to foster a feedback environment', 'Outstanding communication, interpersonal, relationship building skills for team development', 'Possible Travel (10%)', 'Experience within financial services is a plus', 'Two working days per year volunteering for a local charity', 'Flexible hours with possibility to work from home (within job scope)', 'Career development opportunities: online learning, member development programs, Tuition reimbursement program.', 'Company matching 401k program', 'Industry leading Paid Time Off package', 'Outstanding Medical, Dental, Vision benefit programs', 'One month fully paid sabbatical after seven years of service', 'The selection process may involve an assessment.', 'Applications via email will not be reviewed. We advise you to apply online via our career website workingatDLLgroup.com', 'DLL’s referral program applies.']",2020-08-08 12:59:28
Data Engineer,JSR Tech Consulting,N/A,"Newark, NJ","['Design scalable processes in event driven architecture to support Fixed Income applications', 'Develop near real time streaming analytics using Kafka/Kinesis', 'Act as Subject Matter Expert and help rest of the team in leveraging the platform and migrating applications to it', 'Establish end to end data lineage and data catalogue. Work with data governance team to setup data quality checks and metrics', 'Create self-service notebook environment with Zeppelin/Jupyter for exploratory data analytics and rapid interactive development', 'Troubleshoot any performance issues and ensure efficient data organization', 'Build efficient web-based tools for monitoring and tracking', ""Bachelor's degree in computer science or related field required. Master's degree preferred"", 'Knowledge of data structures, algorithms and functional programming', 'Passion to learn new things, experiment with new ideas and build world class data platform', '5+ years of experience in programming with Scala, Python or Java', '2+ years of experience in Scala, Spark and functional programming. Deep knowledge of spark internals such as partitioning, DAG, lazy evaluation.', 'Strong experience with relational data bases, SQL, and query optimization. Knowledge of data warehousing, dimensional data model and business intelligence is a plus.', 'Knowledge/experience with event driven programming and Akka actor model', 'Excellent verbal and written communication skills', 'Experience with AWS infrastructure, docker, ECS/EKS, EMR, Kafka/Kinesis.', 'Front-end development experience with Angular, Java Script, Reactive Programming.', 'Knowledge or desire to learn Investment Management, Fixed Income and Finance', 'Familiarity with NoSQL and ElasticSearch']",2020-08-08 12:59:28
Marketing Analytics Data Engineer,Boston Scientific Corporation,4 out of 5,"Marlborough, MA 01752","['Establish, maintain, and own the marketing analytics data lake using Google BigQuery.', 'Develop datasets to support ad-hoc analytical needs and reporting.', 'Monitor data pipelines for accuracy, missing data, enhancements, changes, and billing volumes to ensure all data is captured and processed accurately and when needed.', 'Ensure that all processes for receiving, processing, and evaluating data are efficient, replicable and documented.', 'Work cross-functionally with marketing, IT and other analytics teams to educate on data availability and access procedures.', 'Proactively consult with the marketing analysts to ensure data collection and pipelines are in place for all required technologies and programs.', 'Fulfill ad-hoc requests and data processing needs with guidance from senior data engineers and marketing analysts.', 'Bachelor’s degree in IT, data science, mathematics, engineering or related fields.', '2+ years of experience with data modeling, data warehousing, and building ETL pipelines.', 'Expertise with Google BigQuery is a must.', 'Experience with Google Analytics, FiveTran, and Salesforce is preferred.', 'Expertise with data analysis using SQL, Python, Excel, and similar tools.', 'Strong working knowledge with data visualization tools (e.g. Tableau, and Google Data Studio).', 'Strong verbal and written communication skills.', 'Demonstrated collaborative skills with individuals from varied backgrounds (e.g. IT, marketing content creators).', 'Strong ability to multi-task and balance competing priorities effectively.']",2020-08-08 12:59:28
Data Engineer / Data Modeler,Pyramid,3.9 out of 5,"Charlotte, NC","['Data Engineer with hands on experience on ETL process.Experienced in working with Python.', 'Experienced in developing Web Services with Python programming language.', 'Integrate up-and-coming data management and software engineering technologies into existing data structures.', 'Develop set processes for data mining, data modeling, and data production.', 'Create custom software components and analytics applications.', 'Hadoop: 5 years (Preferred)', 'Python: 5 years (Preferred)', 'ETL: 5 years (Preferred)', 'Likely', 'Yes', 'Other', 'Monday to Friday', '8 hour shift', 'Other']",2020-08-08 13:00:13
Data Engineer,Strong Analytics,N/A,"Chicago, IL 60611","['Competitive salary', 'Profit sharing or equity, based on experience', '100%-covered Health insurance for employees, 75%-covered dependents', 'Four weeks PTO', 'Work-from-Home Wednesdays', '401(k) matching', 'Personalized monthly perks with matched charitable donations', 'Python', 'SQL', 'Relational Databases (e.g., Postgres, MySQL)', 'Distributed Computation (e.g., Spark, Hive, Hadoop)', 'Deploying and Managing Cloud Services (we use AWS/Azure)', 'Interacting with and building RESTful APIs', 'Git']",2020-08-08 13:00:13
Data Engineer - Advanced Technology Group,Cognizant Technology Solutions,3.9 out of 5,"Atlanta, GA",[],2020-08-08 13:00:13
Data Engineer,"Rooftop Digital, LLC",N/A,"Agoura Hills, CA 91301","['Develop data pipelines and build out integrations to support continuing increases in data volume and complexity.', 'Assist in the design, construction, testing and maintenance of data management systems.', 'Build high-performance algorithms, predictive models, and prototypes.', 'Evaluate and integrate data management and software engineering technologies into existing data structures.', 'Develop set processes for data mining, data modeling, and data production.', 'Research new uses for existing data.', 'Utilize appropriate languages and tools to connect systems together.', 'Collaborate across functional teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.', 'Implement processes and systems to monitor data quality, data accuracy and data availability.', 'Initiate and validate disaster recovery procedures.', 'Ensure that all systems meet the business/company standards as well as industry practices and compliance requirements.', 'Perform data analysis as required to troubleshoot data related issues and assist in the resolution of data issues.', 'Recommend different ways to constantly improve data reliability and quality.', 'Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics statistics.', '4+ years of SQL experience (No-SQL experience is a plus)', 'Practical experience or knowledge of Python or R is a plus', 'Experience in a marketing or related field using large data sets', 'Experience with or knowledge of Agile Software Development methodologies', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills']",2020-08-08 13:00:13
Data Engineer,"KeHE Distributors, LLC",3.1 out of 5,"Naperville, IL 60563","['Develop, construct, test and maintain optimal data pipeline/ETL architectures', 'Work closely within the team to prepare data for predictive and prescriptive modeling', 'Optimize AWS data delivery infrastructure for greater scalability', 'Utilize SQL as well as big data tools and frameworks to optimize data acquisition and preparation from enterprise data lake and data warehouse', 'Work with Enterprise Cloud Architecture teams to strive for greater functionality in our data systems', 'Develop architecture required to return data to data warehouse for front-end product utilization', 'Curate data models in the data warehouse to be used by front-end advanced analytics designers', 'Provide production level code reviews for the team', 'Help design, maintain and implement quality assurance and testing approaches', 'Deploy scripts and architectures to production via Jenkins', 'Bachelor’s Degree in Computer Science, Mathematics, Engineering, Management Information Systems or related field', '1-3 years of experience building data pipelines within the AWS ecosystem', '1-3 years of experience designing and implementing data warehouse solutions', 'Advanced SQL and data design concepts', 'Proficient programing experience using Python, R or similar language with experience building production level code', 'Proficient working with Jenkins and deploying to production via Jenkin’s jobs', 'Desire to stay up to date with current technologies and best practices for data management and data science', 'Drive innovation and efficiency through new approaches', 'Ability to work in a team environment that promotes collaboration', 'Experience implementing AWS architecture using Serverless Framework', 'Understanding of C programming language', 'Experience utilizing big data tools such as PySpark, Scala or others']",2020-08-08 13:00:13
Data Engineer,UnitedHealth Group,3.7 out of 5,"Denver, CO","['Contribute to the success of the Healthcare Economics Data Management team', 'Design, develop, maintain, monitor and administer production ETL processes (PLSQL, Informatica, T-SQL)', 'Investigate production ETL issues / problems', 'Map database sources to specified data formats', 'Verify and validate ETL deliverables incoming/outgoing', 'Provide direction and mentoring of junior colleagues on topics related to datamart design and ETL deliverables', 'Lead troubleshooting episodes and communicate solutions/resolutions to the team', 'Translate concepts to requirements, then design, and develop into an automated production process', 'Act as a subject matter expert for other team members on assigned processes', 'Complete projects and development activities timely and accurately while following the System Development Life Cycle (SDLC)', 'Suggest changes and enhancements for processes.', 'Maintain ongoing self-study program to enhance knowledge of PL/SQL development, Oracle RDBMS Best Practices and Informatica PowerCenter', 'Document hours of design/development activities by following SDLC and IS Change Management', 'Performs all other related duties as assigned.', ""Bachelor's degree in Information Systems, Computer Science or 5 years of related work experience."", '3+ years of experience in Datamart design with Oracle (10g/11g/12c) databases', '3+ years of experience in PL/SQL development', '3+ years of experience in SQL', 'Strong knowledge of Data Warehousing schema design', 'Data Warehouse Extract, Transform, and Load knowledge', 'Production ETL operations and monitoring', 'Database query optimization', 'Windows Command/PowerShell, Cygwin scripting experience', 'Ability to work a flexible schedule to accommodate meetings in various time zones', 'Experience with MS SQL Server:2016 T-SQL; SSIS; Jobs Management', 'Experience with Informatica PowerCenter', 'Experience with Extract, Transform, and Load (ETL) tools', 'ESRI ArcGIS Pro', 'Oracle APEX development', 'All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.']",2020-08-08 13:00:13
Data Engineer,Kar Global,3.2 out of 5,"Carmel, IN 46032","['Collaborate with business partners to understand processes and the relationship to data velocity, availability, and quality', 'Identify improvement areas to enhance existing data processes and offerings', 'Design and recommend modern data warehousing solutions', 'Implement simple, intuitive data engineering and visual solutions', 'Mentor others to improve analytical skillsets across the organization', 'Design solutions with a focus on cloud, PaaS, SaaS, and serverless services', 'Data Warehouse and Business Intelligence experience', 'Strong problem-solving skills, with the ability to analyze and break down problems', 'Advanced SQL and RDBMS experience (ex. Snowflake, RedShift, Oracle, SQL Server, MySQL, etc.)', 'Experience engineering data ingestion and transformation solutions (ex. Azure Data Factory, Informatica, SSIS, Talend, Pentaho, Python, Databricks, stored procedures, etc.)', 'Advanced ability to visualize data (Tableau experience preferred)', 'Understanding and practice of Agile and DevOps principles', 'Experience with cloud warehousing and analytics (ex. Snowflake, Redshift, BigQuery)', 'Experience with semi-structured and unstructured data', 'OOP or functional programming experience (ex. Python, Java, C++, Scala, R, etc.)', 'Working knowledge of message queuing and stream processing', 'We’re a technology company delivering next generation tools to accelerate and simplify remarketing.', 'We’re an analytics company leveraging data to inform and empower our customers with clear, actionable insights.', 'And we’re an auction company powering the world’s most advanced and integrated mobile, digital and physical auction marketplaces.', 'Competitive compensation', 'Insurance coverage that includes medical, dental, vision and life insurance', 'Flexible spending account', 'Wellness program', '401(k) with employer match', 'Employee stock purchase program', 'Paid holidays and generous paid time off', 'Paid parental leave', 'Learning and development resources']",2020-08-08 13:00:13
Big Data Engineer,4S,N/A,"Arlington, VA","['Participate in architecture design', 'Design, develop, and implement scalable fault tolerant data pipelines', 'Monitor and tune existing pipelines and infrastructure', 'Maintain and improve existing solutions', 'Build metrics, analysis, machine learning, and dashboard visualizations', 'Built analytics and machine learning solutions', 'Other duties as assigned', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', 'Big Data experience in both structured and unstructured data', '5+ years working with SQL and NoSQL database platforms including data modeling, writing queries, and performing data analysis', '5+ years demonstrated professional experience with Big Data platforms and tools including Hadoop, GraphDB, Kafka, Spark.', 'Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)', 'Strong software engineering skills using Python and Scala.', 'Work experience on teams using Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', 'Familiarity with DevOps tools, e.g., Jenkins, GIT, Jira, Confluence, Sonar, Nexus', 'Experience with Data Lake concepts and design patterns', 'Experience with BI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)', 'Understanding of Data Management and Data governance best practices', 'Ability to own a project from inception to completion', 'Good communication skills', 'Decision making skills', 'Self Motivated', 'Able to work with a team']",2020-08-08 13:00:13
Data Engineer - Remote,SmileDirectClub,2.9 out of 5,"Nashville, TN 37219","['Design and build new dimensional data models and schema designs to improve accessibility, efficiency, and quality of internal analytics data', 'Build, monitor, and maintain analytics data pipelines', 'Implement systems for tracking data quality and consistency', 'Work closely with Analytics, Marketing, Finance, and Operations teams to understand data and analysis requirements', 'Work with teams to continue to evolve data models and data flows to enable analytics for decision making (e.g., improve instrumentation, optimize logging, etc).', 'Has a curiosity about how things work', 'Has built large-scale data pipelines professionally and can craft clean and beautiful code in Java, Scala, Python and/or SQL', 'Has built batch data pipelines with Hadoop/Spark as well as with relational database engines, and understands their respective strengths and weaknesses', 'Has experience with cloud platforms, preferably Amazon Web Services', 'Experience with event streams, preferably Kafka', 'Has experience with ETL jobs, metrics, alerting, and/or logging', 'Can jump into situations with few guardrails and make things better', 'Possesses strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems, and information retrieval', 'Is a strong communicator. Explaining complex technical concepts to product managers, support, and other engineers is no problem for you', 'When things break, and they will, is eager and able to help fix them', 'Has experience with MPP data warehouses (Redshift, Snowflake, or similar)', 'Is someone that others enjoy working with due to your technical competence and positive attitude', 'Academic background in computer science or mathematics (BSc or MSc)', 'Experience building simple scripts and web applications using Python', 'A solid grasp of basic statistics (regression, hypothesis testing)', 'Experience in small start-up environments', 'Medical, Dental and Vision Insurance', '401K with match', 'PTO', 'Aligner and Whitening Benefit', 'Collaborative work environment and positive culture', 'Medical, Dental and Vision Insurance', '401K with match', 'PTO', 'Aligner and Whitening Benefit', 'Collaborative work environment and positive culture', 'What is SmileDirectClub? Link here.', 'What are our customers saying? Link here.', 'What is a SmileShop? Link here.', 'What is our culture like? Link here.', 'How do we celebrate your team members? Link here.']",2020-08-08 13:00:13
Data Engineer,GalaxE.Solutions,2.6 out of 5,"Hartford, CT 06103","['Design and support the database and table schemas for new and evolving sources of data being brought into the data warehouse', 'Create and support the Analysis Services', 'Monitor and troubleshoot performance issues', 'Define and promote the team’s design principles and best practices', 'Work with business teams to be able to define requirements for real time reporting', '7+ years of experience in IT as a Data Engineer', 'Experience with the following: Python, Hadoop, Hive, and Spark (either Pyspark or Scala)', 'AWS experience']",2020-08-08 13:00:13
Big Data Engineer/Developer,"DynPro, Inc.",3.7 out of 5,"Minneapolis, NC","['Big Data Engineer/Developer', 'Duration – 6 – 12+ Months', 'Location: Minneapolis, MN (Preferably local to Minnesota)', 'Design, develop, test, deliver and operate software solutions for big data and AI problems', 'Apply test-driven and Agile software development methodologies', 'Develop solutions that can scale in system and data size', 'Ensure high reliability for production systems', 'Innovate constantly to improve quality, efficiency, reliability', 'Collaborate with customers to define and meet requirements', 'BS or advanced degree in Computer Science or related field, or equivalent experience', '5+ years’ experience in developing software applications', '2+ years’ experience working on BigData technologies like Hadoop (Hive, HBase, Ooozie) and Spark', 'Understand application/software development and design.', 'Proficiency in at-least one of the following languages: Java, Scala, Python', 'Experience with building and supporting distributed systems. Experience with REST services preferred.', 'Experience with one of more standard automation toolkits (e.g. ansible, chef, puppet, salt) is preferred.', 'Fluency in Unix command line tools and bash is preferred.', 'Experience with streaming and messaging tools (like Kafka, JMS, Avro, Protobuf) is a plus.', 'Experience with one or more cloud deployment automation tools (e.g. OpenStack, docker) is a plus.', 'Experience with a job scheduler like Jenkins, drone, rundeck is a plus.']",2020-08-08 13:00:13
Data Engineer,Benefits Data Trust,3.3 out of 5,"Philadelphia, PA 19102","['Build out our new GCP data platform and collaborate on architectural patterns for it with the Data Engineering team', 'Support the development of machine learning models with productionizing, monitoring and alerting tools', 'Write, update, and maintain ETL jobs across our data pipelines (mostly in Airflow)', 'Implement continuous improvements using our existing tools/technologies, which include SQL, Airflow, Python, Docker/Kubernetes, and others such as Terraform and Apache Beam. May also be expected to research and select other tools when the situation demands', 'Collaborate with internal customers to identify ongoing platform improvements (teams including Analytics, Projects, Policy, Software Engineering, and others throughout the organization)', ""Consult to software engineers on data-related changes to BDT's suite of software applications, including schema/model design, table structure, and data collection"", 'Engage with colleagues and collaborators using curiosity, critical thinking, a drive to completion, empathy, and a focus on impact', 'Follow existing data access and performance design standards for the data platform, software engineering, and all products and services accessing BDT information', 'Communication and Relationship-building – with technical peers and some stakeholders', 'Cloud-based Solution Implementation, of data platforms and infrastructure, including event-driven architectures, microservices and pattern design, supporting compliance and regulated environments (including PII and PHI)', 'Workflow and pipeline development to ensure reliability, availability, and consistency', 'Systems Engineering – on-system service management, typically in *nix environments', 'Data Modeling and Warehousing – proficient understanding of relational data structures and schemas; some familiarity with semi-structured, unstructured (big data) schemas', 'Automation, monitoring, and alerting – creating these tools based on existing designs and frameworks; resolving bugs and issues', 'Cloud engineering – working towards certification on any of the major hyperscale cloud platforms', 'Data Encapsulation & Transfer methodologies – understands standards for file formats and transfer methods', 'Also interested in relevant experience including:', 'o Experience with BI implementations/uplifts (we currently use Looker) and/or Data Governance models and methods', 'o Machine learning techniques, productionizing machine learning models, and/or creating models']",2020-08-08 13:00:13
Data Center Capacity Engineer,Facebook,4.2 out of 5,"Newton County, GA","['Responsible for the planning and technical execution of projects throughout the Data Center.', 'Work as a technical lead with cross-functional data center teams on large-scale data center projects and initiatives.', 'Provide guidance and mentor technical peers and be a go-to technical resource to evaluate and look for better ways to resolve issues and define updates to tools and processes.', 'Track issues and interpret data looking for trends and systemic issues that impact fleet uptime and utilization. Perform root cause analysis of complex technical issues and drive resolution.', 'Plan for large-scale deployments of hardware, while considering space, power, cooling, networking, and resiliency.', 'Provide cross data center support and identify potentially larger issues, displaying effective communication when something is identified.', 'Help develop global standards for processes, workflow and automation roadmaps for tools that facilitate deployment, maintaining and decommissioning of server hardware at scale.', 'Lead process improvements and best practice in data center operations.', ""Work with internal hardware teams and vendors to help resolve complex technical issues that affect Facebook's computing infrastructure."", 'Understand and be able to update and develop scripts and smaller sets of software.', 'Build cross-functional relationships and have the ability to influence policies and procedures to improve global data center operations.', 'Participate in an on-call rotation.', 'BS, BA or BEng or equivalent experience/certification.', '5+ years of infrastructure or related experience.', 'Knowledge of Linux and hardware systems support in an Internet operations environment.', 'Knowledge of the interdependencies of data center functions and technologies.', 'Experience managing multiple projects within the same time schedule.', 'Knowledge of out-of-band/lights-out server communication methods, such as IPMI and serial console.', 'Time and project management experience.']",2020-08-08 13:00:13
Packaging Engineer,HCL America Inc,2.3 out of 5,"West Chester, PA 19380","['Dental Insurance', 'Health Insurance', 'Relocation Assistance', 'Vision Insurance', '8 Hour Shift', 'Packaging: 1 year (Preferred)', 'Orthopedic: 1 year (Preferred)', 'Verification Validation: 1 year (Preferred)', 'surgical instruments: 1 year (Preferred)', 'www.hcltech.com', 'www.hcltech.com']",2020-08-08 13:00:13
Senior Data Engineer (100% Remote),Moveworks.ai,N/A,Remote,"['Work with various internal teams and customers to gather requirements and deliver data solutions to address those requirements', 'Model data and metadata to support analytics and reporting for different use cases', 'Design and implement a data platform to process large, complex data sets', 'Implement best practices around data integrity, validation, and documentation for data processing, reporting, and analysis', 'Optimize data processing pipelines and storage performance', 'Build the team of talented data engineers and coach them as the company grows', 'You have 4+ years of experience as a data engineer, ideally with a cloud-based SaaS company', 'Strong coding and design expertise', 'Familiarity with latest data processing and warehousing technologies is required', 'Hands on experience working with different teams for their data requirements', 'Experience with some data stores, such as Postgres, MySQL, HBase, etc.', 'BS or higher in Computer Science or a related field', 'Experience with large-scale machine learning pipelines is a plus']",2020-08-08 13:00:13
Data Engineer (Spark+Hadoop),NTT DATA Services,3.5 out of 5,"Irving, TX","['Analyze and understand data sources & APIs', 'Design and Develop methods to connect & collect data from different data sources', 'Design and Develop methods to filter/cleanse the data', 'Design and Develop SQL , Hive queries, APIs to extract data from the store', 'Work closely with data Scientists to ensure the source data is aggregated and cleansed', 'Work with product managers to understand the business objectives', 'Work with cloud and data architects to define robust architecture in cloud setup pipelines and work flows', 'Work with DevOps to build automated data pipelines', 'Hands-on experience with the Hadoop eco-system (HDFS, MapReduce, Yarn, Hive, Pig, Impala, Spark, Kafka,)', 'Good understanding for ETL tools like Ab-initio , TalenD', 'Familiarity with HTTP and invoking web-APIs Exposure to machine learning engineering', 'Exposure to NLP and text processing']",2020-08-08 13:00:56
AZURE DATA ENGINEER,CapB InfoteK,N/A,"Des Moines, IA","['Create functional design specifications, Azure reference architectures, and assist with other project deliverables as needed.', 'Design and Develop Platform as a Service (PaaS) Solutions using different Azure Services', 'Create a data factory, orchestrate data processing activities in a data-driven workflow, monitor and manage the data factory, move, transform and analyze data', 'Design complex enterprise Data solutions that utilize Azure Data Factory Create migration plans to move legacy SSIS packages into Azure Data Factory', 'Build conceptual and logical data models', 'Design and implement big data real-time and batch processing solutions', 'Design, build, and scale data pipelines across a variety of source systems and streams (internal, third-party, as well as cloud-based), distributed / elastic environments, and downstream applications and/or self-service solutions.', 'Develop and document mechanisms for deployment, monitoring and maintenance', ""Bachelor's degree or higher in Computer Science Engineering/ Information Technology, Information Systems"", '3+ years experience with Microsoft Cloud Data Platform: Azure Data Factory, Azure Databricks, Python, Scala, Spark SQL, SQL Data Warehouse', '3+ years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL, data lake solutions', 'Expertise with SQL, database design/structures, ETL/ELT design patterns, and DataMart structures (star, snowflake schemas, etc.)', 'Functional knowledge of programming scripting and data science languages such as JavaScript, PowerShell, Python, Bash, SQL, .NET, Java, PHP, Ruby, PERL, C++, R, etc.', 'Creation of descriptive, predictive and prescriptive analytics solutions using Azure Stream Analytics, Azure Analysis Services, Data Lake Analytics, HDInsight, HDP, Spark, Databricks, MapReduce, Pig, Hive, Tez, SSAS, Watson Analytics, SPSSA', 'Experience in Azure Data Factory (ADF) creating multiple pipelines and activities using Azure for full and incremental data loads into Azure Data Lake Store and Azure SQL DW', 'Experience for Azure Data Lake Storage and working with Parquet files and partitions', ""Experience managing Microsoft Azure environments with VM's, VNETS, Subnets, NSG's, Resource Groups, etc."", 'Experience in Creation & Configuration of Azure Resources & RBAC', 'Experience with Git/Azure DevOps', 'Azure certification would be desired', 'Must have an ability to communicate clearly and be a team player']",2020-08-08 13:00:56
Data Engineer,Sinclair Broadcast Group,2.9 out of 5,"Cockeysville, MD 21030","['Familiar with the modern cloud data platforms (Azure preferred but AWS is ok). In particular, experience in some of the following is preferred:Azure Data Lake (Analytics and Storage), Data Warehouse / Synapse Analytics / Amazon Redshift, Data Factory, Logic Apps, Data BricksOther preferred technologies include: Advanced T-SQL (SQL Server), REST API concepts, Powershell, SSIS, PowerBI', 'Experience in database design, architecture and warehousing', 'Experience creating ETL/ELT processes to move data between internal and external sources using APIs, ETL.', 'Fundamental understanding of Data Lakes, Data Catalogs, Hardware and Network Topology', 'Experience with Object-Oriented Programming Languages such as Python, JavaScript, Java, C#, etc.', 'Experience using data reporting and visualization tools (e.g. Cognos, SSRS, Qlik, Data Studio, Power BI, Tableau, etc.)', 'Algorithmic concepts from at least one information-centric discipline (e.g. statistics, machine learning, information processing, natural language processing, etc.)', 'Gathering data requirements from stakeholders', 'Evaluating data collection for accuracy', 'Data Governance concepts', 'Mindful of practices, procedures and legal guidelines that govern PII and other sensitive data', 'Ability to tackle complex problems with creative solutions when the path may not be clear.']",2020-08-08 13:00:56
Data Engineer - Sustainable Packaging,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', ""Bachelor's degree in Computer Science, Engineering, Mathematics, or a related technical discipline"", 'Experience in Data Engineering, BI Engineer, or related field', 'Track record of data management fundamentals and data storage principles', 'Hands-on experience and advanced knowledge of SQL, Python etc.', 'Demonstrated strength in data modeling, ETL development, and data warehousing', 'Knowledge of distributed systems as it pertains to data storage and computing', '2+ years of experience as a Data Engineer, BI Engineer, or Systems Analyst in a company with large, complex data sources.', 'Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets', 'Experience working with AWS big data technologies (EMR, Redshift, S3, Glue, Kinesis and Lambda)', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Experience providing technical leadership and mentoring other engineers for best practices on data engineering', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations']",2020-08-08 13:00:56
DATA ENGINEER,Bangura Solutions,N/A,Remote,"['Develop a Data Migration Strategy and document, which covers business/data quality requirements, sources of data from the legacy systems.', 'Manage the data cleansing and migration work-stream.', 'Oversee the implementation of interfaces.', 'Lead the data work-stream in developing various mappings and process flows using SQL and other business intelligence tools to migrate data from the Legacy systems.', 'Develop Test plans, scripts an execution test cases for Systems End to End testing and UAT.', 'Housing', 'Data Cleansing', 'Data Migration', 'Interfaces', 'Full data lifecycle of project.', 'Excel for data cleansing and migration', 'Experience of data migration from Northgate OHMS', 'Experience of Housing, Local Council, Repairs, Asset Management interfaces', 'Experience of Oracle and SQL Server', 'Experience of managing Junior Staff', 'Full understanding of data protection practice and GDPR', 'Database administration experience and understanding of data management']",2020-08-08 13:00:56
Business Intelligence Engineer,Conde Nast,4 out of 5,"New York, NY 10007","['Provide team leadership and management for BI engineers and Business Partners on our Business Intelligence team to provide reporting, dashboards, insights and quantitative support for longer-term strategic projects', 'Build our client facing analytics solutions and works with vendors/ internal teams to architect a highly scalable solution', 'Manage curation and expansion of our centralized business intelligence platform ensuring a standardized and unified data modeling layer, and experience optimized for self-service of end users with basic data retrieval needs', 'Manage and align team and individual priorities, in order to most effectively support business objectives, while also maintaining bandwidth for interrupt-driven requests as well as proactive insight generation', 'Maintain strong relationships with stakeholders across the organization to drive consistent process for inbound requests, and a higher degree of action ability and impact resulting from reactive work.', 'Manage working relationship between BI team and Data Engineering team, ensuring short-term needs are met while helping craft long-term data warehousing objectives', 'Empower individual team members to both deepen and broaden their skills through growth opportunities that align with their goals', 'Bachelor’s degree in Computer Science, Engineering, Math, Statistics or other quantitative field', 'Strong data management skills including Excel, SQL, R, SAS or other Statistical Packages.', '5+ years of experience in BI tools like (Qlik , Business Objects , Power BI , Tableau etc.)', '5+ years’ experience working on relational databases as an architect or administrator', 'Understanding of server management and server sizing', 'Knowledge of ETL tools and data processing', 'Great relationship building qualities', 'Proven ability to manage multiple tasks while working independently', 'Strong attention to detail', 'A strong sense of urgency and commitment to get the job done quickly and with high quality', 'Excellent communication skills, both written and verbal, with people at all levels of an organization', 'Entrepreneurial nature']",2020-08-08 13:00:56
Support Engineer,LENDKEY TECHNOLOGIES INC F/K/A FYNANZ INC,N/A,Remote,"['You’ll be taking our recently inaugurated Support Desk to the next level, supporting both our business and product development teams by providing Level 1 and 2 support for all application related tickets', 'Take ownership of technical issues and requests and work with level 3 support to resolve more advanced issues', 'Support ad-hoc data extracts and system investigation', 'Participate in daily scrum of scrums.', 'Effectively interact and collaborate with all levels of employees, management, vendors and customers.', 'May be required to be on call on a rotating basis', 'Enhance our existing troubleshooting & problem resolution documentation', 'Bachelor’s Degree in Computer Science, Engineering, Management Information Systems, or relevant technology experience', 'Knowledge of computer science concepts such as object-oriented programming, and ability to apply these concepts in multiple languages', 'Knowledge of scripting languages (preferably Ruby or Python but will substitute other relevant experiences)', 'Knowledge of SQL', 'Excellent problem solving and communication skills both verbal and written', 'A strong work ethic and a positive attitude', 'Strong team orientation', 'Strong attention to detail']",2020-08-08 13:00:56
QA Data Engineer,Thrivent,3.9 out of 5,"New York, NY","['Job', 'Company', 'Develop, implement physical and virtual test data management and test environment solutions across the organization, to contribute towards the success of technology initiatives', 'Develop test data management strategies and plans relevant to each test environment (Dev, Sys and ITE) to provide right-sized, production-like, re-usable and secured test data per data requirements', 'Key responsibilities include source system data analysis, business & privacy data requirements definition, data discovery, profiling, masking & monitoring rules definition and overall data provisioning for setting up a test environment.', 'Works closely with application subject matter experts/business partners/testers to determine appropriate data sources and to define data provisioning mechanism based on the need for test data', 'Learn and contribute to the design of data management and any futuretransformation of the test environment landscape', 'Works very closely with Application Availability, Compliance and Support teams leads to maintain and support all test environments to maintain SLAs and applicable policies / standards', 'Participates in all phases of a solution delivery including test data and env requirements gathering and provisioning the required test data in the appropriate test environments', 'Conducts full lifecycle activities including requirements analysis and design, develop and deliver capabilities, and continuously monitor performance and quality control plans to identify improvements around Test Data and Test Env management process', 'Lead initiatives to design processes to capture and review test data requirements and test data provisioning techniques and plans', 'Lead work to advance and support information management practices within business processes, applications and technology that underpin the Test Data and Test Env management discipline (e.g. establishing quality processes, performing analysis, participating in technology implementation planning and verification to ensure successful installation of software and/or projects), implementing data provisioning processes, providing the right amount of data in an appropriately provisioned test environment', 'Provide leadership for Test Data & Test Env management related tasks in support of projects', ""Lead the Management and proactive improvement of Thrivent's Test Data & Test Env provisioning practice by analyzing the current systems environment, leveraging proven practices, applications, technology, tools and platforms to support and enhance the discipline"", 'Handle budget responsibilities', 'Leads the delivery, support and maintenance of solutions with one or more business and technology areas.', 'Organizational impact results from mid-large sized projects', 'Lead discussions with tool / product vendors in support of evaluating solutions for process improvements or future offerings', 'Lead set up of test data and virtual environment based on functional test requirements utilizing Enterprise standard tool sets', 'Bachelor’s degree or equivalent in MIS, Computer Science, Mathematics, Business or related field.', '5+ years of experience in Technology related field including prior lead experience. For the senior level position 8+ years of experience in Technology related field including 3+ years prior lead experience.', 'Advanced in-depth knowledge of Test Data and Test Env Management concepts and tools.', 'Strong organizational, analytical, critical thinking and leadership skills.', 'Demonstrated leadership on mid-large-scale project impacting strategic partners.', 'Advanced in-depth knowledge of data warehouse and BI systems design, streaming architecture, and architecting and implementing large business systems is desired.']",2020-08-08 13:00:56
Data Engineer,Jane.com,3.8 out of 5,"Lehi, UT 84043","['Take primary responsibility in creating and maintaining data pipelines and monitoring data movement', 'Profile data sources, create dimensional models, implement ETL, and load into data warehouse and data lake', 'Help develop and maintain applications built using Big Data solutions such as Redshift, Apache Airflow, S3, Presto, Python, and Hive', 'Work closely with teams to identify high-value data and integrate it into the data platform to empower each team to make data-driven decisions', 'Ensure data quality and establish best practices across data infrastructure', 'Build, manage, and deploy distributed systems in the AWS ecosystem', 'Create and optimize custom SQL queries to help support the analytics team', 'Gather requirements from teams and translate into codeDeliver clean, scalable, maintainable code and monitoring', 'Be passionate and hungry to learn and succeed', 'Share in on-call responsibilities for the uptime for the data warehouse and ETL processes', ""Bachelor's degree in Information Systems/CS/Engineering or equivalent experience"", '5+ years SQL experience', '5+ years developing and administering on Data Warehouse platforms such as Redshift, Snowflake, Big Query or similar architectures5+ Experience in Data Modeling (ex: Kimball, Inmon, etc.)', 'Preferred Competencies include Redshift, Apache Airflow, S3, AWS Glue, and Presto', 'Experience writing Python for ETLs and data pipelines', 'Experienced with data pipeline orchestration (ex: SSIS, Airflow, Google Composer)Experience integrating disparate data sources into a consumable data model', 'RBMS performance tuning and monitoring experience', 'Desire to work in a collaborative Agile environment solving problems as part of a team', 'Great problem solving skills and the ability to break down large problems, gather requirements, appropriately scope and break down into actionable steps', 'Experience administering Databases (backups, restores, failovers)', 'Dimensional Model Junkie', 'Redshift Expert']",2020-08-08 13:00:56
System Support Engineer,"Gaggle Net, Inc.",N/A,Remote,"['3-5 years experience supporting mail systems such as G Suite, Office 365, Exchange, Groupwise, and others', '3-5 years experience with scripting languages. Python and Bash are a must. Bonus points for Perl experience.', '1-2 years experience AngularJS and nginx', '1-2 years experience with Version control systems (git, cvs, etc..)', 'High speed internet connection', 'Knowledge of firewalls, security solutions, and content filters. The best practices for implementation as well as the ability to troubleshoot them when trying to Integrate 3rd party products into them.', '1-2 years experience with AWS and Docker', 'Ability to create basic SQL statements', 'Basic knowledge of troubleshooting a network infrastructure (servers, routers, switches, cabling, workstations, etc)', ""Single Sign On protocols and it's implementations with external systems (Active Directory, ADFS, SAML, eDirectory)"", 'Monitor/Troubleshoot/Diagnose issues with Gaggle Services and their integration into 3rd party products', 'Work with Customer Service to implement new services and help diagnose customer issues they bring to the SSE team', 'Work with the other technical teams to resolve issues or aid in the setup of services internally', 'Help identify issues where we are not being efficient and design solutions to fix the problems, not only for our team but other teams as well', 'Improve our internal tools for automation to reduce any error caused by our team or other', 'Migrate data from 3rd party systems or disk to Gaggle or to other systems (Office 365/Google/etc)']",2020-08-08 13:00:56
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 13:00:56
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 13:00:56
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:00:56
Cost Engineer,Innovative Turnaround Controls (ITC),4.5 out of 5,"Toledo, OH","['Assessing risks', 'Doing cost estimates', 'Forecasting', 'Reviewing proposed schedules', 'Implementing bets practices', 'Performing cost control', 'Analyzing variances', 'Teamwork', 'Communication', 'Networking', 'Being detail oriented', 'Being focused', 'Being amenable', 'Resolving problems', 'Communication and presentation', 'Analyzing data', 'Leadership', 'Being analytical', 'Being self motivated', 'Being dependable', 'Day Shift', 'Holidays', 'Monday to Friday', 'Night Shift', 'Weekends']",2020-08-08 13:00:56
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:00:56
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:00:56
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:00:56
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:00:56
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:00:56
Senior Data Engineer,iVinci Health,N/A,"Boise, ID 83702","['Design, develop, test and troubleshoot ETL packages', 'Map and load data from source to destination systems', 'Participation in the development and execution of unit and system test plans to ensure data quality meets or exceeds standards and thresholds', 'Story planning, development, and QA as part of our 2-week Agile sprints', 'Thrives on challenges and loves learning', 'Is self-driven, diligent, and enjoys solving problems', 'Wants to be part of a high-growth, high-innovation company that will revolutionize a market', 'Prefers a collaborative environment and is comfortable working with others and giving and receiving feedback', 'BS in Computer Science, Information Systems or related field', 'Min 5 years of significant SQL and Python development experience', 'Hands-on experience developing ETL/data integration solutions', 'Experience working with large and/or complex data sets', 'Excellent analytical, conceptual, troubleshooting, and problem-solving skills', 'Experience working with Azure Databricks', 'Experience working in a secure HIPAA/PHI environment', 'Experience with hospital or financial systems', 'Some programming skills in C#, .NET or PowerShell', 'This position is based in Boise, ID; however, remote candidates will be considered if they have a proven track record of successful remote work and are willing to work a schedule on the MTN time zone.', 'We will only consider applicants who reside within the U.S.', 'Sponsorship is not available for this position.']",2020-08-08 13:01:48
Data Engineer,GSK,4.2 out of 5,"Collegeville, PA 19426","['Partner with data teams to implement pipeline designs to support R&D strategy and conceptual data flows', 'Partner with the metadata leads to translate conceptual data models into physical database/tables optimized for data analytics in RDIP using established environments and tools', 'Assist the design, build, test and maintenance of data acquisition and processing pipelines including but not limited to the creation/maintenance of appropriate artifacts', 'Ensure the preservation of data integrity from source to target state including but not limited to the acquisition of appropriate metadata and the incorporation of appropriate QC checks into the pipelines', 'Support the use and growth of the Data Engineering DataOps environment, influence strategy and roadmap for the curation toolset, work with R&D and Tech to prioritize enhancements', 'Provide Tier 3 support for production pipelines', 'Support DCS and broader R&D in self-service/exploratory efforts', 'Influence vendor roadmaps, work with R&D and Tech to prioritize DataOps enhancements, and onboard these tools or enhancements', 'Ensure the quality consistency and availability of guidance documentation of end users of the tools to support high quality outputs', 'Extend current pipelines to support clinical biomarkers', 'Assess GxP readiness as it related to the upstream data pipelines and develop a plan for addressing any gaps', 'Provide Tier 3 support/administration of DNA Nexus bioinformatics system', 'This position requires a Computer Science, Bioinformatics, or related degree; 5+ years’ experience in data movement, data wrangling and delivery of data or analytics pipelines', 'Experience implementing and maintaining, data or analytic pipelines.', 'Experience with Big Data technologies, Cloud-based offerings (Microsoft Azure, GCP, AWS, etc), and corresponding tools.', 'Experience with open source software, bioinformatics tools and languages such as SQL, R, Perl, Python, Java, and ETL tools.', 'Experience with data movement and management in the Pharmaceutical industry or related scientific fields.', 'Experience with the core components of the Hadoop stack including HDFS and Apache Spark, ideally a Cloudera based stack', 'Background and experience in LIMS systems, Next Generation Sequencing (NGS) workflows, Cloud computing and HPC systems.', 'Understanding of diverse ‘omic data types including RNA-Seq, DNA-Seq, Chip-Seq, WES, WGS, ATAC-seq, microbiome, proteomic, metabolomic data etc. from different sources.', 'Familiarity with data mining, machine learning and artificial intelligence techniques', 'Proven ability to contribute to development projects.', 'Strong interpersonal skills and effective communication of complex concepts to stake holders with wide range of expertise.', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.', 'Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.', 'Continuously looking for opportunities to learn, build skills and share learning.', 'Sustaining energy and well-being.', 'Building strong relationships and collaboration, honest and open conversations.', 'Budgeting and cost-consciousness', 'LI-GSK']",2020-08-08 13:01:48
Data Analyst,IBM,3.9 out of 5,"New York, NY 10002","['Perform analysis and provide actionable insight.', 'Help define strategic goals and supporting KPIs', 'Define and build dashboards and reports for different departments to help monitor KPIs.', 'Perform ongoing analysis to understand user behavior and provide actionable recommendations in different areas of the product', '3 plus years of data analysis experience at a consumer technology company', '3 plus years’ experience performing advanced analytics using structured and unstructured data.', 'Solid conceptual understanding of methods in analytics and data science. Understanding of common roadblocks and technical challenges.', 'Experience with SQL and Python/R.', 'Experience performing product-oriented quantitative analysis, including statistical analysis', 'Ability to execute against defined objectives both tactically and strategically', 'A team player who can collaborate with engineers, designers, and other cross-functional teams', 'Ability to initiate and drive projects to completion with minimal guidance']",2020-08-08 13:01:48
Data Engineer (TS/SCI),IBM,3.9 out of 5,"Washington, DC 20001","['Big Data experience in both structured and unstructured data.', 'Apply methods, techniques & technologies that address data architecture, integration and governance of data', 'Utilize experience in database concepts and data modeling o Integrate data integration including applying methods, techniques & technologies to address design, architecture and the extraction, transformation, movement, storage of data.', 'Work with Master data management, including customer data strategy, product data strategy and organizational hierarchy, and Information (data) Governance including strategy, implementation, business glossary, metadata and industry frameworks', 'Deliver data mapping, detailed data analysis and metadata analysis', 'Provide hands-on business knowledge while working with database developers, DBAs, architects, data quality analysts, and other teams and seamlessly managing client relationships within context of individual role.', 'Utilize skills in VBA, ETL Tools, Cognos, Hadoop or Hadoop based tools as well as other Business Intelligence tools.', 'Apply semantic correlation, ontology and text analytics techniques and systems to analyze nonstructured data and identify critical insights for overall business analytics across various domains.', 'Analyze text, streams, documents, social media, speech and video with emerging Hadoop-based big data, NoSQL, Natural Language Processing (NLP), Search and Text analytics technologies and techniques', 'Utilize skills in Java, C++, Python, or Skala development', 'Big Data', 'Predictive Modeling', 'Machine Learning', 'Active/Current TS/SCI clearance is required to be considered for this position', 'Included but is not limited to design, creation, population, and maintenance of geo-coding, geo-mapping, and entity-relation ontologies.', 'Work modularly to maximize ability to address new visualization needs as data, threats, and relationships change']",2020-08-08 13:01:48
Senior Data Engineer,CVS Health,3.3 out of 5,"New York, NY",[],2020-08-08 13:01:48
Data Engineer,"Amerilife Group, LLC",3 out of 5,"Clearwater, FL 33759","['Install server software', 'Configure database servers', 'Monitor and maintain system health and security', 'Design backup processes for server and associated data', 'Create accounts for all users and assign security levels', 'Establish a disaster recovery protocol', 'Provide end-to-end technical support and problem resolution', 'Schedule and perform regular server maintenance', 'Create database management procedures', 'Evaluate data analysis models and procedures', 'Participate in company’s cross-training program', 'Bachelor’s Degree in Computer Science or Computer Engineering', '5+ years’ professional experience', 'Advanced knowledge of database structure and theory', 'Experience with MySQL and MSSQL', 'Basic understanding of disaster recovery and database backup procedures', 'Familiarity with reporting tools', 'PostgreSQL certification preferred', 'Ability to work independently with minimal supervision and assistance']",2020-08-08 13:01:48
Data Engineer : Python & AWS,Capgemini,3.8 out of 5,"Hartford, CT","['049483', 'Qualification: Minimum 3 years experience, Bachelor’s Degree.', 'Certification: Should have or seeking SE Level 1.', 'Should have progressing knowledge in Business Analysis, Business Knowledge, Software Engineering, Testing, Data Management, Architecture Knowledge and Technical Solution Design.']",2020-08-08 13:01:48
Data Analyst,Shogun,N/A,"Austin, TX 78744","['Leverage data to understand users and their product usage, developing insights that apply to product, marketing, and business strategy.', 'Partner with executives, product managers, engineers, marketers, designers to translate data insights into smarter decisions and applications.', 'Establish and manage KPIs that measure the health of the business, product performance, and customer experience quality.', 'Build dashboards and reporting processes to monitor business and product trends.', 'Develop frameworks, tools, and best practices to apply data insights towards business questions.', 'Conduct analyses and build models that identify opportunities and drive growth.', 'Analyze experiment data, communicate results, and drive decisions.', 'Potential projects may include forecasting business performance, developing data personas, and modeling customer health.', 'Undergraduate and/or graduate degree in Math, Economics, Statistics, Engineering, Computer Science, or other quantitative field.', 'Excellent SQL skills and some experience with either Python or R', 'Proven ability to wrangle large datasets, explore and utilize raw data feeds', 'Demonstrated aptitude toward Data Storytelling and Root Cause Analysis using data', 'Ability to deliver on tight timelines and prioritize multiple tasks while maintaining quality and detail', '2+ years experience as a Data Scientist, or Data Analyst using advanced analytical methods', 'Familiarity with hypothesis testing or modeling/regressions', 'Ability to work in a self-guided manner', 'Excellent communication and organization skills']",2020-08-08 13:01:48
Data Engineer,Kensho,N/A,"Washington, DC","['Designing, coordinating, and implementing production data platforms using industry standard and/or open source software', 'Navigating between project management, technical leadership, and individual contributor roles', 'Negotiating between new requirements, legacy systems, technical debt, and best practices', 'Mentoring colleagues on data engineering best practices and systems design.', 'Work with industry standard and/or open source software such as PostgreSQL, Kafka, Airflow, Hive, etc.Implement and maintain a data management and governance framework.', 'Support machine learning and application teams by setting up custom data solutions.', 'Design, maintain, and scale Kensho’s data pipeline and document processing platform.', 'Build event and batch driven ingestion systems for stand-alone software products, machine learning R&D, and API services.', 'Develop and administer databases, knowledge bases, and distributed data stores.', 'Create and use systems to clean, integrate, or fuse datasets to produce data products.', 'Perform continuous and periodic studies on systems cost efficiency, performance, and overall health', 'Establish and monitor data integrity and value through visualization, profiling, and statistical tools.', 'Implement and maintain a data management and governance framework.', 'Experience with various data-store technologies, distributed messaging platforms, or data processing framework', 'Experience designing, architecting and building reliable data pipelines', 'Experience working with large structured and unstructured data sets', 'Effective coding, documentation, and communication habits', 'Proficient understanding of distributed computing principles', 'Experience integrating/fusing data from multiple data sources', 'Knowledge of various ETL techniques, frameworks, and best practices', 'Project management and organizational skills', 'Experience supporting and working with cross-functional teams in a dynamic environment', '(Bonus) Experience with Site Reliability Engineering, DevOps (CICD), and Cloud Administration.']",2020-08-08 13:01:48
Data Engineer,KBR,4.1 out of 5,"Point Mugu, CA","['Well-rounded skills in data science: computer programming (e.g., Python, R), data structures (e.g., SQL, Hadoop), statistics (e.g., Bayesian modelling), data visualization (e.g., Tableau), modeling and simulation are required.', 'One-year experience developing applications using Big Data databases (e.g., Accumulo, HBase, MongoDB, Cassandra).', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience with installation, configuration and usage of some of the following: Hadoop, Cloudera, Hortonworks, Apache Storm, Apache Spark, HBase, YARN, Kafka, Storm, map-reduce, big-data analytics, semantic-web (RDF, OWL), and graph-databases.', 'Must be prepared to learn new business processes or application nuances.', 'Strong background in working with relational database management systems (e.g., SQL, Postgres, NoSQL) as well as file-based systems (e.g., Hadoop).', 'Working knowledge of message queuing, stream processing and extracting value from large disconnected datasets.', 'Experience with working in teams in the data science industry is preferred.', 'The Data Engineer must have the ability to work closely with data scientists to develop and subsequently implement the best technical design and approach for new analytical products.', 'Ability to problem solve, debug, and troubleshoot while under pressure and time constraints is required.', 'Working knowledge in statistical data analytics, machine learning, open source and proprietary tools and applications. Must have an excellent knowledge of advanced methods, and experience in applying those methods to solve problems.', 'Ability to communicate effectively about technical topics to both experts and non-experts at both the management and technical level is required.', 'Excellent interpersonal skills, oral and written communication skills, and strong personal motivation are preferred.', 'Knowledge of software design patterns and Agile Development methodologies is required.', 'Ability to work independently and provide appropriate recommendations for optimal design, analysis, and development.', 'Excellent written and verbal communications skills are required, as the Data Engineer will be in frequent contact with the project technical lead, be taking direction from various government leads, and will frequently be interacting with end users to gather requirements and implement solutions while away from other team members.', 'Ability to teach and mentor engineers with a variety of skill levels and backgrounds is a plus.', 'Strong analytical skills related to working with both structured and unstructured datasets.', 'Excellent programming, testing, debugging, and problem-solving skills.', 'Experience designing, building, and maintaining both new and existing data systems and solutions', 'Understanding of ETL processes, how they function and experience implementing ETL processes required.']",2020-08-08 13:01:48
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 13:01:48
Data Quality Engineer,Conde Nast,4 out of 5,"New York, NY 10007","['Facilitate the development and implementation of data quality standards and adoptions requirements across the data organization', 'Establish standard operating procedures for data quality and stewardship', 'Build automated data quality frameworks', 'Defining quality and protection KPIs to measure against objectives', 'Ensuring clear accountability for proper stewardship of consumer information throughout the data lifecycle', 'Partner with data stakeholders and implementation specialists during the data onboarding phase on various projects, providing analysis and sharing best practices.', 'Accountable for the active management of data quality program activities; which includes evaluating large datasets for quality and accuracy; proactively identifying, addressing and resolving reconcilable discrepancies through daily data analysis.', 'Work closely with product operations, data engineering and other required team to improve data quality and contribute directly to development by participating in feedback sessions', 'Define and operationalize processes to continuously monitor and quality check data completeness and accuracy', 'Develop a complete inventory of data clean up reports and define the cadence for producing them and addressing uncovered issues', 'BA/BS in technical or quantitative discipline or significant relevant work experience', '3+ years of primary experience in defining, documenting and implementing Data Quality frameworks, best practices & procedures in a large organization', 'Experience with Python or Scala', 'Proficiency in SQL', 'Experience building data visualizations dashboards to capture data quality metrics', 'Experience working successfully with stakeholders and partner teams to translate business needs into quality requirements', 'Understanding of consumer privacy statutes and be current on data trends and legal implications', 'A strong professional background in data manipulation, data analytics, and/or system analysis', 'Experience of data quality practices, business and technology issues related to management of product, content data (marketing/advertising a plus)', 'Highly detail-oriented with a critical degree of accuracy with data management', 'A good understanding of data distribution/interfacing methods & technologies including structured and unstructured data', 'Experience with data across the consumer journey', 'Ability to work independently, multitask, and drive your own projects']",2020-08-08 13:01:48
Data Engineer,Peloton,3.3 out of 5,"New York, NY","['Understand the data needs of different stakeholders across multiple business verticals including Finance, Marketing, Logistics, Product etc.', 'Develop the vision and map strategy to provide proactive solutions and enable stakeholders to extract insights and value from data.', 'Understand end to end data interactions and dependencies across complex data pipelines and data transformation and how they impact business decisions.', 'Design best practices for big data processing, data modeling and warehouse development throughout the company.', 'Familiar with at least one of the programming languages: Python, Java.', 'Comfortable with Linux operating system and command line tools such as Bash.', 'Familiar with REST for accessing cloud based services.', 'Excellent knowledge about databases, such as PostgreSQL and Redshift.', 'Has experiences with GIT, Github, JIRA and SCRUM.', '2+ years in building a data warehouse and data pipelines. Or, 3+ years in data intensive engineering roles.', 'Experience with big data architectures and data modeling to efficiently process large volumes of data.', 'Background in ETL and data processing, know how to transform data to meet business goals.', 'Experience developing large data processing pipelines on Apache Spark.', 'Experience with Python or Java programming languages.', 'Strong understanding of SQL and working knowledge of using SQL(prefer PostgreSQL and Redshift) for various reporting and transformation needs.', 'Excellent communication, adaptability and collaboration skills.', 'Experience running Agile methodology and applying Agile to data engineering.', 'Experience with Java, JDBC, AWS, SDK', 'Familiar with AWS ecosystem, including RDS, Glue, Athena, etc.', 'Has experiences with Apache Hadoop, Hive, Spark and PySpark.']",2020-08-08 13:01:48
Big Data Engineer,Digital dhara,N/A,"McLean, VA","['Big Data: 10 years (Required)', 'S3 + AWS Certification is a Must : 1 year (Required)', ""Bachelor's (Required)""]",2020-08-08 13:01:48
Data Engineer,Fender,2.9 out of 5,"Los Angeles, CA","['Work closely with the Platform, Product, Growth and Content squads to design data models for new and existing applications and services', 'Establish data blueprints, frameworks, standards and best practices, and communicate them to engineers and analysts', 'Translate product specs into robust data models that are scalable and iterable', 'Partner with the Growth & Revenue team to develop strategies for data acquisition, warehousing and reporting', 'Help ensure that real time analytics are available to product teams and proactively identify when issues arise', 'Work closely with DevOps to automate deployments, monitoring, alerting, ETL and reporting systems', 'BA/BS degree in Computer Science, Math or related field preferred with a strong academic record (MS/PhD or equivalent a plus)', 'Excellent understanding and working knowledge of Python, Go, Java or similar. We assume you speak SQL', 'Deep understanding of relational, NoSQL and data warehousing technologies and when to use each', 'Experience with RedShift, PostgreSQL and ElasticSearch preferred', 'Experience with AWS data infrastructure highly preferred', 'Bonus points: Experience with data streaming tools like Kineses, Kafka, Flink, etc.']",2020-08-08 13:01:48
"Software Engineer, Data",Etsy,4.4 out of 5,"Chicago, IL 60657","['Maintain and improve our data pipeline and data warehouse to ensure our users have timely access to accurate data. Our current stack uses Python, Airflow, Redshift, DBT, Looker, and more.', 'Collaborate with data analysts and other internal partners across the organization to find exciting insights within our data and make them available to our product teams.', 'Partner with our data science team to model, train, and apply machine learning models to new areas within our product.', 'Build and share a deep understanding of your chosen languages, framework, or other area of expertise. Push yourself and the team to be continuously learning and growing.', 'Demonstrate a sense of ownership for your work including understanding requirements, crafting solutions, and building robust testing plans to ensure the highest data quality.', 'Participate in pairing sessions, code reviews and other team rituals.', 'Python and/or Ruby experience, either in web applications or data engineering applications.', 'ETL pipelines and data warehousing solutions such as Airflow or Redshift.', 'Relational databases including data modeling, performance and other optimizations, and SQL queries.', 'Understanding of different types of data storage and their trade-offs.', 'High-level understanding and/or interest in machine learning techniques and their applications.', 'Ability to work and connect with engineering peers, data analysts, and other business partners.', 'Familiarity with AWS infrastructure.', 'Experience in agile development.']",2020-08-08 13:02:31
Data Engineer,Autodesk,4.1 out of 5,"Denver, CO 80202","['Maintain/ develop a scalable database/ data warehouse through connecting disparate data housed across numerous organizational systems and different business lines', 'Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies', 'Optimize/ maintain workflows/ scripts on present data warehouses and present ETL', 'Maintain data sources and workflows/ data pipelines across different systems', 'Maintain different data/ analytics outlets including SFDC, Domo, Power BI, etc to ensure data delivery to team members and ad-hoc reporting requirements', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', ""Bachelor's degree computer science, information systems, applied mathematics or a related discipline"", '5+ years of experience', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience of manipulating, processing and extracting value from large disconnected datasets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'Experience with salesforce administration', 'Experience with BI tools such as Domo, Looker, PowerBI and/ or other tools', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Expertise in gathering data through multiple sources through API calls and scripting languages']",2020-08-08 13:02:31
Data Analyst,Shogun,N/A,"Austin, TX 78744","['Leverage data to understand users and their product usage, developing insights that apply to product, marketing, and business strategy.', 'Partner with executives, product managers, engineers, marketers, designers to translate data insights into smarter decisions and applications.', 'Establish and manage KPIs that measure the health of the business, product performance, and customer experience quality.', 'Build dashboards and reporting processes to monitor business and product trends.', 'Develop frameworks, tools, and best practices to apply data insights towards business questions.', 'Conduct analyses and build models that identify opportunities and drive growth.', 'Analyze experiment data, communicate results, and drive decisions.', 'Potential projects may include forecasting business performance, developing data personas, and modeling customer health.', 'Undergraduate and/or graduate degree in Math, Economics, Statistics, Engineering, Computer Science, or other quantitative field.', 'Excellent SQL skills and some experience with either Python or R', 'Proven ability to wrangle large datasets, explore and utilize raw data feeds', 'Demonstrated aptitude toward Data Storytelling and Root Cause Analysis using data', 'Ability to deliver on tight timelines and prioritize multiple tasks while maintaining quality and detail', '2+ years experience as a Data Scientist, or Data Analyst using advanced analytical methods', 'Familiarity with hypothesis testing or modeling/regressions', 'Ability to work in a self-guided manner', 'Excellent communication and organization skills']",2020-08-08 13:02:31
Data Engineer,"ReliaQuest, LLC.",4.1 out of 5,"Tampa, FL","['Ability to work with multiple developer teams', 'Develop and tune queries using SQL Analyzer or other performance tuning tools', 'Maintain the health of SQL servers and troubleshoot performance issues', 'Creation and optimization of table structures, indices, triggers, stored procedures, table relationships, etc.', 'Creating and managing SQL Agent job and overall configuration including scheduled SSIS jobs, backups, DB cleanup, user creation/permissions, etc.', 'Assist with ETL process for importing new data sources, logical design and table structures', 'Create, modify and optimize database auditing, particularly within SQL Server', 'Responsible for the design, development, implementation and maintenance of the database', 'Develop and interpret database models', 'Experience working with ingest and writing to API’s', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Experience with Linux based databases, including Postgres and/or MySQL preferred', 'May work after hours to complete business objectives if required', '4-6 years of MSSQL Database Development or related Database Development and/or DBA experience', 'Experience with developing SSIS Packages. Experience with other ETL tools also useful', ""Bachelor's degree in Computer Science or related discipline preferred"", 'Experience using Elasticsearch and/or other open source or cloud-based databases preferred', 'Excellent written and oral communication skills including an ability to communicate with internal and external cross functional teams (technical and business)', 'Great Attitude, Energy, and Effort']",2020-08-08 13:02:31
Packaging Engineer,HCL America Inc,2.3 out of 5,"West Chester, PA 19380","['Dental Insurance', 'Health Insurance', 'Relocation Assistance', 'Vision Insurance', '8 Hour Shift', 'Packaging: 1 year (Preferred)', 'Orthopedic: 1 year (Preferred)', 'Verification Validation: 1 year (Preferred)', 'surgical instruments: 1 year (Preferred)', 'www.hcltech.com', 'www.hcltech.com']",2020-08-08 13:02:31
Data Engineer,ADT Security Services,3.4 out of 5,"Irving, TX 75063","['Develop and maintain data pipelines including solutions for data collection, monitoring and usage within dashboards.', 'Partner with data and business stakeholders to understand business and technical requirements, plan and execute projects, and communicate status, risks and issues.', 'Work with internal IT and data teams to prioritize external, big data pipelines for use in CX analytics', 'Utilize Python or other tools to automate data ingestion, monitoring and manual tasks within the BI team', 'Work closely with the analyst team to optimize and reengineer code to be modular, efficient and scalable.', 'Focus on performance, throughput, and latency, and drive these throughout our architecture', 'Lead the organization, documentation and data knowledge within the Business Intelligence team', 'Mentor data analyst staff on querying, data collection and data engineering best practices', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'visualization tools such as Tableau and Power BI: 5 years (Required)', 'Relational database systems and SQL: 7 years (Required)', 'Demonstrated Python development: 5 years (Required)', ""Bachelor's (Required)"", 'Temporarily due to COVID-19']",2020-08-08 13:02:31
Data Analytics Engineer,Lubrizol Corporation,3.9 out of 5,"Cleveland, OH","['Degree in mathematics, statistics, data analytics, computer science or closely related field', 'Significant course work in statistics; experience using advanced statistical software such as R or Python', 'Demonstrated computer programming skills, such as formal course work in C/C++, Java, or Python; knowledge of JavaScript, relational databases and SQL are added pluses', 'Strong problem solving and deductive reasoning skills', 'Creativity and curiosity with the ability to learn and apply new concepts quickly', 'Ability to interact effectively with a wide variety of scientists and individuals']",2020-08-08 13:02:31
Data Operations Engineer,Emergent Biosolutions,3.3 out of 5,"Gaithersburg, MD 20879","['Assists in gathering requirements for configuration, maintenance, and upgrade of SCADA/control and automation systems', 'Ensures connectivity and automation of data collection from lab scale equipment and instruments', 'Supports opportunities to standardize data collection and data transfer solutions', 'Participates in development, ongoing support, and delivery activities related to data services', 'Supports rollout of Industry 4.0 digital initiatives', 'Solves a range of increasingly complex problems and analyzes data solutions by acquiring new knowledge', 'Helps coordinate efforts of IT support groups and external resources such as vendors and consultants', 'Assists users in troubleshooting SCADA and control system related problems', 'Contributes to new computer platform design and data driven solutions', 'Responsible for support of laboratory/automation data historians and analytics systems', 'Provides Windows OS environment support, maintenance and patching in a controlled environment', 'Troubleshoots Windows log files and performance', 'Maintains up-to-date knowledge on modern data technologies and data management', 'Assists with support and planning of data related and system architecture portion of CAPEX projects', 'Prepares data related procedures and documentation', 'Adheres to project budgets and schedules, performing work in accordance with internal SOPs and good Engineering Practices, as well as, regulations and compliance', 'Supports testing of deliverables and provides data analysis as needed', 'Supports activities related to global LIMS project', 'Manages and optimizes processes for data intake, transfer, validation, and visualization', 'Bachelor’s degree in Computer Science, IT, Data Science, Engineering or related field from an accredited university', '3+ years’ experience and/or relevant project/coursework', 'Knowledge of real-time data acquisition and/or automation/controls environment', 'Experience with software in the following fields: SCADA and/or control systems, automation, process controls', 'Experience administering and/or configuring data historian systems such as OSIsoft PI', 'Knowledge of PC environment, able to modify network settings, understanding of remote connections', 'Exposure to working with data transfer methods to other digital platforms such as IIoT', 'Experience or exposure to communications protocols such as OPC, Modbus, MQTT', 'Knowledge/exposure to virtual VMWare environment', 'Problem solving, quantitative and analytical abilities', 'Experience in dashboard development to visualize data and metrics', 'Works well within teams and interactions with groups of various disciplines', 'Exercises judgment within generally defined practices and policies in selecting methods and techniques for obtaining data solutions', 'Possesses analytical and logical troubleshooting skills for computer and basic network issues', 'Proficient with computer applications such as Microsoft Suite and Visual Basic, batch files', 'Must lead by example through strong work ethics and high standards', 'Must be able to adapt to change while viewing obstacles as opportunities', 'Desire to continue to promote personal and technical development', 'Interest in cutting edge data technologies', 'Experience supporting lab/manufacturing/automation systems', 'Experience supporting lab systems such as Waters Empower', 'Experience with OSIsoft PI real-time data and events management system', 'Knowledge and desire to work with IIoT platforms', 'Experience with coding in VB, C#, Python, or other standard programming languages', 'Experience/exposure to Machine Learning and Artificial Intelligence, 3-D printing', 'Experience working with data acquisition platforms in a controlled environment', 'IT or specialized certifications such as Network +, Security +, CCENT, Server +, or related', 'Experience in a pharmaceutical, biopharmaceutical, and consumer products process company or food industry', 'Familiarity with data integrity/assurance and data security guidelines']",2020-08-08 13:02:31
Data Quality Engineer,Conde Nast,4 out of 5,"New York, NY 10007","['Facilitate the development and implementation of data quality standards and adoptions requirements across the data organization', 'Establish standard operating procedures for data quality and stewardship', 'Build automated data quality frameworks', 'Defining quality and protection KPIs to measure against objectives', 'Ensuring clear accountability for proper stewardship of consumer information throughout the data lifecycle', 'Partner with data stakeholders and implementation specialists during the data onboarding phase on various projects, providing analysis and sharing best practices.', 'Accountable for the active management of data quality program activities; which includes evaluating large datasets for quality and accuracy; proactively identifying, addressing and resolving reconcilable discrepancies through daily data analysis.', 'Work closely with product operations, data engineering and other required team to improve data quality and contribute directly to development by participating in feedback sessions', 'Define and operationalize processes to continuously monitor and quality check data completeness and accuracy', 'Develop a complete inventory of data clean up reports and define the cadence for producing them and addressing uncovered issues', 'BA/BS in technical or quantitative discipline or significant relevant work experience', '3+ years of primary experience in defining, documenting and implementing Data Quality frameworks, best practices & procedures in a large organization', 'Experience with Python or Scala', 'Proficiency in SQL', 'Experience building data visualizations dashboards to capture data quality metrics', 'Experience working successfully with stakeholders and partner teams to translate business needs into quality requirements', 'Understanding of consumer privacy statutes and be current on data trends and legal implications', 'A strong professional background in data manipulation, data analytics, and/or system analysis', 'Experience of data quality practices, business and technology issues related to management of product, content data (marketing/advertising a plus)', 'Highly detail-oriented with a critical degree of accuracy with data management', 'A good understanding of data distribution/interfacing methods & technologies including structured and unstructured data', 'Experience with data across the consumer journey', 'Ability to work independently, multitask, and drive your own projects']",2020-08-08 13:02:31
Marketing Analytics Data Engineer,Boston Scientific Corporation,4 out of 5,"Marlborough, MA 01752","['Establish, maintain, and own the marketing analytics data lake using Google BigQuery.', 'Develop datasets to support ad-hoc analytical needs and reporting.', 'Monitor data pipelines for accuracy, missing data, enhancements, changes, and billing volumes to ensure all data is captured and processed accurately and when needed.', 'Ensure that all processes for receiving, processing, and evaluating data are efficient, replicable and documented.', 'Work cross-functionally with marketing, IT and other analytics teams to educate on data availability and access procedures.', 'Proactively consult with the marketing analysts to ensure data collection and pipelines are in place for all required technologies and programs.', 'Fulfill ad-hoc requests and data processing needs with guidance from senior data engineers and marketing analysts.', 'Bachelor’s degree in IT, data science, mathematics, engineering or related fields.', '2+ years of experience with data modeling, data warehousing, and building ETL pipelines.', 'Expertise with Google BigQuery is a must.', 'Experience with Google Analytics, FiveTran, and Salesforce is preferred.', 'Expertise with data analysis using SQL, Python, Excel, and similar tools.', 'Strong working knowledge with data visualization tools (e.g. Tableau, and Google Data Studio).', 'Strong verbal and written communication skills.', 'Demonstrated collaborative skills with individuals from varied backgrounds (e.g. IT, marketing content creators).', 'Strong ability to multi-task and balance competing priorities effectively.']",2020-08-08 13:02:31
Data Platform Engineer (Minneapolis or Remote),Branch,5 out of 5,"Minneapolis, MN","['Take ownership of the data warehouse and data pipelines to improve performance, consistency, and quality; includes monitoring, enhancement, and general maintenance of data pipelines', 'Partner with data science, engineering and product on schema design, event structure and data architecture to enable scalability', 'Drive improvements of SQL query performance through code reviews and appropriate changes to architecture', 'Create custom logic and scripts to automate manual data related tasks (including data science model pipeline)', 'Help build a strong data platform team and grow a strong data culture', '5+ years of experience designing, implementing and maintaining data pipelines and databases with', 'Deep experience of OLTP (MySQL, Postgres, etc…) and OLAP (BigQuery, Redshift) databases', 'Strong fundamental knowledge of designing, building and maintaining transactional databases and a data warehouse (star schema etc)', 'Experience with event driven architectures and streaming ETL', 'Fluent in SQL and experience with Python', 'BS in Computer Science or equivalent program', 'Bonus points for', 'Experience with Google Cloud Platform', 'Payments experience (or related industry)', 'Company-paid medical, dental, and vision', '401k', 'Stock Options', 'Flexible time off', 'Paid Holidays']",2020-08-08 13:02:31
Big Data Analytics Engineer,"FYI-For Your Information, Inc.",N/A,"Rockville, MD 20850","['Opportunity to work remotely (per contract requirements).', 'A knowledgeable, high-achieving, experienced and fun team.', 'A diverse work atmosphere.', 'The chance to be part of a rapidly growing company and the next success story.', 'Team building and innovation.', 'A competitive base salary with a loaded benefits package plus 401K.', 'Personal computer device allowance.', 'Pet Insurance.', 'Required: 5+ years IT experience', 'Required: Bachelors of Science. Graduate level degrees in Mathematics/ Statistics highly preferred', 'Required: Programming - Java / C++ / Scala/ Python', 'Required: Experience with Hadoop / Map-Reduce and/or HIVE', 'Required: SQL Development', 'Required: Unix / Shell scripting', 'Required: Designing distributed solutions for parallel processing of large data', 'Required: Full SDLC Experience (requirements analysis, design, development, unit testing, deployment, support)', 'Required: Good communication skills', 'Preferred: Big-Data technologies, Cloud Computing', 'Preferred: Test driven development', 'Preferred: Understanding NASDAQ/ Capital Markets/ Market Structures']",2020-08-08 13:02:31
Data Engineer Consultant,"World Wide Technology, Inc.",3.7 out of 5,Remote,"['Develop high performance distributed data warehouses, distributed analytic systems and cloud architectures', 'Participate in developing relational and non-relational data models designed for optimal storage and retrieval', 'Develop, test, and debug batch and streaming data pipelines (ETL/ELT) to populate databases and object stores from multiple data sources using a variety of scripting languages; provide recommendations to improve data reliability, efficiency and quality', 'Work along-side data scientists, supporting the development of high-performance algorithms, models and prototypes', 'Implement data quality metrics, standards, guidelines; automate data quality checks / routines as part of data processing frameworks; validate flow of information', 'Ensure that Data Warehousing and Big Data systems meet business requirements and industry practices including but not limited to automation of system builds, security requirements, performance requirements and logging/monitoring requirements', 'At least 5 years of experience', 'Ability to translate a logical data model into a relational or non-relational solution', 'Experience with at least one traditional data warehousing technology (e.g., Teradata, Oracle, SQL Server) and/or modern platforms (e.g., AWS, GCP, Azure)', 'Expert in one or more of the following ETL tools: SSIS, Azure Data Factory, AWS Glue, Matillion, Talend, Informatica, Fivetran', 'Experience in SQL scripting, tuning, indexing, partitioning, data access patterns, and scaling strategies', 'Hands-on experience in database development using views, SQL scripts and transformations', 'Experience with data integrations and data processing for business intelligence and analytics workloads', 'Ability to translate complex business problems into data-driven solutions', 'Experience as a key player in developing an enterprise data warehouse', 'Ability to identify data quality issues that could affect business outcomes', 'Flexibility in working across different database technologies and propensity to learn new platforms on-the-fly', 'Strong interpersonal skills', 'Team player prepared to lead or support depending on situation', 'Certification in any of the modern ETL tools (e.g. SSIS, Azure Data Factory, AWS Glue, Matillion, Talend, Informatica, Fivetran)', 'Hands-on ETL development experience with Matillion', 'Health and Wellbeing: Heath, Dental, and Vision Care, Onsite Health Centers, Employee Assistance Program, Wellness program', 'Financial Benefits: Competitive pay, Profit Sharing, 401k Plan with Company Matching, Life and Disability Insurance, Tuition Reimbursement', 'Paid Time Off: PTO & Holidays, Parental Leave, Sick Leave, Military Leave, Bereavement', 'Additional Perks: Nursing Mothers Benefits, Voluntary Legal, Pet Insurance, Employee Discount Program']",2020-08-08 13:02:31
Data Integration Engineer,Arcadia.io,N/A,"Pittsburgh, PA","['Train in the different areas of the data connector life cycle', 'Work on initial data integration and egress', 'Work on data quality and analytics around connector', 'Work on enhancement and issue triage', 'Start to develop clinical and claims data connectors', 'Work on higher level enhancement requests and defects', 'Deliver Data Quality Reviews to clients', 'Developing a range of data connectors with varying complexity', 'Work on teams with Product, Engineering or Implementation to build out tools for better data integration', 'Pick an SME (Subject Matter Expert) path for what excites you the most', 'Working on standardized data connector development', 'Working with product to build out new data types for new requirements', 'Building standard and custom software to integrate large clinical and claims data sets into the Arcadia Analytics infrastructure', 'Use Nifi, Scala, Apache Spark, or other tools/languages to cleanse and transform incoming data into normalized formats', 'Design and implement software components', 'Performing code reviews, Unit & Integration Testing', 'Deploy software components', 'Manage code repositories & enforce software versioning', 'Establish and maintain efficient local development environments', 'Provide feedback and recommendations to improve software development processes', 'At least 2 – 5+ years of related work experience', 'Expert Level in SQL', 'SQL or NoSql database experience such as MySql, Postgres, Cassandra, MS SqlServer, or Oracle', 'Proficient in at least one of the following languages: Scala, Java, Python, R (Expert if no SQL Experience)', 'Experience working with complex data sets', 'Healthcare data experience', 'Experience with Business Intelligence software or advanced reporting queries/frameworks', 'Apache Nifi, Talend, IBM InfoSphere, TIBCO, Pentaho, or Informatica', 'ELK (ElasticSearch/Logstash/Kibana)', 'Distributed Hadoop-like technologies such as Spark, Storm and/or Kafka', 'Tableau, QlikView, Apache Zeppelin, IPython or Jupyter', 'Github', 'HL7, CCD, CCLF file formats/designs', 'Join a high performing team who brings all data into one of the top Healthcare Analytics companies in the US', 'Learn a TON about healthcare and the bleeding edge of healthcare analytics and medical economics', 'Learn the Apache tech stack and distributed computing', 'Become an expert in clinical and claims healthcare data', 'Receive cash compensation with health, dental, and other benefits']",2020-08-08 13:02:31
Production/Data Operations Engineer,Santander Global External,N/A,"Dallas, TX","['Works directly with users to troubleshoot and support incidents regarding failed jobs and systems issues. Tracks all work with through the centralized ticket tracking system.', 'Ability to isolate problems between hardware and software. Working with appropriate team(s) and vendors until a resolution has been reached.', 'Participates in the planning, implementation and reviews changes to processes that will impact the ability for Data Operations to delivery data to the business.', 'Able to work with file transfer and encryption technologies, preferred', 'Able to create and execute queries to relational data tables to identify process issues or to perform mass updates, preferred', 'Ensures that batch production scheduling and report distribution are accurate and timely.', 'Performs ad hoc requests from users such as data research, file manipulation/transfer, research of process issues, etc.', 'Ability to share knowledge and explain processes and procedures to others.', 'Performs other duties and special projects as assigned', 'May assist in other related departments as required by business needs', ""Bachelor's degree in computer science, mathematics or natural sciences preferred. Equivalent combination of education and experience may be considered in lieu of degree."", 'Five (5) to seven (7) years’ hands-on experience with Control-M or other batch scheduling tools.', 'Good working knowledge of file handling: FTP, encryption, compression, preferred', 'General understanding of the function of scripts and system commands, preferred', 'Experience with database connectivity (both between databases and between database systems and clients to databases) in a diverse computing environment, preferred', 'Strong knowledge of MS queries stored procedures and data transformation, preferred', 'Be able to isolate problems between hardware and software and provide information to appropriate development team(s).', 'Highly developed, process-oriented skills for troubleshooting, problem solving, and problem resolution.', 'Able to analyze processes to see patterns and recommend improvements.', 'Minimum five (5) years’ hands-on experience with Microsoft technologies, local area networks, distributed computing environments and information technologies.', 'One (1) year experience in a call center environment, preferred.', 'Three (3) to Five (5) years’ hands-on experience with Microsoft SQL Database technologies, queries, SSIS, etc., preferred', 'Assist in testing of solutions.', 'Good verbal and written communication skills.', 'Must be customer-focused.', 'Ability to maintain confidentiality', 'Extended working hours may be required by management and business needs.', 'Travel to multiple facilities may be required.', 'May be required to lift, push, or pull materials weighing up to twenty (20) pounds.', 'May be required to sit and review information on a computer screen for long periods of time.', 'May require repetitive motions of the hands and wrist related to writing and typing at an electronic keyboard.', 'Corporate / satellite office role.', 'This job description does not list all the duties of the job. You may be asked by your supervisors or managers to perform other duties. You will be evaluated in part based upon your performance of the tasks listed in this job description.', 'The employer has the right to revise this job description at any time. This job description is not a contract for employment, and either you or the employer may terminate employment at any time, for any reason.', 'Completion of at least one year of active service in Santander', 'Completion of at least twelve months in current position', 'Be in ""Good Standing""']",2020-08-08 13:02:31
"Director, Software Engineering",Indeed,4.3 out of 5,Remote,"['Job', 'Company', 'Lead, inspire, and influence to make sure your team is successful', 'Partner with the recruiting team to attract and retain high-quality and diverse talent', 'Establish great rapport with other development teams, Product Managers, Sales and Customer Success to maintain high levels of visibility, efficiency, and collaboration', 'Ensure teams have appropriate technical direction, leadership and balance between short-term impact and long term architectural vision.', 'Lead 5-10 software engineering teams', '5+ years managing software engineering teams in consumer Web or SaaS products', 'Experience leading a geographically distributed software engineering organization comprising multiple teams', 'Strong technical background that allows you to advocate for and support your engineers', 'Experience building strong partnerships with other job functions, like product, marketing and UX, to keep teams collaborating smoothly and working together to improve the product.', 'Strong desire to understand the root cause and details of systems, get hands-on with data and analysis to evaluate how the team and the product are growing.', 'Experience with service-oriented and event-driven system architectures, building high-performance distributed systems']",2020-08-08 13:03:12
Sr Data Engineer,Bind,2.3 out of 5,"Minneapolis, MN 55416","['Partner or Lead, as needed, projects to define solutions to data needs, issues, and defects', 'Translate business needs into meaningful and detailed requirements for the Data Engineering team', 'Understand vendor along w/ Bind capabilities and data to create data definitions, transformation logic, and data storage options based on business requirements', 'Work with developers to validate processes and data input/output quality', 'Analyze Bind data to elicit patterns in the data that can optimize the processing and storage of the data', 'Analyze and document new and existing data interfaces within the Bind Data Platform', 'Contribute to the ETL design and development process, providing inputs to analysis and data mapping', 'Collaborate with product owners, analysts, and vendors to document complex business logic', 'Partner with developers and testers in an Agile Scrum framework to communicate, refine, and validate requirements and solutions', 'Translate complex concepts to messaging that can be understood by broader audiences', 'Participate in user acceptance testing to validate that solutions meet requirements', ""A bachelor's degree in technology, business management, or a healthcare field preferred"", '7+ years in Healthcare with a primary focus on data analysis, ETL, and/or data processing', 'Ability to translate business requirements into deployable assets', 'Strong experience with SQL and data analysis', ""Demonstrated detailed experience with healthcare data, specifically in the claims' domain"", 'Excellent interpersonal and communication skills, both written and verbal', 'Experience with provider directories and member facing applications', 'Ability to successfully operate in an environment that includes ambiguity and change', 'Ability to manage multiple tasks and priorities in a highly dynamic environment, strong problem-solving skills w/ exceptional attention to detail', 'Familiarity with health care industry concepts (encounters, episodes, members, cost of care, etc.)', 'Experience with data taxonomy structures (preferably clinical) and their uses', 'Experience with project and/or product management and lifecycles', 'Experience with Agile / Scrum and other SDLC methodologies', 'Experience with Cloud/AWS environments preferred', 'Ability to leverage Python coding skills', 'Start-up Experience', 'Working in an ambiguous, fast-paced environment', 'Agile, ready to change direction on the fly', 'Chance to join a new tech start-up aiming to fix the healthcare industry', 'Empowerment to shape new solutions disrupting healthcare while providing benefits and choice to its members', 'Flexible work-from-home schedule to support work-life balance', 'Opportunity to work w/ people who are motivated to go to work every day and make a difference', 'Equity, competitive pay, generous PTO and the opportunity to be a part of a new health insurance plan powered by the consumer, you!']",2020-08-08 13:03:12
Help Desk Engineer,Initiate Government Solutions,5 out of 5,Remote,"['Provide end-user support for NCI developed analytical applications residing on the NCI infrastructure monitoring the performance of the computing environment and recommending enhancements and upgrades as required', 'Analytical applications may include data analysis tools and environments', 'Provide maintenance and continuous operations support of information systems and technical support services', 'Support the development, implementation and use of information systems that support the end users', 'Work with the Software Developers to trouble shoot issues with NCI Applications', 'Renewing licenses for all software installed on the infrastructure', 'Monitoring, auditing, and policy enforcement of physical, network, and user-level security of the system and resources', 'Regular maintenance procedures that impact the use of the resource during nights or weekends', 'Ensure monitoring and maintenance of servers', 'Ensure patching and configuration management of servers', 'Provide development of standard operating procedures and maintain service level agreements', 'BS in Computer Science, Software Engineering, or similar discipline with a minimum of 4 years of experience that includes knowledge of various PC and Mac operating systems, experience with networking, and with providing help desk support to end-users of the analytical tools and systems', 'Must have positive customer service attitude', 'Excellent written and communication skills', 'Ability to obtain and maintain a HHS Public Trust', 'Current HHS Public Trust', 'Experience working on federal government contracts, preferably centered around research, grants, or health informatics']",2020-08-08 13:03:12
"Backend Engineer, Data Processing – Rust (Remote)",kraken,3.9 out of 5,Remote,"['Design and implementation of micro-services in Rust', 'Writing reusable, testable, and efficient code', 'Implementation of risk evaluation and anti-fraud systems, or similar scoring and anomaly detection systems', 'Pick and design adequate data processing storage and pipelines', 'Work with our Fraud/Data Science team or provide the Data Science know-how to support Product requirements', 'At least 5 years of experience in software engineering', 'Experience with Rust', 'Experience writing network services or asynchronous code', 'Python, Java or similar work experience', 'Working knowledge using Kafka, Pulsar or similar', 'Experience using a Linux server environment', 'Ability to independently debug problems involving the network and operating system', 'Be familiar with deployment using Docker', 'Have previous work experience on Risk scoring or anomaly detection systems', 'Have experience with Machine Learning and its ecosystem', 'Have experience with other strongly typed programming languages', 'Have experience using SQL and distributed data solutions like Spark, Hadoop or Druid', 'Be passionate about secure, reliable and fast software']",2020-08-08 13:03:12
Data Engineer,Circinus LLC,N/A,United States,"['Maintain and scale production environments for ML-based data pipelines and products.', 'Research, develop and implement open-source data collections into big data analytical platforms.', 'Work with both structured and unstructured datasets in a big data platform environment', 'Collaborate with engineering teams to help bring data science R&D projects into production.', 'Build and maintain internal analytics, reporting, and decisioning applications.', 'Work closely with stakeholders to quickly deliver high-quality solutions.', 'Work with engineering and infrastructure architects to improve data strategy, quality and governance.', 'Contribute to implementation of scalable ETL and data processing systems.', 'Work effectively under time constraints and changing priorities.', 'Other duties as assigned.', 'US citizenship required (dual-national US citizens eligible)', '5+ years of experience as a Data Engineer writing production-level code with Python, Scala and/or Java.', 'Experience in data warehouse/data lake and ETL architecture', 'Hands-on experience utilizing Big Data technologies such as Spark/Hadoop to design and build scalable AI data pipelines strongly preferred.', 'Experience in building and managing batch/real-time data pipelines using Airflow/Luigi or other enterprise-scale workflow scheduling tools.', 'Proficiency in database technologies (SQL, NoSQL).', 'Experience in building and deploying CI/CD frameworks and code versioning such as Jenkins and Git.', 'Hands-on experience with “software as a service” deployments and orchestration technologies such as Docker and Kubernetes required.', 'Experience working with ELK stack: Elasticsearch, Kibana and Logstash preferred.', 'Excellent verbal and written communications skills.', 'Ability to work in a fast-paced environment and navigate through ambiguity in accordance with deadlines.', 'BS or higher in Computer Science or related field with 5+ years of professional experience in algorithms, data structures, and object-oriented programming.', 'Competitive salary based on professional and educational experience.', 'Company matched 401K retirement plan.']",2020-08-08 13:03:12
"Forward Deployed Software Engineer, Internship",Palantir Technologies,4.3 out of 5,"Washington, DC 20007","['Dedication: We see projects through from beginning to end in spite of obstacles we may encounter.', 'Collaboration: We work internally with people from a variety of backgrounds — such as other FDSEs, product teams, and Deployment Strategists. We also work externally with our customers, often on site, to understand and solve their problems.', ""Trust: We trust each other to effectively manage time and priorities—we don't micromanage. We want to give people the space to think for themselves."", 'Core Palantir products, which provide the foundations for our deployments', 'Custom applications built on top of core Palantir platforms', 'Postgres, Cassandra, Hadoop, and Spark for distributed data storage and parallel computing', 'Java and Groovy for our back-end applications and data integration tools', 'Typescript, React, Leaflet, and d3 for our web technologies', 'Python for data processing and analysis', 'Palantir cloud infrastructure based on AWS EC2 and S3', 'Strong engineering background in fields such as Computer Science, Mathematics, Software Engineering, and Physics.', 'Familiarity with data structures, storage systems, cloud infrastructure, front-end frameworks, and other technical tools.', 'Strong coding skills with demonstrated proficiency in programming languages, such as Java, C++, Python, JavaScript, or similar languages.', 'Ability to collaborate and empathize with a variety of individuals. You can iterate with users and non-technical stakeholders and understand how your technical decisions impact them.', 'Demonstrated ability to learn and work independently and make decisions with minimal supervision.', 'Must be planning on graduating in 2022. This should be your final internship before graduating.', 'An updated resume / CV', 'Thoughtful responses to our application questions', 'In an effort to build more transparency into our recruitment process, we’d like to share our offer deadline expectations. By applying to this position, you commit to confirming your decision within three weeks of receiving your written offer']",2020-08-08 13:03:12
Data Engineer,Global Atlantic Financial Group Opportunities,N/A,"New York, NY","['Design and develop enterprise data / data architecture solutions using Hadoop and other data technologies like Spark, Scala, Python, SQL etc.', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Create and maintain optimal data pipeline architecture.', 'Devise and execute continual improvement initiatives in all Data Management Service delivery and technology, with a focus on delivery velocity and quality.', 'Partner with business leaders to determine and prioritize delivery initiatives.', 'Define or influence system, technical and application architectures for major areas of development.', 'Devise and execute in software development life cycle including requirements gathering, development, testing, release management, and maintenance.', 'Engage with business partners to report (formally and informally) on technology strengths, weaknesses, successes and challenges on a regular basis.', 'Ability to do analytical programming in EDW architecture to bridge the gap between a traditional DB architecture and a Hadoop centric architecture.', 'Highly organized and analytic, capable of solving business problems using technology.', 'Ensure appropriate change management and other technology methodologies are carried out on a consistent basis over time.', 'Should be an individual with in-depth technical knowledge and hands-on experience in the areas of Data Management, BI Architecture, Product Development, RDBMS and non-RDBMS platforms.', 'Should have excellent analytical skills, able to recognize data patterns and troubleshoot the data.', 'Will be responsible for design and delivery of data solutions to empower data migration initiatives, BI initiatives, dashboards development etc.', 'Undergraduate degree required, MBA or other advanced degree preferred.', '3+ years of experience as a member of an information technology team.', 'Minimum of 2 years of relevant experience architecting the complete end to end design of enterprise wide solution using latest technologies – Hadoop, Spring boot/Spring Cloud, Rest API, SQL', 'Minimum of 2 years of professional experience in Python, Core Java, Hortonworks, AWS, Rest API, Microservices, Spring Boot, Spring cloud etc.', 'Ideally a strong Life Insurance background.', 'Experience with data modeling, complex data structures, data processing, and data quality and data lifecycle', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', ""Experience building and optimizing 'big data' data pipelines, architectures and data sets."", 'Experience performing root cause analysis on internal and external data and processes to provide solution for specific business requirements.', 'Experience building solutions for streaming applications.', 'Should be able to lead critical aspects of the data management and application management.', 'Experience in UNIX shell scripting, batch scheduling and version control tools.', 'Experience in large scale server-side application development that includes the design and implementation of high-volume data processing jobs.', 'Cultural awareness with excellent interpersonal and relationship building skills.', 'Passion and drive for continuous improvement and transformational change, with a business owner mentality.', 'Strong written and verbal communication skills.']",2020-08-08 13:03:12
Medicare Advantage Generalist - Data Science,Devoted Health,2.5 out of 5,Remote,"['Working closely with key business stakeholders to understand the analytical needs of the business and providing insight in a rapid, iterative, and collaborative process', 'Developing thoughtful reports and dashboards that help Operations teams improve their business decision-making', 'Identifying patterns in the analyses you conduct, and using those patterns to improve our tools and processes so we can deliver results more quickly and accurately', 'Sharing your domain knowledge with technical team-members who do not have an MA background', 'Communicating results to an audience of mixed technical backgrounds', 'Ability to work in a fast-paced startup environment', '2+ years of technical work at a Medicare Advantage plan or service provider', 'Experience collaborating effectively with stakeholders', 'Experience with SQL', 'Experience with dashboarding and creating reports', 'Bonus: In-depth experience with Risk Adjustment']",2020-08-08 13:03:12
BI/ DATA ENGINEER,Pilgrim's,3.4 out of 5,"Greeley, CO","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.', 'Documents work and processes.', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Works closely with a team of frontend developers, product managers, and analysts.', 'Designs data integrations and data quality framework.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units to develop strategy for long term data platform architecture.', 'Manage from start to finish a portfolio of data integration and BI projects, working as the liaison between the business, IT and third party providers.', 'Strong SQL skills', 'Ability to integrate data from multiple sources and organize data targets', 'Programming skills (Powershell, Python, .Net etc)', 'Knowledge of best practices and IT operations in an always-up, always-available service', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills', 'Experience with integration modeling tools like Alteryx', 'Experience with QlikSense, Tableau, or other reporting layer software', 'BS or MS degree in Computer Science or a related technical field', '2+ years of Python development experience', '4+ years of SQL experience', '4+ years of experience with schema design and dimensional data modeling', 'Ability in managing and communicating data warehouse plans to internal clients', 'Experience designing, building, and maintaining data processing systems']",2020-08-08 13:03:12
Big Data Engineer,7Kingscode,N/A,"Parsippany, NJ","['Datastage, Big Query', 'Source date : is in GCP-Big Query', 'Traget platform : is Onprem Linux', 'Data gets extracted using datastage using FTP', 'The predictive modeling is done using R, Python and Linux scripting', 'Primary Skills - Python, R, SQL, Datastage, Linux scripting, API knowledge, SSIS', 'Platform Knowledge - GCP Big Query', 'Supporting skills - Azure platform knowledge and Partykit', 'Monday to Friday', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:03:12
Data Analytics Engineer,Lubrizol Corporation,3.9 out of 5,"Cleveland, OH","['Degree in mathematics, statistics, data analytics, computer science or closely related field', 'Significant course work in statistics; experience using advanced statistical software such as R or Python', 'Demonstrated computer programming skills, such as formal course work in C/C++, Java, or Python; knowledge of JavaScript, relational databases and SQL are added pluses', 'Strong problem solving and deductive reasoning skills', 'Creativity and curiosity with the ability to learn and apply new concepts quickly', 'Ability to interact effectively with a wide variety of scientists and individuals']",2020-08-08 13:03:12
Lead Data Engineer (Remote),Output,3.9 out of 5,Remote,"['Design, develop, and deploy backend data systems with a focus on quality, performance, and reliability', 'Support machine learning, analytics, and marketing user cases', 'Collaborate closely with engineering and product teams, becoming a core member of an autonomous, cross-functional team', 'Work collaboratively with stakeholders to understand business requirements, connect these to possible solutions, and deliver successful engineering outcomes', 'Advise stakeholders on best practices and opportunities for improvement in Output’s data technology operations', 'Work in an environment that supports your individual growth', 'Dedication to industry-standard engineering processes for reliability and long-term quality', 'Experience with data warehouse technologies such as BigQuery, Snowflake, or Redshift', 'Experience with data processing services, ETL, and API integration', 'Experience deploying data processing pipelines in Python', 'Familiarity with machine learning techniques for data analysis and prediction a plus', 'Strong communication skills with a focus on cross-disciplinary collaboration', 'Fluency in SQL', 'Experience with Facebook and Google ad platforms a plus', 'Experience with business intelligence tools such as Looker a plus', 'You have errors in applying']",2020-08-08 13:03:12
Data Engineer,ADT Security Services,3.4 out of 5,"Irving, TX 75063","['Develop and maintain data pipelines including solutions for data collection, monitoring and usage within dashboards.', 'Partner with data and business stakeholders to understand business and technical requirements, plan and execute projects, and communicate status, risks and issues.', 'Work with internal IT and data teams to prioritize external, big data pipelines for use in CX analytics', 'Utilize Python or other tools to automate data ingestion, monitoring and manual tasks within the BI team', 'Work closely with the analyst team to optimize and reengineer code to be modular, efficient and scalable.', 'Focus on performance, throughput, and latency, and drive these throughout our architecture', 'Lead the organization, documentation and data knowledge within the Business Intelligence team', 'Mentor data analyst staff on querying, data collection and data engineering best practices', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'visualization tools such as Tableau and Power BI: 5 years (Required)', 'Relational database systems and SQL: 7 years (Required)', 'Demonstrated Python development: 5 years (Required)', ""Bachelor's (Required)"", 'Temporarily due to COVID-19']",2020-08-08 13:03:12
Data Engineer - FinTech,Amazon.com Services LLC,3.6 out of 5,Texas,"['Job', 'Company', '1+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', 'Intermediate to Expert experience in data engineering or Business Intelligence space', 'Strong understanding of ETL concepts and experience building them with large-scale, complex datasets using traditional or map reduce batch mechanism.', 'Strong data modelling skills with solid knowledge of various industry standards such as dimensional modelling, star schemas etc', 'Proficient in writing SQL working with large data volumes', 'Experience designing and operating very large Data Warehouses', 'Experience with scripting (e.g., Python, UNIX Shell scripting, Perl, or Ruby).', 'Experience or willingness to learn working on the AWS stack.', 'Clear thinker with superb problem-solving skills to prioritize and stay focused on big needle movers', 'Curious, self-motivated & a self-starter with a ‘can do attitude’. Comfortable working in fast paced dynamic environment.', 'Able to work in a diverse team', 'Design, implement, and support a platform providing secured access to large datasets.', 'Interface with tax, finance and accounting customers, gathering requirements and delivering complete BI solutions.', 'Model data and metadata to support ad-hoc and pre-built reporting.', 'Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.', 'Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.', 'Tune application and query performance using profiling tools and SQL.', 'Analyze and solve problems at their root, stepping back to understand the broader context.', 'Learn and understand a broad range of Amazon’s data resources and know when, how, and which to use and which not to use.', 'Keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using AWS.', 'Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for datasets.', 'Triage many possible courses of action in a high-ambiguity environment, making use of both quantitative analysis and business judgment.', 'Be ready to learn and train on radical new tools on the AWS stack.', 'Working knowledge of PL/SQL working with large data sets.', 'Experience working with Oracle Hyperion or Oracle Data Integrator (ODI)', 'Ideally have experience with AWS technologies including Redshift, RDS, S3, EMR, DynamoDB, Hive, Spark etc.', 'Experience with dimensional modelling skills.', 'Knowledge of a programming or scripting language (R, Python, Ruby, or JavaScript)..', 'Must have excellent knowledge of Advanced SQL working with large data sets.', 'Must have excellent dimensional modelling skills.', 'Good to have experience with reporting tools like Tableau, OBIEE or other BI packages.']",2020-08-08 13:03:12
Data Integration Engineer,Riskified,N/A,"New York, NY","['Working with some of the largest companies in the world to perform comprehensive analysis of their data', 'Perform due diligence of business models and flows', 'Data modeling as part of the integration architecture', 'Combining the technical, business and analytical objectives to come up with tailored solutions for onboarding merchants', 'Data wrangling & sanitization', 'Prioritize, track, and communicate data issues internally and externally', 'Become the subject matter expert of riskified product and technology', 'Work closely with analysts, research and data science teams to accommodate changes in industry data', 'Monitor key health indicators and automated alerts', 'Identify, research, and offer system-wide solutions for common issues', 'Work closely with Account Management to engage customers', '3+ years of experience in a data-centric industry role (ETL, DBA, etc.)', '2+ years with SQL or NoSQL databases', '2+ years experience with data wrangling (R, Python for data processing)', '2+ years with optimizing technical processes', 'Strong verbal and written communication skills', 'Eagerness to learn new technical concepts', 'Strong analytical skills and attention to detail', 'Fully-covered medical, dental, and vision insurance from your first day', 'Stock options for all employees, 401(k) + matching, commuter benefits', 'Catered lunch, team events, healthy snacks, yoga, pilates, soccer league, and more']",2020-08-08 13:03:12
Data Engineer,Mosaic Group,3.9 out of 5,"New York, NY","['Gather requirements from business stakeholders (product, marketing, analytics) and effectively translate them into a data environment that supports business needs', 'Design and maintain data warehouse (PostgreSQL and BigQuery) and data lake (GCS)', 'Build batch and real-time data pipelines to ingest and process data from various sources such as product backends, third party platforms, etc.', 'Build internal tools and services to support data analytics and engineering', 'Help product, marketing, analytics, and engineering with diagnosing data-related issues', 'Document, profile, and manage data across multiple products and platforms for data governance (consistent naming conventions, data validation, data retention)', 'Maintain a line of communication between developers and data team to ensure all stakeholders are up to speed on changes to source database schema for analytics purposes', 'Work closely with other data engineering teams across Mosaic to ensure alignment of methodologies and best practices', '2 - 4 years experience programming and scripting in Python within a production environment', 'Hands-on experience with relational databases (MySQL and PostgreSQL)', 'Familiarity with creating ETL processes for large-scale data warehouses', 'Must have familiarity with GCP and its offered services (BigQuery, CloudSQL, Dataprep, etc)', 'Knowledge of PubSub, or relevant messaging queue like Kafka, is a must', 'Distributed file systems (GCS, HDFS) knowledge is a must', 'Familiarity with Java, JavaScript, Airflow, Docker, Scala, and Spark are preferred', 'Familiarity with NoSQL is a plus', 'Prior experience with CI/CD is a plus', 'An amazing working environment with a lot of perks including but not limited to:', 'Unlimited PTO!', 'Matching 401k!', 'Company Contribution towards Commuter Benefits!', 'Fully stocked kitchen!', 'Environment where you can mentor and learn from others.']",2020-08-08 13:03:53
Experienced Data Engineer,Principal Financial Group,3.9 out of 5,"Denver, CO","['Develop and deploy robust and scalable data platforms that efficiently process data and enable the development of advanced analytics.', 'Learn best practices, standardization and procedures around data warehousing and development processes to ensure data quality and integrity.', 'Research, maintain and evaluate emerging data engineering and warehousing technologies and solutions for continuous improvements to solve business problems.', 'Competitive pay, benefits, perks and more. We’ll reward you for the skills and experience you have. Find out more.', 'Respect for your unique perspective. Diversity, inclusion and empowerment are at the core of our culture.', 'A career, not just a job. Principal is a place where you can learn and innovate. Do important work. Make an impact. And achieve your professional goals.', 'The ability to have a great job and a great life. Sure, work is important. But so is your family. And your friends. And your community. That’s why we provide the flexibility needed to find the right balance between your job and the rest of your life.', ""Associate's or Bachelor's degree with a preference in a science, technology, engineering, or math related field or equivalent work experience (6 years of experience equates to an Associate’s degree when defining “equivalent work experience”)"", '2+ years’ experience with Functional or Object-Oriented programming', 'Strong SQL experience', 'Data Stores such as Hadoop', 'Scala/Java preferred; Python acceptable', 'System design experience', 'Cloud Platforms', 'Various extreme programming practices, including DevOps']",2020-08-08 13:03:53
"Analyst, Data Analytics Engineer",Travelers,3.7 out of 5,"Hartford, CT","['Assist with Data Acquisition, Prep and Exploration following well defined criteria and steps.', 'Apply data derivations, business transformation rules, and data requirements.', 'Perform basic analysis with guidance of others.', 'Identify issues and recommend solutions.', 'Under guidance operationalize and automate well defined simple data products.', 'Learning and partner with others in providing training to users.', 'Begin to develop basic insurance and business intelligence and analytics knowledge through daily work assignments.', 'Learn Travelers BI&A standards, processes, and environmental landscape.', 'Understand core data management competencies - data governance, data security, data quality.', 'College degree or equivalent training with data tools, techniques, and manipulation experience required.', 'College Degree in STEM related field', 'Basic knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to):', 'Big data and Cloud platforms', 'Programming languages - SAS, SQL, Spark, Python, Hive, AWS', 'Visualization platforms: QlikView, Tableau and Qlik Sense', 'Prior relevant intern experience preferred.', 'Ability to communicate thoughts/ideas clearly.', 'Demonstrates basic active and effective communication skills with team members - including active listening and effective written and verbal communication skills.', 'Effectively contributes and communicates with the immediate team.', 'Problem Solving & Decision Making:', 'Able to recognize and analyze basic issues and develop timely, practical, cost effective solutions with supervisory assistance.', 'Able to identify cause and effect relationships in assigned systems and applications.', ""Ability to foster relationships with peers to achieve objectives. Practices objectivity and openness to others' views."", 'Ability to manage time and competing priorities.', 'Developing the ability to accurately evaluate and estimate new tasks.', 'Developing a planning skill set including providing management with accurate and timely status information.']",2020-08-08 13:03:53
Product Data Analyst,Drizly,3 out of 5,"Denver, NY","['Advise product teams on data ingestion, interpretation, and implementation.', 'Assist in the design, implementation, and analysis of A/B testing with a Product Managers.', 'Build and maintain our tracking “dictionary” for the consumer platform.', 'Create and update automated reports on an ad hoc basis.', 'Competitive salary', 'One-on-one professional coaching with an external expert', 'Health, Dental and Vision Insurance', 'Flexible vacation policy', '401(K) Plan', 'Added perks']",2020-08-08 13:03:53
Big Data Engineer,ANB Sourcing LLC,N/A,"Jersey City, NJ","['Monday to Friday', 'Current Location:', '1 year', 'Possible', 'No', 'One location', 'www.anbsourcing.com', 'Temporarily due to COVID-19']",2020-08-08 13:03:53
Senior Big Data Engineer,Warner Bros. Entertainment Group,4.2 out of 5,"Burbank, CA","['Data Integration and Pipelines – Design and develop data integrations from a variety of formats including files, database extracts and external APIs.', 'Operations and Tuning - Investigate problems and resolve as required, including working with various internal teams and vendors. Proactively monitor the data flows with a focus on continued performance improvements. Develop POC’s and best practices for application development.', 'Application Onwership – Own the application/data end-to-end from requirements to post production, working closely with other teams. Provide engineering leadership by actively advocating best practices and standards for software engineering. Share knowledge and guide junior engineers to level-up the whole team.', 'Bachelor’s degree in Computer Science or related field.', 'Minimum or 7 years of software engineering/development experience.', 'Minimum of 5 years of Data Analytics/data engineering, Complex ETL/ELT experience.', 'Minimum of 3 years working with Big data technologies including Hadoop, Apache Spark, Snowflake and AWS Suite of technologies (S3, EMR, Lambda).', 'Minimum of 3 years architecting datastores – NoSQL/SQL.', 'Experience with scripting (Shell, Python) in a linux environment.', 'Experience with consuming and creating restful API’s.', 'Expert problem solver with strong analytical skills.', 'Expert in Spark (Scala/Java), Spark SQL and Spark Streaming.', 'Expert in SQL (Snowflake, MySQL).', 'Experience using big data tools (Hadoop, Map-reduce, Elastic search, Kinesis, Kafka, Solr).', 'Experience using AWS technologies (EMR, S3, Kinesis, Lambda).', 'Strong object oriented and functional programming skills.', 'Experience writing BaSH Scripts.', 'Experience using Git or SVN and Jira.', 'Experience using Python is a plus.', 'Experience using Restful APIs is a plus.', 'Experience with Ad platforms or CRM solutions is a plus.', 'Strong communication skills.', 'Ability to work independently or collaboratively.', 'Detail oriented with strong organization and prioritization skills.', 'Entertainment and/or Social Media experience a plus.', 'Demonstrated ability to work well under time constraints.', 'Must be able to work flexible hours, including possible overtime, when necessary.', 'Must be able to maintain confidentiality.', 'Management has the right to add or change duties and job requirements at any time.']",2020-08-08 13:03:53
Machine Learning Engineer,Path2Response LLC,N/A,Remote,"['Work with other data scientists and engineers to build novel solutions and enhance the existing machine learning platform', 'Design and implement robust testing systems', 'Develop deployment pipelines of data science assets across multiple systems', 'Serve as a critical team member of the rotational on-call support team', '2+ years Python experience in a production setting', '2+ years experience working with scientific Python stack (scikit-learn, pandas, numpy)', '1+ years experience with serverless architectures, preferably AWS services', 'Experience with Docker', 'Experience with CI/CD systems', 'Comfortable working in an Agile environment', 'Experience working with distributed systems (PySpark, Spark, DASK) a plus', 'Scala experience a plus', 'Be flexible and adapt to change quickly — this is a startup so we are continuously innovating', 'Willingness to learn new techniques and technologies independently', 'Sense of humor and a positive attitude']",2020-08-08 13:03:53
Lead Data Engineer,National Audubon Society,3.9 out of 5,"New York, NY 10014","['Migratory Bird Initiative, a multi-year project to track and aggregate varied data sources about migratory bird species, where they go, and the threats they face', 'Integrate data from multiple sources (e.g., email, website interactions, CRM and volunteer activity, voter files, demographic data to support inclusion and equity metrics) into a data warehouse and building optimized views and workflows for analysis, reporting, and dashboard visualization', 'Identify, evaluate, and implement infrastructure solutions for unified business intelligence, data warehousing, scaling and parallel processing, and machine learning', 'Proactive data analysis to identify issues and implement a plan to improve the quality and integrity of operational data, particularly constituent data across data-heavy systems like Salesforce and EveryAction', 'Advise on the design, build, and maintenance of structured databases to track curated data such as bird species taxonomies, bird-friendly native plants by geolocation, and important bird areas, along with product and engineering staff', 'Convert raster data of predictive bird species ranges based on climate change models to vector features to enable enterprise GIS analysis and further conservation research', 'Contribute to the design of a new strategic data infrastructure to support the National Audubon Society mission.', 'Take ownership of building and maintaining the new data infrastructure, including data platforms, data pipelines, and analytical and business intelligence tools.', 'Develop run books and documentation to detail all data infrastructure design and operations, including backup and recovery.', 'Collaborate with the Enterprise Geographic Information Systems (GIS) team to leverage enterprise GIS and mapping technologies as part of the overall data architecture.', 'Advise the VP of Data and Analytics, as well as others throughout the organization, on data-related tools and platforms, data best practices for integrity, testing, and modeling, and analytical approaches.', 'Collaborate with the peer Engineering team to ensure data quality and to advise on the design and implementation of system integrations and API services.', 'Work with the VP of Data and Analytics and the Director of IT to support data governance initiatives and to ensure the reliability and security of data services and infrastructure.', '10+ years of experience as a Data Engineer, or in similar roles, with increasing levels of responsibility.', 'Degree in Computer Science, Statistics, Data Science, Mathematics, or related quantitative field strongly preferred.', 'Significant hands-on experience building and working with data lakes, warehouses, marts, pipelines, and providing reporting or analytical services.', 'Fluency in Linux-based operating systems.', 'Experience with RDBM Systems and deep SQL experience.', 'Experience with cloud data warehouse solutions like Redshift, Snowflake, Azure Data Warehouse, and/or BigQuery.', 'Experience with cloud infrastructure (e.g., AWS EC2, S3, Lambda or equivalent services from Azure or Google).', 'Experience with Linux scripting, Python, Java, Scala, .NET, R or other programming languages proven to be robust and widely used for ETL/ELT and data analytics.', 'Experience with business intelligence tools (e.g., Tableau, Looker, PowerBI).', 'Experience with or strong understanding of ETL/ELT and workflow tools like AWS Glue and Apache Airflow.', 'Experience with or strong understanding of big data architectures and data modeling to efficiently process large volumes of data, including solutions like Spark, Hadoop, EMR, Kafka, etc.', 'Experience supporting data science notebook environments such as Jupyter Hub or R Studio preferred.', 'Experience building data architectures that support web application such as RESTful web services. Familiarity with web data and mapping visualization technologies such as D3.js, Plotly, ArgGIS API for JavaScript, and Leaflet a plus.', 'Familiarity with machine learning/data science platforms and services like Sagemaker, Domino, TensorFlow, etc. a plus.', 'Demonstrated ability to communicate technical information to non-technical audiences.', 'Self-starter who can work as part of a virtual team and remain motivated in a dynamic environment.', 'Genuine passion for conservation and the mission of the National Audubon Society.']",2020-08-08 13:03:53
"Director, Software Engineering",Indeed,4.3 out of 5,Remote,"['Job', 'Company', 'Lead, inspire, and influence to make sure your team is successful', 'Partner with the recruiting team to attract and retain high-quality and diverse talent', 'Establish great rapport with other development teams, Product Managers, Sales and Customer Success to maintain high levels of visibility, efficiency, and collaboration', 'Ensure teams have appropriate technical direction, leadership and balance between short-term impact and long term architectural vision.', 'Lead 5-10 software engineering teams', '5+ years managing software engineering teams in consumer Web or SaaS products', 'Experience leading a geographically distributed software engineering organization comprising multiple teams', 'Strong technical background that allows you to advocate for and support your engineers', 'Experience building strong partnerships with other job functions, like product, marketing and UX, to keep teams collaborating smoothly and working together to improve the product.', 'Strong desire to understand the root cause and details of systems, get hands-on with data and analysis to evaluate how the team and the product are growing.', 'Experience with service-oriented and event-driven system architectures, building high-performance distributed systems']",2020-08-08 13:03:53
Data Engineer,NORC at the University of Chicago,3.6 out of 5,"Chicago, IL 60602","['The successful candidate should have at least a Bachelors degree in one of the following fields: math, statistics, computer science, data science, or a social science or public policy related field.', 'He/she must have at least five years’ experience in positions of increasing responsibility, preferably working with large datasets and conducting statistical and quantitative modeling, melding analytics with programming, data mining, clustering, and segmentation.', 'He/she should have a strong foundation in areas of statistics, mathematics, and computer programming.', 'Mature fluency in Python programming and familiarity with both Linux and Windows operating environments required along with parallelization technologies for high performance computing.', 'Familiarity with utility scripting languages such as Bash and Powershell, code repository tools such as Git and Subversion (SVN), and Atlassian products JIRA and Bitbucket.', 'Experience with a broad array of data storage platforms, including, but not limited to: SQL (Postgres, MS SQL, MySQL), NoSQL (MongoDB), and data warehousing solutions (Vertica/Greenplum) with emphasis on performance tuning, query optimizations, big data workloads.', 'Extensive hands on experience in leading large-scale, full-cycle MPP enterprise data warehousing (EDW) projects.', 'Extensive hands on experience in data warehousing design, tuning, and ETL/ELT process development.', 'Recommend solutions that follow accepted standards regarding database physical structure, functional capabilities, and security.', 'Maintain database performance by calculating optimal parameters values.', 'Perform query and database design optimization in addition to providing assistance/reviews/feedback to stakeholders in writing complex queries, stored procedures/functions, views, and DDL/DML scripts.', 'Troubleshoot complex database issues in accurate and timely manner ensuring compliance with SLAs.', 'Have strong skills in problem solving and quantitative/qualitative analysis required.', 'Be able to organize and prioritize work assignments to meet project goals.']",2020-08-08 13:03:53
Production/Data Operations Engineer,Santander Global External,N/A,"Dallas, TX","['Works directly with users to troubleshoot and support incidents regarding failed jobs and systems issues. Tracks all work with through the centralized ticket tracking system.', 'Ability to isolate problems between hardware and software. Working with appropriate team(s) and vendors until a resolution has been reached.', 'Participates in the planning, implementation and reviews changes to processes that will impact the ability for Data Operations to delivery data to the business.', 'Able to work with file transfer and encryption technologies, preferred', 'Able to create and execute queries to relational data tables to identify process issues or to perform mass updates, preferred', 'Ensures that batch production scheduling and report distribution are accurate and timely.', 'Performs ad hoc requests from users such as data research, file manipulation/transfer, research of process issues, etc.', 'Ability to share knowledge and explain processes and procedures to others.', 'Performs other duties and special projects as assigned', 'May assist in other related departments as required by business needs', ""Bachelor's degree in computer science, mathematics or natural sciences preferred. Equivalent combination of education and experience may be considered in lieu of degree."", 'Five (5) to seven (7) years’ hands-on experience with Control-M or other batch scheduling tools.', 'Good working knowledge of file handling: FTP, encryption, compression, preferred', 'General understanding of the function of scripts and system commands, preferred', 'Experience with database connectivity (both between databases and between database systems and clients to databases) in a diverse computing environment, preferred', 'Strong knowledge of MS queries stored procedures and data transformation, preferred', 'Be able to isolate problems between hardware and software and provide information to appropriate development team(s).', 'Highly developed, process-oriented skills for troubleshooting, problem solving, and problem resolution.', 'Able to analyze processes to see patterns and recommend improvements.', 'Minimum five (5) years’ hands-on experience with Microsoft technologies, local area networks, distributed computing environments and information technologies.', 'One (1) year experience in a call center environment, preferred.', 'Three (3) to Five (5) years’ hands-on experience with Microsoft SQL Database technologies, queries, SSIS, etc., preferred', 'Assist in testing of solutions.', 'Good verbal and written communication skills.', 'Must be customer-focused.', 'Ability to maintain confidentiality', 'Extended working hours may be required by management and business needs.', 'Travel to multiple facilities may be required.', 'May be required to lift, push, or pull materials weighing up to twenty (20) pounds.', 'May be required to sit and review information on a computer screen for long periods of time.', 'May require repetitive motions of the hands and wrist related to writing and typing at an electronic keyboard.', 'Corporate / satellite office role.', 'This job description does not list all the duties of the job. You may be asked by your supervisors or managers to perform other duties. You will be evaluated in part based upon your performance of the tasks listed in this job description.', 'The employer has the right to revise this job description at any time. This job description is not a contract for employment, and either you or the employer may terminate employment at any time, for any reason.', 'Completion of at least one year of active service in Santander', 'Completion of at least twelve months in current position', 'Be in ""Good Standing""']",2020-08-08 13:03:53
Spark Hadoop Data Engineer,NTT DATA Services,3.5 out of 5,"Irving, TX","['Analyze and understand data sources & APIs', 'Design and Develop methods to connect & collect data from different data sources', 'Design and Develop methods to filter/cleanse the data', 'Design and Develop SQL , Hive queries, APIs to extract data from the store', 'Work closely with data Scientists to ensure the source data is aggregated and cleansed', 'Work with product managers to understand the business objectives', 'Work with cloud and data architects to define robust architecture in cloud setup pipelines and work flows', 'Work with DevOps to build automated data pipelines', 'Hands-on experience with the Hadoop eco-system (HDFS, MapReduce, Yarn, Hive, Pig, Impala, Spark, Kafka,)', 'Good understanding for ETL tools like Ab-initio , TalenD', 'Familiarity with HTTP and invoking web-APIs', 'Exposure to machine learning engineering', 'Exposure to NLP and text processing', 'Experienced in managing work with distributed teams', 'Experience working in SCRUM methodology', 'Proven sense of high accountability and self-drive to take on and see through big challenges', 'Confident, takes ownership, willingness to get the job done', 'Excellent verbal communications and cross group collaboration skills', '3+ years of Advanced knowledge of Hadoop ecosystem and Big Data technologies', '3+ years of experience and Expert level knowledge building pipelines using Spark /Pyspark', '3+ years of experience in programming in Scala and Python']",2020-08-08 13:03:53
Data Engineer,Realogy Holdings Corp,3.4 out of 5,"Madison, NJ","['Create, build and maintain high performance data storages based on best practice standards.', 'Create, build and maintain scalable data models for machine learning.', 'Design, build and optimize new and existing processes supporting data transformation, data structures, meta data, dependency and workload management.', 'Support engineering in building highly efficient queries and advise on code to data optimizations.', 'Create and provide regular feedback loops.', ""Bachelor's degree in Computer Science or related field and at least 5 years of relevant experience."", 'Strong technical background in relational SQL and NoSQL non-cloud and cloud databases including MySql, Aurora or Postgres.', 'History of manipulating, processing and extracting values from large disconnected data sets.', 'History of optimizing and refactoring large data sets.', 'Working experience with message queuing, stream processing and highly scalable big data storages.', 'Strong analytic skills and ability to transform unstructured into structured data.', 'Strong technical background with hands-on development in at least one of the following programming languages: PHP, Go, Ruby or Python.', 'Proficiency in testing tools.', 'Hands-on experience in developing micro-service solutions and large scale, enterprise-grade applications.', 'Experience developing in a cloud-first environment (containers, server-less, cloud db).', 'Proficiency in Project Management and ability to work in an agile development process.', 'Solid understanding and proficiency with git and other standard development tools.', 'Ability to work quickly with an eye towards writing clean, efficient and reusable code.', 'Excellent analytical and troubleshooting skills.', 'Excellent written and verbal communication skills.', 'Strong work ethic.']",2020-08-08 13:03:53
Data Operations Engineer,Emergent Biosolutions,3.3 out of 5,"Gaithersburg, MD 20879","['Assists in gathering requirements for configuration, maintenance, and upgrade of SCADA/control and automation systems', 'Ensures connectivity and automation of data collection from lab scale equipment and instruments', 'Supports opportunities to standardize data collection and data transfer solutions', 'Participates in development, ongoing support, and delivery activities related to data services', 'Supports rollout of Industry 4.0 digital initiatives', 'Solves a range of increasingly complex problems and analyzes data solutions by acquiring new knowledge', 'Helps coordinate efforts of IT support groups and external resources such as vendors and consultants', 'Assists users in troubleshooting SCADA and control system related problems', 'Contributes to new computer platform design and data driven solutions', 'Responsible for support of laboratory/automation data historians and analytics systems', 'Provides Windows OS environment support, maintenance and patching in a controlled environment', 'Troubleshoots Windows log files and performance', 'Maintains up-to-date knowledge on modern data technologies and data management', 'Assists with support and planning of data related and system architecture portion of CAPEX projects', 'Prepares data related procedures and documentation', 'Adheres to project budgets and schedules, performing work in accordance with internal SOPs and good Engineering Practices, as well as, regulations and compliance', 'Supports testing of deliverables and provides data analysis as needed', 'Supports activities related to global LIMS project', 'Manages and optimizes processes for data intake, transfer, validation, and visualization', 'Bachelor’s degree in Computer Science, IT, Data Science, Engineering or related field from an accredited university', '3+ years’ experience and/or relevant project/coursework', 'Knowledge of real-time data acquisition and/or automation/controls environment', 'Experience with software in the following fields: SCADA and/or control systems, automation, process controls', 'Experience administering and/or configuring data historian systems such as OSIsoft PI', 'Knowledge of PC environment, able to modify network settings, understanding of remote connections', 'Exposure to working with data transfer methods to other digital platforms such as IIoT', 'Experience or exposure to communications protocols such as OPC, Modbus, MQTT', 'Knowledge/exposure to virtual VMWare environment', 'Problem solving, quantitative and analytical abilities', 'Experience in dashboard development to visualize data and metrics', 'Works well within teams and interactions with groups of various disciplines', 'Exercises judgment within generally defined practices and policies in selecting methods and techniques for obtaining data solutions', 'Possesses analytical and logical troubleshooting skills for computer and basic network issues', 'Proficient with computer applications such as Microsoft Suite and Visual Basic, batch files', 'Must lead by example through strong work ethics and high standards', 'Must be able to adapt to change while viewing obstacles as opportunities', 'Desire to continue to promote personal and technical development', 'Interest in cutting edge data technologies', 'Experience supporting lab/manufacturing/automation systems', 'Experience supporting lab systems such as Waters Empower', 'Experience with OSIsoft PI real-time data and events management system', 'Knowledge and desire to work with IIoT platforms', 'Experience with coding in VB, C#, Python, or other standard programming languages', 'Experience/exposure to Machine Learning and Artificial Intelligence, 3-D printing', 'Experience working with data acquisition platforms in a controlled environment', 'IT or specialized certifications such as Network +, Security +, CCENT, Server +, or related', 'Experience in a pharmaceutical, biopharmaceutical, and consumer products process company or food industry', 'Familiarity with data integrity/assurance and data security guidelines']",2020-08-08 13:03:53
Data Engineer Trainee,Cndro,N/A,"Houston, TX",[],2020-08-08 13:03:53
Data Engineer - P3,Kani Solutions,N/A,"Milwaukee, WI","['Full lifecycle application development', 'Design, code and debug software', 'Perform software analysis, risk analysis, reliability analysis', 'Participate in software modeling and simulation', 'Integrate new software solutions with existing systems', 'Perform migrations', 'Perform regular status reviews of problems/issues', 'Participate in the development or refinement of proactive services and/or data repositories', 'Query database to provide data extracts', 'Perform ETL processes', '5-15 years of experience in IT', 'Experience with databases (DB2, SQL, UDB)', 'Experience with ETL (Informatica preferred)', 'Experience with Linux scripting and Autosys jobs', 'Experience with CI/CD pipelines', 'Experience working in a Scrum/Agile environment', 'Experience working in large environments with an understanding of complexity, business rules, and tranformations', 'Documentation skills', 'Monday to Friday', 'ETL (Informatica preferred: 2 years (Required)', '(DB2, SQL, UDB): 2 years (Required)', 'CI/CD pipelines: 1 year (Required)', 'Database, UDB, Db2, ETL, Linux: 3 years (Required)', 'Temporarily due to COVID-19']",2020-08-08 13:04:40
Senior Data Engineer,Gathi Analytics,N/A,"Columbus, OH","['Weekends', 'Data Engineer: 10 years (Required)', 'python: 5 years (Preferred)', 'spark: 4 years (Required)', 'azure: 3 years (Preferred)', ""Bachelor's (Required)"", 'Columbus, OH (Required)', 'www.gathi.com', 'Temporarily due to COVID-19']",2020-08-08 13:04:40
Data Engineer,ANB Sourcing LLC,N/A,"Carlsbad, CA","['7 to 9 years working experience in data integration and pipeline development with data warehousing .', 'Experience with AWS Cloud on data integration with Apache Spark, EMR, Glue, Kafka, Kinesis, and Lambda in S3, Redshift, RDS, MongoDB/DynamoDB ecosystems', 'Strong real-life experience in python development especially in pySpark in AWS Cloud environment.', 'Design, develop test, deploy, maintain and improve data integration pipeline.', 'Experience in Python and common python libraries.', 'Strong analytical experience with database in writing complex queries, query optimization, debugging, user defined functions, views, indexes etc.', 'Strong experience with source control systems such as Git, Bitbucket, and Jenkins build and continuous integration tools.', 'Experience with continuous deployment(CI/CD)', 'Databricks, Airflow and Apache Spark Experience is a plus.', 'Experience with databases (PostgreSQL, Redshift, MySQL, or similar)', 'Exposure to ETL tools including Informatica and any other .', '8 Hour Shift', 'Monday to Friday', 'AWS: 1 year (Required)', 'Pyspark: 3 years (Required)', 'Databricks: 2 years (Required)', 'ETL: 1 year (Required)', 'Current Location & Visa status:', '1 year', 'Likely', 'No', 'One location', 'www.anbsourcing.com', 'Temporarily due to COVID-19']",2020-08-08 13:04:40
Data Engineer,Inspire Brands,3.1 out of 5,"Atlanta, GA 30328","['Job', 'Company', 'Design, develop and maintain reliable automated data solutions based on the identification, collection and evaluation of business requirements. Including but not limited to data models, database objects, stored procedures and views.', 'Developing new and enhancing existing data processing (Data Ingest, Data Transformation, Data Store, Data Management, Data Quality) components', 'Support and troubleshoot the data environment (including periodically on call)', 'Document technical artifacts for developed solutions', 'Good interpersonal skills; comfort and competence in dealing with different teams within the organization. Requires an ability to interface with multiple constituent groups and build sustainable relationships.', 'Versatile, creative temperament, ability to think out-of-the box while defining sound and practical solutions. Ability to master new skills.', 'Proactive approach to problem solving with effective influencing skills.', 'Familiar with Agile practices and methodologies', '4+ years professional data engineering experience focused on batch and real time data pipelines development using Spark, Python or Java; Data processing / data transformation using ETL tools, Azure Databricks platform (preferred)', 'Cloud Data Warehouse solutions experience (Snowflake, Azure DW, or Redshift); data modeling, analysis, programming', 'Experience with a DevOps model utilizing a CI/CD tool', 'Experienced in Azure Cloud Platform. (ADLS, Blob)', 'Hands-on Talend work experience (anyone with this skill will have an advantage over other candidates)', 'Apache Airflow, Azure Data Factory experience', 'BS in either Information Systems, Finance/Mathematics, or Computer Science or similar', '5 - 8 years experience']",2020-08-08 13:04:40
Data Scientist - Climate Analytics,McKinsey & Company,4.3 out of 5,"Denver, CO 80202","['Graduate degree (PhD/postdoc highly preferred) in atmospheric science, meteorology, climate/earth systems science, hydrology, civil/environmental engineering, astrophysics, or similar fields', 'Required modeling experience: experience working with climate models (i.e. CMIP5 GCMs, RCMs, etc.), ensemble analysis, uncertainty quantification', 'Preferred modeling experience: flood/hydrological modeling, bias correction/downscaling methods, climate impact assessments', 'Knowledge of climate risk assessment, extreme events analysis required', 'Ability to work with large, multi-dimensional data (e.g. netCDF, GRIB, TIFF files)', 'Python knowledge required (experience with xarray and knowledge of basic software engineering principles highly preferred)', 'Experience working with Linux and command line scripting (i.e. bash, zsh), and familiarity with cloud computing environments highly preferred', 'Self-management skills and ability to work as part of an agile team', 'Strong multitasking and parallel development abilities', 'Strong analytical and problem-solving skills paired with the ability to develop creative and efficient solutions', 'Strong interpersonal communication skills', 'Able to work under competing, quickly-changing priorities, manage expectations effectively and support the team under pressure', 'Willingness to travel up to 50% (will likely travel 20-40%) (after current McKinsey travel restrictions due to COVID-19 are lifted; all work is currently remote)']",2020-08-08 13:04:40
Data Engineer – Sales Insights and Analytics **,The Hartford,3.7 out of 5,"Hartford, CT","['Job', 'Company']",2020-08-08 13:04:40
Software Engineer - All Levels,Xometry Inc,N/A,Remote,"['Active participation on a software development team designing, coding, testing, and releasing functionality to our customers', 'Close collaboration with other engineers and product managers to become a valued member of an autonomous, cross-functional team', 'Operational responsibility for the services that are owned by your team, potentially including taking part in an on-call rotation', 'Experience working on a web application project that you can talk about, showing off some of your work', 'Some understanding and maybe some experience with front-end technologies HTML, CSS, DOM, JavaScript, Ajax and any of the common frameworks like React, Angular, Ember, Backbone, …etc (really any javascript based framework)', 'Some understanding and maybe some experience with using using C#, Java, C, C++, Ruby, Python, Node or similar back-end technologies', 'Familiarity with code management (GIT) and continuous integration build and deploy', 'Must be a US citizen, green card holder, or a legal permanent resident of the United States', 'Excellent oral and written (English) communication skills', 'Must be able to work core aligned hours to US Eastern Time / GMT-5', 'Work in a highly collaborative, self-organizing team with the ability to decide how your team works and what technologies you use', 'Competitive salary + comprehensive benefits', 'Flexible working hours with paid time off', 'Health, Dental, Vision, Commuter, Dependent Care, Primary & Secondary Parental Leave, and 401K benefit options', 'Continuous development opportunities such as onsite training, meetups, conferences, and online training subscriptions', 'Stock Options – we’re a growing startup so you get a piece of the pie', 'And more!']",2020-08-08 13:04:40
Data Engineer,Perpay Inc.,N/A,"Philadelphia, PA 19103","['Analyze and resolve complex challenges around data and tools. Optimize analytical workflows by identifying opportunities and automating them', 'Implement solutions to bring together application data generated by distributed systems, third-party data, and real-time user data needed to make key business decisions', 'Work within the Data Science team to serve machine learning solutions at scale', 'Work on projects of growing responsibility, both individually and as part of a team, to build experience and skills at a pace matched to your shown ability', 'Learn more about the industry and Perpay, establishing a solid foundation to be better positioned for long-term career success', 'Bachelor’s degree or higher in a quantitative/technical field (Computer Science, Statistics, Engineering)', 'Minimum two years work experience in related field required', 'Working knowledge of data design, architecture and warehousing', 'Understanding of data management fundamentals and data storage principles', 'Knowledge of distributed systems as it pertains to data storage and cloud computing', 'Understanding and administration of AWS, Docker and Linux-based systems', 'Experience in custom ETL design, implementation and maintenance', 'Experience in large scale data processing using traditional and distributed systems like Hadoop, Spark, Dataflow, and Airflow.', 'Strong working knowledge of SQL/NoSQL, relational databases and Python is required (2+ years experience)', 'Knowledge and practical experience in machine learning and AI fundamentals', 'Experience implementing machine learning solutions at scale', 'Experience working with both Batch and Real Time data processing systems', 'Ability to work and communicate effectively with stakeholders.', 'Effective project management, problem solving, analytical and troubleshooting skills.', 'Opportunity to work with one of the fastest growing financial startups', 'Competitive salary + equity', 'Health/dental/vision insurance + 401K', 'Gym + public transportation subsidy', 'Relocation assistance', 'Centrally located in downtown Philadelphia']",2020-08-08 13:04:40
Senior Data Engineer,silicon tech solutions,N/A,"Wilmington, DE",[],2020-08-08 13:04:40
Data Engineer,Cielo Talent,3.3 out of 5,United States,"['Develop, test, implement and document technical engineering solutions to assist business partner’s self-service analytic needs.', 'Work on project teams consisting of business partners, architects, and other groups to identify technical and functional needs of analytical systems, and determine priority of needs.', 'Assist in efforts to analyze, define, design and document requirements for data, workflow, logical processes, hardware and operating system environment.', 'Work under broad direction and be fully accountable for own technical work and/or project/supervisory responsibilities. Receive assignments in the form of objectives. Establish own milestones and team objectives. Work is often self-initiated.', 'Champion technology internally across clients, fostering knowledge and optimization of technology to raise the bar throughout the organization, with entrepreneurial spirting to build new solutions and drive organizational change.', 'High School Diploma or equivalent required.', 'Bachelor’s degree preferred.', 'At least two years of results-oriented experience in cloud-based analytics platforms.', 'At least two years of experience with SQL on any major RDBMS.', 'At least two years of experience developing ETL solutions working with diverse data sources.', 'At least two years of experience using Python for data analysis, data science, ETL/ELT, or integrations through the building and consuming SOAP and REST APIs.', 'Deep technical expertise with cloud-based analytics platforms.', 'Proficiency in reporting and analytics tools.', 'Proficiency in Word, Excel, PowerPoint, Visio, Outlook, Internet and other related software.']",2020-08-08 13:04:40
Data Engineer,Binary tech consulting corp,N/A,"Carlsbad, CA","['7 to 9 years working experience in data integration and pipeline development with data warehousing .', 'Experience with AWS Cloud on data integration with Apache Spark, EMR, Glue, Kafka, Kinesis, and Lambda in S3, Redshift, RDS, MongoDB/DynamoDB ecosystems', 'Strong real-life experience in python development especially in pySpark in AWS Cloud environment.', 'Design, develop test, deploy, maintain and improve data integration pipeline.', 'Experience in Python and common python libraries.', 'Strong analytical experience with database in writing complex queries, query optimization, debugging, user defined functions, views, indexes etc.', 'Strong experience with source control systems such as Git, Bitbucket, and Jenkins build and continuous integration tools.', 'Experience with continuous deployment(CI/CD)', 'Databricks, Airflow and Apache Spark Experience is a plus.', 'Experience with databases (PostgreSQL, Redshift, MySQL, or similar)', 'Exposure to ETL tools including Informatica and any other .', 'BS/MS degree in CS, CE or EE.', 'Monday to Friday', 'Data Integration: 8 years (Required)', 'More than 1 year', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:04:40
Enterprise Engineer Intern,Facebook,4.2 out of 5,"Austin, TX","['Create elegant enterprise software applications using PHP/Hack or Python', 'Implement web interfaces using React, XHTML, CSS, and JavaScript', 'Build report interfaces and data feeds', 'Experience in C++, Java, JavaScript Perl, PHP, or Python', 'High levels of creativity and quick problem-solving capabilities', 'Experience working with or in support of diverse communities', 'Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment']",2020-08-08 13:04:40
Customer Success Representative - Robotics,Cobalt Robotics,N/A,Remote,"['You will be a friendly, professional Specialist who regularly interacts with customers to build a safe and friendly work environment.', 'This position requires excellent customer service to our clients, which include several Fortune 500 companies.', 'You will be an ambassador for the remote robots to help ensure smooth operations.', 'You will organize and direct a fleet of mobile robots, but you don’t need any prior experience with robots! You can learn on the job.', 'Experience working in a customer-facing position (i.e., sales, restaurant, hospitality)', 'Experience working directly with engineering teams and building and integrating systems', 'Proven ability to provide hands on support and diagnose technical issues across a variety of different platforms', 'Strong interpersonal skills with an ability to communicate technical information effectively to technical and non-technical stakeholders', 'High attention to detail', 'Positive outlook for learning new skills', 'Previous work experience that required late hours']",2020-08-08 13:04:40
Data Engineer,Charlie's Produce,3.4 out of 5,"Seattle, WA 98134","['Job', 'Company', 'Proven ability to deliver high quality work on time and with minimal supervision', 'Deep experience with Data Architecture, Database Design including Data Quality and Master Data Management (MDM) tools, processes and governance', 'Experience in defining the steps to perform a change, managing expectations, tracking status, and communicating to all constituents. Conceptual knowledge of IT infrastructure and supporting application across the company', 'Lead analysis, architecture, design, and development of data warehouse and business intelligence solutions', 'Work as part of a team, to design and develop cloud data solutions', 'Good experience designing highly scalable ETL processes with complex data transformations, data formats including error handling and monitoring, etc', 'Knowledge of methodologies such as Star Schema is a plus', 'Experience documenting business requirements and technical architecture/design while translating complex requirements and designs for development, testing and implementation', 'Hands-on experience in proactive monitoring of database environments (backups, recovery, capacity planning, job scheduling…), with Performance Tuning and Troubleshooting', 'Providing support for planning and performing database migrations, upgrades and updates', 'Experience on AWS, Azure, Tableau with data architecture, design, analytics and deployment is a big plus', 'Strong MS-SQL Server 2012 / 2014 experience with hands-on database design and Transact-SQL, SSIS / SSRS / SSAS development, testing, performance tuning, etc.', 'Experience in product development and / or consulting delivery engagements', 'Proven ability to communicate technical information to non-technical staff, both written and verbally', 'Candidate will be required to maintain a strong working relationship with key stakeholders at all levels within the organization to understand their business modules and must be able to work with the systems analysts to understand the necessary requirements to deliver and promote technical solutions as the business evolves.', 'Knowledgeable about technical concepts, pricnciple and apply project management methodolgies to support the business expectations', 'Expertise in SQL and experience with programming languages (Python, Java, C#,Power Shell is highly desireable)', 'Skillful at listening, prioritizing and follow ups while meeting customer expecttions.', 'Ability to work as an effective team member and self-motivated individual contributor', 'Competitive starting pay', '90 day performance-based raise', 'Yearly review with possibility of increase based on performance and tenure', 'We recognize and reward hard work and commitment. Supplemental retirement plan through our Employee Stock Ownership Plan (ESOP)', 'Employee assistance program (EAP)', 'Vacation pay, paid holidays, pre-tax commuter benefits, and free onsite parking', 'Employer-covered College Program', 'Coverage under State Sick Leave', '401(k) available', 'Health and wellness benefits including medical, dental, and vision', 'Remote Work option TBD', ""Bachelor's degree or equivalent experience required."", 'Minimum of 5 years’ experience of data architecture, business intelligence and/or consulting services, implementation, customer facing, vendor management and project management', 'Conceptual knowledge of applications and IT infrastructure', 'Familiar with the concepts, principles and practices of software applications, data bases, BI, Data warehouse platform', 'Knowledgeable and understanding of scripting and programming languages', 'One or more certifications to support the desired job description is preferred', 'Ability to travel as needed, approximately 5%', 'Knowledge of design, build and supports data base, data analytics, application integration and meeting customer expectations']",2020-08-08 13:04:40
Senior Data Engineer (Product),Intelligent Medical Objects,3.8 out of 5,Remote,"['Define technology vision, roadmap, and growth opportunities', 'Interact regularly with stakeholders to understand the problems being solved and curate feature and story backlogs according to business value', 'Intake, facilitate, refine, and organize work from stakeholders within Executive, Product, Architecture, Data, and Design teams to assist with data-related technical issues and support their data infrastructure needs', 'Provide vision and create requirements for the agile development teams throughout development', 'Document and develop user stories and use cases', 'Work in a large, complex data platform, and lead application and database design and implementation', 'Use standards and metrics to provide guidance and feedback to focus the teams towards building quality applications and services', 'Manage and respond promptly to defect reports', 'Aid support personnel as needed to determine system problems', 'Identify obstacles to programmer productivity and raise these to software engineering management to ensure successful team completion of sprint/quarterly goals', 'Keep abreast with agile/scrum best practices and new trends', 'A relevant technical BA/BS Degree and five years of experience, or seven years of relevant professional experience implementing well-architected data pipelines that are dynamically scalable, highly available, fault-tolerant, and reliable for analytics and platform solutions', 'Experience working within an agile team as a Product Owner, Product Manager, Business Analyst, team lead, or Scrum Master', 'In-depth knowledge of agile process and principles', 'Excellent communication skills', 'Experience performing root cause analysis on data and processes to answer specific business questions, and identify opportunities for improvement', 'Strong analytic skills related to working with unstructured datasets', 'A successful history of manipulating, processing, and extracting value from large disconnected datasets', 'Advanced working SQL knowledge, and experience with relational SQL and NoSQL databases, such as: PostgreSQL, DynamoDB, MongoDB, Elasticsearch.', 'Experience with ETL and BI Dashboard tools, such as: Talend, Informatica, Tableau, Looker', 'Experience with AWS cloud services, such as: EC2, EMR, RDS, Redshift']",2020-08-08 13:04:40
Data Engineer,UnitedHealth Group,3.7 out of 5,"Denver, CO","['Job', 'Company', 'Contribute to the success of the Healthcare Economics Data Management team', 'Design, develop, maintain, monitor and administer production ETL processes (PLSQL, Informatica, T-SQL)', 'Investigate production ETL issues / problems', 'Map database sources to specified data formats', 'Verify and validate ETL deliverables incoming/outgoing', 'Provide direction and mentoring of junior colleagues on topics related to datamart design and ETL deliverables', 'Lead troubleshooting episodes and communicate solutions/resolutions to the team', 'Translate concepts to requirements, then design, and develop into an automated production process', 'Act as a subject matter expert for other team members on assigned processes', 'Complete projects and development activities timely and accurately while following the System Development Life Cycle (SDLC)', 'Suggest changes and enhancements for processes.', 'Maintain ongoing self-study program to enhance knowledge of PL/SQL development, Oracle RDBMS Best Practices and Informatica PowerCenter', 'Document hours of design/development activities by following SDLC and IS Change Management', 'Performs all other related duties as assigned.', ""Bachelor's degree in Information Systems, Computer Science or 5 years of related work experience."", '3+ years of experience in Datamart design with Oracle (10g/11g/12c) databases', '3+ years of experience in PL/SQL development', '3+ years of experience in SQL', 'Strong knowledge of Data Warehousing schema design', 'Data Warehouse Extract, Transform, and Load knowledge', 'Production ETL operations and monitoring', 'Database query optimization', 'Windows Command/PowerShell, Cygwin scripting experience', 'Ability to work a flexible schedule to accommodate meetings in various time zones', 'Experience with MS SQL Server:2016 T-SQL; SSIS; Jobs Management', 'Experience with Informatica PowerCenter', 'Experience with Extract, Transform, and Load (ETL) tools', 'ESRI ArcGIS Pro', 'Oracle APEX development', 'All Telecommuters will be required to adhere to UnitedHealth Group’s Telecommuter Policy.']",2020-08-08 13:05:24
Big Data Engineer,Digital dhara,N/A,"McLean, VA","['Big Data: 10 years (Required)', 'S3 + AWS Certification is a Must : 1 year (Required)', ""Bachelor's (Required)""]",2020-08-08 13:05:24
Data Engineer,Kar Global,3.2 out of 5,"Carmel, IN 46032","['Collaborate with business partners to understand processes and the relationship to data velocity, availability, and quality', 'Identify improvement areas to enhance existing data processes and offerings', 'Design and recommend modern data warehousing solutions', 'Implement simple, intuitive data engineering and visual solutions', 'Mentor others to improve analytical skillsets across the organization', 'Design solutions with a focus on cloud, PaaS, SaaS, and serverless services', 'Data Warehouse and Business Intelligence experience', 'Strong problem-solving skills, with the ability to analyze and break down problems', 'Advanced SQL and RDBMS experience (ex. Snowflake, RedShift, Oracle, SQL Server, MySQL, etc.)', 'Experience engineering data ingestion and transformation solutions (ex. Azure Data Factory, Informatica, SSIS, Talend, Pentaho, Python, Databricks, stored procedures, etc.)', 'Advanced ability to visualize data (Tableau experience preferred)', 'Understanding and practice of Agile and DevOps principles', 'Experience with cloud warehousing and analytics (ex. Snowflake, Redshift, BigQuery)', 'Experience with semi-structured and unstructured data', 'OOP or functional programming experience (ex. Python, Java, C++, Scala, R, etc.)', 'Working knowledge of message queuing and stream processing', 'We’re a technology company delivering next generation tools to accelerate and simplify remarketing.', 'We’re an analytics company leveraging data to inform and empower our customers with clear, actionable insights.', 'And we’re an auction company powering the world’s most advanced and integrated mobile, digital and physical auction marketplaces.', 'Competitive compensation', 'Insurance coverage that includes medical, dental, vision and life insurance', 'Flexible spending account', 'Wellness program', '401(k) with employer match', 'Employee stock purchase program', 'Paid holidays and generous paid time off', 'Paid parental leave', 'Learning and development resources']",2020-08-08 13:05:24
Big Data Engineer,4S,N/A,"Arlington, VA","['Participate in architecture design', 'Design, develop, and implement scalable fault tolerant data pipelines', 'Monitor and tune existing pipelines and infrastructure', 'Maintain and improve existing solutions', 'Build metrics, analysis, machine learning, and dashboard visualizations', 'Built analytics and machine learning solutions', 'Other duties as assigned', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', 'Big Data experience in both structured and unstructured data', '5+ years working with SQL and NoSQL database platforms including data modeling, writing queries, and performing data analysis', '5+ years demonstrated professional experience with Big Data platforms and tools including Hadoop, GraphDB, Kafka, Spark.', 'Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)', 'Strong software engineering skills using Python and Scala.', 'Work experience on teams using Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', 'Familiarity with DevOps tools, e.g., Jenkins, GIT, Jira, Confluence, Sonar, Nexus', 'Experience with Data Lake concepts and design patterns', 'Experience with BI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)', 'Understanding of Data Management and Data governance best practices', 'Ability to own a project from inception to completion', 'Good communication skills', 'Decision making skills', 'Self Motivated', 'Able to work with a team']",2020-08-08 13:05:24
Data Engineer - Remote,SmileDirectClub,2.9 out of 5,"Nashville, TN 37219","['Design and build new dimensional data models and schema designs to improve accessibility, efficiency, and quality of internal analytics data', 'Build, monitor, and maintain analytics data pipelines', 'Implement systems for tracking data quality and consistency', 'Work closely with Analytics, Marketing, Finance, and Operations teams to understand data and analysis requirements', 'Work with teams to continue to evolve data models and data flows to enable analytics for decision making (e.g., improve instrumentation, optimize logging, etc).', 'Has a curiosity about how things work', 'Has built large-scale data pipelines professionally and can craft clean and beautiful code in Java, Scala, Python and/or SQL', 'Has built batch data pipelines with Hadoop/Spark as well as with relational database engines, and understands their respective strengths and weaknesses', 'Has experience with cloud platforms, preferably Amazon Web Services', 'Experience with event streams, preferably Kafka', 'Has experience with ETL jobs, metrics, alerting, and/or logging', 'Can jump into situations with few guardrails and make things better', 'Possesses strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems, and information retrieval', 'Is a strong communicator. Explaining complex technical concepts to product managers, support, and other engineers is no problem for you', 'When things break, and they will, is eager and able to help fix them', 'Has experience with MPP data warehouses (Redshift, Snowflake, or similar)', 'Is someone that others enjoy working with due to your technical competence and positive attitude', 'Academic background in computer science or mathematics (BSc or MSc)', 'Experience building simple scripts and web applications using Python', 'A solid grasp of basic statistics (regression, hypothesis testing)', 'Experience in small start-up environments', 'Medical, Dental and Vision Insurance', '401K with match', 'PTO', 'Aligner and Whitening Benefit', 'Collaborative work environment and positive culture', 'Medical, Dental and Vision Insurance', '401K with match', 'PTO', 'Aligner and Whitening Benefit', 'Collaborative work environment and positive culture', 'What is SmileDirectClub? Link here.', 'What are our customers saying? Link here.', 'What is a SmileShop? Link here.', 'What is our culture like? Link here.', 'How do we celebrate your team members? Link here.']",2020-08-08 13:05:24
Data Engineer,GalaxE.Solutions,2.6 out of 5,"Hartford, CT 06103","['Design and support the database and table schemas for new and evolving sources of data being brought into the data warehouse', 'Create and support the Analysis Services', 'Monitor and troubleshoot performance issues', 'Define and promote the team’s design principles and best practices', 'Work with business teams to be able to define requirements for real time reporting', '7+ years of experience in IT as a Data Engineer', 'Experience with the following: Python, Hadoop, Hive, and Spark (either Pyspark or Scala)', 'AWS experience']",2020-08-08 13:05:24
Big Data Engineer/Developer,"DynPro, Inc.",3.7 out of 5,"Minneapolis, NC","['Big Data Engineer/Developer', 'Duration – 6 – 12+ Months', 'Location: Minneapolis, MN (Preferably local to Minnesota)', 'Design, develop, test, deliver and operate software solutions for big data and AI problems', 'Apply test-driven and Agile software development methodologies', 'Develop solutions that can scale in system and data size', 'Ensure high reliability for production systems', 'Innovate constantly to improve quality, efficiency, reliability', 'Collaborate with customers to define and meet requirements', 'BS or advanced degree in Computer Science or related field, or equivalent experience', '5+ years’ experience in developing software applications', '2+ years’ experience working on BigData technologies like Hadoop (Hive, HBase, Ooozie) and Spark', 'Understand application/software development and design.', 'Proficiency in at-least one of the following languages: Java, Scala, Python', 'Experience with building and supporting distributed systems. Experience with REST services preferred.', 'Experience with one of more standard automation toolkits (e.g. ansible, chef, puppet, salt) is preferred.', 'Fluency in Unix command line tools and bash is preferred.', 'Experience with streaming and messaging tools (like Kafka, JMS, Avro, Protobuf) is a plus.', 'Experience with one or more cloud deployment automation tools (e.g. OpenStack, docker) is a plus.', 'Experience with a job scheduler like Jenkins, drone, rundeck is a plus.']",2020-08-08 13:05:24
Data Engineer,Benefits Data Trust,3.3 out of 5,"Philadelphia, PA 19102","['Build out our new GCP data platform and collaborate on architectural patterns for it with the Data Engineering team', 'Support the development of machine learning models with productionizing, monitoring and alerting tools', 'Write, update, and maintain ETL jobs across our data pipelines (mostly in Airflow)', 'Implement continuous improvements using our existing tools/technologies, which include SQL, Airflow, Python, Docker/Kubernetes, and others such as Terraform and Apache Beam. May also be expected to research and select other tools when the situation demands', 'Collaborate with internal customers to identify ongoing platform improvements (teams including Analytics, Projects, Policy, Software Engineering, and others throughout the organization)', ""Consult to software engineers on data-related changes to BDT's suite of software applications, including schema/model design, table structure, and data collection"", 'Engage with colleagues and collaborators using curiosity, critical thinking, a drive to completion, empathy, and a focus on impact', 'Follow existing data access and performance design standards for the data platform, software engineering, and all products and services accessing BDT information', 'Communication and Relationship-building – with technical peers and some stakeholders', 'Cloud-based Solution Implementation, of data platforms and infrastructure, including event-driven architectures, microservices and pattern design, supporting compliance and regulated environments (including PII and PHI)', 'Workflow and pipeline development to ensure reliability, availability, and consistency', 'Systems Engineering – on-system service management, typically in *nix environments', 'Data Modeling and Warehousing – proficient understanding of relational data structures and schemas; some familiarity with semi-structured, unstructured (big data) schemas', 'Automation, monitoring, and alerting – creating these tools based on existing designs and frameworks; resolving bugs and issues', 'Cloud engineering – working towards certification on any of the major hyperscale cloud platforms', 'Data Encapsulation & Transfer methodologies – understands standards for file formats and transfer methods', 'Also interested in relevant experience including:', 'o Experience with BI implementations/uplifts (we currently use Looker) and/or Data Governance models and methods', 'o Machine learning techniques, productionizing machine learning models, and/or creating models']",2020-08-08 13:05:24
Data Center Capacity Engineer,Facebook,4.2 out of 5,"Newton County, GA","['Responsible for the planning and technical execution of projects throughout the Data Center.', 'Work as a technical lead with cross-functional data center teams on large-scale data center projects and initiatives.', 'Provide guidance and mentor technical peers and be a go-to technical resource to evaluate and look for better ways to resolve issues and define updates to tools and processes.', 'Track issues and interpret data looking for trends and systemic issues that impact fleet uptime and utilization. Perform root cause analysis of complex technical issues and drive resolution.', 'Plan for large-scale deployments of hardware, while considering space, power, cooling, networking, and resiliency.', 'Provide cross data center support and identify potentially larger issues, displaying effective communication when something is identified.', 'Help develop global standards for processes, workflow and automation roadmaps for tools that facilitate deployment, maintaining and decommissioning of server hardware at scale.', 'Lead process improvements and best practice in data center operations.', ""Work with internal hardware teams and vendors to help resolve complex technical issues that affect Facebook's computing infrastructure."", 'Understand and be able to update and develop scripts and smaller sets of software.', 'Build cross-functional relationships and have the ability to influence policies and procedures to improve global data center operations.', 'Participate in an on-call rotation.', 'BS, BA or BEng or equivalent experience/certification.', '5+ years of infrastructure or related experience.', 'Knowledge of Linux and hardware systems support in an Internet operations environment.', 'Knowledge of the interdependencies of data center functions and technologies.', 'Experience managing multiple projects within the same time schedule.', 'Knowledge of out-of-band/lights-out server communication methods, such as IPMI and serial console.', 'Time and project management experience.']",2020-08-08 13:05:24
Packaging Engineer,HCL America Inc,2.3 out of 5,"West Chester, PA 19380","['Dental Insurance', 'Health Insurance', 'Relocation Assistance', 'Vision Insurance', '8 Hour Shift', 'Packaging: 1 year (Preferred)', 'Orthopedic: 1 year (Preferred)', 'Verification Validation: 1 year (Preferred)', 'surgical instruments: 1 year (Preferred)', 'www.hcltech.com', 'www.hcltech.com']",2020-08-08 13:05:24
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 13:05:24
Sr. DDI Migration Engineer,"Efficient IP, Inc.",N/A,"Philadelphia, PA","['Lead technical design meetings with customers', 'Configure appliances', 'Migrate data from existing DDI solutions to Efficient IP [i.e. from Microsoft, ISC, BlueCat, Infoblox, etc]', 'Scripting and data manipulation for migration', 'Assist with support during escalation and level 3/4.', 'You’ll always be technically challenged working with customers in every business sector who are looking to consolidate their DDI infrastructure', 'As part of the onboarding, Efficient IP will provide hands-on training and you’ll become Certified in our SOLIDServer solution', 'You’ll serve as the DDI subject matter expert and be instrumental in deploying Efficient IP', 'Opportunity for growth', 'Strong technical experience with one or more of the following:', 'DNS, working and protocol [ISC, Microsoft]', 'DHCP, working and protocol.', 'TCP/IP, both IPv4 and IPv6.', 'Bonus points:', 'Familiar with scripting to automate tasks (Perl, Bash, PHP, etc).', 'Data migration experience', 'DDI vendor experience in a Professional Services capacity with Infoblox, BlueCat or similar', 'Must be inquisitive, have the technical aptitude, curiosity and passion to become an SME in the DDI industry', 'Must have worked in a customer-facing role', 'Strong communication, interpersonal and presentation skills', 'Strong technical problem-solving ability and troubleshooting skills', 'Must have strong attention to detail, be organized, self-motivated and able to handle multiple projects', 'Bachelor’s Degree preferred', 'Must be able to work in the US without any type of sponsorship', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Vision Insurance', 'Monday to Friday', 'DNS, DHCP, IPAM: 5 years (Preferred)', 'Philadelphia, PA (Preferred)', 'United States (Required)', '25% (Required)', 'Do you have any experience with data migrations?', 'Bonuses', 'Fully Remote', 'www.efficientip.com', 'Yes']",2020-08-08 13:05:24
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:05:24
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:05:24
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:05:24
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:05:24
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:05:24
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:05:24
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:05:24
Data Engineer Consultant,"World Wide Technology, Inc.",3.7 out of 5,Remote,"['Develop high performance distributed data warehouses, distributed analytic systems and cloud architectures', 'Participate in developing relational and non-relational data models designed for optimal storage and retrieval', 'Develop, test, and debug batch and streaming data pipelines (ETL/ELT) to populate databases and object stores from multiple data sources using a variety of scripting languages; provide recommendations to improve data reliability, efficiency and quality', 'Work along-side data scientists, supporting the development of high-performance algorithms, models and prototypes', 'Implement data quality metrics, standards, guidelines; automate data quality checks / routines as part of data processing frameworks; validate flow of information', 'Ensure that Data Warehousing and Big Data systems meet business requirements and industry practices including but not limited to automation of system builds, security requirements, performance requirements and logging/monitoring requirements', 'At least 5 years of experience', 'Ability to translate a logical data model into a relational or non-relational solution', 'Experience with at least one traditional data warehousing technology (e.g., Teradata, Oracle, SQL Server) and/or modern platforms (e.g., AWS, GCP, Azure)', 'Expert in one or more of the following ETL tools: SSIS, Azure Data Factory, AWS Glue, Matillion, Talend, Informatica, Fivetran', 'Experience in SQL scripting, tuning, indexing, partitioning, data access patterns, and scaling strategies', 'Hands-on experience in database development using views, SQL scripts and transformations', 'Experience with data integrations and data processing for business intelligence and analytics workloads', 'Ability to translate complex business problems into data-driven solutions', 'Experience as a key player in developing an enterprise data warehouse', 'Ability to identify data quality issues that could affect business outcomes', 'Flexibility in working across different database technologies and propensity to learn new platforms on-the-fly', 'Strong interpersonal skills', 'Team player prepared to lead or support depending on situation', 'Certification in any of the modern ETL tools (e.g. SSIS, Azure Data Factory, AWS Glue, Matillion, Talend, Informatica, Fivetran)', 'Hands-on ETL development experience with Matillion', 'Health and Wellbeing: Heath, Dental, and Vision Care, Onsite Health Centers, Employee Assistance Program, Wellness program', 'Financial Benefits: Competitive pay, Profit Sharing, 401k Plan with Company Matching, Life and Disability Insurance, Tuition Reimbursement', 'Paid Time Off: PTO & Holidays, Parental Leave, Sick Leave, Military Leave, Bereavement', 'Additional Perks: Nursing Mothers Benefits, Voluntary Legal, Pet Insurance, Employee Discount Program']",2020-08-08 13:06:13
Streaming Data Engineer,TPC Energy Fund,N/A,"Washington, DC","['Relevant research experience, such as a PhD, Masters, or Architect Role in Math, Computer Science, Physics, Machine Learning or a relevant quantitative field', '3-5 years managing and optimizing large sets of data', 'Ability to work with trading team and make creative suggestions for evaluating the data', 'Knowledge of time series data classification and anomaly detection', 'Excellent programming skills (proficient in Python, GO or Java)', 'AWS experience and/or experience architecting cloud based system', 'Eager to conquer large sets of data and improve both our capabilities and speed of analysis', 'Driven by solving complex problems', 'Strong communication skills and a self-starter', 'Ability to learn from mistakes and make improvements', 'Experience in the energy markets is preferred but not a must']",2020-08-08 13:06:13
Data Analyst (Data Engineer),data.world,N/A,"Austin, TX 78731","['Collaborate with business groups at data.world to gather requirements around key insights and reporting needs', 'Develop effective and intuitive BI data reports, visualizations, and queries in support of insights for both internal-facing and customer-facing use cases', 'Conduct evidence-based investigations and draw actionable conclusions in support of company and team goals and overall product success', 'Develop new data and analytics capabilities for our customer-facing Usage and Governance Reporting', 'Administer and optimize our SaaS-based data warehouse and BI infrastructure in support of self-service analytics dashboards, ad hoc analytics, and reporting', 'Evolve our star schema data model and architecture to ensure performance and usefulness across the organization', 'Write and maintain SQL jobs in support of ETL/ELT and BI analysis, reporting, and visualization, ability to troubleshoot SQL jobs as required', 'Engage and coordinate with data science, engineering, and others at data.world in support of data initiatives', 'Maintain diagrams and documentation of data models and data flows as needed to support understanding and troubleshooting of data infrastructure', 'Build and maintain internal data catalog including data dictionaries, glossary, and curated datasets in support of easy consumption by the rest of the company', 'Manage and drive improvements for the metrics collection pipeline, data processing, and self-service data & insight tools', 'Be stewards and evangelists for data driven culture and data best practices within the company', 'Be customer zero, leveraging our product and providing feedback as one of the key target personas that the product intends to provide value for', '5+ years of experience working with BI or data warehouse technologies in support of insights and reporting', '5+ years of SQL experience with ability to write and tune SQL jobs for a variety of usage patterns', 'Strong interpersonal skills and experience interfacing with others internally and externally from the company', 'Understanding of ETL, ELT, star schema, and other data model and data warehouse concepts, techniques, and best practices', 'Good communication and presentation skills with the ability to explain concepts and conclusions around data and insights in a clear, concise, and compelling way', 'Strong data visualization skills and ability to choose the best way to present information', 'Experience working with Snowflake or other applicable SQL data warehouse technologies', 'Experience working with Tableau, Looker, or other modern data visualization tools', 'Experience with DBT and/or Python', 'Experience working in for SaaS or enterprise software companies in the data or analytics space']",2020-08-08 13:06:13
Entry Level - Associate Data Scientist,IBM,3.9 out of 5,United States,"['Implement and validate predictive and prescriptive models, create and maintain statistical models with a focus on big data.', 'Incorporate a variety of statistical and machine learning techniques in your projects.', 'Write programs to cleanse and integrate data in an efficient and reusable manner.', 'Use leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites.', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'Communicate with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.', 'Evaluate modelling results and communicate the results to technical and non-technical audiences.', 'Ability to look at things differently, debug, troubleshoot, design and implement solutions to complex technical issues.', 'Strong technical and analytical abilities, a knack for driving impact and growth, and experience with a programming/scripting in a language such as Java or Python.', 'Basic understanding of statistical programming in a language such as R, Python, or SAS, SPSS, MATLAB.', 'Basic understanding of Cloud (AWS, Azure, etc.)', 'Excellent verbal and written communication skills.', 'Work or internship experience using data science tools in a corporate environment.', 'Interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'Willingness to travel up to 100% of the time.']",2020-08-08 13:06:13
"Senior Software Engineer, Data Integrations",Transfix.io,N/A,Remote,"['Write code to extend Transfix’s platform and endpoints for data exchange with our proprietary freight management system via APIs and EDI.', 'Develop self-serve API documentation and testing platforms that enable developers to integrate with our platforms with minimal direct support.', 'Manage technical operations and scaling for our existing services, e.g. monitoring and triaging errors, maintaining low-latency in runtime performance, scaling infrastructure as our business grows.', 'Write automated tests—linting, unit tests, and end-to-end integration tests.', 'Deploy code to production frequently.', 'Collaborate with partners across the company, as well as external customers and partners (shippers, carriers, software partners).', 'Our platforms are built with Ruby on Rails, Java, PostgreSQL, and Redis. We are hosted on AWS and leverage a variety of their native services. Code is tested using CircleCI and a variety of unit- and end-to-end testing frameworks, including RSpec. We monitor our production software with tools like DataDog, Sentry, and CloudWatch.', 'You have 5+ years professional experience writing, delivering, supporting, and debugging production software.', 'You have a mastery of Ruby, and at least one additional language (e.g. Python, Java, Go, C, or C++).', 'You have prior experience supporting external APIs and associated authentication schemes, documentation, and testing frameworks.', 'You advocate for best practices and high quality code in your teams, and are thoughtful about prioritizing improvements that will have the most impact in your team.', 'You take pride in delivering high-quality products and build confidence in the software you deploy using a combination of automated testing, manual testing, and monitoring tools.', 'You have excellent communication skills and enjoy collaborating with a diverse set of partners.', 'You have a bias for shipping, learning, and iterating.', 'You enjoy both learning from colleagues and mentoring others.', 'You can constructively disagree with others while maintaining trust and respect.']",2020-08-08 13:06:13
Big Data Engineer,CloudZenix LLC,N/A,"New York, NY","['Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities', 'Implementing ETL process {{if importing data from existing data sources is relevant}}', 'Monitoring performance and advising any necessary infrastructure changes', 'Defining data retention policies', '{{Add any other responsibility that is relevant}}', 'Proficient understanding of distributed computing principles', 'Management of Hadoop cluster, with all included services {{unless you are going to have specific Big Data DevOps roles for this}}', 'Ability to solve any ongoing issues with operating the cluster {{unless you are going to have specific Big Data DevOps roles for this}}', 'Proficiency with Hadoop v2, MapReduce, HDFS', 'Experience with building stream-processing systems, using solutions such as Storm or Spark-Streaming {{if stream-processing is relevant for the role}}', 'Good knowledge of Big Data querying tools, such as Pig, Hive, and Impala', 'Experience with Spark {{if you are including or planning to include it}}', 'Experience with integration of data from multiple data sources', 'Experience with NoSQL databases, such as HBase, Cassandra, MongoDB', 'Knowledge of various ETL techniques and frameworks, such as Flume', 'Experience with various messaging systems, such as Kafka or RabbitMQ', 'Experience with Big Data ML toolkits, such as Mahout, SparkML, or H2O {{if you are going to integrate Machine Learning in your Big Data infrastructure}}', 'Good understanding of Lambda Architecture, along with its advantages and drawbacks', 'Experience with Cloudera/MapR/Hortonworks {{you can specify the distribution you are currently using or planning to use here}}', '{{List any other technologies you are using or planning to use. Most Big Data Engineers will know some of the ones listed here: The Hadoop Ecosystem Table}', 'Monday to Friday', 'Kafka: 6 years (Preferred)', 'Cloudera: 5 years (Preferred)', 'Hive: 8 years (Preferred)', 'Machine Learning: 2 years (Preferred)', 'NoSQL: 5 years (Preferred)', 'Spark: 5 years (Preferred)', 'MapR: 5 years (Preferred)', 'Big Data: 10 years (Preferred)', 'Flume: 3 years (Preferred)', 'ETL: 3 years (Preferred)', 'United States (Required)', '100% (Required)', 'Confidential (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 13:06:13
Quality Engineer,MiTek Industries,3.5 out of 5,"Chester Springs, PA","['Create quality standards and testing systems to reflect efficiency, reliability and performance to both industry and internal standards for all business processes.', 'Development of documentation system that reports issues and errors relating to the specific business processes, with efforts placed to find a solution.', 'Develop, train, and motivate employees engaged in quality activities across the division at multiple facilities.', 'Monitor performance of quality control systems to ensure effectiveness and efficiency.', 'Participate and oversee audits of the quality and documentation systems.', 'Supervise the tracking of defects, test results or other quality control data.', 'Communicate quality control information to all relevant organizational departments.', 'Effectively communicate with associates and all teams supporting the business process functions.', 'Lead quality role in daily accountability meetings.', 'Provide leadership in meeting aggressive quality goals.', 'Prepare and report out quality metrics.', 'Use data driven decisions for continuous improvement.', 'Responsible lead in control of changes; review of changes for impact on quality system and implementation of appropriate qualification, documentation, and procedures.', 'Devise methods, processes, and procedures to increase efficiency.', 'Responsibility for leading the voice of the customer in product quality, safety, and integrity.', 'Performs other related duties/special projects as assigned.', ""Bachelor's degree in engineering or a related field."", 'Five to seven years of Quality experience.', 'Proficient in computer technology and systems with an in-depth knowledge of market trends and conditions.', 'Proficient at Excel and PowerPoint', 'Additional skills include strong leadership, management abilities, analytical and problem-solving abilities.', 'Read and understand engineering drawings and specifications', 'Strong working knowledge of Lean Manufacturing, Process Flow, FMEA, Control Plan, PPAP, & LPA', 'Experience in problem-solving tools: 8D, PPSR, 5 why, Pareto Principles and data analysis.', 'Experience in Structured Problem Solving: Six Sigma Certified Plus', 'Ability to prioritize issues, analyze situations and implement effective corrective actions.', 'Ability to respond to changes in the work environment.', 'Demonstrated managerial courage; self-confident and able to act as role model.', 'Travel up to 30%']",2020-08-08 13:06:13
Data Analytics Engineer,ION IP Optical Networks,N/A,"New York, NY","['Develop new infrastructure for data pipelines, analytic tools, and signal processing SW to support the data analytics team.', 'Develop new analytical approaches and innovate on performance and yield optimization.', 'Interact with data providers and test team.', 'Provide rapid and concise feedback for debugging of yield and design problems in real time.', 'Collaborate with all other functional teams in the organization to deliver crisp, actionable results in situations of considerable complexity.', 'M.S. or Ph.D. in computer science / electrical engineering / physics / applied physics / similar quantitative fields.', 'Fluency with programming in Python, C++, or similar.', 'Familiarity with data infrastructure, ETL, and analytics platform development.', 'Good understanding of general concepts in physics.', 'Understanding of multi-variate statistics and stochastic processes.', 'Strong experience in ETL framework, database/data warehouse, analytic platforms development and optimization.', 'Proficiency in SQL, experience in PDF Solutions DB tools, MySQL, PostgreSQL, Oracle.', 'Familiarity with analytic platforms such as TIBCO Spotfire, Tableau.', 'Proficiency with JMP and Bash scripting.', 'Experience with designing or characterizing silicon photonic or other integrated optical/optoelectronic devices or circuits.']",2020-08-08 13:06:13
Data Engineer,"Navstar, Inc.",3.8 out of 5,"McLean, VA","['Highly Competitive Health Care Premiums, including 100% employer paid for employee', 'Flexible Spending Accounts for Medical and Dependent Care', 'Generous PTO and Federal Holiday Paid Leave', 'Employer Paid STD/LTD', 'Employer Paid Life Insurance', '401K plan and Employer Match', 'Referral and Opportunity Referral Programs', 'Professional Development Assistance']",2020-08-08 13:06:13
Software Engineer I,DICK'S Sporting Goods,3.5 out of 5,"Coraopolis, PA 15108","['Collaborates with other team members (UX, engineering, and platform management) and teams to create secure, reliable, scalable software solutions', 'Works with ERA Platform Team to ensure user stories that are developer-ready, easy to understand, and testable', 'Writes custom code or scripts to automate infrastructure, monitoring services, and test cases', 'Writes custom code or scripts to do “destructive testing” to ensure adequate resiliency in production', 'Configures commercial off the shelf solutions to align with evolving business needs', 'Creates meaningful dashboards, logging, alerting, and responses to ensure that issues are captured and addressed proactively', 'Fields questions from other product teams or support teams', 'Monitors tools and participates in conversations to encourage collaboration', 'Provides application support for software running in production', 'Proactively monitors production Service Level Objectives for products', 'Proactively reviews the Performance and Capacity of all aspects of production: code, infrastructure, data, and message processing', 'Participates in learning activities around modern software design and development core practices (communities of practice)', 'Proactively views articles, tutorials, and videos to learn about new technologies and best practices being used within other technology organizations', 'Reviews and discusses code from more senior engineers to understand best practices and design patterns', 'Increases business acumen by learning about other parts of the business', ""Bachelor's Degree"", 'Three to five years of experience', 'Experience creating load scripts and developing applications with Qlik Sense or similar BI Tool', 'Exposure to query optimization and troubleshooting', 'Experience in writing SQL queries against a relational database. Working experience in SQ', 'Action Oriented: Taking on new opportunities and tough challenges with a sense of urgency, high energy and enthusiasm', 'Collaborates: Building partnerships and working collaboratively with others to meet shared objectives', 'Communicates Effectively: Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences', 'Cultivates Innovation: Creating new and better ways for the organization to be successful', 'Drives Results: Consistently achieving results, even under tough circumstances', 'Global Perspective: Taking a broad view when approaching issues; using a global lens', 'Interpersonal Savvy: Relating openly and comfortably with diverse groups of people', 'Manages Ambiguity: Operating effectively, even when things are not certain or the way forward is not clear', 'Nimble Learning: Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder', 'Self-Development: Actively seeking new ways to grow and be challenged using both formal and informal development channels', 'Situational Adaptability: Adapting approach and demeanor in real time to match the shifting demands of different situations', 'Good Knowledge of Retail E-Commerce Domain', 'Experience with Agile Development and knowledge on Agile Development tools and versioning using Git or similar tools', 'Exposure to a cloud computing platform', 'JDBC/ODBC, SQL and experience working with RDBMS', 'Exposure to destructive testing methodologies, behavioral testing and tools', 'Exposure to production systems design including High Availability, Disaster Recovery, Performance, Efficiency, and Security', 'Exposure to defensive coding practices and patterns for high-availability', 'Experience with Apache Service Mix (or other ESB and Integration technologies)', 'JEE/Java development including JSP, JSTL, Servlets, Java Beans, EJBs, JPA']",2020-08-08 13:06:13
Sr. Cloud Support Engineer Data Domains - Nationwide,"Amazon Web Services, Inc.",3.6 out of 5,Remote,"['Experience in the technology that aligns with any of the (3) Big Data, Database and/or Analytics', 'Expert experience in Database Administration and strong Troubleshooting skills (tuning and optimization, deadlocks, schema design) in any Relational Database Engines (MySQL, PostgreSQL, Oracle, SQLServer)', 'Expert experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto', 'Expert experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra', 'Expert administration experience with (1) of the following Database engines: MySQL / Oracle / PostgreSQL / MariaDB / SQL Server / Amazon Aurora', 'Expert experience in Business Analytics data streaming, reporting, text/semantic analytics, application, support, and troubleshooting', 'Prior working experience with AWS - any or all of EC2, S3, EBS, ELB, RDS, Dynamo DB, EMR', 'Experience with data warehousing, ETL process, streaming and search services, and graph databases', 'Expert experience with System Administration with Linux (RHEL/CentOS) including Microsoft ActiveDirectory, and LDAP integration. Experience with troubleshooting Kerberos Authentication problems.', 'Expert experience with Networking and troubleshooting (TCP/IP, DNS, routing, switching, firewalls, LAN/WAN, traceroute, iperf, dig, cURL or related)', 'Good understanding of Machine Learning and statistics', 'Experience with Java and/or Python and shell scripting', 'Bachelor’s degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position', '6+ years professional experience', 'Learn and use groundbreaking technologies.', ""Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs."", 'Interact with leading engineers around the world.', 'Partner with Amazon Web Services teams to help reproduce and resolve customer issues.', 'Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.', 'Drive customer communication during critical events.', 'Drive projects that improve support-related processes and our customers’ technical support experience.', 'Write tutorials, how-to videos, and other technical articles for the developer community.', 'Work on critical, highly complex customer problems that may span multiple AWS services.', 'First and foremost this is a customer support role – in The Cloud.', 'On a typical day, a Support Engineer will be primarily responsible for solving customer’s cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.', 'Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.', 'Career development: We promote advancement opportunities across the organization to help you meet your career goals.', 'Training: We have training programs to help you develop the skills required to be successful in your role.', 'Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.', 'As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.', 'Experience in data visualization tools such as Tableau, PowerBI, Advanced Excel, QuickSight, etc.', 'Expert experience in the Hadoop Ecosystem including Apache Spark and Presto', 'Expert experience in NoSQL', 'Expert experience with blockchain technologies like Etherium', 'Expert experience in data Data Lake architecture and administration', 'Experience managing full application stacks from the OS up through custom applications', 'Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker', 'Excellent knowledge of Hadoop architecture, administration and support', 'Experience with NoSQL technologies like DynamoDB, Redis, MongoDB, Cassandra or Riak', 'Prior working experience with AWS - any or all of EC2, S3, EBS, ELB, RDS, Dynamo DB, EMR', 'Expertise with Load Balancing, Iperf, MTR, netcat, and other network monitoring / troubleshooting tools', 'Experience in data visualization tools such as Tableau, PowerBI, Advanced Excel, QuickSight, etc.', 'Familiar with AWS services, preferably Redshift, ElasticSearch, Kinesis, Neptune, Kafka, etc.', 'Expert understanding of distributed computing principles and their application in the cloud', 'Good understanding of distributed computing environments', 'Lead technical discussions on big data systems architecture and design', 'Strong analysis and troubleshooting skills and experience', 'AWS Certified Solutions Architect', 'AWS certified Big Data Specialty', 'Master’s degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position']",2020-08-08 13:06:13
Data Engineer/Big data Engineer-C2C-IL/VA/DE,Vy Systems,N/A,"Alexandria, VA","[""Bachelor's (Preferred)"", 'data engineer: 9 years (Preferred)', 'Possible', 'Temporarily due to COVID-19']",2020-08-08 13:06:13
SQL SERVER DATA ENGINEER,InspiHER Tech,N/A,"Chicago, IL","['Contribute to design and development database solutions', 'Contribute to the technical design including high-level conceptual diagrams, updates to data dictionary, creation of standards', 'Capable of executing/running projects with least amount of guidance', 'Develop database structures that fit into the overall architecture of the systems under development', 'Effectively manage trade-offs among data volumes, number of users logical and physical distribution, response times, retention rules, security and domain controls', 'Code, install, optimize and debug database queries and stored procedures using appropriate tools or editors', 'Proactively monitor database trends and act to improve database systems and processes', 'Identify tactical risks and raise/resolve issues effectively and in a timely manner', '5+ years managing MS SQL database systems', '5+ years OO programming in .Net and deploying Restful API’s', '1+ years developing data driven Cloud and on Prem solutions and integrations preferring AWS', 'Must have Microsoft SQL Server and MS SQL Server Integration Services, T-SQL and Powershell Scripting', 'Must be adept at creating stored procedures, views, user-defined functions, and table functions', 'Proven record on performing near real time data integrations and processing vis: JSON/CSV/XML file/message types', 'Must have Performance tuning SQL queries and strong table design, DML (data manipulation language)', 'Master Degree in Computer Science or equivalent years of experience']",2020-08-08 13:06:13
Data Engineer,KoBold Metals,N/A,Remote,"['Help develop KoBold’s proprietary data system, TerraShed™, and modeling software, Machine Prospector™', 'Design components of the data system to ingest, store, process, and access a large volume and wide variety of geoscience data for both predictive modeling and visualization', 'Integrate diverse and messy geophysical, geochemical, geologic, and geographic data from around the world into a well-structured proprietary database', 'Create tools for ingesting unstructured datasets and extracting key features', 'Work with data scientists to implement and improve algorithms and predictive models', 'Develop interactive visualizations to enable the data team and geoscience teams to rapidly view and interrogate the model results and underlying data', 'Proficiency in Python', 'A technical stack that includes Postgres/PostGIS and Elasticsearch', 'Experience storing and processing diverse datasets in both relational and no-sql architectures', 'Experience with data processing technologies such as Airflow, Spark, and Dask', 'Experience creating/managing large databases and pipelines', 'Experience with setting up and deploying systems on AWS', 'Excited to work on a wide range of problems, and to take on a wide range of responsibilities, learning new tech tools whenever needed', 'Highly intellectually curious and eager to learn from technical experts who aren’t software people', 'Keen not just to build products, but to figure out what product to build to best achieve the business objectives of the company', 'Highly self-motivated and autonomous, able to effectively structure one’s own work, make realistic time estimates, and communicate well as one progresses', 'Comfortable with a fast-changing work environment', 'Careful to get the details right', 'Experience with geospatial databases, analyses, and/or visualizations', 'Experience with Flask or similar web frameworks', 'Experience with planning and implementing information security measures', 'A bachelor’s degree or higher in the physical sciences, engineering, computer science, or mathematics']",2020-08-08 13:06:13
Software Engineer I - Integration,UHS Corporate Office,3 out of 5,"Tredyffrin, PA 19087","['Designs, codes, tests and documents new systems or enhancements to existing systems.', 'Assists in recommending application solutions to meet business need.', 'Participates in meetings with users, vendors, and IS staff to develop/modify system specifications.', 'Supports the implementations of applications and prepares the appropriate documentation.', 'Performs system testing and documentation for all phases of the application development life cycle.', 'Performs Q/A on application functionality.', 'Researches and resolves implementation-related application issues.', 'Adheres to appropriate UHS Project Management standards.', 'Ensures strict adherence to work plans, reporting all serious deviations to management.', 'Assists with the training of users in operating procedures for application.', 'Researches and resolves Customer Support Center Tickets including major application upgrades.', 'Adheres to Service Level and Change Management Policies.', 'Provides on-call support as scheduled.', 'Establishes and maintains regular communications with user community.', 'Provides technical support and guidance to other team members as required.', 'Maintains Service Excellence principles.', 'Prepares and promptly submits all routine and special reports.', 'Contributes to performance evaluation of junior staff members as needed.', 'Keeps management well informed of activities, needs, problems.', 'Reviews and reports progress on an ongoing basis', 'Provides technical advice to staff as required', 'Directs and assists other Software Engineers, when necessary', 'Performs other tasks as required by management.', 'Working knowledge of current database development methodologies.', 'Working knowledge of system application implementation, enhancement and support methods and practices.', 'Comprehensive working knowledge of computer systems analysis and programming techniques and procedures, including consulting with users to determine hardware, software or system functional specifications; design, development, documentation, analysis, creation, testing, coding, debugging, or modification of interfaces or programs based on and related to user design specifications.', 'Working knowledge of development standards and quality methods and metrics.', 'Working knowledge of project management methods.', 'General familiarity of user business practices, concepts and terminology sufficient to support the applications.', 'Experience will include problem solving, creating system and program level documentation, complex database design concepts, knowledge of basic business management concepts.', 'Ability to clearly convey and assimilate information, and prepare detailed specifications and documentation.', 'Position also requires a working knowledge of all aspects of the project development life cycle and the ability to multi-task while effectively managing time and meeting deadlines.', 'Language proficiency in English, with excellent written and verbal fluency.', '3-5 years of experience', 'Cerner Revenue Cycle experience', 'Data warehousing experience', 'Predictive analytics experience', 'Challenging and rewarding work environment', 'Growth and development opportunities within UHS and its subsidiaries', 'Competitive Compensation', 'Excellent Medical, Dental, Vision and Prescription Drug Plan', '401k plan with company match', 'Generous Paid Time Off']",2020-08-08 13:06:13
Data Engineer (Remote),Slync.io,N/A,Remote,"['Design, build and integrate new cutting edge databases and data warehouses, develop new data schemas and figure out new innovative ways of storing, integrating, and representing our data.', 'Research, architect, build and test robust, highly available, and massively scalable systems, software, and services.', 'Contribute to the AI/Machine Learning integration process and platform.', 'Contribute to the core design of data architecture, data models and schemas, and implementation plan.', 'Optimize and execute requests to pull, analyze, interpret, and visualize data.', 'Design and develop a new framework and automation tools to enable teams to consume and understand data faster.', 'Write well-tested, production-ready code.', 'Improve the efficiency, reliability, and latency of our data system.', 'Create automated, highly reliable data pipelines.', 'Test all code written and ensure production readiness before shipping.', 'You have a high sense of urgency to deliver projects as well as troubleshoot and fix data queries/ issues.', 'You are always on the lookout to automate and improve existing data processes for quicker turnaround and high productivity.', 'Will run ETL processes on a large scale sensitive datasets.', 'B.S. or above in Computer Science or a related field with 3+ years of experience in data-driven technology.', 'Experience with building scalable and reliable data pipelines using Big Data engine technologies.', 'Development experience on GCP platform/ tools and/ or alternate cloud platforms like AWS is highly desirable.', '3+ years writing complicated database SQL queries (Oracle, PostgresQL, Hive, etc).', '3+ years of programming experience is necessary; Java experience highly desirable.', 'Working experience in Big data/ Hadoop Ecosystem of Tools (Spark, Hive, Pig, MapReduce).', 'Proficient in data modeling and data warehouse concepts.', 'Experience building/ maintaining data pipelines in a data warehouse, data lake environment preferably on a cloud platform.', 'Experience implementing operational best practices such as monitoring, alerting, metadata management.', 'Experience using ETL or Data Virtualization for scalable data integration.']",2020-08-08 13:06:55
Data Engineer,For The Record,N/A,Remote,"['3-5 years proven experience in software engineering/development, specifically Azure, AWS or other cloud based platforms', 'Experience with 1 or more Javascript languages (Angular, ReactJS, Vue, Node.js)', 'Bachelor’s Degree or equivalent work experience', 'Exceptional interpersonal communication skills. Able to distill complex information into easily understandable materials for users', 'Ability and desire to work as part of a remote team', '2+ years working in a mature agile environment', 'Working knowledge of CI/CD engineering practices', 'Experience working with Application Lifecycle Management']",2020-08-08 13:06:55
Data Engineer,Apple,4.2 out of 5,"Austin, TX","['Minimum 5 years experience within Operations and Supply Chain desired', 'Proven data driven decision making skills', 'Computational analysis using Excel, mySQL, Teradata, Python, Tableau, Business Objects, JMP, R,Matlab, SPSS and SAP preferred.', 'Experience with Teradata, SQL, Tableau preferred', 'Fluency in SQL or other programing languages (Python, Java, and/or C++)', 'Development experience with at least one scripting language (PHP, Perl, Python, etc.)', 'Applied Machine Learning experience (regression analysis, time series, probabilistic models, bayesian statistics)', 'BS/MS/PhD in Data Mining, Statistics, Machine Learning, Computer Science, Operations Research or related field']",2020-08-08 13:06:55
SAP Data Governance (MDG) Engineer,Accenture,4 out of 5,"Phoenix, AZ 85016","['Minimum two years of relevant data management consulting or industry experience', 'Implementation experience and deep knowledge in any of the following three areas (Master Data Management, Data Governance, Data Quality) as well as knowledge of the other two areas', 'Technical experience with one of the SAP Data Management applications, SAP Master Data Governance (MDG), SAP Data Services (BODS), SAP Information Steward, SAP SLT, Smart Data Integration (SDI), or Smart Data Quality (SDQ).', 'Minimum two years delivering complex data management engagements including all phases of the project life cycle from scoping and planning, requirements gathering, design, development, testing, and go live with team sizes ranging from five to twenty resources', 'Willingness to travel to client locations (100%)', 'Implementation experience in all three data management areas: Master Data Management, Data Governance, Data Quality', 'Bachelor’s degree or equivalent work experience']",2020-08-08 13:06:55
Specialist Data Visualization Lead,AmerisourceBergen,3.4 out of 5,"Chesterbrook, PA 19087","['Works on projects that span a broad range of technologies.', 'Has expertise in multiple technical environments and possesses business knowledge that spans multiple business areas.', 'Leads project planning processes.', 'Develops work plans or reviews other work plan timelines and manages workflows to meet project timeframes.', 'Responsible for identifying project tasks in support of project planning and estimation.', 'Contributes to strategic planning meetings and provides guidance and expertise on system options, risk, cost vs. benefits, and impacts on business processes and goals.', 'Works closely with architects to assure all systems are in line with IT long-term strategy.', 'Together with business stakeholders leads the development of business analytics requirements.', 'Brings deep understanding of business data domain and underlying data sources.', 'Leads development of data visualization and semantic data access requirements.', 'Brings expert knowledge of data visualization tools and techniques to drive business analytics and semantic data access requirements.', 'Ensures semantic layer design and implementation satisfy business analytics requirements.', 'Leads development of business analytics insight visualization.', 'Ensures functional and non-functional visualization requirements are met.', 'Leads knowledge transfer around using data visualizations to business stakeholders.', 'Drives business stakeholder adoption of insights-driven decision making and/or business process innovation.', 'Ensures data visualization standards are maintained and implemented.', 'Oversees and assists in testing business analytics solutions.', 'Provides technical leadership, coaching and mentoring to team members.', 'Provides technical guidance or system process expertise.', 'Provides performance feedback to managers.', 'Develops reports and presentations for senior management, as needed.', 'Evaluates new visualization tools and performs research on best practices.', 'Participates in POC projects and provides business analytics solutions recommendations.', 'Conceptualize, design and develop data visualization solutions that synthesize data concepts into clear communications for key business stakeholders.', 'Drive adoption of data and insights-driven business decision making processes and analytics-enabled business process innovation.', 'Collaborate with data engineers and analytics and subject matter experts to identify useful and strategically relevant insights.', 'Demonstrate a strong sense of visual design and interest in creative visualization work.', 'Assist in developing best practices for data presentation and sharing across the organization.', 'Demonstrate an ability to know and understand the audience and the information the audience needs.', 'Demonstrate an ability to reduce data to the bare minimum of what is needed to optimally communicate a message.', 'Demonstrate a drive to learn new tools and new ways of visualizing/displaying data and insights.', 'Work closely with business users, vendors and delivery teams to understand the business requirements that drive the analysis and design of business analytics and reporting solutions.', 'Show strong team building and creative thinking skills, and a desire to “make a difference”.', '8 or more years of experience in developing business analytics solutions, focusing on requirements gathering and effective visualization of insights.', '8 or more years of experience with data visualization/BI tools, such as Qlik or Tableau, SQL and semantic data access mechanisms.', 'Experience in driving analytics-enabled business process innovation and organizational change management.', 'Has a broad level of understanding surrounding business information systems.', 'Experience in leading projects and teams.', 'Demonstrated ability to analyze and interpret complex problems or processes that span multiple business areas, identify and understand requirements and develop alternate solutions.', 'Experience designing, developing and testing business analytics solutions using proven or emerging technologies in a variety of technologies and environments.', 'Thought leadership in applying visualization techniques and User Experience design.', 'Excellent written/oral communication and presentation/interpersonal skills.', 'Healthcare for associates and eligible dependents, same-sex and domestic partners', 'Paid time off, including vacations and holidays', 'Paid volunteer time off', 'Life insurance and disability protection', 'Pet insurance', 'Employee Stock Purchase Program', 'Retirement benefits and more…']",2020-08-08 13:06:55
Senior Data Engineer,iVinci Health,N/A,"Boise, ID 83702","['Design, develop, test and troubleshoot ETL packages', 'Map and load data from source to destination systems', 'Participation in the development and execution of unit and system test plans to ensure data quality meets or exceeds standards and thresholds', 'Story planning, development, and QA as part of our 2-week Agile sprints', 'Thrives on challenges and loves learning', 'Is self-driven, diligent, and enjoys solving problems', 'Wants to be part of a high-growth, high-innovation company that will revolutionize a market', 'Prefers a collaborative environment and is comfortable working with others and giving and receiving feedback', 'BS in Computer Science, Information Systems or related field', 'Min 5 years of significant SQL and Python development experience', 'Hands-on experience developing ETL/data integration solutions', 'Experience working with large and/or complex data sets', 'Excellent analytical, conceptual, troubleshooting, and problem-solving skills', 'Experience working with Azure Databricks', 'Experience working in a secure HIPAA/PHI environment', 'Experience with hospital or financial systems', 'Some programming skills in C#, .NET or PowerShell', 'This position is based in Boise, ID; however, remote candidates will be considered if they have a proven track record of successful remote work and are willing to work a schedule on the MTN time zone.', 'We will only consider applicants who reside within the U.S.', 'Sponsorship is not available for this position.']",2020-08-08 13:06:55
Data Engineer,GSK,4.2 out of 5,"Collegeville, PA 19426","['Partner with data teams to implement pipeline designs to support R&D strategy and conceptual data flows', 'Partner with the metadata leads to translate conceptual data models into physical database/tables optimized for data analytics in RDIP using established environments and tools', 'Assist the design, build, test and maintenance of data acquisition and processing pipelines including but not limited to the creation/maintenance of appropriate artifacts', 'Ensure the preservation of data integrity from source to target state including but not limited to the acquisition of appropriate metadata and the incorporation of appropriate QC checks into the pipelines', 'Support the use and growth of the Data Engineering DataOps environment, influence strategy and roadmap for the curation toolset, work with R&D and Tech to prioritize enhancements', 'Provide Tier 3 support for production pipelines', 'Support DCS and broader R&D in self-service/exploratory efforts', 'Influence vendor roadmaps, work with R&D and Tech to prioritize DataOps enhancements, and onboard these tools or enhancements', 'Ensure the quality consistency and availability of guidance documentation of end users of the tools to support high quality outputs', 'Extend current pipelines to support clinical biomarkers', 'Assess GxP readiness as it related to the upstream data pipelines and develop a plan for addressing any gaps', 'Provide Tier 3 support/administration of DNA Nexus bioinformatics system', 'This position requires a Computer Science, Bioinformatics, or related degree; 5+ years’ experience in data movement, data wrangling and delivery of data or analytics pipelines', 'Experience implementing and maintaining, data or analytic pipelines.', 'Experience with Big Data technologies, Cloud-based offerings (Microsoft Azure, GCP, AWS, etc), and corresponding tools.', 'Experience with open source software, bioinformatics tools and languages such as SQL, R, Perl, Python, Java, and ETL tools.', 'Experience with data movement and management in the Pharmaceutical industry or related scientific fields.', 'Experience with the core components of the Hadoop stack including HDFS and Apache Spark, ideally a Cloudera based stack', 'Background and experience in LIMS systems, Next Generation Sequencing (NGS) workflows, Cloud computing and HPC systems.', 'Understanding of diverse ‘omic data types including RNA-Seq, DNA-Seq, Chip-Seq, WES, WGS, ATAC-seq, microbiome, proteomic, metabolomic data etc. from different sources.', 'Familiarity with data mining, machine learning and artificial intelligence techniques', 'Proven ability to contribute to development projects.', 'Strong interpersonal skills and effective communication of complex concepts to stake holders with wide range of expertise.', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.', 'Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.', 'Continuously looking for opportunities to learn, build skills and share learning.', 'Sustaining energy and well-being.', 'Building strong relationships and collaboration, honest and open conversations.', 'Budgeting and cost-consciousness', 'LI-GSK']",2020-08-08 13:06:55
Data Analyst,IBM,3.9 out of 5,"New York, NY 10002","['Perform analysis and provide actionable insight.', 'Help define strategic goals and supporting KPIs', 'Define and build dashboards and reports for different departments to help monitor KPIs.', 'Perform ongoing analysis to understand user behavior and provide actionable recommendations in different areas of the product', '3 plus years of data analysis experience at a consumer technology company', '3 plus years’ experience performing advanced analytics using structured and unstructured data.', 'Solid conceptual understanding of methods in analytics and data science. Understanding of common roadblocks and technical challenges.', 'Experience with SQL and Python/R.', 'Experience performing product-oriented quantitative analysis, including statistical analysis', 'Ability to execute against defined objectives both tactically and strategically', 'A team player who can collaborate with engineers, designers, and other cross-functional teams', 'Ability to initiate and drive projects to completion with minimal guidance']",2020-08-08 13:06:55
Data Engineer (TS/SCI),IBM,3.9 out of 5,"Washington, DC 20001","['Big Data experience in both structured and unstructured data.', 'Apply methods, techniques & technologies that address data architecture, integration and governance of data', 'Utilize experience in database concepts and data modeling o Integrate data integration including applying methods, techniques & technologies to address design, architecture and the extraction, transformation, movement, storage of data.', 'Work with Master data management, including customer data strategy, product data strategy and organizational hierarchy, and Information (data) Governance including strategy, implementation, business glossary, metadata and industry frameworks', 'Deliver data mapping, detailed data analysis and metadata analysis', 'Provide hands-on business knowledge while working with database developers, DBAs, architects, data quality analysts, and other teams and seamlessly managing client relationships within context of individual role.', 'Utilize skills in VBA, ETL Tools, Cognos, Hadoop or Hadoop based tools as well as other Business Intelligence tools.', 'Apply semantic correlation, ontology and text analytics techniques and systems to analyze nonstructured data and identify critical insights for overall business analytics across various domains.', 'Analyze text, streams, documents, social media, speech and video with emerging Hadoop-based big data, NoSQL, Natural Language Processing (NLP), Search and Text analytics technologies and techniques', 'Utilize skills in Java, C++, Python, or Skala development', 'Big Data', 'Predictive Modeling', 'Machine Learning', 'Active/Current TS/SCI clearance is required to be considered for this position', 'Included but is not limited to design, creation, population, and maintenance of geo-coding, geo-mapping, and entity-relation ontologies.', 'Work modularly to maximize ability to address new visualization needs as data, threats, and relationships change']",2020-08-08 13:06:55
Senior Data Engineer,CVS Health,3.3 out of 5,"New York, NY",[],2020-08-08 13:06:55
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:06:55
Hadoop Engineer,EviCore,3.2 out of 5,"Franklin, TN 37067","['Minimum 2 years of experience with Hadoop/HDP in an enterprise data lake environment', 'Experienced with Java, NiFi, Kafka, HDFS, HAWQ, Shell scripting and performance optimization', 'Full medical, dental, vision, and vision benefits with employer-funded HSA starting day 1', 'Strong work/life balance with 15 days of PTO (starting) per year plus 8 paid holidays', 'Competitive compensation package including base salary, and short and long term incentives depending on role.', 'Education assistance and tuition reimbursement along with ample opportunities for growth', 'Time away from work programs including employer-paid short-term and long-term disability, caregiver leave, BTO (bought-time off) options, company paid volunteer community service hours, and more', 'Onsite fitness facilities, casual dress code- wear your jeans to work, and two comprehensive employee discount programs', 'Health coaching, Employee Assistance Program, resiliency and stress management solutions, Adoption Assistance Program and additional resources to support your well-being', 'Life & Accidental Death Dismemberment and additional Accidental Injury, Critical Illness, and Hospital Care Insurance', '401k retirement plan with a company match of 50% employee contributions up to 6%', 'Monday to Friday', 'Night Shift', 'United States (Required)', 'Overnight (Required)', 'Bonuses', 'One location', 'Fully Remote', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Work from home', 'Flexible schedule', 'Parental leave', 'Relocation assistance', 'Professional development assistance', 'Tuition reimbursement', 'Detail-oriented -- quality and precision-focused', 'Stable -- traditional, stable, strong processes', 'A job for which military experienced candidates are encouraged to apply', 'Open to applicants who do not have a college diploma', 'A job for which people with disabilities are encouraged to apply', 'www.evicore.com/careers', 'Yes']",2020-08-08 13:06:55
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:06:55
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:06:55
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:06:55
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:06:55
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:06:55
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:06:55
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:06:55
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:07:45
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 13:07:45
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:07:45
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:07:45
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:07:45
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:07:45
Data Engineer (TS/SCI),IBM,3.9 out of 5,"Washington, DC 20001","['Big Data experience in both structured and unstructured data.', 'Apply methods, techniques & technologies that address data architecture, integration and governance of data', 'Utilize experience in database concepts and data modeling o Integrate data integration including applying methods, techniques & technologies to address design, architecture and the extraction, transformation, movement, storage of data.', 'Work with Master data management, including customer data strategy, product data strategy and organizational hierarchy, and Information (data) Governance including strategy, implementation, business glossary, metadata and industry frameworks', 'Deliver data mapping, detailed data analysis and metadata analysis', 'Provide hands-on business knowledge while working with database developers, DBAs, architects, data quality analysts, and other teams and seamlessly managing client relationships within context of individual role.', 'Utilize skills in VBA, ETL Tools, Cognos, Hadoop or Hadoop based tools as well as other Business Intelligence tools.', 'Apply semantic correlation, ontology and text analytics techniques and systems to analyze nonstructured data and identify critical insights for overall business analytics across various domains.', 'Analyze text, streams, documents, social media, speech and video with emerging Hadoop-based big data, NoSQL, Natural Language Processing (NLP), Search and Text analytics technologies and techniques', 'Utilize skills in Java, C++, Python, or Skala development', 'Big Data', 'Predictive Modeling', 'Machine Learning', 'Active/Current TS/SCI clearance is required to be considered for this position', 'Included but is not limited to design, creation, population, and maintenance of geo-coding, geo-mapping, and entity-relation ontologies.', 'Work modularly to maximize ability to address new visualization needs as data, threats, and relationships change']",2020-08-08 13:07:45
SAP Data Governance (MDG) Engineer,Accenture,4 out of 5,"Phoenix, AZ 85016","['Minimum two years of relevant data management consulting or industry experience', 'Implementation experience and deep knowledge in any of the following three areas (Master Data Management, Data Governance, Data Quality) as well as knowledge of the other two areas', 'Technical experience with one of the SAP Data Management applications, SAP Master Data Governance (MDG), SAP Data Services (BODS), SAP Information Steward, SAP SLT, Smart Data Integration (SDI), or Smart Data Quality (SDQ).', 'Minimum two years delivering complex data management engagements including all phases of the project life cycle from scoping and planning, requirements gathering, design, development, testing, and go live with team sizes ranging from five to twenty resources', 'Willingness to travel to client locations (100%)', 'Implementation experience in all three data management areas: Master Data Management, Data Governance, Data Quality', 'Bachelor’s degree or equivalent work experience']",2020-08-08 13:07:45
Lead Data Engineer (Remote),Output,3.9 out of 5,Remote,"['Design, develop, and deploy backend data systems with a focus on quality, performance, and reliability', 'Support machine learning, analytics, and marketing user cases', 'Collaborate closely with engineering and product teams, becoming a core member of an autonomous, cross-functional team', 'Work collaboratively with stakeholders to understand business requirements, connect these to possible solutions, and deliver successful engineering outcomes', 'Advise stakeholders on best practices and opportunities for improvement in Output’s data technology operations', 'Work in an environment that supports your individual growth', 'Dedication to industry-standard engineering processes for reliability and long-term quality', 'Experience with data warehouse technologies such as BigQuery, Snowflake, or Redshift', 'Experience with data processing services, ETL, and API integration', 'Experience deploying data processing pipelines in Python', 'Familiarity with machine learning techniques for data analysis and prediction a plus', 'Strong communication skills with a focus on cross-disciplinary collaboration', 'Fluency in SQL', 'Experience with Facebook and Google ad platforms a plus', 'Experience with business intelligence tools such as Looker a plus', 'You have errors in applying']",2020-08-08 13:07:45
"Forward Deployed Software Engineer, Internship",Palantir Technologies,4.3 out of 5,"Washington, DC 20007","['Dedication: We see projects through from beginning to end in spite of obstacles we may encounter.', 'Collaboration: We work internally with people from a variety of backgrounds — such as other FDSEs, product teams, and Deployment Strategists. We also work externally with our customers, often on site, to understand and solve their problems.', ""Trust: We trust each other to effectively manage time and priorities—we don't micromanage. We want to give people the space to think for themselves."", 'Core Palantir products, which provide the foundations for our deployments', 'Custom applications built on top of core Palantir platforms', 'Postgres, Cassandra, Hadoop, and Spark for distributed data storage and parallel computing', 'Java and Groovy for our back-end applications and data integration tools', 'Typescript, React, Leaflet, and d3 for our web technologies', 'Python for data processing and analysis', 'Palantir cloud infrastructure based on AWS EC2 and S3', 'Strong engineering background in fields such as Computer Science, Mathematics, Software Engineering, and Physics.', 'Familiarity with data structures, storage systems, cloud infrastructure, front-end frameworks, and other technical tools.', 'Strong coding skills with demonstrated proficiency in programming languages, such as Java, C++, Python, JavaScript, or similar languages.', 'Ability to collaborate and empathize with a variety of individuals. You can iterate with users and non-technical stakeholders and understand how your technical decisions impact them.', 'Demonstrated ability to learn and work independently and make decisions with minimal supervision.', 'Must be planning on graduating in 2022. This should be your final internship before graduating.', 'An updated resume / CV', 'Thoughtful responses to our application questions', 'In an effort to build more transparency into our recruitment process, we’d like to share our offer deadline expectations. By applying to this position, you commit to confirming your decision within three weeks of receiving your written offer']",2020-08-08 13:07:45
Pricing Data Engineer,Best Buy,3.9 out of 5,"Richfield, MN 55423","['Develop analytics and pricing platforms, including data warehouses, data models, and scheduled processes.', 'Structure data to support modeling, analytics, and reporting for pricing', 'Architect solutions that are robust, scalable and maintainable. Participate in technical design and code reviews', 'Understand and identify downstream impacts of changes within complex systems', 'Create process maps to show how data flows across systems', 'Design, execute, and document the results of user acceptance testing', 'Consult and advise on best practices for development and technology adoption', 'Collect, catalog, and develop Pricing reference documents and deliver training to analysts', 'Manage technology projects performed by internal and external resources. Write specifications, resolve ambiguities, and track progress.', 'Foster a strong collaboration with the IT and Pricing teams.', 'Drive project outcomes while maintaining time, scope, resources, and quality.', 'Maintain ongoing internal customer relationships with project sponsors, business, and IT project leaders, project team members and key vendor contacts.', 'Facilitate resolution of project issues impacting the projects', 'Perform pricing analytics', 'Serve as a subject matter expert on Best Buy’s Pricing data', 'Identify data gaps and inconsistencies. Troubleshoot unexplainable phenomena in the data. Propose, price, evaluate, and recommend options to remedy data discrepancies', 'Identify, manage, investigate, and resolve data quality issues. Ensure uniqueness, integrity, consistency, completeness, and actionability in the data', ""7 or more years' experience in a data engineering, data steward, analytics or statistics focused role working to include data manipulation, data structures and/or data modeling"", ""4 or more years' experience in writing SQL"", ""3 or more years' experience in project management"", ""2 or more years' experience in managing and leading the work of third parties"", ""3 or more years' experience with any of these: Teradata, Oracle, Netezza, Informatica, Hadoop, and data modeling"", ""2 or more years' experience in Spark, Python or R"", ""2 or more years' experience working in Google Cloud Platform, Microsoft Azure, or AWS""]",2020-08-08 13:07:45
Data Center Engineer I,"JPMorgan Chase Bank, N.A.",3.9 out of 5,"Totowa, NJ","['Ability to identify problems and clearly communicate strategic solutions to clients', 'Desire to develop a working knowledge of change management, corporate IT audit processes, IT risk management, technical problem resolution, operations systems, and data sources knowledge', 'Strong initiative and desire to learn', 'Ability to effectively collaborate with team members and clients to achieve common goals', 'Good knowledge of Windows/MAC OS with the ability to carry out root cause analysis', 'Working knowledge of Microsoft Office products', 'Strong analytical and problem resolution skills', 'Understanding of information technology concepts in a working or academic environment', 'General knowledge of a physical IT infrastructure (server, networking, storage', 'Some understanding of network concepts (switching, routing, perimeter security)', 'Some understanding of operating systems (Windows, Linux, AIX)']",2020-08-08 13:07:45
Senior Data Engineer,silicon tech solutions,N/A,"Wilmington, DE",[],2020-08-08 13:07:45
Data Engineer,KBR,4.1 out of 5,"Point Mugu, CA","['Well-rounded skills in data science: computer programming (e.g., Python, R), data structures (e.g., SQL, Hadoop), statistics (e.g., Bayesian modelling), data visualization (e.g., Tableau), modeling and simulation are required.', 'One-year experience developing applications using Big Data databases (e.g., Accumulo, HBase, MongoDB, Cassandra).', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience with installation, configuration and usage of some of the following: Hadoop, Cloudera, Hortonworks, Apache Storm, Apache Spark, HBase, YARN, Kafka, Storm, map-reduce, big-data analytics, semantic-web (RDF, OWL), and graph-databases.', 'Must be prepared to learn new business processes or application nuances.', 'Strong background in working with relational database management systems (e.g., SQL, Postgres, NoSQL) as well as file-based systems (e.g., Hadoop).', 'Working knowledge of message queuing, stream processing and extracting value from large disconnected datasets.', 'Experience with working in teams in the data science industry is preferred.', 'The Data Engineer must have the ability to work closely with data scientists to develop and subsequently implement the best technical design and approach for new analytical products.', 'Ability to problem solve, debug, and troubleshoot while under pressure and time constraints is required.', 'Working knowledge in statistical data analytics, machine learning, open source and proprietary tools and applications. Must have an excellent knowledge of advanced methods, and experience in applying those methods to solve problems.', 'Ability to communicate effectively about technical topics to both experts and non-experts at both the management and technical level is required.', 'Excellent interpersonal skills, oral and written communication skills, and strong personal motivation are preferred.', 'Knowledge of software design patterns and Agile Development methodologies is required.', 'Ability to work independently and provide appropriate recommendations for optimal design, analysis, and development.', 'Excellent written and verbal communications skills are required, as the Data Engineer will be in frequent contact with the project technical lead, be taking direction from various government leads, and will frequently be interacting with end users to gather requirements and implement solutions while away from other team members.', 'Ability to teach and mentor engineers with a variety of skill levels and backgrounds is a plus.', 'Strong analytical skills related to working with both structured and unstructured datasets.', 'Excellent programming, testing, debugging, and problem-solving skills.', 'Experience designing, building, and maintaining both new and existing data systems and solutions', 'Understanding of ETL processes, how they function and experience implementing ETL processes required.']",2020-08-08 13:07:45
Big Data Analytics Engineer,"FYI-For Your Information, Inc.",N/A,"Rockville, MD 20850","['Opportunity to work remotely (per contract requirements).', 'A knowledgeable, high-achieving, experienced and fun team.', 'A diverse work atmosphere.', 'The chance to be part of a rapidly growing company and the next success story.', 'Team building and innovation.', 'A competitive base salary with a loaded benefits package plus 401K.', 'Personal computer device allowance.', 'Pet Insurance.', 'Required: 5+ years IT experience', 'Required: Bachelors of Science. Graduate level degrees in Mathematics/ Statistics highly preferred', 'Required: Programming - Java / C++ / Scala/ Python', 'Required: Experience with Hadoop / Map-Reduce and/or HIVE', 'Required: SQL Development', 'Required: Unix / Shell scripting', 'Required: Designing distributed solutions for parallel processing of large data', 'Required: Full SDLC Experience (requirements analysis, design, development, unit testing, deployment, support)', 'Required: Good communication skills', 'Preferred: Big-Data technologies, Cloud Computing', 'Preferred: Test driven development', 'Preferred: Understanding NASDAQ/ Capital Markets/ Market Structures']",2020-08-08 13:07:45
Data Engineer,Benefits Data Trust,3.3 out of 5,"Philadelphia, PA 19102","['Build out our new GCP data platform and collaborate on architectural patterns for it with the Data Engineering team', 'Support the development of machine learning models with productionizing, monitoring and alerting tools', 'Write, update, and maintain ETL jobs across our data pipelines (mostly in Airflow)', 'Implement continuous improvements using our existing tools/technologies, which include SQL, Airflow, Python, Docker/Kubernetes, and others such as Terraform and Apache Beam. May also be expected to research and select other tools when the situation demands', 'Collaborate with internal customers to identify ongoing platform improvements (teams including Analytics, Projects, Policy, Software Engineering, and others throughout the organization)', ""Consult to software engineers on data-related changes to BDT's suite of software applications, including schema/model design, table structure, and data collection"", 'Engage with colleagues and collaborators using curiosity, critical thinking, a drive to completion, empathy, and a focus on impact', 'Follow existing data access and performance design standards for the data platform, software engineering, and all products and services accessing BDT information', 'Communication and Relationship-building – with technical peers and some stakeholders', 'Cloud-based Solution Implementation, of data platforms and infrastructure, including event-driven architectures, microservices and pattern design, supporting compliance and regulated environments (including PII and PHI)', 'Workflow and pipeline development to ensure reliability, availability, and consistency', 'Systems Engineering – on-system service management, typically in *nix environments', 'Data Modeling and Warehousing – proficient understanding of relational data structures and schemas; some familiarity with semi-structured, unstructured (big data) schemas', 'Automation, monitoring, and alerting – creating these tools based on existing designs and frameworks; resolving bugs and issues', 'Cloud engineering – working towards certification on any of the major hyperscale cloud platforms', 'Data Encapsulation & Transfer methodologies – understands standards for file formats and transfer methods', 'Also interested in relevant experience including:', 'o Experience with BI implementations/uplifts (we currently use Looker) and/or Data Governance models and methods', 'o Machine learning techniques, productionizing machine learning models, and/or creating models']",2020-08-08 13:07:45
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:07:45
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:07:45
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:07:45
AWS Data Engineer,IXIS,N/A,"Burlington, VT 05401","['Build enterprise-grade batch and real-time data processing pipelines leveraging the AWS cloud platform, with an emphasis on serverless architectures', 'Work with the Data Science and Development teams to design, implement, and facilitate data ingest, extraction, and integration across multiple programming languages (primarily R, Python, and node.js) directly and via REST and GraphQL APIs', 'Work with our Data Science and Development teams to facilitate automated data analysis, reporting, and dashboarding solutions in support of client deliverables and licensed SaaS products', 'Design and implement automated acceptance and reliability tests based on business requirements and company standards', 'Design robust, appropriately normalized schemas for warehousing a wide variety of datasets and determine when SQL vs. NoSQL solutions are preferred', 'Collaborate with technical, development, QA, and operational resources', 'Leverage traditional and container orchestration technologies to operate data systems', 'Leverage shell scripting and Linux system operation skills to assist in the maintenance of and migration from legacy systems', 'B.A./B.S. in Computer Science, Software Engineering, or related area; formal training in statistics/mathematics/machine learning a plus', '1-3 years’ professional experience building resilient, scalable, and performant data warehousing solutions using AWS; CI/CD experience a plus', '1-3 years’ real-world experience with ETL workflows and SQL', 'Intermediate or better skills with one or more high-level/scripting programming languages', 'Intermediate to advanced shell scripting skills', 'Proficient in Linux system operation', 'Advanced relational database design skills', 'Advanced Excel skills', 'Experience working with data “in the wild”', 'Experience with record linkage, consolidation and householding in relational databases', 'Core critical thinking skills, including good data intuition', 'Experience multitasking and prioritizing data initiatives with minimal guidance and instruction at times', 'Experience with statistical programming, ideally in R or Python', 'Experience with Docker containerization and orchestration', 'Experience developing and working with APIs for data transfer', 'Development experience in a Linux or Mac environment']",2020-08-08 13:08:35
Data Engineer,Logistics Management Institute,3.9 out of 5,"Tysons, VA","['Design, develop, test and manage the overall data architecture.', 'Develop, construct, test and maintain relational and non-relational databases.', 'Build data pipelines to curate and collect the data from a variety of traditional and non-traditional sources: extract data from sources, transform and integrate data in line with existing data, and load data into data stores for access by others.', 'Process, clean, and verify the integrity, accuracy, completeness, and uniformity of data.', 'Assess the effectiveness and accuracy of new data sources and data gathering techniques.', 'Perform data system operations associated with data acquisition, data maintenance, maintaining and updating metadata, and other data and information services for stakeholders.', 'Build data and analytics tools that will offer deeper insight into the pipeline, allowing for critical discoveries surrounding key performance indicators and customer activity.', 'Collaborate with systems architects, data scientists, and analysts to direct and optimize the flow of data within the pipeline and ensure consistency of data delivery and utilization across multiple projects.', 'Give recommendations and implement ways to improve data reliability, efficiency, and quality: evaluate, compare and improve the different approaches including design patterns innovation, data lifecycle design, data ontology alignment, annotated datasets, and elastic search approaches.', 'Document all processes, models and activities.', ""Bachelor's Degree or higher in Computer Science, Information Technology, or software development-related field from an accredited institution. Additional 5 years of experience can be substituted for the bachelor's degree requirement."", '5 Years or higher in experience.', 'Data, storage, and compute tools on AWS, such as EC2, RDS, Redshift, and Glue.', 'Know basics of algorithms and data structures, distributed computing, and stream-processing solutions, including Spark.', 'Advanced SQL knowledge and experience working with relational databases, as well as working familiarity with a variety of databases (e.g., NoSQL, graph).', 'Experience building and optimizing data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Knowledge of ETL tools, data APIs, data modeling, and data warehousing solutions.', 'R, Python, Ruby, C++, Perl, Java, SAS, SPSS, and Matlab.', 'Experience writing server-side APIs and using client-side APIs', 'Demonstrated ability to work with enterprises to develop processes that support data transformation, data structures, metadata, dependency and workload management.', 'Comfort working in a dynamic environment with several ongoing concurrent projects; able to multitask, prioritize, and manage time effectively.', 'Creative problem solver who thrives when presented with a challenge; able to analyze problems and strategize for better solutions; strong problem-solving skills with an emphasis on production for re-use.']",2020-08-08 13:08:35
Principal Data Engineer,Inflection,4 out of 5,Remote,[],2020-08-08 13:08:35
Data Engineer,DataDog,3.4 out of 5,"New York, NY","['Collect data from a wide range of sources: AWS S3, Redshift, PostgreSQL, and various APIs', 'Build data ETL pipelines using Spark, Luigi and other open-source technologies, with programming languages like Scala, Python, and SQL', 'Tune Spark jobs to improve performance', 'Work closely with product managers, designers, and engineers in order to collect the right data that will help them better understand our customers, product usage, or our own operations', 'Work with Data Analysts to build the right analytics reports', 'Have a meaningful impact on many teams at Datadog thanks to data', 'Join a tightly knit team solving hard problems the right way', 'Grow with the company', 'You are fluent in several programming languages such as Python, R, or Scala', 'You have 2+ years of work experience in building ETL pipelines in production', 'You value code simplicity and performance', 'You have work experience with data storage such as AWS S3, Redshift or similar.', 'Being a SQL expert is a minimum for this position', 'You are fluent with command line', 'You enjoy wrangling huge amounts of data and exploring new data sets', 'You have a natural curiosity and investigative mindset - driven to know “why”.', 'You can explain complex datasets in very clear ways', 'You want to work in a fast, high-growth startup environment and thrive on autonomy', 'You are familiar with Spark and/or Hadoop', 'Experience with AWS Redshift and S3']",2020-08-08 13:08:35
Data Engineer,IPPON Technologies USA,N/A,"New York, NY 10022","['Batch processing for historical data (e.g. Hadoop, Spark)', 'Streaming processing for near-real time analysis (e.g. Kafka, Flink)', 'Machine Learning for classification, prediction, root-cause-analysis, etc. (e.g. Sci-Kit Learn, Keras, Tensorflow)', 'Design and implement Data Architectures', 'Create and optimize data pipelines', 'Enhance real-time data processing', 'Work with Data Scientists and Data Owners to understand use cases and hypothesis to test with the data', 'Build complete data platforms by assembling major Big Data solutions such as: EMR, Kafka, Spark, Airflow, Flink, Snowflake, Elasticsearch, etc.', 'Scala / Java / Python coding', ""Bachelor's degree in Computer Science or a related field"", 'At least three (3+) years of software development experience', 'Data Streaming techniques: Apache Kafka, Amazon Kinesis, Flink, Spark Streaming, etc.', 'Experience with AWS technologies: DynamoDB, Glue, Athena, Redshift, Kinesis, EMR…', 'Cloud Certifications (AWS/AZURE/GCP): Solution Architect Associate or Pro, Big Data Specialty', 'Good knowledge of NoSQL solutions, must be able to recommend the best fit for NoSQL solutions (MongoDB and/or Cassandra is a plus)', 'Snowflake experience desirable', 'CI/CD', 'Agile development', 'ETL / ELT tool experience', 'Judo optional', 'Must love croissants', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Referral Program', 'Retirement Plan', 'Vision Insurance', 'Monday to Friday', 'AWS: 1 year (Preferred)', 'Data Engineering: 2 years (Required)', 'Data Streaming: 2 years (Required)', 'Scala, Java, or Python coding: 1 year (Preferred)', 'New York, NY 10022 (Required)', 'Bonuses', 'One location', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'People-oriented -- supportive and fairness-focused', 'https://blog.ippon.tech/', 'Temporarily due to COVID-19']",2020-08-08 13:08:35
Android Engineer,Spotify,4.3 out of 5,"New York, NY 10011","['Collaborate with a small, autonomous team of engineers, designers, and product managers to find end-to-end solutions to important problems', 'Implement these solutions for our Android client, adhering to Android development best practices', 'Help your team solve problems in a way that makes sense for Android users and our codebase', 'Work with a functional reactive framework for managing state evolution and side-effects, with add-ons for connecting to Android UIs and RxJava Observables (Mobius)', 'Join dozens of other developers and help to shape the direction of Android development at Spotify', 'Flexibility to work from home/remotely for the remainder of the year', 'You have a deep understanding of modern Android development', 'You know how to write readable, maintainable, performant object-oriented Java. Experience in Kotlin is a plus.', 'You are experienced with Android development tools', 'You care about quality and you know what it means to ship high quality code', 'You have 4+ years of experience', 'Having iOS or backend experience is a plus!']",2020-08-08 13:08:35
Data Scientist - Climate Analytics,McKinsey & Company,4.3 out of 5,"Denver, CO 80202","['Graduate degree (PhD/postdoc highly preferred) in atmospheric science, meteorology, climate/earth systems science, hydrology, civil/environmental engineering, astrophysics, or similar fields', 'Required modeling experience: experience working with climate models (i.e. CMIP5 GCMs, RCMs, etc.), ensemble analysis, uncertainty quantification', 'Preferred modeling experience: flood/hydrological modeling, bias correction/downscaling methods, climate impact assessments', 'Knowledge of climate risk assessment, extreme events analysis required', 'Ability to work with large, multi-dimensional data (e.g. netCDF, GRIB, TIFF files)', 'Python knowledge required (experience with xarray and knowledge of basic software engineering principles highly preferred)', 'Experience working with Linux and command line scripting (i.e. bash, zsh), and familiarity with cloud computing environments highly preferred', 'Self-management skills and ability to work as part of an agile team', 'Strong multitasking and parallel development abilities', 'Strong analytical and problem-solving skills paired with the ability to develop creative and efficient solutions', 'Strong interpersonal communication skills', 'Able to work under competing, quickly-changing priorities, manage expectations effectively and support the team under pressure', 'Willingness to travel up to 50% (will likely travel 20-40%) (after current McKinsey travel restrictions due to COVID-19 are lifted; all work is currently remote)']",2020-08-08 13:08:35
Data Engineer (Remote),PlayQ,N/A,California,"['Build and manage efficient and reliable real-time data pipelines from disparate data sources', 'Design, develop and launch data ingestion and storage systems with high availability and reliability that can scale', 'Drive the advancement of data infrastructure by developing and implementing underlying logic and structure for how data is set up, cleaned and stored', 'Take an integral role in designing and implementing a data lake strategy', 'Build and manage a universal semantic layer over the data lake', 'Architect, launch and manage automated extraction & transformation processes', 'Build scalable data aggregation layer from queues and batches of data for data visualization', 'Collaborate with development teams on design, architecture, and expansion of infrastructure', 'BS from an accredited university in Computer Science, Engineering, Math or related field', '4-5 years of experience in building data pipelines, data architecture, data modeling & data governance', 'Proficient working with SQL/NoSQL databases and MPP/columnar data warehouse solutions (Redshift, BigQuery, Snowflake etc.)', 'Experience with AWS environments: Redshift, EC2, Data Pipeline, S3, RDS, Glue, Spectrum, Dynamodb, Lambda', 'Proficient working with Python, bash or other scripting languages', 'Must have experience working with large data sets', 'Experience working in the mobile gaming industry', 'Competitive compensation and equity options', 'Comprehensive medical, dental, vision, life and long term disability insurance', 'Flexible time off', '401K plan with company match', 'Stocked kitchen with free snacks and beverages of your choice', 'Catered weekly team lunches', 'Brand new penthouse office space equipped with outdoor patios offering beachfront views', 'Monthly team outings and volunteer opportunities', ""Help build and support awesome GAMES. For a living! Who doesn't love games?""]",2020-08-08 13:08:35
Data Engineer,Rogers Behavioral Health,3.1 out of 5,"Oconomowoc, WI","['Combined and clean data from multiple different systems.Prepare data for prescriptive and predictive modeling', 'Develop, construct, test and maintain data architectures.Ensure architecture will support the requirements of the organization.Identify valuable data sources and automate collection processes.', 'Develop data set processes for data modeling, mining and production.Increasing data accessibility and fostering data-driven decision making across the organization.Implements processes and systems to monitor data quality, ensuring data is always accurate and available for individuals and processes that depend on it.', 'Propose solutions and strategies to business challenges.Recommend ways to improve data reliability, efficiency and quality.Engage in independent research as well as provide recommendations and implementation of new processes and solutions to efficiently support the department goals.Discover opportunities for data acquisition.', 'Demonstrates mastery with Rogers Outcomes Assessment System (ROAS) and relevant Cerner applications.Assisting with customer support to both employees and patients utilizing ROAS.Independently engages in learning opportunities and certifications to enhance knowledge of the usage, function and technical build of assigned solutions or solution family.', 'Protects subject confidentiality by:Exercising safe data practices.Protecting patient privacy during follow-up data collection.Securing safe storage of patient-sensitive documents.Assuring appropriate disposal of sensitive documents.', 'When assigned, participate in hospital, committees, performance improvement team meetings and team projects, as directed by:Demonstrating punctuality and preparedness.Demonstrating effective communication skills and good organizational skills.Contributing in a positive, solution-focused manner.', ""When assigned, participate in events or projects with the Rogers Operating System (ROS) by:Gaining understanding of the Rogers Improvement System (ROS).Applying continuous improvement initiatives to your department's activities.Participating and/or creating RIS events that lead to improvement in other Hospital areas.Educating and involving self in the system and department's continuous improvement plans."", 'Promote department goals and mission of the Hospital:Communicate goals to fellow staff workers.Demonstrate measurable goal achievement.Maintain department policies and procedures.Include requirements and guidelines from external agencies (i.e., Joint Commission, State of Wisconsin).Educate new staff to regulations or requirements of those functions that relate to their areas or departments, as directed.Demonstrate acceptance and training of student interns in the department, as directed.', 'Demonstrate understanding of quality initiatives:Involve self in the learning and application of standards relevant to the Clinical Effectiveness department.Participate in inservices/seminars and other meetings to increase involvement and awareness of quality initiatives.Involve self in the education of other disciplines regarding respective quality initiatives.Engage in independent research to provide recommendations and develop solutions related to department projects.', 'Strong interpersonal skills needed, due to interaction with professional staff and patients.', 'Must be able to work independently and complete assignments within specified timeframes.', 'Must be highly proficient in verbal and written communication skills.', 'Position requires walking, sitting and standing. Lifting is moderate; must be capable of lifting a minimum of twenty (20) pounds. Reaching, handling, grasping and manual dexterity are necessary to operate various office equipment. Stooping, bending, kneeling and flexible movements required to work with orientation equipment.', 'Verbal and hearing ability required to interact with patients and employees. Numerical ability required to maintain records and operate computer.', 'Be able to plan, control and direct all aspects of employee relations. Tact required to deal effectively with staff. Logical thinking and discretion required to make decisions in initiating and implementing policies and procedures and standards.', 'Must be able to read and communicate through written, verbal and auditory skills and abilities.', 'Be physically/mentally able to perform job duties as verified by a physical exam by a licensed physician, per post-employment physical.', 'Masters degree in computer science or related field required.', 'Medical or mental health research experience preferred.', 'Requires working at a highly technical, analytical and detail-oriented level.', 'Exceptional problem-solving skills with an emphasis on product development.', 'Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.', 'Experience working with and creating data architectures and data pipelines.', 'Technical expertise with data models, data mining, and segmentation techniques.', 'Knowledge of advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.', 'Excellent written and verbal communication skills for coordinating across teams.', 'Experience with Microsoft applications including MS Forms, Power Automate and PowerBI.']",2020-08-08 13:08:35
Data Engineer,INTURN,N/A,"New York, NY 10011","['Strong CS skills with 3+ years in professional data-oriented engineering experience.', 'Expert in at least of one or more of the following languages PHP/Ruby/Python/Java', 'Proven SQL and scripting skills.', 'Experience with AWS, EC2, Linux command-line.', 'Willingness to learn and try to technologies', 'Experience with non-relational and/or column-oriented data stores', 'Comfort working with large data sets.', 'Familiarity with Amazon Web Services (AWS)', 'Love data! Charting, recording, exploring, and finding the underlying causes', 'BA in Computer Science or related field', 'Experience with CSS Preprocessors (SaSS or less)', 'Familiarity with R', 'Previous startup experience', 'Benefits include Premium health benefits (including health,vision, dental), competitive salaries, equity, and a chance to do cutting-edge work with a great team']",2020-08-08 13:08:35
Data Engineer,MINT dentistry,3.3 out of 5,"Dallas, TX 75206","['Job', 'Company', 'AWS data service expert – S3, RDS, QuickSight, Lambda', 'MySQL expert – SQL and Container/Service management', 'Scripting expert (various languages)', 'Software Development experience', 'Excellent Verbal and Written communicator', 'Adept at working in project teams or individually', 'Information Security and encryption understanding', 'Expert documentation skills', 'IT Project management', 'Self-Starter and Self-Manager', 'Bachelors or Masters degree in Computer Science or related field required', '5+ years’ related professional experience required', 'Proven and successful expertise with large-scale projects', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Data Science / Data Analysis: 4 years (Required)', ""Bachelor's (Required)"", 'mintdentistry.com', 'No']",2020-08-08 13:08:35
Data Engineer,Vydia,N/A,"Holmdel, NJ 07733","['Ensuring the availability and timely delivery of data, company-wide', 'Modeling new data sets and crafting all new ELT workflows and pipelines', 'Lead the orchestration of the workflows and contribute strongly to infrastructure decisions', 'Improving on and monitoring of existing pipelines and oversight of our ELT workflow', 'Maintaining a single version of truth for our data and working with others to implement continuous integration (CI) data quality tests', 'Mentoring and guiding your junior colleagues and leading with vision, and with respect to the company’s data strategy', 'You are a Python pro and have regularly used AWS or Google Cloud Platform to manage data and move it between applications', 'Do you love APIs? When you encounter a new one, do you study it inside and out and learn every corner of it, as though you designed it yourself?', 'Working with deeply-nested, complex JSON is a fun day at the office for you.', 'You can articulate the merits and pitfalls of the different approaches in designing a pipeline.', 'You are passionate about data quality control and know how and where to anticipate potential errors.', 'Working “in the cloud” is not a point of distinction for you, it is a given.', 'You understand what it means to work at a tech startup. Hopefully, this is what excites you more than anything else about working here.', 'You intuitively know how to extract value and insights from data.', 'You love the idea of building the data scene in NJ and being a leader in this community.', 'You have orchestrated workflows using Airflow and are familiar with the challenges and how to overcome them.']",2020-08-08 13:08:35
Production Engineer,BASF Corporation,4.1 out of 5,"Newport, DE 19804","['Job', 'Company', ""Support and adhere to the principles of the American Chemistry Council's Responsible Care® by protecting the environment, health, safety and security of our employees, contractors, carriers, distributors, visitors, customers and neighbors. Be knowledgeable of and follow all Environmental, Health and Safety practices including but not limited to: manage waste movements according to satellite and/or 90-day accumulation requirements, inspect air contaminant sources and institute corrective action for out-of-spec conditions, prevent releases into the sewer and/or stormwater systems by following BMPs (best management practices), activate BASF emergency response procedures in case of spills or other emergencies. Comply with the requirements of the ISO9001:2015 Quality Management System."", 'Review, monitor, develop, modify and maintain manufacturing processes and their control systems to maximize contribution to profitability. Utilize lean manufacturing tools where appropriate. Design data collection plans, lead plant trials, analyze data, and implement improvements. Lead or participate in teams in support of optimizing plant processes for quality, cost, reliability, and productivity.', 'Represent manufacturing, coordinating new product introductions, process optimization projects, and process and product changes using a cross- functional team approach that ensures all aspects of the product and process changes have been addressed. Identify, evaluate, and make recommendations regarding new process technologies.', 'Monitor and help establish the performance standards for the manufacturing process and the systems which control them. Maintain process databases and provide timely and routine feedback to those responsible for the performance.', 'Troubleshoot system and process problems in collaboration with other production engineers, process support engineers and others to ensure that all aspects of the manufacturing process, process control system and equipment operation are managed effectively. This may also include management of small capital projects to support asset effectiveness and production needs.', 'Support existing automation systems (hardware and software) by: process and automation changes required by operations; when scheduled, provide 24 hr. on-call technical support for troubleshooting process and control system problems, recommend and implement control system hardware and software upgrades as necessary.', 'Provide support to the site to ensure all ISO, PSM and other regulatory, external and internal, requirements are met. This includes, but is not limited to: coordinating and leading PHAs, managing/supporting the Change Manager and AIM reporting tools, investigating incidents, driving/coordinating closure of action items.', 'Degree in Chemical Engineering, Industrial Engineering or Chemistry.', 'Working knowledge of chemical processes both batch and continuous operations.', 'Functional computer skills (Microsoft Office, SAP).', 'Minimum 3 years technical experience in the Chemical industry.', 'Familiarity developing Standard Operating Procedures.', 'Understanding of advanced process automation systems.', 'Must be able to work independently, possess excellent written and verbal communication skills and serving as a member or interfacing with multi-disciplinary teams.', 'Strong analytical skills and demonstrated success in implementing Operational Excellence improvement tools such as Six Sigma, SPC, etc. in a manufacturing environment.', 'Strong interpersonal skills and the ability to interact effectively with all levels of personnel in a matrix organization.', 'Root cause analysis and problem solving.', 'Planning and prioritizing effectively to meet deadlines.', 'Taking initiatives; being open to new ideas.', 'Do you have working knowledge of technical computer skills such as ASPEN, OSI PI and CAD? Great!', '5 to 10 years technical experience in the Chemical industry is a plus.', 'Working knowledge of OSHA Process Safety Management (PSM) Requirements preferred.', 'Programming, developing and maintaining the software of process automation systems preferred.']",2020-08-08 13:08:35
Sr. Data Engineer,Centerfield,3 out of 5,"Los Angeles, CA","['Help to implement maintenance strategy for all datasets', 'Work with relevant stakeholders to deliver appropriate BI, data warehousing, reporting, and analytical infrastructure required to support Centerfield’s assets', 'Own problems from end-to-end, so that you can best collect, extract, and clean the data', '5+ years working in a Data Engineer, BI Engineer, or Data Warehousing Engineer role', 'Strong experience with any ETL tool like Talend or SSIS or Informatica, etc.', 'Experience with Google Big Query, Google Analytics', 'Ability to lead projects individually and deliver them on time', 'Strong experience in performance tuning techniques', 'Experience with real-time streaming implementation and architecture', 'Experience building reports and with data visualization with any BI tools like Tableau, Power BI, etc.', 'Strong foundation in SQL coding and experience with ETL processes', 'ETL tools like Talend or SSIS or Informatica, etc.', 'BI tools like Tableau, PowerBI, or Microstrategy etc.', 'Experience with NoSQL databases like MongoDB, DynamoDB, Druid, etc.', 'Amazon Web Services (S3, SQS, Redshift, DocumentDB, etc.)', 'Experience with Python', 'Competitive salary + quarterly bonus', 'Unlimited PTO – take a break when you need it!', 'Industry leading medical, dental, and vision plans + generous parental leave', '401(k) company match plan – fully vested day 1', 'Outside patio overlooking Playa Vista + cabanas, fire pits, & working grills', 'Monthly happy hours, catered lunches + daily food trucks', 'Award winning culture & unprecedented team spirit (featured in LA Business Journal & Built In LA)', 'Fully stocked break rooms with drinks & snacks', 'Break room fully stocked with games, workout equipment + weekly in-office exercise classes (yoga, kickboxing, & circuit training', 'Free onsite gym + locker rooms', 'Paid charity and volunteer days (local mentor programs, adopt a pet, beach cleanup, etc.)', 'Monthly team outings (ball games, casino night, hikes, etc.)', 'Career growth – we enjoy promoting from within!']",2020-08-08 13:08:35
Senior Software Engineer - Big Data Analytics,Proofpoint,3.9 out of 5,"Boston, MA 02108","['Job', 'Company']",2020-08-08 13:08:35
Entry Level Federal Associate Data Science,IBM,3.9 out of 5,"Washington, DC 20001","['Implement and validate predictive and prescriptive models, create and maintain statistical models with a focus on big data', 'Incorporate a variety of statistical and machine learning techniques in your projects', 'Write programs to cleanse and integrate data in an efficient and reusable manner', 'Use leading edge and open-source tools such as Python or R combined with IBM tools and our AI application suites', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors', 'Communicate with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions', 'Evaluate modelling results and communicate the results to technical and non-technical audiences', 'Ability to look at things differently, debug, troubleshoot, design and implement solutions to complex technical issues', 'Strong technical and analytical abilities, a knack for driving impact and growth', 'Basic understanding of statistical programming in a language such as R, Python, SAS, SPSS, Hadoop, Spark, Tableau or D3 and exposure to Machine Learning and Big Stack Development', 'Proficiency in at least one computer programming language is a plus such as Java, C++, JavaScript, Node, JSs', 'Basic understanding of Cloud (AWS, Azure, etc.)', 'Ability to thrive in a team-based environment', 'Excellent verbal and written communication skills', 'Work or internship experience using data science tools in a corporate environment', 'Interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'Willingness to relocate to the Washington, DC metropolitan area', 'Many jobs within GBS Federal Sector require U.S. citizenship and/or security clearance because of government or contract requirements. If you are not a U.S. citizen or are unable to obtain security clearance, there may be limited work opportunities for you, which may affect your continued employment at IBM.', 'Bachelor’s Degree from an accredited 4-year institution coupled with internship, work, and/or project experience, which will provide the analytical and technical acumen that translates to an entry level consulting role.', 'While many Federal projects are located in the Washington, DC area and have limited travel, candidates must be willing and able to travel up to 100% of the time, if project/business needs require.']",2020-08-08 13:09:18
Data Engineer I,Ryder,3.4 out of 5,"Franklin, TN 37067","['Job', 'Company', 'Develop and maintain a robust data lake architecture', 'Develop and maintain an ETL and data management strategy', 'Utilize integrated data to prioritize, synthesize and develop solutions to key business problems', 'Utilize predictive and prescriptive modeling techniques using mathematical modeling and traditional statistical approaches in addition to the latest algorithm technology in machine learning and artificial intelligence', 'Design critical analytical dashboards, reports and queries to drive strategic business decisions, ad-hoc analysis and identify descriptive and prescriptive solutions for internal Ryder teams and our external customers', ""Think on your feet, communicate constantly and professionally, and above all else drive solutions to meet the expectations of our external and internal customer's business requirements"", ""Bachelor's degree Business Administration, Supply Chain, Computer Science, Data Analytics or equivalent"", ""Master's degree Computer Science, Data Analytics, Operational Research, Mathematics or equivalent preferred"", 'Two (2) to four (4) years or more experience in demonstrating advanced analytics, digital transformation, data management, dashboarding and/or product management skills in an educational/project or intern type environment with a Bachelor’s degree', 'One (1) year or more experience in demonstrating advanced analytics, digital transformation, data management, dashboarding and/or product management skills in an educational/project or intern type environment with a Master’s degree', 'Two (2) to four (4) years or more experience in analytics, data extraction, transformation & loading, data visualization, and agile development. Experience working in a cloud environment a plus (AWS/Azure) preferred', 'Ability to:Articulate issues, present ""pros and cons"" and provide solutions to next supervisory level preferredExpress complex technical concepts in business termsPartner with colleagues to identify the role that data, cloud, and intelligence play in the digital product, defining tactical opportunities to build into product roadmapPartner with technology teams to identify the platform and cloud capabilities required to support product innovation, working closely with technology throughout the build, test, and release of the product using continuous improvement continuous deployment processes', 'Strong verbal and written communication skills', 'Time management, collaboration, organization and presentation skills. Proficiency in Agile Design Thinking methodology, with a focus on managing solution driven strategy plans to achieve goals', 'Knowledge of supply chain management and third party logistics industries (intermediate level)', 'Experience using tools like:ETL tools (Paxata or SSIS)Data manipulation tools (SQL or Python)Object oriented development stacks (.net) (intermediate level)', 'Experience developing BI solutions with tools like:TableauPower BiMicroStrategy (intermediate level)', 'Exposure to the development of predictive analytic solutions using predictive analytics tools like:AlteryxPythonR+Stat/ML (intermediate level) preferred', 'Enhance Data Maturity by interacting with the business to understand their decision making information needs and serve as a liaison with IT source system owners so data is structured, loaded and processed in the data lake in an accurate and timely manner. Establish standards, processes, methodologies and governance for data integration across the enterprise to ensure the data is relevant, clean and usable. Demonstrate Data Integration leadership across disciplines and domains to facilitate consensus, buy-in and adoption by engaging, teaching, training, and mentoring peers and associates', 'Develop Dashboards by understanding business needs, interpret the integrated data and translate this into usable visualizations to drive business decisions. Assist the business with interpreting results and how to utilize the dashboards. Support the business with evaluating needs and ad-hoc requests to prioritize efforts. Coordinate efforts across dash boarding resources and provide guidance and support', 'Utilize Advanced Analytics to develop solutions to address key business problems. This will be done through predictive and prescriptive modeling techniques along with the ability to think on your feet, communicate constantly and professionally, and above all else drive solutions to meet the expectations of our external and internal customer’s business requirements', 'The Data Engineer I will be a specialist of data integration and analytics, bringing the required qualitative (to understand why they are doing) and quantitative (to analyze data to surface meaningful insights) skills', 'This position will be an expert in the Ryder business, understanding the complexity of the supply chain world and the role that advanced products play within the Supply Chain ecosystem', 'Performs other duties as assigned.']",2020-08-08 13:09:18
Quality Technician,Masco,3.4 out of 5,"Aston, PA","['Data entry for Quality Systems—inspections, material rejections, etc.', 'Inspection- incoming, in-process, final. measure material, parts or assemblies against a standard to ensure high quality parts are going to our customers.', 'Troubleshooting/material review with manufacturing engineer.', 'Standard work/process documentation, creation and updates as needed.', 'Record keeping/production log management for traceability of our products.', 'Quality stamp/operator number system upkeep- assign qa numbers to new employees and maintain stamp log.', 'Assist in process reviews with manufacturing engineer.', 'Assist with training as required & ensures procedures are being signed off once operators are trained.', 'Assist with time studies of our processes as required.', 'Audits as required- safety, 5s, kanban, etc.', 'Other documentation updates as needed- updating inspection criteria (aql level), etc.', 'Attending meetings with qa or other departments as required.', 'Assisting with gauge calibration as required.', 'Use hand tools and measuring tools regularly.', 'Assisting with continuous improvement efforts as required- Kaizen, projects, etc.', 'Proficient in MS Office suite, primarily Excel & Word.', 'Must be able to read Engineering Drawings.', 'Time management skills and multitasking ability.', 'Math skills including adding, subtraction, multiplication, and division.', 'Must be able to read and interpret documents such as Procedures, Engineering drawings and data sheets.', 'Must be able to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form.Ability to deal with problems involving several concrete variables in standardized situations.', 'Experience using hand tools and measuring tools.', 'Able to communicate well, verbally and in writing.', 'Able to work well with, and build/maintain positive relationships with other departments, co-workers, and vendors.', 'Able to stand and walk for long periods of time.', 'Able to sit for long periods of time', 'Able to work in front of a computer screen for long periods of time', 'Able to lift up to 50 pounds on occasion.', 'The noise level in the work environment can be in a loud manufacturing environment.']",2020-08-08 13:09:18
Data Engineer,Autoweb Inc,N/A,"Brimfield, MA 01010","['Selecting and integrating any Data tools and frameworks required to provide requested capabilities', 'Knowledge of Cloud infrastructure and services (AWS/Azure/GCP)', 'Strong Analytical and Reasoning Skills', 'Implementing ETL process', 'Monitoring performance and advising any necessary infrastructure changes', 'Defining data retention policies', 'Knowledge of various ETL techniques and frameworks', 'Experience with integration of data from multiple data sources', 'Proficient understanding of distributed computing principles', 'Proficient in Application Development code like Java, C# or Python', 'Proficient understanding of Data Store technologies like Relational Databases and NoSQL but not limited to those.', 'Good understanding of Lambda Architecture, along with its advantages and drawbacks', 'Experience with various messaging systems, such as Kafka or RabbitMQ', 'Knowledge of Cloud based solutions', 'English: 75% oral English proficiency, 75% written English proficiency']",2020-08-08 13:09:18
Senior Data Engineer,Infotree Global,N/A,"Creve Coeur, MO","['8+ years of experience (minimum)', 'BS degree or equivalent experience', 'Demonstrated prior experience in developing using SQL, SQL Performance Tuning, relational database design, development and implementation for both row-wise (PostgreSQL, Teradata, Aurora, etc…) and columnar data stores (Hana).', 'Ability to communicate across diverse audience of business analysts, architects, business users and technical project staff', 'Strong organization and interpersonal skills. Ability to deal with and balance multiple priorities. Ability to deal with ambiguity and rapid change. Demonstrated interaction skills across a wide spectrum of technical contacts and teams.', 'Passion for the integrity of database design and a willingness to compromise appropriately to balance design and delivery.', 'Hands-on role requiring rigorous attention to detail and thorough application of standards.', 'Self-starter, capable of driving towards goals independently. Highly self-motivated and delivery focused.', 'Have demonstrable understanding and awareness of technology and an ability to learn and acquire new technologies as needed.', 'Willingness to do collaborative software development.', 'Extreme familiarity and comfort with the Teradata, Redshift, Hana, PostgreSQL (or equivalent)', 'Large development project experience.', 'Strong database design, development and tuning skills.', 'Experience with both real time and batch data delivery architectures.', 'Understanding of stream processing using Apache Kafka, enabling data-intensive API’s using a RESTful approach is a plus.', 'Ability to work as a member of a diverse team to achieve a common goal.', 'Proven to possess excellent verbal and written communication skills.', 'Thorough understanding of the software lifecycle and relevant software methodologies used in software development.', 'Experience with geospatial and agricultural ecosystems is a plus.', 'Performance: Takes responsibility for achieving results, overcomes obstacles and adapts approach, bias for action.', 'Business Awareness: Displays awareness of the impact of actions on the business, demonstrates understanding of the business context of the company and acts in line with it.', 'Communication and Influence: Uses negotiation skills and techniques to obtain agreement between different interests, challenges management constructively, bringing different views into the open.', 'Partnership and Teamwork: Actively promotes a positive team spirit, builds networks to enhance effectiveness and share knowledge.', 'SQL Performance Tuning: 4 years (Required)', 'Teredata: 4 years (Required)', '""W2 ONLY"". What is your work authorization in US?']",2020-08-08 13:09:18
Data Engineer,CircleBlack,N/A,"Jersey City, NJ 07302","['Contribute to the data platform design and implement scalable, extensible solutions that supports key business data ingestion flows.', 'Gather and document requirements for future system enhancement working with both the business, production, and core systems teams', 'Design and Build pipelines that support the ingestion, analysis, and enrichment of financial data.', 'Improve the existing data platform to increase the throughput and accuracy of data.', 'Identify areas of automation opportunities and implement improvements.', 'Work with the business team to analyze, understand and map source data fields from custodial and market data sources to expand and improve the platform.', 'Work closely with the production team to identify, troubleshoot, and resolve issues.', 'BA/BS in Computer Science / related technical field or equivalent practical experience.', '2+ years of relevant work experience developing with Python in a MySQL environment', 'Experience building maintainable and testable code bases in an agile environment', 'Experience with object-oriented programming and understanding of data structures and algorithms', 'Exceptional Problem solving and analytical skills.', 'Excellent communication, interpersonal, time management and conflict resolution skills', 'Knowledge of SQL and relational database concepts and the ability to develop complex and efficient queries', 'Knowledge of financial concepts (e.g., stocks, bonds, etc.) is encouraged', 'Knowledge of Linux (preferable Centos), Amazon Web Services (AWS) EC2 and RDS, as well as Javascript a plus', 'Possess an enthusiastic and positive attitude', '401(k)', 'Dental Insurance', 'Employee Assistance Program', 'Employee Discount', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'No: Not providing sponsorship for this job', 'Dependable -- more reliable than spontaneous', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'www.circleblack.com', 'https://www.facebook.com/CircleBlackInc/', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:09:18
Data Engineer,Blue Cross Blue Shield of Louisiana,4 out of 5,"Baton Rouge, LA","['Jobs are updated and posted daily.', 'You must submit your resume online.', 'Apply for each position for which you are qualified and interested in.', 'You will only be considered for positions for which you apply.', 'Resumes are only accepted for posted positions.', 'Positions are full-time unless otherwise stated.', 'Due to the high volume of applicants, only those most qualified will be contacted.', 'We are unable to accept phone calls.', 'Support of a data warehousing, data mart, data lake, and/or business intelligence environment', 'ETL/ELT development background with Informatica PowerCenter, DataStage, SSIS, or Azure Data Factory', 'Development experience with Teradata, Oracle, SQL Server, Data Lake, or Sybase repositories', 'Other programming language such as C#, Python, PL/SQL, SparkSQL, NoSQL', 'Shared API for web or cloud applications development background', 'Big Data technologies such as Hadoop, Spark, Artificial Intelligence (AI), Machine Learning (ML), Natural Language Processing (NLP)', 'BI tools or reporting experience with SSAS, SSRS, BOE, and/or Tableau', 'Project Management Experience', 'Healthcare Payer experience', 'Experience working in an agile development methodology', 'DevOps experience (automation of code or workflow through release pipeline)', 'Data warehousing development lifecycle', 'Ability to independently design, develop and debug basic ETL/ELT or API solutions based on business requirements with feedback from the team’s technical lead', 'Ability to independently evaluate the test results of others', 'Ability to become self-sufficient with integration tools', 'Ability to independently create basic integrations to build dimensional databases, data marts, data lake, and cubes with feedback from the team’s technical lead', 'Strong analytical, problem-solving and decision-making skills along with the ability to react quickly to changing requirements due to product limitation or driven by enterprise need', 'Ability to independently develop Unit Test Plans and Test Data with feedback from the team’s technical lead', 'Ability to resolve the issues found in workflows, mappings, stored procedures, and data pipelines', 'Develop basic system and integration test plans', 'Ability to execute test plans and document results and discrepancies with feedback from the team’s technical lead', 'Ability to write SQL queries using subqueries', 'Strong knowledge of SQL data types and functions', 'Very good communication and writing skills with an attention to detail']",2020-08-08 13:09:18
Data Engineer,Elkay Manufacturing,3.3 out of 5,"Downers Grove, IL 60515","['Design, develop and maintain data models, database architectures, and associated database objects in Snowflake, Oracle, and other database solutions such as Azure.', 'Design, develop, and maintain data integrations using Informatica Power Center, Informatica Integrated Cloud Services, and data prep tools.', 'Participate in or drive project activities such as requirements gathering, design, develop, test, and deploy.', 'Assist in the set-up of, and administer, on premise and cloud tools used in the Elkay analytics infrastructure.', 'Create and maintain necessary technical documentation, including requirements, design, and test documents.', 'Identify emerging trends, processes, and techniques impacting Elkay’s analytics infrastructure and make suggestions for incorporation of these into the analytics infrastructure.', 'A Master’s or Bachelor’s degree in Computer Science, MIS, engineering, or a related technical discipline is required.', '5+ years of experience in data engineering, data warehousing, business intelligence, ETL on databases such as Oracle or SQL Server, and/or big data is required.', '3+ years of experience in ETL/ data integration is required with 2+ years of experience in Informatica PowerCenter, job scheduling tools is required.', 'Working experience in Python/R/Scala, Snowflake is required.', 'Hands on experience in writing and understanding complex SQL (e.g. CTE’s others).', 'Thorough understanding of relational database design and best practices, including dimensional (star, snowflake) models is required.', 'A collaborative working style and ability to work well within the team and with business consumers is required.', 'Ability to clearly communicate to technical and non-technical audience by written and verbal is required.', 'Independent analytical, critical thinking, and problem-solving ability in complex technical environments is required.', 'Production experience in OBIEE, Oracle Analytics Cloud (OAC) and Tableau is nice to have.', 'Familiarity with big data technologies such as Microsoft Azure Data or AWS is nice to have.']",2020-08-08 13:09:18
Data Software Engineer,BuyerSight,N/A,"New York, NY","['You are eager to learn and become proficient in new technologies, and don’t shy away from doing whatever needs to get done.', 'Iterate and ship quickly to build new products for our customers. You understand the tradeoffs between building for immediate business needs vs. long-term engineering stability.', 'Be thoughtful about establishing good practices now in how we write and deploy our code so that we can scale effectively and quickly.', 'Contribute to our product development process and take charge of not just the technology being built, but the products that our customers will be using.', 'Experience building an AI/ML platform on top of a cloud service like AWS or Google Cloud. Leveraging their existing tools and products to accomplish business goals.', 'Experience designing and building performant ETL processes on top of AWS or Google Cloud. We will be dealing with multiple data sources that will need to be processed and normalized for our front end.', 'We use Python, Node, and React for our app development. That being said there is a lot of open room to use whatever technology you feel is right for the job.', 'You understand how to build performant data pipelines from scratch. You understand how to deliver on customer needs and timelines while minimizing accumulation of technical debt.', 'You are opinionated about engineering best practices and always seek to improve your understanding of the best way to do things.', 'We have a number of ML jobs that run asynchronously and need to have an efficient pipeline for both processing and loading the processed data into our application database. We need to be able to process thousands of communication records per client per day and deliver results quickly and accurately to the end user.', 'Continually monitor and improve the accuracy of our AI models.', 'We will need to be able to pull communication data from multiple sources from our clients. You will be in charge of building the connections from these data sources and defining how to standardize their format as they are stored on our databases.', 'The founders, Scott and Brian, each have over a decade of experience in B2B startups. You will be drawing on their experience and learn what it means to build a business from its earliest stages.', 'The opportunity to take ownership over the technology that we use and build things the way you want to build it.', 'Flexible work accommodations.', 'The chance to shape how management and leadership is done in sales organizations across the B2B ecosystem.', 'We also like to think we’re pretty cool, and generally fun to hang out with.']",2020-08-08 13:09:18
"Senior Engineer, Data",SiriusXM,3.6 out of 5,"New York, NY","['Build and deploy streaming and batch data pipelines capable of processing and storing petabytes of data quickly and reliably.', 'Collaborate with product teams, data analysts and data scientists to design and build data-forward solutions.', 'Gather and process all types of data including raw, structured, semi-structured, and unstructured data.', 'Integrate with a variety of data providers ranging from marketing, web analytics, and consumer devices including IoT and Telematics.', 'Build and maintain dimensional data warehouses in support of business intelligence tools.', 'Develop data catalogs and data validations to ensure clarity and correctness of key business metrics.', 'Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result.', 'Derive an overall strategy of data management, within an established information architecture (including both structured and unstructured data), that supports the development and secure operation of existing and new information and digital services.', 'Plan effective data storage, security, sharing and publishing within the organization.', 'Ensure data quality and implement tools and frameworks for automating the identification of data quality issues.', 'Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings.', 'Mentor and lead data engineers providing technical guidance and oversight.', 'Provide ongoing support, monitoring, and maintenance of deployed products.', 'Drive and maintain a culture of quality, innovation and experimentation.', 'This is an individual contributor role without direct reports, however as a Senior level role we expect this candidate to coach, mentor, and help develop junior developers and engineers to inspire, motivate, grow, and help structure a high performance team.', 'Advanced degree in relevant field of study strongly desirable, particularly in computer science or engineering level programs.', '5+ years professional experience working with data extract/manipulation logic.', '5+ years professional experience with object-oriented programming, functional programming, and data design.', '7+ years experience with Development, Engineering, R&D or Information Technology.', '3+ years working with a public cloud big data ecosystem (certification in AWS a plus).', '3+ years working with MPP databases, distributed databases, and/or Hadoop.', 'Passion for data engineering, able to excite and lead by example and mentoring others.', 'Hungry and eager to learn new systems and technologies.', 'Self-directed and enjoys the challenge and freedom of deciding what is the most impactful thing to work on next.', 'Ability to deliver exceptional results through iterative improvement rather than initial perfection.', 'Excellent communication and presentation skills and ability to interact appropriately with all levels of the organization, including: business users, technical staff, senior level colleagues, vendors, and partners.', 'An extensive track record that demonstrates effectiveness in driving business results through data and analytics.', 'The ability to develop and articulate a compelling vision and generate necessary consensus.', 'A successful history of translating business objectives and problems into analytic problems, and analytic solutions into actionable business solutions.', 'A proven ability to influence decision making across large organizations.', 'A proven ability to hire, develop, and effectively lead deeply technical resources.', 'Demonstrate and foster a sense of urgency, strong commitment, and accountability while making sound decisions and achieving goals.', 'Articulate, inspire, and engage commitment to a plan of action aligned with organizational mission and goals.', 'Create an environment where people from diverse cultures and backgrounds work together effectively.', 'Experience deploying and running AWS-based data solutions and familiar with tools such as Cloud Formation, IAM, Athena, and Kinesis.', 'Experience engineering big-data solutions using technologies like EMR, S3, Spark and an in-depth understanding of data partitioning and sharding techniques.', 'Experience loading and querying both on premise and cloud-hosted databases such as Teradata and Redshift.', 'Building streaming data pipelines using Kafka, Spark, or Flink.', 'Familiarity with binary data serialization formats such as Parquet, Avro, and Thrift.', 'Experience deploying data notebook and analytic environments such as Jupyter and Databricks.', 'Knowledge of the Python data ecosystem using pandas and numpy.', 'Experience building and deploying ML pipelines: training models, feature development, regression testing.', 'Experience with graph-based data workflows using Apache Airflow.', 'Expertise writing distributed, high-volume services in Python, Java or Scala.', 'Expertise with high volume heterogeneous data, preferably with distributed systems.', 'Knowledge of data modeling, data access, and data storage techniques.', 'Appreciation of agile software processes, data-driven development, reliability, and responsible experimentation.', 'Familiar with metadata management, data lineage, and principles of data governance.', 'ETL/ELT Tools', 'BI tools', 'MDM / Reference Data', 'RDBMS, NoSQL and NewSQL', 'MS Office Suite']",2020-08-08 13:09:18
Data Scientist,White Ops,4 out of 5,"New York, NY 10010","['Develop algorithms (i.e. rule based, statistical, machine learning) that automatically detect emerging threats', 'Evaluate and implement data analysis strategies to improve detection efficacy at internet-scale', 'Ad hoc investigations to respond to emerging threats with velocity and quality', 'Collaborate with product, engineering, customer success, to define and develop new product features that will delight our customers', 'Research for case studies and white papers on bot detection', 'Contribute to toolkits and platforms that scale detection analytics', 'You have a strong sense of ownership which drives you to find ways to do things better, faster, and cheaper', 'You look to find new and innovative ways to solve complex problems through rigorous experimentation, all by yourself', 'You are open, transparent and work in tight collaboration with anyone', 'You constantly drive for correctness and performance, in that order', 'You are a data scientist, analyst, engineer and have solved difficult problems to prove it', 'You have proficiency with SQL, Python', 'You have familiarity with tools, libraries and platforms such as Jupyter notebooks, Pandas, NumPy etc', 'Track record of independent, creative problem solving with large amounts of complex data', 'Knowledge of how the Internet works', 'Comfort with ad tech terminology', 'Background in data science for security is a plus', 'Knowledge of how web browsers work is a plus', 'Unlimited vacation policy', 'Stock options, 401(k), and commuter benefits', 'Competitive salary and commission structure', 'Medical and dental insurance for all full-time employees', 'Fully paid parental leave', 'Professional development fund', 'Great coaching from senior leaders and challenging development opportunities']",2020-08-08 13:09:18
Data Engineer - BI,F. Schumacher & Co.,3.3 out of 5,"New York, NY 10001","['Architect, implement and operate stable, scalable and highly performance data pipelines that cleanse, structure and integrate data sets from source systems and third-party data structures into easily consumable data models', 'Migrate legacy reporting data structures to new Enterprise data platform.', 'Promote the usage of data engineering and data management best practices across the Enterprise.', 'Mentor & train team members on the appropriate usage of data marts models and other data sources used in analytics.', 'Organize and promote a Data Governance Committee to manage source system data structures and changes to those structures to ensure consistent business definitions and data quality.', 'BS/MS in Computer Science, Information Systems or related field', 'Experience planning, designing and delivering a pipeline for analytics', 'Experience with data warehousing design and implementation', 'Experience with data visualization tools such as Tableau or Power BI', 'Experience with Microsoft SQL and ability to write efficient cod', 'Ability to analyze existing tools and databases and provide recommendations', 'Culture: In our company, you’re judged by your ideas and results, not by your experience or title. So, we encourage you to be thoughtful, casual, and to speak your mind.', 'Development: We strive every day to develop you and your colleagues for what we believe is a challenging and supportive business environment.', 'Teamwork: We believe that success and efficiency can only be a product of collaboration. At FSCO, working together is the rule, not the exception.', 'Innovation: We have achieved success and longevity through innovation. And we encourage experimentation and rule breaking. Mistakes? Those are things we embrace, talk about and learn from.', 'Life balance: Focused, productive time is more important than long hours. We believe in having enough time to be happy both in the office and out of it.']",2020-08-08 13:09:18
Data Engineer - Integrations,Dragos Inc,N/A,"Hanover, MD 21076","['Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', '3-5 years’ experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Strong analytic skills related to working with unstructured datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Intellectual curiosity to find new and unusual ways of how to solve data management issues.', 'Strong knowledge of building and interacting with REST APIs.', 'Experience with HashiCorp automation and security tools, specifically Vault and Terraform', 'Familiar with serverless system architectures and Infrastructure as Code design patterns', 'Software development skills in JavaScript/Node.js, Python, or Kotlin', 'This position is available either in Hanover, MD or remote.']",2020-08-08 13:09:18
Senior Data Engineer,UnitedHealth Group,3.7 out of 5,"New York, NY 10261","['Job', 'Company', 'Build scalable, fault-tolerant batch and real-time data pipelines to power internal applications, operational workflows, and business intelligence platforms', 'Create and maintain data-driven APIs to support a wide range of integration with healthcare partners', 'Recommend and implement best practices for data management and governance', 'Help set technical direction and provide guidance to more junior data engineers.', 'Work as a partner with our product team to represent engineering interests and inform product decisions', 'Solve technical problems, simple and complex, in a lean and efficient manner', 'Follow engineering best practices and cultivate a best-practices culture', 'Resolve to put the customer first, by chasing ROI in all engineering efforts, recognizing that doing something the fastest way possible, lets us do more for patients', 'Bachelor’s degree in computer science, engineering or a similar field of study, or equivalent experience', '3+ years of experience with professional data engineering, building and using data infrastructure, APIs, and integrations in a cloud-hosted setting.', 'Demonstrate a keen awareness of the importance of security, scalability, reliability, and feasibility in solution design', 'Fluent in at least one general-purpose programming language (Python, Java, Scala, Go, Ruby, C#, etc…)', 'Expert knowledge of SQL', 'Familiarity with electronic health record (EHR) data and standards (HL7, FHIR, and similar protocols)', 'Experience with performance tuning tools and/or techniques', 'Experience with AWS technologies such as Redshift, S3, Lambda, EMR, Kinesis, RDS', 'Experience with QuickSights, PowerBI, Qlikview, Tableau or other Reporting Tools']",2020-08-08 13:09:18
Data Management Engineer,Solidus Technical Solutions,N/A,"Lexington, MA 02420","['perform all infrastructure development provided inputs from the team with a high degree of autonomy', 'set up a continuous integration pipeline for databases and embedded software', 'efficiently curate, manage, query, and access large datasets for algorithm training and validation.', 'working closely with a small team to design a data management', 'develop geospatial database and query tools to access data for curating training and test datasets', 'stand-up automatic test infrastructure to evaluate algorithm performance', 'close interaction with other stakeholders on the team to create an architecture that meets individual and programmatic needs.', 'US Citizenship and the ability to obtain a DoD Clearance', 'MS +3 years of experience or BS +5 years of experience', 'Geospatial data including imagery and digital elevation maps', 'Geospatial tools and utilities', 'MongoDB database design and implementation', 'REST API development', 'GitHub version control and documentation', 'Jenkins automatic test and continuous integration', 'Python scripting', 'Experience with GPU algorithm implementation, NVIDIA TX2', 'Excellent interpersonal and communication skills and be able to work in a team-oriented environment with minimal supervision.', 'Python algorithm development and data analysis', 'Neural network development with PyTorch', 'Hardware-in-the-loop development and test experience', 'Familiarity with GDAL and ArcGIS', 'Background in computer vision', 'C/C++ development experience']",2020-08-08 13:09:18
Data Engineer - Top Secret Clearance Required,Deloitte,4 out of 5,"Arlington, VA 22209","['Job', 'Company', 'Perform project tasks independently, and may direct the efforts of others', 'Participate in and/or lead the development of deliverable content that meets the needs of the client and contract', 'Anticipate client needs and formulate solutions to client issues', 'Review deliverables for accuracy and quality', 'Provides coaching to junior staff', 'Contribute to new business proposals and proposal development', 'Manages own personal and professional development; seeks opportunities for professional growth and expansion of consulting skills and experiences', 'Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms', 'Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions', 'Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements', 'Active Top Secret Level Government Security Clearance (SCI Eligible)', '3+ years of professional experience.', '3+ years of experience as a Data Engineer or ETL Developer', '2+ years of experience with data modeling, data profiling, and relational database technologies (e.g. Oracle, MySQL).', '2+ years of SQL and PL/SQL experience', ""Bachelor's degree in Computer Science, Engineering, Mathematics or other business-related field"", 'Ability to reverse engineer existing data models into conceptual and logical data model constructs.', '2+ years of relevant consulting or industry experience', 'Prior experience migrating data from a legacy platform to a modern platform', 'Prior professional services or federal consulting experience']",2020-08-08 13:10:01
R&D Leadership Development Program,Johnson & Johnson Family of Companies,4.2 out of 5,"West Chester, PA","['You will have opportunities to participate and/or lead in rotational assignments encompassing entire project or a large portion of a major project. This may include resolving advanced materials, process, inspection/testing or procedural approaches to advance a medical device through the pipeline process into full R&D, and potentially into commercialization.', 'Support of products’ design development, manufacturing and commercialization, leveraging technical expertise to anticipate and proactively address challenges and risks.', 'Increase the productivity of product’s design utilizing CAD, improve the quality of projects, improve communications through documentation, and to create a database for manufacturing.', 'Engineer capabilities required to develop and deliver automated medical devices - including requisite instruments, advanced imaging, and user interface / experience.', 'Pursue a number of internal developmental training programs as well as externally recognized qualifications such as Process Design Excellence.', 'Opportunity to work in a fast-paced cross functional, technologically advanced corporate environment in a program focused on developing individual engineers capable of pursuing careers across medical device businesses and high-volume manufacturers.', 'Currently enrolled in an Engineering Graduate Program (Master’s Degree or PhD) graduating by June 2021.', 'The following engineering disciplines or specialties are preferred: Mechanical, Robotics, Electrical, Computer, Systems, Software, Materials Science, Biomedical and Computer Science.', 'The following concentration fields and/or skills are strongly preferred: Machine Learning, IoT, Embedded Software, Deep Machine Learning, Prototyping, Robot Design, Systems Reliability, Firmware and hardware integration.', 'A minimum GPA of 3.3 is strongly preferred.', 'You must have the ability to work closely with technical and non-technical personnel and have excellent communication skills with the ability to influence others.', 'You must have the ability to demonstrate excellent problem-solving skills, intellectual curiosity and a dedicated approach to achieving success.', 'Validated leadership experience through extra-curricular activities, employment and/or internship experiences is required. R&D internship highly preferred.', 'Ability to relocate anywhere in the United States as required by the program’s rotations – mandatory requirement.']",2020-08-08 13:10:01
Lead Data Engineer,CVS Health,3.3 out of 5,"Hartford, CT","['Job', 'Company']",2020-08-08 13:10:01
Engineer - Distribution Planning,Exelon Corporation,3.9 out of 5,"Christiana, DE 19702","['Performs engineering assignments while exercising independent discretion under the guidance of an experienced engineer. (e.g. Collect data, perform complex analysis, interpret results, draw conclusions, and clearly present a recommendation to management)', 'Performs engineering tasks associated with large projects or a number of small projects. (e.g. Analyze and interpret the results of complex power flows and perform complex engineering tests, and analyze non-specific and ambiguous results)', 'May direct the engineering tasks associated with a large project or a number of small projects (e.g. Verify and validate studies, blueprints, or designs against accepted engineering principles and practices. Design high voltage transmission and distribution circuits, meeting all engineering standards and criteria)', 'Participates on teams and may lead teams.', 'Provides technical assistance in support of senior engineers., managers and others.', 'Applies technical knowledge to help promote a safe work environment and to enhance customer satisfaction.', 'Bachelor of Science degree in Engineering', 'Two or more years of professional engineering experience', 'General knowledge and experience with regulations, guides, standards, codes, methods, and practices necessary to perform assignments for a specific discipline, various installations, or services', 'Engineer in Training License', 'Strong written and oral communication/presentation skills, report generation & technical writing skills', 'Interpersonal skills & the ability to collaborate with peers and managers', 'Consulting and needs assessment skills', 'Time, project management and multi-tasking skills']",2020-08-08 13:10:01
Lead Data Engineer,DLL Group,4.3 out of 5,"Wayne, PA","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and enabling data-driven decisions across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate, secure, and available for key stakeholders and business processes that depend on it.', 'Contributes to engineering communities of practice, and documents work.', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Works closely with a team of frontend and backend engineers, product managers, and analysts.', 'Defines company data models, uses ELT pipeline and data streaming tools to populate data models.', 'Designs data integrations and data quality framework.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'BS or MS degree in Computer Information Science or related technical field', '8-10 years of Information Technology experience with data management', '5+ years of software engineering experience in Python, Scala, Java, or .NET', '5+ years of experience with schema design, dimensional data modeling, and data storage technology', '5+ years of multiple kinds of database experience (SQL and No-SQL)', 'Proven ability in managing and communicating data warehouse plans to internal clients', 'Experience designing, building, and maintaining secure, reliable batch and real time data pipelines', 'Experience with cloud data ingestion, data lake, and modern warehouse solutions (Azure is a plus)', 'Experience with event streaming platforms like Kafka or Azure Event Hubs', 'Ability to provide data architecture and engineering thought leadership across business and technical dimensions solving complex business cases', 'Possesses a deep understanding of enterprise software patterns and how they may be leveraged in modern data management', 'Knowledge of best practices and IT operations in an always-up, always-available service', 'Experience with or knowledge of Agile Development methodologies (SAFe is a plus)', 'Excellent analytical problem solving and troubleshooting skills', 'Excellent oral and written communication skills with a keen sense of customer service', 'Excellent team player with proven ability to influence', 'Highly adaptable to a continuously changing environment', 'Able to give and receive open, honest feedback and to foster a feedback environment', 'Outstanding communication, interpersonal, relationship building skills for team development', 'Possible Travel (10%)', 'Experience within financial services is a plus', 'Two working days per year volunteering for a local charity', 'Flexible hours with possibility to work from home (within job scope)', 'Career development opportunities: online learning, member development programs, Tuition reimbursement program.', 'Company matching 401k program', 'Industry leading Paid Time Off package', 'Outstanding Medical, Dental, Vision benefit programs', 'One month fully paid sabbatical after seven years of service', 'The selection process may involve an assessment.', 'Applications via email will not be reviewed. We advise you to apply online via our career website workingatDLLgroup.com', 'DLL’s referral program applies.']",2020-08-08 13:10:01
Big Data Engineer (mini. 5 yr. exp.),Smart IT Professionals,N/A,"Detroit, MI","['2 years of experience with a Hadoop distribution and ecosystem tools such as Hive, Spark, Nifi and Oozie', '2 years of experience developing batch and streaming ETL/ELT processes', '2 years of experience with relational and NoSQL databases, including modeling and writing complex queries', 'Proficiency in at least one programming language such as Python or Java', 'Excellent communication, analytical, and problem-solving skills', 'Experience with Linux system administration, Linux scripting and basic network skills', 'AWS experience', 'Temporarily due to COVID-19']",2020-08-08 13:10:01
Data Engineer,Petram Data,N/A,"Detroit, MI 48226","[""Bachelor's degree in computer science, information technology, or a related field or equivalent experience"", '3 years of experience working with database tools', '3 years of programming experience using Python and C#', '3 years of experience working with SQL server integration services or ETL tools', '3 years of experience working with data integration tools', 'Proficiency in the Microsoft Office suite', 'Experience working with ETL tools', 'Knowledge of data integration tools', 'Software programming languages, such as Python and C#', 'Design and support the new and evolving sources of data being brought into the data warehouse', 'Work closely with data architects and follow best practices for data management consumption', 'Work closely with business analysts to work through business requirements and develop processes to provide the needed data visibility via the data warehouse and reporting platform', 'Model application layer and metadata design', 'Design and create automated applications and reporting solutions', 'Work closely with front-end developers to ensure data is being brought in and data integrity is being maintained', 'Monitor and troubleshoot performance issues on the data warehouse servers']",2020-08-08 13:10:01
Senior Data Engineer,HelioCampus,N/A,"Adelphi, MD","['Develop complex SQL queries and analyze data, systems integration experience; understand data warehouse concepts and structures.', 'Experience with data mapping, and the ability to design and develop ETL solutions.', 'Experience with translation of requirements into data model specifications.', 'Ability to multi-task, ability to troubleshoot problems in real-time and diagnose the root cause.', 'Competitive salary, based on experience and bonus program', 'Comprehensive benefits package includes medical, dental, vision, life and disability insurance', '401K with company match', '5+ weeks of paid time off including holidays and vacation']",2020-08-08 13:10:01
Data Engineer,Bitwise INC,3.3 out of 5,"Santa Monica, CA 90401","['Platform engg. will need to help setup the APIs using Lamda and AWS API Gateways to accept concurrent API calls', 'Expertise in setting Event Bus framework using AWS EventBridge', 'Expertise in Athena editor to create Framework that will help access the data in the S3 bucket. This framework will be used by embedded developers for their data pipelines', 'Setup framework with SQS messaging services that will be used by embedded developers for their pipelines.', 'Expertise in developing framework using Spark Libraries for batch/streaming, machine learning or graph processing etc', '401(k)', 'Health Insurance', 'Paid Time Off', '8 Hour Shift', 'Monday to Friday', 'SQS messaging: 1 year (Preferred)', 'AWS EventBridge: 2 years (Preferred)', 'Spark: 3 years (Preferred)', 'S3: 1 year (Preferred)', 'Data Engineer: 5 years (Preferred)', 'AWS API Gateways: 3 years (Preferred)', 'Big Data: 1 year (Preferred)', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:10:01
Big Data Engineer Lead,Cognizant Technology Solutions,3.9 out of 5,"Bridgewater, NJ 08807",[],2020-08-08 13:10:01
Azure Data Engineer,Quadrant Resource,N/A,"Seattle, WA","['Min 5+ year of experience in Data and Analytics area', 'Hands on coding experience with Databricks with Spark, Scala, SQL & Python', 'Data Science with Statistics, data analysis, machine learning, deep learning, mathematics, AI, NLP, neural networks & data engineering.', 'Experience in data acquisition, data collection, data cleaning, model development, model validation, and visualization to deliver data science solutions.', 'Designing and implementing highly performant data ingestion pipelines from multiple sources using Apache Spark and/or Azure Databricks', 'Delivering and presenting proofs of concept to of key technology components to project stakeholders.', 'Developing scalable and re-usable frameworks for ingesting of geospatial data sets', 'Integrating the end to end data pipleline to take data from source systems to target data repositories ensuring the quality and consistency of data is maintained at all times', 'Working with event based / streaming technologies to ingest and process data', 'Working with other members of the project team to support delivery of additional project components (API interfaces, Search)', 'Evaluating the performance and applicability of multiple tools against customer requirements', 'Scala: 3 years (Required)', 'Data Analytics: 5 years (Required)', 'Spark: 3 years (Required)', 'Azure Databricks: 3 years (Required)', 'BigData: 5 years (Required)', 'Python: 3 years (Preferred)', 'SQL Server: 3 years (Required)', 'Seattle, WA (Preferred)']",2020-08-08 13:10:01
Data Engineer,Idelic,N/A,"Pittsburgh, PA 15212","['Build new integrations, features, and support our Data Services Platform', 'Define internal development processes & practices for scaling our organization', 'Lead & contribute to the development of tools to scale our business and our customers', 'Participate in internal reviews of code, software components, and systems and make data-driven decisions on how they should evolve', 'Communicate effectively and participate with team members in an Agile environment', 'Work on any task and help solve problems when needed — be humble and scrappy!', '1+ years of experience as a software developer (or significant demonstration of studies or relevant experience)', 'Strong proficiency with Google Go (Golang), Python, or similar language', 'Experience reviewing code and mentoring less experienced developers', 'Strong quantitative and analytical background & process', 'Knowledge of streaming (Kafka, RabbitMQ)', 'Experience writing unit, integration, and end-to-end test code', 'Experience in the Logistics / Transportation industry', 'Experience with cloud computing (AWS, Azure) and services like KMS, RDS, SQS, etc', 'Understanding of data pipelining tools like Hadoop and Kafka', 'Experience with distributed technologies like Cassandra, Kubernetes', 'Experience working in an entrepreneurial or enterprise environment', 'Competitive Compensation Package Including Options', 'Medical, Dental, and Vision Insurance', 'Regular Company Outings and Events', 'Personal Choice of Hardware', 'Kickstarter Company Breakfast every Monday / Lunch Served up Every Friday', 'A Dynamic and Supportive Environment', 'Professional Development Opportunities', 'Be Part of a Small Team (to Start)— Which Translates To You Having A Big Personal Impact']",2020-08-08 13:10:01
Data Engineer,Backblaze,3.5 out of 5,"San Mateo, CA 94401","['Build scalable, efficient and high-performance pipelines/ workflows that are capable of processing large amounts of batch and real-time data', 'Build out our data service architecture to support internal and customer facing application use cases', 'Multidisciplinary work supporting real-time streams, ETL pipelines, data warehouses and reporting services', 'Bring new and innovative solutions to the table to resolve challenging performance and load issues', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability', 'Build out the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Java, Python, and SQL', 'Respond quickly to bug fixes and enhancement requests and be able to take directions and complete tasks on-time with minimal supervision.', 'Collaborate with business analytics team to optimize complex queries needed by regular Tableau reports', '5+ years of Java or Python', '3+ years in designing relational database, data modeling and ETL', 'Strong experience with SQL databases', 'Experience in operational data stores and real time data integration', 'Experience with RESTful APIs and server-side APIs integration', 'Proficient with development on Linux and Macintosh platforms', 'Maria DB', 'NoSQL DB', 'Cassandra experience', 'Salesforce', 'Passionate about building friendly, easy to use Interfaces and APIs.', 'Likes to work closely with other engineers, support, and sales to help customers.', 'Believes the whole world needs backup, not just English speakers in the USA.', 'Customer Focused (!!) — always focus on the customer’s point of view and how to solve their problem!', 'Good attitude and willingness to do whatever it takes to get the job done', 'Strong desire to work for a small, fast-paced company', 'Desire to learn and adapt to rapidly changing technologies and work environment', 'Rigorous adherence to best practices', 'Relentless attention to detail', 'Excellent interpersonal skills and good oral/written communication', 'Excellent troubleshooting and problem-solving skills', '100% healthcare for family', 'Competitive compensation and 401k', 'Full-time employees receive option grants', 'Flexible vacation policy', 'MacBook Pro to use for work plus a generous stipend to personalize your workstation', 'Fully stocked micro kitchens and strong coffee', 'Catered breakfast and lunches twice a week', 'Childcare bonus (human children only)', 'Pet-friendly office', 'Generous skills training policy to continue your professional development', 'Culture that supports healthy work-life balance']",2020-08-08 13:10:01
"Data Engineer position in Charlotte, NC",iknowvate technologies,N/A,"Charlotte, NC",[],2020-08-08 13:10:01
"Director, Software Engineering",Indeed,4.3 out of 5,Remote,"['Job', 'Company', 'Lead, inspire, and influence to make sure your team is successful', 'Partner with the recruiting team to attract and retain high-quality and diverse talent', 'Establish great rapport with other development teams, Product Managers, Sales and Customer Success to maintain high levels of visibility, efficiency, and collaboration', 'Ensure teams have appropriate technical direction, leadership and balance between short-term impact and long term architectural vision.', 'Lead 5-10 software engineering teams', '5+ years managing software engineering teams in consumer Web or SaaS products', 'Experience leading a geographically distributed software engineering organization comprising multiple teams', 'Strong technical background that allows you to advocate for and support your engineers', 'Experience building strong partnerships with other job functions, like product, marketing and UX, to keep teams collaborating smoothly and working together to improve the product.', 'Strong desire to understand the root cause and details of systems, get hands-on with data and analysis to evaluate how the team and the product are growing.', 'Experience with service-oriented and event-driven system architectures, building high-performance distributed systems']",2020-08-08 13:10:01
Data Engineer,Petram Data,N/A,"Detroit, MI 48226","[""Bachelor's degree in computer science, information technology, or a related field or equivalent experience"", '3 years of experience working with database tools', '3 years of programming experience using Python and C#', '3 years of experience working with SQL server integration services or ETL tools', '3 years of experience working with data integration tools', 'Proficiency in the Microsoft Office suite', 'Experience working with ETL tools', 'Knowledge of data integration tools', 'Software programming languages, such as Python and C#', 'Design and support the new and evolving sources of data being brought into the data warehouse', 'Work closely with data architects and follow best practices for data management consumption', 'Work closely with business analysts to work through business requirements and develop processes to provide the needed data visibility via the data warehouse and reporting platform', 'Model application layer and metadata design', 'Design and create automated applications and reporting solutions', 'Work closely with front-end developers to ensure data is being brought in and data integrity is being maintained', 'Monitor and troubleshoot performance issues on the data warehouse servers']",2020-08-08 13:10:46
Data Engineer I,Ryder,3.4 out of 5,"Franklin, TN 37067","['Job', 'Company', 'Develop and maintain a robust data lake architecture', 'Develop and maintain an ETL and data management strategy', 'Utilize integrated data to prioritize, synthesize and develop solutions to key business problems', 'Utilize predictive and prescriptive modeling techniques using mathematical modeling and traditional statistical approaches in addition to the latest algorithm technology in machine learning and artificial intelligence', 'Design critical analytical dashboards, reports and queries to drive strategic business decisions, ad-hoc analysis and identify descriptive and prescriptive solutions for internal Ryder teams and our external customers', ""Think on your feet, communicate constantly and professionally, and above all else drive solutions to meet the expectations of our external and internal customer's business requirements"", ""Bachelor's degree Business Administration, Supply Chain, Computer Science, Data Analytics or equivalent"", ""Master's degree Computer Science, Data Analytics, Operational Research, Mathematics or equivalent preferred"", 'Two (2) to four (4) years or more experience in demonstrating advanced analytics, digital transformation, data management, dashboarding and/or product management skills in an educational/project or intern type environment with a Bachelor’s degree', 'One (1) year or more experience in demonstrating advanced analytics, digital transformation, data management, dashboarding and/or product management skills in an educational/project or intern type environment with a Master’s degree', 'Two (2) to four (4) years or more experience in analytics, data extraction, transformation & loading, data visualization, and agile development. Experience working in a cloud environment a plus (AWS/Azure) preferred', 'Ability to:Articulate issues, present ""pros and cons"" and provide solutions to next supervisory level preferredExpress complex technical concepts in business termsPartner with colleagues to identify the role that data, cloud, and intelligence play in the digital product, defining tactical opportunities to build into product roadmapPartner with technology teams to identify the platform and cloud capabilities required to support product innovation, working closely with technology throughout the build, test, and release of the product using continuous improvement continuous deployment processes', 'Strong verbal and written communication skills', 'Time management, collaboration, organization and presentation skills. Proficiency in Agile Design Thinking methodology, with a focus on managing solution driven strategy plans to achieve goals', 'Knowledge of supply chain management and third party logistics industries (intermediate level)', 'Experience using tools like:ETL tools (Paxata or SSIS)Data manipulation tools (SQL or Python)Object oriented development stacks (.net) (intermediate level)', 'Experience developing BI solutions with tools like:TableauPower BiMicroStrategy (intermediate level)', 'Exposure to the development of predictive analytic solutions using predictive analytics tools like:AlteryxPythonR+Stat/ML (intermediate level) preferred', 'Enhance Data Maturity by interacting with the business to understand their decision making information needs and serve as a liaison with IT source system owners so data is structured, loaded and processed in the data lake in an accurate and timely manner. Establish standards, processes, methodologies and governance for data integration across the enterprise to ensure the data is relevant, clean and usable. Demonstrate Data Integration leadership across disciplines and domains to facilitate consensus, buy-in and adoption by engaging, teaching, training, and mentoring peers and associates', 'Develop Dashboards by understanding business needs, interpret the integrated data and translate this into usable visualizations to drive business decisions. Assist the business with interpreting results and how to utilize the dashboards. Support the business with evaluating needs and ad-hoc requests to prioritize efforts. Coordinate efforts across dash boarding resources and provide guidance and support', 'Utilize Advanced Analytics to develop solutions to address key business problems. This will be done through predictive and prescriptive modeling techniques along with the ability to think on your feet, communicate constantly and professionally, and above all else drive solutions to meet the expectations of our external and internal customer’s business requirements', 'The Data Engineer I will be a specialist of data integration and analytics, bringing the required qualitative (to understand why they are doing) and quantitative (to analyze data to surface meaningful insights) skills', 'This position will be an expert in the Ryder business, understanding the complexity of the supply chain world and the role that advanced products play within the Supply Chain ecosystem', 'Performs other duties as assigned.']",2020-08-08 13:10:46
Data Engineer,MINT dentistry,3.3 out of 5,"Dallas, TX 75206","['Job', 'Company', 'AWS data service expert – S3, RDS, QuickSight, Lambda', 'MySQL expert – SQL and Container/Service management', 'Scripting expert (various languages)', 'Software Development experience', 'Excellent Verbal and Written communicator', 'Adept at working in project teams or individually', 'Information Security and encryption understanding', 'Expert documentation skills', 'IT Project management', 'Self-Starter and Self-Manager', 'Bachelors or Masters degree in Computer Science or related field required', '5+ years’ related professional experience required', 'Proven and successful expertise with large-scale projects', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Data Science / Data Analysis: 4 years (Required)', ""Bachelor's (Required)"", 'mintdentistry.com', 'No']",2020-08-08 13:10:46
Algorithmic Trading Data Analyst/Engineer,Quantitative Brokers,N/A,"New York, NY","['Experience working with large financial datasets like market data, order/execution data, or positions data', 'Experience with data analysis using languages such as KDB+/Q, R, Python/Pandas', 'Comfortable with mathematical concepts such as regression techniques, and statistical analysis', 'Experience working in a Unix/Linux environment', 'Strong analytical and problem-solving skills with a proactive attitude to own issues and solve them', 'Excellent team-player and communication skills', 'Experience with algorithmic execution and TCA especially in the futures/cash treasuries market is a big plus', 'Familiarity with distributed trading systems/parallel computing', 'Proficiency with C++, REST APIs and UI technologies/framework such as Node.JS, Angular']",2020-08-08 13:10:46
Data Engineer,AlgoLIFT,N/A,"Los Angeles, CA","['Support data integrations with clients', 'Author and support data integrations with Ad Networks and other data providers', 'Maintain and improve various other ETL processes', 'Automate data integrity validation processes', 'At least 3 years of full time engineering', 'Significant knowledge of SQL and Python', 'Direct experience with data pipeline engineering']",2020-08-08 13:10:46
Data Engineer,Martin's Point Health Care,3.5 out of 5,"Portland, ME","['Participates in the development, testing, implementation and maintenance of uni-directional and bi-directional interfaces in support of information needs within Martin’s Point application environment.', 'Understands basic data extraction and data transfer tools utilized at Martin’s Point and is able to utilize those tools.', 'Utilizes data storage, access and transfer policies and procedures instituted.', 'Analyzes the use of data within Martin’s Point for an assigned project and will develop integration methods in support of that projects data needs.', 'Designs and builds data integration methods to guarantee accuracy as well as accessibility of all valuable data while understanding what data is important for that project and why.', 'Creates and maintains accurate and relevant network documentation including diagrams, as-built documents, configuration templates, inventories and IT Service Catalog.', 'Participates in after-hours work as needed', 'Participates in Process Improvements and other duties as assigned', 'Bachelor’s Degree in Computer Science or combination of relevant and equivalent education and experience', '3+ years of data integration experience', 'Educational/professional experience in SQL database design and Service Oriented Architecture', 'Educational/professional experience with Unix, SQL, Oracle, TCL as well as other scripting languages', 'Knowledge of HL7\\FHIR interface development and deployment']",2020-08-08 13:10:46
Data Scientist,NBCUniversal,4 out of 5,"Seattle, WA","['Minimum of a Bachelor’s degree in Computer Science,', '6+ years experience as a data scientist or data analyst', 'Mastery of SQL and either R or Python', 'Demonstrated success with statistical modeling and', 'Experience with AWS', 'Experience with data visualization tools (e.g. Looker,', 'Possess strong interpersonal skills with the ability to', 'Ability to deliver on multiple projects and meet tight', 'Flexible and adaptable, self-driven, confident and', 'Background in digital media or entertainment a plus', 'Experience with software development and automation a']",2020-08-08 13:10:46
Data Engineer - Full Time,Data Bridge Consultants,4.5 out of 5,United States,"['Builds complex technical solutions that turn business requirements into operational processes and inject analytical insights into the business', 'Aligns complex technical solutions to corporate governance requirements to ensure data security and maintain data quality standards', ""Remains on the cutting edge of industry trends to ensure that the Lowe's COE is aligned with industry best practices"", 'Builds automation and self-service consumption tools to operationalize data ingestion and analytic models', 'Aligns technical solutions to corporate standards to ensure that security and privacy requirements are met', 'Communicates clearly and concisely to key leadership and stakeholders to ensure alignment on project status and deliverables', 'Partners with Big Data architects, Data Scientists and other key stakeholders to ensure that project deliverables align with cost and timing standards', ""Bachelor's Degree in Computer Science, Engineering or related field and 3 years of experience in strong software programming fundamentals, with knowledge of Python, Scala or Java"", 'Good Understanding of SQL and NoSQL databases', '12 months experience in Data Engineering or relevantOR', ""Master's Degree in Computer Science, Engineering or related field and 1 year of experience in strong software programming fundamentals, with knowledge of Python, Scala or Java"", 'Good Understanding of SQL and NoSQL databases and related concepts', '6 months experience in Data Engineering or relevant']",2020-08-08 13:10:46
Data / ETL Engineer,DRINKS,3.6 out of 5,"Los Angeles, CA 90025","['Become a member of agile development team', 'Actively participate in daily code review sessions', 'Understand and implement best practices in managing enterprise data including master data, data quality, lineage and security', ""Interface with the department's business analysts, developers, data architects and system administrators on daily support tasks and project-driven activities"", 'Share best practices and be open to alternative technology implementations', 'Work with business team and engineering teams to design and implement large data processing flows', 'Take on special projects as necessary', 'Ability to collaborate with engineering team as well as work independently on projects', 'Exceptional time management and ability to problem solve under pressure', 'Strong understanding of data and analytics solution architecture, including experience with Big Data, Relational databases, streaming and batch data processing', 'Strong verbal and written communication skills and excellent attention to detail', 'Flexibility in work schedule as needs arise', 'Energetic, enthusiastic and self-motivated with a strong work ethic', 'Matillion ETL', 'Ruby / Rails', 'Linux scripting', 'MySQL', 'Redshift', 'Familiarity with AWS; S3, Lambda', 'Tableau report writing experience', ""Bachelor's Degree in Computer Science or equivalent"", 'Experience at a startup or similar fast-paced tech environment', 'A passion for wine!']",2020-08-08 13:10:46
"Data Engineer, Enterprise Data Services",New York City MAYORS OFFICE OF CONTRACT SVCS,N/A,"Manhattan, NY 10007","['Collaborate with the other members of the integration team in the design, implementation and documentation of solutions for daily issues/support, release management, and new projects', 'Assist in architecting, mapping, developing, and testing data movement to data warehouses (Redshift and SQL Server), with emphasis on the ETL process', 'Develop, document, and execute SQL/stored procedures/server scripts as needed to support ETL code', 'Determine ETL requirements and assist with production, setup, and execution of migrations', 'Work closely with BI and PASSPort teams on ETL development efforts including analysis and design of integration solutions, data and reporting needs of internal and external stakeholders, and enhancements', 'Identify and resolve data, technical issues and mediate business impact', 'Collect requirements, design, build and test reports and dashboards across applications and programs', 'Perform ad hoc analysis as required', 'Excellent writing and communication skills', 'Knowledge and interest in computer systems and the latest technologies', 'Familiar with AWS ecosystem including S3, Redshift databases, Lamda, EC2, Matillion and necessary supporting activities', 'The ability to learn new technologies quickly', 'Ability to write complex procedures using SQL (i.e. T-SQL, PL/pgSQL, etc.)', 'Experience in generic object-oriented languages (i.e. C#, Java, etc.)', 'Experience in scripting languages (i.e. Python, PowerShell, etc.)', 'Experience in ETL tools (i.e. Matillion, SSIS, Informatica, ets.)', 'Knowledge of testing tools and techniques and executing test scripts to test performance of ETL procedures', 'Significant experience in development, maintenance, and enhancements of ETL Mappings, Work-flows, and processes', 'Excellent analytical, organization, presentation and facilitation skills; ability to handle multiple tasks under tight deadlines', 'Familiarity with New York City’s data share platforms, including Open Data (DOITT’s DataShare) (FMS, PIP, APT).', 'Working knowledge of database back-end systems (i.e. AWS Redshift, SQL Server, Oracle, PostgreSQL).', 'Familiarity with Data Warehouse concept (Kimball), fact tables, slowly changing dimensions types.', 'Past utilization of code repositories (i.e. GitHub, GitLab or AWS CodeCommit).', 'Analyze user requirements and convert requirements to design documents.', 'Multi-task and change from one task to another without loss of efficiency or composure.', 'Development of technical specifications and plans.']",2020-08-08 13:10:46
Data Engineer,Vydia,N/A,"Holmdel, NJ 07733","['Ensuring the availability and timely delivery of data, company-wide', 'Modeling new data sets and crafting all new ELT workflows and pipelines', 'Lead the orchestration of the workflows and contribute strongly to infrastructure decisions', 'Improving on and monitoring of existing pipelines and oversight of our ELT workflow', 'Maintaining a single version of truth for our data and working with others to implement continuous integration (CI) data quality tests', 'Mentoring and guiding your junior colleagues and leading with vision, and with respect to the company’s data strategy', 'You are a Python pro and have regularly used AWS or Google Cloud Platform to manage data and move it between applications', 'Do you love APIs? When you encounter a new one, do you study it inside and out and learn every corner of it, as though you designed it yourself?', 'Working with deeply-nested, complex JSON is a fun day at the office for you.', 'You can articulate the merits and pitfalls of the different approaches in designing a pipeline.', 'You are passionate about data quality control and know how and where to anticipate potential errors.', 'Working “in the cloud” is not a point of distinction for you, it is a given.', 'You understand what it means to work at a tech startup. Hopefully, this is what excites you more than anything else about working here.', 'You intuitively know how to extract value and insights from data.', 'You love the idea of building the data scene in NJ and being a leader in this community.', 'You have orchestrated workflows using Airflow and are familiar with the challenges and how to overcome them.']",2020-08-08 13:10:46
Client & Data Test Engineer,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Job', 'Company', 'Comfortable and adaptable in a fast-paced environment.', 'Strong analytical, problem solving and creative thinking skills.', 'Excellent verbal and written communication.', 'Strong commitment to technical quality assurance as a key part of the software development cycle. Willingness to work cross-functionally.', 'Results-oriented, persistent, and meticulous.', 'Experience writing automation using Python, JavaScript scripting and user-level automation for iOS.', 'Experience with Spark, Hadoop, Kafka or other distributed systems is a plus.', 'Experience in developing and verifying Spark/Map Reduce jobs is a plus.', 'Familiarity with Objective-C or Swift is a plus.', 'Knowledge in SQL, CSS, HTML, JSON a plus.']",2020-08-08 13:10:46
Software Development Engineer - AWS - Fully Virtual,"Amazon Web Services, Inc.",3.6 out of 5,Remote,"['Job', 'Company', '5+ years of non-internship professional software development experience with at least one modern language such as Java, Python or Node including object-oriented design', '1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems', 'Implement best practices in modern software engineering: design, implementation, testing, version control, documentation, deployment, monitoring and operations', 'Write high quality code that is robust and can be delivered and maintained by customers', 'Build flexible systems choosing simple, straightforward solutions over more complex ones', 'Possess self-drive to dive deep and maintain progress even in the face of ambiguity and imperfect knowledge (avoid “analysis paralysis”)', 'Encourage and support knowledge-sharing within team and external groups', 'Communicate clearly both verbally and in writing, within team and external groups', 'Actively participate in hiring and mentoring the very best', 'Obtain/maintain AWS Certifications', 'Occasional customer travel (<20%)', 'Can potentially work remotely (can live within 2 hours of Amazon/AWS office).', 'Effective verbal and written communication skills', 'Proficiency in design and analysis of algorithms and data structures that will operate at potentially global scale.', 'Proficiency in the DevOps style of software deployment', 'Proficiency in developing software in a cloud-native environment', 'Knowledge of Application Security principles and how they impact development and deployment of applications.', 'Experience handing off and supporting maintainable code artifacts', 'Experience in an agile development environment', 'Experience with Cloud Operational Excellence practices', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-08-08 13:10:46
Data Engineer (Remote),PlayQ,N/A,California,"['Build and manage efficient and reliable real-time data pipelines from disparate data sources', 'Design, develop and launch data ingestion and storage systems with high availability and reliability that can scale', 'Drive the advancement of data infrastructure by developing and implementing underlying logic and structure for how data is set up, cleaned and stored', 'Take an integral role in designing and implementing a data lake strategy', 'Build and manage a universal semantic layer over the data lake', 'Architect, launch and manage automated extraction & transformation processes', 'Build scalable data aggregation layer from queues and batches of data for data visualization', 'Collaborate with development teams on design, architecture, and expansion of infrastructure', 'BS from an accredited university in Computer Science, Engineering, Math or related field', '4-5 years of experience in building data pipelines, data architecture, data modeling & data governance', 'Proficient working with SQL/NoSQL databases and MPP/columnar data warehouse solutions (Redshift, BigQuery, Snowflake etc.)', 'Experience with AWS environments: Redshift, EC2, Data Pipeline, S3, RDS, Glue, Spectrum, Dynamodb, Lambda', 'Proficient working with Python, bash or other scripting languages', 'Must have experience working with large data sets', 'Experience working in the mobile gaming industry', 'Competitive compensation and equity options', 'Comprehensive medical, dental, vision, life and long term disability insurance', 'Flexible time off', '401K plan with company match', 'Stocked kitchen with free snacks and beverages of your choice', 'Catered weekly team lunches', 'Brand new penthouse office space equipped with outdoor patios offering beachfront views', 'Monthly team outings and volunteer opportunities', ""Help build and support awesome GAMES. For a living! Who doesn't love games?""]",2020-08-08 13:10:46
R&D Leadership Development Program,Johnson & Johnson Family of Companies,4.2 out of 5,"West Chester, PA","['You will have opportunities to participate and/or lead in rotational assignments encompassing entire project or a large portion of a major project. This may include resolving advanced materials, process, inspection/testing or procedural approaches to advance a medical device through the pipeline process into full R&D, and potentially into commercialization.', 'Support of products’ design development, manufacturing and commercialization, leveraging technical expertise to anticipate and proactively address challenges and risks.', 'Increase the productivity of product’s design utilizing CAD, improve the quality of projects, improve communications through documentation, and to create a database for manufacturing.', 'Engineer capabilities required to develop and deliver automated medical devices - including requisite instruments, advanced imaging, and user interface / experience.', 'Pursue a number of internal developmental training programs as well as externally recognized qualifications such as Process Design Excellence.', 'Opportunity to work in a fast-paced cross functional, technologically advanced corporate environment in a program focused on developing individual engineers capable of pursuing careers across medical device businesses and high-volume manufacturers.', 'Currently enrolled in an Engineering Graduate Program (Master’s Degree or PhD) graduating by June 2021.', 'The following engineering disciplines or specialties are preferred: Mechanical, Robotics, Electrical, Computer, Systems, Software, Materials Science, Biomedical and Computer Science.', 'The following concentration fields and/or skills are strongly preferred: Machine Learning, IoT, Embedded Software, Deep Machine Learning, Prototyping, Robot Design, Systems Reliability, Firmware and hardware integration.', 'A minimum GPA of 3.3 is strongly preferred.', 'You must have the ability to work closely with technical and non-technical personnel and have excellent communication skills with the ability to influence others.', 'You must have the ability to demonstrate excellent problem-solving skills, intellectual curiosity and a dedicated approach to achieving success.', 'Validated leadership experience through extra-curricular activities, employment and/or internship experiences is required. R&D internship highly preferred.', 'Ability to relocate anywhere in the United States as required by the program’s rotations – mandatory requirement.']",2020-08-08 13:10:46
R&D Leadership Development Program,Johnson & Johnson Family of Companies,4.2 out of 5,"West Chester, PA","['You will have opportunities to participate and/or lead in rotational assignments encompassing entire project or a large portion of a major project. This may include resolving advanced materials, process, inspection/testing or procedural approaches to advance a medical device through the pipeline process into full R&D, and potentially into commercialization.', 'Support of products’ design development, manufacturing and commercialization, leveraging technical expertise to anticipate and proactively address challenges and risks.', 'Increase the productivity of product’s design utilizing CAD, improve the quality of projects, improve communications through documentation, and to create a database for manufacturing.', 'Engineer capabilities required to develop and deliver automated medical devices - including requisite instruments, advanced imaging, and user interface / experience.', 'Pursue a number of internal developmental training programs as well as externally recognized qualifications such as Process Design Excellence.', 'Opportunity to work in a fast-paced cross functional, technologically advanced corporate environment in a program focused on developing individual engineers capable of pursuing careers across medical device businesses and high-volume manufacturers.', 'Currently enrolled in an Engineering Graduate Program (Master’s Degree or PhD) graduating by June 2021.', 'The following engineering disciplines or specialties are preferred: Mechanical, Robotics, Electrical, Computer, Systems, Software, Materials Science, Biomedical and Computer Science.', 'The following concentration fields and/or skills are strongly preferred: Machine Learning, IoT, Embedded Software, Deep Machine Learning, Prototyping, Robot Design, Systems Reliability, Firmware and hardware integration.', 'A minimum GPA of 3.3 is strongly preferred.', 'You must have the ability to work closely with technical and non-technical personnel and have excellent communication skills with the ability to influence others.', 'You must have the ability to demonstrate excellent problem-solving skills, intellectual curiosity and a dedicated approach to achieving success.', 'Validated leadership experience through extra-curricular activities, employment and/or internship experiences is required. R&D internship highly preferred.', 'Ability to relocate anywhere in the United States as required by the program’s rotations – mandatory requirement.']",2020-08-08 13:11:30
Big Data Engineer,Huntington Ingalls Industries Inc.,3.8 out of 5,"Springfield, VA 22150","['Designs, modifies, develops, writes and implements software systems.', 'Participates in software and systems testing, validation, and maintenance processes through test witnessing, certification of software, and other activities as directed.', 'Provides support to senior staff on projects/programs. Familiar with standard concepts, practices, and procedures within a variety of fields related to the project. This position takes direction from senior technical leadership.', 'Designs, develops, documents, tests and debugs applications software and systems that contain logical and mathematical solutions.', 'Conducts multidisciplinary research and collaborates with equipment designers and/or hardware engineers in the planning, design, development, and utilization of electronic data processing systems for product and commercial software.', 'Determines computer user needs; analyzes system capabilities to resolve problems on program intent, output requirements, input data acquisition, programming techniques and controls; prepares operating instructions; designs and develops compilers and assemblers, utility programs, and operating systems.', 'Ensures software standards are met.', 'COMPTIA Security+ certification or CISSP certification', 'Proficiency in two or more of the following programming languages: C#, Java, .NET, Python, Perl, Ruby, or similar', 'Familiarity with current Agile methods', 'Proficiency with the following:Multiple operating systems including: UNIX, Linux, Windows, Cisco IOS, etc.Machine learning, data mining, and knowledge discoveryAnalytic algorithm design and implementationETL processes; including document parsing techniquesNetworking, computer, and storage technologiesUsing or designing RESTful APIs, SOAP, XMLDeveloping large cloud software projects, preferably in Java, Python or C++ languageJava/J2EE, multithreaded and concurrency systemsMulti-threaded, big data, distributive cloud architectures and frameworks including Hadoop, MapReduce, Cloudera, Hive, Spark, Elasticsearch, etc. for the purposes of conducting analytic algorithm design and implementationNoSQL database such as Neo4J, Titan, Mongo, Cassandra, and hBaseAWS Services (EC2, Network, ELB, S3/EBS, etc.)Processing and managing large data sets (multi PB scale)Web services environment and technologies such as XML, KML, SOAP, and JSONProficiency in trouble-shooting in very complex distributed environments including following stack traces back to code and identifying a root cause', ""9 years relevant experience with Bachelors; 7 years relevant experience with Masters. An additional 4 years of specific job experience with a HS diploma may be substituted for the Bachelor's degree requirement for this job. This experience is in addition to the relevant years of experience listed with the job's education requirements."", 'Clearance: Must possess and maintain a TS/SCI clearance', 'Education – Masters Degree in Computer Science or related field (e.g. Statistics, Mathematics, Engineering) – but a technical BS degree will suffice', 'Distributed computing-based certifications', ""Proficiency with the following:Management/tracking utilities such as Jira, Redmine, or similarRunning Internet facing or Service Level Agreement (SLA'd) auto-deployed environmentsReal-time media protocols (Real-time Transport Protocol (RTP), Secure Real-time Transport Protocol (SRTP))Data transfer systems such NiFiText processing: NPL, NER, entity retrieval (e.g. Solr/Lucene), topic extraction, summarization, clustering, etc.Certification from an Agile certified institute, International Consortium for Agile, Scaled Agile Academy, Scrum Alliance, Scrum.org, International Scrum Institute, ScrumStudy, Project Management Institute - Agile Certified Practitioner, or similar XP/Scrum certification or training is desiredSupport to SOF; Previous experience with technology, intelligence and cyber under the umbrella of USSOCOM""]",2020-08-08 13:11:30
Lead Data Engineer,Guru,N/A,"Gaithersburg, MD 20878","['Ability to solve problems with data & superb attention to data accuracy', 'Experience with AWS Big Data solutions & tools', 'Proficiency with AWS environments and implementation of AWS data tools (RedShift, Dynamo, RDS, Migration Services)', 'Hands-on experience working with a variety of data repository models including Data Marts, Data Warehouses and Data Lakes', 'Experience integrating data across many different systems & data sources including both structured and unstructured data', 'Demonstrated experience with both SQL and NoSQL database tools', 'Hands-on experience in all aspects of data warehousing and schema', 'Proficiency in designing efficient and robust ETL workflows', 'Working with cloud computing environments and tune solutions to improve performance and end-user experience', 'Experience working collaboratively with cross-functional agile teams', 'Contribute to group knowledge sharing platforms and best practices', 'Critical thinking, willingness to ask questions and help determine the best course for solutions', 'Ability to complete tasks independently', 'Strong interpersonal skills to build relationships and communicate effectively with multiple personality types', 'Demonstrated ability to work effectively in a fast-paced, complex, and dynamic business environment', 'Enjoy being challenged and to solve complex problems daily', 'Proven ability to support a strong member/customer service culture', 'Demonstrated and dynamic analytical/ problem-solving skills', 'Continuous improvement mindset', 'Ability to understand the big picture', 'BA/BS data analytics/computer science/information or similar degree', 'Four years of job-related experience is preferred', 'Building reporting semantic layers and BI dashboards are preferred', 'SQL Server Integration Services is preferred', 'Experience with AWS, DOMO, Tableau, Microsoft Power BI, Alteryx Designer, and Microsoft Azure preferred', 'Musical Background', 'Love of Video Games', 'Love of Sushi', 'Sense of Humor', 'Ping Pong skills']",2020-08-08 13:11:30
Data Engineer,Logistics Management Institute,3.9 out of 5,"Tysons, VA","['Design, develop, test and manage the overall data architecture.', 'Develop, construct, test and maintain relational and non-relational databases.', 'Build data pipelines to curate and collect the data from a variety of traditional and non-traditional sources: extract data from sources, transform and integrate data in line with existing data, and load data into data stores for access by others.', 'Process, clean, and verify the integrity, accuracy, completeness, and uniformity of data.', 'Assess the effectiveness and accuracy of new data sources and data gathering techniques.', 'Perform data system operations associated with data acquisition, data maintenance, maintaining and updating metadata, and other data and information services for stakeholders.', 'Build data and analytics tools that will offer deeper insight into the pipeline, allowing for critical discoveries surrounding key performance indicators and customer activity.', 'Collaborate with systems architects, data scientists, and analysts to direct and optimize the flow of data within the pipeline and ensure consistency of data delivery and utilization across multiple projects.', 'Give recommendations and implement ways to improve data reliability, efficiency, and quality: evaluate, compare and improve the different approaches including design patterns innovation, data lifecycle design, data ontology alignment, annotated datasets, and elastic search approaches.', 'Document all processes, models and activities.', ""Bachelor's Degree or higher in Computer Science, Information Technology, or software development-related field from an accredited institution. Additional 5 years of experience can be substituted for the bachelor's degree requirement."", '5 Years or higher in experience.', 'Data, storage, and compute tools on AWS, such as EC2, RDS, Redshift, and Glue.', 'Know basics of algorithms and data structures, distributed computing, and stream-processing solutions, including Spark.', 'Advanced SQL knowledge and experience working with relational databases, as well as working familiarity with a variety of databases (e.g., NoSQL, graph).', 'Experience building and optimizing data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Knowledge of ETL tools, data APIs, data modeling, and data warehousing solutions.', 'R, Python, Ruby, C++, Perl, Java, SAS, SPSS, and Matlab.', 'Experience writing server-side APIs and using client-side APIs', 'Demonstrated ability to work with enterprises to develop processes that support data transformation, data structures, metadata, dependency and workload management.', 'Comfort working in a dynamic environment with several ongoing concurrent projects; able to multitask, prioritize, and manage time effectively.', 'Creative problem solver who thrives when presented with a challenge; able to analyze problems and strategize for better solutions; strong problem-solving skills with an emphasis on production for re-use.']",2020-08-08 13:11:30
Solutions Engineer,Relode1,N/A,"New York, NY","['2-4 years of Solution Engineering experience', '2+ years of Python Scripting Language', 'Familiarity with data structures, relational databases, cloud infrastructure', 'Newer Team, so lots of Internal Growth Opportunities', 'Lots of autonomy in this role', 'Great company culture and atmosphere, supportive, always helping one another', 'Must be currently authorized to work in the United States on a full-time basis', 'Work autonomously and creatively in navigating and overcoming obstacles that you encounter', ""Develop software to integrate with client's electronic health record (EHR) data"", 'Role based in New York City with occasional travel to client sites (~1 trip / quarter)', 'An opportunity to work on a platform that is scaling very rapidly with 200,000 engaged patients a day as of May 2020', 'A chance to join a high-growth company at an early stage', 'The ability to impact the growth of our company, we value all comments and suggestions', 'Transparency across teams and interaction with multiple departments', 'Competitive pay, employer-paid healthcare, stock options', 'Daily team lunch and unlimited healthy snacks at our NYC office', '401(k)', 'Health Insurance', 'Paid Time Off', 'Day shift', 'Solution Engineering: 2 years (Required)', 'data structures, relational databases, cloud infrastructure: 1 year (Preferred)', 'Python Scripting Language: 2 years (Required)', 'New York, NY (Preferred)', 'United States (Preferred)']",2020-08-08 13:11:30
Big Data Engineer,Kairos Technologies,N/A,"Dallas, TX","['Health Insurance', 'Temporarily due to COVID-19']",2020-08-08 13:11:30
Data Engineer II,Microsoft,4.2 out of 5,"Redmond, WA","['Design, develop, and maintain data pipelines for real-time/batch analysis, reporting, optimization, data collection, and related functions.', 'Build and Maintain data processing infrastructure that support complex analysis across our data science, product, and experimentation teams.', 'Evaluate and propose the best tooling and processes for data access and analysis.', 'Use large data sets to resolve major business and functional issues while improving data reliability, efficiency and quality.', 'Ensuring security, privacy and compliance for all data assets.', 'Work iteratively.', 'Communicate effectively, both written and verbal, with technical and non-technical cross-functional and geographically distributed teams', 'Collaborate with Data Scientists and Applied Scientists', '3+ years relevant industry experience designing data models and ETL pipelines that are secure, testable, and modular.', 'Experience working with cloud infrastructure (at least one of Azure, AWS, GCP)', 'Experience with distributed computing frameworks (e.g. Spark, Hadoop, Flink)', 'Experience working with Data Scientists and Applied Scientists', 'Development Expertise in at least one programming language (Java, .NET, Python).', 'Experience in designing and executing data pipelines using GDPR and private data', 'Promote a culture of self-serve data analytics by minimizing technical barriers to data access and understanding.', 'Ability to communicate well with users, partner teams and senior management to collect requirements, explain data collection decisions and create data engineering strategy', 'BS or MS degree in Computer Science or a related technical field', 'Hands-on experience in writing complex, highly-optimized SQL queries across large data sets', 'Experience in data visualization and dashboard design including tools such as Tableau, PowerBIetc', 'Stay current with the latest technology and communicate your knowledge throughout the team']",2020-08-08 13:11:30
Data Engineer,Rogers Behavioral Health,3.1 out of 5,"Oconomowoc, WI","['Combined and clean data from multiple different systems.Prepare data for prescriptive and predictive modeling', 'Develop, construct, test and maintain data architectures.Ensure architecture will support the requirements of the organization.Identify valuable data sources and automate collection processes.', 'Develop data set processes for data modeling, mining and production.Increasing data accessibility and fostering data-driven decision making across the organization.Implements processes and systems to monitor data quality, ensuring data is always accurate and available for individuals and processes that depend on it.', 'Propose solutions and strategies to business challenges.Recommend ways to improve data reliability, efficiency and quality.Engage in independent research as well as provide recommendations and implementation of new processes and solutions to efficiently support the department goals.Discover opportunities for data acquisition.', 'Demonstrates mastery with Rogers Outcomes Assessment System (ROAS) and relevant Cerner applications.Assisting with customer support to both employees and patients utilizing ROAS.Independently engages in learning opportunities and certifications to enhance knowledge of the usage, function and technical build of assigned solutions or solution family.', 'Protects subject confidentiality by:Exercising safe data practices.Protecting patient privacy during follow-up data collection.Securing safe storage of patient-sensitive documents.Assuring appropriate disposal of sensitive documents.', 'When assigned, participate in hospital, committees, performance improvement team meetings and team projects, as directed by:Demonstrating punctuality and preparedness.Demonstrating effective communication skills and good organizational skills.Contributing in a positive, solution-focused manner.', ""When assigned, participate in events or projects with the Rogers Operating System (ROS) by:Gaining understanding of the Rogers Improvement System (ROS).Applying continuous improvement initiatives to your department's activities.Participating and/or creating RIS events that lead to improvement in other Hospital areas.Educating and involving self in the system and department's continuous improvement plans."", 'Promote department goals and mission of the Hospital:Communicate goals to fellow staff workers.Demonstrate measurable goal achievement.Maintain department policies and procedures.Include requirements and guidelines from external agencies (i.e., Joint Commission, State of Wisconsin).Educate new staff to regulations or requirements of those functions that relate to their areas or departments, as directed.Demonstrate acceptance and training of student interns in the department, as directed.', 'Demonstrate understanding of quality initiatives:Involve self in the learning and application of standards relevant to the Clinical Effectiveness department.Participate in inservices/seminars and other meetings to increase involvement and awareness of quality initiatives.Involve self in the education of other disciplines regarding respective quality initiatives.Engage in independent research to provide recommendations and develop solutions related to department projects.', 'Strong interpersonal skills needed, due to interaction with professional staff and patients.', 'Must be able to work independently and complete assignments within specified timeframes.', 'Must be highly proficient in verbal and written communication skills.', 'Position requires walking, sitting and standing. Lifting is moderate; must be capable of lifting a minimum of twenty (20) pounds. Reaching, handling, grasping and manual dexterity are necessary to operate various office equipment. Stooping, bending, kneeling and flexible movements required to work with orientation equipment.', 'Verbal and hearing ability required to interact with patients and employees. Numerical ability required to maintain records and operate computer.', 'Be able to plan, control and direct all aspects of employee relations. Tact required to deal effectively with staff. Logical thinking and discretion required to make decisions in initiating and implementing policies and procedures and standards.', 'Must be able to read and communicate through written, verbal and auditory skills and abilities.', 'Be physically/mentally able to perform job duties as verified by a physical exam by a licensed physician, per post-employment physical.', 'Masters degree in computer science or related field required.', 'Medical or mental health research experience preferred.', 'Requires working at a highly technical, analytical and detail-oriented level.', 'Exceptional problem-solving skills with an emphasis on product development.', 'Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.', 'Experience working with and creating data architectures and data pipelines.', 'Technical expertise with data models, data mining, and segmentation techniques.', 'Knowledge of advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.', 'Excellent written and verbal communication skills for coordinating across teams.', 'Experience with Microsoft applications including MS Forms, Power Automate and PowerBI.']",2020-08-08 13:11:30
Data Engineer,Shutterfly,3.8 out of 5,"Fort Mill, SC","['Design Extract-Transform-Load (ETL) Workflows for data migration from various sources to data warehouse using batch or incremental loading strategies.', 'Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.', 'Excellent understanding of development processes and agile methodologies', 'Document database design including data modeling, metadata and business process flow for the new business integration requirements.', 'Document technical ETL specifications for a data warehouse. Perform periodic code reviews and test plans to ensure data quality and integrity.', 'Strong analytical and interpersonal skills', 'Enthusiastic, highly motivated and ability to learn quick', 'Ability to work through ambiguity in a fast-paced, dynamically changing business environment', 'Ability to manage multiple tasks at the same time with minimum supervision', 'Bachelor’s degree from an accredited university or college in computer science.', '3+ years’ experience in the data warehouse space.', '3+ years’ experience working with large scale ETL systems (implementation and maintenance, CDC/Event-driven architectures).', '3+ years of experience building clean, maintainable, and well-tested code.', 'Experience dealing with large databases', 'SQL proficiency', 'Databases such as MemSQL, MySQL, Postgres', 'Bonus points for background in data science, analytics, or data mining', 'Experience in any of the following are preferred but not required: Spark, Dask, Jupyter', 'Excellent communication skills to collaborate with stakeholders at all levels of the company.', 'Proven ability to learn quickly, work independently, and adapt to change in a fast-paced environment', 'High-level written and verbal communication skills.']",2020-08-08 13:11:30
"iOS Engineer, Audio",The New York Times,4 out of 5,"New York, NY","['Belief in our mission: You have a passion for the news and for making the Times an indispensable daily destination for our readers.', 'Technical competency: You have deep knowledge of iOS frameworks and Swift, and keep up to date on changes in the frameworks, language and overall developer community.', 'Code cleanliness: You have an understanding of what makes code well structured, maintainable and flexible and strive to create a culture where quality code is valued.', 'User focus: You care deeply about how design, engineering and product decisions contribute to creating a seamless, engaging and enjoyable user experience.', 'You will create and maintain features using Swift.', 'You will contribute to app architectural decisions technical roadmap and timeline estimations.', 'You will participate in technical discussions with backend developers and other owners of internal/external dependencies.', 'You will help promote standards in Swift development and delivery, and engage with the community of iOS developers at the Times.', 'Where applicable, you will integrate with broader New York Times iOS platform code, which may be at least partially written or have dependencies written in Objective-C.', 'You have an understanding of iOS design patterns, memory management and multi-threading.', 'You have experience working with audio or video (not required but a big bonus!).', 'You have hands-on iOS Swift experience, including writing unit tests, networking, data persistence and UI.', 'You have a good product sense and the vision to translate product goals into quality shippable code.']",2020-08-08 13:11:30
Data Engineer,KoreMinds LLC,N/A,"Columbus, OH",[],2020-08-08 13:11:30
Senior Data Engineer,AARG,4.5 out of 5,"Richmond, VA","['Build data pipeline frameworks to automate high-volume and real-time data delivery to our cloud platform', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies', 'Develop and enhance applications using a modern technology stack such as Java, Python, Shell Scripting, Scala, Postgres, Angular JS, React, and Cloud based data warehousing services such as Snowflake', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree; nice to have Accounting / finance business knowledge is a plus', '5+ years of experience building data pipelines and using ETL tools to solve complex business problems in an Agile environment', '5+ years of experience in at least one scripting language (SQL, Python, Perl, JavaScript, Shell)', '3+ year of experience using relational database systems (Snowflake, PostgreSQL, or MySQL)', '3+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink)', '3+ years of experience in big data technologies (MapReduce, Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', '3+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', 'Monday to Friday', 'Data: 3 years (Preferred)', 'United States (Preferred)', 'Likely', 'Yes', 'Fully Remote']",2020-08-08 13:11:30
Data Developer/Engineer,M&T Bank,3.6 out of 5,"Buffalo, NY","['Informatica tools: PowerCenter, MDM, Big Data Manager', 'Python', 'Java', 'Scala', 'Spark', 'Kafka', 'Hive', 'HBase', 'Databases: SQL, NoSQL, Postgres, Cassandra', 'AWS cloud services: EC2, EMR, RDS, Redshift', 'Stream-processing systems: Storm, Spark-Streaming', 'Associates degree and 5 years’ systems analysis/application development experience, or in lieu of a degree, a combined minimum of 7 years’ higher education and/or work experience', 'Experience with Agile Methodology', 'An ability to build out data products & product enhancements from idea through to launch', 'Strong collaboration with technology partners and customers on feature requirements and prioritization', 'A team player mindset with an ability to thrive and effectively communicate in a fast-paced, constantly evolving environment']",2020-08-08 13:11:30
Entry Level Federal Associate Data Science,IBM,3.9 out of 5,"Washington, DC 20001","['Implement and validate predictive and prescriptive models, create and maintain statistical models with a focus on big data', 'Incorporate a variety of statistical and machine learning techniques in your projects', 'Write programs to cleanse and integrate data in an efficient and reusable manner', 'Use leading edge and open-source tools such as Python or R combined with IBM tools and our AI application suites', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors', 'Communicate with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions', 'Evaluate modelling results and communicate the results to technical and non-technical audiences', 'Ability to look at things differently, debug, troubleshoot, design and implement solutions to complex technical issues', 'Strong technical and analytical abilities, a knack for driving impact and growth', 'Basic understanding of statistical programming in a language such as R, Python, SAS, SPSS, Hadoop, Spark, Tableau or D3 and exposure to Machine Learning and Big Stack Development', 'Proficiency in at least one computer programming language is a plus such as Java, C++, JavaScript, Node, JSs', 'Basic understanding of Cloud (AWS, Azure, etc.)', 'Ability to thrive in a team-based environment', 'Excellent verbal and written communication skills', 'Work or internship experience using data science tools in a corporate environment', 'Interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'Willingness to relocate to the Washington, DC metropolitan area', 'Many jobs within GBS Federal Sector require U.S. citizenship and/or security clearance because of government or contract requirements. If you are not a U.S. citizen or are unable to obtain security clearance, there may be limited work opportunities for you, which may affect your continued employment at IBM.', 'Bachelor’s Degree from an accredited 4-year institution coupled with internship, work, and/or project experience, which will provide the analytical and technical acumen that translates to an entry level consulting role.', 'While many Federal projects are located in the Washington, DC area and have limited travel, candidates must be willing and able to travel up to 100% of the time, if project/business needs require.']",2020-08-08 13:11:30
Active Drive Assist Data Analytics Engineer,Ford Motor Company,4.2 out of 5,"Dearborn, MI","['Support Sign-off of Feature Level performance for a given vehicle via data exploration and analysis of Active Drive Assist Features.', 'Develop and refine scripts, reports, and dashboards for ensuring accurate feature-level performance across a variety of environmental and cross-carline noise factors.', 'Support design verification plans by analyzing resulting data and delivering reports and/or dashboards showing compliance with internal and external requirements.', 'Support and coordinate root-cause analysis with internal and external suppliers to ensure delivered system thrills our customers with the user experience via data-driven reports, signal-level traces, or other mechanisms.', 'Develop innovative methods for analysis of Active Drive Assist Features & Functions using state of the art tools and big-data approaches.', 'Bachelor’s Degree in Electrical, Mechanical, Aerospace, Controls, Computer or Software Engineering or Computer Science', '1+ year diagnostics software quality', 'Experience with ANY of the following areas: Adaptive Cruise Control, Blind Spot Systems, Lane Keeping or Lane Centering Systems.', 'Experience with GPS / GNSS systems including inertial navigation system validation.', 'Understanding of embedded hardware and software design.', 'Understanding of Kalman filtering, vehicle dynamics, linear & nonlinear control methods.', 'Software engineering & algorithm development experience. Any development time in any language (C, C++, Python, Matlab, etc.)', 'Experience with MobilEye EyeQ technology', 'Developing and conducting laboratory and vehicle tests.', 'Developing reports and dashboards using Excel, Tableau, QlikView, Alteryx or other industry standard tools.']",2020-08-08 13:11:30
Active Drive Assist Data Analytics Engineer,Ford Motor Company,4.2 out of 5,"Dearborn, MI","['Support Sign-off of Feature Level performance for a given vehicle via data exploration and analysis of Active Drive Assist Features.', 'Develop and refine scripts, reports, and dashboards for ensuring accurate feature-level performance across a variety of environmental and cross-carline noise factors.', 'Support design verification plans by analyzing resulting data and delivering reports and/or dashboards showing compliance with internal and external requirements.', 'Support and coordinate root-cause analysis with internal and external suppliers to ensure delivered system thrills our customers with the user experience via data-driven reports, signal-level traces, or other mechanisms.', 'Develop innovative methods for analysis of Active Drive Assist Features & Functions using state of the art tools and big-data approaches.', 'Bachelor’s Degree in Electrical, Mechanical, Aerospace, Controls, Computer or Software Engineering or Computer Science', '1+ year diagnostics software quality', 'Experience with ANY of the following areas: Adaptive Cruise Control, Blind Spot Systems, Lane Keeping or Lane Centering Systems.', 'Experience with GPS / GNSS systems including inertial navigation system validation.', 'Understanding of embedded hardware and software design.', 'Understanding of Kalman filtering, vehicle dynamics, linear & nonlinear control methods.', 'Software engineering & algorithm development experience. Any development time in any language (C, C++, Python, Matlab, etc.)', 'Experience with MobilEye EyeQ technology', 'Developing and conducting laboratory and vehicle tests.', 'Developing reports and dashboards using Excel, Tableau, QlikView, Alteryx or other industry standard tools.']",2020-08-08 13:12:15
"Data Engineer, Advertising Analytics",Amazon Advertising LLC,3.6 out of 5,"New York, NY","['Job', 'Company', '3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', 'Bachelor’s degree or higher in an analytical area such as Computer Science, Physics, Mathematics, Statistics, Engineering or similar.', 'Proficiency in one or more of the following languages - Python, Java, R or similar.', 'A real passion for technology. We are looking for someone who is keen to demonstrate their existing skills while trying new approaches.', 'Ability to communicate effectively and work independently with little supervision to deliver on time quality products', 'Design, develop, and maintain data pipelines to enable faster business analysis and reporting.', 'Manage automated unit and integration test suites to ensure data correctness and consistency.', 'Maintain source code repository of scripts (SQL, Python/R) and other products (dashboards, reports, etc.).', 'Partner with our product managers and finance teams to publish datasets for measuring key performance indicators', 'Understand and document business processes and design a path to incorporate new initiatives into existing solutions (or build new ones where required)', 'Graduate degree in Computer Science, Engineering or related technical field.', 'Understanding of Big Data technologies and solutions (Spark, EMR, Hive, S3, Redshift, etc.)', 'Understanding of Amazon Web Services (AWS) technologies', 'Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.']",2020-08-08 13:12:15
Data Engineer,Kitcheck,N/A,"Washington, DC","['Opportunities to solve problems of scale, debt and security to redefine what’s possible in medication intelligence', 'Strong voice in what we work on, how it works, and how it is built', 'Room to be creative and choose your own path', 'Trust in your sense of ownership', 'Dedicated budget for training and career development', ""Coworkers who you'll learn from, who will push you and who are looking to learn from you"", 'Define, design, implement and maintain data architectures and infrastructure that unify our core products and our understanding of our customers and their medication workflows', ""Dive deep into how the FDA, our nation's healthcare systems and drug manufacturers interface and communicate at the medication level"", 'Develop and champion good data stewardship and governance practices across the company and work closely with Security to insure customer assurance', 'Design and support customer facing data products both with API and interactive components.', 'Ability to communicate clearly with all audiences about data architecture and implementations, from engineering to product, sales to customer', 'Strong written and analytical skills', 'Proficiency in SQL, ETL processes, denormalization concepts and a programming language', 'Strong bias for action, documentation and education', 'Proficiency implementing monitoring instrumentation, triaging incidents, resolving customer issues, and continuous product improvement', 'Ability to work through ambiguity with open communication and autonomy.', 'Experience with SaaS data management and warehousing platforms and tools (AWS preferred)', 'Any code, writing or projects that are public or shareable demonstrating experience or understanding of how data architecture excellence is key to delivering great products', 'Experience working with data in a regulated industry and working around systemic data quality issues.', 'Competitive salary', 'Time off when you need it – unlimited vacation days!', 'Generous insurance coverage', '401k program with a company match', 'Employee stock options', 'Fun, collaborative culture with lots of employee activities (and snacks)!']",2020-08-08 13:12:15
Data Engineer - Healthcare (s),Keyseries,N/A,"Albany, NY","['ETL/ Quality/ MDM/ Harmonization/ Masking/ De-Lineanation/ Profiling, etc.', '3-5 years’ experience in OLTP/OLAP data Modeling / DB architecture, including a working knowledge of various business process and system modeling tools including: data flow diagrams, process models, ER diagrams, dimensional data models, context models, event modeling, state modeling, process decomposition, and use case scenarios']",2020-08-08 13:12:15
Staff Engineer - Data Science,Harvard University,4.3 out of 5,"Boston, MA",[],2020-08-08 13:12:15
Data Engineer II,TeleTracking Technologies,4 out of 5,Remote,"['Writing, debugging, unit testing, and performance test code in the data access layer in accordance with TeleTracking standards.', 'As an agile team member, participate in code reviews, design reviews, etc.', 'Utilize domain driven techniques and design patterns to build and contribute to technical design.', 'Develop and maintain strong knowledge of implemented requirements and detailed application behaviors.', 'Assists in the development and training of SE I.', ""Bachelor's computer information technology, computer science, management required"", ""Master's preferred"", 'Strong understanding and familiarity working in the Linux operating environment.', 'Familiarity and experience executing several software development methodologies and life cycles preferred.', '5+ years of developing software using object-oriented or functional language experience5+ years of SQL', '2+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.)', '3+ years with document databases (e.g. MongoDB, Accumulo, etc.)', '3+ years of experience using Agile development processes (e.g. developing and estimating user stories, sprint planning, sprint retrospectives, etc.)', '2+ years of distributed version control system (e.g. git)3+ years of experience in cloud-based development and delivery', 'Familiarity with distributed computing patterns, techniques, and technologies (e.g. ESB)Familiarity with continuous delivery technologies (e.g. Puppet, Chef, Ansible, Docker, Vagrant, etc.)', 'Familiarity with build automation and continuous integration tools (e.g. Maven, Jenkins, Bamboo, etc.)', 'Familiarity with Agile process management tools (e.g. Atlassian Jira)', 'Familiarity with test automation (Selenium, SoapUI, etc.)', 'Good software development and Object Oriented programming skills.', 'Strong analytical skills and the ability to work with end users to transform requests into robust solutions.', 'Excellent oral and written communication skills.', 'Initiative and self-motivation to work independently on projects.']",2020-08-08 13:12:15
Senior Data Engineer,Bitwise INC,3.3 out of 5,"Renton, WA 98057","['IS Customer Experience team has been created with the purpose to define and develop internal teams’ Service Delivery KPIs to improve caregiver experience when contacting IS department and bring to light customer-impacting issues within IS.', 'The Data Engineer role provides strong technical and analytical support for advanced analytical projects supporting Providence IS End User Services team.', 'This person is directly involved in investigative design, data collection and data modelling, performing statistical analyses and communication of results using interactive visualization tools for interpretation and action by organizational leaders.', 'He/she is working independently or in collaboration with immediate team members in US, is a Subject Matter Expert on data governance methodologies and exercises sound judgment and expertise in selecting methods, techniques and evaluation criteria for obtaining results.', 'The work involved is usually highly important to the business objectives of the IS organization, is high-risk and/or time sensitive.', 'IS Customer Experience team has been created with the purpose to define and develop internal teams’ Service Delivery KPIs to improve caregiver experience when contacting IS department and bring to light customer-impacting issues within IS.', 'The Data Engineer role provides strong technical and analytical support for advanced analytical projects supporting Providence IS End User Services team.', 'This person is directly involved in investigative design, data collection and data modelling, performing statistical analyses and communication of results using interactive visualization tools for interpretation and action by organizational leaders.', 'He/she is working independently or in collaboration with immediate team members in US, is a Subject Matter Expert on data governance methodologies and exercises sound judgment and expertise in selecting methods, techniques and evaluation criteria for obtaining results.', 'The work involved is usually highly important to the business objectives of the IS organization, is high-risk and/or time sensitive.', 'Monday to Friday', 'Virtualization: 3 years (Preferred)', 'ssrs: 5 years (Preferred)', 'KPI: 5 years (Preferred)', 'Power BI: 5 years (Preferred)', 'Data governance: 3 years (Preferred)', 'Cloud Computing: 3 years (Preferred)', 'Data Engineer: 5 years (Preferred)', 'Tableau: 5 years (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 13:12:15
Quality Technician,Masco,3.4 out of 5,"Aston, PA","['Data entry for Quality Systems—inspections, material rejections, etc.', 'Inspection- incoming, in-process, final. measure material, parts or assemblies against a standard to ensure high quality parts are going to our customers.', 'Troubleshooting/material review with manufacturing engineer.', 'Standard work/process documentation, creation and updates as needed.', 'Record keeping/production log management for traceability of our products.', 'Quality stamp/operator number system upkeep- assign qa numbers to new employees and maintain stamp log.', 'Assist in process reviews with manufacturing engineer.', 'Assist with training as required & ensures procedures are being signed off once operators are trained.', 'Assist with time studies of our processes as required.', 'Audits as required- safety, 5s, kanban, etc.', 'Other documentation updates as needed- updating inspection criteria (aql level), etc.', 'Attending meetings with qa or other departments as required.', 'Assisting with gauge calibration as required.', 'Use hand tools and measuring tools regularly.', 'Assisting with continuous improvement efforts as required- Kaizen, projects, etc.', 'Proficient in MS Office suite, primarily Excel & Word.', 'Must be able to read Engineering Drawings.', 'Time management skills and multitasking ability.', 'Math skills including adding, subtraction, multiplication, and division.', 'Must be able to read and interpret documents such as Procedures, Engineering drawings and data sheets.', 'Must be able to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form.Ability to deal with problems involving several concrete variables in standardized situations.', 'Experience using hand tools and measuring tools.', 'Able to communicate well, verbally and in writing.', 'Able to work well with, and build/maintain positive relationships with other departments, co-workers, and vendors.', 'Able to stand and walk for long periods of time.', 'Able to sit for long periods of time', 'Able to work in front of a computer screen for long periods of time', 'Able to lift up to 50 pounds on occasion.', 'The noise level in the work environment can be in a loud manufacturing environment.']",2020-08-08 13:12:15
Staff Big Data Engineer (Analytics),Proofpoint,3.9 out of 5,"Annapolis, MD 21401","['Job', 'Company']",2020-08-08 13:12:15
Data Engineer,Brevco Services,N/A,"Baton Rouge, LA 70805","['AWS (S3, EMR, Glue),: 5 years (Required)', 'Shell Scripting: 3 years (Required)', 'SQL: 5 years (Required)', 'JSON, Postgres: 3 years (Required)', 'Python: 5 years (Required)', 'Baton Rouge, LA 70805 (Preferred)', 'United States (Required)']",2020-08-08 13:12:15
Data Engineer (Data Platform team),TripAdvisor,4 out of 5,"Lisbon, ME","['Solid experience developing complex ETL processes; these should include defining SLA, performance measurements and monitoring', 'Experience working with large datasets (terabyte scale and growing) and familiarity with various technologies and tooling associated with databases and big data.', 'Relational DB (MS SQL, PostgreSQL/MySQL).', 'Big Data (i.e. Hadoop, Hive, BigQuery, Snowflake)', 'Strong experience in OO or functional programming in Java/Python or equivalent language', 'Strong Software Engineering principles', 'Systems performance and tuning experience, with an eye for how systems architecture and design impacts performance and scalability', 'Knowledge of best practices around DB administration', 'Organized, self-motivator, great communicator and detail-oriented', 'Ability to work in a fast-paced and dynamic environment', 'Strong interpersonal skills, intense curiosity, and an enthusiasm for solving difficult problems.', 'Ability to work with end users to solve technical challenges', 'BS or MS in Computer Science or equivalent', '4+ years of general software development', 'Proven record of writing technical documentation and presenting at design reviews.', 'Proven record of technical leadership on medium to large size projects']",2020-08-08 13:12:15
Data Scientist I,Expedia.com,3.9 out of 5,"Seattle, WA 98119","['You will apply solid coding skills, strong analytical and innovative thinking, and Artificial Intelligence/ML expertise to quickly learn new domains and turn innovative ideas into working solutions', 'You will use Statistics and Data Science techniques to make decisions based on data', 'You will manipulate large data sets for business insights and drive solutions', 'You will utilize appropriate methods and approaches to develop practical solutions for the business', 'You will structure work, frame issues, and produce analyses that answer complex business questions in a pragmatic approach', 'You will communicate complex analytical topics in a clean & simple way to multiple partners and senior leadership', 'Your degree is in Data Science/ML or a related quantitative science & engineering field such as Artificial Intelligence, Engineering, Mathematics, Operations Research, Statistics, Computer Science, Physics, and Econometrics. MS required.', 'You understand the concepts and steps involved in working with real-world large data sets: from domain-specific problem understanding, data preparation, travel-related data processing, data integration, data structures for ML, data pipelining, data modeling, and AI/ML algorithms; strong data science knowledge and skills.', 'You have industry experiences on leveraging Statistics and Data Science on real-world large data sets', 'You have strong knowledge and experience in database technologies, including SQL, Hadoop, Teradata, AWS / Qubole.', 'You have knowledge on hands-on practice in Python and R.', 'You have proven knowledge of ML techniques such as Operations Research, Bayesian methods, clustering, decision trees, random forests, NLP, etc., excellent grasp of statistical concepts and methods.', 'You have strong passions for solving problems and finding patterns and insights within structured and unstructured data.']",2020-08-08 13:12:15
Big Data Engineer (mini. 5 yr. exp.),Smart IT Professionals,N/A,"Detroit, MI","['2 years of experience with a Hadoop distribution and ecosystem tools such as Hive, Spark, Nifi and Oozie', '2 years of experience developing batch and streaming ETL/ELT processes', '2 years of experience with relational and NoSQL databases, including modeling and writing complex queries', 'Proficiency in at least one programming language such as Python or Java', 'Excellent communication, analytical, and problem-solving skills', 'Experience with Linux system administration, Linux scripting and basic network skills', 'AWS experience', 'Temporarily due to COVID-19']",2020-08-08 13:12:15
Data Engineer,Maine Technology Users Group,N/A,"Portland, ME",[],2020-08-08 13:12:15
Data Scientist,HubSpot,4.4 out of 5,Massachusetts,"['Collaborate with product design and engineering to develop an understanding of needs', 'Research and devise innovative statistical models for data analysis', 'Enable smarter business processes—and implement analytics for meaningful insights', 'Keep current with technical and industry developments', 'Work as the lead data strategist, building models to improve internal efficiency and customer experience', 'Work closely with the engineering team to strategize and execute the development of data products', 'Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries', 'Implement analytical models into production by collaborating with software developers and machine learning engineers.', 'Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy', 'Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables', 'Analyze data for trends and patterns, and Interpret data with a clear objective in mind', 'Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems', 'Degree in statistics, applied mathematics, or related discipline', '5+ years experience in data science', 'Proficiency with data mining, mathematics, and statistical analysis', 'Advanced pattern recognition and predictive modeling experience', 'Advanced use of SQL, R, Python', 'Experience with machine learning models', 'Comfort working in a dynamic, research-oriented group with several ongoing concurrent projects', ""Master's degree in stats, applied math, or related discipline"", '2+ years of project management experience', 'Professional certifications']",2020-08-08 13:12:15
Support and Operations Engineer - Remote,Quadrotech,3.8 out of 5,"Fargo, ND","['Be the first point of contact for customers tickets', 'Confirm the client is under contract, incident details and contact information', 'Troubleshoot complex technical problems and work with various teams (development, consultancy, quality assurance) to consistently and efficiently deliver high quality solutions to customers’ issues', 'Provide technical consulting as part of a team that provides customer support', 'Be a trusted partner for the customer', 'Establish, develop and maintain good relationship with employees, internal partners, vendors, and customers', 'Propose and implement system enhancements that will improve the performance and reliability of the customers’ systems', 'Interface with customers regarding specific customer dependent projects or deliverables and status', 'Support and troubleshoot issues with customers via online meeting (remote sessions)', 'Provide operational support for the managed environment, including but not limited to patch management and proactive platform management', 'Keep accurate records of discussions or correspondence with customers', 'Provide reports from the managed environment to a customer', 'Improving customer service procedures, policies and standards for Customer Experience Team', 'Give feedback to product owners around possible product improvements', 'Be responsible for creation and update of knowledge base articles linked to our products', 'Passionate about helping others', 'Ability to diagnose and troubleshoot technical issues', 'Excellent problem-solving and communication skills', 'Ability to provide step by step technical help, both written and verbal', 'Ability to prioritize work and have exceptional time management skills', 'Ability to work together in a team', 'Demonstrable experience in customer support', 'Knowledge of Microsoft Exchange', 'Knowledge of Microsoft Office 365', 'Knowledge of Microsoft Azure', 'Knowledge of Microsoft SQL and experience with writing SQL queries', '20 PTO (Paid Time Off) Days to all employees', 'Additional one day paid leave on the Employee’s birthday', 'Private health insurance with the option of dental and vision coverage', '401k Plan with employer contribution', 'We support employees staying up to date (e.g. events, skills training)', 'LinkedIn Learning account for all employees with free access to learning courses', 'Flexible working hours', 'Hardship loan', 'Refer a friend bonus scheme']",2020-08-08 13:12:58
Data Engineer - BI,F. Schumacher & Co.,3.3 out of 5,"New York, NY 10001","['Architect, implement and operate stable, scalable and highly performance data pipelines that cleanse, structure and integrate data sets from source systems and third-party data structures into easily consumable data models', 'Migrate legacy reporting data structures to new Enterprise data platform.', 'Promote the usage of data engineering and data management best practices across the Enterprise.', 'Mentor & train team members on the appropriate usage of data marts models and other data sources used in analytics.', 'Organize and promote a Data Governance Committee to manage source system data structures and changes to those structures to ensure consistent business definitions and data quality.', 'BS/MS in Computer Science, Information Systems or related field', 'Experience planning, designing and delivering a pipeline for analytics', 'Experience with data warehousing design and implementation', 'Experience with data visualization tools such as Tableau or Power BI', 'Experience with Microsoft SQL and ability to write efficient cod', 'Ability to analyze existing tools and databases and provide recommendations', 'Culture: In our company, you’re judged by your ideas and results, not by your experience or title. So, we encourage you to be thoughtful, casual, and to speak your mind.', 'Development: We strive every day to develop you and your colleagues for what we believe is a challenging and supportive business environment.', 'Teamwork: We believe that success and efficiency can only be a product of collaboration. At FSCO, working together is the rule, not the exception.', 'Innovation: We have achieved success and longevity through innovation. And we encourage experimentation and rule breaking. Mistakes? Those are things we embrace, talk about and learn from.', 'Life balance: Focused, productive time is more important than long hours. We believe in having enough time to be happy both in the office and out of it.']",2020-08-08 13:12:58
Data Analytic Engineer,FacilityConneX,N/A,"Nashua, NH",[],2020-08-08 13:12:58
Lead Data Engineer,DLL Group,4.3 out of 5,"Wayne, PA","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and enabling data-driven decisions across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate, secure, and available for key stakeholders and business processes that depend on it.', 'Contributes to engineering communities of practice, and documents work.', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Works closely with a team of frontend and backend engineers, product managers, and analysts.', 'Defines company data models, uses ELT pipeline and data streaming tools to populate data models.', 'Designs data integrations and data quality framework.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'BS or MS degree in Computer Information Science or related technical field', '8-10 years of Information Technology experience with data management', '5+ years of software engineering experience in Python, Scala, Java, or .NET', '5+ years of experience with schema design, dimensional data modeling, and data storage technology', '5+ years of multiple kinds of database experience (SQL and No-SQL)', 'Proven ability in managing and communicating data warehouse plans to internal clients', 'Experience designing, building, and maintaining secure, reliable batch and real time data pipelines', 'Experience with cloud data ingestion, data lake, and modern warehouse solutions (Azure is a plus)', 'Experience with event streaming platforms like Kafka or Azure Event Hubs', 'Ability to provide data architecture and engineering thought leadership across business and technical dimensions solving complex business cases', 'Possesses a deep understanding of enterprise software patterns and how they may be leveraged in modern data management', 'Knowledge of best practices and IT operations in an always-up, always-available service', 'Experience with or knowledge of Agile Development methodologies (SAFe is a plus)', 'Excellent analytical problem solving and troubleshooting skills', 'Excellent oral and written communication skills with a keen sense of customer service', 'Excellent team player with proven ability to influence', 'Highly adaptable to a continuously changing environment', 'Able to give and receive open, honest feedback and to foster a feedback environment', 'Outstanding communication, interpersonal, relationship building skills for team development', 'Possible Travel (10%)', 'Experience within financial services is a plus', 'Two working days per year volunteering for a local charity', 'Flexible hours with possibility to work from home (within job scope)', 'Career development opportunities: online learning, member development programs, Tuition reimbursement program.', 'Company matching 401k program', 'Industry leading Paid Time Off package', 'Outstanding Medical, Dental, Vision benefit programs', 'One month fully paid sabbatical after seven years of service', 'The selection process may involve an assessment.', 'Applications via email will not be reviewed. We advise you to apply online via our career website workingatDLLgroup.com', 'DLL’s referral program applies.']",2020-08-08 13:12:58
"Engineer, Data",Satcom Direct,3 out of 5,"Melbourne, FL 32940","['Processing confidential data and information according to guidelines.', 'Helping develop reports and analysis.', 'Managing and designing the reporting environment, including data sources, security, and metadata.', 'Supporting the data warehouse in identifying and revising reporting requirements.', 'Supporting initiatives for data integrity and normalization.', 'Assessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems.', 'Generating reports from single or multiple systems.', 'Troubleshooting the reporting database environment and reports.', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Bachelor’s Degree in Mathematics, Statistics, Computer Science, or related STEM field with minimum 3 years’ experience in a similar role or Master’s Degree with minimum 1 year experience in a similar role.', 'Experience with relational SQL and NoSQL databases, such as SQL server, MariaDB, MongoDB, or Cassandra. Knowledge of Big Data technologies such as Hadoop, Hive/Impala, and/or Spark preferred.', 'Experience with either Python or R. Python preferred with knowledge of numpy/scipy/pandas/sklearn considered a plus.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc. merit extra attention.', 'Work experience as a data analyst, data engineer or in related field.', 'Ability to work with stakeholders to assess potential risks.', 'Ability to analyze existing tools and databases and provide software solution recommendations.', 'Ability to translate business requirements into non-technical, lay terms.']",2020-08-08 13:12:58
Senior Data Engineer,HelioCampus,N/A,"Adelphi, MD","['Develop complex SQL queries and analyze data, systems integration experience; understand data warehouse concepts and structures.', 'Experience with data mapping, and the ability to design and develop ETL solutions.', 'Experience with translation of requirements into data model specifications.', 'Ability to multi-task, ability to troubleshoot problems in real-time and diagnose the root cause.', 'Competitive salary, based on experience and bonus program', 'Comprehensive benefits package includes medical, dental, vision, life and disability insurance', '401K with company match', '5+ weeks of paid time off including holidays and vacation']",2020-08-08 13:12:58
Big Data Engineer,"Amazon Web Services, Inc.",3.6 out of 5,"Seattle, WA","[""This position requires a Bachelor's Degree in Computer Science or a related technical field, and 3+ years of meaningful employment experience."", '3+ years of work experience with ETL, Data Modeling, and Data Architecture.', 'Expert-level skills in writing and optimizing SQL.', 'Experience with Big Data technologies such as Hive/Spark.', 'Proficiency in one of the scripting languages - python, ruby, linux or similar.', 'Experience operating very large data warehouses or data lakes.', 'Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.', 'Experience with building data pipelines and applications to stream and process datasets at low latencies.', 'Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.', 'Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.', 'Knowledge of Engineering and Operational Excellence using standard methodologies.', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-08-08 13:12:58
Clinical Quality Data Engineer,Scotland Memorial Hospital,3.8 out of 5,"Laurinburg, NC 28352",[],2020-08-08 13:12:58
Production Engineer,Facebook,4.2 out of 5,"New York, NY","['Own back-end services like our Hadoop data warehouses, front-end services like Messenger and Newsfeed, infrastructure components like our Memcache infrastructure, and everything in between', 'Write and review code, develop documentation and capacity plans, and debug the hardest problems, live, on some of the largest and most complex systems in the world', 'Together with your engineering team, you will share an on-call rotation and be an escalation contact for service incidents', 'Partner alongside the best engineers in the industry on the coolest stuff around, the code and systems you work on will be in production and used by billions of users all around the world', 'Engineering degree, or a related technical discipline, or equivalent work experience', 'Experience with operating systems and TCP/IP network fundamentals', 'Experience coding in higher-level languages (e.g., PHP, Python, C++, or Java)', 'Experience in configuration and maintenance of applications such as web servers, load balancers, relational databases, storage systems and messaging systems', 'Experience learning software, frameworks and APIs']",2020-08-08 13:12:58
Data Engineer/Architect,Noble-D,N/A,"Trenton, NJ","['Empowering our businesses with the enterprise information and data knowledge they need to achieve value', 'Building and maintaining data-intensive applications utilizing modern front-end and back-end technologies to deliver value to our businesses', 'Creating and maintaining optimal data pipeline architecture assembling large, complex data sets that meet functional / non-functional business requirements.', 'Identifying, designing and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.', 'Building the infrastructure required for optimal extraction, transformation, and', 'Building and maintain data services and data consumption tools that utilize the data pipeline to deliver actionable insights into key business performance metrics.', 'Creating data visualizations for analytics and assisting other team members with using our data products.', 'Working with partners including the Architecture, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Preparing and maintaining physical models and implementation-level details that affect the continuum of disciplines involved in the architecture, design, implementation and management of enterprise information.', 'Collaborating with other teams to design, develop data tools that support both operations and data application use cases.', 'Analyzing large data sets using components from the Hadoop ecosystem.', 'Evaluating big data technologies and prototype solutions to improve our data processing architecture.', ""Bachelor's degree in computer science, engineering, math, etc. or equivalent experience"", 'Strong analytic skills related to working with structured and unstructured datasets', 'Experience building processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Experience with big data technologies: Hadoop, Hive, Impala, Hbase, Spark, PIG, SQOOP, HDFS, Solr', 'Expert-level query language skills including SQL, HiveQL and experience working with Relational, NoSQL & Hadoop systems', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Experience with Denodo Data Virtualization Platform (nice to Have)', 'Working skills with back-end technologies: Node.js, Python, Java; front end technologies: HTML, CSS, JavaScript; data visualization tools: Tableau, Power BI', 'Hands-on experience implementing MDM, BI or data warehouse solutions preferred', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and find opportunities for improvement.']",2020-08-08 13:12:58
Big Data Analytics Engineer,Lincoln Financial,3.7 out of 5,"Radnor, PA","['Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assesses the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.', 'Directs and enhances organizational initiatives by positively influencing and supporting change management and/or departmental/enterprise initiatives within assigned area(s) of responsibility.', 'Identifies and directs the implementation of process improvements that significantly improve quality across the team, department and/or business unit for his/her assigned area(s) of responsibility.', 'Provides subject matter expertise to team members and applicable internal/external stakeholders on complex assignments/projects for his/her assigned area(s) of responsibility.', 'Provides direction on complex assignments, projects, and/or initiatives to build and enhance the capability of his/her assigned area(s) of responsibility.', 'Creates and maintains technical documentation for his/her assigned area(s) of responsibility.', 'Gathers requirements and translates into actionable tasks for the development team.', 'Story telling via visualizations and data.', '7+ Years experience in application development that directly aligns with the specific responsibilities for this position (Required )', 'Extensive SQL experience - preference in Presto / Oracle / Redshift', 'Big Data analysis (moderate-advanced proficiency)', 'Front-end BI experience (moderate-advanced proficiency) – Tableau, Quicksight, Data Studio', 'Data modeling / event modeling experience', 'JQuery / javascript experience (low-moderate proficiency)', 'Machine learning experience preferred, but not required – NLP, predictive, AI', 'AWS certification (Preferred)']",2020-08-08 13:12:58
Data Networks Engineer,Yoga Dasa,N/A,"New York, NY","['Candidates who are only from the Tri-state area ( New York (NY), New Jersey (NJ) and Connecticut (CT)) can apply']",2020-08-08 13:12:58
Data Center Operations Engineer I :20-02109,Akraya Inc.,3.7 out of 5,"East Wenatchee, WA 98802","['Receive and Categorize inventory daily using predefined processes and procedures.', 'Inventory hardware devices with attention to detail and conformance with internal systems.', 'Rack and document hardware installation within the datacenter using predefined processes and tools.', 'Cable and document connections between devices.', 'Assign Static IP configurations for device setup and installation.', 'Cable and confirm power on status for storage devices', 'Moderate Connectivity IP Troubleshooting', 'Basic knowledge of operating a range of operating systems and technologies.', 'Moderately familiar with MS Office applications', 'Moderately familiar with Web Based applications and browser basics.', 'Basic understanding of network & hardware terminology', ""There's also a physical end to this job so the role needs to include a description around physical activity like lifting""]",2020-08-08 13:12:58
Data Entry Specialist,ABC Legal Services Inc.,2.9 out of 5,"Seattle, WA 98104","['You challenge prevailing assumptions and suggest better approaches in a positive way.', 'You discover practical solutions to difficult, reoccurring problems.', 'Your colleagues and our customers can rely on you.', 'You never ignore or hide mistakes, inaccuracies, or dishonesty.', 'You believe that complexity creates more opportunity for error.', 'You listen well, as opposed to reacting fast, so you can better understand.', 'You seek to understand our business, our customers, and our mission.', 'You don’t hesitate to ask for help.', 'You type like the wind (75+ WPM).', 'Excellent skills manipulating physical documents, and operating scanners, copiers and printers.', 'Advanced electronic document handling experience.', 'You maintain high performance expectations for yourself and your colleagues – you have a sense of urgency.', 'Thrive in a fast paced, ever changing environment.', 'Self-sufficient and quick on your feet.', 'Attention to detail, assertiveness, consistency, and timeliness are must have skills.', 'Advanced Microsoft Suite and technical aptitude to learn new software quickly and comprehensively.', 'You have a desire to improve upon our culture.']",2020-08-08 13:12:58
Line Engineer,Altra Industrial Motion Corp.,3.4 out of 5,"West Chester, PA","['Acts as PRIMARY OWNER for technical questions and challenges from operatorsAnswers process related questions promptlyReacts quickly to initial quality, tooling, and equipment issues to keep cells running', 'Lead DAILY MANAGEMENT to drive Safety, Quality, Delivery, Inventory and Productivity performance in area of responsibilityCollects and compiles data for cell level SQDIP (Safety, Quality, Delivery, Inventory, Productivity)Establishes regular communication of data to associates and affected personsCreate action plan and executes to drives action to successfully meet goals', 'Performs ROOT CAUSE & COUNTERMEASURE analysis (RCCM’s) of internal quality issuesCollects and receives first signals of potential defective product in area of ownership, troubleshoots, and provides feedback to operators on initial dispositionPerforms MRB (Material Review Board) daily. Identify plan for disposition/rework/salvage of defective parts originating in area of ownershipSubmits deviation and Engineering Change Order requests as neededWorks closely with Quality Team on external returns (RMA’s) including analysis related to defects originating in area of ownership, both determination of root cause and implementation of countermeasures', 'Performs basic TROUBLESHOOTING / REPAIRS of EQUIPMENT in area of ownershipPerform initial mechanical and electrical troubleshooting to determine root cause of equipment failuresAssists Maintenance with minor repairs and troubleshooting of equipment. Escalate to Maintenance staff as requiredEnsure Equipment Preventative Maintenance is performed in a timely mannerEnsure calibration/validation are completed', 'Conducts PROCESS IMPROVEMENT activitiesEnsure repeatability and reproducibility of processes, testing, and measurement and analytical equipmentSpecifies manufacturing methods and part routingsPerforms time studies or observe/capture standard workParticipate and conduct standard work (SW), Variation Reduction Kaizen (VRK), as well as other Kaizen activities to improve stability of processesSpecifies and orders tooling and equipmentDesigns and documents fixturing and tools using Solidwork softwareFocus on sustainable, long-term success of processes', 'Maintains DOCUMENTATION related to part routings, work instructions and inspectionCreates/updates Process Documentation for areas of ownership – Routers, OMS, MP, QSBCompiles and write training material and conduct training/coaching sessions on quality control and manufacturing activities', 'Supports NEW PRODUCT DEVELOPMENT as needed', 'High sense of urgency and results driven', 'A strong understanding of quality systems and other process improvement tools', 'Familiarity with various manufacturing equipment and processes (laser welding, transfer molding)', 'Working knowledge of inspection and measurement tools (CMM, Caliper, Micrometer, Gages)', 'Familiarity with documentation and process control', 'Demonstrated proficiency in time and project management', 'Ability to work in a cross functional environment', 'Strong written, verbal and computer skills', 'Bachelor’s degree in Mechanical/ Industrial Engineering or related field, or equivalent experience', 'At least one year of Manufacturing Engineering experience required', 'Previous experience with Lean Manufacturing / Problem Solving tools is preferred', 'Previous Experience with QS and ISO requirements is preferred']",2020-08-08 13:12:58
Data Engineer,Adswerve Inc,N/A,"Seattle, WA","['Develop apps (visualization, routing data, cleaning data, access to data, interacting with data) within Google Cloud Platform (GCP)', 'Develop various Big Data capabilities in GCP for our different systems, aligning them with business strategies and reporting requirements', 'Architect data solutions for scale, resiliency and maintainability, leveraging various cloud providers which meet technical, security and business needs for applications and workloads', 'Execute strategic engineering proof of concepts and contribute to technology strategy and engineering roadmaps', 'Develop monitoring strategies for infrastructure, platforms and applications aligning with enterprise strategy and overall industry trends', 'Translate solutions and complicated concepts to both technical and non-technical audiences across the organization', 'Other duties as assigned', 'College degree, preferably in Computer Science, Information Science - OR - equivalent experience in data engineering', 'Strong SQL or MySQL query writing experience with the ability to take a request and transfer it into a query', 'Experience with one or more of the following: JavaScript, Python, Java, Google BigQuery, Google Data Studio, Salesforce or Google App Engine', 'Proven ability to solve complex problems with on-time delivery, the highest quality, and creativity in the approach', 'Ability to listen and understand business needs and creatively develop solutions', 'Ability to work on a team and manage and prioritize individual workloads', 'Strong desire to become a proficient Data Engineer for a fast paced company']",2020-08-08 13:13:41
Data Engineer,IZEA,2.9 out of 5,"Winter Park, FL 32789","['Work with stakeholders to define the solutions to development problems and business requirements', 'Develop and maintain the features and capabilities of our data ingestion pipelines', 'Extract actionable and impactful insights from vast amounts of data', 'Develop and maintain the services that surface those insights and make them available for consumption in a performant manner', 'Create unit and integration tests for your code', 'Reproduce and fix bugs reported by internal and external users', 'Set goals and communicate often about your progress toward them', 'Contribute to the ongoing improvement of the engineering organization and our software', ""Much of our work revolves around problems that have no existing off-the-shelf solution or consensus on best practices. You'll often need to break down large problems into smaller more manageable tasks and utilize critical thinking to come up with novel ideas."", 'Things move quickly in the data group. You’ll need to be comfortable and familiar with delivering highly scalable cloud based applications.', 'This will be a significant component of your responsibilities. You will be working with large data sets in a distributed environment on a daily basis. Familiarity w/ the Hadoop/Spark ecosystem is a must.', 'Our data team uses PySpark and Jupyter notebooks extensively. Familiarity with these technologies will also serve you well.', 'We use the best tool for the job around here. When it comes to storing and accessing data, we recognize that the technology decisions we make directly impact our ability to provide a performant customer experience, and our own costs.', 'Because we are building our application with a front end framework, we carefully design and document the APIs to power it. To help us, we follow the JSON API spec, but any experience in building a RESTful API will be useful. Remember, the API is your contract with the consumers of your data!', 'IZEAx still has some legacy monolithic characteristics. We move more and more of our technology to a distributed set of services, there are new challenges to overcome. Understanding the differences between these two models will help you take those challenges head on.', ""In order to develop our data pipelines and services, you need to run it on your laptop. This means opening up some terminal windows, running some commands, and keeping the log output open. Additionally, some of our technology stack is better accessed through CLIs. Examples include the Ember CLI, the Rails CLI/console, Docker commands, Gradle, and our own CLIs. We'll walk you through it, but you should be comfy in a terminal."", ""IZEA's Engineering team strives to provide a great experience and great service to our users. In order to do that, you may need to context switch into a support issue or drop what you are doing to start work on something else. This is part of what Agile means to us."", 'Regular and timely communication is the key to a trust based development process. You should be able to simply and concisely ask for feedback and direction in terms that your audience understands, and relay requested information in a timely fashion to your leaders. You should prioritize documentation of processes and code.', 'While not required, a fundamental understanding of statistics and modeling would be a great asset. Practical experience with Machine Learning and/or complex data pipelines would also be welcome.', 'From time to time you may need to build visualization, or (lite) user facing experiences. Familiarity with modern web frameworks like Angular, React, Ember, or Vue would be helpful. Extra bonus points if you have familiarity w/ Javascript based visualization libraries like d3.js or Highcharts.', ""IZEA's software is hosted on AWS, and you will need to acquire some familiarity with it. Previous experience in using a cloud provider, even if just for developer tooling, shows that you understand some of the nuances involved in working in the cloud. Familiarity with Amazon’s EMR would also be an asset."", 'IZEA needs to get features and fixes out to customers as soon as we possibly can with as much confidence as possible. To facilitate this, we have developed a CI/CD pipeline (using 3rd party services). An understanding of what CI/CD is will help you understand how this pipeline works and how to make it even better.', ""All of IZEA's code is source controlled on Github. We leverage Github Pull Requests for code reviews, Github integrations manage parts of our CI/CD pipeline, and Github releases define the code tags that ultimately get deployed. Much of our process documentation exists on Github pages. Familiarity with navigating Github's features will help you ramp up in our SDLC faster."", 'IZEA uses JIRA to manage projects and report on progress to stakeholders inside and outside the company. While we strive to automate as much of JIRA as possible with bots, webhooks and reports, understanding how JIRA issues, links, attachments, and workflows work will help you understand our SDLC faster.']",2020-08-08 13:13:41
Data Engineer II,Microsoft,4.2 out of 5,"Redmond, WA","['Design, develop, and maintain data pipelines for real-time/batch analysis, reporting, optimization, data collection, and related functions.', 'Build and Maintain data processing infrastructure that support complex analysis across our data science, product, and experimentation teams.', 'Evaluate and propose the best tooling and processes for data access and analysis.', 'Use large data sets to resolve major business and functional issues while improving data reliability, efficiency and quality.', 'Ensuring security, privacy and compliance for all data assets.', 'Work iteratively.', 'Communicate effectively, both written and verbal, with technical and non-technical cross-functional and geographically distributed teams', 'Collaborate with Data Scientists and Applied Scientists', '3+ years relevant industry experience designing data models and ETL pipelines that are secure, testable, and modular.', 'Experience working with cloud infrastructure (at least one of Azure, AWS, GCP)', 'Experience with distributed computing frameworks (e.g. Spark, Hadoop, Flink)', 'Experience working with Data Scientists and Applied Scientists', 'Development Expertise in at least one programming language (Java, .NET, Python).', 'Experience in designing and executing data pipelines using GDPR and private data', 'Promote a culture of self-serve data analytics by minimizing technical barriers to data access and understanding.', 'Ability to communicate well with users, partner teams and senior management to collect requirements, explain data collection decisions and create data engineering strategy', 'BS or MS degree in Computer Science or a related technical field', 'Hands-on experience in writing complex, highly-optimized SQL queries across large data sets', 'Experience in data visualization and dashboard design including tools such as Tableau, PowerBIetc', 'Stay current with the latest technology and communicate your knowledge throughout the team']",2020-08-08 13:13:41
Head of Data,Tempest,3.3 out of 5,Remote,"['An open-minded, accepting, mostly hilarious culture that believes employee happiness comes first', 'Unique holidays (and a lot of them)', 'Great health insurance with One Medical benefits', 'Wellness reimbursement', '401k + FSA', 'Heads down Fridays', 'Weekly team lunch and office snacks (when we’re not in a pandemic)', 'Family-friendly policies', 'In-house recovery meetings', 'Zero happy hours', 'some benefits also available to part-time staff', 'Build the Data Models that power a Tempest Members personalized recovery pathway', 'Define the Data Architecture that powers Tempest, which includes Web Analytics, AB Test framework, the Data Pipelines and the Data Warehouse', 'Build and manage a small team of Data Analysts, Data Scientists, and Data Engineers to support the Tempest vision', 'Interface and Partner with Clinical Researchers and Subject Matter Experts within Academia on Substance Abuse/ Mental Health Research', 'Collaborate with stakeholders to translate business vision into an actionable Data strategy and roadmaps, and own execution.', 'Collaborate with, equip, and empower the rest of the engineering team to join you in implementing the data strategy.', '5+ years of experience as a Data Scientist with hands-on experience in Data engineering.', '3+ years experience translating business vision into company-wide data strategy', 'Experience with Machine Learning, Statistical Modeling, specifically around multilevel modeling/growth mixture modeling, and other AI techniques', 'Experience building and managing small Data teams', 'Strong knowledge of data warehousing, and ETL/ELT conceptsExpert knowledge and experience developing and running ETL data pipelines of multiple sources and targets.', 'Strong business sense and ability to collaborate with leadership and non-technical stakeholders on highly visible projects', 'Experience with both self report and passive/platform data', 'Strong leadership, communication, and time management skills', 'Experience working in agile software development environments', 'A passion for and an ability to thrive in fast paced environments', 'Ability to work remotely and effectively manage your time']",2020-08-08 13:13:41
Data Scientist,HubSpot,4.4 out of 5,Massachusetts,"['Collaborate with product design and engineering to develop an understanding of needs', 'Research and devise innovative statistical models for data analysis', 'Enable smarter business processes—and implement analytics for meaningful insights', 'Keep current with technical and industry developments', 'Work as the lead data strategist, building models to improve internal efficiency and customer experience', 'Work closely with the engineering team to strategize and execute the development of data products', 'Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries', 'Implement analytical models into production by collaborating with software developers and machine learning engineers.', 'Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy', 'Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables', 'Analyze data for trends and patterns, and Interpret data with a clear objective in mind', 'Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems', 'Degree in statistics, applied mathematics, or related discipline', '5+ years experience in data science', 'Proficiency with data mining, mathematics, and statistical analysis', 'Advanced pattern recognition and predictive modeling experience', 'Advanced use of SQL, R, Python', 'Experience with machine learning models', 'Comfort working in a dynamic, research-oriented group with several ongoing concurrent projects', ""Master's degree in stats, applied math, or related discipline"", '2+ years of project management experience', 'Professional certifications']",2020-08-08 13:13:41
Senior Risk Adjustment Data Engineer,Neighborhood Health Plan of RI,3.8 out of 5,"Smithfield, RI 02917","['Enable Risk Adjustment Program Analytics by developing a data reconciliation model that compares submitted claims and return files to drive RAF improvement.', 'Correlate the differences in Risk Scores to Claims Acceptance Rate and empower the Encounter Data Submissions team to drive towards the desired outcomes.', 'Enable the Operational processes to address and resolve the rejected claims in a timely manner.', 'Develop Analytical Modeling to value the claims accepted versus claims rejected / outstanding.', 'Develop discipline around data management and data integrity to mitigate data (member diagnosis) leakage.', 'Develop processes to ingest the return files from the regulatory agencies for different lines of business.', 'Contribute to the development of business requirements, functional requirements, solution design, process flow and other related documentation for supporting the Regulatory Submissions.', 'Develop the Financial Accrual Model and Risk Transfer Model to correlate Member Comorbidity with Premium.', 'Support strategies for effective monitoring and auditing to identify risks, improve quality and reduce risk stemming from CMS RADV audits.', 'Assume ownership of business processes and develop procedures to mitigate audit risks.', 'Develop and implement programs that will enhance provider training and education of the HCC Risk Adjustment Process, Proper Medical Record Documentation and Diagnosis Accuracy.', 'Drive towards the integration of prospective programs into care management processes and promote the use of risk adjustment programs to help facilitate care management.', 'Provides guidance to junior-level analysts on data management, data analysis techniques, communication with non-technical stakeholders, project management, and healthcare industry knowledge.', 'Other duties as assigned', 'Corporate Compliance Responsibility - As an essential function, responsible for complying with Neighborhood’s Corporate Compliance Program, Standards of Business Conduct, applicable contracts, laws, rules and regulations, policies and procedures as it applies to individual job duties, the department, and the Company. This position must exercise due diligence to prevent, detect and report unlawful and/or unethical conduct by fellow co-workers, professional affiliates and/or agents', 'Bachelor Degree in Information Technology, Computer Science, Mathematics, Statistics, Business or Finance', '5 years of progressive industry experience in data analysis and tools.', '2-3 years’ experience in Health Plan Operations to include Risk Adjustment Activities', 'Experience and strong participation within a Risk Adjustment Team as the primary point of contact for Encounter Data Submissions Team.', 'Experience translating business and design requirements into technical requirements for Risk Adjustment as outlined by CMS or other State Regulatory Requirements.', 'Previous experience in risk adjustment activities in a Medicare, Affordable Care Act or provider organization to including submission of RAPs, and EDPS, EDGE Server files submission, responses and reconciliation per CMS and other State and Federal Guidelines.', 'Experience with business and technical requirements of all inbound and outbound data associated with a strong Risk Adjustment Business Unit.', 'Experience in critical analysis on information from multiple sources, identify issues and break down high-level information into detailed workable plan.', 'Serve as a resource between Risk Adjustment Team and all Operational Business Units to include Encounter Data Submissions, Finance and other departments that may need understanding of the overall Technical aspect of the Risk Adjustment submission and reporting process.', 'Knowledge of claims coding and payment methodology, associated with a Health Plan domain.', 'Advanced analytical problem solving skills.', 'Advanced skills with Microsoft Office (Project, Word, Excel, PowerPoint, Outlook)', 'Demonstrated experience in Data Analysis using various analysis tools (SQL, SAS, etc.) and a strong understanding of database concepts.', 'Demonstrated experience in collaboration, teamwork, and cross-functional communication.', 'High level organizational and project management skills in order to effectively handle concurrent assignments.', 'Advanced Degree or Certifications in related field', 'Strong knowledge base of data points associated with the end to end process of plan payment.', 'Strong background in CPT, HCPCS, and related Hierarchical Condition Coding (HCC) Methodologies.', 'Communicate Effectively', 'Respect Others & Value Diversity', 'Analyze Issues & Solve Problems', 'Drive for Customer Success', 'Manage Performance, Productivity & Results', 'Develop Flexibility & Achieve Change', 'Collaborate & Foster Teamwork', 'Create & Innovate', 'Exercise Sound Judgement & Decision Making', 'Achieve Professional Growth', 'Yes', 'Yes, 2 days a week', 'Some travel locally between locations is required']",2020-08-08 13:13:41
Data Engineer/Architect,Noble-D,N/A,"Trenton, NJ","['Empowering our businesses with the enterprise information and data knowledge they need to achieve value', 'Building and maintaining data-intensive applications utilizing modern front-end and back-end technologies to deliver value to our businesses', 'Creating and maintaining optimal data pipeline architecture assembling large, complex data sets that meet functional / non-functional business requirements.', 'Identifying, designing and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.', 'Building the infrastructure required for optimal extraction, transformation, and', 'Building and maintain data services and data consumption tools that utilize the data pipeline to deliver actionable insights into key business performance metrics.', 'Creating data visualizations for analytics and assisting other team members with using our data products.', 'Working with partners including the Architecture, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Preparing and maintaining physical models and implementation-level details that affect the continuum of disciplines involved in the architecture, design, implementation and management of enterprise information.', 'Collaborating with other teams to design, develop data tools that support both operations and data application use cases.', 'Analyzing large data sets using components from the Hadoop ecosystem.', 'Evaluating big data technologies and prototype solutions to improve our data processing architecture.', ""Bachelor's degree in computer science, engineering, math, etc. or equivalent experience"", 'Strong analytic skills related to working with structured and unstructured datasets', 'Experience building processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Experience with big data technologies: Hadoop, Hive, Impala, Hbase, Spark, PIG, SQOOP, HDFS, Solr', 'Expert-level query language skills including SQL, HiveQL and experience working with Relational, NoSQL & Hadoop systems', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Experience with Denodo Data Virtualization Platform (nice to Have)', 'Working skills with back-end technologies: Node.js, Python, Java; front end technologies: HTML, CSS, JavaScript; data visualization tools: Tableau, Power BI', 'Hands-on experience implementing MDM, BI or data warehouse solutions preferred', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and find opportunities for improvement.']",2020-08-08 13:13:41
Senior Data Engineer,AARG,4.5 out of 5,"Richmond, VA","['Build data pipeline frameworks to automate high-volume and real-time data delivery to our cloud platform', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies', 'Develop and enhance applications using a modern technology stack such as Java, Python, Shell Scripting, Scala, Postgres, Angular JS, React, and Cloud based data warehousing services such as Snowflake', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree; nice to have Accounting / finance business knowledge is a plus', '5+ years of experience building data pipelines and using ETL tools to solve complex business problems in an Agile environment', '5+ years of experience in at least one scripting language (SQL, Python, Perl, JavaScript, Shell)', '3+ year of experience using relational database systems (Snowflake, PostgreSQL, or MySQL)', '3+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink)', '3+ years of experience in big data technologies (MapReduce, Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', '3+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', 'Monday to Friday', 'Data: 3 years (Preferred)', 'United States (Preferred)', 'Likely', 'Yes', 'Fully Remote']",2020-08-08 13:13:41
Sr. Data Engineer,Workforce Logiq,3.1 out of 5,"Fort Lauderdale, FL","['The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting.', 'This engineer’s duty is to monitor the existing metrics, analyze data, and lead partnerships with other Data and Analytics teams in an effort to identify and implement systems and process improvements.', 'This engineer also designs, architects, implements, and supports key datasets.', 'Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud', 'Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery', 'Develop and promote best practices in data engineering', 'Develop real-time data processing applications using Google Cloud', 'Be part of the on-call rotation supporting our SLA’s', 'Participate in design and code reviews', ""Bachelor's degree in Computer Science or equivalent experience in a related field of hands-on experience working in data warehousing or data engineering environment"", 'Advanced SQL programming skills', 'Experience developing data solutions on GCP or AWS', 'Experience in ingestion of data from external APIsand data stores', 'Experience in design, build and operationalization of big data pipelines on Cloud Technologies.', 'on problem-solving, quality and ability to execute', 'Strong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow related technologies)', 'Strong communication & interpersonal skills', 'Google Cloud Certified - Professional Data Engineer certification would be a plus', 'Knowledge of Git, Jinja2, Docker, Bitbucket, and Bamboo', 'Familiar with a NoSQL database such as MongoDB', 'Familiar with version control systems (Git and Bitbucket)', 'Familiar with Atlassian products Jira and Confluence', 'Hands-on experience with Apache Airflow or Google Composer']",2020-08-08 13:13:41
Data Engineer,WellNow Urgent Care,2.6 out of 5,"East Syracuse, NY 13057","['Design and develop complex ETL data loading packages.', 'Drive for and create ETL architectural and development standards.', 'Drive ETL development efforts and share knowledge capital.', 'Assist in design, architecture and development of Data Warehouse/Datamart.', 'Adhere to ETL/Data Warehouse/Datamart development best practices.', 'Identify and resolve any performance and/or data related issues', 'Analyze business requirements as a guide to data preparation and modeling', 'Build data models with the flexibility to change when business requirements change', 'Provide documentation (Data Mapping, Technical Specifications, Production Support, data dictionaries, test cases, etc.)', 'Provide Production Support of Data Warehouse as well as ETL jobs used to support the Data Warehouse.', 'Provide support for stakeholders, analysts and report creators.', 'Perform duties & responsibilities specific to department functions & activities and any other assigned task by reporting manager.', 'Bachelor’s degree in Information Technology, Management of Information Systems, or a related field', '5+ Years of experience with MS SQL Server Integration Services (SSIS)', '5+ Years of experience with MS SQL Server Reporting Services (SSRS)', '3+ Years of experience with MS SQL Server Database Design/Development', '3+ Years of Data Warehousing Experience', 'Experience implementing and supporting Enterprise Level Data Warehouse', '2+ Years of experience with MS SQL Server Analytical Services (SSAS)', 'Expert Microsoft SQL Development (T-SQL)', 'Experience in Data Modeling (Erwin, Power designer, etc.)', 'Strong Understanding of Agile Data Warehouse Development, data modeling and data classification', 'Advance knowledge of performance tuning related to ETL Development', 'Strong experience with Source Control (TFS, RedGate, etc.)', 'Strong experience with job automation tools (Autosys, Tidal, BMC, etc.)', 'Strong experience with SQL Server Management Studio & BIDS', 'Strong Leadership, communication (verbal & written) and problem-solving skills', 'Business analyst experience helpful', 'Results/Goal oriented', 'Ability to handle multiple projects and manage time efficiently']",2020-08-08 13:13:41
Big Data Engineer,Huntington Ingalls Industries Inc.,3.8 out of 5,"Springfield, VA 22150","['Designs, modifies, develops, writes and implements software systems.', 'Participates in software and systems testing, validation, and maintenance processes through test witnessing, certification of software, and other activities as directed.', 'Provides support to senior staff on projects/programs. Familiar with standard concepts, practices, and procedures within a variety of fields related to the project. This position takes direction from senior technical leadership.', 'Designs, develops, documents, tests and debugs applications software and systems that contain logical and mathematical solutions.', 'Conducts multidisciplinary research and collaborates with equipment designers and/or hardware engineers in the planning, design, development, and utilization of electronic data processing systems for product and commercial software.', 'Determines computer user needs; analyzes system capabilities to resolve problems on program intent, output requirements, input data acquisition, programming techniques and controls; prepares operating instructions; designs and develops compilers and assemblers, utility programs, and operating systems.', 'Ensures software standards are met.', 'COMPTIA Security+ certification or CISSP certification', 'Proficiency in two or more of the following programming languages: C#, Java, .NET, Python, Perl, Ruby, or similar', 'Familiarity with current Agile methods', 'Proficiency with the following:Multiple operating systems including: UNIX, Linux, Windows, Cisco IOS, etc.Machine learning, data mining, and knowledge discoveryAnalytic algorithm design and implementationETL processes; including document parsing techniquesNetworking, computer, and storage technologiesUsing or designing RESTful APIs, SOAP, XMLDeveloping large cloud software projects, preferably in Java, Python or C++ languageJava/J2EE, multithreaded and concurrency systemsMulti-threaded, big data, distributive cloud architectures and frameworks including Hadoop, MapReduce, Cloudera, Hive, Spark, Elasticsearch, etc. for the purposes of conducting analytic algorithm design and implementationNoSQL database such as Neo4J, Titan, Mongo, Cassandra, and hBaseAWS Services (EC2, Network, ELB, S3/EBS, etc.)Processing and managing large data sets (multi PB scale)Web services environment and technologies such as XML, KML, SOAP, and JSONProficiency in trouble-shooting in very complex distributed environments including following stack traces back to code and identifying a root cause', ""9 years relevant experience with Bachelors; 7 years relevant experience with Masters. An additional 4 years of specific job experience with a HS diploma may be substituted for the Bachelor's degree requirement for this job. This experience is in addition to the relevant years of experience listed with the job's education requirements."", 'Clearance: Must possess and maintain a TS/SCI clearance', 'Education – Masters Degree in Computer Science or related field (e.g. Statistics, Mathematics, Engineering) – but a technical BS degree will suffice', 'Distributed computing-based certifications', ""Proficiency with the following:Management/tracking utilities such as Jira, Redmine, or similarRunning Internet facing or Service Level Agreement (SLA'd) auto-deployed environmentsReal-time media protocols (Real-time Transport Protocol (RTP), Secure Real-time Transport Protocol (SRTP))Data transfer systems such NiFiText processing: NPL, NER, entity retrieval (e.g. Solr/Lucene), topic extraction, summarization, clustering, etc.Certification from an Agile certified institute, International Consortium for Agile, Scaled Agile Academy, Scrum Alliance, Scrum.org, International Scrum Institute, ScrumStudy, Project Management Institute - Agile Certified Practitioner, or similar XP/Scrum certification or training is desiredSupport to SOF; Previous experience with technology, intelligence and cyber under the umbrella of USSOCOM""]",2020-08-08 13:13:41
Data Engineer,Alion Science and Technology,3.7 out of 5,"Linthicum Heights, MD","['Must have a current Secret level security clearance and therefore all candidates must be a U.S. Citizen.', 'B.S. degree in Computer Science, Information Technology, Electrical Engineering, Statistics, or equivalent fields. Educational requirements may be adjusted for applicable work experience. Work experience may be adjusted for highly specialized knowledge or uniquely applicable experience.', '2+ years of experience as a developer, analyst, or engineer.', 'Experience with programming languages such as Python and Java.', 'Proficiency with acquisition and understanding of network data and the associated metadata.', 'Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics.', 'Experience with Kibana and Elasticsearch.', 'Familiarity with various log formats such as JSON, XML, and others.', 'Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions).', 'Ability to decompose technical problems and troubleshoot system and dataflow issues.', 'Experience with NOSQL databases such as Accumulo desired', 'Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer.']",2020-08-08 13:13:41
Data Engineer,B12,N/A,"New York, NY 10003","['We build our product on Python/Django and JavaScript/React.', ""We store blobs in Amazon's S3, munch on them in Amazon's EC2, develop in Docker, and deploy containers to Amazon's Elastic Beanstalk."", 'We believe Postgres should be the first system you consider when you think about persisting structured data.', ""We religiously clean and centralize data in Amazon's Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!"", 'Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.', 'We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.', ""We set up continuous integration and deployment because, while this model comes with its own pains, we've disliked being on fixed release schedules on previous projects."", 'We like to move fast and support point-in-time recovery :).', 'Collaborate with operational teams including sales, marketing, and customer success.', ""Contribute to infrastructure that enables and informs B12's analytical efforts."", 'Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.', 'Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.', 'Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.', 'You are fluent in SQL and Python.', 'You have experience building and using data infrastructure, including systems like Postgres and Redshift.', ""You've used reporting tools like Metabase, Tableau, or Looker in the past."", 'You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.', ""You've contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse."", 'You feel comfortable managing your time and deciding amongst competing priorities.', 'You have worked with non-engineering teams and are comfortable explaining technical solutions to them.', 'You are passionate about the future of work.', 'You enjoy learning and teaching.', 'You have strong written and verbal communication skills in English.', 'You care about and want to contribute to our mission of helping people do meaningful work.', ""We don't have a minimum number of years of experience for this role. We highly favor talent and interest."", ""Some candidates may see this list and feel discouraged because they don't match all the items. Please apply anyway: there's a good chance you're more wonderful than you think you are."", 'B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.', 'A pointer to your CV, resume, LinkedIn profile, or any other summary of your career so far.', 'Some informal text introducing yourself and what you are excited about.', ""If you have a profile on websites like GitHub or other repositories of open source software, you can provide that as well. If you don't have one, it's still very possible for us to get along just fine!""]",2020-08-08 13:13:41
Junior Data Science Research Engineer,Technica Corporation,3.7 out of 5,"Dulles, VA","['Support a team of Developers and Data Scientists working on a variety of research and development projects as well as customer projects', 'Research and analyze cutting edge algorithms and technologies with a focus on Natural Language Processing and data visualization techniques', 'Effectively communicate results of research and analysis with teammates and senior management in the form of essays, whitepapers, and Powerpoint presentations', 'Design, Develop and Deploy:', 'Automated analytic software, techniques, and algorithms', 'Data-driven analytics; event-driven analytics', 'Bachelor’s in Computer Science, Mathematics, or relevant technical field', '1+ years’ experience using Natural Language Processing techniques', '1+ years’ experience with web frameworks (React, Flask, NodeJS)', '1+ years’ experience with Python', 'Eligible to obtain a U.S. Secret clearance', 'Using Linux as a development operating system', 'Professional experience with Docker and Singularity container platforms', 'Professional experience with Machine Learning toolkits such as Tensorflow, Pytorch', 'Professional experience with customer facing data visualization', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Python: 1 year (Required)', 'Natural Language Processing techniques: 1 year (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'Secret (Preferred)']",2020-08-08 13:13:41
Data Analytics Engineer,Travelers,3.7 out of 5,"Hartford, CT","['Reviews unfamiliar data sources.', 'Connects to value for business.', 'Able to link to systems.', 'Develops process to acquire and integrate data.', 'Independently reviews, prepares, designs and integrates complex (type, quality, volume) data correcting problems and recommends data cleansing/quality solutions to major issues.', 'Works within Travelers standards, processes, and protocols.', 'Develops moderate and applies complex data derivations, business transformation rules, and data requirements.', 'Leads medium scale projects and coordinates aspects of larger projects with limited supervision.', 'Performs analysis of complex (type, quality, volume) sources to determine value and use.', 'Determines and recommends data to include in analytical projects.', 'Creates moderate (technology and features) data visualization techniques to help support data exploration.', 'Utilizes business knowledge to explain technical activities in business terms.', 'Actively seeks opportunities to expand technical knowledge and capabilities.', 'Develops and maintains relationships across the enterprise.', 'Operationalizes and automates more complex (more systems, data sets and streams, size of data sets more substantial) products into business.', 'Proactively looks to improve and optimize data products.', 'Builds, tests, and implements complex analytic business products, including pilots and proof of concept.', 'Applies knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects and/or enhancements.', 'Independently train business users on data products/analytic environment.', 'Ensures customer satisfaction through professional communication, follow-up, and responsiveness to issues.', 'Consultation: Shares knowledge with users on data or analytic products. Builds effective relationships with stakeholders.', '4 years of relevant experience with data tools, techniques, and manipulation required.', 'College Degree in STEM related field', 'Advanced knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to):', 'Big data and Cloud platforms', 'Programming languages - SAS, SQL, Spark, Python, Hive, AWS', 'Visualization platforms: QlikView, Tableau, MicroStrategy and Qlik Sense', '5 years of relevant experience with data tools, techniques, and manipulation preferred.', 'Advanced knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to): Big data and Hadoop platforms and languages - SAS, SQL, Spark, Python, Pig, Hive, QlikView, Tableau.', 'Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.', 'Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills.', 'Effectively contributes and communicates with the immediate team.', 'Able to clearly and concisely communicate with the business.', 'Demonstrates willingness, cooperation, and concern for business issues.', 'Able to understand assigned business unit and business priorities.', 'Able to coordinate with other technical areas to achieve project/department or division goals. Able to recognize, analyze, and diagnose business and data issues of advanced complexity.', 'Able to creatively evaluate alternative solutions.', 'Able to reuse previously completed processes.', 'Ability to build and foster relationships with team, business, and technical partners to achieve objectives.', 'Operates standard office equipment - Continuously', 'Sitting (Can stand at will) - Continuously', 'Use of Keyboards, Sporadic 10-Key - Continuously']",2020-08-08 13:13:41
Data Analytics Engineer,Travelers,3.7 out of 5,"Hartford, CT","['Reviews unfamiliar data sources.', 'Connects to value for business.', 'Able to link to systems.', 'Develops process to acquire and integrate data.', 'Independently reviews, prepares, designs and integrates complex (type, quality, volume) data correcting problems and recommends data cleansing/quality solutions to major issues.', 'Works within Travelers standards, processes, and protocols.', 'Develops moderate and applies complex data derivations, business transformation rules, and data requirements.', 'Leads medium scale projects and coordinates aspects of larger projects with limited supervision.', 'Performs analysis of complex (type, quality, volume) sources to determine value and use.', 'Determines and recommends data to include in analytical projects.', 'Creates moderate (technology and features) data visualization techniques to help support data exploration.', 'Utilizes business knowledge to explain technical activities in business terms.', 'Actively seeks opportunities to expand technical knowledge and capabilities.', 'Develops and maintains relationships across the enterprise.', 'Operationalizes and automates more complex (more systems, data sets and streams, size of data sets more substantial) products into business.', 'Proactively looks to improve and optimize data products.', 'Builds, tests, and implements complex analytic business products, including pilots and proof of concept.', 'Applies knowledge of current industry trends and techniques to formulate solutions within the context of assigned projects and/or enhancements.', 'Independently train business users on data products/analytic environment.', 'Ensures customer satisfaction through professional communication, follow-up, and responsiveness to issues.', 'Consultation: Shares knowledge with users on data or analytic products. Builds effective relationships with stakeholders.', '4 years of relevant experience with data tools, techniques, and manipulation required.', 'College Degree in STEM related field', 'Advanced knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to):', 'Big data and Cloud platforms', 'Programming languages - SAS, SQL, Spark, Python, Hive, AWS', 'Visualization platforms: QlikView, Tableau, MicroStrategy and Qlik Sense', '5 years of relevant experience with data tools, techniques, and manipulation preferred.', 'Advanced knowledge of data tools, techniques, and manipulation preferred. Examples (but not limited to): Big data and Hadoop platforms and languages - SAS, SQL, Spark, Python, Pig, Hive, QlikView, Tableau.', 'Ability to communicate thoughts/designs/ideas in an unambiguous manner and adjusts communication based on audience.', 'Exhibits active and effective communication skills with team members - including active listening and effective written and verbal communication skills.', 'Effectively contributes and communicates with the immediate team.', 'Able to clearly and concisely communicate with the business.', 'Demonstrates willingness, cooperation, and concern for business issues.', 'Able to understand assigned business unit and business priorities.', 'Able to coordinate with other technical areas to achieve project/department or division goals. Able to recognize, analyze, and diagnose business and data issues of advanced complexity.', 'Able to creatively evaluate alternative solutions.', 'Able to reuse previously completed processes.', 'Ability to build and foster relationships with team, business, and technical partners to achieve objectives.', 'Operates standard office equipment - Continuously', 'Sitting (Can stand at will) - Continuously', 'Use of Keyboards, Sporadic 10-Key - Continuously']",2020-08-08 13:14:23
Data Engineer,April Health,N/A,"Houston, TX","['Work with Data Architect to develop a data lake, data warehouse in local and/or Azure cloud environment', 'Integrate disparate data models into coherent enterprise data models', 'Develop ETL data pipelines to populate data lake and warehouse', 'Actively participate in Data Governance Program to maintain metadata and data definitions', 'Work in a team environment with other departments to develop reports, KPIs and dashboards (very strong communication skills)', 'Interpret business requirements to identify proper tools and methods to analyze, identify and report data trends and variances', 'Bachelor’s Degree in Computer Science, Computer Engineering or Information Systems with university level programming courses', '3+ years of data engineer experience', '3+ years of recent experience in ETL and data warehouse development or maintenance', '3+ years of experience in KPI, reports and dashboard development', 'Experience in healthcare company a plus', 'Experience in Azure and Sharepoint a plus', 'Experience in agile software development is a plus', 'Proficiency in Power BI, Azure Cloud, C#, ETL (SSIS preferred), T-SQL, Excel', 'Ability to develop data dictionaries of an existing database', 'Ability to write, analyze and debug SQL queries', 'Ability to develop dashboards and data models in Power BI; must be familiar with DAX and Power Pivot, and be willing to get proficient at them', 'Ability to develop business models and perform analysis in MS Excel', 'Proficiency in R and Python preferred']",2020-08-08 13:14:23
Active Drive Assist Data Analytics Engineer,Ford Motor Company,4.2 out of 5,"Dearborn, MI","['Support Sign-off of Feature Level performance for a given vehicle via data exploration and analysis of Active Drive Assist Features.', 'Develop and refine scripts, reports, and dashboards for ensuring accurate feature-level performance across a variety of environmental and cross-carline noise factors.', 'Support design verification plans by analyzing resulting data and delivering reports and/or dashboards showing compliance with internal and external requirements.', 'Support and coordinate root-cause analysis with internal and external suppliers to ensure delivered system thrills our customers with the user experience via data-driven reports, signal-level traces, or other mechanisms.', 'Develop innovative methods for analysis of Active Drive Assist Features & Functions using state of the art tools and big-data approaches.', 'Bachelor’s Degree in Electrical, Mechanical, Aerospace, Controls, Computer or Software Engineering or Computer Science', '1+ year diagnostics software quality', 'Experience with ANY of the following areas: Adaptive Cruise Control, Blind Spot Systems, Lane Keeping or Lane Centering Systems.', 'Experience with GPS / GNSS systems including inertial navigation system validation.', 'Understanding of embedded hardware and software design.', 'Understanding of Kalman filtering, vehicle dynamics, linear & nonlinear control methods.', 'Software engineering & algorithm development experience. Any development time in any language (C, C++, Python, Matlab, etc.)', 'Experience with MobilEye EyeQ technology', 'Developing and conducting laboratory and vehicle tests.', 'Developing reports and dashboards using Excel, Tableau, QlikView, Alteryx or other industry standard tools.']",2020-08-08 13:14:23
"Data Engineer(Java , SQL , ETL)",Tata Elxsi,N/A,"Philadelphia, PA","['AWS: 1 year (Required)', 'ETL/SQL: 5 years (Required)', 'Java: 5 years (Required)', 'Linux/Ubuntu: 1 year (Required)', 'Tableau: 5 years (Required)', 'Data Analysis: 5 years (Required)', 'Teradata, Redshift, Snowflake : 5 years (Required)', ""Bachelor's (Required)"", 'More than 1 year', 'Varies', 'Likely', 'One location', 'Monday to Friday']",2020-08-08 13:14:23
Data Engineer,"Loyalty Builders, Inc.",N/A,"Portsmouth, NH 03801","['Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Data analysis and report building: 2 years (Preferred)', ""Data integration, API's, and pipelines: 2 years (Required)"", 'C#, Python, R, or Matlab: 2 years (Preferred)', 'SQL and SQL based programing languages: 4 years (Required)', ""Bachelor's (Required)"", 'Other forms', 'One location', 'Dependable -- more reliable than spontaneous', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'www.loyaltybuilders.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:14:23
Big Data Engineer,"JPMorgan Chase Bank, N.A.",3.9 out of 5,"Jersey City, NJ","['Job', 'Company', 'BS/BA degree or equivalent experience', 'Expertise in application, data and infrastructure architecture disciplines', 'Knowledge of industry wide technology strategies and best practices', 'Keen understanding of financial control', 'Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture', 'Business facing experience is definite plus.', 'Must have proven technical expertise in:Core Java , collections, Exception Handling, Generics & MultithreadingBIG data stack - HDFS, Spark, Impala .. etc.']",2020-08-08 13:14:23
Executive Assistant / Chief of Staff,Bentley Systems,3.9 out of 5,"Exton, PA 19341","['Support the VP in preparing presentations for external and internal audiences such as users, conferences, senior leaders of the company, All Hands meetings etc.', 'Chair the team meetings, including developing the agenda to review strategic topics and monitor operational health such as success indicators, budget, colleague engagement, etc.', 'Gathering statistics to support the sales monthly, quarterly, annual report.', 'Structure Operational reviews- project reviews that drive operational efficiencies', 'Drive people development initiatives in conjunction with VP and HR Business Partner. Examples include defining and executing hiring strategies, supporting the development of a learning agenda, assisting with inclusion initiatives, and instituting policy/guidelines to respond to group’s feedback/improvement areas.', 'Establishing priorities for the VP’s calendar considering organizational and cross-group schedules and commitments. Manage day to day schedules in such a way that the executive is able to complete their obligations in an organized, efficient way.', 'Act as a proxy to the VP in requested meetings.', 'Book appropriate domestic and international travel within Concur travel policy, taking into account travel Visas, costs and proper documentation. Expense reimbursement, submission and issue tracking.', 'Business Intelligence/Sales Support work (Forecast, discount/exception approvals), using our SAP CRM system and our online reporting tools.', 'Assisting Sales with the most strategic Proposals and Sales issues.', 'Occasional support for Events organization where needed.', 'Other administrative and project duties as requested.', '5+ years of SaaS/Software or other high-tech industry experience', 'Experience with executive level calendar management', 'Experience with domestic and/or international travel coordination', 'Experience with Microsoft Office Products', 'Microsoft Suite (Outlook, Word, Excel, SharePoint, and Visio)', 'Detail-oriented, strategically adept, and a go-getter', 'Proven, applied data-driven, decision-making skillset', 'Demonstrated ability to create and drive strategies, work independently, and simultaneously manage diverse assignments while remaining organized and productive in a highly interrupt driven environment.', 'Must possess a well-developed ability to read the internal and external landscape', 'Must have strong business acumen in order to understand, prioritize, and act on the many requests received.', 'Strong ability to influence and collaborate is a must in this position, as success will be measured by ability to influence situations where no formal authority exists.', 'Excellent organizational skills, written and oral communications skills.', 'Strong desire and commitment to achieve operational excellence.', 'Must demonstrate strong teamwork, resourcefulness, and be trustworthy with sensitive information.', 'High tolerance for ambiguity, with the ability to create order.', 'Have fun at work and help others do the same!', 'Capacity to quickly learn organizational structure and the objectives of the team.', 'A terrific work ethic accompanied by an ever-positive, get-it-done attitude.']",2020-08-08 13:14:23
Data Center Production Operations Engineer,Facebook,4.2 out of 5,"Ashburn, VA","['Perform deep dives and analyze complex technical issues within the data center, ranging from automated tooling to hardware failures and network issues.', 'Work as a technical lead with cross functional teams on large scale data center projects and initiatives.', 'Provide cross data center support and identify potentially larger issues, displaying effective communication when something is identified.', 'Work with internal hardware teams and vendors to help resolve complex technical issues, maintain high hardware quality levels and influence future design to ensure ease of serviceability.', 'Understand/analyze issues and be able to update and develop scripts and smaller sets of software.', 'Use data to drive maximum server fleet up-time and utilization rates, by understanding hardware failure rates and SLAs to customers. Identify trends and systemic issues in the fleet and drive resolution.', 'Mentor team members to evaluate and identify better ways to resolve issues and define updates to tools and processes.', 'Provide guidance and mentor technical leads and the go-to technical resource for management.', 'Build cross functional relationships and have the ability to influence policies and procedures to improve global data center operations.', 'Participate in an on-call rotation.', 'BS, BA or BEng in technical field or commensurate experience.', '5+ years of infrastructure or related experience.', 'Knowledge of Linux and hardware systems support in an Internet operations environment.', 'Knowledge of the interdependencies of data center functions and technologies.', 'Experience managing multiple projects within the same time schedule.', 'Knowledge of enterprise level networking and storage equipment installs.', 'Knowledge of out-of-band/lights-out server communication methods, such as IPMI and serial console.', 'Time and project management experience.', 'Experience in modifying and developing in commonly used scripting or programming languages.', 'Proven communication skills.']",2020-08-08 13:14:23
Data Engineer,Uplight,4.3 out of 5,"Denver, CO","['Work as an Engineer on our residential analytics team, primarily developing in Python and leveraging a wide range of technologies, notably: AWS and GCP, Docker, Apache Airflow, Apache Spark, and PostgreSQL', 'Take problems from inception all the way to completion - own the building, testing, deployment, and maintenance of the code that you work on', 'Tackle complex problems that span a wide range of technical abilities, including:', 'Work effectively on an Agile team and collaborate well with your other team members.', 'A minimum of 2 years of professional experience developing in a modern programming language (Python preferred)', 'Solid knowledge of ETL and data integration', 'Existing familiarity and interest in developing Machine Learning Engineering skills', 'A value for testing and developing quality software', 'Strong critical thinking skills and a desire to work with ambiguous challenges', 'Experience working in an Agile environment and a strong understanding of the full SDLC', 'Strong troubleshooting skills that span the full-stack (front-end clients, APIs, networking, DNS, Linux, containers, databases, distributed systems, etc.)', 'Experience deploying production applications on at least one major cloud provider (AWS, GCP, Azure)', 'Experience writing and maintaining data pipelines and ETLs leveraging Spark', 'Experience working cross-functionally with design, product, customer success, sales, etc.', 'Are proud to be over 300+ rebels with an important cause by helping to create a more sustainable planet.', 'Are committed to the environment, our employees, and our communities.', 'Are focused on career growth by following defined career ladders', 'Take our work and mission seriously and….we love to laugh!', 'Provide a 401k Match', 'Have an innovative flexible time-off policy', 'Keep you energized with plenty of food and drink']",2020-08-08 13:14:23
Data Scientist,Infotree Global,N/A,"Creve Coeur, MO","['Design, implement and optimize algorithms for unsupervised and supervised learning based on structured and unstructured data.', 'Develop powerful business insights from social, marketing, industrial data and public policy using advanced machine learning techniques.', 'Work closely with the software engineering team to productize analytic software.', 'Collaborate with system integration and data warehouse engineers on data extraction and data cleaning.', 'Work in a highly interactive, team-oriented environment.', ""Requires a bachelor's degree in a STEM or related field and 5 years of experience, or a Master's degree in same with 3 years, or a PhD."", 'Temporarily due to COVID-19']",2020-08-08 13:14:23
Clinical Quality Data Engineer,Scotland Memorial Hospital,3.8 out of 5,"Laurinburg, NC 28352",[],2020-08-08 13:14:23
Data Engineer,the NBA,4.2 out of 5,"Secaucus, NJ 07094","['Understands business needs and develop solutions that delight consumers and customers', 'Understands Agile artifacts and develops applications based upon business priority.', 'Collaborate with project partners to ensure all requirements are met.', 'Handles relationships with end-user communities. Interacts regularly with users to gather feedback, listen to their issues and concerns, recommend solutions.', 'Build scalable, fault-tolerant batch and real-time data pipelines to power internal applications, operational workflows, and business intelligence platforms', 'Create and maintain data-driven APIs to support a wide range of integration with NBA partners', 'Recommend and implement best practices for data management and governance', 'Demonstrate your technical abilities and contribute to our overall architecture', 'Help implement the Enterprise Data Architecture for NBA and help implement it in multi-functional alignment with the Data teams that exist across functions like Marketing, Finance, HR etc.', 'Provide insights during application design and development for highly complex or critical machine learning projects across numerous lines of business and shared technology.', 'Ensure alignment to enterprise architecture and usage of enterprise platforms when delivering projects', 'Continuously improve the quality of deliverables and SDLC processes', ""Master's Degree in Computer Science, Engineering, or Management of Info Systems/Technology preferred"", 'Advanced Education in Statistics or Mathematics would be a plus 3+ year of experience in developing ETL and ELT pipelines using SQL and MSFT SSIS 3+ years of experience in developing BigData and/or machine learning solutions 3+ years of experience in a highly regulated industry', '1+ Years of experience defining and/or designing data architectures', '1+ Years of experience leading and/or managing product engineering teams', 'Experience with the MS Cloud stack (Azure) or AWS', 'Experience with SQL, NoSQL, BigData and Graph Technologies along with Programming languages like R, Python, Kafka, Storm etc.', 'Experience building microservices', 'Background in agile SW development and Scaled Agile Frameworks', 'A true believer in measuring success based on working software and in quick prototyping', 'Someone who is a passionate coder and can spin up a snippet of code quickly', 'Strategic thinker with the ability to build and execute innovative digital product, combined with tactical ability to execute simultaneously against multiple contending priorities', 'Someone with an iterative approach, drive to move fast and think big', 'Experience working with and/or managing internal and external teams at the same time, working with multiple brands and digital properties of varying maturities', 'Demonstrated ability to partner and communicate effectively with non-technical team members, resolving contending or contradictory objectives, and unifying disparate ideas into a homogenized solution', 'Ability to be versatile and handle multiple projects and re-prioritizations', 'Possess the ability to influence others, implement change, and standardize processes in a complex business environment', 'A passion for data and growing in your current role', 'Ability to effectively and appropriately interview technical candidates', 'Passion for Automation and Hunger for Acceleration', 'Keen knowledge of Devops as well as RPA is a big plus', 'Experience with Architecting Applications (e.g. Design Patterns, distributed applications etc.) with the aim of reuse would be a big plus', 'Superb communication skills (both written and verbal)', 'Great teammate - should be ready to go beyond to help immediate team and do not be averse to not shy away from asking for help if needed.', 'Ability to translate ideas into solutions based on user and business needs', 'Open Eagerness to learn new technologies and bring new ideas to the table']",2020-08-08 13:14:23
Data Engineer,"RIVA Solutions, Inc.",3.6 out of 5,"Washington, DC","['Under little or no supervision, responsible for the development of analytical solutions and databases.', 'Develops specifications for the most efficient database solutions.', 'Supports the evaluation and selection of solutions that meets customer requirements', 'Good working knowledge and hands-on experience with key software platform architectures, web servers, application servers, and relational databases.', 'Performs work involved in one or more of the phases of developing software used in products or services provided to the customer.', 'Designs and implements enterprise infrastructure and platforms required for cloud computing.', 'Analyzes system requirements and ensures that systems will be securely integrated with current applications.', 'Has a deep understanding of system development in cloud environments, including Software as Service (SaaS), Platform as Service (PaaS), or Infrastructure as a Service (IaaS).', 'Designs and builds relational databases for data storage or processing.', 'Develops strategies for warehouse implementation, data acquisition, and archive recovery.', ""May evaluate new data sources for adherence to the organization's quality standards and ease of integration."", 'Provide consultation on complex projects and is considered to be a top-level contributor/specialist', 'Key member of a data science project team supporting analytic development.', 'Eight (8) years relevant experience in applied data science research or big data analytics', 'Bachelor’s Degree in Computer Science, Engineering, Information Systems or related technical discipline. A Master’s degree may be substituted for up to two (2) years of experience. A PhD may be substituted for up to five (5) years of experience.', 'Ability to perform functional and data requirements analysis, and implementation of data engineering projects, analyze customer requirements and provide solution recommendations.', 'Demonstrate knowledge of information engineering methodologies, process improvement, and performance measurement.', 'Ability to support the development of organization-wide data models for use in designing and building integrated, shared software and database systems.']",2020-08-08 13:14:23
Data Modeler / ETL Engineer,Madison Logic,3.3 out of 5,"New York, NY 10010","['Use SQL/Python to create reports, dashboards, and visualizations.', 'Aggregate/Model data using SQL and use that data to build reports in BI platform.', 'Analyze data to help improve business performance.', 'Identify the best data sources for a given analysis.', 'Develop processes for data mining, data modeling, and data production.', 'Optimize and tune data models and assist the data team in building and maintaining the data warehouse.', ""Bachelor's degree in computer science, statistics or mathematics"", ""3+ year's experience with Python or Node.js"", ""4+ year's experience with SQL or mySQL"", 'Working understanding of big data analytics', 'Experience working with data cleaning and standardizing process']",2020-08-08 13:14:23
Data Center Operations Engineer I :20-02109,Akraya Inc.,3.7 out of 5,"East Wenatchee, WA 98802","['Receive and Categorize inventory daily using predefined processes and procedures.', 'Inventory hardware devices with attention to detail and conformance with internal systems.', 'Rack and document hardware installation within the datacenter using predefined processes and tools.', 'Cable and document connections between devices.', 'Assign Static IP configurations for device setup and installation.', 'Cable and confirm power on status for storage devices', 'Moderate Connectivity IP Troubleshooting', 'Basic knowledge of operating a range of operating systems and technologies.', 'Moderately familiar with MS Office applications', 'Moderately familiar with Web Based applications and browser basics.', 'Basic understanding of network & hardware terminology', ""There's also a physical end to this job so the role needs to include a description around physical activity like lifting""]",2020-08-08 13:14:23
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:15:10
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:15:10
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:15:10
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 13:15:10
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:15:10
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:15:10
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:15:10
Data Engineer (Big Data)**NO C2C**,BSI Solutions,N/A,"New York, NY 10001","['Minimize ""meetings"" to get requirements and have direct business interactions', 'Write referenceable & modular code', 'Design and architect the solution independently', 'Be fluent in particular areas and have proficiency in many areas', 'Have a passion to learn', 'Take ownership and accountability', 'Understands when to automate and when not to', 'Have a desire to simplify', 'Be entrepreneurial / business minded', 'Have a quality mindset, not just code quality but also to ensure ongoing data quality by monitoring data to identify problems before they have business impact', 'Take risks and champion new idea', '2+ years being part of Agile teams & Scrum or Kanban (must)', '3+ years of working in an object-oriented language: C, C++, Java, Scala, or other OO compiled language(must)', '2+ years of scripting (JavaScript, Python, R, Ruby, Perl, etc.) (must)', '3+ years of database & SQL(must)', 'Experience with Git/SVN and other code versioning tools', 'Experience with big data technologies a plus, such as Hadoop, Hive,impala, HBase Spark', 'Understanding of data streaming tools like Kafka, SKyline is a plus', 'Excellent troubleshooting skills', 'Strong communication skills', 'Fluent in BDD and TDD development methodologies', 'Work in an agile CI/CD environment (Jenkins experience a plus)', 'Knowledge and/or experience with Health care information domains is a plus']",2020-08-08 13:15:10
"Data Scientist/Engineer (SAS, R code, Python & Sql (Open to remote Workers))",Medidata Solutions,3.7 out of 5,"New York, NY 10003","['Power smarter treatments and healthier people with innovative analytic applications and advanced data systems', 'Create innovative applications and data flows for research and production settings with engineering best practices, transparency, and scalability.', 'Develop advanced data systems to extract, assess, integrate, transform, clean, analyze and visualize datasets for complex analytics and statistical modeling.', 'Solve complex business questions where situations or data require in-depth evaluation of variable factors.', 'Assess analytical data sources, conduct hands-on exploration to determine their value, and make them available enterprise-wide', 'Collaborate with data scientists, business leaders and cross-functional stakeholders to implement data science solutions based on business priorities and technology initiatives.', 'Advanced skills in data transformation, statistical processing, modeling dataset construction and manipulation of structured and unstructured data sources.', 'Deep experience in data engineering technologies including SAS, R, Python, SQL in a cloud setting. Familiarity in NLP and entity recognition are a plus.', 'Familiarity with statistical concepts and experience supporting complex predictive model builds and implementations.', 'Demonstrated ability to collaborate with all levels of data science, technology personnel and senior leadership.', 'Clear, concise communication abilities – writing, verbal, presentation – to all levels of technical and non-technical audiences.', 'Entrepreneurial spirit and commitment to creating rigorous, high-quality insights from data, at scale.', 'Undergraduate degree in a technical or scientific field, such as Statistics, Data Science, Computer Science, or similar. Master’s degree or PhD preferred.', '5+ years professional experience as a data scientist, data engineer, data analyst, or related role', 'Experience with clinical trial data is not required, but interest to learn and understand how these data drive medical research is paramount']",2020-08-08 13:15:10
Associate Data Engineer,NYC Cyber Command,N/A,"New York, NY 10038","['SPECIAL NOTE:', 'Developing and maintaining our data pipeline using Apache Beam, Java, Python and other data processing technologies', 'Identifying and implementing performance improvements across all pipelines', 'Engaging with data consumers and producers in order to design appropriate models to suit all needs', 'Maintaining information exchanges through publish, subscribe, and alert functions that enable users to send and receive critical information as required', 'Supporting incident management, service-level management, change management, release management, continuity management, and availability management for databases and data management systems', 'Administering databases and/or data management systems that allow for the secure storage, query, protection, and utilization of data.', 'Experience with the Agile Development Methodology', 'Practical knowledge of both Java and Python', 'Familiarity with Unix scripting, Web development, and automated testing', 'Familiarity with machine learning techniques and machine learning toolkits such as R, scikit-learn, etc.', 'Experience working with Terraform', 'Familiarity with the CI/CD process', 'At least one year professional, academic, or personal experience with software development or data engineering experience (includes internship experience);', 'At least 1 year professional, academic, or personal experience with object-oriented/object function scripting languages; preferably java or python;', 'Familiarity with or exposure to cloud application development;', 'Familiarity with distributed data processing frameworks.']",2020-08-08 13:15:10
Data Engineer,Binary tech consulting corp,N/A,"Carlsbad, CA","['7 to 9 years working experience in data integration and pipeline development with data warehousing .', 'Experience with AWS Cloud on data integration with Apache Spark, EMR, Glue, Kafka, Kinesis, and Lambda in S3, Redshift, RDS, MongoDB/DynamoDB ecosystems', 'Strong real-life experience in python development especially in pySpark in AWS Cloud environment.', 'Design, develop test, deploy, maintain and improve data integration pipeline.', 'Experience in Python and common python libraries.', 'Strong analytical experience with database in writing complex queries, query optimization, debugging, user defined functions, views, indexes etc.', 'Strong experience with source control systems such as Git, Bitbucket, and Jenkins build and continuous integration tools.', 'Experience with continuous deployment(CI/CD)', 'Databricks, Airflow and Apache Spark Experience is a plus.', 'Experience with databases (PostgreSQL, Redshift, MySQL, or similar)', 'Exposure to ETL tools including Informatica and any other .', 'BS/MS degree in CS, CE or EE.', 'Monday to Friday', 'Data Integration: 8 years (Required)', 'More than 1 year', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:15:10
Senior Data Engineer,The Boston Consulting Group - Platinion,N/A,"New York, NY","['https://strike.chat/s/schedule-chat/bcg_platinion/data_engineering/e677c?src=indeed', 'Iterative. They are excited to prototype at all levels of fidelity—and have the humility to walk away from ideas when they fail.', 'Collaborative. They have the ability and enthusiasm to work with researchers, engineers, business consultants, and other designers who will challenge and support one another.', 'Comfortable with ambiguity. They know projects and businesses move fast. That means the path forward isn’t always well-defined. They are comfortable and collaborative through our process.', 'Interdisciplinary. They deliver data products for digital solutions, deploy analytical models into production, fix existing data platforms, or coach and enable other teams in best practices depending on need.', 'Working with a diverse set of clients across domains and industries', 'Implementing data orchestration pipelines, data sourcing, cleansing, and augmentation and quality', 'control processes', 'Deploying machine learning models in production', 'Supporting data architects in designing data architectures', 'Assisting in mentoring data engineers to further their personal and professional growth', 'Supporting project management operations of a project', 'Translating business needs into solutions', 'Contributing to overall solution, integration, and enterprise architecture', '2+ years of experience working on large scale, full lifecycle data implementation projects', 'BS/BA in data engineering, software engineering, data science, computer science, applied mathematics, or equivalent experience', '2+ years professional development experience with some of the AWS/Azure/GCP data stack: S3, Redshift, AWS glue, EMR, Azure Data Warehouse, Azure Blob Store, Google Big Query', 'A deep knowledge of performant SQL and understanding of relational database technology', 'Hands-on RDBMS experience (data modeling, analysis, programming, stored procedures)', 'Expertise in developing ETL/ELT workflows with one or more of the following: Python, Scala, Java', 'Deployment of data pipelines in the Cloud in at least AWS, Azure, or GCP', 'A deep understanding of relational and warehousing database technology,', 'working with at least one of the major databases platforms (Oracle, SQLServer, Teradata, MySQL, Postgres)', 'Experience working with Big Data technologies such as Spark, Hive, Impala, Druid, or Presto', 'A solid foundation in data structures, algorithms, and OO Design with fundamentally strong programming skills', 'Proven success working in and promoting a rapidly changing, collaborative, and iterative product development environment', 'Strong interpersonal and analytical skills', 'Intellectual curiosity and an ability to execute projects', 'An understanding of “big picture” business requirements that drive architecture', 'and design decisions', 'DevOps and DataOps skills including “infrastructure as code” systems like', 'CloudFormation or Terraform', 'Data system performance tuning', 'Implementation of predictive analytics and machine learning models (MLlib,', 'scikit-learn, etc)', 'Willingness to travel around the globe to work with clients and BCG teams. At', 'times, this role involves significant travel to client sites. The amount of travel will depend on client needs and nature of projects', 'https://strike.chat/s/schedule-chat/bcg_platinion/data_engineering/e677c?src=indeed', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Relocation Assistance', 'Retirement Plan', 'Vision Insurance']",2020-08-08 13:15:10
Data Engineer,Charlie's Produce,3.4 out of 5,"Seattle, WA 98134","['Job', 'Company', 'Proven ability to deliver high quality work on time and with minimal supervision', 'Deep experience with Data Architecture, Database Design including Data Quality and Master Data Management (MDM) tools, processes and governance', 'Experience in defining the steps to perform a change, managing expectations, tracking status, and communicating to all constituents. Conceptual knowledge of IT infrastructure and supporting application across the company', 'Lead analysis, architecture, design, and development of data warehouse and business intelligence solutions', 'Work as part of a team, to design and develop cloud data solutions', 'Good experience designing highly scalable ETL processes with complex data transformations, data formats including error handling and monitoring, etc', 'Knowledge of methodologies such as Star Schema is a plus', 'Experience documenting business requirements and technical architecture/design while translating complex requirements and designs for development, testing and implementation', 'Hands-on experience in proactive monitoring of database environments (backups, recovery, capacity planning, job scheduling…), with Performance Tuning and Troubleshooting', 'Providing support for planning and performing database migrations, upgrades and updates', 'Experience on AWS, Azure, Tableau with data architecture, design, analytics and deployment is a big plus', 'Strong MS-SQL Server 2012 / 2014 experience with hands-on database design and Transact-SQL, SSIS / SSRS / SSAS development, testing, performance tuning, etc.', 'Experience in product development and / or consulting delivery engagements', 'Proven ability to communicate technical information to non-technical staff, both written and verbally', 'Candidate will be required to maintain a strong working relationship with key stakeholders at all levels within the organization to understand their business modules and must be able to work with the systems analysts to understand the necessary requirements to deliver and promote technical solutions as the business evolves.', 'Knowledgeable about technical concepts, pricnciple and apply project management methodolgies to support the business expectations', 'Expertise in SQL and experience with programming languages (Python, Java, C#,Power Shell is highly desireable)', 'Skillful at listening, prioritizing and follow ups while meeting customer expecttions.', 'Ability to work as an effective team member and self-motivated individual contributor', 'Competitive starting pay', '90 day performance-based raise', 'Yearly review with possibility of increase based on performance and tenure', 'We recognize and reward hard work and commitment. Supplemental retirement plan through our Employee Stock Ownership Plan (ESOP)', 'Employee assistance program (EAP)', 'Vacation pay, paid holidays, pre-tax commuter benefits, and free onsite parking', 'Employer-covered College Program', 'Coverage under State Sick Leave', '401(k) available', 'Health and wellness benefits including medical, dental, and vision', 'Remote Work option TBD', ""Bachelor's degree or equivalent experience required."", 'Minimum of 5 years’ experience of data architecture, business intelligence and/or consulting services, implementation, customer facing, vendor management and project management', 'Conceptual knowledge of applications and IT infrastructure', 'Familiar with the concepts, principles and practices of software applications, data bases, BI, Data warehouse platform', 'Knowledgeable and understanding of scripting and programming languages', 'One or more certifications to support the desired job description is preferred', 'Ability to travel as needed, approximately 5%', 'Knowledge of design, build and supports data base, data analytics, application integration and meeting customer expectations']",2020-08-08 13:15:10
Big Data Engineer,4S,N/A,"Arlington, VA","['Participate in architecture design', 'Design, develop, and implement scalable fault tolerant data pipelines', 'Monitor and tune existing pipelines and infrastructure', 'Maintain and improve existing solutions', 'Build metrics, analysis, machine learning, and dashboard visualizations', 'Built analytics and machine learning solutions', 'Other duties as assigned', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', 'Big Data experience in both structured and unstructured data', '5+ years working with SQL and NoSQL database platforms including data modeling, writing queries, and performing data analysis', '5+ years demonstrated professional experience with Big Data platforms and tools including Hadoop, GraphDB, Kafka, Spark.', 'Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)', 'Strong software engineering skills using Python and Scala.', 'Work experience on teams using Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', 'Familiarity with DevOps tools, e.g., Jenkins, GIT, Jira, Confluence, Sonar, Nexus', 'Experience with Data Lake concepts and design patterns', 'Experience with BI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)', 'Understanding of Data Management and Data governance best practices', 'Ability to own a project from inception to completion', 'Good communication skills', 'Decision making skills', 'Self Motivated', 'Able to work with a team']",2020-08-08 13:15:10
Data Engineer,Cielo Talent,3.3 out of 5,United States,"['Develop, test, implement and document technical engineering solutions to assist business partner’s self-service analytic needs.', 'Work on project teams consisting of business partners, architects, and other groups to identify technical and functional needs of analytical systems, and determine priority of needs.', 'Assist in efforts to analyze, define, design and document requirements for data, workflow, logical processes, hardware and operating system environment.', 'Work under broad direction and be fully accountable for own technical work and/or project/supervisory responsibilities. Receive assignments in the form of objectives. Establish own milestones and team objectives. Work is often self-initiated.', 'Champion technology internally across clients, fostering knowledge and optimization of technology to raise the bar throughout the organization, with entrepreneurial spirting to build new solutions and drive organizational change.', 'High School Diploma or equivalent required.', 'Bachelor’s degree preferred.', 'At least two years of results-oriented experience in cloud-based analytics platforms.', 'At least two years of experience with SQL on any major RDBMS.', 'At least two years of experience developing ETL solutions working with diverse data sources.', 'At least two years of experience using Python for data analysis, data science, ETL/ELT, or integrations through the building and consuming SOAP and REST APIs.', 'Deep technical expertise with cloud-based analytics platforms.', 'Proficiency in reporting and analytics tools.', 'Proficiency in Word, Excel, PowerPoint, Visio, Outlook, Internet and other related software.']",2020-08-08 13:15:10
Data Engineer,Ribbon Health,N/A,"New York, NY","['Passion and drive to simplify healthcare by building products that increase access to care and power every healthcare decision to be high-quality, cost-effective, and convenient', 'Commitment to Ribbon Health company values, working on an exceptional team, and building an exceptional company', 'Grit, hustle, desire, and a “get-it-done” attitude; strong comfort with a lean startup environment, where everyone is encouraged to participate in and contribute across all teams', 'You have experience designing and implementing data warehouses and ETL architecture in the cloud and are excited to leverage your experience to build from the ground up', 'You are very comfortable with SQL (Hive, Oracle, Vertica…etc.) and relational databases; Python experience would be a big plus but not required', 'You have a unique ability and passion for transforming large and complex datasets into information that is useful for real life decision making', 'You are able to break down ambiguous problems and propose clear data modeling designs', 'You have the ability to make thoughtful trade-offs between long-term scalability and moving quickly in the short-term', 'You care deeply about implementing best practices that ensure data integrity and reliability because you understand how our products meaningfully impact patients downstream', 'Helpful but not required: You have experience working with healthcare data (e.g. claims, directory, medical records)', 'Architect and build our data warehouse: You will design and build a data warehouse that will serve as the foundation for our data pipelines and machine learning', 'Scale our machine learning efforts: You will build data infrastructure to enable our machine learning engineers to deploy existing models to our production data pipeline and expand their analytics efforts', 'Build a data extraction framework: You will design and improve upon our current system of record for ingesting data from hundreds of different sources', 'Build data pipelines: You will integrate many data sources into the Ribbon data pipeline. You will set the standards by which other engineers building data pipelines will follow', 'Build light-weight automation: You will develop systems and tools to configure, monitor, and orchestrate our data infrastructure', 'Develop data standards: You will develop Ribbon’s internal standards for data management and data governance']",2020-08-08 13:15:10
Data Integration Engineer,Govplace,3.6 out of 5,"Reston, VA 20190","['Design, develop, test, and provide production support of integration development process.', 'Perform data analysis and data modeling to create source to target mapping documents.', 'Develop Connectors and processes for Elastic to various security sensors and tools.', 'Create documentation for the installation, configuration and implementation of these connectors and', 'Interpret functional requirements and implements them into processes between a sensor layer and dashboard', 'Perform functional testing in cybersecurity', 'Provide support to test team and to tool subject matter experts through systems engineering life', 'Provide Tier 3 support to operations teams when deployed into', 'BS in Computer Science or related field required, Masters a plus', '3-5+ years of Data Integration experience with a minimum 4 years of IT enterprise experienc', '3-5+ years of experience with system integration API such as JSON, XML, XSLT, SQL, XML and VMF (Variable Message Formats)', '3-5+ years of experience with code development interfacing with SQL, NoSQL, other relational and non-relational databases', ""3-5+ years' experience with ETL using technologies such as REST, SOAP, Native API, and WSDL, Logstash, Transporter, Python. JavaScript, XML, XSLT, JSON, SQL."", '3-5+ years of experience using technologies such as Spark, Impala, Unix Shell/KSH, control-M, SQL, Hive, and Oracle PL/SQL', 'Hands-on experience with process building & deployment, alert framework/exception handling, connectors/listeners', 'Worked in a DevOps model leveraging the following services GitHub, Jenkins, Docker, Kubernetes, Openstac', 'Understands and applies information system or operational solution related data modeling methods and tools to perform data integration tool interoperability', 'Excellent communication, and relationship skills to articulate advanced technical topics and build consensus among clients and technical stakeholders', 'Strong interpersonal and collaborations skills working in a team-oriented environment', 'Strong analytical and problem-solving skills', 'Ability to adhere to defined processes & procedures, and suggest improvements', 'Ability to effectively prioritize and handle multiple tasks simultaneously', 'Strong technical documenting skills Preferred Skills', 'Advanced SQL, NoSQL query and scripting', 'Experience with relational database systems (i.e. DB2, SQL Server).', 'Experience with non-relational databases such as (Amazon RDBS, MongoDB, Hadoop tools)', 'Experience with Python, Java', 'Understanding of data design concepts (i.e. data modeling, data mapping).', 'Overall strong background in systems engineering, security engineering, architecting, enterprise integration, and interoperability in a complex systems environmen', 'Knowledge of emerging cybersecurity technologies', 'Experience modeling data, message, and service interoperability', 'Understanding of technical, operational, and management issues related to design, development, and deployment of complex and distributed systems', 'Understanding of interrelationships between critical infrastructure protection and cybersecurity', 'Familiarity with DHS Cybersecurity programs such as Continuous Diagnostics and Mitigation (CDM)', 'Certified Information Systems Security Professional (CISSP) Certification', 'Knowledge and experience with Assessment & Authorization (A&A) processes in Federal environments, preferably with experience utilizing the NIST Risk Management Framework (RMF) for complex systems or networks', 'Powershell knowledge is a benefit', 'Must be a US citizen and pass a background', 'Able to obtain and maintain a DHS Suitability/Entry on Duty (EOD).', 'Active Secret or Top Secret clearance', 'Office work, typically sedentary with some movement around the']",2020-08-08 13:15:10
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:15:10
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:15:10
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:16:04
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:16:04
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:16:04
Data Movement Engineer (nifi),"Clarity Innovations, LLC",N/A,"Arlington, VA 22202","['Nifi', 'Kubernetes', 'Docker', 'Nexus', 'Jenkins', 'GitLab', 'Nagios or Elastic/Kibana experience', 'Strong Linux skills, including scripting', 'Strong networking skills, including DNS, TCP/IP, and firewalls', 'Ability to read, write, and debug bash/csh/sh shell scripts', 'Experience working in this customer environment.', 'Linux and CentOS/RedHat administration experience', 'Mastery of storage concepts: filesystems, extendts, luns, raid', 'Working knowledge of OpenShift', 'Grafana', 'Elastic Stack', 'Nvidia/GPU', 'Puppet/Salt', 'Web/Appplications', 'Java/JavaScript', 'ActiveMQ', 'Redis', 'Agile/SCRUM', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Schedule', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Referral Program', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'United States (Required)', 'Top Secret (Required)', 'Bonuses', 'One location', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'A job for which military experienced candidates are encouraged to apply', 'clarityinnovates.com', 'Temporarily due to COVID-19']",2020-08-08 13:16:04
Experienced Data Engineer,Principal Financial Group,3.9 out of 5,"Denver, CO","['Develop and deploy robust and scalable data platforms that efficiently process data and enable the development of advanced analytics.', 'Learn best practices, standardization and procedures around data warehousing and development processes to ensure data quality and integrity.', 'Research, maintain and evaluate emerging data engineering and warehousing technologies and solutions for continuous improvements to solve business problems.', 'Competitive pay, benefits, perks and more. We’ll reward you for the skills and experience you have. Find out more.', 'Respect for your unique perspective. Diversity, inclusion and empowerment are at the core of our culture.', 'A career, not just a job. Principal is a place where you can learn and innovate. Do important work. Make an impact. And achieve your professional goals.', 'The ability to have a great job and a great life. Sure, work is important. But so is your family. And your friends. And your community. That’s why we provide the flexibility needed to find the right balance between your job and the rest of your life.', ""Associate's or Bachelor's degree with a preference in a science, technology, engineering, or math related field or equivalent work experience (6 years of experience equates to an Associate’s degree when defining “equivalent work experience”)"", '2+ years’ experience with Functional or Object-Oriented programming', 'Strong SQL experience', 'Data Stores such as Hadoop', 'Scala/Java preferred; Python acceptable', 'System design experience', 'Cloud Platforms', 'Various extreme programming practices, including DevOps']",2020-08-08 13:16:04
QA Engineer- Remote,Software Systems & Applications,N/A,"Bethesda, MD","['Monday to Friday', 'Quality Assurance: 3 years (Preferred)', '1 year', 'Fully Remote']",2020-08-08 13:16:04
Intern,WEX Inc.,3.5 out of 5,Remote,"['Work with developers and testers to create and maintain quality products for WEX Over the Road in a SAFe agile environment.', '**This is a remote position', 'Debugs software products through the use of systematic tests to develop, apply, and maintain quality standards for company products', 'Develop, modify, and execute software test plans, automated scripts and programs for testings;', 'Analyzes and writes test standards and procedures; Write Test Cases', 'Maintains documentation of test results to assist in debugging and modification of software', 'Manually Test Software', 'Analyze test results to ensure existing functionality and recommends corrective action', 'Consult with development engineers in resolution of problems', 'A collaborative and challenging working environment', 'The opportunity to engage with various stakeholders across the business and senior leadership teams', 'To train and develop your skills in your area of work with some of the best experts in the payment industry', 'At a minimum, you should be a rising junior, senior, OR masters-level student, in a degree/certificate-seeking accredited program', 'Strong project management skills, including planning and execution', 'Strong written and verbal communication skills, including presenting information', 'Strong quantitative, analytical and problem solving skills', 'Strong interpersonal, leadership and communication skills', 'Ability to work in a dynamic, collaborative environment', 'Basic SQL Experience', 'Interested in mobile application testing and in technology']",2020-08-08 13:16:04
Help Desk Engineer,Initiate Government Solutions,5 out of 5,Remote,"['Provide end-user support for NCI developed analytical applications residing on the NCI infrastructure monitoring the performance of the computing environment and recommending enhancements and upgrades as required', 'Analytical applications may include data analysis tools and environments', 'Provide maintenance and continuous operations support of information systems and technical support services', 'Support the development, implementation and use of information systems that support the end users', 'Work with the Software Developers to trouble shoot issues with NCI Applications', 'Renewing licenses for all software installed on the infrastructure', 'Monitoring, auditing, and policy enforcement of physical, network, and user-level security of the system and resources', 'Regular maintenance procedures that impact the use of the resource during nights or weekends', 'Ensure monitoring and maintenance of servers', 'Ensure patching and configuration management of servers', 'Provide development of standard operating procedures and maintain service level agreements', 'BS in Computer Science, Software Engineering, or similar discipline with a minimum of 4 years of experience that includes knowledge of various PC and Mac operating systems, experience with networking, and with providing help desk support to end-users of the analytical tools and systems', 'Must have positive customer service attitude', 'Excellent written and communication skills', 'Ability to obtain and maintain a HHS Public Trust', 'Current HHS Public Trust', 'Experience working on federal government contracts, preferably centered around research, grants, or health informatics']",2020-08-08 13:16:04
Data Engineer with looker,Bitwise INC,3.3 out of 5,"Santa Monica, CA 90401","['ELT SQL to build to populate Redshift models. Basically, loading staging tables and then using Redshift SQL to transform/massage the data. So will need extensive capabilities in SQL coding in Redshift.', 'Python may be required to get the data from source and then load into staging tables by executing basic data standardization. Python will also be used for any analysis request using existing Python libraries.', 'Similarly Airflow is also an option to move data into the staging tables before the ELT is run within Redshift.', 'For Looker modeling they will need expertise in LookerML tool that is used for data exploration with Looker', '401(k)', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Redshift: 1 year (Preferred)', 'SQL: 5 years (Preferred)', 'Data Engineer: 5 years (Preferred)', 'ELT SQL: 3 years (Preferred)', 'Python: 3 years (Preferred)', 'Looker modeling: 1 year (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 13:16:04
Product Data Analyst,Drizly,3 out of 5,"Denver, NY","['Advise product teams on data ingestion, interpretation, and implementation.', 'Assist in the design, implementation, and analysis of A/B testing with a Product Managers.', 'Build and maintain our tracking “dictionary” for the consumer platform.', 'Create and update automated reports on an ad hoc basis.', 'Competitive salary', 'One-on-one professional coaching with an external expert', 'Health, Dental and Vision Insurance', 'Flexible vacation policy', '401(K) Plan', 'Added perks']",2020-08-08 13:16:04
Data Engineer,Clear Street,N/A,"New York, NY","['You have ~5 years of data engineering experience focused on delivering highly scalable data pipelines. Your code has handled the full ETL process used for large scale analytics across huge datasets. Your pipelines have ingested data from multiple data sources (proprietary and vendor datasets).', 'You have a strong command over object-oriented design patterns, data structures, and algorithms.', 'You communicate technical ideas with ease and always look to collaborate to deliver high quality products.', ""Your experience will help you mentor team members and accelerate the development of both our system and our team's growth."", 'You grasp product specifications and effectively map them to technical requirements. You thoughtfully and successfully incorporate these requirements into your system design and implementation.', 'You are a collaborator by nature who works effectively with product teams to understand the scope, cost, and requirements of new product feature development.', 'The opportunity to join a small and growing team of good people, where you can make a difference', 'A new, high-quality code base with little technical debt and room to build new services and features', 'An environment that embraces the utility of a DevOps oriented culture and combines it with a focus on CI/CD methodology', 'A meritocratic philosophy that champions collaboration', 'Competitive compensation, benefits, and perks']",2020-08-08 13:16:04
Data Engineer,Strive Health,4.5 out of 5,"Denver, CO","['use cloud-native infrastructure and modern software development methodologies', 'share ideas freely to keep our software and processes accessible, scalable, and sustainable', 'iterate frequently on our software and our processes to enhance outcomes for ourselves and our users', 'experiment with emerging technologies to accommodate the expanding scope of this ambitious project', 'celebrate each other’s success', 'oversee bringing new source systems into the Strive’s Data Platform using various cutting-edge technologies', 'have ability to dig into the data and understand business logic within the source system data', 'build and perform data validation tests to ensure quality via data pipeline', 'balance tasks and priorities between multiple client projects and internal initiatives; ensure assigned tasks are executed efficiently and according to project requirements and timelines', 'are an expert in Structured Query Language (SQL)', 'have experience working with EMR\\EHR systems and an understanding of the healthcare clinical domain', 'have exposure to Extract, Transform and Load (ETL) concepts and processes', 'have a working knowledge of database principles, processes, technologies and tools', 'have a working knowledge with structured and unstructured data', 'have an experience with processing HL7 messages, CCD documents, and EDI X12 Claims files.', 'have a familiarity with development methodologies, including the AGILE development approaches', 'are able to code and comprehend code around technologies that deal with acquiring data', 'have an experience working with Hadoop and other Big Data Technologies', 'have exposure to programming languages such as Python, C#, or Java', 'have 5+ years’ experience in healthcare/technology related field']",2020-08-08 13:16:04
Senior Data Engineer,Paylocity,3.7 out of 5,Remote,[],2020-08-08 13:16:04
Quality Engineer,Confidential,N/A,"Glen Mills, PA 19342","['Collect, organize, and analyze data and develop conclusions and recommendations to support the business.', 'Develops quality metrics to ensure compliance with contractual requirements.', 'Conducts reviews to ensure quality attributes are incorporated into product designs.', 'Performs analysis, tests, and process audits to ensure manufacturing & engineering readiness.', 'Provides input on dispositions for non-conformances.', 'Analyzes non-conformance trends to evaluate the effectiveness of corrective actions.', 'Recommends corrective actions to address non-conformances.', ""Bachelor's degree or higher in engineering or any technical field."", '3 + years of experience do you have developing quality metrics, reading and interpreting engineering drawings and Quality Management System (QMS).', 'Six Sigma certification.', 'American Society for Quality (ASQ) Certifications.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', ""Bachelor's (Required)"", 'American Society for Quality (ASQ) (Preferred)', 'Six Sigma (Preferred)', 'United States (Required)', 'One location', 'No']",2020-08-08 13:16:04
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:16:04
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:16:04
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:16:04
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:16:04
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:16:04
Data Science Contractor,CollegeVine,4 out of 5,Remote,"['A well-commented program (something like a Jupyter notebook is fine) that generates the ""natural"" clusters of our students. Ideally the weighting of individual features should be configurable. The output will be a clustering model we can use on new users.', 'A well-commented program (something like a Jupyter notebook is fine) that takes a clustering model and two sets of chancing parameters (A & B) as input. The program must output and visualize the delta between the A & B chancing parameters for each cluster.', 'A CSV containing the user data to be clustered.', 'A CSV containing the current chancing model parameters', 'Access to our internal documentation and APIs showing you how to apply our chancing algorithm to a set of user profiles and model parameters.']",2020-08-08 13:16:55
Fall 2020 DNC Technology Internship,Democratic National Committee,4.1 out of 5,"Washington, DC","['Secure the future of our country? Right now a lot is at stake in our country and our team has a huge opportunity to make a real difference.', 'Work with amazing people? We’re building a diverse, distributed team, hiring the best people we can wherever they are—alumni from past Presidential campaigns working out of DC and New York, experienced product developers from the SF Bay Area and across the country, and much more.', 'Never stop learning? There are people who know about politics and people who know about technology and a few who have figured out some things about how to combine the two, but we are blazing a lot of new trails and you should be comfortable exploring and learning from everyone you can.', 'Working with the rest of the DNC Tech team, and a smaller project team, in order to develop regular reporting, communication, and process / product improvements', 'Ad-hoc tasks, including but not limited to building reports using Google tools, making queries, reading other people’s work to understand it better, editing documentation for clarity or writing new documentation, building charts/reports, data entry, and/or reviewing other people’s code or writing your own', 'Meeting with a mentor within the team to discuss your process, concerns, questions, work or anything else you’re interested in (via Zoom or Google Hangouts)', 'A regularly scheduled meeting with some/all of your project team(s)', 'A recent graduate or a current undergraduate or graduate student with an interest in data and technology', 'A problem solver who is able to handle multiple tasks at once, working both independently and with others in a fast-paced office', 'Willing to commit over 30 hours / week in a remote internship (time zones flexible within the contiguous US time zones)', 'Motivated to get Democrats elected up and down the ballot', 'Knowledge of VAN/Votebuilder - bonus points if you’ve ever been an administrator or a political volunteer using these tools', 'Campaign data management relating to field campaigns, including volunteering - bonus points for electoral campaign experience', 'Databases and data management using any of the following: Microsoft Excel, MySQL, PostgreSQL, Microsoft SQL Server or similar systems', 'If you’re interested in working with the Engineering team: some experience with any programming language and an interest in developing your skills in Python and/or JavaScript']",2020-08-08 13:16:55
Data Scientist,Infotree Global,N/A,"Creve Coeur, MO","['Design, implement and optimize algorithms for unsupervised and supervised learning based on structured and unstructured data.', 'Develop powerful business insights from social, marketing, industrial data and public policy using advanced machine learning techniques.', 'Work closely with the software engineering team to productize analytic software.', 'Collaborate with system integration and data warehouse engineers on data extraction and data cleaning.', 'Work in a highly interactive, team-oriented environment.', ""Requires a bachelor's degree in a STEM or related field and 5 years of experience, or a Master's degree in same with 3 years, or a PhD."", 'Temporarily due to COVID-19']",2020-08-08 13:16:55
Big Data Engineer,"JPMorgan Chase Bank, N.A.",3.9 out of 5,"Jersey City, NJ","['Job', 'Company', 'BS/BA degree or equivalent experience', 'Expertise in application, data and infrastructure architecture disciplines', 'Knowledge of industry wide technology strategies and best practices', 'Keen understanding of financial control', 'Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture', 'Business facing experience is definite plus.', 'Must have proven technical expertise in:Core Java , collections, Exception Handling, Generics & MultithreadingBIG data stack - HDFS, Spark, Impala .. etc.']",2020-08-08 13:16:55
Data Journalist,"HealthCare, Inc.",N/A,Remote,"['Explore internal and external data sets to identify stories that will help bring light to healthcare stories around the country.', 'Write about, report on and analyze these data sets to create compelling stories for a wide audience', 'Take the initial concept to publication, while incorporating editorial changes.', 'Desire and ability to work in a cross-functional team, and communicate across functions (e.g., to designers, engineers, managers, etc.).', 'Explore data visually and prototype data visualizations, including interactive visualizations', 'Take ownership of an early-days workstream at a growing startup and push it forward, accelerating the pace of storytelling and leveling up the quality of our work.', 'Assist other team members with data research for graphics, which includes generating maps.', 'Help build a proprietary data set that is sought after in media and academic circles.', 'Stay abreast of the latest tools and techniques in data visualization and story-telling', 'Methods for parsing, scraping, cleaning, and analyzing data from a variety of sources.', 'Tableau or other data visualization tool experience', 'Masterful in Excel', 'At least two years of experience reporting and building data visualizations.', 'Experience collecting and cleaning data, with regards to best journalistic practices.', 'Experience using large amounts of quantitative information in your stories.', 'Meticulous attention to detail and exceptional organizational skills.', 'Ability to visualize complex ideas in a clear, accurate, and intelligent manner.', 'Proficiency in writing detailed and accessible methodology notes.', 'Experience working with complex internal and external data.', 'Strong writing skills - ability to produce clean, grammatically correct copy.', 'Comfortable with healthcare data, and a general interest in the healthcare system', 'Reliable/good with deadlines.', 'Remote work opportunity', 'Medical, dental, and vision with 100% company paid premiums for the employee', '15 days of paid time off', '10 company observed holidays with an additional 3 floating holidays', 'Annual learning and development stipend', '8 weeks of paid parental leave', 'Commuter benefits', '401k plan with company match', 'Most importantly, an amazing company culture established by an incredible team!']",2020-08-08 13:16:55
AWS Data Engineer,iLink Systems Inc.,N/A,"Dallas, TX 75201","['Monday to Friday', 'AWS: 3 years (Preferred)', 'Apache nifi: 3 years (Preferred)', 'data stack: 5 years (Preferred)', 'Data Engineer: 9 years (Preferred)', 'More than 1 year', 'Likely', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:16:55
Data Analyst,"Xyntek, a CXV Global Company",N/A,"Philadelphia, PA 19103","['Location: Newtown, PA', 'Department: Engineering', 'Type: Full Time', 'Min. Experience: Mid Level', 'Collect, interpret and analyze complex data sets for specific business needs;', 'Execute clean reports on data for all levels of the organization;', 'Utilize database experience and create reporting dashboards based on various source systems and spreadsheets;', 'Perform Installations, architectural analysis and oversee implementation of Databases;', 'Design and implement architectural solutions to promote a scalable, robust and manageable database environment that meets business requirements;', 'Suggest and provide process improvement initiatives as it relates to the collection and analyzation of data;', 'Experience using PowerBI and Tableau', 'Bachelors / Master’s degree in Data Analytics, Statistics, Computer Engineering, Computer Science, MIS or related IT degrees;', 'Minimum three (3) years of experience in managing and analyzing data, preferably within the Life Sciences Industry;', 'Proven track record of data management and data processing flowcharting techniques;', 'Strong technical writing, communication, statistical analysis and presentation skills;', 'Experience with Reporting Packages and Statistical Software. Specific experience with PowerBI and/or Tableau required;', 'Ability to present ideas in user-friendly language and solve complex problems;', 'Experience with Labs Instrumentation software and Manufacturing execution systems software a plus;', 'Understanding of working in regulated environments.', 'Pharmaceutical / Biotech', 'Medical Device', 'Healthcare (Hospital IT)', 'Government & Department of Defense (DoD)', 'Competitive compensation and growth tracks;', 'Annual performance-based raises and bonuses;', 'Engineering mentorship programs;', 'Technical & management career growth fast tracks.', ""Health Insurance:100% Company-paid insurance premium for employees;No deductions to the employee's paycheck.Dental Insurance:100% Company-paid insurance premium for employees;No deductions to the employee's paycheck.Vision Insurance:100% Company-paid insurance premium for employees;No deductions to the employee's paycheck.Disability Insurance:Short-Term & Long-Term Disability Insurance for illness or injury to provide security when you need it.Premiums paid by the Company.Life Insurance:Term Life Insurance to ensure your loved ones can maintain financial stability if an unexpected death should occur.Voluntary Term Life Insurance program for employee’s contribution to additional needs in the event of an unexpected death."", '401(k) with company matching;', '401(k) enrollment after one (1) year of full employment;', 'Wealth management and financial services education and resources for participants.', 'Paid Holiday Leave:Paid holidays for full-time employees including New Year’s Day, Memorial Day, Independence Day, Labor Day, Thanksgiving Day & the day after, Christmas Eve Day, and Christmas Day.Paid Vacation Leave:Five (5) days of paid vacation earned for every six (6) months worked for full-time employees.', '100% Company-paid lunches when working in the office. Xyntek orders lunch daily at no cost to the employee;', '100% Company-paid snacks. Xyntek provides in-house snacks (free of charge) to the employees;', '100% Company-paid professional events. Xyntek covers all associated fees and expenses for attendance at professional conferences, workshops, trade shows, and training;', 'Company-sponsored social gatherings & events.']",2020-08-08 13:16:55
Sr. API QA Engineer (freelance),T3,N/A,Remote,"['Work in digital agency framework', 'Work with clients to solve problems', 'Testing Web UI manually or with automation in a complex environment', 'Write, verify and report and document testing plans and processes', 'Verify and manage bugs/defects and fixes', 'Train other team members as needed', 'Ability to work flexible hours for project completion', 'Experience using Eggplant or other automation platform for testing Web UI', 'Manual Web testing experience', 'Experience writing testing strategies and test cases', 'Crossbrowser and mobile device testing experience', 'Experience using device cloud-based services to test', 'Experience testing using VMs', 'Thorough understanding of the different types of testing and when they should be utilized', 'Experience performing data-driven testing', 'Experience with CI/CD, Git and or Gitlab', 'Experience working with API testers and DEV to find root cause', 'Experience testing and knowledge of API testing a nice to have', 'Excellent analytical skills', 'Excellent verbal and written communication']",2020-08-08 13:16:55
Software Engineer/Data Engineer,BlueVoyant,3.5 out of 5,"College Park, MD 20740","['Strong hands-on programming skills, with expertise in multiple implementation languages/frameworks including a subset of Python, Java, and Scala with delivery background in middleware, and backend implementations.', 'Familiarity with large-scale, big data, and streaming data technologies, as well as exposure to a variety of structured (Postgres, MySQL) and unstructured data sources (Elastic, Kafka, and the Hadoop ecosystem) as implemented at Internet-scale.', 'Experience writing and optimizing streaming and batch analytics.', 'Experience with Agile frameworks, secure software design, test-driven development, and modern, container-delivered code deployment in a cloud-based DevOps environment.', 'BS/BA in Computer Science, Engineering, or relevant field experience.', 'Work closely with analysts to transform threat analytics into production-level code.', 'Actively contribute to application architecture and product vision.', 'Participate in requirements gathering and transformation from prototype to product design.', 'Participate in daily development stand-up meetings and regular sprint planning and product demo meetings.', 'Help us stay current on the latest data processing tools and trends.', 'Thrive in our small, fast-paced, product-driven environment', 'Collaborate with teams from across the organization', 'Deliver features and fixes on tight schedules and under pressure', 'Present ideas in business-friendly and user-friendly language', 'Create systems that are maintainable, flexible and scalable', 'Define and follow a disciplined development and engineering workflow', 'Demonstrate ownership of tasks with escalation as needed', 'Be a subject matter expert in one or more of the technologies employed', 'Relentlessly push for successful customer outcomes', 'Possess a strong interest or background in cyber security', 'Participate in all stages of an agile software development lifecycle, including product ideation, requirements gathering, architecture, design, implementation, testing, documentation, and support', 'Refine our software development methodology based on agile/lean practices with continuous feedback and well-defined metrics to drive improvement', 'Maintain up-to-date knowledge of technology standards, industry trends, emerging technologies, and software development best practices', 'Ensure technical issues are quickly resolved and help implement strategies and solutions to reduce the likelihood of reoccurrence', 'Identify competitive offerings and opportunities for innovation including assessments of risk/reward to the company.', 'Jim Penrose, COO, former EVP at Darktrace with 17 years at the NSA in key leadership roles.', 'Robert Hannigan, Chairman of BlueVoyant International, former Director of GCHQ.', 'Gad Goldstein, President BlueVoyant International and Chairman of BlueVoyant Israel, former division head in the Israel Security Agency, Shin Bet.', ""Austin Berglas, Global Head of Professional Services, former head of the FBI's New York Cyber Branch."", 'Milan Patel, Chief Client Officer, former CTO of the FBI Cyber Division.', 'Ron Feler, Global Head of Threat Intelligence and Operations, former Deputy Commander of Unit 8200, the cybersecurity division of the Israel Defense Forces.', 'Mike Wertheimer, Senior Advisor, former Research Director of NSA', 'Bill Crumm, Senior Advisor, former NSA SIGINT Director and former Cybersecurity Head, Morgan Stanley.', 'Jim Bieda, Senior Advisor, former NSA Deputy CTO.']",2020-08-08 13:16:55
Data Engineer,COTA,3.9 out of 5,"Boston, MA","['Develop and maintain various data ETL processes and the data warehouse', 'Implement quality monitoring to report on the accuracy and relevancy of processed data', 'Support data analytics requests for bespoke reports and data exports', 'Understand the available architectures and technologies, assess the available options', 'Catalog our overall schema design and reference data', 'As part of a team, own data-centric processes, develop alerts for errors and service issues, and respond to alerts', 'Contribute, shape, improve the way we use and manage infrastructure', 'Perform specialized data investigations to support analytics and custom reporting scenarios', 'Participate in code reviews with a goal of understanding the overall data pipeline and ensuring data quality', 'Holds a Bachelor’s degree in Computer Science, Information Systems, or related major, or equivalent work experience', 'Able to write well-documented, reusable, and testable code', 'Strong working knowledge of Postgres or other relational databases', 'Ability to write complex SQL queries for ETL or reporting', 'Experience with R or Pandas a plus', 'Proficiency in distributed version control systems such as git or mercurial (we use git).', 'Proficiency working as part of an Agile development team', 'Experience with workflow/scheduling frameworks a plus.', 'Design experience a plus', 'Ability to interact and communicate effectively with colleagues on requirements and set expectations accordingly', 'Ability to work independently as well as with a team', 'Excellent written and oral communications', 'Energetic and self-starting']",2020-08-08 13:16:55
Data Architect,Terazo,N/A,"Durham, NC","['View your clients’ success as your own', 'Are passionate about what you do', 'Love to teach yourself new skills', 'Seek opportunities to learn', 'Thrive in ambiguity', 'Enjoy working on a team', 'Easily adapt to new project requirements and client expectations', 'Work directly with our clients and internal executives in presale and client delivery environments to architect sustainable data solutions, design data engineering delivery plans and mentor our data engineers build and maintain these solutions.', 'Leverage your advanced software engineering expertise including experience analyzing transactional and reporting system data and available cloud and on-prem storage and retrieval options. Design interactions with large-scale processing systems, develop real-time integrations leveraging RESTful APIs, and develop scalable data structures to address our client’s most pressing data engineering needs.', 'Partner with clients and provide leadership to our data engineering team members in developing, constructing, testing and maintaining first-class data architectures.', 'Share your experience supporting real-time data, data streaming, scalability of the platform and management of large volumes of data.', 'Use your mastery of a variety of languages and tools to marry systems and data while recommending ways to improve current systems and data reliability, efficiency and quality.', 'Provide thought leadership internally and externally, always staying abreast of the very latest tools and technology available.', 'Leverage your deep expertise in data engineering best practices, serving as mentor and coach to team members, sharing the expertise throughout our team.', 'Create sophisticated analytics programs, machine learning and statistical methods to prepare data for use in predictive analytics.', 'Bring a focus to automating our clients’ work through the use of the solutions you develop.', 'Collaborate with API developers to build data-driven microservices for our clients', 'Designing, developing, scaling, and maintaining data using Spark, Kafka, Hive, Python or Scala.', 'Experience with modern ETL and workflow capabilities such as Apache Airflow, Luigi and Jenkins.', 'Experience designing and implementing SQL and NoSQL systems of record.', 'Experience designing and implementing various data hub architectures, supporting a variety of business use cases.', 'Hadoop Developer', 'Putting modern data platforms into use, including platform as a service variant.', 'Providing expertise with humility; communicating complex ideas with clients and technical staff.', 'Using Git or Github in a CI/CD development workflow.', 'Developing microservices using languages like Java, Python or JavaScript and using REST APIs.', 'Writing effective technical documentation and thought leadership artifacts (best practices, blogs, client documentation).', 'Automating deployments using DevOps tools like Docker, Ansible, Terraform, or Kubernetes.']",2020-08-08 13:16:55
Data Engineer,HEB,4.3 out of 5,"San Antonio, TX 78204","['Work with HEB Digital teams to provide data solutions for e-commerce, supply chain, store operations, finance, and marketing reporting and analytics platforms', 'Contribute to existing data platforms and implement new technologies', 'Develop a deep understanding of HEB’s data and become a domain expert', 'Ensure data is distributed in a timely and accurate manner', 'Make data discoverable and accessible to business users', '2+ years of data engineering experience', 'Proficient with data technologies (e.g. Spark, Kinesis, Kafka, Airflow, Oracle, PostgreSQL, Redshift, Presto, etc.)', 'Experienced with designing and developing ETL data pipelines using tools such as Airflow, Nifi, or Kafka.', 'Strong understanding of SQL and data modeling', 'Understanding of Linux, Amazon Web Services (or other cloud platforms), Python, Docker, and Kubernetes', 'Experienced with common software engineering tools (e.g., Git, JIRA, Confluence, or similar)', ""Bachelor's degree in computer science or comparable field or equivalent experience"", 'A proven understanding and application of computer science fundamentals: data structures, algorithms, design patterns, and data modeling', 'A robust Benefits plan with coverage starting Day One', 'Dental, vision, life, and other insurance plans; flexible spending accounts; short term / long term disability coverage', 'Partner Care Team, for any time you have healthcare or coverage questions', 'Telehealth offers 24/7 access to board-certified doctors by phone', 'Partner Guidance allows free counselor visits', 'Funeral leave, jury duty, and military pay (subject to applicable law)', 'Maternal / paternal leave for new parents, including adoptions', '10% off H-E-B brand products in-store and online', 'Eligibility to participate in 401(k)', 'Opportunity to become a “Partner-Owner” after 12 months', 'H-E-B is one of the largest, independently owned food retailers in the nation, operating over 400 stores throughout Texas and Mexico, with annual sales generating over $25 billion', 'We hire talented people (109,000+ Partners), and give them autonomy to be creative in how they impact the business', 'We’re a Partner-driven company with a Bold Promise – Because People Matter', 'We embrace Diversity and Inclusion as core values, and support them with thriving company-wide programs', 'We’re a truly original Texas-based company that created the Spirit of Giving to help Texas communities every day', 'Once eligible, our Partners become Owners in the company. “Partner-owned” means our most important resources—People—drive the innovation, growth, and success that make H-E-B The Greatest Retailing Company']",2020-08-08 13:16:55
Data Engineer,Budget Dumpster,4 out of 5,"Westlake, OH 44145","['Job', 'Company', 'Develop and maintain in-house databases specifically designed for the company.', 'Ability to extract and transform data into information essential to the business from various sources internally and externally.', 'Work with the analytics and technology teams to gather requirements and turn those requirements into a function specification/design.', 'Manage ETL activities and support application development work.', 'Gather feedback from the divisions on the effectiveness and operation of the ERP/CRM system. Make recommendations for enhancements, improvements, and changes.', 'Design, implement and build pipelines that deliver data with measurable quality.', 'Own and document foundational company metrics with a clear definition and data lineage.', 'Must have at least 3+ years of experience with SQL Server and CRM database management', 'Experienced with: Microsoft SQL Server, Stored procedures, jobs, and triggers, and Enterprise application support', 'Preferred experience with: Python, Tableau, ETL and API tools', 'Experience with Salesforce preferred', 'Ability to work in a fast-paced, dynamic environment', 'Attention to detail, proactive, and good organization', 'Can analyze, reason and make decisions independently', 'Salary will commensurate with experience', 'Vacation that includes 10 days of PTO (pro-rated from start date) plus 8 major holidays', '401K with 4% match', '$3k annually contributed to health care (vision & dental available too)']",2020-08-08 13:16:55
Big Data Engineer,Avani Systems,N/A,"Seattle, WA","['Ensure high throughput of development teams by identifying potential issues, removing impediments or guiding the team to remove impediments by collaborating with the appropriate resource', 'Manage sprint planning and execution which includes the management of project progress and provide status and visibility', 'Facilitate release planning and scheduling by providing empirical Scrum team statistics, identifying project dependencies, and creating velocity forecasts', 'Assist with internal and external communications to improve transparency and radiate information ensuring the team’s progress and successes are highly visible to all stakeholders including the team itself (e.g. backlogs, burn down/up charts, etc.)', 'Develop pipelines using copy activity from different sources like FTP, Windows Blob Storage, SQL SERVER, COSMOS big data etc. and scheduling the pipelines as per requirement using azure data factory.', 'Required minimum Bachelor’s degree in Computer Science']",2020-08-08 13:16:55
"Data Engineer, Amazon Games",Amazon.com Services LLC,3.6 out of 5,"San Diego, CA","['Job', 'Company', '5+ years of industry experience in data engineering, with a track record of manipulating, processing, and extracting value from large datasets', 'Demonstrated strength in data modeling, ETL development, and data warehousing', 'Experience using big data technologies (Airflow, EMR, Columnar Data Warehouses, Spark etc.)', 'Knowledge of data management fundamentals and data storage principles', 'Knowledge of distributed systems as it pertains to data storage and computing', 'Have a penchant for digging deep and attacking difficult and complex problems.', 'Be a self-starter who is able to work alone or as a member of a team.', 'Excellent oral and written communication skills as well as strong analytical and problem-solving skills.', 'Ability to work on multiple concurrent projects and interface with all levels within the organization.', 'Architect scalable data pipelines that handle millions of events per second in a cost-effective manner using AWS technologies including Airflow, Spark, EMR, Glue, Kinesis, Redshift/Spectrum and Athena.', 'Create automated ingestion, processing, cleaning and aggregation of large data sets', 'Design user access controls that allows partial and complete data access to large and diverse groups of users', 'Work closely with game teams, Twitch, finance and marketing to build data solutions.', 'Help continually improve ongoing reporting and analysis processes', 'Experience working with AWS big data technologies (Redshift, S3, EMR)', 'Experience with Airflow or other similar ETL tools', 'Experience providing technical leadership and mentoring other engineers for best practices on data engineering', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Familiarity with statistical models and data mining algorithms', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Meets/exceeds Amazon’s leadership principles requirements for this role.', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role.']",2020-08-08 13:16:55
Data Engineer,DISH,3.3 out of 5,"New York, NY 10014","['Design and build ETL jobs in a managed AWS environment', 'Provide support and enhancements for existing automation workflows and applications', 'Perform SQL-based exploratory analysis using Apache Hive and Presto (AWS Athena)', 'Communicate effectively with project stakeholders to gather requirements, identify operational shortcomings, propose technical solutions, and deliver production-ready outcomes', 'Present results to key stakeholders in the form of visualizations, dashboards, and presentations', 'Effectively identify and prioritize support issues and respond with the appropriate level of urgency', 'Maintain concise documentation in a version control environment', 'Degree in Computer Science, Mathematics, or a STEM related field', 'Experience with AWS services including Data Pipeline, Athena, CloudFormation, etc.', 'Hands-on development experience in Python, Java/C++, Perl, etc.', '2+ years of data engineering or software development experience preferred', 'Experience with version control', 'Strong knowledge of SQL and database applications such as MySQL, SSMS, Oracle, etc.', 'Experience in a Linux environment with knowledge of basic shell scripting preferred', 'Familiarity with Big Data Applications such as Hadoop', 'Experience with data visualization tools such as Tableau and Excel', 'Excellent verbal and written communication skills', 'Strong organizational skills, attention to detail, and the ability to focus in a fast-paced workplace']",2020-08-08 13:17:38
IT Specialist - Career Development Program,Air Products,3.8 out of 5,"Allentown, PA","['Currently pursuing a degree in Computer Science, Information Systems, or Information Technology graduating between December 2020 and June 2021.', 'Strong academic performance; minimum GPA 3.0.', 'Relevant work experience (co-ops or internships) and involvement in campus activities.']",2020-08-08 13:17:38
Data Engineer with looker/lookml,Bitwise INC,3.3 out of 5,"Santa Monica, CA 90401","['ELT SQL to build to populate Redshift models. Basically, loading staging tables and then using Redshift SQL to transform/massage the data. So will need extensive capabilities in SQL coding in Redshift.', 'Python may be required to get the data from source and then load into staging tables by executing basic data standardization. Python will also be used for any analysis request using existing Python libraries.', 'Similarly Airflow is also an option to move data into the staging tables before the ELT is run within Redshift.', 'For Looker modeling they will need expertise in LookerML tool that is used for data exploration with Looker', '401(k)', 'Health Insurance', 'Paid Time Off', '8 Hour Shift', 'Monday to Friday', 'Redshift: 1 year (Preferred)', 'SQL: 5 years (Preferred)', 'Data Engineer: 5 years (Preferred)', 'Airflow: 1 year (Preferred)', 'Python: 5 years (Preferred)', 'PageLooker: 1 year (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 13:17:38
Data Intelligence Engineer,ERGO,N/A,"New York, NY 10036","['Design, develop and optimize database queries', 'Work with our Data Scientists to create data-driven insights and reports for senior management', 'Assist Data Scientists in developing processes to migrate data from various formats and data sources (Oracle, MySQL, Sybase, flat files, etc.) to database architecture', 'Design and implement tools to analyze very large data set of raw data', 'Process unstructured data into a form suitable for analysis', 'Perform ad hoc data updates and other follow-on data services', 'Automate recurring analytics reports for clients', 'Bachelor’s degree or higher in Computer Science, Information Systems or related field', 'Highly proficient in SQL (MySQL, Postgres)', 'Expertise with relational databases (implementation, queries, modeling)', 'Working knowledge of distributed data stores (Cassandra, Redshift, Hadoop, HBase)', 'Proficient in scripting language of choice (Python, R, PHP, Ruby)', 'Expertise with optimizing query performance', 'Familiarity with NoSQL technologies (Mongo DB, DynamoDB)', 'Deep understanding of data structures and schema design', 'Detail-oriented, proactive problem solving skills', 'Choice of Blink Gym or Citibike membership', 'Bagel Mondays', 'Working From Home Fridays', ""Total of 24 PTO package that includes things like: company shut down between Christmas and New Years, Presidents' Day, Martin Luther King, Jr. Day, two 4-day weekends on the summer holidays, July 4th and a 4-day Thanksgiving break. This also includes 10 PTO days to use at your convenience."", 'Office bar cart, daily produce, healthy and unhealthy snacks, Nespresso', 'Pool table', 'Health, vision & dental benefits', '401k plan with matching', 'Pet-friendly office', 'Referral bonus program', 'A comprehensive career development program and training', 'Fun company outings and events', 'Very cool industrial-style West Village studio space']",2020-08-08 13:17:38
Data Center Production Operations Engineer,Facebook,4.2 out of 5,"Ashburn, VA","['Perform deep dives and analyze complex technical issues within the data center, ranging from automated tooling to hardware failures and network issues.', 'Work as a technical lead with cross functional teams on large scale data center projects and initiatives.', 'Provide cross data center support and identify potentially larger issues, displaying effective communication when something is identified.', 'Work with internal hardware teams and vendors to help resolve complex technical issues, maintain high hardware quality levels and influence future design to ensure ease of serviceability.', 'Understand/analyze issues and be able to update and develop scripts and smaller sets of software.', 'Use data to drive maximum server fleet up-time and utilization rates, by understanding hardware failure rates and SLAs to customers. Identify trends and systemic issues in the fleet and drive resolution.', 'Mentor team members to evaluate and identify better ways to resolve issues and define updates to tools and processes.', 'Provide guidance and mentor technical leads and the go-to technical resource for management.', 'Build cross functional relationships and have the ability to influence policies and procedures to improve global data center operations.', 'Participate in an on-call rotation.', 'BS, BA or BEng in technical field or commensurate experience.', '5+ years of infrastructure or related experience.', 'Knowledge of Linux and hardware systems support in an Internet operations environment.', 'Knowledge of the interdependencies of data center functions and technologies.', 'Experience managing multiple projects within the same time schedule.', 'Knowledge of enterprise level networking and storage equipment installs.', 'Knowledge of out-of-band/lights-out server communication methods, such as IPMI and serial console.', 'Time and project management experience.', 'Experience in modifying and developing in commonly used scripting or programming languages.', 'Proven communication skills.']",2020-08-08 13:17:38
Data Engineer - Top Secret Clearance Required,Deloitte,4 out of 5,"Arlington, VA 22209","['Perform project tasks independently, and may direct the efforts of others', 'Participate in and/or lead the development of deliverable content that meets the needs of the client and contract', 'Anticipate client needs and formulate solutions to client issues', 'Review deliverables for accuracy and quality', 'Provides coaching to junior staff', 'Contribute to new business proposals and proposal development', 'Manages own personal and professional development; seeks opportunities for professional growth and expansion of consulting skills and experiences', 'Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms', 'Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions', 'Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements', 'Active Top Secret Level Government Security Clearance (SCI Eligible)', '3+ years of professional experience.', '3+ years of experience as a Data Engineer or ETL Developer', '2+ years of experience with data modeling, data profiling, and relational database technologies (e.g. Oracle, MySQL).', '2+ years of SQL and PL/SQL experience', ""Bachelor's degree in Computer Science, Engineering, Mathematics or other business-related field"", 'Ability to reverse engineer existing data models into conceptual and logical data model constructs.', '2+ years of relevant consulting or industry experience', 'Prior experience migrating data from a legacy platform to a modern platform', 'Prior professional services or federal consulting experience']",2020-08-08 13:17:38
Junior Data Science Research Engineer,Technica Corporation,3.7 out of 5,"Dulles, VA","['Support a team of Developers and Data Scientists working on a variety of research and development projects as well as customer projects', 'Research and analyze cutting edge algorithms and technologies with a focus on Natural Language Processing and data visualization techniques', 'Effectively communicate results of research and analysis with teammates and senior management in the form of essays, whitepapers, and Powerpoint presentations', 'Design, Develop and Deploy:', 'Automated analytic software, techniques, and algorithms', 'Data-driven analytics; event-driven analytics', 'Bachelor’s in Computer Science, Mathematics, or relevant technical field', '1+ years’ experience using Natural Language Processing techniques', '1+ years’ experience with web frameworks (React, Flask, NodeJS)', '1+ years’ experience with Python', 'Eligible to obtain a U.S. Secret clearance', 'Using Linux as a development operating system', 'Professional experience with Docker and Singularity container platforms', 'Professional experience with Machine Learning toolkits such as Tensorflow, Pytorch', 'Professional experience with customer facing data visualization', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Python: 1 year (Required)', 'Natural Language Processing techniques: 1 year (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'Secret (Preferred)']",2020-08-08 13:17:38
Data Engineer,CircleBlack,N/A,"Jersey City, NJ 07302","['Contribute to the data platform design and implement scalable, extensible solutions that supports key business data ingestion flows.', 'Gather and document requirements for future system enhancement working with both the business, production, and core systems teams', 'Design and Build pipelines that support the ingestion, analysis, and enrichment of financial data.', 'Improve the existing data platform to increase the throughput and accuracy of data.', 'Identify areas of automation opportunities and implement improvements.', 'Work with the business team to analyze, understand and map source data fields from custodial and market data sources to expand and improve the platform.', 'Work closely with the production team to identify, troubleshoot, and resolve issues.', 'BA/BS in Computer Science / related technical field or equivalent practical experience.', '2+ years of relevant work experience developing with Python in a MySQL environment', 'Experience building maintainable and testable code bases in an agile environment', 'Experience with object-oriented programming and understanding of data structures and algorithms', 'Exceptional Problem solving and analytical skills.', 'Excellent communication, interpersonal, time management and conflict resolution skills', 'Knowledge of SQL and relational database concepts and the ability to develop complex and efficient queries', 'Knowledge of financial concepts (e.g., stocks, bonds, etc.) is encouraged', 'Knowledge of Linux (preferable Centos), Amazon Web Services (AWS) EC2 and RDS, as well as Javascript a plus', 'Possess an enthusiastic and positive attitude', '401(k)', 'Dental Insurance', 'Employee Assistance Program', 'Employee Discount', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'No: Not providing sponsorship for this job', 'Dependable -- more reliable than spontaneous', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'www.circleblack.com', 'https://www.facebook.com/CircleBlackInc/', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:17:38
Data Engineer,ITTStar Consulting LLC,N/A,"Alpharetta, GA","['Alpharetta, GA.', 'Full time', '$90,000 - $110,000 / year', '40h / week', '2+ years experience', 'Master or Bachelor']",2020-08-08 13:17:38
Lead Data Engineer,"Canopy One Solutions, Inc.",N/A,"San Diego, CA 92109","['Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:17:38
"Data Engineer, AVS",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', 'Design, implement and support an analytical data infrastructure', 'Managing AWS resources including EC2, EMR, S3, Glue, Redshift, etc.', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies', 'Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency', 'Collaborate with Data Scientists and Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis', 'Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Maintain internal reporting platforms/tools including troubleshooting and development. Interact with internal users to establish and clarify requirements in order to develop report specifications.', 'Work with Engineering partners to help shape and implement the development of BI infrastructure including Data Warehousing, reporting and analytics platforms.', 'Contribute to the development of the BI tools, skills, culture and impact.', 'Write advanced SQL queries and Python code to develop solutions.', 'Design, implement and support an analytical data infrastructure', 'Managing AWS resources including EC2, EMR, S3, Glue, Redshift, etc.', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies', 'Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency', 'Collaborate with Data Scientists and Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis', 'Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Maintain internal reporting platforms/tools including troubleshooting and development. Interact with internal users to establish and clarify requirements in order to develop report specifications.', 'Work with Engineering partners to help shape and implement the development of BI infrastructure including Data Warehousing, reporting and analytics platforms.', 'Contribute to the development of the BI tools, skills, culture and impact.', 'Write advanced SQL queries and Python code to develop solutions.', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)', 'Implement standardized, automated operational processes to deliver accurate and timely data for reporting to meet or exceed SLAs', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Experience transforming complex data sets. Experience in evaluating data accuracy and quality.', 'Experience working directly with remote technical teams and client services', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Implement standardized, automated operational processes to deliver accurate and timely data for reporting to meet or exceed SLAs', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Experience providing technical leadership and mentoring other Data Engineers for best practices on data engineering']",2020-08-08 13:17:38
Product Data Scientist,Twitter,4.1 out of 5,"New York, NY","['Experience using data intelligently to optimize product performance', 'Experience performing analysis on raw event data in modern data warehouse systems', 'Deep understanding of data platforms in which you’ve previously worked', 'Good understanding of how to grow and shape data tools and datasets to improve data-driven decision making', 'Ability to thrive in an unstructured environment, working autonomously on a strong team to find opportunity and deliver business impact', 'Good understanding of (one or more of the following): Python or R', 'Past experience in adtech', 'PhD or MS in computer science, machine learning, or statistics', 'Good understanding of (one or more of the following): Java, Scala, or C++', 'Interesting side projects or Kaggle competition results']",2020-08-08 13:17:38
Data Engineer,"Loyalty Builders, Inc.",N/A,"Portsmouth, NH 03801","['Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Data analysis and report building: 2 years (Preferred)', ""Data integration, API's, and pipelines: 2 years (Required)"", 'C#, Python, R, or Matlab: 2 years (Preferred)', 'SQL and SQL based programing languages: 4 years (Required)', ""Bachelor's (Required)"", 'Other forms', 'One location', 'Dependable -- more reliable than spontaneous', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'www.loyaltybuilders.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:17:38
Quantitative Developer / Engineer,Luminous Analytics,N/A,"New York, NY 10016","['Skilled in creating and building models, and building successful strategies.', 'Background working across multi-asset classes, with a focus on ETF, Equities, Indexes, Bonds, Fixed Income, etc.', 'Present and defend model results.', 'Data and complex statistical analysis, utilize SAS, R and Python.', 'Create, design, implement and maintain systems for pricing, analysis, etc.', 'Excellent quantitative / quant, researcher, and programming skills.', 'Develop and create predictive models and analytic frameworks.', 'Good Financial Risk Management, Credit Risk Models, Value at Risk (VaR), etc.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', 'Quantitative Developer: 7 years (Preferred)']",2020-08-08 13:17:38
Data Engineer,Budget Dumpster,4 out of 5,"Westlake, OH 44145","['Develop and maintain in-house databases specifically designed for the company.', 'Ability to extract and transform data into information essential to the business from various sources internally and externally.', 'Work with the analytics and technology teams to gather requirements and turn those requirements into a function specification/design.', 'Manage ETL activities and support application development work.', 'Gather feedback from the divisions on the effectiveness and operation of the ERP/CRM system. Make recommendations for enhancements, improvements, and changes.', 'Design, implement and build pipelines that deliver data with measurable quality.', 'Own and document foundational company metrics with a clear definition and data lineage.', 'Must have at least 3+ years of experience with SQL Server and CRM database management', 'Experienced with: Microsoft SQL Server, Stored procedures, jobs, and triggers, and Enterprise application support', 'Preferred experience with: Python, Tableau, ETL and API tools', 'Experience with Salesforce preferred', 'Ability to work in a fast-paced, dynamic environment', 'Attention to detail, proactive, and good organization', 'Can analyze, reason and make decisions independently', 'Salary will commensurate with experience', 'Vacation that includes 10 days of PTO (pro-rated from start date) plus 8 major holidays', '401K with 4% match', '$3k annually contributed to health care (vision & dental available too)']",2020-08-08 13:17:38
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:18:19
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:18:19
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:18:19
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:18:19
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:18:19
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:18:19
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:18:19
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:18:19
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:18:19
Sr. Data Engineer,Centerfield,3 out of 5,"Los Angeles, CA","['Help to implement maintenance strategy for all datasets', 'Work with relevant stakeholders to deliver appropriate BI, data warehousing, reporting, and analytical infrastructure required to support Centerfield’s assets', 'Own problems from end-to-end, so that you can best collect, extract, and clean the data', '5+ years working in a Data Engineer, BI Engineer, or Data Warehousing Engineer role', 'Strong experience with any ETL tool like Talend or SSIS or Informatica, etc.', 'Experience with Google Big Query, Google Analytics', 'Ability to lead projects individually and deliver them on time', 'Strong experience in performance tuning techniques', 'Experience with real-time streaming implementation and architecture', 'Experience building reports and with data visualization with any BI tools like Tableau, Power BI, etc.', 'Strong foundation in SQL coding and experience with ETL processes', 'ETL tools like Talend or SSIS or Informatica, etc.', 'BI tools like Tableau, PowerBI, or Microstrategy etc.', 'Experience with NoSQL databases like MongoDB, DynamoDB, Druid, etc.', 'Amazon Web Services (S3, SQS, Redshift, DocumentDB, etc.)', 'Experience with Python', 'Competitive salary + quarterly bonus', 'Unlimited PTO – take a break when you need it!', 'Industry leading medical, dental, and vision plans + generous parental leave', '401(k) company match plan – fully vested day 1', 'Outside patio overlooking Playa Vista + cabanas, fire pits, & working grills', 'Monthly happy hours, catered lunches + daily food trucks', 'Award winning culture & unprecedented team spirit (featured in LA Business Journal & Built In LA)', 'Fully stocked break rooms with drinks & snacks', 'Break room fully stocked with games, workout equipment + weekly in-office exercise classes (yoga, kickboxing, & circuit training', 'Free onsite gym + locker rooms', 'Paid charity and volunteer days (local mentor programs, adopt a pet, beach cleanup, etc.)', 'Monthly team outings (ball games, casino night, hikes, etc.)', 'Career growth – we enjoy promoting from within!']",2020-08-08 13:18:19
Senior Software Engineer - Big Data Analytics,Proofpoint,3.9 out of 5,"Boston, MA 02108",[],2020-08-08 13:18:19
Entry Level Federal Associate Data Science,IBM,3.9 out of 5,"Washington, DC 20001","['Implement and validate predictive and prescriptive models, create and maintain statistical models with a focus on big data', 'Incorporate a variety of statistical and machine learning techniques in your projects', 'Write programs to cleanse and integrate data in an efficient and reusable manner', 'Use leading edge and open-source tools such as Python or R combined with IBM tools and our AI application suites', 'Work in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors', 'Communicate with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions', 'Evaluate modelling results and communicate the results to technical and non-technical audiences', 'Ability to look at things differently, debug, troubleshoot, design and implement solutions to complex technical issues', 'Strong technical and analytical abilities, a knack for driving impact and growth', 'Basic understanding of statistical programming in a language such as R, Python, SAS, SPSS, Hadoop, Spark, Tableau or D3 and exposure to Machine Learning and Big Stack Development', 'Proficiency in at least one computer programming language is a plus such as Java, C++, JavaScript, Node, JSs', 'Basic understanding of Cloud (AWS, Azure, etc.)', 'Ability to thrive in a team-based environment', 'Excellent verbal and written communication skills', 'Work or internship experience using data science tools in a corporate environment', 'Interest in, understanding of, or experience with Design Thinking and Agile Development Methodologies', 'Willingness to relocate to the Washington, DC metropolitan area', 'Many jobs within GBS Federal Sector require U.S. citizenship and/or security clearance because of government or contract requirements. If you are not a U.S. citizen or are unable to obtain security clearance, there may be limited work opportunities for you, which may affect your continued employment at IBM.', 'Bachelor’s Degree from an accredited 4-year institution coupled with internship, work, and/or project experience, which will provide the analytical and technical acumen that translates to an entry level consulting role.', 'While many Federal projects are located in the Washington, DC area and have limited travel, candidates must be willing and able to travel up to 100% of the time, if project/business needs require.']",2020-08-08 13:18:19
Data Engineer I,Ryder,3.4 out of 5,"Franklin, TN 37067","['Develop and maintain a robust data lake architecture', 'Develop and maintain an ETL and data management strategy', 'Utilize integrated data to prioritize, synthesize and develop solutions to key business problems', 'Utilize predictive and prescriptive modeling techniques using mathematical modeling and traditional statistical approaches in addition to the latest algorithm technology in machine learning and artificial intelligence', 'Design critical analytical dashboards, reports and queries to drive strategic business decisions, ad-hoc analysis and identify descriptive and prescriptive solutions for internal Ryder teams and our external customers', ""Think on your feet, communicate constantly and professionally, and above all else drive solutions to meet the expectations of our external and internal customer's business requirements"", ""Bachelor's degree Business Administration, Supply Chain, Computer Science, Data Analytics or equivalent"", ""Master's degree Computer Science, Data Analytics, Operational Research, Mathematics or equivalent preferred"", 'Two (2) to four (4) years or more experience in demonstrating advanced analytics, digital transformation, data management, dashboarding and/or product management skills in an educational/project or intern type environment with a Bachelor’s degree', 'One (1) year or more experience in demonstrating advanced analytics, digital transformation, data management, dashboarding and/or product management skills in an educational/project or intern type environment with a Master’s degree', 'Two (2) to four (4) years or more experience in analytics, data extraction, transformation & loading, data visualization, and agile development. Experience working in a cloud environment a plus (AWS/Azure) preferred', 'Ability to:Articulate issues, present ""pros and cons"" and provide solutions to next supervisory level preferredExpress complex technical concepts in business termsPartner with colleagues to identify the role that data, cloud, and intelligence play in the digital product, defining tactical opportunities to build into product roadmapPartner with technology teams to identify the platform and cloud capabilities required to support product innovation, working closely with technology throughout the build, test, and release of the product using continuous improvement continuous deployment processes', 'Strong verbal and written communication skills', 'Time management, collaboration, organization and presentation skills. Proficiency in Agile Design Thinking methodology, with a focus on managing solution driven strategy plans to achieve goals', 'Knowledge of supply chain management and third party logistics industries (intermediate level)', 'Experience using tools like:ETL tools (Paxata or SSIS)Data manipulation tools (SQL or Python)Object oriented development stacks (.net) (intermediate level)', 'Experience developing BI solutions with tools like:TableauPower BiMicroStrategy (intermediate level)', 'Exposure to the development of predictive analytic solutions using predictive analytics tools like:AlteryxPythonR+Stat/ML (intermediate level) preferred', 'Enhance Data Maturity by interacting with the business to understand their decision making information needs and serve as a liaison with IT source system owners so data is structured, loaded and processed in the data lake in an accurate and timely manner. Establish standards, processes, methodologies and governance for data integration across the enterprise to ensure the data is relevant, clean and usable. Demonstrate Data Integration leadership across disciplines and domains to facilitate consensus, buy-in and adoption by engaging, teaching, training, and mentoring peers and associates', 'Develop Dashboards by understanding business needs, interpret the integrated data and translate this into usable visualizations to drive business decisions. Assist the business with interpreting results and how to utilize the dashboards. Support the business with evaluating needs and ad-hoc requests to prioritize efforts. Coordinate efforts across dash boarding resources and provide guidance and support', 'Utilize Advanced Analytics to develop solutions to address key business problems. This will be done through predictive and prescriptive modeling techniques along with the ability to think on your feet, communicate constantly and professionally, and above all else drive solutions to meet the expectations of our external and internal customer’s business requirements', 'The Data Engineer I will be a specialist of data integration and analytics, bringing the required qualitative (to understand why they are doing) and quantitative (to analyze data to surface meaningful insights) skills', 'This position will be an expert in the Ryder business, understanding the complexity of the supply chain world and the role that advanced products play within the Supply Chain ecosystem', 'Performs other duties as assigned.']",2020-08-08 13:18:19
Quality Technician,Masco,3.4 out of 5,"Aston, PA","['Data entry for Quality Systems—inspections, material rejections, etc.', 'Inspection- incoming, in-process, final. measure material, parts or assemblies against a standard to ensure high quality parts are going to our customers.', 'Troubleshooting/material review with manufacturing engineer.', 'Standard work/process documentation, creation and updates as needed.', 'Record keeping/production log management for traceability of our products.', 'Quality stamp/operator number system upkeep- assign qa numbers to new employees and maintain stamp log.', 'Assist in process reviews with manufacturing engineer.', 'Assist with training as required & ensures procedures are being signed off once operators are trained.', 'Assist with time studies of our processes as required.', 'Audits as required- safety, 5s, kanban, etc.', 'Other documentation updates as needed- updating inspection criteria (aql level), etc.', 'Attending meetings with qa or other departments as required.', 'Assisting with gauge calibration as required.', 'Use hand tools and measuring tools regularly.', 'Assisting with continuous improvement efforts as required- Kaizen, projects, etc.', 'Proficient in MS Office suite, primarily Excel & Word.', 'Must be able to read Engineering Drawings.', 'Time management skills and multitasking ability.', 'Math skills including adding, subtraction, multiplication, and division.', 'Must be able to read and interpret documents such as Procedures, Engineering drawings and data sheets.', 'Must be able to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form.Ability to deal with problems involving several concrete variables in standardized situations.', 'Experience using hand tools and measuring tools.', 'Able to communicate well, verbally and in writing.', 'Able to work well with, and build/maintain positive relationships with other departments, co-workers, and vendors.', 'Able to stand and walk for long periods of time.', 'Able to sit for long periods of time', 'Able to work in front of a computer screen for long periods of time', 'Able to lift up to 50 pounds on occasion.', 'The noise level in the work environment can be in a loud manufacturing environment.']",2020-08-08 13:18:19
Data Engineer,Autoweb Inc,N/A,"Brimfield, MA 01010","['Selecting and integrating any Data tools and frameworks required to provide requested capabilities', 'Knowledge of Cloud infrastructure and services (AWS/Azure/GCP)', 'Strong Analytical and Reasoning Skills', 'Implementing ETL process', 'Monitoring performance and advising any necessary infrastructure changes', 'Defining data retention policies', 'Knowledge of various ETL techniques and frameworks', 'Experience with integration of data from multiple data sources', 'Proficient understanding of distributed computing principles', 'Proficient in Application Development code like Java, C# or Python', 'Proficient understanding of Data Store technologies like Relational Databases and NoSQL but not limited to those.', 'Good understanding of Lambda Architecture, along with its advantages and drawbacks', 'Experience with various messaging systems, such as Kafka or RabbitMQ', 'Knowledge of Cloud based solutions', 'English: 75% oral English proficiency, 75% written English proficiency']",2020-08-08 13:18:19
Senior Data Engineer,Infotree Global,N/A,"Creve Coeur, MO","['8+ years of experience (minimum)', 'BS degree or equivalent experience', 'Demonstrated prior experience in developing using SQL, SQL Performance Tuning, relational database design, development and implementation for both row-wise (PostgreSQL, Teradata, Aurora, etc…) and columnar data stores (Hana).', 'Ability to communicate across diverse audience of business analysts, architects, business users and technical project staff', 'Strong organization and interpersonal skills. Ability to deal with and balance multiple priorities. Ability to deal with ambiguity and rapid change. Demonstrated interaction skills across a wide spectrum of technical contacts and teams.', 'Passion for the integrity of database design and a willingness to compromise appropriately to balance design and delivery.', 'Hands-on role requiring rigorous attention to detail and thorough application of standards.', 'Self-starter, capable of driving towards goals independently. Highly self-motivated and delivery focused.', 'Have demonstrable understanding and awareness of technology and an ability to learn and acquire new technologies as needed.', 'Willingness to do collaborative software development.', 'Extreme familiarity and comfort with the Teradata, Redshift, Hana, PostgreSQL (or equivalent)', 'Large development project experience.', 'Strong database design, development and tuning skills.', 'Experience with both real time and batch data delivery architectures.', 'Understanding of stream processing using Apache Kafka, enabling data-intensive API’s using a RESTful approach is a plus.', 'Ability to work as a member of a diverse team to achieve a common goal.', 'Proven to possess excellent verbal and written communication skills.', 'Thorough understanding of the software lifecycle and relevant software methodologies used in software development.', 'Experience with geospatial and agricultural ecosystems is a plus.', 'Performance: Takes responsibility for achieving results, overcomes obstacles and adapts approach, bias for action.', 'Business Awareness: Displays awareness of the impact of actions on the business, demonstrates understanding of the business context of the company and acts in line with it.', 'Communication and Influence: Uses negotiation skills and techniques to obtain agreement between different interests, challenges management constructively, bringing different views into the open.', 'Partnership and Teamwork: Actively promotes a positive team spirit, builds networks to enhance effectiveness and share knowledge.', 'SQL Performance Tuning: 4 years (Required)', 'Teredata: 4 years (Required)', '""W2 ONLY"". What is your work authorization in US?']",2020-08-08 13:18:19
Data Engineer,Blue Cross Blue Shield of Louisiana,4 out of 5,"Baton Rouge, LA","['Jobs are updated and posted daily.', 'You must submit your resume online.', 'Apply for each position for which you are qualified and interested in.', 'You will only be considered for positions for which you apply.', 'Resumes are only accepted for posted positions.', 'Positions are full-time unless otherwise stated.', 'Due to the high volume of applicants, only those most qualified will be contacted.', 'We are unable to accept phone calls.', 'Support of a data warehousing, data mart, data lake, and/or business intelligence environment', 'ETL/ELT development background with Informatica PowerCenter, DataStage, SSIS, or Azure Data Factory', 'Development experience with Teradata, Oracle, SQL Server, Data Lake, or Sybase repositories', 'Other programming language such as C#, Python, PL/SQL, SparkSQL, NoSQL', 'Shared API for web or cloud applications development background', 'Big Data technologies such as Hadoop, Spark, Artificial Intelligence (AI), Machine Learning (ML), Natural Language Processing (NLP)', 'BI tools or reporting experience with SSAS, SSRS, BOE, and/or Tableau', 'Project Management Experience', 'Healthcare Payer experience', 'Experience working in an agile development methodology', 'DevOps experience (automation of code or workflow through release pipeline)', 'Data warehousing development lifecycle', 'Ability to independently design, develop and debug basic ETL/ELT or API solutions based on business requirements with feedback from the team’s technical lead', 'Ability to independently evaluate the test results of others', 'Ability to become self-sufficient with integration tools', 'Ability to independently create basic integrations to build dimensional databases, data marts, data lake, and cubes with feedback from the team’s technical lead', 'Strong analytical, problem-solving and decision-making skills along with the ability to react quickly to changing requirements due to product limitation or driven by enterprise need', 'Ability to independently develop Unit Test Plans and Test Data with feedback from the team’s technical lead', 'Ability to resolve the issues found in workflows, mappings, stored procedures, and data pipelines', 'Develop basic system and integration test plans', 'Ability to execute test plans and document results and discrepancies with feedback from the team’s technical lead', 'Ability to write SQL queries using subqueries', 'Strong knowledge of SQL data types and functions', 'Very good communication and writing skills with an attention to detail']",2020-08-08 13:18:19
Data Engineer,Elkay Manufacturing,3.3 out of 5,"Downers Grove, IL 60515","['Design, develop and maintain data models, database architectures, and associated database objects in Snowflake, Oracle, and other database solutions such as Azure.', 'Design, develop, and maintain data integrations using Informatica Power Center, Informatica Integrated Cloud Services, and data prep tools.', 'Participate in or drive project activities such as requirements gathering, design, develop, test, and deploy.', 'Assist in the set-up of, and administer, on premise and cloud tools used in the Elkay analytics infrastructure.', 'Create and maintain necessary technical documentation, including requirements, design, and test documents.', 'Identify emerging trends, processes, and techniques impacting Elkay’s analytics infrastructure and make suggestions for incorporation of these into the analytics infrastructure.', 'A Master’s or Bachelor’s degree in Computer Science, MIS, engineering, or a related technical discipline is required.', '5+ years of experience in data engineering, data warehousing, business intelligence, ETL on databases such as Oracle or SQL Server, and/or big data is required.', '3+ years of experience in ETL/ data integration is required with 2+ years of experience in Informatica PowerCenter, job scheduling tools is required.', 'Working experience in Python/R/Scala, Snowflake is required.', 'Hands on experience in writing and understanding complex SQL (e.g. CTE’s others).', 'Thorough understanding of relational database design and best practices, including dimensional (star, snowflake) models is required.', 'A collaborative working style and ability to work well within the team and with business consumers is required.', 'Ability to clearly communicate to technical and non-technical audience by written and verbal is required.', 'Independent analytical, critical thinking, and problem-solving ability in complex technical environments is required.', 'Production experience in OBIEE, Oracle Analytics Cloud (OAC) and Tableau is nice to have.', 'Familiarity with big data technologies such as Microsoft Azure Data or AWS is nice to have.']",2020-08-08 13:18:19
Data engineer,Colgate-Palmolive,4.3 out of 5,"Piscataway, NJ 08854","['Prospect of using technology to seek challenging data problems', 'Build data applications on SAP BI/BW, HANA & Google cloud platform', 'Design, develop, and maintain a best-in-class data warehouse and analytics architecture to meet business analysis, reporting needs, and data science initiatives', 'Work directly with supply chain business users and data scientists to assist in project analysis', 'Participate in the development and maintenance of ETL jobs and data pipelines to aggregate data from various on premise, cloud platforms & external data sources', 'Design and develop data marts for consumption by analytics tools and end users', 'Develop code standards, guidelines to lead and ensure data quality and integrity', 'Optimize and scale data warehouse and data processing infrastructure', 'Evaluate new technologies and constantly work towards continuous improvements in data engineering, our platform, and the organization', ""Bachelor's degree in Computer Science, Data Science, Statistics, Informatics, Information Systems or related field."", '1+ years of experience in a Data Engineer role.', ""More than 1 year of SAP data warehousing & analytical tool's experience."", 'Data modeling, ETL development, and Data warehousing experience', 'Knowledge of data management fundamentals and data storage principles', 'Experience with Python/Javascript or similar programming languages', 'Hands on experience with SQL and Tableau.', 'Experience building and optimizing""big data"" data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and find opportunities for improvement.', 'Data warehousing platforms/storage platforms such as SAP BW/HANA experience', 'Experience with SAP data extractors, SAP Integration tools like SLT, SDI & understanding of Supply chain processes is preferred', 'Experience with cloud data warehousing/Big data environments like Snowflakes, BigQuery, Google cloud storage etc is a plus', 'Experience with data pipelines and streaming frameworks such as Pubsub, Spark, Airflow, Kafka etc', 'Experience with RDBMS; NoSQL experience also encouraged', 'Ability to adopt, learn, and apply new technologies and tools', 'Familiarity with agile software development methodology', 'Ability to communicate well with both technical and non-technical teams']",2020-08-08 13:18:19
Big Data Engineer,Supremus,N/A,"Philadelphia, PA 19152","['Apply semantic correlation, ontology structured data, and text analytics techniques and systems to analyze non-structured data and identify critical insights.', 'Apply Big Data technologies, such as Hadoop or Cassandra, with NoSQL data management and related programming languages, such as Jaql, HBase, Pig, or Hive.', 'Participate in all aspects of the software life cycle, including analysis, design, development, unit testing, production deployment and support.', 'Formulate approaches and gather data to solve business problems, develop conclusions and present solutions through formal deliverables.', 'Create Big Data accelerators to help deploy scalable solutions fast.']",2020-08-08 13:19:08
"Software Engineer - Data Engineering (Remote, US or HQ)",Aledade,3.3 out of 5,"Bethesda, MD 20814",[],2020-08-08 13:19:08
Data Operations Engineer,Pluralsight,4.2 out of 5,"South Jordan, UT",[],2020-08-08 13:19:08
Data Engineer,"Alteryx, Inc.",4 out of 5,"Ann Arbor, MI","['Build, test, monitor and maintain a highly scalable data management ecosystem', 'Execute architected techniques and solutions for data collection, management and usage', 'Take business requirements and produce data sets for efficient cross-business analysis', 'Extreme focus on detail and data quality validation', 'Deep interest in the data and analytics market with ability to constantly evaluate new ways to enhance the telemetry system and train it to be smarter and more scalable', '3+ years of data engineering / development / integration experience', 'Experience with SQL required', 'Experience with Alteryx platform preferred, but not required', 'Experience with Enterprise Data Warehouse development and ETL processes', 'Knowledge of at least one modern scripting language (Python, R, etc.)', 'Understanding of cloud infrastructure', 'Experience with automated software testing and deployment', 'Ability to work with geographically distributed teams', 'Ability to work with other teams across an organization', 'Strong oral and written communication', 'BA/BS degree in Information Science, Data Analytics, Computer Science, Software Engineering or related technical field']",2020-08-08 13:19:08
Data Engineer,Assurant,3.5 out of 5,"Miami, FL 33157","['Gains a thorough understanding of the requirements and ensure that work product aligns with customer requirements.', 'Works within the established development guidelines, standards, methodologies, and naming conventions.', 'Builds processes to ingest, process and store massive amount of data.', 'Assists with optimization and performance of bigdata ecosystems.', 'Performs productionization of Machine Learning and Statistical models for Data Scientists & Statisticians.', 'Assists with research and building of proof of concepts to test out theories recommended by Senior and Lead Data Engineers.', 'Collaborates and contributes in identifying project risks, design mitigation plans, develops estimates.', 'Bachelor of Science in Computer Science or in a related field required.', '5 years of design, development and production support experience on Data Warehousing and Business Intelligence.', '5 years of experience with SQL Server, C#/.NET using On-Premise and/or Microsoft Cloud Service Models: PaaS, IaaS, SaaS.', 'Experience using Azure offerings for Compute, Containers, Big Data, Data Analytics : Data Lake, Data Factory, Stream Analytics, NoSQL.', 'Expertise with scripting languages like Python (or similar) , Linux shell or Windows Power-shell and/or Azure CLI.', 'Ability to use and create web services and other integration technologies (REST, XML/JSON, SOAP).', 'Knowledge in fundamentals of Machine Learning and Artificial Intelligence using Microsoft technologies.', 'Experience with Azure Databricks, HDInsight, Spark, Hadoop is highly desirable.', 'Data profiling and dimension modeling techniques and creation of logical and physical data models.', 'Experience working with job scheduling tools.']",2020-08-08 13:19:08
Senior Data Engineer,Kognetics,N/A,"Gahanna, OH","['Based on business strategy and knowledge of emerging technologies, drive the architecture and design of the analytical platform (Big Data, Semantic Computing, Graph Database, Graph Analytics)', 'Use data mining & Text mining algorithms using open source tool like R, Gate & NLP (Stanford, Berkley, UIMA, etc … ) to provide the solution to various business problems.', 'Use data visualizations tools such as D3J, to tell compelling business stories, via complex mashups', '4+ years of experience in core Java/J2EE, Python.', '2+ Year of experience in Struts/Spring,', 'Experience in Hibernate, Django will be added advantage.', 'Experience in MySQL / PostgreSQL', 'Good knowledge of JavaScript, JQuery.', 'Experience in Open Source search technology Like SOLR / Elasticsearch is a plus', 'Experience in Hadoop, HBase, Graph database and MongoDB will be added advantage.', 'Experience in Product development background will be a plus.', 'Passion,commitment, resourcefulness, and a drive to continue learning are essentialprerequisites. For this role, we’re also looking for someone who meets thefollowing criteria:', ""B. Tech/PhD/ Master's Degree inStatistics, Mathematics, Computer Science, or equivalent; 5+ years of datascience mining experience;""]",2020-08-08 13:19:08
ETL Developer,Analogiks,N/A,"Washington, DC","['Extract and integrate data from multiple data systems and organize data in a format that can be easily read by human or machine', 'Create and enhance software that enables state of the art data science, data analysis, and machine learning', 'Develop data processing solutions and custom ETL pipelines for varied data formats like parquet and Avro', 'Utilize programming languages like Java, Scala, Python, and Open Source RDBMS and NoSQL databases and Cloud-based data warehousing services to design and develop reports and provide informational capabilities required to support the reporting/analytics needs', 'Build reports and visualizations to effectively communicate data-driven insights', 'Work with end-users and cross-functional teams to identify, troubleshoot and fix data issues, and resolve data gaps that impact the fulfillment of the business’s functional requirements', 'Derive business insights using data and develop data benchmarks, trends, and forecasts', 'Leverage DevOps techniques and practices like Continuous Integration, Continuous Deployment and Test Automation to enable the rapid delivery of working code', 'Perform unit tests and conduct reviews with other team members to make sure the code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Provide support with gathering and developing complex business, functional, and system requirements', 'BS in Information Technology, Computer Science, Software Engineering or related field', 'Excellent problem-solving techniques using any programming language', '5+ years of working experience in ETL development and functional programming knowledge preferably with Scala, Spark, Java, Python, R', '5+ years of experience with Relational Database Systems and SQL', '3+ years of data modeling experience', '2+ years of experience with Cloud computing (AWS)', '2+ years of experience with Spark', '2+ years of experience in developing high volume transaction processing solutions', 'dw/bi technologies: 2 years (Preferred)', 'informatica mdm: 2 years (Preferred)', 'informatica: 2 years (Preferred)', 'etl: 2 years (Preferred)', 'writing sql queries: 2 years (Preferred)', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Yes']",2020-08-08 13:19:08
Data Engineer,NBKC BANK,3.8 out of 5,"Kansas City, MO 64114","['Deploy your problem solving and modeling capabilities on one of the most data-rich industries around: finance', 'Contribute to all facets of the data ecosystem (storage, pipelines, reporting, etc.)', 'Work directly with key business leaders to deliver insight that has a real impact on the bank and its customers', 'Play an integral role in designing and building nbkc’s data architecture', 'Keep pace with the latest research and cutting-edge open source projects in the field today.', 'Automate the movement of data throughout the bank', 'Support the progression and maturation of nbkc into the data science space', 'Bachelor’s degree in Computer Science, Analytics or related field', '3+ years of work experience in data engineering, software development, data visualization or related topics', '3+ years of experience writing production-oriented Python including major data libraries (Pandas, NumPy, etc.)', '3+ years of experience with SQL', 'A positive, self-motivated disposition and an excitement to tackle challenging problems', 'Ability to communicate precisely on complex topics', 'Knowledge of ETL and data warehousing best practices and processes', 'Proficiency with relational and non-relational databases', 'Ability to work comfortably in a Linux command line environment', 'Familiarity working with cloud platforms', 'Experience with git or other VCS', 'Familiarity with machine learning principles', 'Experience building components in Microsoft Azure', 'Familiarity with Microsoft Power BI or other visualization tools', 'Experience with data pipelines like Luigi or AirFlow', 'Take care of yourself and your family with our comprehensive health coverage', 'Save more for your future with our 401k retirement savings plan + a sweet company match with immediate vesting.', 'Enjoy 4 weeks of paid time off, 10 paid holidays, and 8 paid volunteer hours per year', 'Spend time bonding with your family with paid parental leave options', 'On-site gym facilities, personal trainer, and yoga instructor will get you moving', 'On-site flu shots and health screenings make it easy to stay healthy', 'Professional coaching and learning sessions help you build the career you want', 'Casual dress code and work environment let you be yourself', 'Arcade games and open spaces to meet and work on every floor keep your brain moving', 'Flexible schedules let you take care of what you need to in and out of the office', 'Enjoy a $1000 travel voucher or an extra week of PTO for your 5-year anniversary', 'Take a 4-week paid sabbatical for your 10-, 18-, and 25-year anniversaries']",2020-08-08 13:19:08
Data Scientist - Nationwide Opportunities,"Amazon Web Services, Inc.",3.6 out of 5,Remote,"['Job', 'Company', 'Bachelor’s degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent professional or military experience', 'Experience with ML fields, e.g., natural language processing, computer vision, statistical learning theory', '4+ years of industry experience in predictive modeling, data science, and analysis', 'Experience in an ML engineer or data scientist role building ML models', 'Experience writing code in Python, R, Scala, Java, C++ with documentation for reproducibility', 'Experience handling terabyte size datasets, diving into data to discover hidden patterns, using data visualization tools, writing SQL, and working with GPUs to develop models', 'Experience writing and speaking about technical concepts to business, technical, and lay audiences and giving data-driven presentations', 'Assist customers by being able to deliver a ML project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models with concept-drift monitoring and retraining to deliver business impact to the organization', 'Use AWS AI services (e.g., Personalize), ML platforms (SageMaker), and frameworks (e.g., MXNet, TensorFlow, PyTorch, SparkML, scikit-learn) to help our customers build ML models', 'Research and implement novel ML approaches, including hardware optimizations on platforms such as AWS Inferentia', 'Work with our other Professional Services consultants (Big Data, IoT, HPC) to analyze, extract, normalize, and label relevant data, and with our Professional Services engineers to operationalize customers’ models after they are prototyped', 'Master’s degree of PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)', 'Ability to develop strategic, baselined, data modeling processes; ability to accurately determine cause-and-effect relationships.', 'Publications or presentations in recognized ML journals or conferences', 'Deep technical skills, consulting experience, and business savvy to interface with all levels and disciplines within our customers’ organization', 'Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment']",2020-08-08 13:19:08
Data Journalist,"HealthCare, Inc.",N/A,Remote,"['Explore internal and external data sets to identify stories that will help bring light to healthcare stories around the country.', 'Write about, report on and analyze these data sets to create compelling stories for a wide audience', 'Take the initial concept to publication, while incorporating editorial changes.', 'Desire and ability to work in a cross-functional team, and communicate across functions (e.g., to designers, engineers, managers, etc.).', 'Explore data visually and prototype data visualizations, including interactive visualizations', 'Take ownership of an early-days workstream at a growing startup and push it forward, accelerating the pace of storytelling and leveling up the quality of our work.', 'Assist other team members with data research for graphics, which includes generating maps.', 'Help build a proprietary data set that is sought after in media and academic circles.', 'Stay abreast of the latest tools and techniques in data visualization and story-telling', 'Methods for parsing, scraping, cleaning, and analyzing data from a variety of sources.', 'Tableau or other data visualization tool experience', 'Masterful in Excel', 'At least two years of experience reporting and building data visualizations.', 'Experience collecting and cleaning data, with regards to best journalistic practices.', 'Experience using large amounts of quantitative information in your stories.', 'Meticulous attention to detail and exceptional organizational skills.', 'Ability to visualize complex ideas in a clear, accurate, and intelligent manner.', 'Proficiency in writing detailed and accessible methodology notes.', 'Experience working with complex internal and external data.', 'Strong writing skills - ability to produce clean, grammatically correct copy.', 'Comfortable with healthcare data, and a general interest in the healthcare system', 'Reliable/good with deadlines.', 'Remote work opportunity', 'Medical, dental, and vision with 100% company paid premiums for the employee', '15 days of paid time off', '10 company observed holidays with an additional 3 floating holidays', 'Annual learning and development stipend', '8 weeks of paid parental leave', 'Commuter benefits', '401k plan with company match', 'Most importantly, an amazing company culture established by an incredible team!']",2020-08-08 13:19:08
Line Engineer,Altra Industrial Motion Corp.,3.4 out of 5,"West Chester, PA","['Acts as PRIMARY OWNER for technical questions and challenges from operatorsAnswers process related questions promptlyReacts quickly to initial quality, tooling, and equipment issues to keep cells running', 'Lead DAILY MANAGEMENT to drive Safety, Quality, Delivery, Inventory and Productivity performance in area of responsibilityCollects and compiles data for cell level SQDIP (Safety, Quality, Delivery, Inventory, Productivity)Establishes regular communication of data to associates and affected personsCreate action plan and executes to drives action to successfully meet goals', 'Performs ROOT CAUSE & COUNTERMEASURE analysis (RCCM’s) of internal quality issuesCollects and receives first signals of potential defective product in area of ownership, troubleshoots, and provides feedback to operators on initial dispositionPerforms MRB (Material Review Board) daily. Identify plan for disposition/rework/salvage of defective parts originating in area of ownershipSubmits deviation and Engineering Change Order requests as neededWorks closely with Quality Team on external returns (RMA’s) including analysis related to defects originating in area of ownership, both determination of root cause and implementation of countermeasures', 'Performs basic TROUBLESHOOTING / REPAIRS of EQUIPMENT in area of ownershipPerform initial mechanical and electrical troubleshooting to determine root cause of equipment failuresAssists Maintenance with minor repairs and troubleshooting of equipment. Escalate to Maintenance staff as requiredEnsure Equipment Preventative Maintenance is performed in a timely mannerEnsure calibration/validation are completed', 'Conducts PROCESS IMPROVEMENT activitiesEnsure repeatability and reproducibility of processes, testing, and measurement and analytical equipmentSpecifies manufacturing methods and part routingsPerforms time studies or observe/capture standard workParticipate and conduct standard work (SW), Variation Reduction Kaizen (VRK), as well as other Kaizen activities to improve stability of processesSpecifies and orders tooling and equipmentDesigns and documents fixturing and tools using Solidwork softwareFocus on sustainable, long-term success of processes', 'Maintains DOCUMENTATION related to part routings, work instructions and inspectionCreates/updates Process Documentation for areas of ownership – Routers, OMS, MP, QSBCompiles and write training material and conduct training/coaching sessions on quality control and manufacturing activities', 'Supports NEW PRODUCT DEVELOPMENT as needed', 'High sense of urgency and results driven', 'A strong understanding of quality systems and other process improvement tools', 'Familiarity with various manufacturing equipment and processes (laser welding, transfer molding)', 'Working knowledge of inspection and measurement tools (CMM, Caliper, Micrometer, Gages)', 'Familiarity with documentation and process control', 'Demonstrated proficiency in time and project management', 'Ability to work in a cross functional environment', 'Strong written, verbal and computer skills', 'Bachelor’s degree in Mechanical/ Industrial Engineering or related field, or equivalent experience', 'At least one year of Manufacturing Engineering experience required', 'Previous experience with Lean Manufacturing / Problem Solving tools is preferred', 'Previous Experience with QS and ISO requirements is preferred']",2020-08-08 13:19:08
Quality Assurance Engineer,Synaptic Advisory Partners,4.3 out of 5,"Annapolis, MD 21401","['Support the product development lifecycle', 'Contribute to design sessions', 'Confirm new product features align with requirements', 'Confirm the existing features continue to support requirements', 'Engage with Clients to understand their requirements', 'Assist with Client communication', 'S. in Computer Science or a related field (or the equivalent experience of such a degree)', 'Minimum 3 years of QA experience', 'Experience in mobile testing preferred', 'Well versed with writing testing documents', 'Have worked with automation testing', 'Experience with functional testing, regression testing, cross-browser testing, performance testing, load testing, and smoke testing', 'Experience with Salesforce preferred', 'Ability to prioritize, manage multiple tasks, and deliver results under tight deadlines', 'Organized, with keen attention to detail', 'Excellent oral and written communication skills', 'Work closely with the development team to improve existing product', 'Ensure products meet customer expectations and demand', 'Ability to work both individually and in a team environment', 'An amazing team focused on doing #Whateverittakes to help our clients and teammates be successful', 'A calling to innovate and improve every day', 'A competitive benefits and compensation package', 'Room for rapid growth and an emphasis on talent development', 'A fun, casual team environment with cool co-workers who will make you feel like you are an important part of our team, engage you in developing new solutions to challenging problems, and help you leverage your strengths to make all of us better!']",2020-08-08 13:19:08
Data Engineer,"Clearsense, LLC",4 out of 5,"Jacksonville, FL 32224","['The Data Engineer will support the design and development of data workflows, ETL-like processes, SQL queries, and Visualizations of various clinical and non-clinical databases in the Clearsense Data Ecosystem. They must also demonstrate advanced analytical skills, technical and business knowledge and have a strong understanding of how to leverage industry standard tools and methods to solve problems.The Data Engineer will work closely with Software Engineers by providing data mapping and wrangling expertise and Data Scientists by helping to determine and provide data sets needed for analysis. They often wrestle with problems associated with database integration and messy, unstructured data sets. Their ultimate aim is to provide clean, usable data to whomever may require it.Responsibilities:Research opportunities for data acquisition and new uses for existing dataDevelop data set processes for data modeling, mining and productionEmploy a variety of languages and tools (e.g. scripting languages) to merge data togetherRecommend ways to improve data reliability, efficiency and qualityDefine and Develop Clearsense Data Governance PoliciesAggregate and analyze various data sets to provide actionable insightDevelop reports, dashboards, and tools for business-usersPerform detailed analysis of Customer data sourcesWrite complex SQL queries across multiple data sourcesQualifications:Must have 5+ years within a data management role performing implementation, integration and/or technical development, with a heavy focus on SQL and relational databasesA nice to have is prior use of Data Governance tools and processesA nice to have background would involve knowledge and experience with healthcare data exchange platforms and data aggregation tools and healthcare interoperability and messaging standards, including but not limited to HL7 2.x, HL7 3.x, HL7 FHIR, IHE integration profilesA nice to have background would be an understanding of general medical terminology and healthcare clinical code sets such as LOINC, CPT, ICD, RxNorm, etc.A nice to have background would be a demonstrated advanced knowledge in Healthcare data, HL7 scripting and two or more programming languages, Healthcare operations, process improvement, and application of technology to improve patient outcomes.A nice to have background would be as a highly skilled and proficient knowledge of and experience with build tools of the electronic medical record, and other clinical systems.Self-starter, self-motivated, high level of initiative within a fast-paced, constantly evolving data management environmentResult focused, ability to solve complex problems and resolve conflicts in a timely mannerAbility to travel to Customer sites (up to 10%)REQUIRED:Bachelor’s degree in Data Informatics, Computer Science, Business or related field.Must have experience:SQL, scripting languages, ETL tools and Data workflow tools']",2020-08-08 13:19:08
Data Scientist (Coordinated Campaign),Democratic National Committee,4.1 out of 5,Remote,"['Create predictive models of voter and supporter behavior.', 'Prepare and analyze datasets to extract meaningful campaign insights.', 'Employ supervised and unsupervised learning techniques, along with other statistical methods, to solve complex optimization problems.', 'Contribute to testing and experimentation design, infrastructure, and implementation.', 'Contribute to broader methodological standards across analytics team.', 'Collaborate with analysts, data scientists, and engineers to produce deliverables.', '2-4+ years of experience applying data and advanced analytics tools in a commercial, political, or non-profit setting, or equivalent academic experience (such as a postgraduate degree in a quantitative field).', 'Fluency in Python or R', 'Familiarity with executing all components of predictive modeling, including data collection and cleaning, model building using regression and other machine learning techniques, and model validation.', 'Ability to communicate technical concepts to a non-technical audience, both in writing and verbally.', 'Experience manipulating data in SQL.', 'Knowledge of experimental design and causal inference.', 'Experience volunteering or working on a political campaign data team, in polling, or with the Voter File']",2020-08-08 13:19:08
Software Engineer - Entry Level,HubSpot: Students,N/A,"Cambridge, MA","['Back End: We write lots of microservices, primarily with Java 11. Our APIs are RESTful and use the minimal Dropwizard framework. We take advantage of Kafka, Spark, and Hadoop for processing volumes of data.', ""Front End: Our web applications are complex, single-page apps written in JavaScript (React, ECMAScript 6, Sass). We make extensive use of HubSpot's own design system Canvas."", 'Core Data, Infrastructure, & Reliability: Building the systems that power thousands of services with Singularity on Apache Mesos, and empowering access to massive datasets with HBase, Elastic Search, ZooKeeper, Redis, MySQL, and Memcached.']",2020-08-08 13:19:08
Data Scientist/ML Engineer,PA Consulting Group,3.9 out of 5,"New York, NY 10174","[""2-5 years' professional experience as a data scientist, software engineer or statistical modeler"", ""Master's degree from top tier university in Computer Science, Statistics, Economics, Physics, Engineering, Mathematics or similar field"", 'Expertise in Machine Learning algorithms and methods', 'Strong understanding and application of statistical methods', 'Experience writing production level code in one of the following: Python, Java, C++, C', 'Experience with database systems preferred', 'Experience working with big data distributed programming languages and ecosystems (e.g. S3, EC2, Hadoop/MapReduce, Pig, Hive, Spark)', 'Experience building scalable data pipelines with data/feature engineering', 'Experience Webscraping leveraging Beaituflsoup, Selenium, Scrappy etc preferred', 'Experience with front end (UI), HTML5, JavaScript, CSS, R Shiny, Tableau preferred', 'Group medical insurance', 'Health Savings Account with company match', 'Teladoc and informed Nurse line resources', 'Long term care plan', 'Group dental insurance', 'Vision plan', '401(k) Savings Plan with company profit sharing contribution', 'Commuter and Parking tax-savings benefit', '15 days paid vacation days with the opportunity to buy five additional days', '10 paid Holidays plus 10 paid sick days', 'Company and Voluntary income protection benefits', 'Gym and health incentive reimbursement', 'Pet and legal insurance Plans', 'Employee Assistance Plan', 'Annual performance-based bonus']",2020-08-08 13:19:52
ETL Developer/Data Ingestion Engineer,Booz Allen Hamilton,3.9 out of 5,"Reston, VA","['2+ years of experience with Java', '1+ years of experience with a streaming data framework, including Apache Kafka', '1+ years of experience with web-based architecture, including HTML and JavaScript', '1+ years of experience with ETL development and processes from diverse data sources', '1+ years of experience with the development, maintenance, and enhancement of data mappings, work-flows, and processes', '1+ years of experience in working with Relational Databases', 'Experience with a variety of data feed types, including RSS, SOAP, and REST', 'Experience with data modeling concepts', 'TS/SCI clearance required', 'HS diploma or GED', 'Experience with XML, JSON, and TXT transformations, including writing and applying XSLT to transform data', 'Experience with any of the following technologies: Apache Kafka, NiFi, Airflow, PostgreSQL, Pentaho Data Integration, Accumulo, Solr, Elastic Stack, Firefox, Chromium, or Kubernetes', 'Experience with DoD or IC clients', 'Experience as a database administrator', 'Experience with web scraping, including Document Object Model (DOM) exploration', 'Knowledge of the Agile software development process, including Scrum and Kanban', 'Ability to map and document needed data elements in multiple databases to aggregate them under one schema', 'BA or BS degree preferred', 'Database Administration, ETL, or Business Intelligence-related Certifications preferred', 'DoDD 8570 Compliance Certification, including Security+']",2020-08-08 13:19:52
FIELD ENGINEER,ProPetro Holding Corp,N/A,"Midland, TX 79706","['Complete pre-job tasks in conjunction with field personnel such as bucket tests, sand/silo checks, water analysis and other possible fluid preparations on location', 'Prepare pre-job paperwork in order to be utilized during the job such as treatment reports, sand trackers, pump schedules, etc.', 'Monitor treatment/chemical plots and in some cases provide suggestions to possible changes that need to be made on the fly all the while being able to accurately record data in a presentable manner.', ""Stay in constant contact with sand QCM's and accurately keep track of sand on location at all times"", 'Once job is complete, compile all necessary data to present to the customer to distribute out to the necessary parties', 'At minimum, must have a 4-year college degree. Preferably, and engineering degree that pertains to the oil field such as petroleum or mechanical', 'Must be able and willing to perform some daily frac duties during and after their training portion', 'Must be assertive and willing to speak up when noticing something inefficient or unsafe', 'Must be able to think on their feet and multi-task different scenarios and communicate effectively with other people', 'Must be organized in their work space. This includes proper computer file recording, saving, and sharing', 'Must be a leader on location and uphold ProPetro safety and culture standards at all times', 'While performing the duties of this job, the employee is regularly required to sit, stand or walk; use hands to finger, handle, or feel; reach with hands and arms; stoop or bend; and talk or hear. The employee must occasionally lift and/or move up to 50 lbs.', 'The noise level in some work environments can be moderate.']",2020-08-08 13:19:52
Data Warehouse Engineer,CareFirst BlueCross BlueShield,3.9 out of 5,"Washington, DC 20002",[],2020-08-08 13:19:52
Data Engineer,B12,N/A,"New York, NY 10003","['We build our product on Python/Django and JavaScript/React.', ""We store blobs in Amazon's S3, munch on them in Amazon's EC2, develop in Docker, and deploy containers to Amazon's Elastic Beanstalk."", 'We believe Postgres should be the first system you consider when you think about persisting structured data.', ""We religiously clean and centralize data in Amazon's Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!"", 'Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.', 'We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.', ""We set up continuous integration and deployment because, while this model comes with its own pains, we've disliked being on fixed release schedules on previous projects."", 'We like to move fast and support point-in-time recovery :).', 'Collaborate with operational teams including sales, marketing, and customer success.', ""Contribute to infrastructure that enables and informs B12's analytical efforts."", 'Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.', 'Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.', 'Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.', 'You are fluent in SQL and Python.', 'You have experience building and using data infrastructure, including systems like Postgres and Redshift.', ""You've used reporting tools like Metabase, Tableau, or Looker in the past."", 'You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.', ""You've contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse."", 'You feel comfortable managing your time and deciding amongst competing priorities.', 'You have worked with non-engineering teams and are comfortable explaining technical solutions to them.', 'You are passionate about the future of work.', 'You enjoy learning and teaching.', 'You have strong written and verbal communication skills in English.', 'You care about and want to contribute to our mission of helping people do meaningful work.', ""We don't have a minimum number of years of experience for this role. We highly favor talent and interest."", ""Some candidates may see this list and feel discouraged because they don't match all the items. Please apply anyway: there's a good chance you're more wonderful than you think you are."", 'B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.', 'A pointer to your CV, resume, LinkedIn profile, or any other summary of your career so far.', 'Some informal text introducing yourself and what you are excited about.', ""If you have a profile on websites like GitHub or other repositories of open source software, you can provide that as well. If you don't have one, it's still very possible for us to get along just fine!""]",2020-08-08 13:19:52
Recruiting Coordinator,Mode,4.2 out of 5,Pennsylvania,"['Own scheduling for the entire interview process as well as other recruiting events', 'Collaborate with full-cycle recruiters and hiring managers to source for candidates who would be a great fit for the Mode team', 'Guide candidates through the process during their onsite interviews to ensure everything is going smoothly', 'Collaborate with hiring managers and the recruiting team to ensure that candidates are moving seamlessly and smoothly though the interview process', 'Effective time management and organizational skills', 'Excellent written and verbal communication', 'The ability to interact effectively with team members and candidates at all levels with professionalism, tact, and diplomacy', 'Strong interpersonal and relationship-building skills', 'Ability to quickly familiarize yourself with new technology and balance multiple tasks at once', 'Integrity in handling confidential and sensitive information', 'Hustle and sales-mentality', 'Generous, flexible PTO and family leave', 'Flexible work schedules—we trust you to know what will make yourself most productive', ""Generous professional development policy that includes funds earmarked for each employee's discretionary professional growth—Have a conference you want to attend? A class you want to take? If it's helping take your career to the next level, it's on us"", 'Excellent health coverage for team members and their families (Mode pays the 100% of the premiums)', 'Supportive work environment and a manager who is focused on your professional growth', ""Company events that highlight our team's passions and hobbies""]",2020-08-08 13:19:52
Data Engineer,the NBA,4.2 out of 5,"Secaucus, NJ 07094","['Understands business needs and develop solutions that delight consumers and customers', 'Understands Agile artifacts and develops applications based upon business priority.', 'Collaborate with project partners to ensure all requirements are met.', 'Handles relationships with end-user communities. Interacts regularly with users to gather feedback, listen to their issues and concerns, recommend solutions.', 'Build scalable, fault-tolerant batch and real-time data pipelines to power internal applications, operational workflows, and business intelligence platforms', 'Create and maintain data-driven APIs to support a wide range of integration with NBA partners', 'Recommend and implement best practices for data management and governance', 'Demonstrate your technical abilities and contribute to our overall architecture', 'Help implement the Enterprise Data Architecture for NBA and help implement it in multi-functional alignment with the Data teams that exist across functions like Marketing, Finance, HR etc.', 'Provide insights during application design and development for highly complex or critical machine learning projects across numerous lines of business and shared technology.', 'Ensure alignment to enterprise architecture and usage of enterprise platforms when delivering projects', 'Continuously improve the quality of deliverables and SDLC processes', ""Master's Degree in Computer Science, Engineering, or Management of Info Systems/Technology preferred"", 'Advanced Education in Statistics or Mathematics would be a plus 3+ year of experience in developing ETL and ELT pipelines using SQL and MSFT SSIS 3+ years of experience in developing BigData and/or machine learning solutions 3+ years of experience in a highly regulated industry', '1+ Years of experience defining and/or designing data architectures', '1+ Years of experience leading and/or managing product engineering teams', 'Experience with the MS Cloud stack (Azure) or AWS', 'Experience with SQL, NoSQL, BigData and Graph Technologies along with Programming languages like R, Python, Kafka, Storm etc.', 'Experience building microservices', 'Background in agile SW development and Scaled Agile Frameworks', 'A true believer in measuring success based on working software and in quick prototyping', 'Someone who is a passionate coder and can spin up a snippet of code quickly', 'Strategic thinker with the ability to build and execute innovative digital product, combined with tactical ability to execute simultaneously against multiple contending priorities', 'Someone with an iterative approach, drive to move fast and think big', 'Experience working with and/or managing internal and external teams at the same time, working with multiple brands and digital properties of varying maturities', 'Demonstrated ability to partner and communicate effectively with non-technical team members, resolving contending or contradictory objectives, and unifying disparate ideas into a homogenized solution', 'Ability to be versatile and handle multiple projects and re-prioritizations', 'Possess the ability to influence others, implement change, and standardize processes in a complex business environment', 'A passion for data and growing in your current role', 'Ability to effectively and appropriately interview technical candidates', 'Passion for Automation and Hunger for Acceleration', 'Keen knowledge of Devops as well as RPA is a big plus', 'Experience with Architecting Applications (e.g. Design Patterns, distributed applications etc.) with the aim of reuse would be a big plus', 'Superb communication skills (both written and verbal)', 'Great teammate - should be ready to go beyond to help immediate team and do not be averse to not shy away from asking for help if needed.', 'Ability to translate ideas into solutions based on user and business needs', 'Open Eagerness to learn new technologies and bring new ideas to the table']",2020-08-08 13:19:52
"Conversion, Associate Engineer Mechanical",Northrop Grumman,4 out of 5,"Northridge, CA","['Performs a variety of duties in the electronic, mechanical, electromechanical, or optical areas.', 'Constructs, troubleshoots, calibrates, adjusts, tests, and maintains equipment, components, devices, or systems.', 'Works from engineering drawings and written or verbal instructions. Operates related equipment; conducts tests and reports data in prescribed format.', 'Performs calibration and alignment checks; makes adjustments, modifications, and replacements as directed; prepares prescribed compounds and solutions. Exclude technicians working in Production or Quality Assurance']",2020-08-08 13:19:52
Data Engineer,US Pharmacopeia,4.2 out of 5,"Rockville, MD","['Designs, builds, and implements data pipelines to support advanced use cases for product grade data science products', 'Manages data ingestion, processing and production process as well as managing tools and platforms', 'Interfaces with internal and external teams of data scientists and data engineers on process development', 'Collaborates with IT to integrate data warehouse, analytics applications, and data science platforms', 'Supports transition to agile approaches for data asset development and deployment', 'Supports transition to a SDLC approach to data asset and data science product development and deployment.', 'Bachelor’s Degree in Computer Science, Engineering, Mathematics, or related technical area', 'Five (5) years of data engineering specific experience designing, building, and supporting data pipelines', 'Strong core SQL development experience writing efficient SQL', 'Strong core data modeling ability', 'Very strong development ability in Python (additional languages such as Ruby, C#, Javascript a plus)', 'Hands-on experience with ETL/ELT tools and concepts', 'Experience working in cloud platforms (AWS, Azure, Google Cloud Platform, etc.)', 'Experience in at least one modern relational database', 'Strong communications and collaboration skills with a strength in working in teams', 'Strong problem solving and time management skills', 'Very strong learning agility- ability to pick up new tools and capabilities quickly', 'Ability to work across structured, semi-structured, structured data to extract information and identify linkage across disparate datasets', 'Experience with SDLC and Agile work environments', 'Ability to derive data modeling decisions and data engineering strategy to meet data strategy objectives', 'Direct experience supporting Data Science teams in moving from development to production environments', 'The ability to influence without direct authority.', 'Proven ability to clearly define priorities and focus on delivering work products in agile fashion', 'Ability to handle multiple priorities and complex projects in a fast-paced environment.', 'Prior experience in a scientific based industry or related content area a plus (pharma, life sciences, public health, research, etc.)', 'Experience with Apache Spark', 'Experience with Continuous Integration and Continuous Delivery (Deployment) software development approach', 'Substantial experience with Git for version control', 'Generous paid time off – 14 paid holidays, 10 sick days and 15 vacation days per year to start', 'An annual 401(k) contribution, beginning after 1 year of service, of 10% of pay (base and bonus) every pay period that vests immediately', 'Comprehensive individual and family healthcare plans with affordable premiums and low annual deductibles ($250/individual or $500/family)']",2020-08-08 13:19:52
"Data Engineer Austin, TX",VMware,4.1 out of 5,"Austin, TX","['Understand the business capability/requirements and transform them into robust design solutions', 'Perform hands on work using Python, able to write complex SQL’s, understand API and be able to consume/write API’s as needed', 'Perform report development using enterprise tools such as Tableau, SAP BOBJ and other open source reporting platforms.', 'Perform hands on work using SAP HANA, Hadoop/HAWQ SDI/SLT, Informatica to build next generation NearRealTime data analytics platform.', 'Integrate data sets from difference sources using Informatica, Python, SAP SDI/SLT', 'Protect data integrity and accuracy. Perform root cause analysis of issues that hinder the data quality. Work with data source owner to increase quality and accuracy of the source data.', 'Help data consumers to correctly understand and use the data.', '8+ years of experience in as a Data Engineer handling large volumes of data.', 'Excellent knowledge of data warehouse technical architecture, infrastructure components, ETL/ELT and reporting/analytic tools.', 'Expertise in writing advanced SQL queries.', 'Experience working with Informatica, SAP SDI/SLT', 'Expertise in SAP HANA, Hive/Hadoop/Hawq/Spark', 'Working knowledge of BI Reporting tools like BOBJ and Tableau', 'Experience in Python Scripting', 'Strong analytical and troubleshooting skills', 'Excellent verbal and written communication skills', 'Bachelor’s degree in Computer science, Statistics, Mathematics, Engineering or relevant field.']",2020-08-08 13:19:52
R&D Leadership Development Program – Internship Summer 2021,Johnson & Johnson Family of Companies,4.2 out of 5,"West Chester, PA","['Improve your industry knowledge through open forum conversations with senior company leaders and shadowing of senior engineers.', 'Create or improve your personal brand through skills building workshops and internship networking events.', 'Have the power to connect and support our local towns through community activities.', 'Work in a fast-paced cross functional, technologically advanced corporate environment in an internship program focused on developing individual engineers capable of pursuing careers across medical device businesses and high-volume manufacturers.', 'Have the opportunity to learn about anatomy, disease states, and deformities and the surgical procedures and products used to address these conditions.', 'Be involved in the design, development, manufacturing and commercialization of new products or product modifications.', 'Assist with the development of advanced materials, process improvements, risk management, and/or mechanical testing or advance a medical device through the development process.', 'Utilize solid modeling to design products, create drawings and tolerance analyses of mating components.', 'Become familiar with design control documentation required by regulatory governing bodies.', 'Present to leadership your learnings and development experience.', 'Currently enrolled in an Engineering Graduate Program (Master’s Degree or PhD) graduating in the Fall 2021 or Spring 2022.', 'The following engineering disciplines or specialties are preferred: Mechanical, Robotics, Electrical, Computer, Systems, Software, Materials Science, Biomedical and Computer Science.', 'The following concentration fields and/or skills are strongly preferred: Machine Learning, IoT, Embedded Software, Deep Machine Learning, Prototyping, Robot Design, Systems Reliability, Firmware and hardware integration.', 'A minimum GPA of 3.3 is strongly preferred.', 'Validated leadership experience through extra-curricular activities, employment and/or previous internship experiences is required. R&D Internships highly preferred.', 'Team player with the ability to work closely with technical and non-technical personnel is required.', 'Excellent communication skills and the ability to influence others is required.', 'Ability to demonstrate excellent problem-solving skills, intellectual curiosity and a dedicated approach to achieving success is required.', 'Proactive self-starter and have the courage to take a leadership position to help deliver robust results is required.', 'Ability to relocate across the United States as required by the internship program.']",2020-08-08 13:19:52
"Software Engineer, Data",Fathom Health,N/A,Remote,"['Develop data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs', 'Build performant and expressive interfaces to the data', 'Build infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning', '3+ years of development experience in a company/production setting', 'Experience building data pipelines from disparate sources', 'Hands-on experience building and scaling up compute clusters', 'Excitement about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration', 'A solid understanding of databases and large-scale data processing frameworks like Hadoop or Spark. You’ve not only worked with a variety of technologies, but know how to pick the right tool for the job', 'A unique combination of creative and analytic skills capable of designing a system capable of pulling together, training, and testing dozens of data sources under a unified ontology', 'Developing systems to do or support machine learning, including experience working with NLP toolkits like Stanford CoreNLP, OpenNLP, and/or Python’s NLTK', 'Expertise with wrangling healthcare data and/or HIPAA', 'Experience with managing large-scale data labelling and acquisition, through tools such as through Amazon Turk or DeepDive']",2020-08-08 13:19:52
Data Engineer,Hired Recruiters,N/A,"Austin, TX","['Cutting-edge tech We’ve built a cloud-first Serverless Architecture with tools like Lambda, API Gateway, GraphQL, ReactJS,', 'Founded by engineers Having a CEO who’s also an engineer is nice — he knows the effort it takes to make things awesome.', 'We don’t bite We’re friendly, down-to-earth, and collaborative. There are no high-performing jerks and no heroes. Just great teams.', 'Hungry and humble We’re dedicated to learning all the things to create the best product possible.', 'Be an essential part of designing and building ACG’s new data platform, as we evolve the existing databases into a cutting-edge solution to meet the needs of our 2021 data plans and beyond', 'Explore and contribute to discussions around technologies under consideration, such as Snowflake, Kappa/Lambda architecture, Delta Lakes and Data Vault', 'Develop, test and maintain existing architecture, including databases, data pipelines, and large-scale processing systems', 'Collaborate with the Analytics team on transformation processes to populate data models', 'Recommend ways to improve data reliability, efficiency, and quality of the data platform and optimize for performance, scalability, and cost', 'Discover opportunities for data acquisition and explore new ways of using existing data', 'Identify gaps in data processes and drive improvements', 'Utilize a variety of languages and tools (e.g. scripting languages) to marry systems together', 'Recommend ways to improve data reliability, efficiency, and quality for the whole data platform', 'Optimize solution designs for performance, scalability, and costs', '2+ years of Data Engineering, Data Warehousing, or related experience', '2+ years of development experience with Python or similar scripting language', '2+ years of SQL experience, including experience with schema design and dimensional data modeling', 'Experience working with AWS services such as DynamoDB, Glue, Lambda, Step Functions, S3, CloudFormation or Redshift', 'Experience with ETL development, metadata management, and data quality', 'Knowledge of software engineering best practices with experience with implementing CI/CD, monitoring & alerting for production systems', 'Experience with complex data structures and No-SQL databases', 'Experience with open source orchestration platforms (e.g. Airflow)', ""4 weeks PTO, plus 10 sick days, and holidays. Whether it's hiking to a waterfall in Costa Rica or bonding with your couch, we all need downtime. All Gurus get four weeks paid time off, 10 sick days, and enough holiday to make a banker blush."", ""Let's get lunch. Lunches are catered three times per week, and our kitchen stays stocked with a smorgasbord of the team’s most requested snacks and drinks."", 'Parking is on us. We have your Downtown parking covered. We offer paid garage parking near the office. We also have perks for going green by walking and taking public transit.', 'We’ve got you covered. We offer insurance plans that pay for 100% of your medical, dental, and vision and 80% for your family/dependents.', 'Gender-neutral paid parental leave. Expanding your family? We offer 12 weeks of gender-neutral paid parental leave and reimburse up to $10,000 for eligible adoption expenses.', '$1,000 continuing education budget. All Gurus get $250 a quarter to spend on personal development and 2 hours each week reserved for learning something new.']",2020-08-08 13:19:52
"Data Engineer, Senior",Booz Allen Hamilton,3.9 out of 5,"Herndon, VA","['5+ years of experience with coding using Java, Scala, or Python', 'Experience with developing and deploying ETL pipelines using Apache Spark', 'Experience with data tools', 'Experience in interfacing with modern relational databases, including MySQL or PostgreSQL', 'Experience in working with Big Data platforms, including Hadoop, AWS, Azure, or DataBricks', 'Ability to learn technical concepts quickly and communicate with multiple functional groups', 'Ability to obtain a security clearance', 'BA or BS degree', 'Experience with Agile software development', 'Experience with NoSQL data stores, including HBase, MongoDB, JanusGraph or Neo4J, and Cassandra', 'Experience with ETL tools, including StreamSets, NiFi, and Taland', 'Experience in working with enterprise production systems', 'Ability to display a positive, can-do attitude to solve the challenges of tomorrow', 'Possession of excellent oral and written communication skills', 'BA or BS degree in CS, Information Systems, or a related field preferred; MA or MS degree a plus', 'AWS or related certifications']",2020-08-08 13:19:52
Data Architect,Elder Research Inc,N/A,"Arlington, VA 22201","['Work collaboratively with data scientists, business consultants, and software engineers to create and deploy dynamic data applications that help our customers make meaningful business decisions.', 'Develop and deploy robust data pipelines and end-to-end systems', 'Participate in every stage of the engineering lifecycle, from ideation and requirements gathering through implementation, testing, deployment, and maintenance', 'Provide leadership and coordination for certain stages of the engineering lifecycle as needed', 'Perform other technical tasks as needed, including writing project reports, managing, implementing, and/or maintaining technical infrastructure, etc.', 'Ability and the willingness to tailor applications to a client’s business goals using an iterative methodology.', 'Ability to consider both long-term stability and scalability while taking a user-focused approach to development and deployment.', 'Communicate clearly both verbally and in writing to teammates and clients', 'Ability to work independently in a collaborative, dynamic, cross-functional environment', 'Travel to and work on-site at clients both local and non-local. Number of days at client site vary depending on project requirements', 'Eight (8) years relevant experience data architecture, Computer Science, Engineering, Information Systems or related technical discipline in applied data science research or big data analytics.', 'Bachelor’s Degree in Computer Science, Engineering, Information Systems or related technical discipline. A Master’s degree may be substituted for up to two (2) years of experience. A PhD may be substituted for up to five (5) years of experience.', 'Ability to perform functional and data requirements analysis, and implementation of data architecture projects, analyze customer requirements and provide solution recommendations.', 'Demonstrate knowledge of information architecture methodologies,', 'Ability to support the development of organization-wide data architecture for use in designing and building integrated, shared software and database systems', 'Must be able and willing to obtain a successful CBP Background investigation. A secret or higher clearance may be required in the future.', 'Previous experience supporting projects with Customs and Border Protection', 'Data manipulation, SQL, relational databases, and/or NoSQL databases – experience as a DBA is a huge plus', 'Cloud platform development and SaaS', 'DevOps – infrastructure, continuous integration and automation, packaging and deployment', 'Consulting experience is a plus']",2020-08-08 13:19:52
"Data Engineer: Bloomingdale's, New York, NY",Bloomingdale's,3.7 out of 5,"Long Island City, NY 11101","['Integrate data from multiple databases across different platforms such as Oracle, SQL Server, Teradata and Hadoop to integrate data and build a data lake and analytical data marts.', 'Work with the Lead Data Architect to determine high level data strategy for the Enterprise Data Warehouse within a Microsoft Azure environment.', 'Work extensively with Azure Data Warehouse MPP database platform.', 'Create logical and physical data models for operational applications and all analytic applications.', 'Participate in ETL design and act as the subject matter expert on source and target data structures.', 'Work with various outside vendors and internal support teams in maintaining and/or enhancing processes and data integrations.', 'Support business by generating ad-hoc analysis, using SQL, for overall business as needed.', 'Perform extensive data quality and data analysis checks to ensure integrity of database for business use.', 'Work with business partners on the full lifecycle of data related projects from requirements analysis and design through development.', 'Maintain and manage scheduling and distribution of reporting.', 'Manage and monitor server processes and jobs for on-premise and Azure cloud environments.', 'Investigate and resolve root cause for complex data issues.', 'Script and automate processes.', 'Diagram and document databases and data flows.', 'Regular, dependable attendance and punctuality.', 'Bachelor’s degree in Information Technology, Computer Science.', 'Minimum 4 years’ experience in database development and administration.', 'Experience with data integration and database design.', 'Experience with Hadoop, Spark, Hive experience preferred.', 'Experience with ETL tools. Microsoft SSIS preferred. Azure Data Factory nice to have.', 'Experience with enterprise reporting tools. Business Objects, Microsoft SSRS, Power BI or Tableau preferred.', 'Excellent data interpretation and communication skills;', 'Ability to summarize complex findings clearly and concisely, ability to communicate effectively to all levels of management.', 'Basic math functions such as addition, subtraction, multiplication, and division.', 'Strong conceptual/analytical/creative thinker.', 'Strong skills in SQL to analyze, manipulate data, investigate data problems, and develop reports.', 'Must be able to work independently with minimal supervision.', 'Strong organizational and time management skills; ability to adhere to deadlines.', 'This position involves regular walking, standing, hearing, and talking.', 'May occasionally involve stooping, kneeling, or crouching.', 'Involves close vision, color vision, depth perception, and focus adjustment.', 'Knowledge of data warehousing methodologies.', 'Familiarity with a programming/scripting language such as Java, .Net, PowerShell or Python.', 'Ability to work a flexible schedule based on department and company needs.']",2020-08-08 13:20:36
Data Engineer,Backblaze,3.5 out of 5,"San Mateo, CA 94401","['Build scalable, efficient and high-performance pipelines/ workflows that are capable of processing large amounts of batch and real-time data', 'Build out our data service architecture to support internal and customer facing application use cases', 'Multidisciplinary work supporting real-time streams, ETL pipelines, data warehouses and reporting services', 'Bring new and innovative solutions to the table to resolve challenging performance and load issues', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability', 'Build out the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using Java, Python, and SQL', 'Respond quickly to bug fixes and enhancement requests and be able to take directions and complete tasks on-time with minimal supervision.', 'Collaborate with business analytics team to optimize complex queries needed by regular Tableau reports', '5+ years of Java or Python', '3+ years in designing relational database, data modeling and ETL', 'Strong experience with SQL databases', 'Experience in operational data stores and real time data integration', 'Experience with RESTful APIs and server-side APIs integration', 'Proficient with development on Linux and Macintosh platforms', 'Maria DB', 'NoSQL DB', 'Cassandra experience', 'Salesforce', 'Passionate about building friendly, easy to use Interfaces and APIs.', 'Likes to work closely with other engineers, support, and sales to help customers.', 'Believes the whole world needs backup, not just English speakers in the USA.', 'Customer Focused (!!) — always focus on the customer’s point of view and how to solve their problem!', 'Good attitude and willingness to do whatever it takes to get the job done', 'Strong desire to work for a small, fast-paced company', 'Desire to learn and adapt to rapidly changing technologies and work environment', 'Rigorous adherence to best practices', 'Relentless attention to detail', 'Excellent interpersonal skills and good oral/written communication', 'Excellent troubleshooting and problem-solving skills', '100% healthcare for family', 'Competitive compensation and 401k', 'Full-time employees receive option grants', 'Flexible vacation policy', 'MacBook Pro to use for work plus a generous stipend to personalize your workstation', 'Fully stocked micro kitchens and strong coffee', 'Catered breakfast and lunches twice a week', 'Childcare bonus (human children only)', 'Pet-friendly office', 'Generous skills training policy to continue your professional development', 'Culture that supports healthy work-life balance']",2020-08-08 13:20:36
"Data Engineer position in Charlotte, NC",iknowvate technologies,N/A,"Charlotte, NC",[],2020-08-08 13:20:36
Software Engineer - All Levels,Xometry Inc,N/A,Remote,"['Active participation on a software development team designing, coding, testing, and releasing functionality to our customers', 'Close collaboration with other engineers and product managers to become a valued member of an autonomous, cross-functional team', 'Operational responsibility for the services that are owned by your team, potentially including taking part in an on-call rotation', 'Experience working on a web application project that you can talk about, showing off some of your work', 'Some understanding and maybe some experience with front-end technologies HTML, CSS, DOM, JavaScript, Ajax and any of the common frameworks like React, Angular, Ember, Backbone, …etc (really any javascript based framework)', 'Some understanding and maybe some experience with using using C#, Java, C, C++, Ruby, Python, Node or similar back-end technologies', 'Familiarity with code management (GIT) and continuous integration build and deploy', 'Must be a US citizen, green card holder, or a legal permanent resident of the United States', 'Excellent oral and written (English) communication skills', 'Must be able to work core aligned hours to US Eastern Time / GMT-5', 'Work in a highly collaborative, self-organizing team with the ability to decide how your team works and what technologies you use', 'Competitive salary + comprehensive benefits', 'Flexible working hours with paid time off', 'Health, Dental, Vision, Commuter, Dependent Care, Primary & Secondary Parental Leave, and 401K benefit options', 'Continuous development opportunities such as onsite training, meetups, conferences, and online training subscriptions', 'Stock Options – we’re a growing startup so you get a piece of the pie', 'And more!']",2020-08-08 13:20:36
Data Intelligence Engineer,Anderson Direct & Digital,N/A,"Poway, CA 92064","['Work cross-functionally with members of various teams', 'Strong technical and problem-solving skills with an impeccable eye for detail', 'Ability to translate business requirements into technical requirements and instructions', 'Implement, test and maintain highly scalable, robust and data solutions and systems', 'Data “cleansing and manipulation” involving Cass/NCOA/Matchcoding to merge data from multiple sources', 'Skilled in SQL, programming languages, IDE’s, relational database design, cloud services and ability to learn new technologies and software quickly', 'Advanced Microsoft Excel skills', 'Analyzing business and data processing issues', 'Help identify ways to improve existing processes including automated and adhoc QA processes to ensure the accuracy and quality of programming output', 'Excellent written and verbal communication skills and strong organizational and time management skills', 'Versatility, flexibility and a willingness to work within constantly changing priorities', 'Other duties and responsibilities as apparent or assigned, including mutually agreed upon objectives', 'Bachelor’s degree (B.A.) from a four-year college or university, preferred', '2 plus years SQL programming', '2 plus years related experience in data & digital applications including direct marketing, marketing databases, merge purge, list processing, and data hygiene', 'General knowledge of:', 'Various operating systems (e.g. Unix, Linus, Solaris, MS Windows)', 'Database design, architecture (1-tier, 2-tier, 3-tier and n-tier) and associated interdependencies on Windows and other systems', 'Strong command of:', 'Database technologies (e.g.: MySQL, MSSQL, Postgre SQL, Oracle, Cassandra & MongoMB)', 'Various programming languages (e.g. Python, C#, Scala, Java)', 'ETL/Data Warehousing solutions', 'Version control (e.g. TFS, SVN or Git)', 'Cloud systems (e.g. Amazon Web Services and Microsoft Azure', 'First-hand experience with preparing data for Tableau and interdependencies', '401(k)', '401(k) Matching', 'Dental Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'digital project management: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'Poway, CA 92064 (Preferred)', 'United States (Preferred)', 'What is your expected compensation for this position?', 'One location', 'www.andersondd.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:20:36
Residential Design Engineer,Sunpower,3.6 out of 5,Remote,"['Use photos and other data from Customers homes to design safe and effective solar and battery storage plansets', 'Apply understanding of building codes and solar fundamentals to optimize designs', 'Ability to think outside the box, applying critical thinking, and creative problem solving skills are critical for success in this role', 'Use AutoCAD and other Sunpower tools to design projects']",2020-08-08 13:20:36
Data Engineer,Maine Technology Users Group,N/A,"Portland, ME",[],2020-08-08 13:20:36
Research Data Engineer FEATURED,Galaxy Tek Hires,N/A,"New York, NY","['Design, develop, test, and deploy elegant software solutions across the firm to support critical investment decisions', 'Partner with business leaders, quantitative researchers and technologists to define priorities and deliver custom solutions', 'A deep passion for working with data and developing software to address data processing challenges', 'Minimum of a bachelor’s degree in Computer Science or equivalent experience with good software design and engineering skills', 'Proficiency within one or more programming languages including Python, C, C++, R and/or JavaScript is a plus', 'Proficiency with multiple data platforms including RDBMS, NoSQL, MongoDB, Spark, Hadoop', 'Experience with some of the following areas: Distributed Computing, Natural Language Processing, Machine Learning, Cloud Platform Development, Networking, and/or REST Service Development', 'Good analytical and quantitative abilities', 'Demonstrated ability to quickly learn new technologies and skills', 'Ability to manage multiple tasks and thrive in a fast-paced team environment']",2020-08-08 13:20:36
Data Engineer,Shutterfly,3.8 out of 5,"Fort Mill, SC","['Design Extract-Transform-Load (ETL) Workflows for data migration from various sources to data warehouse using batch or incremental loading strategies.', 'Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.', 'Excellent understanding of development processes and agile methodologies', 'Document database design including data modeling, metadata and business process flow for the new business integration requirements.', 'Document technical ETL specifications for a data warehouse. Perform periodic code reviews and test plans to ensure data quality and integrity.', 'Strong analytical and interpersonal skills', 'Enthusiastic, highly motivated and ability to learn quick', 'Ability to work through ambiguity in a fast-paced, dynamically changing business environment', 'Ability to manage multiple tasks at the same time with minimum supervision', 'Bachelor’s degree from an accredited university or college in computer science.', '3+ years’ experience in the data warehouse space.', '3+ years’ experience working with large scale ETL systems (implementation and maintenance, CDC/Event-driven architectures).', '3+ years of experience building clean, maintainable, and well-tested code.', 'Experience dealing with large databases', 'SQL proficiency', 'Databases such as MemSQL, MySQL, Postgres', 'Bonus points for background in data science, analytics, or data mining', 'Experience in any of the following are preferred but not required: Spark, Dask, Jupyter', 'Excellent communication skills to collaborate with stakeholders at all levels of the company.', 'Proven ability to learn quickly, work independently, and adapt to change in a fast-paced environment', 'High-level written and verbal communication skills.']",2020-08-08 13:20:36
Data Engineer,KoBold Metals,N/A,Remote,"['Help develop KoBold’s proprietary data system, TerraShed™, and modeling software, Machine Prospector™', 'Design components of the data system to ingest, store, process, and access a large volume and wide variety of geoscience data for both predictive modeling and visualization', 'Integrate diverse and messy geophysical, geochemical, geologic, and geographic data from around the world into a well-structured proprietary database', 'Create tools for ingesting unstructured datasets and extracting key features', 'Work with data scientists to implement and improve algorithms and predictive models', 'Develop interactive visualizations to enable the data team and geoscience teams to rapidly view and interrogate the model results and underlying data', 'Proficiency in Python', 'A technical stack that includes Postgres/PostGIS and Elasticsearch', 'Experience storing and processing diverse datasets in both relational and no-sql architectures', 'Experience with data processing technologies such as Airflow, Spark, and Dask', 'Experience creating/managing large databases and pipelines', 'Experience with setting up and deploying systems on AWS', 'Excited to work on a wide range of problems, and to take on a wide range of responsibilities, learning new tech tools whenever needed', 'Highly intellectually curious and eager to learn from technical experts who aren’t software people', 'Keen not just to build products, but to figure out what product to build to best achieve the business objectives of the company', 'Highly self-motivated and autonomous, able to effectively structure one’s own work, make realistic time estimates, and communicate well as one progresses', 'Comfortable with a fast-changing work environment', 'Careful to get the details right', 'Experience with geospatial databases, analyses, and/or visualizations', 'Experience with Flask or similar web frameworks', 'Experience with planning and implementing information security measures', 'A bachelor’s degree or higher in the physical sciences, engineering, computer science, or mathematics']",2020-08-08 13:20:36
Data Visualization Engineer II,Blue Margin,N/A,"Fort Collins, CO 80524","['Develop accurate reports in Power BI that are not only visually engaging, but also make customers’ data accessible and actionable', 'Regularly interact with clients for project updates and inquiries', 'Create, enhance and troubleshoot data models in Power BI and Visual Studio', 'Author documentation of customer reporting requirements and finished reports', 'Craft and use T-SQL queries for data validation', '1-2 years of experience in Power BI Desktop creating tables, graphs, drill downs, drillthroughs, bookmarks, and KPIs', 'Working knowledge of Power BI Service and how to configure it', 'Ability to create intermediate to advanced DAX calculations using functions such as Calculate, Summarize and Filter', 'Experience creating T-SQL queries in SSMS', 'Comprehensive grasp of data visualization methods', 'Familiarity with data modeling', 'Broad business experience with a proficient ability to talk to executives in business terms', 'Professional demeanor', 'Experience using Visual Studio 2017/2019, DAX Studio, Tabular Editor, ALM Toolkit', 'Familiarity with tabular data models', 'Comfortable with manipulating data in Power Query Editor', 'Company Core Values: Embrace Transparency, Choose to Be Positive, Be Efficient/Systematize, Pursue Learning, Be Generous', 'Weekly personal and professional development programs for all', 'Teamwork—we maintain company-wide interaction and communication', 'Entrepreneurism – we want everyone on our team to be eager to adapt and evolve with our advancing business. We are looking for someone who is comfortable wearing more than one hat.', 'This job may require moderate physical effort including lifting materials and equipment of less than 50 pounds and involves viewing a CRT or VDT screen more than 80 percent of the time. The job will take place in a normal office environment with controlled temperature and lighting conditions. The position may require some travel and occasional participation in off-site functions. This position requires standing or sitting for long durations.', 'Starting salary for this position is between $70,000-$75,000 and is commensurate with experience and qualifications. This position comes with a comprehensive benefits package consisting of medical and dental coverage, paid sick leave, vacation, and a retirement plan.']",2020-08-08 13:20:36
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:20:36
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:20:36
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:20:36
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:20:36
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:20:36
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:20:36
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:20:36
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:20:36
Data Engineer,Martin's Point Health Care,3.5 out of 5,"Portland, ME","['Participates in the development, testing, implementation and maintenance of uni-directional and bi-directional interfaces in support of information needs within Martin’s Point application environment.', 'Understands basic data extraction and data transfer tools utilized at Martin’s Point and is able to utilize those tools.', 'Utilizes data storage, access and transfer policies and procedures instituted.', 'Analyzes the use of data within Martin’s Point for an assigned project and will develop integration methods in support of that projects data needs.', 'Designs and builds data integration methods to guarantee accuracy as well as accessibility of all valuable data while understanding what data is important for that project and why.', 'Creates and maintains accurate and relevant network documentation including diagrams, as-built documents, configuration templates, inventories and IT Service Catalog.', 'Participates in after-hours work as needed', 'Participates in Process Improvements and other duties as assigned', 'Bachelor’s Degree in Computer Science or combination of relevant and equivalent education and experience', '3+ years of data integration experience', 'Educational/professional experience in SQL database design and Service Oriented Architecture', 'Educational/professional experience with Unix, SQL, Oracle, TCL as well as other scripting languages', 'Knowledge of HL7\\FHIR interface development and deployment']",2020-08-08 13:21:23
Data Scientist,NBCUniversal,4 out of 5,"Seattle, WA","['Minimum of a Bachelor’s degree in Computer Science,', '6+ years experience as a data scientist or data analyst', 'Mastery of SQL and either R or Python', 'Demonstrated success with statistical modeling and', 'Experience with AWS', 'Experience with data visualization tools (e.g. Looker,', 'Possess strong interpersonal skills with the ability to', 'Ability to deliver on multiple projects and meet tight', 'Flexible and adaptable, self-driven, confident and', 'Background in digital media or entertainment a plus', 'Experience with software development and automation a']",2020-08-08 13:21:23
Data Engineer - Full Time,Data Bridge Consultants,4.5 out of 5,United States,"['Builds complex technical solutions that turn business requirements into operational processes and inject analytical insights into the business', 'Aligns complex technical solutions to corporate governance requirements to ensure data security and maintain data quality standards', ""Remains on the cutting edge of industry trends to ensure that the Lowe's COE is aligned with industry best practices"", 'Builds automation and self-service consumption tools to operationalize data ingestion and analytic models', 'Aligns technical solutions to corporate standards to ensure that security and privacy requirements are met', 'Communicates clearly and concisely to key leadership and stakeholders to ensure alignment on project status and deliverables', 'Partners with Big Data architects, Data Scientists and other key stakeholders to ensure that project deliverables align with cost and timing standards', ""Bachelor's Degree in Computer Science, Engineering or related field and 3 years of experience in strong software programming fundamentals, with knowledge of Python, Scala or Java"", 'Good Understanding of SQL and NoSQL databases', '12 months experience in Data Engineering or relevantOR', ""Master's Degree in Computer Science, Engineering or related field and 1 year of experience in strong software programming fundamentals, with knowledge of Python, Scala or Java"", 'Good Understanding of SQL and NoSQL databases and related concepts', '6 months experience in Data Engineering or relevant']",2020-08-08 13:21:23
Data / ETL Engineer,DRINKS,3.6 out of 5,"Los Angeles, CA 90025","['Become a member of agile development team', 'Actively participate in daily code review sessions', 'Understand and implement best practices in managing enterprise data including master data, data quality, lineage and security', ""Interface with the department's business analysts, developers, data architects and system administrators on daily support tasks and project-driven activities"", 'Share best practices and be open to alternative technology implementations', 'Work with business team and engineering teams to design and implement large data processing flows', 'Take on special projects as necessary', 'Ability to collaborate with engineering team as well as work independently on projects', 'Exceptional time management and ability to problem solve under pressure', 'Strong understanding of data and analytics solution architecture, including experience with Big Data, Relational databases, streaming and batch data processing', 'Strong verbal and written communication skills and excellent attention to detail', 'Flexibility in work schedule as needs arise', 'Energetic, enthusiastic and self-motivated with a strong work ethic', 'Matillion ETL', 'Ruby / Rails', 'Linux scripting', 'MySQL', 'Redshift', 'Familiarity with AWS; S3, Lambda', 'Tableau report writing experience', ""Bachelor's Degree in Computer Science or equivalent"", 'Experience at a startup or similar fast-paced tech environment', 'A passion for wine!']",2020-08-08 13:21:23
"Data Engineer, Enterprise Data Services",New York City MAYORS OFFICE OF CONTRACT SVCS,N/A,"Manhattan, NY 10007","['Collaborate with the other members of the integration team in the design, implementation and documentation of solutions for daily issues/support, release management, and new projects', 'Assist in architecting, mapping, developing, and testing data movement to data warehouses (Redshift and SQL Server), with emphasis on the ETL process', 'Develop, document, and execute SQL/stored procedures/server scripts as needed to support ETL code', 'Determine ETL requirements and assist with production, setup, and execution of migrations', 'Work closely with BI and PASSPort teams on ETL development efforts including analysis and design of integration solutions, data and reporting needs of internal and external stakeholders, and enhancements', 'Identify and resolve data, technical issues and mediate business impact', 'Collect requirements, design, build and test reports and dashboards across applications and programs', 'Perform ad hoc analysis as required', 'Excellent writing and communication skills', 'Knowledge and interest in computer systems and the latest technologies', 'Familiar with AWS ecosystem including S3, Redshift databases, Lamda, EC2, Matillion and necessary supporting activities', 'The ability to learn new technologies quickly', 'Ability to write complex procedures using SQL (i.e. T-SQL, PL/pgSQL, etc.)', 'Experience in generic object-oriented languages (i.e. C#, Java, etc.)', 'Experience in scripting languages (i.e. Python, PowerShell, etc.)', 'Experience in ETL tools (i.e. Matillion, SSIS, Informatica, ets.)', 'Knowledge of testing tools and techniques and executing test scripts to test performance of ETL procedures', 'Significant experience in development, maintenance, and enhancements of ETL Mappings, Work-flows, and processes', 'Excellent analytical, organization, presentation and facilitation skills; ability to handle multiple tasks under tight deadlines', 'Familiarity with New York City’s data share platforms, including Open Data (DOITT’s DataShare) (FMS, PIP, APT).', 'Working knowledge of database back-end systems (i.e. AWS Redshift, SQL Server, Oracle, PostgreSQL).', 'Familiarity with Data Warehouse concept (Kimball), fact tables, slowly changing dimensions types.', 'Past utilization of code repositories (i.e. GitHub, GitLab or AWS CodeCommit).', 'Analyze user requirements and convert requirements to design documents.', 'Multi-task and change from one task to another without loss of efficiency or composure.', 'Development of technical specifications and plans.']",2020-08-08 13:21:23
Data Engineer,Vydia,N/A,"Holmdel, NJ 07733","['Ensuring the availability and timely delivery of data, company-wide', 'Modeling new data sets and crafting all new ELT workflows and pipelines', 'Lead the orchestration of the workflows and contribute strongly to infrastructure decisions', 'Improving on and monitoring of existing pipelines and oversight of our ELT workflow', 'Maintaining a single version of truth for our data and working with others to implement continuous integration (CI) data quality tests', 'Mentoring and guiding your junior colleagues and leading with vision, and with respect to the company’s data strategy', 'You are a Python pro and have regularly used AWS or Google Cloud Platform to manage data and move it between applications', 'Do you love APIs? When you encounter a new one, do you study it inside and out and learn every corner of it, as though you designed it yourself?', 'Working with deeply-nested, complex JSON is a fun day at the office for you.', 'You can articulate the merits and pitfalls of the different approaches in designing a pipeline.', 'You are passionate about data quality control and know how and where to anticipate potential errors.', 'Working “in the cloud” is not a point of distinction for you, it is a given.', 'You understand what it means to work at a tech startup. Hopefully, this is what excites you more than anything else about working here.', 'You intuitively know how to extract value and insights from data.', 'You love the idea of building the data scene in NJ and being a leader in this community.', 'You have orchestrated workflows using Airflow and are familiar with the challenges and how to overcome them.']",2020-08-08 13:21:23
Client & Data Test Engineer,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Comfortable and adaptable in a fast-paced environment.', 'Strong analytical, problem solving and creative thinking skills.', 'Excellent verbal and written communication.', 'Strong commitment to technical quality assurance as a key part of the software development cycle. Willingness to work cross-functionally.', 'Results-oriented, persistent, and meticulous.', 'Experience writing automation using Python, JavaScript scripting and user-level automation for iOS.', 'Experience with Spark, Hadoop, Kafka or other distributed systems is a plus.', 'Experience in developing and verifying Spark/Map Reduce jobs is a plus.', 'Familiarity with Objective-C or Swift is a plus.', 'Knowledge in SQL, CSS, HTML, JSON a plus.']",2020-08-08 13:21:23
Software Development Engineer - AWS - Fully Virtual,"Amazon Web Services, Inc.",3.6 out of 5,Remote,"['5+ years of non-internship professional software development experience with at least one modern language such as Java, Python or Node including object-oriented design', '1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems', 'Implement best practices in modern software engineering: design, implementation, testing, version control, documentation, deployment, monitoring and operations', 'Write high quality code that is robust and can be delivered and maintained by customers', 'Build flexible systems choosing simple, straightforward solutions over more complex ones', 'Possess self-drive to dive deep and maintain progress even in the face of ambiguity and imperfect knowledge (avoid “analysis paralysis”)', 'Encourage and support knowledge-sharing within team and external groups', 'Communicate clearly both verbally and in writing, within team and external groups', 'Actively participate in hiring and mentoring the very best', 'Obtain/maintain AWS Certifications', 'Occasional customer travel (<20%)', 'Can potentially work remotely (can live within 2 hours of Amazon/AWS office).', 'Effective verbal and written communication skills', 'Proficiency in design and analysis of algorithms and data structures that will operate at potentially global scale.', 'Proficiency in the DevOps style of software deployment', 'Proficiency in developing software in a cloud-native environment', 'Knowledge of Application Security principles and how they impact development and deployment of applications.', 'Experience handing off and supporting maintainable code artifacts', 'Experience in an agile development environment', 'Experience with Cloud Operational Excellence practices', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-08-08 13:21:23
Data Engineer (Remote),PlayQ,N/A,California,"['Build and manage efficient and reliable real-time data pipelines from disparate data sources', 'Design, develop and launch data ingestion and storage systems with high availability and reliability that can scale', 'Drive the advancement of data infrastructure by developing and implementing underlying logic and structure for how data is set up, cleaned and stored', 'Take an integral role in designing and implementing a data lake strategy', 'Build and manage a universal semantic layer over the data lake', 'Architect, launch and manage automated extraction & transformation processes', 'Build scalable data aggregation layer from queues and batches of data for data visualization', 'Collaborate with development teams on design, architecture, and expansion of infrastructure', 'BS from an accredited university in Computer Science, Engineering, Math or related field', '4-5 years of experience in building data pipelines, data architecture, data modeling & data governance', 'Proficient working with SQL/NoSQL databases and MPP/columnar data warehouse solutions (Redshift, BigQuery, Snowflake etc.)', 'Experience with AWS environments: Redshift, EC2, Data Pipeline, S3, RDS, Glue, Spectrum, Dynamodb, Lambda', 'Proficient working with Python, bash or other scripting languages', 'Must have experience working with large data sets', 'Experience working in the mobile gaming industry', 'Competitive compensation and equity options', 'Comprehensive medical, dental, vision, life and long term disability insurance', 'Flexible time off', '401K plan with company match', 'Stocked kitchen with free snacks and beverages of your choice', 'Catered weekly team lunches', 'Brand new penthouse office space equipped with outdoor patios offering beachfront views', 'Monthly team outings and volunteer opportunities', ""Help build and support awesome GAMES. For a living! Who doesn't love games?""]",2020-08-08 13:21:23
R&D Leadership Development Program,Johnson & Johnson Family of Companies,4.2 out of 5,"West Chester, PA","['You will have opportunities to participate and/or lead in rotational assignments encompassing entire project or a large portion of a major project. This may include resolving advanced materials, process, inspection/testing or procedural approaches to advance a medical device through the pipeline process into full R&D, and potentially into commercialization.', 'Support of products’ design development, manufacturing and commercialization, leveraging technical expertise to anticipate and proactively address challenges and risks.', 'Increase the productivity of product’s design utilizing CAD, improve the quality of projects, improve communications through documentation, and to create a database for manufacturing.', 'Engineer capabilities required to develop and deliver automated medical devices - including requisite instruments, advanced imaging, and user interface / experience.', 'Pursue a number of internal developmental training programs as well as externally recognized qualifications such as Process Design Excellence.', 'Opportunity to work in a fast-paced cross functional, technologically advanced corporate environment in a program focused on developing individual engineers capable of pursuing careers across medical device businesses and high-volume manufacturers.', 'Currently enrolled in an Engineering Graduate Program (Master’s Degree or PhD) graduating by June 2021.', 'The following engineering disciplines or specialties are preferred: Mechanical, Robotics, Electrical, Computer, Systems, Software, Materials Science, Biomedical and Computer Science.', 'The following concentration fields and/or skills are strongly preferred: Machine Learning, IoT, Embedded Software, Deep Machine Learning, Prototyping, Robot Design, Systems Reliability, Firmware and hardware integration.', 'A minimum GPA of 3.3 is strongly preferred.', 'You must have the ability to work closely with technical and non-technical personnel and have excellent communication skills with the ability to influence others.', 'You must have the ability to demonstrate excellent problem-solving skills, intellectual curiosity and a dedicated approach to achieving success.', 'Validated leadership experience through extra-curricular activities, employment and/or internship experiences is required. R&D internship highly preferred.', 'Ability to relocate anywhere in the United States as required by the program’s rotations – mandatory requirement.']",2020-08-08 13:21:23
Data Visualization Engineer II,Blue Margin,N/A,"Fort Collins, CO 80524","['Develop accurate reports in Power BI that are not only visually engaging, but also make customers’ data accessible and actionable', 'Regularly interact with clients for project updates and inquiries', 'Create, enhance and troubleshoot data models in Power BI and Visual Studio', 'Author documentation of customer reporting requirements and finished reports', 'Craft and use T-SQL queries for data validation', '1-2 years of experience in Power BI Desktop creating tables, graphs, drill downs, drillthroughs, bookmarks, and KPIs', 'Working knowledge of Power BI Service and how to configure it', 'Ability to create intermediate to advanced DAX calculations using functions such as Calculate, Summarize and Filter', 'Experience creating T-SQL queries in SSMS', 'Comprehensive grasp of data visualization methods', 'Familiarity with data modeling', 'Broad business experience with a proficient ability to talk to executives in business terms', 'Professional demeanor', 'Experience using Visual Studio 2017/2019, DAX Studio, Tabular Editor, ALM Toolkit', 'Familiarity with tabular data models', 'Comfortable with manipulating data in Power Query Editor', 'Company Core Values: Embrace Transparency, Choose to Be Positive, Be Efficient/Systematize, Pursue Learning, Be Generous', 'Weekly personal and professional development programs for all', 'Teamwork—we maintain company-wide interaction and communication', 'Entrepreneurism – we want everyone on our team to be eager to adapt and evolve with our advancing business. We are looking for someone who is comfortable wearing more than one hat.', 'This job may require moderate physical effort including lifting materials and equipment of less than 50 pounds and involves viewing a CRT or VDT screen more than 80 percent of the time. The job will take place in a normal office environment with controlled temperature and lighting conditions. The position may require some travel and occasional participation in off-site functions. This position requires standing or sitting for long durations.', 'Starting salary for this position is between $70,000-$75,000 and is commensurate with experience and qualifications. This position comes with a comprehensive benefits package consisting of medical and dental coverage, paid sick leave, vacation, and a retirement plan.']",2020-08-08 13:21:23
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:21:23
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:21:23
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:21:23
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:21:23
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:21:23
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:21:23
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:21:23
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:21:23
Data Engineer,Hudson River Trading,3.5 out of 5,"New York, NY 10005","['Strong programming experience in Python', 'Demonstrated ability to work with data', ""Data infrastructure experience - you know how to really store data; and no, we don't mean saving an Excel file on your desktop (everyone knows that's messy and it should be in a nicely named folder)"", 'Track record of working successfully in a collaborative environment', 'Top-notch communication skills', 'You have a minimum of 2-3 years of experience working in data infrastructure', ""Bachelor's degree in computer science, math or a related field"", ""You enjoy being part of an amazing team but don't mind working alone on a difficult problem"", 'You can analyze and fix problems quickly', 'You really like to work with people who motivate you and make you better', 'In your spare time you: code, tinker, read, explore, break things, and have an insatiable curiosity for all things computer related']",2020-08-08 13:22:09
Data Engineer,1904labs,N/A,"St. Louis, MO 63108","['Agile: Experience working in an agile team oriented environment', 'Attitude / Aptitude: A passion for everything data with a desire to be at the cutting edge of technology and consistently deliver working software while always keeping an eye on opportunities for innovation.', 'Technical Skills (You have experience with 2 or more of these bulletpoints):Programming in Java (Or similar JVM language such as Scala, Groovy, etc) and/or PythonArchitecting and integrating big data pipelinesWorking with large data volumes; this includes processing, transforming and transporting large scale data using technologies such as: MR/TEZ, Hive SQL, Spark, etc.Have a strong background in SQL / Data Warehousing (dimensional modeling)Have a strong background working with and/or implementing architecture for RDBMS such as: Oracle, MySQL, Postgres and/or SQLServer.Experience with traditional ETL tools such as SSIS, Informatica, Pentaho, Talend, etc.Experience with NoSQL/Graph Data Modeling and are actively using Cassandra, HBase, DynamoDB, Neo4J, Titan, or DataStax GraphInstalling/configuring a distributed computing/storage platform, such as Apache Hadoop, Amazon EMR, Apache Spark, Apache Hive, and/or PrestoWorking with one or more streaming platforms, such as Apache Kafka, Spark Streaming, Storm, or AWS KinesisWorking knowledge of the Linux command line and shell scripting', 'Analytics: Have working knowledge of analytics/reporting tools such as Tableau, Spotfire, Qlikview, etc.', 'Open Source: Are working with open source tools now and have a background in contributing to open source projects.', 'Standard Benefits Program (medical, dental, life insurance, 401(k), professional development and education assistance, PTO).', 'Innovation Hours - Ten percent (10%) of our work week is set aside to work on our own product ideas in a highly collaborative and supportive environment. The best part: The IP remains your own. We are a high-growth culture and we know that when we help people focus on personal and professional growth, collectively, we can achieve great things.', ""Dress Code - we don't have one""]",2020-08-08 13:22:09
Data Engineer II,"TechPro, LLC",N/A,"San Francisco, CA 94103","['Understand the data landscape of products', 'Design, architect, and implement new source of truth datasets, in partnership with analytics and business teams', 'Build the required data and reporting pipelines using internal ETL tools', 'Develop dashboards, web-based visualizations (using Tableau, D3, or Plotly), and web-based tools (node.js or flask apps)', 'Collaborate with other engineering teams to develop and integrate BI solutions', 'Experience designing, architecting, and maintaining data warehouses that seamlessly stitches together data from production databases and clickstream event data', 'Hands-on experience with Hive query development and optimization, and, building workflows (preferably using Airflow)', 'Hands-on experience with building data pipelines in a programming language like Python', 'Hands-on experience with building and maintaining Tableau dashboards and/or Jupyter reports', 'Working understanding of Hadoop and Big data analytics', 'Ability to understand the needs of and collaborate with stakeholders from analytics and business teams', 'Monday to Friday', 'Hive query development and optimization, and, building workf: 3 years (Required)', 'building and maintaining Tableau dashboards: 3 years (Required)', 'building data pipelines in a programming language like Pytho: 3 years (Required)', 'Hadoop and Big data analytics: 3 years (Required)', 'data engineering or business intelligence/analytics: 3 years (Preferred)', ""Bachelor's (Required)"", 'San Francisco, CA 94103 (Required)', 'United States (Required)', 'No']",2020-08-08 13:22:09
Data Engineer – Core Data,Spotify,4.3 out of 5,"New York, NY 10011","['Who you areAn BS/MS in CS or any other relevant fields of study', 'You have 3+ years of experience in the development of high-quality database and data solutions.', 'Strong analytical and problem solving ability', 'Have worked in a team with both Data Engineers and Data Scientists', 'You are capable of tackling very loosely defined problems and thrive when working on a team which has autonomy in their day to day decisions', 'You are a self-motivated individual contributor and great teammate with the ability to multitask, prioritize and communicate progress in a rapidly changing environment.', 'Would like to build skills to further enhance the t-shape within analytics and data engineering', 'Strong coding skills in preferably Scala, Java and Python', 'Strong communication and data presentation skills (such as Tableau, PowerPoint, Qlik, etc.)', 'Experience performing analysis with large datasets in a cloud based-environment, preferably with an understanding of Google’s Cloud Platform', 'You are a communicative person that values building strong relationships with colleagues and multiple stakeholders, and have the ability to explain complex topics in simple terms', 'Ideally you have experience working in a large scale, global consumer product company, in an engineering or insights role', 'Getting hands-on experience with Google Cloud Platform and technology/languages such as BigQuery, Scala, Scio, Luigi, Styx and Docker', 'Understand what fuels many of Spotify’s product features such as Discover Weekly, Daily Mix, Podcast offerings, holiday campaigns and others', 'Work hand-in-hand with the data science community to understand various user or content trends that influence product changes and customer acquisition strategies', 'Collaboration on a global scale; our squad offers ongoing opportunities to work in Stockholm with other engineering colleagues', 'Innovate our data products to create a single coherent platform with sources of truth that serve a plethora of product and data stakeholders', 'Communicate insights and recommendations to key stakeholders, engineering, data science and product partners', 'Work in a supportive team that offers engineers the flexibility to be creative and chase interesting ideas', 'Work closely with the product manager, end-users and stakeholders to understand, document, troubleshoot and analyze requirements for complex data solutions', 'Lead and mentor engineers as we grow the bigger team… and of course, having fun! Being passionate about what you do also means celebrating milestones within the team and the tribe!']",2020-08-08 13:22:09
Senior Data Integration Engineer,Northwestern Mutual,3.8 out of 5,"Milwaukee, WI",[],2020-08-08 13:22:09
Senior Data Engineer,R&K Solutions,3.8 out of 5,"Roanoke, VA 24017",[],2020-08-08 13:22:09
Data Engineer,Next Generation Technology,N/A,"McLean, VA","['Responsible for delivery in the areas of: big data engineering with Hadoop, Python and Spark (PySpark) and a high-level understanding of machine learning', 'Develop scalable and reliable data solutions to move data across systems from multiple sources in real time (Nifi, Kafka) as well as batch modes (Sqoop)', 'Construct data staging layers and fast real-time systems to feed BI applications and machine learning algorithms', 'Utilize expertise in technologies and tools, such as Python, Hadoop, Spark, AWS, as well as other cutting-edge tools and applications for Big Data', 'Demonstrated ability to quickly learn new tools and paradigms to deploy cutting edge solutions.', 'Develop both deployment architecture and scripts for automated system deployment in AWS', 'Create large scale deployments using newly researched methodologies.', 'Work in Agile environment', 'Strong SQL skills to process large sets of data']",2020-08-08 13:22:09
Data Operations Engineer,Pluralsight,4.2 out of 5,"South Jordan, UT",[],2020-08-08 13:22:09
Data Engineer (Remote),Cloudbeds,N/A,"Boston, MA 02111","['Code ETL data transformations in PySpark/Spark.', 'Design and manage processing pipelines via AWS Glue and/or EMR clusters.', 'Manage ingestion and replication via DBMS from cloud MySQL databases.', 'Process external sources like Salesforce via Appflow or kaggle datasets.', 'Manage AWS Athena views and endpoints for consumption.', 'Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)', 'Implement logging and debugging approaches in a standardized fashion.', 'Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.', 'Develop a framework for future extensions through standardized modern workflows.', 'Bachelor’s degree in computer science or related field, or equivalent experience.', '3+ years experience as a Data Engineer.', '2+ years experience working with Amazon Web Services.', 'Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.', 'Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.', 'Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.', 'Strong knowledge of how to compose and implement structural data models.', 'Experience molding fresh environments into efficient mature data platforms.', 'Experience with performance optimization for processing and storage via data partitioning and indexing techniques.', 'Ability to take a consultative approach to data strategy.', 'Ability to work in an Agile Scrum environment.', 'Ability to thrive in a fast-paced environment.', 'Ability to work remotely and manage your own time in an international team.', 'Exceptional written and verbal communication in English.', 'Best Startup Employers in 2020 | Forbes', 'Best Places to Work | HotelTechReport (2018, 2019, 2020)', 'Deloitte’s North America Technology Fast 500 (2019)', 'Inc. 500 Fastest Growing Companies (2018 & 2019)', 'Inc. Best Places to Work (2017 & 2018)', 'Best Places to Work | Inc Magazine (2017 & 2018)', 'Start-Ups to Watch in 2018 | Forbes', 'Connect MIP Award (Technology)']",2020-08-08 13:22:09
Data Engineer,Arrive,3.5 out of 5,"Chicago, IL","['Accountable for daily completion, accuracy and performance monitoring of all ETL and data warehousing tasks', 'Develop new ETL processes to ingest source data from our on-line transactional systems as well was 3rd party services', 'Maintain our CI/CD pipeline to ensure Business Analysts can build, test, deploy and iterate quickly', 'Maintain infrastructure in AWS and other 3rd party service to support all data team operations and company business intelligence as a whole', 'Manage and optimize Redshift clusters/data lake to ensure current health and performance and future scaling needs', 'Detect quality issues, track them to their root source, implement fixes and preventative audits', 'Become the “go to” expert of our data. Work closely with staff to understand all data from our core systems, partner services, and any other platforms we rely on', 'Experience with AWS; expertise in Redshift, Postgres or other RDBSs (preferably column-oriented)', 'Proficiency in SQL and ability to write and optimize complex queries', 'Experience with Docker, Elastic Container Service, Lambda a plus', 'DevOps and Linux systems administration fundamentals', 'Ability to write customized software in Python, Bash, Go or other common open source languages.', 'Experience with Airflow or similar scheduling service a plus', 'Experience with CI/CD tools like Jenkins or Drone', 'Creativity in approaching data organization challenges with an understanding of the end goal', 'A collaborative nature and entrepreneurial spirit. Prior startup experience a huge plus', 'A sense of ownership and accountability for your work and the success of the team']",2020-08-08 13:22:09
Machine Learning Engineer,Silverfin,N/A,Remote,"['You’re experienced in applying machine learning, from proof of concept to a production system. You’re able to both get your hands dirty building models, and integrating what you’ve built into a production system. While our core application is built in Ruby on Rails, it’s probably not well-suited for machine learning projects, and you can suggest a more applicable language based on the project. We’re guessing Python.', 'You’re up for mentoring coworkers and can give in-depth, productive feedback during reviews. While you appreciate the small stuff, you recognize bikeshedding and can avoid its pitfalls.', 'You’re able to take initiative and push projects forward without being micromanaged.', 'You can code with reason and can justify the important decisions you made during development.', 'You can communicate clearly in English, both written and verbally.', 'You recognize and can apply engineering best practices when relevant. This includes the usual like version control, testing, and refactoring; but you also appreciate hygienic code, good naming, explicitness and readability over cleverness, etc. You’re willing to be flexible and pick-up other practices that the team decides on but you might not agree with.', ""You're aware of the trade-offs involved in proper engineering and can make balanced business decisions, keeping in mind all the stakeholders of the project."", 'The opportunity to build unique projects based on a significant amount of data, on top of a solid product-oriented foundation', 'Actual, proper work-life balance', 'Choose your own working hours and work 100% remotely', 'Personal growth training and opportunities', 'The possibility to grow the team and become a teamlead', 'Join a distributed remote-first engineering team with 25 colleagues in 14 different countries', 'A refreshing work environment with professional, friendly and welcoming colleagues', 'A €1000 yearly budget for conferences, courses, workshops or other expenses that will improve your skills', 'You have successfully taken a significant machine learning project from concept to production', 'At least 2 years of full-time experience with machine learning projects', 'Your work hours have some overlap with EU business hours (we require your local timezone to be within CET +/- 3h)', 'Experience as a remote worker in a fully remote team', 'Experience in Fintech', 'Accounting knowledge', 'Read about how our regular development interviewing process looks like (the machine learning engineer job is a bit different, but this should give you some idea)', 'Or email us with any questions on engineering-recruitment@silverfin.com']",2020-08-08 13:22:09
Data Engineer,SmileDirectClub,2.9 out of 5,"Nashville, TN 37219","['Design and build new dimensional data models and schema designs to improve accessibility, efficiency, and quality of internal analytics data', 'Build, monitor, and maintain batch and streaming analytics data pipelines', 'Implement systems for tracking data quality and consistency', 'Work closely with Analytics, Marketing, Finance, Data Science and Operations teams to understand data and analysis requirements.', 'Work with teams to continue to evolve data models and data flows to enable analytics for decision making (e.g., improve instrumentation, optimize logging, etc).', 'Build and maintain serverless API’s', 'Enhance and maintain data platform SDK', 'Participate in code reviews', 'Pair program with team members', 'Partner with data scientists to put models into production.', 'Work with the latest technologies to deliver and process large datasets.', 'Has a curiosity about how things work', 'Experience with DataFrames', 'Has built large-scale data pipelines professionally and can craft clean and beautiful code in Java, Scala, Python and/or SQL', 'Has built batch data pipelines with Hadoop/Spark/Dask as well as with relational database engines, and understands their respective strengths and weaknesses', 'Has experience with cloud platforms, preferably Amazon Web Services', 'Experience with event streams, preferably Kafka', 'Has experience with ETL jobs, metrics, alerting, and/or logging', 'Can jump into situations with few guardrails and make things better', 'Possesses strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems, and information retrieval, object oriented programming.', 'Is a strong communicator. Explaining complex technical concepts to product managers, support, and other engineers is no problem for you', 'When things break, and they will, is eager and able to help fix them', 'Has experience with MPP data warehouses (Redshift, Snowflake, or similar)', 'Understands when and how to use a datalake and how to build them.', 'Ability to adapt in a fast paced and mentally stimulating environment.', 'Academic background in computer science or mathematics (BSc or MSc)', 'Experience building simple scripts and web applications using Python', 'A solid grasp of basic statistics (regression, hypothesis testing)', 'Experience in small start-up environments', 'What is SmileDirectClub? Link here.', 'What are our customers saying? Link here.', 'What is a SmileShop? Link here.', 'What is our culture like? Link here.', 'How do we celebrate your team members? Link here.']",2020-08-08 13:22:09
Data Scanners,"IPolarity, LLC",N/A,New York State,"[""Using ASG DI (Data Intelligence); While BeCubic and Rochade are not required here he basically said if they don't have it they better be good scanners. So find guys with it."", 'ASG Scanner tools', 'Strong analytical skills to identify breaks in lineage; understand logic']",2020-08-08 13:22:09
Tableau Data Visualization Engineer,BCC Software LLC,3.4 out of 5,"Rochester, NY 14623","['Create responsive dashboards, reports, and visualization in Tableau.', 'Design and develop performant and scalable Data Sources from SQL, Textual or NoSQL databases to power Tableau visualizations.', 'Be a key contributor in our efforts to position BI customer-facing solutions for growth.', 'Work in an agile team environment to deliver results on a consistent iterative basis.', 'Communicate and keep your team up to date in daily standup meetings, hallway conversations, online team chats, and via documenting your work.', 'Participate in planning and sizing activities.', 'Influence product direction by Review requirements & provide feedback to product owners.', 'Demonstrably experienced in any of the fields of Software Engineering/Architecture, Data Analytics, Big Data, or Database Development/Warehousing.', 'Highly skilled in developing Tableau visualizations.', 'Experienced in scaling Tableau server(s), understanding of its components as well as how to configure and tuning them to achieve optimally performing visualizations.', 'Highly technical with hands-on experience of working with MS SQL Server or like relational and/or non-relational databases; Working knowledge and experience with Microsoft C#/.Net framework is a definite plus.', 'Actively practiced software engineering agile methodology of consistently delivering results.']",2020-08-08 13:22:09
Big Data Engineer,Cognizant Technology Solutions,3.9 out of 5,"Richmond, VA 23173",[],2020-08-08 13:22:09
Data Engineer,"Lokavant, Inc.",N/A,"New York, NY","['Design, develop, and implement data infrastructure and pipelines that ingest and transform data from various external sources, storing it in highly optimized database systems, and making it useful to our application and reporting layers', 'Create automation systems and tools to configure, monitor, and orchestrate data infrastructure and pipelines', 'Create data integration services to help onboard new customers as quickly as possible', 'Maintain ongoing reliability, performance, and support of the data infrastructure, providing solutions based on application needs and anticipated growth', 'Participate in creating and maintaining strict compliance, data privacy and security measures', 'Develop robust and production-level code to implement new product features in collaboration with other engineers and subject matter experts', 'Identify and resolve performance and scalability issues, troubleshoot problems, and improve product quality', 'Collaborate with the Front-End Development team to thread the right information through to forward-facing applications', 'Interface with the Development Operations colleagues to evaluate and implement methodologies and workflows to facilitate the frequent and continuous release of high-quality software', 'Work closely with Data Science colleagues to implement descriptive and predictive algorithms and models using the latest technologies', 'Keep up to date on emerging technology solutions, particularly those on AWS, for continuous improvements in data engineering', 'Help recruit highly capable engineers to the team from diverse backgrounds', 'Mentor and be mentored by engineers of varied experience levels and subject matter areas', '3+ years relevant experience with data engineering', 'Strong proficiency with Python (ideally PySpark) and SQL', 'Experience with AWS S3, EC2, EMR, or an equivalent cloud-hosted infrastructure', 'Experience with cloud-hosted database/data warehouse architecture (e.g. Redshift, Snowflake, etc.)', 'Experience writing and productionizing complex data transformations in SQL and related frameworks', 'Interest in building distributed computing and orchestration frameworks (e.g. Spark, Kubernetes, Airflow, etc.)', 'Experience working in an Agile software development environment', 'Exceptional written and verbal communication skills', 'Strong attention to detail and highly organized, with effective multi-tasking and prioritization skills', 'Proactive, self-motivated and self-directed, with the ability to learn quickly and autonomously', 'Comfortable with ambiguity', 'Superior problem-solving and troubleshooting skills', 'Ability to work as part of a collaborative cross-functional team in a fast-paced environment', 'Sincere interest in working at a rapidly changing start-up and scaling with the company as we grow', 'Bachelor’s degree with strong academic performance in Computer Science, Software Engineering, Applied Science, or equivalent field', 'Experience building and deploying large-scale data processing pipelines', 'Experience integrating data from disparate data sources', 'Experience with continuous integration and automation tools and processes (e.g. Jenkins, Semaphore, etc.)', 'Experience with healthcare data, ideally clinical/operational clinical trial data', 'Knowledge of clinical data standards (e.g. CDISC, FHIR, HL7, etc.)', 'Knowledge of e-clinical systems and technologies (e.g. EDC, CTMS, IRT, etc.)', 'Competitive salary and equity compensation', 'Full medical, dental, and vision benefits', 'One Medical membership', '401(k) plan', 'Flexible PTO policy', 'Generous parental leave', 'Great NYC office located in the heart of Times Square', 'Team events and outings']",2020-08-08 13:22:52
HADOOP DATA ENGINEER,Emids Technologies Pvt. Ltd.,3.9 out of 5,"Hartford, CT","['Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.', 'Collaborates with other data teams to transform data and integrate algorithms and models into automated processes.', 'Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines.', 'Builds data marts and data models to support Data Science and other internal customers.', 'Analyzes current information technology environments to identify and assess critical capabilities and recommend solutions.', 'Experiments with available tools and advises on new tools in order to determine optimal solution given the requirements dictated by the model/use cases', '3 or more years of progressively complex related experience.', 'Has strong knowledge of large scale search applications and building high volume data pipelines.', 'Experience building data transformation and processing solutions.', 'Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.', 'Ability to understand complex systems and solve challenging analytical problems.', 'Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.', 'Strong collaboration and communication skills within and across teams.', 'Strong problem solving skills and critical thinking ability.', 'Hive', 'Shell Script', 'Unix', 'Hadoop Concepts (Sqoop, YARN, MapReduce ,etc.)', 'Python']",2020-08-08 13:22:52
Data Scientist,Infotree Global,N/A,"Creve Coeur, MO","['Design, implement and optimize algorithms for unsupervised and supervised learning based on structured and unstructured data.', 'Develop powerful business insights from social, marketing, industrial data and public policy using advanced machine learning techniques.', 'Work closely with the software engineering team to productize analytic software.', 'Collaborate with system integration and data warehouse engineers on data extraction and data cleaning.', 'Work in a highly interactive, team-oriented environment.', ""Requires a bachelor's degree in a STEM or related field and 5 years of experience, or a Master's degree in same with 3 years, or a PhD."", 'Temporarily due to COVID-19']",2020-08-08 13:22:52
Data Engineer - Reports,Illumination Works,2.5 out of 5,"Mason, OH 45040","['SQL', 'Data Analysis', 'SSRS', 'DataStage']",2020-08-08 13:22:52
Data Engineer,SpringML,N/A,"Herndon, VA","['Ability to work as a member of a team assigned to design and implement data integration solutions.', 'Build Data pipelines using standard frameworks in Hadoop, Apache Beam and other open source solutions.', 'Learn quickly – ability to understand and rapidly comprehend new areas – functional and technical – and apply detailed and critical thinking to customer solutions.', 'Propose design solutions and recommend best practices for large scale data analysis', 'B.S. or equivalent degree in computer science, mathematics or other relevant fields.', '5-10 years of experience in ETL, Datawarehouse, Visualization and building data pipelines.', 'Strong Programming skills – experience and expertise in one of the following: Java, Python, Scala, C.', 'Proficient in big data/distributed computing frameworks such as Apache Spark, Kafka,', 'Experience with Agile implementation methodologies.']",2020-08-08 13:22:52
"Data Engineer, Data Warehouse",Lighthouse,3.7 out of 5,Remote,"['Build and operate stable, scalable and highly performant data pipelines that cleanse, structure and integrate disparate big data sets into a readable and accessible format for end user analyses.', 'Construct, maintain and optimize data-marts and the Enterprise Data Warehouse to support reporting, analytics and business intelligence.', 'Collaborate with senior management, product development, finance, IT and other stakeholders in the development of optimal data products.', 'Develop tools to monitor, debug, and analyze data pipelines.', 'Design and implement data schemas and models that can scale.', 'Provide technical recommendations regarding buy vs. build decisions for different components of the data analytics infrastructure.', 'Define the simple and complex ETL processes for the EDW.', 'Write SQL queries to extract data and perform complex analytics.', 'Work with internal business customers to define and deliver effective data visualizations and scalable reporting solutions.', 'Serve as owner of the quality of the data as well as how the data is used and leveraged by the business.', 'Have a hands-on approach in bringing data insights to tackle business challenges.', 'Help drive cross-functional projects around enterprise data and analytics solutions.', ""Bachelor's Degree in Computer Science, Data Engineering, Data Analytics, Information Systems, Mathematics or equivalent."", '5+ years of relevant experience in data warehousing, data engineering, data analysis, business intelligence or similar roles.', 'Proficiency in one or more scripting languages.', 'Experience with compliance and certifications relevant to IT operations – ISO 27001, SOC 2 type 2, Sox, PCI, HIPAA', 'Experience with modern data warehouse platforms is a must. Proven track record of implementing data warehouse solutions for large companies. Experience with large scale and/or high performance database systems in an operational environment.', 'Knowledge of principles and practices of enterprise data warehouse development, data modeling, data governance.', 'Experience with data visualization and dashboarding tools such as Power BI, Tableau, etc.', 'Proficiency in normalized and de-normalized data models, data schemas, analytic cubes, etc.', 'Able to thrive in a fast-paced environment and manage competing priorities effectively.', 'Expert analytical and problem solving skills. Extreme attention to detail.', 'Excellent verbal and written communication skills.', 'Experience with ServiceNow, Salesforce.com, QuickBase, Microsoft Dynamics, Adaptive Insights and/or web development is a plus.', 'Experience in e-discovery industry or a service-based businesses is a plus.']",2020-08-08 13:22:52
Machine Learning Engineer,Proxet,N/A,"Boston, MA","['Good compensation package', 'Insurance Coverage', 'Fully remote flexible hours (voice/video conferences are taking place 2-3 times a week)', 'Courses and professional certifications allowance', 'Personal and professional growth', 'Dental Insurance', 'Health Insurance', 'Professional Development Assistance', 'Referral Program', 'Tuition Reimbursement', 'Monday to Friday', 'Machine Learning: 1 year (Preferred)', 'Fully Remote', 'A job for which people with disabilities are encouraged to apply', 'www.proxet.com', 'Only full-time employees eligible']",2020-08-08 13:22:52
Data Scientist,UNITED PARCEL SERVICE,3.8 out of 5,"Alpharetta, GA","['Job', 'Company', 'Provides expertise on computational, quantitative, and algorithmic techniques applicable to data science', 'Performs data wrangling, ETL, and data exploration tasks', 'Builds predictive and prescriptive models, algorithms, and simulations', 'Collaborates with cross-functional teams of data scientists, data engineers, application developers, etc. to deliver measurable outcomes', 'Identifies and champions new initiatives aimed at delivering value to business stakeholders', 'Manages multiple work streams while proactively responding to competing demands', 'Evaluates open-source and vendor-based tools, such as applications, platforms, frameworks and programming languages', ""Master's degree in a quantitative or computational field such as statistics, operations research, computer science, physics, engineering, mathematics, economics, or related discipline"", '2+ years of industry experience in a technical role, preferably in a data science capacity', 'Intermediate knowledge of R or Python', 'Some knowledge of the following: Generalized Linear and Non-Linear Models, Time Series Analysis, Random Forest, Gradient Boosted Machines, Neural Networks, Unsupervised Methods (Dimensionality Reduction, Clustering, etc.)', 'Experience querying relational data systems for ETL and data integration tasks', 'Good communications skills with ability to present to technical and business audiences', 'Experience using Spark/Hadoop systems for distributed analytics and data processing', 'PHD degree', 'Knowledge of any of the following: Natural Language Processing & Text Mining, Experimental Design, Computer Vision & Image Processing, Bayesian Networks, Reinforcement Learning, Collaborative Filtering, Network/Graph Mining, Combinatorial Optimization, Linear & Mixed-Integer Programming, Discrete-Event & Stochastic Simulation', 'Knowledge of: H2O.ai, TensorFlow, SAS', 'Familiarity with scaling and operationalizing data science models in production settings', 'Experience working in a cloud-computing environment such as AWS, Azure, GCP, etc', 'Prior exposure to the transportation or logistics industry']",2020-08-08 13:22:52
Data Engineer,Onebridge,N/A,"Indianapolis, IN 46256",[],2020-08-08 13:22:52
Software Engineer - Data - New York,Uber,3.7 out of 5,"New York, NY 10018","['Own data expertise and data quality for the pipelines', 'Create and launch new data models that provide intuitive analytics to your customers', 'Design, develop and launch extremely efficient & reliable data pipelines to move data', 'Design and develop new systems and tools to enable folks to consume and understand data faster', '2+ years of full-time engineering experience', 'General coding chops with Java, Python or Scala', 'Proficiency in Spark/MapReduce development and expertise with data processing (ETL) technologies', 'Knowledge of Hadoop related techologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig', 'Knowledge of SQL', 'Experience with large-scale data warehousing architecture and data modeling', 'BS/MS/PhD in Computer Science or a related field']",2020-08-08 13:22:52
"Strategic Customer Engagements, Data Engineer - Pricing Analytics","Amazon Web Services, Inc.",3.6 out of 5,"Seattle, WA","['Job', 'Company', 'Bachelor’s degree in Computer Science, MIS, related technical field, or equivalent work experience.', ""More than 5 or more years' of overall work experience in a related field, including 3 or more years analytics, data engineering or related field"", 'Proven experience in data modeling, ETL development, and data warehousing, or similar skills', 'Demonstrable skills and experience using SQL with large data sets (e.g. Oracle, SQL Server, Redshift)', 'Experience with AWS technologies including Redshift, RDS, S3', 'Proven track record of successful communication of data infrastructure, data models, and data engineering solutions through written communication, including an ability to effectively communicate with both business and technical teams', 'Design, implement, and support an analytical data infrastructure providing ad hoc access to large datasets and computing power', 'Managing AWS resources including EC2, RDS, Redshift, et cetera', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies', 'Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency', 'Collaborate with Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative field', 'Both technically deep and business savvy enough to interface with all levels and disciplines within the organization', 'Demonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, finance, and operations', 'Knowledge of Advanced SQL and scripting for automation (e.g. Python, Perl or Ruby)', 'Experience with AWS technologies including EMR, Kinesis', 'Experience with reporting tools like Tableau, Excel or other BI packages', 'Familiarity with statistical models and data mining algorithms', 'Familiarity with Linux', 'Experience with Hadoop or other map/reduce ""big data"" systems and services']",2020-08-08 13:22:52
Data Engineer,Unity Technologies,4 out of 5,"Framingham, MA","['Participate in designing and maintaining data pools', 'Develop new products and services using the data we collect', 'Ensure consistency and accuracy of data aggregation', 'Work with multiple engineering and business groups on data collection practices and data analysis needs', 'Proven experience in building stable and scalable production services', 'Working knowledge of noSQL data stores and related querying languages, such as lucene, elasticsearch or mongodb, or time series data stores', 'Working knowledge of regular expressions', 'Working knowledge of SQL', 'Efficient communication skills in translating graphs and tables to stories', 'Experience in game development or social / communication services', 'Working experience in one or more of the following:: Python, C/C++, Erlang, Golang', 'Working experience in one or more of the following: ELK stack, TICK stack, BigQuery and related cloud data storage', 'A drive for data integrity and looking for patterns and trends in data', 'An ability to accept confirmed data as it is, and to learn what it may be trying to tell us']",2020-08-08 13:22:52
Data Engineer,Matouk,N/A,"Fall River, MA 02720","['Using the enterprise ETL tool, create modify, and improve integration pipelines', 'Translate business requirements into data warehouse pipelines using ETL/ELT methodologies', 'Staging Data Views with optimized SQL queries per Business Unit specifications to be used/ingested with BI tools such as Tableau, Google Data Studio, PowerBI or SSRS', 'Working with Business leaders to develop reports and dashboards', 'Extract and load many disparate systems into a centralized data warehouse', 'Assist in gathering requirements for new pipelines', 'Connecting/Integrating to new data sources through various methods (API, FTP, WebService, etc)', 'Migrating legacy data/BI processes to new cloud-based infrastructure', 'Documentation and Data Auditing', 'Implement data auditing strategies and processes to ensure data integrity', 'Have a point of view around new and emerging technology such as AI & Machine Learning and how it can be used to enhance the company’s BI/Data strategy', 'Perform data modeling to document existing and new tables in the data warehouse', 'Monitor and troubleshoot data problems', 'Identify ways to improve existing processes', 'Handle multiple projects and meet deadlines', ""Bachelor's Degree in Computer Science, Information Systems, or related field."", '3-5 years of experience working with data using SQL or similar technology. Strong understanding of SQL queries/optimization required', '3+ years of experience using a data integration platform, such as Jitterbit, SSIS, or FiveTran', 'Familiarity with OLAP CUBE / SSAS technology and SSRS a strong plus.', 'Familiarity with Cloud warehouse technologies a strong plus (Azure Synapse, Azure SQL, Google Cloud Platform, AWS, Snowflake)', 'Strong understanding of data warehousing principles and methodologies', 'Ability to manage multiple projects in a fast-paced environment', 'Strong communication skills to all levels of technical expertise', 'Very high attention to detail', 'Familiarity with BI Visualization tools', 'Sitting for extended periods of time', 'Dexterity of hands and fingers to operate a computer keyboard', 'Salesforce, Jitterbit, SSIS, SSRS, SSAS, SQL Server, PostgreSQL']",2020-08-08 13:22:52
Big Data Engineer,Rackspace,3.8 out of 5,"Denver, CO","['Build complex ETL code', 'Build complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL', 'Work on Data and Analytics Tools in the Cloud', 'Develop code using Python, Scala, R languages', 'Work with technologies such as Spark, Hadoop, Kafka, etc.', 'Build complex Data Engineering workflows', 'Create complex data solutions and build data pipelines', 'Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates', 'Capture and share industry best practices amongst the community', 'Attend and present valuable information at Industry Events', 'Traveling up to 50% of the time', '3+ years design & implementation experience with distributed applications', '2+ years of experience in database architectures and data pipeline development', 'Demonstrated knowledge of software development tools and methodologies', 'Presentation skills with a high degree of comfort speaking with executives, IT management, and developers', 'Excellent communication skills with an ability to right level conversations', 'Technical degree required; Computer Science or Math background desired', 'Demonstrated ability to adapt to new technologies and learn quickly']",2020-08-08 13:22:52
Software Engineer (ETL/Data),Rx Savings Solutions,N/A,"Overland Park, KS 66210","['Bachelor’s degree or greater in Computer Science or related experience', 'Strong analytical skills and attention to detail.', 'Ability to communicate with stakeholders of different backgrounds and skill levels.', 'Understanding of BI concepts and be familiar with relational or multi-dimensional modeling.', 'Demonstrated one or more of the four development areas of Data Management: Integration, Modeling, Analytics, Reporting.', 'Hands-on experience in SQL queries.', 'Highly-motivated, self-directed and flexible.', 'Investigate and resolve data related issues and provide support and troubleshooting expertise.', 'A great attitude with a passion for supporting your team and offering creative solutions.', 'Willingness and enthusiasm to learn new skills and techniques.', '0 - 2 years of work experience in Data.', 'Good understanding/experience in ETL Tools (Talend is a plus).', 'Understanding of RDBMS best practices.', 'Familiarity with Agile and Scrum methodologies.', 'Knowledge of Java or JavaScript.']",2020-08-08 13:22:52
Data Engineer,Tabula Rasa Health Care,N/A,"Quincy, MA","['Participate in use case feasibility discussions and translate business idea / business problems into analytics use case.', 'Develop and maintain complex ETL processes and algorithms', 'Build sophisticated predictive / prescriptive models to generate insights about customers products, sales, and operations for specific use cases.', 'Support internal teams with data requests and BI Tool enhancements', 'Be able to work well with people of various backgrounds and education levels and establish cooperative working relationships with all coworkers.', 'Timely and effectively communicate information to and consult with others in order to complete work assignments.', 'Act in a responsible, trustworthy and ethical manner that considers the impact and consequences of one’s actions or decisions.', 'Communicate ideas, thoughts, and facts in writing through the use of proper grammar, spelling, document formatting and sentence structure.', 'Identify and respond to current and future clients’ needs; provide excellent client service.', 'Evaluate and analyze problems or tasks from multiple perspectives; adaptively employ problem solving methods to find creative or novel solutions; use logical, systematic and sequential processes to solve problems.', 'Complete assigned job tasks in an accurate and timely manner.', 'Carefully prepare for meetings and presentations; follow up with others to ensure that agreements, tasks or commitments have been fulfilled.', 'Demonstrate commitment to achieving Company’s core business objectives of increasing the role of pharmacy', 'Experience working with healthcare professionals in a clinical setting.', 'Experience resolving issues that do not have clear answers.', 'Highly motivated and possessed excellent interpersonal, problem solving, and technical skills.', 'High sense of urgency and accountability', 'Adaptable, friendly, and ability to work with a team.', 'Excellent attendance', 'Passion for data and digging into the minutia of datasets.', 'Take calculated risks based on data-driven analytics', 'Be a self-starter', 'Enjoy working in a fast-paced environment.', 'Bachelor’s degree in Business, Computer Science, Information Systems or equivalent combination of education and experience.', 'Experience working with healthcare professionals in a clinical setting', '4+ years of data analysis experience', 'Expertise in algorithm design, machine learning, and applied statistics', 'Proven track record in use of SQL specifically in Oracle and working with data including extracting information, validating data, creating and maintaining custom data structures.', 'Work in Company’s office located in Boston, Massachusetts.', 'Must work in office: Monday – Friday.', 'Travel to remote offices and educational events may be required.', 'Collaboration across remote sites within the company', 'A welcoming and inclusive environment', 'Professional development opportunities', 'Generous health, dental, and vision coverage', 'Competitive salary with employee stock option plan', '401K']",2020-08-08 13:23:36
Data Engineer - Azure Data Factory,Datasys America,N/A,"Houston, TX","['Monday to Friday', 'Azure: 4 years (Preferred)']",2020-08-08 13:23:36
Big Data Software Engineer,HP,4 out of 5,"Corvallis, OR 97330","['Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data pipelines, repositories or models for structured/unstructured data.', 'Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution.', 'Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture.', 'Leads a project team of other data engineers to develop reliable, cost effective and high-quality solutions for assigned data system, model, or component.', 'Collaborates and communicates with project team regarding project progress and issue resolution.', 'Represents the data engineering team for all phases of larger and more-complex development projects.', 'Provides guidance and mentoring to less experienced staff members.', 'Using data engineering tools, languages, frameworks to mine, cleanse and explore data.', 'Fluent in NoSQL & relational based systems.', 'Fluent in complex, distributed and massively parallel systems.', 'Strong analytical and problem-solving skills with ability to represent complex algorithms in software.', 'Designing data systems/solutions to manage complex data.', 'Strong understanding of database technologies and management systems.', 'Strong understanding of cloud-based systems/services.', 'Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools.', 'Excellent written and verbal communication skills; mastery in English and local language.', 'Ability to effectively communicate product architectures, design proposals and negotiate options at management levels.', 'Collaborates with peers, junior engineers, data scientists and project team.', 'Typically interacts with high-level Individual Contributors, Managers and Program Teams.', 'Leads a project requiring data engineering solutions development.', ""Bachelor's or Master's degree in Computer Science, Information Systems, Engineering or equivalent."", 'Typically 4-6 years’ experience.']",2020-08-08 13:23:36
Senior Software Engineer - Data Engineering,realtor.com,3.5 out of 5,"Morgantown, WV","['Job', 'Company', 'Work collaboratively in teams composed of Product Managers, Designers, and Engineers', 'Implement new application features that delight our users', 'Develop reusable components and frameworks for ingestion, cleansing, and data quality', 'Develop and operationalize data pipelines, backend services and distributed systems using advanced data architectures deployed on Amazon Web Services', 'Optimize our developer toolchain to support instant provisioning of new services and infrastructure, fully automate deployment, and minimize development friction.', 'Own our processed data and act as support for production issues, profile data, and assist in root cause analysis.', 'Actively seek out new technologies, evaluate them and make recommendations to integrate them in our solutions and products', 'Work in a product development process that is primarily Agile/Scrum', 'A driven software engineer that is motivated to build great products and a great codebase in a fast-paced environment', '5+ years experience building data pipelines and platforms', 'Proficient in Python, experience with other object oriented programming language (e.g. Ruby, Go, Java, Node.js, Dart) and the eagerness to learn more', 'Exposure to cloud-based architectures, development, and deployment', 'Exposure to build, test and deployment automation technologies', 'Familiarity with cloud technologies such as AWS ECS, S3, RDS, EMR, Redshift, Glue, Athena', 'Familiarity with technologies in the data engineering ecosystem tooling including EMR/Hadoop, Spark/PySpark, Kafka/Kinesis/Flume, and Airflow/luigi/AWS Data Pipeline.', 'Exposure to monitoring for SLAs, alerting, and remediating service disruptions', 'Understanding of computer science fundamentals, schema design, and best practices', ""Bachelor's degree in Computer Science/Engineering or related field, Master's degree a plus""]",2020-08-08 13:23:36
Data Engineer,HTI Labs,N/A,"Omaha, NE 68102","['Collaborate with team members to plan, prototype, and build data pipelines', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Enhance data collection procedures to include information that is relevant for building analytic systems', 'Optimize data storage practices according to user requirements', 'Programming experience in Python and Node', 'Experience working with large quantities of data', 'Experience with AWS cloud services', 'Knowledge in data modeling, data access, and data storage techniques for big data platforms', 'Experience with Docker/Kubernetes']",2020-08-08 13:23:36
Systems Administrator (Data Integration Engineer),Apex Clean Energy,3.3 out of 5,"Charlottesville, VA 22902","['Build and maintain the ETL processes', 'Develop ETL packages, ensuring that best practices are implemented for data governance, data quality, data cleansing.', 'Development of scalable and robust ETL routines, using ETL tools and external programming and/or scripting languages as necessary.', 'Manage the day-to-day support and maintenance of the data warehouse environment, reports, data integration jobs and job schedules.', 'Collaborate with stakeholders to define business logic for source-to-target mappings and integration workflows.', 'Assisting in production support by resolving source data issues and refining transformation rules when needed.', 'Maintain the existing data warehouses and facilitate aggregation, slicing and dicing of data using dbt.', 'Design and develop data extraction SQL queries that are highly optimized for very large data sets.', 'Creating and maintaining the company data dictionary as well as technical documentation for source-to-target mapping.', 'Follow current trends, their impact on business strategies, and their implications for creating sustainable data warehouse architecture.', ""Analyze the needs and the environment to make sure the solution you're developing considers the current architecture and operating environment as well as future functionality and enhancements."", 'Work closely and collaborate with various cross functional teams to identify, troubleshoot and fix data issues, and resolve data gaps that impact the fulfillment of the business’s functional requirements.', 'Work collaboratively with team members and customers to gather and validate requirements as well as deliver features/enhancements.', 'Collaborate with architects, team leads and team members to architect and design solutions to meet functional and technical requirements.', 'Troubleshoot issues, identify resolutions.', 'Responsible for writing complex SQL queries for mining of operational data.', 'At least two years of experience with complex/large data management and systems integration.', 'Familiar with ETL tools for database / warehouse development. Experience with Azure, preferred.', 'Experience developing ETL packages, ensuring that best practices are implemented for data governance, data quality, data cleansing.', 'Experience in all aspects of project development life cycle such as identifying requirements, design, feasibility analysis, allocating timelines, task prioritization, development, performance, best practices and testing.', 'Hands-on experience performing data modeling and warehousing in a cloud-based data-warehousing system (Snowflake)', 'Experience in day-to-day support and maintenance of the data warehouse environment, reports, data integration jobs and job schedules.', 'Experience performing analysis and reporting from the data warehouse, ideally using PowerBI.', 'Experience setting up data access and visualization tools and systems for non-technical users.', 'Working knowledge of Python and/or SQL.', 'Prior experience with renewable energy and/or SCADA a plus.', 'Experience working in a rapidly evolving environment, adapting quickly to new information and re-prioritizing as needed.', 'Demonstrated interest/passion for renewable energy required.', 'Health Insurance', 'Dental Insurance', 'Vision Insurance', '401(k) Employer Match', '401(k) Pre-tax or Roth Deferrals', 'Health Savings Accounts', 'Flexible Spending Arrangements', 'Short-term Disability Insurance', 'Long-term Disability Insurance', 'Group Term Life Insurance', 'Voluntary Additional Term Life Insurance', 'Paid Time Off (PTO)', 'Holidays', 'Volunteer Time Off', 'Progressive Parental Leave Plan', 'Milk Stork Travel Solution', 'Professional Development Opportunities', 'Employee Referral Program', 'ACAC Fitness and Wellness Center - Corporate Discount', 'Company Paid Cell Phone', 'Company Paid Parking', 'United Van Lines - Relocation Discounts']",2020-08-08 13:23:36
"Data Engineer, Data Warehouse",Lighthouse,3.7 out of 5,Remote,"['Build and operate stable, scalable and highly performant data pipelines that cleanse, structure and integrate disparate big data sets into a readable and accessible format for end user analyses.', 'Construct, maintain and optimize data-marts and the Enterprise Data Warehouse to support reporting, analytics and business intelligence.', 'Collaborate with senior management, product development, finance, IT and other stakeholders in the development of optimal data products.', 'Develop tools to monitor, debug, and analyze data pipelines.', 'Design and implement data schemas and models that can scale.', 'Provide technical recommendations regarding buy vs. build decisions for different components of the data analytics infrastructure.', 'Define the simple and complex ETL processes for the EDW.', 'Write SQL queries to extract data and perform complex analytics.', 'Work with internal business customers to define and deliver effective data visualizations and scalable reporting solutions.', 'Serve as owner of the quality of the data as well as how the data is used and leveraged by the business.', 'Have a hands-on approach in bringing data insights to tackle business challenges.', 'Help drive cross-functional projects around enterprise data and analytics solutions.', ""Bachelor's Degree in Computer Science, Data Engineering, Data Analytics, Information Systems, Mathematics or equivalent."", '5+ years of relevant experience in data warehousing, data engineering, data analysis, business intelligence or similar roles.', 'Proficiency in one or more scripting languages.', 'Experience with compliance and certifications relevant to IT operations – ISO 27001, SOC 2 type 2, Sox, PCI, HIPAA', 'Experience with modern data warehouse platforms is a must. Proven track record of implementing data warehouse solutions for large companies. Experience with large scale and/or high performance database systems in an operational environment.', 'Knowledge of principles and practices of enterprise data warehouse development, data modeling, data governance.', 'Experience with data visualization and dashboarding tools such as Power BI, Tableau, etc.', 'Proficiency in normalized and de-normalized data models, data schemas, analytic cubes, etc.', 'Able to thrive in a fast-paced environment and manage competing priorities effectively.', 'Expert analytical and problem solving skills. Extreme attention to detail.', 'Excellent verbal and written communication skills.', 'Experience with ServiceNow, Salesforce.com, QuickBase, Microsoft Dynamics, Adaptive Insights and/or web development is a plus.', 'Experience in e-discovery industry or a service-based businesses is a plus.']",2020-08-08 13:23:36
Critical Facility Engineer,Facebook,4.2 out of 5,"Henrico County, VA","['Perform all maintenance to ensure the highest level of efficiency without disruption to the business', 'Accurate and timely completion of work order requests', 'Maintain a positive and professional working relationship with internal clients', 'Respond to facility emergencies', 'Perform routine maintenance tasks in accordance with Facebook Safety Policy and Procedures', 'Regularly inspect buildings, grounds and equipment for unsafe or malfunctioning conditions', 'Troubleshoot, evaluate and recommend system upgrades', 'Order parts and supplies for maintenance and repairs', 'Solicit proposals for outsourced work', 'Work with vendors and contractors to ensure their work meets Facebook standards', 'Escalate issues to facility management as needed', 'Ability to work night shift', 'High school diploma or equivalent (i.e. GED)', '5+ years experience in electrical, HVAC, mechanical, controls, or other technical maintenance field', ""Associate's degree in engineering plus 3+ years experience or Bachelor's degree in related field plus 2+ years experience in electrical, HVAC, mechanical, or controls will be considered in lieu of 5+ years experience"", 'Knowledge of Microsoft Office Suite - Word, Excel and Outlook', 'Experience interpreting blueprints/CAD drawings', 'Regularly walk job site areas of flat and uneven terrain', 'Work at varying heights and from ladders', 'Use hands and fingers', 'Reach/push/pull with hands/arms/shoulders', 'Stoop, kneel, crouch and crawl', 'May lift and/or otherwise move 45 pounds or more']",2020-08-08 13:23:36
Data Analytics Engineer,Refinitiv,3.6 out of 5,"Brookfield, WI 53005","['Job', 'Company', 'Design, develop, implement and support complex solutions using SAS, Domo and Power BI', 'Assist users during requirements gathering, design, testing, and implementation phases', 'Build, manipulate, analyze and verify large and sophisticated datasets', 'Craft reports and visualizations to present the data in ways that are significant, impactful, and understandable', 'Lead output review sessions with internal and external partners in a clear and effective manner', 'Clearly document data workflows and solution runbooks for end users and support teams', 'Support other team member’s growth through information sharing and cross-training', 'Seeks opportunities to expand technical knowledge and explore new methods to tackle problems', 'BS or MS Degree in Computer Science, Mathematics, Statistics, or a related technical field, or equivalent experience', 'Detail oriented with strong analytical and problem-solving skills', '4+ years of development using ETL (Extract, Transform, Load) software, preferably with SAS or Domo', '4+ years using reporting and data visualization tools such as SAS, Domo, Power BI, or Tableau', 'Hands-on working knowledge and experience with SQL and relational databases', 'Practical experience establishing and utilizing data analytics standard methodologies', 'Experience with transactional data processing, ETL, data warehouse, data mart, and operational reporting solutions is preferred', 'Familiarity with BMC’s Control-M and/or Remedy, JIRA, or Salesforce Service model is a plus', 'Exceptional teammate who establishes positive working relationships', 'Proven leadership skills', 'Good communication skills with the ability to express sophisticated concepts effectively', 'Demonstrated ability to multi-task in a dynamic environment']",2020-08-08 13:23:36
Data Analyst,Gainful Health,N/A,"New York, NY","['Working with the CTO and COO to discover insights in the data.', 'Plan ways to test and measure the insights from above.', 'Provide suggestions for how to meet our customers needs, keeping in mind business constraints.', 'Support backend and frontend engineers in their data needs', 'Support growth marketing team to help efficiently test and evaluate different initiatives', 'Be an owner of the Looker platform in order to allow other team members to access the data they need', ""Bachelor's Degree or equivalent"", 'Basic understanding of SQL', 'Expert in Excel or another data analysis tool', 'Relentless attitude toward continuous improvement', 'Interest or experience in nutrition, wellness, or food/bev', 'Desire to work on a small team and self-starter to quickly iterate on initiatives', 'Experience in data science tools such as pandas (Python library)', 'Background in financial and/or subscription modeling', 'Gainful will cover 99% of the monthly cost of the Gold plan, or 85% of Platinum', 'If you opt out of group healthcare coverage, Gainful will add $250/month to your salary as a wellness stipend', 'Dental: Guardian EM Dental 10', 'Vision: CA Beam VSP Choice Plan 2', 'Health FSA', 'Dependent Care FSA', 'Commuter', 'Lunch every other Friday', 'Free snacks/beverages of every kind', 'Unlimited Gainful product & swag', 'Macbook Pro and whatever tools you need to do your job']",2020-08-08 13:23:36
Data Engineer II,Spring Venture Group,3.6 out of 5,"Kansas City, MO 64105","['Job', 'Company', ""Bachelor's degree in Computer Science or related technical field, or equivalent practical experience"", '2+ years of Data Engineering experience', 'Experience with the Python language; it’s design, base libraries, built-in features, and how it compares to other languages', 'Exposure to Python data engineering libraries, including pandas and pyspark', 'Experience with SQL and data warehouse tools such as AWS Athena', 'Experience with batch processing tools such as AWS Batch or AWS Glue, or other DAG systems', 'Real-time processing tools such as AWS Kinesis and AWS Firehose', 'Intermediate data modeling and architecture design']",2020-08-08 13:23:36
Sr. Data Engineer,Hasbro,4.2 out of 5,"East Providence, RI","['Write routines and build data pipelines to ingest, clean, and prepare data for analysis. Develop views and aggregated datasets that can be easily loaded into analytical tools.', 'Conduct analysis. Using descriptive and exploratory techniques, text analytics, and statistical methods to help answer business questions. Prepare and communicate results to other members of the Advanced Analytics team and to business partners.', 'Expand Hasbro’s data model by incorporating internal Hasbro and external third-party data. Identify data sources and catalog metadata.', 'Provide guidance on appropriate infrastructure and understand how business requirements map onto infrastructure needs and toolset.', 'Support architecture plan to accommodate existing and future datasets. Create business processes for on-boarding new data sources.', '5+ years of experience in Data Engineering, Analytics, Consulting, or a related data/quantitative field.', 'B.S. in a quantitative field (Computer Science, Engineering, Economics). Advanced degree/MS preferred.', 'Hands-on experience with ""big data"" platforms including Hadoop and Spark as well as experience with traditional RDBMS (SQLServer, Oracle).', 'Proficiency with Python, Pyspark, shell scripting, SQL and Hive.', 'Experience with cloud-based data tools and platforms (Azure preferred, Google or AWS are fine).', 'Knowledge of reporting and visualization tools (Tableau, Power BI, Spotfire).', 'Ability to design and build a framework to orchestrate data pipelines.', 'Familiarity with data modeling and data architecture concepts.', 'Project management capabilities, able to take initiative, coordinate and prioritize multiple projects and shifting priorities.', 'Experience in Business Analysis, Business Knowledge, Software Engineering, Data Management and Technical Solution Design.']",2020-08-08 13:23:36
Sr. Big Data Engineer (Flexible Location),"Pixalate, Inc.",N/A,Remote,"['http://pixalate.com/press', 'Harvard Business Review', 'Buzz Feed', 'Forbes', 'NBC News', 'CNBC', 'Business Insider', 'AdAge', 'AdAge', 'CSO Online', 'Mediapost', 'Mediapost', 'The Drum', 'Mediapost', 'Mediapost', 'We believe in Small teams that produce high output', 'Slack is a way of life, short emails are encouraged', 'Fearless attitude holds high esteem', 'Bold ideas are worshipped', 'Chess players do really well', 'Titles don’t mean much, you attain respect by producing results', 'Everyone’s a data addict and an analytical thinker (you won’t survive if you run away from details)', 'Collaboration, collaboration, collaboration', 'Support existing processes running in production', 'Design, develop, and support of various big data solutions at scale (hundreds of Billions of transactions a day)', 'Find smart, fault tolerant, self-healing, cost efficient solutions to extremely hard data problems', 'Take ownership of the various big data solutions, troubleshoot issues, and provide production support', 'Conduct research on new technologies that can improve current processes', 'Contribute to publications of case studies and white papers delivering cutting edge research in the ad fraud, security and measurement space', 'Bachelors, Masters or Phd in Computer Science, Computer Engineering, Software Engineering, or other related technical field.', 'A minimum of 3 years of experience in a software or data engineering role', 'Excellent teamwork and communication skills', 'Extremely analytical, critical thinking, and problem solving abilities', 'Proficiency in Java', 'Very strong knowledge of SQL and ability to implement advanced queries to extract information from very large datasets', 'Experience in working with very large datasets using big data technologies such as Spark, BigQuery, Hive, Hadoop, Redshift, etc', 'Ability to design, develop and deploy end-to-end data pipelines that meet business requirements.', 'Strong experience in AWS and Google Cloud platforms is a big plus', 'Deep understanding of computer science concepts such as data structures, algorithms, and algorithmic complexity', 'Deep understanding of statistics and machine learning algorithms foundations is a huge plus', 'Experience with Machine Learning big data technologies such as R, Spark ML, H2O, Mahout etc is a plus', 'Experienced leadership and founding team', 'Casual environment', 'Flexible hours', 'High performing team who wants to win and have fun doing it', 'Extremely Competitive Compensation', 'OPPORTUNITY (Pixalate will be what you make it)']",2020-08-08 13:23:36
"Software Engineer, Data",Fathom Health,N/A,Remote,"['Develop data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs', 'Build performant and expressive interfaces to the data', 'Build infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning', '3+ years of development experience in a company/production setting', 'Experience building data pipelines from disparate sources', 'Hands-on experience building and scaling up compute clusters', 'Excitement about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration', 'A solid understanding of databases and large-scale data processing frameworks like Hadoop or Spark. You’ve not only worked with a variety of technologies, but know how to pick the right tool for the job', 'A unique combination of creative and analytic skills capable of designing a system capable of pulling together, training, and testing dozens of data sources under a unified ontology', 'Developing systems to do or support machine learning, including experience working with NLP toolkits like Stanford CoreNLP, OpenNLP, and/or Python’s NLTK', 'Expertise with wrangling healthcare data and/or HIPAA', 'Experience with managing large-scale data labelling and acquisition, through tools such as through Amazon Turk or DeepDive']",2020-08-08 13:23:36
Enterprise Data- Solutions Engineer,Bloomberg,3.9 out of 5,"New York, NY","[""Work closely with technical and market data contacts at client firms to understand their requirements and help them to build out solutions using Bloomberg's Enterprise Data Technology such as BLAPI & HAPI."", 'Collaborate with peers, sales, technical account managers and service delivery teams to drive critical client on-boarding initiatives, technology partnerships and highly technical projects.', 'Proactively identify ideas to help drive stronger product performance and implement those ideas from start to finish.', 'Provide technical development guidance, leadership & structure to Enterprise Data clients.', 'Cultivate deep technical partnerships with key members of the client development community.', 'Building strong stakeholder relationships with clients, engineering and product development teams to resolve issues or build out enhancements.', 'Actively identify potential areas of improvement or gaps in internal tools & monitoring systems and propose solutions.', 'Administer training to clients for coding to our API during the pre-sale, implementation and adoption phases of an engagement.', ""Support the developer community around Bloomberg's data delivery mechanisms."", 'Provide timely and informative feedback to the Enterprise Data Product teams.', 'Take ownership of complex questions and issues reported by clients as a second tier of technical support via phone calls, ticket systems, email, and in person.', 'Strong client facing experience, be presentable & able to articulate complex technical concepts to all skill levels.', 'Strong organisational skills, attention to detail and the ability to handle multiple technical streams / lead client engagements whilst collaborating across different teams.', 'At least 3-5 years of development experience.', ""Bachelor's degree in Computer Science or Information Systems/Technology or equivalent experience."", 'Industry experience with software development .NET, Java, C++, C# and Python.', 'Experience programming in UNIX and/or Windows.', 'Excellent written/verbal communication skills.', 'The ability to communicate complex information to a wide range of skill levels both in verbal and written form.', 'Excellent analysis and problem solving skills.', 'Experience writing readable example code.', 'Confident to work with clients ranging from developers to CTOs.', 'Exposure and understanding of Financial Data, especially Real Time Market Data is helpful.', 'Knowledge of market data distribution platforms and feed handlers is preferred.', 'Knowledge and experience of Big Data, Data Science and Cloud technologies.', 'Knowledge and experience with Hypermedia APIs.', 'Experience developing on public cloud platforms, AWS, GCP and Azure.', ""Ability to derive requirements from stakeholders via email, meetings, and conference calls, relay this to internal groups, plan detailed technical engagements and facilitate client adoption of Bloomberg's Enterprise Data products and services."", 'UNIX skills with ability to investigate technical issues or willingness to learn', 'Exposure to Perl is useful (for some of the older tools)', 'Experience with database querying languages such as SQL, NoSQL or similar', ""Exposure to architectural design in order to facilitate client adoption of Bloomberg's Enterprise Data products and services""]",2020-08-08 13:23:36
Junior Test Engineer,Battelle,3.8 out of 5,"Crystal City, VA","['The candidate must have a BS in engineering, operations research, mathematics, or physical science from an accredited college or university and a minimum of 0-2 years of experience or a minimum of 4 years of experience with no degree.', 'Sole US Citizenship with the eligibility and willingness to obtain and maintain a DOD Secret Security Clearance and to obtain TSA Security Suitability.', 'Experience with Acceptance Testing.', 'Experience with Explosive Detection Technologies and/or Baggage Handling Systems (BHS).', 'Already possess a Secret Security Clearance.', 'Already possess TSA Security Suitability.']",2020-08-08 13:24:18
Sr. Quality Engineer,Rinnai America Corporation,2.9 out of 5,Remote,"['Lead problem-solving to determine root cause of failures and drive product improvement initiatives.', 'Participate in the development of product acceptance criteria, design reviews and ensure design robustness.', 'Facilitate FMEA’s for Rinnai developed products and ensure proper action and resolutions are implemented.', 'Provide support to development projects through its lifecycle.', 'Support Engineering changes and improvements and ensure Quality systems are updated to compliance.', 'Work in coordination with management, monitor new and existing product launches, warranty claims to determine root causes and implement corrective actions as necessary by analyzing field failures, parts, and customer complaints.', 'Develop, collect and analyze quality metrics.', 'Generate quality reports to support analysis and improvement projects.', 'Support the Non-Conformance Program including Pareto analysis and Root Cause Analysis (8D or similar format) and track to closure.', 'Manage approvals of deviations and change controls.', 'From customer and field driven RCCA activities, create or revise quality control plans which include the identification of critical control points, preventive measures, monitoring procedures and verification procedures.', 'Promote adherence to quality standards, test methodologies, quality plans, documents and procedures as well as records and objective evidence of activities.', 'Application and operation of quality inspection tools and procedures.', 'Bachelor of Science in a relevant Engineering discipline', 'Minimum five years of relevant experience', 'Comprehensive quality knowledge and experience in such as statistics, DOE, test method validation, quality, and failure analysis', 'Lean and Six Sigma trained / Green or Black Belt preferred', 'Inspection techniques, tools, and testing methodologies', 'Manufacturing Procedures and specifications', 'Product experience in related gas fired consumer products such as tankless water heaters, hybrid tankless water heaters, commercial water heaters, boilers, and other water and combined space heating products is a plus', 'Understanding standards related to quality and safety standards is a plus (ANSI, CSA, ISO and others)', 'Experience with SolidWorks or similar 3D software', 'Understanding of component Prints', 'MS Office Products and statistical software', 'Ability to develop high levels of cooperation and respect from staff, colleagues, and suppliers alike', 'High level of personal integrity and honesty', 'Team player able to operate with independence and enthusiasm', 'Technical, Customer service and Quality discipline', 'Well-developed and thorough understanding of analytical analysis, problem-solving tools, and quality improvement tools and techniques', 'Proven experience in quality', 'Able to manage and control quality records', 'Includes knowledge of management and planning tools, quality tools, preventive and corrective actions, and how to overcome barriers to quality improvements.', 'Proficiency in using statistical, quality, and continuous improvement methods, and data analysis to diagnose and correct improper quality control practices.', 'Well-developed analytical and problem-solving skills.', 'Use auditing techniques to get an understanding of processes', 'Able to use MS Office products to communicate quality data', 'Can communicate effectively by using written and oral skills.']",2020-08-08 13:24:18
Data Engineer,Onix Networking Corp,3 out of 5,"Lakewood, OH 44107","['The Onix Cloud Data Team helps customers transform and evolve their business through the use of Google’s extensive cloud services. As part of an entrepreneurial team in this rapidly growing business, you will work with cutting-edge cloud technologies and help shape the future of how data is used in the Enterprise.', 'Use Google Cloud Platform to build Enterprise-grade Big Data solutions.', 'Architect and build new cloud-based data pipelines.', 'Bring together multiple data sources into a unified data warehouse.', 'Apply analytics and visualizations to customer data sets.', 'Help customers understand the right technologies for their use case.', 'Establish strategic customer relationships and become their go-to trusted advisor for Big Data needs.', 'Assist in strategic direction and planning for growth of the Cloud Data Team.', ""Bachelor's Degree in Computer Science, Data Science or a related discipline."", '5+ years or more of enterprise-level consulting.', 'Experience with large data sets and Enterprise-grade databases (structured and unstructured)', 'Experience architecting and building data pipelines.', 'Deep understanding of the ETL (extract, transform, load) process.', 'Experience extracting data from multiple sources via APIs and scripting.', 'Experience transforming data through field mapping, programmatic rulesets, and data integrity checking.', 'Able to expertly convey ideas and concepts to others.', 'Excellent communication skills (verbal, written and presentation)', 'Creative problem solving skills and the ability to design solutions not immediately apparent.', 'Ability to participate in multiple projects concurrently.', 'Customer-oriented and shows a bias for action.', 'Able to function in a highly dynamic team that moves rapidly from idea to planning to implementation.', 'Highly adaptable with the ability to learn new technologies quickly without direct oversight.', 'Experience with BigQuery', 'Experience with SQL (architecture and queries)', 'Experience with Tableau / other enterprise visualization and BI tools']",2020-08-08 13:24:18
Data Engineer,"U.S. Xpress Enterprises, Inc.",3 out of 5,"Atlanta, GA","['Job', 'Company', 'Develop robust, scalable solutions for collecting & analyzing large data sets. Must be proficient in creating & maintaining data pipelines.', 'Proficiency in developing packages, stored procedures, functions, triggers, and complex SQL statements.', 'Experience with ETL tools (such as Informatica)', 'Design logical data models and their physical schema design.', 'Some experience programming in Java & Python. Big data knowledge is a plus', 'Experience with Git and/or bitbucket is a plus.', 'Ability to work with multiple data sources and types (structured/semi-structured/unstructured)', 'Cloud experience (AWS/Azure/Google)', 'Bachelors or Master’s Degree in Computer Science, Information Systems, or a related field.', 'Develop robust, scalable solutions for collecting & analyzing large data sets. Must be proficient in creating & maintaining data pipelines.', 'Proficiency in developing packages, stored procedures, functions, triggers, and complex SQL statements.', 'Experience with ETL tools (such as Informatica)', 'Design logical data models and their physical schema design.', 'Some experience programming in Java & Python. Big data knowledge is a plus', 'Experience with Git and/or bitbucket is a plus.', 'Ability to work with multiple data sources and types (structured/semi-structured/unstructured)', 'Cloud experience (AWS/Azure/Google)', 'High level expertise with SQL. Graph database experience is highly desired.', 'Partner with Data Owners to design solutions that align to data governance and data management principles best practices.', 'Data Visualization with PowerBI / Tableau / QlikView or equivalent is a plus', 'Ability to work in a fast-paced, agile and dynamic environment with both virtual and face-to-face interactions.', 'Strong collaborative mindset, good judgment with great interpersonal skills required to help solve complex business problems.', 'Medical, Dental and Vision', '401K', 'Stock Purchase Plan', 'Vacation, Sick, & Personal time', 'Paid Holidays', 'Tuition Reimbursement', 'On-site work out facility', 'Monthly Parking']",2020-08-08 13:24:18
Cloud Infrastructure Engineer,DataAxxis,N/A,"New York, NY","['Hands-on engineers who can help us implementation of our cloud infra needs and review cloud infra based on cloud operating model and help us operate in Agile Mode.', '6+ years exp.', 'Monday to Friday', 'Possible', 'Temporarily due to COVID-19']",2020-08-08 13:24:18
Software Test Engineer,Tyler Technologies,3.6 out of 5,Remote,"['Create test plans and test matrices based off business and functional requirements', 'Perform manual test case execution against our platform UI', 'Organize cross team “bug bashes”', 'Create, manage and triage defects', 'Troubleshoot issues experienced during testing', 'Provide daily and weekly status reporting', 'Comprehend and understand testing requirements', 'Ensure strong attention to detail and be able to accomplish a wide variety of tasks', 'Follow written and verbal instructions from client and leads', 'Understand and use JIRA for test case management, creation and execution', 'Archive all test documentation as directed', 'BE in Computer Science or equivalent combination of experience in a technical role of minimum 1 year, ideally with demonstrated QA experience as a STE or QA Engineer.', 'STE or QA Engineer experience should ideally be in the software industry.', 'Experience with data visualization – this role will be heavily involved in testing charts and maps', 'Excitement, not just willingness, to talk to developers to gather requirements, understand systems, and scope the bugs you find – essentially the drive to “unblock” yourself and always ask for help when needed.', 'Expertise in test methodologies and test processes', 'Ability to understand technical specifications and generate test cases from them', 'Comfort communicating cross-functionally and across management levels in formal and informal settings', 'Comfort working in an often-ambiguous area', 'Strong organizational skills, ability to track multiple test executions simultaneously and synthesize the results', 'May be required to pass a fingerprint background check (for potential CJIS requirements).', 'Experience automating test cases (if you don’t have this, don’t worry. We can teach you)']",2020-08-08 13:24:18
Big Data Engineer,"DataSync Technologies, Inc",N/A,"Reston, VA","['Bachelor’s or Master’s degree in computer science or software engineering preferred', 'Experience with object-oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large-scale data infrastructures.', 'Ability to architect highly scalable distributed systems, using different open source tools.', 'Experience building high-performance algorithms.', 'Extensive knowledge of different programming or scripting languages such as Java, Linux, C++, PHP, Ruby, Phyton and/or R.', 'Experience with different (NoSQL or RDBMS) databases such as MongoDB needed.', 'Experience building data processing systems with Hadoop and Hive using Java or Python', 'Excellent oral and written communication skills;', 'Experience in designing efficient and robust ETL workflows;', 'AWS experience', 'www.datasynctech.com', 'www.facebook.com/DatasyncTechnologies', 'www.twitter.com/Jobs at DataSync (@DatasyncJobs)', 'www.twitter.com/datasynctech', '#datasynctech on Instagram', 'Interested in Joining Our Team? - Check out this YouTube video!']",2020-08-08 13:24:18
"Data Engineer, AVS",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', '3+ years of experience as a Data Engineer or in a similar role', 'Experience with data modeling, data warehousing, and building ETL pipelines', 'Experience in SQL', 'Design, implement and support an analytical data infrastructure', 'Managing AWS resources including EC2, EMR, S3, Glue, Redshift, etc.', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies', 'Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency', 'Collaborate with Data Scientists and Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis', 'Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Maintain internal reporting platforms/tools including troubleshooting and development. Interact with internal users to establish and clarify requirements in order to develop report specifications.', 'Work with Engineering partners to help shape and implement the development of BI infrastructure including Data Warehousing, reporting and analytics platforms.', 'Contribute to the development of the BI tools, skills, culture and impact.', 'Write advanced SQL queries and Python code to develop solutions.', 'Design, implement and support an analytical data infrastructure', 'Managing AWS resources including EC2, EMR, S3, Glue, Redshift, etc.', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies', 'Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency', 'Collaborate with Data Scientists and Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis', 'Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Maintain internal reporting platforms/tools including troubleshooting and development. Interact with internal users to establish and clarify requirements in order to develop report specifications.', 'Work with Engineering partners to help shape and implement the development of BI infrastructure including Data Warehousing, reporting and analytics platforms.', 'Contribute to the development of the BI tools, skills, culture and impact.', 'Write advanced SQL queries and Python code to develop solutions.', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)', 'Implement standardized, automated operational processes to deliver accurate and timely data for reporting to meet or exceed SLAs', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Experience transforming complex data sets. Experience in evaluating data accuracy and quality.', 'Experience working directly with remote technical teams and client services', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Implement standardized, automated operational processes to deliver accurate and timely data for reporting to meet or exceed SLAs', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Experience providing technical leadership and mentoring other Data Engineers for best practices on data engineering']",2020-08-08 13:24:18
Enterprise Data- Solutions Engineer,Bloomberg,3.9 out of 5,"New York, NY","[""Work closely with technical and market data contacts at client firms to understand their requirements and help them to build out solutions using Bloomberg's Enterprise Data Technology such as BLAPI & HAPI."", 'Collaborate with peers, sales, technical account managers and service delivery teams to drive critical client on-boarding initiatives, technology partnerships and highly technical projects.', 'Proactively identify ideas to help drive stronger product performance and implement those ideas from start to finish.', 'Provide technical development guidance, leadership & structure to Enterprise Data clients.', 'Cultivate deep technical partnerships with key members of the client development community.', 'Building strong stakeholder relationships with clients, engineering and product development teams to resolve issues or build out enhancements.', 'Actively identify potential areas of improvement or gaps in internal tools & monitoring systems and propose solutions.', 'Administer training to clients for coding to our API during the pre-sale, implementation and adoption phases of an engagement.', ""Support the developer community around Bloomberg's data delivery mechanisms."", 'Provide timely and informative feedback to the Enterprise Data Product teams.', 'Take ownership of complex questions and issues reported by clients as a second tier of technical support via phone calls, ticket systems, email, and in person.', 'Strong client facing experience, be presentable & able to articulate complex technical concepts to all skill levels.', 'Strong organisational skills, attention to detail and the ability to handle multiple technical streams / lead client engagements whilst collaborating across different teams.', 'At least 3-5 years of development experience.', ""Bachelor's degree in Computer Science or Information Systems/Technology or equivalent experience."", 'Industry experience with software development .NET, Java, C++, C# and Python.', 'Experience programming in UNIX and/or Windows.', 'Excellent written/verbal communication skills.', 'The ability to communicate complex information to a wide range of skill levels both in verbal and written form.', 'Excellent analysis and problem solving skills.', 'Experience writing readable example code.', 'Confident to work with clients ranging from developers to CTOs.', 'Exposure and understanding of Financial Data, especially Real Time Market Data is helpful.', 'Knowledge of market data distribution platforms and feed handlers is preferred.', 'Knowledge and experience of Big Data, Data Science and Cloud technologies.', 'Knowledge and experience with Hypermedia APIs.', 'Experience developing on public cloud platforms, AWS, GCP and Azure.', ""Ability to derive requirements from stakeholders via email, meetings, and conference calls, relay this to internal groups, plan detailed technical engagements and facilitate client adoption of Bloomberg's Enterprise Data products and services."", 'UNIX skills with ability to investigate technical issues or willingness to learn', 'Exposure to Perl is useful (for some of the older tools)', 'Experience with database querying languages such as SQL, NoSQL or similar', ""Exposure to architectural design in order to facilitate client adoption of Bloomberg's Enterprise Data products and services""]",2020-08-08 13:24:18
Software Engineer - Data - New York,Uber,3.7 out of 5,"New York, NY 10018","['Own data expertise and data quality for the pipelines', 'Create and launch new data models that provide intuitive analytics to your customers', 'Design, develop and launch extremely efficient & reliable data pipelines to move data', 'Design and develop new systems and tools to enable folks to consume and understand data faster', '2+ years of full-time engineering experience', 'General coding chops with Java, Python or Scala', 'Proficiency in Spark/MapReduce development and expertise with data processing (ETL) technologies', 'Knowledge of Hadoop related techologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig', 'Knowledge of SQL', 'Experience with large-scale data warehousing architecture and data modeling', 'BS/MS/PhD in Computer Science or a related field']",2020-08-08 13:24:18
Data Engineer,SmileDirectClub,2.9 out of 5,"Nashville, TN 37219","['Design and build new dimensional data models and schema designs to improve accessibility, efficiency, and quality of internal analytics data', 'Build, monitor, and maintain batch and streaming analytics data pipelines', 'Implement systems for tracking data quality and consistency', 'Work closely with Analytics, Marketing, Finance, Data Science and Operations teams to understand data and analysis requirements.', 'Work with teams to continue to evolve data models and data flows to enable analytics for decision making (e.g., improve instrumentation, optimize logging, etc).', 'Build and maintain serverless API’s', 'Enhance and maintain data platform SDK', 'Participate in code reviews', 'Pair program with team members', 'Partner with data scientists to put models into production.', 'Work with the latest technologies to deliver and process large datasets.', 'Has a curiosity about how things work', 'Experience with DataFrames', 'Has built large-scale data pipelines professionally and can craft clean and beautiful code in Java, Scala, Python and/or SQL', 'Has built batch data pipelines with Hadoop/Spark/Dask as well as with relational database engines, and understands their respective strengths and weaknesses', 'Has experience with cloud platforms, preferably Amazon Web Services', 'Experience with event streams, preferably Kafka', 'Has experience with ETL jobs, metrics, alerting, and/or logging', 'Can jump into situations with few guardrails and make things better', 'Possesses strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems, and information retrieval, object oriented programming.', 'Is a strong communicator. Explaining complex technical concepts to product managers, support, and other engineers is no problem for you', 'When things break, and they will, is eager and able to help fix them', 'Has experience with MPP data warehouses (Redshift, Snowflake, or similar)', 'Understands when and how to use a datalake and how to build them.', 'Ability to adapt in a fast paced and mentally stimulating environment.', 'Academic background in computer science or mathematics (BSc or MSc)', 'Experience building simple scripts and web applications using Python', 'A solid grasp of basic statistics (regression, hypothesis testing)', 'Experience in small start-up environments', 'What is SmileDirectClub? Link here.', 'What are our customers saying? Link here.', 'What is a SmileShop? Link here.', 'What is our culture like? Link here.', 'How do we celebrate your team members? Link here.']",2020-08-08 13:24:18
Senior Data Engineer,Kinship,4.6 out of 5,"Portland, OR","['Design and implement optimal data models and pipelines, building the foundations for a better understanding of pets and pet owners for our Kinship businesses', 'Create data infrastructure from variety of sources, leveraging existing tech stack and processes as well as identifying opportunities to build upon it as we mature', 'Build tools that utilize the data pipeline that provide actionable insights into pet owner acquisition, operational efficiency and other key business performance metrics', 'Help us evolve as a team by suggesting new methods or technologies, through POCs or related activities', 'Further a collaborative environment across teams and business units by operating in an agile environment', 'Identify, design, and implement internal process improvements: including process automation, optimizing data delivery, etc.', 'Incorporate governance processes and tools into the data landscape to ensure data quality and privacy', ""Optimistic. Those who are Courageous. Who's boundlessly energy and enthusiasm for what's next shines through in everything they do. We seek to work with people who are intrinsically happy, and who will drive our vision and purpose while managing the complexities of our businesses."", 'Purposefully Inquisitive. Those who Learn at Pace and use their deep business insights to cultivate innovation. We want the trailblazers in tech. Those who are entrepreneurs at heart, ask the tough questions, adapt quickly to new situations, and analyze data in new ways to push our big ideas forward.', 'Open to All. Those who Value Difference. People who are inclusive leaders and believe that our differences make us better. We hire people who are naturally collaborative, thrive in a flat and flexible organization, and seek broad perspectives in their work.', ""At least 5 years' experience in data engineering; experience in some of the following is preferred: Microsoft Azure, Snowflake, Redshift, etc."", 'Experience with big data tools: Spark, Hadoop, etc.', 'Fluent in Python; ideally fluent in SQL as well', 'Demonstrated experience in building end-to-end data pipeline/ETL/ELT solutions', 'Advocate of CI/CD methodologies and agile ways of working', 'Able to collaborate effectively with both technical and non-technical stakeholders in order to deliver value', 'Enthusiastic about mentoring and coaching as the team grows', 'Knowledge of popular data visualization tools e.g. Tableau, Looker, etc.', 'Familiarity with subscription business models and the data challenges that these businesses have', 'Understanding of Microsoft Azure cloud technologies e.g. Blob Storage, ADLS, Azure DevOps, Azure Logic Apps, Azure Functions', 'Unique opportunities for a customizable career within pet care', 'A super collaborative, flat work environment with direct access to our senior leadership team', 'Multiple hubs to work from: NYC, San Francisco, Portland, London, Shanghai, and Moscow', 'A dog-friendly workplace at most hubs, or right from your couch when you work from home', 'Exceptional health, dental, vision, and pet benefits for you and your family', 'Unlimited paid time off', 'Flexible work opportunities', 'Support for pet-related appointments and leaves', 'Parental leave for the birth or adoption of your new child', 'Discounts on pet products, services, nutrition and veterinary wellness plans', 'Welcome kits with pet merch & Kinship swag', 'An extensive onboarding program with a chance to meet all of our leaders across Kinship']",2020-08-08 13:24:18
"Strategic Customer Engagements, Data Engineer - Pricing Analytics","Amazon Web Services, Inc.",3.6 out of 5,"Seattle, WA","['Job', 'Company', 'Bachelor’s degree in Computer Science, MIS, related technical field, or equivalent work experience.', ""More than 5 or more years' of overall work experience in a related field, including 3 or more years analytics, data engineering or related field"", 'Proven experience in data modeling, ETL development, and data warehousing, or similar skills', 'Demonstrable skills and experience using SQL with large data sets (e.g. Oracle, SQL Server, Redshift)', 'Experience with AWS technologies including Redshift, RDS, S3', 'Proven track record of successful communication of data infrastructure, data models, and data engineering solutions through written communication, including an ability to effectively communicate with both business and technical teams', 'Design, implement, and support an analytical data infrastructure providing ad hoc access to large datasets and computing power', 'Managing AWS resources including EC2, RDS, Redshift, et cetera', 'Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies', 'Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency', 'Collaborate with Business Intelligence Engineers (BIEs) to recognize and help adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation', 'Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers', 'Graduate degree in computer science, business, mathematics, statistics, economics, or other quantitative field', 'Both technically deep and business savvy enough to interface with all levels and disciplines within the organization', 'Demonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, finance, and operations', 'Knowledge of Advanced SQL and scripting for automation (e.g. Python, Perl or Ruby)', 'Experience with AWS technologies including EMR, Kinesis', 'Experience with reporting tools like Tableau, Excel or other BI packages', 'Familiarity with statistical models and data mining algorithms', 'Familiarity with Linux', 'Experience with Hadoop or other map/reduce ""big data"" systems and services']",2020-08-08 13:24:18
Data Engineer II,"TechPro, LLC",N/A,"San Francisco, CA 94103","['Understand the data landscape of products', 'Design, architect, and implement new source of truth datasets, in partnership with analytics and business teams', 'Build the required data and reporting pipelines using internal ETL tools', 'Develop dashboards, web-based visualizations (using Tableau, D3, or Plotly), and web-based tools (node.js or flask apps)', 'Collaborate with other engineering teams to develop and integrate BI solutions', 'Experience designing, architecting, and maintaining data warehouses that seamlessly stitches together data from production databases and clickstream event data', 'Hands-on experience with Hive query development and optimization, and, building workflows (preferably using Airflow)', 'Hands-on experience with building data pipelines in a programming language like Python', 'Hands-on experience with building and maintaining Tableau dashboards and/or Jupyter reports', 'Working understanding of Hadoop and Big data analytics', 'Ability to understand the needs of and collaborate with stakeholders from analytics and business teams', 'Monday to Friday', 'Hive query development and optimization, and, building workf: 3 years (Required)', 'building and maintaining Tableau dashboards: 3 years (Required)', 'building data pipelines in a programming language like Pytho: 3 years (Required)', 'Hadoop and Big data analytics: 3 years (Required)', 'data engineering or business intelligence/analytics: 3 years (Preferred)', ""Bachelor's (Required)"", 'San Francisco, CA 94103 (Required)', 'United States (Required)', 'No']",2020-08-08 13:24:18
BIG Data Engineer,Flexon Technologies Inc,N/A,"Pleasanton, CA 94588","['401(k)', 'Dental Insurance', 'Health Insurance', 'Monday to Friday', 'Likely', 'https://www.flexontechnologies.com', 'Temporarily due to COVID-19']",2020-08-08 13:24:18
Senior Data Engineer,"iHeartMedia, Inc.",3.7 out of 5,"Nashville, TN 37201",[],2020-08-08 13:25:00
Senior Data Engineer,Chipotle,3.7 out of 5,"Newport Beach, CA","['Design, develop and maintain scalable data pipelines', 'Develop data ingestion and integrations (REST, SOAP, SFTP, MQ, etc. ) processes', 'Take ownership of building data pipelines', 'Actively engage in technology discovery and implementation for both on-prem and in Cloud (i.e. Azure or AWS) to build solution for future systems', 'Develop high performance scripts in SQL/Python/etc. to achieve objectives of enterprise data, BI and analytics need.', 'Incorporate standards and best practices into engineering solutions', 'Manage code versions in source control and coordinate changes across team', 'Participate in architecture design and discussions', 'Provide logical and physical data design, and database modeling', 'Be part of the Agile team to collaborate and to help shape requirements', 'Solve complex data issues around data integration, unusable data elements, unstructured data sets, and other data processing incidents', 'Supports the development and design of the internal data integration framework', 'Works with system owners to resolve source data issues and refine transformation rules', 'Partner with enterprise teams, data scientist, architects to define requirements and solution', 'Have a B.A./B.S. and 5-8 years of relevant work experience; or an equivalent in education and experience', 'Hands on experience with Microsoft Stack SSIS, SQL, etc.', 'Possess strong analytical skills with the ability to analyze raw data, draw conclusions, and develop actionable recommendations', 'Experience with the Agile development process preferred', 'Proven track-record of excellence and consistently delivered past project successfully', 'Hands on experience with Azure data factory V2, Azure Databricks, SQLDW or Snowflake, Azure analysis services and Cosmos DB', 'Experience with Python or Scala.', 'Understanding of continuous integration and continuous deployment on Azure', 'Experience with large scale data lake or warehouse implementation on any of the public cloud (AWS, Azure, GCP)', 'Have excellent interpersonal and written/verbal communication skills', 'Manage financial information in a confidential and professional manner', 'Be highly motivated and flexible', 'Effectively handle multiple projects simultaneously and pay close attention to detail', 'Have experience in a multi-dimensional data environment']",2020-08-08 13:25:00
"Data Engineer, Amazon Games",Amazon.com Services LLC,3.6 out of 5,"San Diego, CA","['5+ years of industry experience in data engineering, with a track record of manipulating, processing, and extracting value from large datasets', 'Demonstrated strength in data modeling, ETL development, and data warehousing', 'Experience using big data technologies (Airflow, EMR, Columnar Data Warehouses, Spark etc.)', 'Knowledge of data management fundamentals and data storage principles', 'Knowledge of distributed systems as it pertains to data storage and computing', 'Have a penchant for digging deep and attacking difficult and complex problems.', 'Be a self-starter who is able to work alone or as a member of a team.', 'Excellent oral and written communication skills as well as strong analytical and problem-solving skills.', 'Ability to work on multiple concurrent projects and interface with all levels within the organization.', 'Architect scalable data pipelines that handle millions of events per second in a cost-effective manner using AWS technologies including Airflow, Spark, EMR, Glue, Kinesis, Redshift/Spectrum and Athena.', 'Create automated ingestion, processing, cleaning and aggregation of large data sets', 'Design user access controls that allows partial and complete data access to large and diverse groups of users', 'Work closely with game teams, Twitch, finance and marketing to build data solutions.', 'Help continually improve ongoing reporting and analysis processes', 'Experience working with AWS big data technologies (Redshift, S3, EMR)', 'Experience with Airflow or other similar ETL tools', 'Experience providing technical leadership and mentoring other engineers for best practices on data engineering', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Familiarity with statistical models and data mining algorithms', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', 'Meets/exceeds Amazon’s leadership principles requirements for this role.', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role.']",2020-08-08 13:25:00
Senior Data Engineer ( 10+exp),Spotline Inc,N/A,"San Mateo, CA","['Monday to Friday', 'Let me know your Visa and Total exp?', 'Temporarily due to COVID-19']",2020-08-08 13:25:00
Data Platform Engineer,K12 INC,3.2 out of 5,Remote,"['About us', 'K12 Produces Results', 'Kudos and Honors', 'thinkTANK12', 'Develop and build data infrastructures and leveraging tools that allow data flow pipelines to be built for data science and business user consumption.', 'Write CloudFormation scripts to enable automated infrastructure setup; write integration code where necessary', 'Leverage APIs to integrate SaaS and PaaS components of the data platform', 'Collaborate with product development and data science teams to solve challenging business and technical problems', 'Deploy data pipeline jobs created using best practices for ingesting surrounding ecosystem of products such as Snowflake, S3, Neo4J, RDBMS, NoSQL, etc.', 'Document deployment architectures pipeline coding best practices', 'Bachelor’s Degree in information systems, computer science, engineering or other relevant discipline AND', '5 years’ experience in data platform development across several ETL/DW platforms OR', 'Equivalent combination of education and experience', 'Detail oriented, capable of envisioning edge-cases that are likely to happen in the real data sets', 'Aware of software engineering / DevOps best practices (Source control & branching patterns, automated testing, automated deployments)', 'Ideally capable of writing data transformations in code, but in some organizations may utilize a GUI tool', 'Experience in AWS cloud platform infrastructure development and deployment', 'Strong understanding of modern CI / CD practices and principles, with experience in Jenkins development preferred', 'Strong understanding of DataOps principles', 'Microsoft Office (Outlook, Word, Excel, PowerPoint, Project, Visio, etc.); Web proficiency.', 'Ability to travel 10% of the time', 'Ability to pass required background check', 'Familiarity with Streamsets, Alation, Snowflake, Power BI', 'This is a home based position']",2020-08-08 13:25:00
BIG Data Engineer,Flexon Technologies Inc,N/A,"Pleasanton, CA 94588","['401(k)', 'Dental Insurance', 'Health Insurance', 'Monday to Friday', 'Likely', 'https://www.flexontechnologies.com', 'Temporarily due to COVID-19']",2020-08-08 13:25:00
Sr. Data Engineer,Echo Global Logistics,3.3 out of 5,"Chicago, IL 60654","['', '']",2020-08-08 13:25:00
Data Solutions Analyst,Quicken Loans,3.8 out of 5,"Detroit, MI 48226","['Leverage data visualization, data manipulation and mathematics skills to identify patterns in response to business and data science needs', 'Translate data science model results into actionable and quantifiable business insights', 'Understand, collect and feature engineer data for further statistical analysis', 'Develop and implement multivariate tests', 'Validate and monitor performance/accuracy and business impact of data science models', 'Maintain relationships between business area clients and the Business Intelligence and Technology teams so all teams are aligned to meet objectives', 'Work with Project Managers to develop detailed project timelines', 'Summarize and present conclusions and solutions', 'Communicate complex analyses clearly to all audiences as requested', 'Bachelor’s degree in a quantitative field such as computer science, statistics, applied mathematics, operations research, engineering, economics, social sciences, physics or chemistry', '1 year of experience providing data analysis and visualization experience within a business setting', '1 year of experience working with raw data', 'Understanding of statistics', 'Proficiency in SQL, Tableau and Microsoft data packages', 'Understanding of programming fundamentals', 'Working knowledge of relational databases and standard SQL query methods', 'Experience working with big data within a Hadoop environment', 'Experience working with R, Python or other programming packages', 'Experience with machine learning methods (such as regressions, clustering, classification, etc.)']",2020-08-08 13:25:00
Data Engineer,Everytown for Gun Safety,2 out of 5,"Washington, DC","['Gather and spec requirements for a successful project;', 'Maintain existing systems, and deliver enhancements;', 'Perform peer code review and quality assurance as part of a team;', 'Build pipelines for automated transforms of data into data marts in order to support reporting, predictive analytics, and targeting.', ""Provide support and training for staff and volunteers on Everytown's suite of tools and best practices for using data effectively;"", 'Make recommendations and provide guidance on ways to make programs, campaigns, and data collection more efficient and effective;', 'Other responsibilities as assigned.', '2-3 Years in SQL;', '2-3 Years in software development languages, Python preferred.', 'Developing and maintaining pipelines to perform ETL;', 'Working with version control systems such as Git;', 'Experience using APIs to construct and maintain data synchronizations', ""Experience training people on a variety of activities, experienced/comfortable at conducting trainings (even if you didn't create them);"", 'Ability to manage several tasks or projects concurrently and prioritize work effectively;', 'Ability to communicate effectively, especially technical ideas to non-technical people, work well under pressure, be detail oriented and meet deadlines;', 'Strong attention to detail, including producing technical documentation.', 'Mapping visualization, D3, GIS applications or R Leaflet;', 'Familiarity with R, Javascript, or other scripting languages;', 'Experience with Civis Analytics Platform;', 'Ability to diagnose and improve database and query performance issues;', 'Digital Campaigning platforms data schemas;', 'Data Visualization & reporting of metrics using tools such as Tableau;', 'Knowledge of CRM & Donation Data Schemas']",2020-08-08 13:25:00
Senior Data Engineer,Adaptimmune,4 out of 5,"Philadelphia, PA 19112","['Understand the vision, gather requirements and convert needs to technical / data specifications', 'Hands-on technical design, coding / implementation, and operational support for every step of a data process', 'Working alongside data scientists, analysts, IT experts and stakeholders to build / scale data pipelines, data algorithms and production systems and solutions (using commercial packages and custom development)', 'Management of data flow from source through database to data presentation and/or delivery', 'Oversight of data processing platforms and tools (e.g. database, data transformation, and integration technologies) and front-end data visualization software (e.g. Spotfire)', 'Understanding of data schema and design, metadata and analytic requirements in a scientific environment', 'Understanding and advocate for the big-picture vision', 'Gather requirements and convert needs to technical / data specifications', 'Technical design, coding, transformation and operational support for every step of a data process', 'Working alongside data scientists, analysts, IT experts and stakeholders to build / scale data pipelines / algorithms (including tools to monitor performance and completion), and production systems and solutions (using commercial packages and custom development)', 'Management of data flow from source through database to data presentation and/or delivery', 'Create end user data visualization (traditional reporting and multi-modal data exploration)', 'Assemble large, complex data sets to support business needs', 'Deploy sophisticated analytics programs, machine learning and statistical methods', 'Data automation', 'Prepare data for predictive and prescriptive modelling', 'Data transformation, query, bioinformatic pipeline and visualization techniques', 'Recommend ways to improve data reliability, efficiency and quality', 'Oversight of data processing platforms and tools (e.g. database, data transformation, and integration technologies) and front-end data visualization software (e.g. Spotfire)', 'Optimization of processing performance and data models', 'Production orchestration (pipelines/algorithms, performance, scale, infrastructure, data flow)', 'Data governance and data security best practices', 'BSc or MSc degree in a relevant field, such as computer science, statistics, applied mathematics, computational biology, data management, data science, information systems, bioinformatics etc.', 'Combination of experience in IT software engineering, data management and integration, and data visualization skills with data science or big data background', 'Experience of partnering with business users, technical specialists and speaking the language of data', 'Open source and commercial scientific software package experience', 'Strong data flow design including database schema / low level architecture and transformation skill-sets', 'High performance computing and data storage using cloud technologies', 'Prior experience in complex biotechnology and / or pharmaceuticals industry', 'GxP experience', 'Expertise in Next Generation Sequencing-RNA sequencing data and other bioinformatics tools', 'Understanding of computational methods, scripting and programming languages, and relevant concepts in cancer biology, biotechnology, immunology and/or geneticss', 'Prior experience as bioinformatician, biostatician, biotech software programmer or data architect a plus', 'Strong and demonstrated software engineering experience using computational programming languages (i.e. R, Python, Java, C++), pipeline lifecycle tools, and popular database programming languages (ie. SQL, PL/SQL) for relational databases, operational data stores and data lakes', 'Strong ability to design, build and manage data pipelines for data structures encompassing data transformation, data integration, data models, schemas and meta-data', 'Experience with integration of data from multiple data sources to support down-stream scientific analysis', 'Strong experience in working with large, heterogeneous datasets in building and optimizing data pipelines, pipeline architectures and integrated datasets using traditional data integration technologies. These should include ETL/ELT, data replication/CDC, message-oriented data movement, API design and access and upcoming data ingestion and integration technologies such as stream data integration, CEP and data virtualization.', 'Open source and commercial software package experience', 'Strong experience in working with and optimizing existing ETL processes and data integration and data preparation flows and helping to move them in production', 'Basic experience working with popular data discovery, analytics and BI software tools like Tableau, Qlik, PowerBI, etc. for semantic-layer-based data discovery and end user visualization', 'Strong experience in working with data science teams in refining and optimizing data science and machine learning models and algorithms', 'Demonstrated success in working with large, heterogeneous datasets to extract business value using popular data preparation tools to reduce or even automate parts of the tedious data preparation tasks.', 'Basic experience in working with data governance/data quality and data security teams in moving data pipelines into production with appropriate data quality, governance and security standards and certification.', 'Demonstrated ability to work across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through containerization techniques such as Docker, AWS, etc.', 'Adept in agile methodologies and capable of applying DevOps and increasingly DataOps principles to data pipelines to improve the communication, integration, reuse and automation of data flows between data managers and consumers across an organization', 'Hands on skills with pipeline, data visualization and analysis tools', 'An understanding of the principles of oncology / immuno-oncology', 'Outstanding communication, collaboration and partnering skills', 'Good knowledge of in-process manufacture, research and clinical trial data', 'Demonstrated ability to work across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through tools such as Docker, AWS, etc.', 'Demonstrable experience of pipeline workflow tools as used in a life science environment']",2020-08-08 13:25:00
"Software Engineer, Data",Fathom Health,N/A,Remote,"['Develop data infrastructure to ingest, sanitize and normalize a broad range of medical data, such as electronics health records, journals, established medical ontologies, crowd-sourced labelling and other human inputs', 'Build performant and expressive interfaces to the data', 'Build infrastructure to help us not only scale up data ingest, but large-scale cloud-based machine learning', '3+ years of development experience in a company/production setting', 'Experience building data pipelines from disparate sources', 'Hands-on experience building and scaling up compute clusters', 'Excitement about learning how to build and support machine learning pipelines that scale not just computationally, but in ways that are flexible, iterative, and geared for collaboration', 'A solid understanding of databases and large-scale data processing frameworks like Hadoop or Spark. You’ve not only worked with a variety of technologies, but know how to pick the right tool for the job', 'A unique combination of creative and analytic skills capable of designing a system capable of pulling together, training, and testing dozens of data sources under a unified ontology', 'Developing systems to do or support machine learning, including experience working with NLP toolkits like Stanford CoreNLP, OpenNLP, and/or Python’s NLTK', 'Expertise with wrangling healthcare data and/or HIPAA', 'Experience with managing large-scale data labelling and acquisition, through tools such as through Amazon Turk or DeepDive']",2020-08-08 13:25:00
Data Engineer,Blueprint Technologies,3.2 out of 5,Washington State,"[""2 (+) years' experience working with Azure Data Factory, data lake & data warehouse"", 'At least 5-years of experience with SQL Development (ETL, transformations, stored procedure)', ""4 (+) years' experience working with Spark or Databricks"", 'Experience working with Python and in SQL development', ""3 (+) years' experience working with Azure Cloud Securities and Operations"", 'Proven ability in building high-performance and scalable data solutions using Azure, or similar cloud platforms', 'Excellent collaboration skills to work on a team as well as independently (be self-reliant and resourceful)', 'Excellent organization skills and able to multi-task and detailed oriented', 'Excellent verbal and written communication skills (must be able to write clear and concise emails for any audience, etc.', 'Ability to look at solutions in unconventional ways and see opportunities to innovate', 'Proven experience in accessing, communicating and implementing enterprise strategy', 'Proficient in Azure BI Stack', 'Experience in advanced analytics (ML or AI)', ""Bachelor's or master's degree in Computer Science, Computer Engineering or related technical discipline is favored.""]",2020-08-08 13:25:00
IT Support Engineer II,Amazon.com Services LLC,3.6 out of 5,"Sparrows Point, MD","['High school or equivalent diploma', '4+ years of hands on IT systems or relevant experience in a commercial production environment', '4+ years of experience in each of the following: Microsoft Administration, Linux Administration, or Cisco IOS (CLI)', '4+ years of experience troubleshooting skills in a multi-user high availability environment', '4+ years of experience with networking concepts such as DNS, DHCP, SSL, OSI Model, and TCP/IP', '4+ years of experience in PC repair, troubleshooting, deployment, and liquidation', '3+ years IT experience with client, server, and network service delivery', 'Has obtained two of the following certifications: CompTIA A+, CompTIA Network+, Cisco/CCNA, Linux (Redhat), Microsoft hardware (installation), AWS, or other industry relevant certifications', 'Troubleshooting difficult IT problems without SOPs', 'Planning and coordinating CMs and CM templates.', 'Collaborating with internal teams or vendors to execute projects.', 'Leading continuous improvement efforts.', 'Auditing the quality of work performed and provide constructive feedback when necessary.', 'Automating manual tasks; create/improve small tools that help make team operations more efficient.', 'Serving as the first point of escalation.', 'Participating in hiring, training and development of others.', 'Moving up to 49 lbs as well as standing and walking during shifts lasting 12 hours.', 'Traveling up to 25% of the time.', 'Bachelor’s degree in Computer science or IT related field', 'Microsoft Certified Solutions Expert and Microsoft Certified IT Professional Systems Administrator Certifications', 'Strong troubleshooting skills of very complex systems', 'Ability to explain complex IT concepts in simple terms', 'Excellent written and verbal communication skills', 'Ability to manage high priority projects']",2020-08-08 13:25:00
Data Engineer,Airlines Reporting Corporation,3.4 out of 5,"Arlington, VA 22201","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 13:25:00
Sr Data Platform Engineer,Spreetail,2.7 out of 5,"Lincoln, NE","['Lead the architecture, maintenance, support, and scalability of the enterprise data platform and supporting systems.', 'Build systems that are well-performing, reliable, and trusted by the business.', 'Keep up-to-date on emerging data technologies and plan for the integration of those technologies into our platform.', 'Build systems/components that make the data engineers more efficient (e.g. CI/CD).', 'Maintain strong and effective relationships with analysts throughout the company, ensuring their analytical needs are supported through data systems and the data systems adapt to new analytical needs.', 'Dig into complicated data designs and systems, optimize performance, and design the technical architecture of data systems.', 'Mentor and lead the team using your data expertise.', 'Provide on-call support for the data platform systems.', 'Decompose complex business processes into workable technical pieces for the data platform engineering team.', 'Build a vision and strategy for the delivery of analytics tools for both internal and potential vendor partner use.', '5-10+ years of experience in data warehouse modeling, design, and development.', '5-10+ years of experience in ETL tools (SSIS, DataStage, Informatica, etc.) and OLAP tools.', 'Highly experienced with SQL development skills (stored procedures, views, functions, etc.).', 'Proficient in data warehouse design philosophies (star vs snowflake schemas, etc.).', 'Passionate with on-premises, hybrid, and cloud-based analytical solutions.', 'Proficient with end-user data integration tools (Power Query, Alteryx, etc.).', 'Proficient with data presentation tools (Power BI, Tableau, QlikView, etc.).', 'Quick to learn and adapt to new technologies.', 'Bring a lot of energy and curiosity while working with many teams across the company.', 'Enthusiastic towards contributing to the vision and strategy of the team and company.', 'Actively give and receive feedback in a manner that drives team success.', 'Maintain a positive attitude so your teammates and colleagues look forward to working with you.', 'Able to effectively and influentially communicate across a variety of business functions.', 'Unit Appreciation Rights: Up to 5% of yearly salary; based upon company and team', 'Company Bonus: Up to 5% of yearly salary; based upon company and team performance', 'Health Insurance: Spreetail will pay for your full premium and half for spouse/family', 'Dental Insurance: Spreetail will pay half of the dental coverage for you/spouse/family', '401k: Spreetail partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan options', 'Paid Time Off: untracked time off', 'Wedding Week: Enjoy an additional 5 paid days off before or after your wedding', 'Gym Membership: Spreetail will pay for half of your membership to a specified gym', 'Creating a Home: After 2 years of employment, Spreetail will give you $5,000 when you', 'Year 3 Vacation: After 3 years of employment, you will be eligible for an all-inclusive', 'Year 5 Sabbatical: After 5 years of employment, you will be eligible for a 2-week paid', 'Donation Matching: Spreetail will match your donation dollar for dollar, up to $250 a', 'Community Involvement: Spreetail encourages employees to take time off for volunteer', 'Product Discount: Enjoy a 20% discount on the products we sell']",2020-08-08 13:25:00
US Data Engineer,Babylon Health,3.3 out of 5,"Austin, TX","['Build, test and refine data pipelines for data analytics & business intelligence (BI)', 'Data modelling, process design and overall data pipeline architecture', 'Ensure the data quality and consistency with monitoring and support, and play an active role in establishing data governance around company KPIs', 'Work closely with the BI teams to design, build & test end-to-end solutions', 'Work closely with the Data Science team to support processing data into a form suitable for machine learning models', 'Champion SSDLC (Secure Software Development Life Cycle) within Analytics & Data Science and lead by example in building self-service, well tested solutions', 'Champion high engineering standards through comprehensive testing, code reviews, continuous integration and continuous deployment across the team', 'Our technology stack includes Python, dbt, AirFlow and a host of Google Cloud products that run on a range of technologies (GCP/AWS, Docker, GitHub, CircleCI & Jenkins)', ""Bachelor's Degree in Computer Science or related field"", 'Proven ability to looking at solutions unconventionally and explore opportunities and devise innovative solutions', 'Excellent communication skills (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams', 'Experience gathering complex business requirements and identifying data needs', 'Experience with design & development of relational databases and data warehouses', 'Advanced level of proficiency in SQL development', 'Knowledge & expertise with Python, Shell, Java scripting', 'ETL development experience with large-scale DBs or big data systems such as Hive, BigQuery, AWS Redshift, Snowflake, etc', 'Experience using data transformation tools such as dbt', 'Experience using data orchestration tools such as Apache AirFlow or Apache Beam', 'Experience with using a cloud platform provider (such as AWS/GCP) to develop tools and infrastructure', 'Exposure to a BI reporting tool (such as Looker/Tableau) with an understanding of why they are an important part of the analytics stack', 'Experience analyzing data to identify deliverables, gaps, and inconsistencies.']",2020-08-08 13:25:44
Lead Data Engineer,Guru,N/A,"Gaithersburg, MD 20878","['Ability to solve problems with data & superb attention to data accuracy', 'Experience with AWS Big Data solutions & tools', 'Proficiency with AWS environments and implementation of AWS data tools (RedShift, Dynamo, RDS, Migration Services)', 'Hands-on experience working with a variety of data repository models including Data Marts, Data Warehouses and Data Lakes', 'Experience integrating data across many different systems & data sources including both structured and unstructured data', 'Demonstrated experience with both SQL and NoSQL database tools', 'Hands-on experience in all aspects of data warehousing and schema', 'Proficiency in designing efficient and robust ETL workflows', 'Working with cloud computing environments and tune solutions to improve performance and end-user experience', 'Experience working collaboratively with cross-functional agile teams', 'Contribute to group knowledge sharing platforms and best practices', 'Critical thinking, willingness to ask questions and help determine the best course for solutions', 'Ability to complete tasks independently', 'Strong interpersonal skills to build relationships and communicate effectively with multiple personality types', 'Demonstrated ability to work effectively in a fast-paced, complex, and dynamic business environment', 'Enjoy being challenged and to solve complex problems daily', 'Proven ability to support a strong member/customer service culture', 'Demonstrated and dynamic analytical/ problem-solving skills', 'Continuous improvement mindset', 'Ability to understand the big picture', 'BA/BS data analytics/computer science/information or similar degree', 'Four years of job-related experience is preferred', 'Building reporting semantic layers and BI dashboards are preferred', 'SQL Server Integration Services is preferred', 'Experience with AWS, DOMO, Tableau, Microsoft Power BI, Alteryx Designer, and Microsoft Azure preferred', 'Musical Background', 'Love of Video Games', 'Love of Sushi', 'Sense of Humor', 'Ping Pong skills']",2020-08-08 13:25:44
Data Center Engineer,HealthBPM,4 out of 5,"Minneapolis, MN","['Provision, plan, and install all new equipment in the data center including servers, network switches and routers.', 'Order and procure equipment and parts necessary for installations in advance to ensure hardware/software needed for project implementations meet the project dates.', 'Troubleshoot and maintain equipment within the data center.', 'Collaborate with management to determine efficiency and effectiveness of IT systems or services.', 'Keep up to date on policies and requirements to ensure the data center equipment meets standards.', 'Ensure all necessary operational processes and procedures are carried out with a high level of attention to detail, expediency, and on-time delivery.', 'Assist in the creation and maintenance of network and datacenter diagrams and detailed site documentation.', 'Write procedural and policy documentation for internal and external use.', 'Validate that all documentation is current and accurate.', 'Coordinate large expansion projects with implementations or upgrades to Data Center equipment.', 'Perform regular inspections of the critical infrastructure including data collection and evaluation.', 'Alert appropriate team to provide warning/notification if thresholds have been reached, something has changed, or a failure has occurred.', 'Documents findings and concerns, collect all pertinent data.', 'Maintain inventory and labeling of equipment.', 'Monitor rack & room environments for adequate power and cooling for IT equipment.', 'Configure tools for power and environmental monitoring.', 'Provision security access to the Data Centers.', 'Perform Tape Library duties: Ensuring accuracy of incoming and outgoing tapes. Tracking the volume of tapes being used. Requesting offsite tapes as needed. Participates in tape audits.', 'Part of a 24x7 on-call support rotation schedule.', '5+ years of experience in Data Center Management', 'Fiber Optic Cable Installation', 'Excellent interpersonal, communication, documentation, and troubleshooting', 'Experience in the installation, de-installation, repair, and maintenance of electronic equipment in a data center environment', 'Monday to Friday', 'Fiber Optics: 2 years (Required)', 'Data Center: 5 years (Required)', 'Server: 3 years (Required)', 'Minneapolis, MN (Required)', 'United States (Required)', 'Yes', 'No']",2020-08-08 13:25:44
Big Data Engineer,LOTAME,4.5 out of 5,"Elkridge, MD 21075","['What do we mean by “big data”? 17 Terabytes ingested daily, processed against a pool of 4 Petabytes.', 'Work with both technology and business leadership to evaluate new business needs and product strategies, and create solutions to solve complex business problems.', 'Manage the full lifecycle of feature delivery, from idea to deployment.', 'Guide the work of multiple engineers as a part of a scrum team, holding the team accountable for commitments and deliverables.', 'WRITE CODE! (yes, you will personally build scalable, efficient systems)', 'Ensure product quality by enforcing testing standards, measuring release defect rates, and leading other quality initiatives.', 'Collaborate with other team members toward shared product goals, and communicate team performance through shared metrics.', 'Utilize sound engineering practices to deliver functional, stable, and scalable technology.', 'Work in a fast-paced, flexible, and fun environment, with a talented, diverse, and forward-thinking team.', 'Demonstrated communication and collaboration skills, and an ability to develop team members to learn and grow', 'Demonstrated self-motivation to work independently, as well as a part of a high-performing team', 'Experience working with source control systems', 'B.S. in computer science, engineering or related field (or significant related experience)', '5+ years development experience, with a demonstrated ability to decompose complex problems and create simple solutions. Java language preferred', 'HTTP/REST-based Web Services', 'MySQL', 'Hadoop YARN/Spark/Hive', 'Cassandra/HBase', 'Storm/CASK', 'Kafka/Flume', 'Git', 'Continuous Integration / Deployment']",2020-08-08 13:25:44
Data Scientist (Coordinated Campaign),Democratic National Committee,4.1 out of 5,Remote,"['Create predictive models of voter and supporter behavior.', 'Prepare and analyze datasets to extract meaningful campaign insights.', 'Employ supervised and unsupervised learning techniques, along with other statistical methods, to solve complex optimization problems.', 'Contribute to testing and experimentation design, infrastructure, and implementation.', 'Contribute to broader methodological standards across analytics team.', 'Collaborate with analysts, data scientists, and engineers to produce deliverables.', '2-4+ years of experience applying data and advanced analytics tools in a commercial, political, or non-profit setting, or equivalent academic experience (such as a postgraduate degree in a quantitative field).', 'Fluency in Python or R', 'Familiarity with executing all components of predictive modeling, including data collection and cleaning, model building using regression and other machine learning techniques, and model validation.', 'Ability to communicate technical concepts to a non-technical audience, both in writing and verbally.', 'Experience manipulating data in SQL.', 'Knowledge of experimental design and causal inference.', 'Experience volunteering or working on a political campaign data team, in polling, or with the Voter File']",2020-08-08 13:25:44
Data Engineer,COTA,3.9 out of 5,"Boston, MA","['Develop and maintain various data ETL processes and the data warehouse', 'Implement quality monitoring to report on the accuracy and relevancy of processed data', 'Support data analytics requests for bespoke reports and data exports', 'Understand the available architectures and technologies, assess the available options', 'Catalog our overall schema design and reference data', 'As part of a team, own data-centric processes, develop alerts for errors and service issues, and respond to alerts', 'Contribute, shape, improve the way we use and manage infrastructure', 'Perform specialized data investigations to support analytics and custom reporting scenarios', 'Participate in code reviews with a goal of understanding the overall data pipeline and ensuring data quality', 'Holds a Bachelor’s degree in Computer Science, Information Systems, or related major, or equivalent work experience', 'Able to write well-documented, reusable, and testable code', 'Strong working knowledge of Postgres or other relational databases', 'Ability to write complex SQL queries for ETL or reporting', 'Experience with R or Pandas a plus', 'Proficiency in distributed version control systems such as git or mercurial (we use git).', 'Proficiency working as part of an Agile development team', 'Experience with workflow/scheduling frameworks a plus.', 'Design experience a plus', 'Ability to interact and communicate effectively with colleagues on requirements and set expectations accordingly', 'Ability to work independently as well as with a team', 'Excellent written and oral communications', 'Energetic and self-starting']",2020-08-08 13:25:44
Junior Business Intelligence Data Engineer,MotorTrend Group,4 out of 5,"El Segundo, CA 90245","['Collaborate with product teams and data analysts to design and build data-forward solutions', 'Build and deploy streaming and batch data pipelines capable of processing and storing petabytes of data quickly and reliably', 'Integrate with a variety of data metric providers ranging from advertising, web analytics, and consumer devices', 'Build and maintain dimensional data warehouses in support of business intelligence tools', 'Develop data catalogs and data validations to ensure clarity and correctness of key business metrics', 'Drive and maintain a culture of quality, innovation and experimentation', 'Deliver strong Python and SQL development and maintenance techniques surrounding data movement to include technologies', 'Investigate and understand different data sources and ability to connect to a wide variety of 3rd party APIs', 'Design, enhance and implement ETL/data ingestion platform on the cloud', 'Development of ETL source and target mapping design/specifications based on the business requirements. Create ETLs/ELTs to take data from various operational systems and create a unified/enterprise data model for analytics and reporting', 'Develop load and transformation processes in support of the requirements, validate that they meet business and technical specifications, manage ongoing maintenance of the system and data, and make recommendations for process improvements to optimize data movement from source to target', 'Provide production and operational support to existing ETL jobs. Monitor and manage production ETL jobs to verify execution and measure performance to assure ongoing data quality and optimization of the system to manage scalability and performance and identify improvement opportunities for key ETL processes.', 'Strong troubleshooting and problem-solving skills in large data environment', 'Capable of investigating, familiarizing and mastering new data sets quickly', ""Bachelor's degree – Computer Science or equivalent"", 'Strong background in scripting language using Python, Bash, Perl, PHP or any other language to solving data problems', 'Experience with relational SQL and NoSQL databases, including Postgres, ,Neo4j and MongoDb', 'Experience with Big Data tools; Hadoop, Spark, Kafka, Hive etc', 'Proficiency with the AWS cloud services : EC2, EMR, RDS, S3, Redshift (spectrum)', 'Proficiency with data exchange types and protocols (json, xml, soap, rest)', 'Experience with Stream Processing systems: Storm ,Spark-Streaming etc', 'Experience with BI tools like Tableau or any other open source BI tools etc.', 'Knowledge of the Python data ecosystem using pandas and numpy', 'Data integration tools', 'Proficiency in SQL, data modeling, and data warehousing', 'Excellent problem solving skills', 'Exposure to cloud platforms (preferably AWS)', 'The ability to sit for prolonged period of time and view computer screen.', 'Microsoft Office Suite (Outlook, Word, Excel, PowerPoint)', 'SQL, MySQL or other relational databases', 'Linux, Python, AWS Stack (EC2,EMR S3, Redshift)', 'Tableau or any other data visualization tool', 'SiteCatalyst (Omniture)/Google Analytics or any other web analytics tools experience (Nice to have)', 'Work is performed in an office environment that is well lit and ventilated.']",2020-08-08 13:25:44
Data Engineer,eHana,N/A,"Boston, MA","['Permanent unrestricted legal right to work in the US required', '5+ years of professional experience', 'Advanced skills in SQL and ETL tools', 'Programming experience in Powershell, C#/.NET, python, or similar technologies', 'Creatively addressing customer challenges using all the quantitative and technological skills and tools at your disposal', 'Independently managing project goals, closing open loops, and ensuring your high-quality work output is both accessible to and actionable by end users', 'Coordinating directly with eHana’s implementation, product, and engineering teams to ensure smooth flow of data and intuitive user experiences', 'Developing management reports, dashboards, tools, and user interfaces that effectively address real-world customer needs using both eHana and external data sources', 'Continually tracking emerging trends and best practices via journals, academic papers, and events, around behavioral health data and integrating industry developments into eHana’s product suite']",2020-08-08 13:25:44
Data Engineer,Fayetteville Public Works Commission,4.3 out of 5,"Fayetteville, NC 28301","['Thorough knowledge of ingestion, processing frameworks and storage engines', 'Thorough knowledge architecting distributed systems, creating reliable pipelines, combining data sources, architecting data stores', 'Thorough knowledge of batch and stream processing', 'Thorough knowledge of Linux and command line tools such as grep, awk, etc.', 'Thorough knowledge of SQL and programming such as Java, Python, Scala, R, etc.', 'Thorough knowledge and holistic understanding of data as an asset', 'Thorough knowledge of safety rules/regulations/procedures, as applicable', 'Thorough knowledge in operating computers and applicable software including Microsoft Office tools', 'Ability to design and implement data models', 'Ability to unlock additional value from data through completion of feasibility studies for assigned use cases', 'Ability to use SQL for queries and report building', 'Ability to translate logical models into physical models, adding appropriate physical objects to create the objects within the data store (e.g., indexes, sequences, etc.)', 'Ability to interpret complex business requirements and create data models across multiple applications that support business goals', 'Ability to solve problems independently and provide recommendations for continuous improvement', 'Ability to ensure quality control in all work products/outputs', 'Thorough knowledge of math concepts and formulas required for data analysis and reporting', 'Ability to work as part of a cross functional team', 'Ability to use strong analytics skills in interpreting and visualizing data', 'Ability to create and maintain reports/records, spreadsheets, documents, tables, etc.', 'Ability to organize/prioritize work and provide excellent customer service', 'Ability to maintain knowledge on current and emerging technologies and evaluate the impact of new applications and technologies on data structures', 'Ability to work with staff across all divisions to maintain data models and processes that are scalable, adaptable, and in synchronization with ever-changing business needs', 'Ability to perform troubleshooting/root cause analysis to pinpoint issues and devise resolutions for data/reporting issues', 'Ability to share information and insight on source data structures in order to support decision-making for technical and functional modifications to enterprise software applications', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', '8 Hour Shift', 'Monday to Friday', 'Data Management: 5 years (Preferred)', 'Associate (Preferred)', 'United States (Preferred)', 'www.faypwc.com', 'https://www.facebook.com/faypwc', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:25:44
Contract Recruiter - Fully Remote,ASSURANCE,3.2 out of 5,Remote,"['Experience recruiting in a high volume environment', 'Exceptional ability to work self-sufficiently', 'A passion for full-cycle recruiting, from source to close', 'Data-driven approach to your work - metrics keep you focused and motivated', 'Ability to conduct screens and capture comprehensive notes', 'Comfort in modern applicant tracking systems', 'Experience recruiting insurance professionals', 'Passion for operating in a fast-paced startup environment']",2020-08-08 13:25:44
Data Visualization Engineer II,Blue Margin,N/A,"Fort Collins, CO 80524","['Develop accurate reports in Power BI that are not only visually engaging, but also make customers’ data accessible and actionable', 'Regularly interact with clients for project updates and inquiries', 'Create, enhance and troubleshoot data models in Power BI and Visual Studio', 'Author documentation of customer reporting requirements and finished reports', 'Craft and use T-SQL queries for data validation', '1-2 years of experience in Power BI Desktop creating tables, graphs, drill downs, drillthroughs, bookmarks, and KPIs', 'Working knowledge of Power BI Service and how to configure it', 'Ability to create intermediate to advanced DAX calculations using functions such as Calculate, Summarize and Filter', 'Experience creating T-SQL queries in SSMS', 'Comprehensive grasp of data visualization methods', 'Familiarity with data modeling', 'Broad business experience with a proficient ability to talk to executives in business terms', 'Professional demeanor', 'Experience using Visual Studio 2017/2019, DAX Studio, Tabular Editor, ALM Toolkit', 'Familiarity with tabular data models', 'Comfortable with manipulating data in Power Query Editor', 'Company Core Values: Embrace Transparency, Choose to Be Positive, Be Efficient/Systematize, Pursue Learning, Be Generous', 'Weekly personal and professional development programs for all', 'Teamwork—we maintain company-wide interaction and communication', 'Entrepreneurism – we want everyone on our team to be eager to adapt and evolve with our advancing business. We are looking for someone who is comfortable wearing more than one hat.', 'This job may require moderate physical effort including lifting materials and equipment of less than 50 pounds and involves viewing a CRT or VDT screen more than 80 percent of the time. The job will take place in a normal office environment with controlled temperature and lighting conditions. The position may require some travel and occasional participation in off-site functions. This position requires standing or sitting for long durations.', 'Starting salary for this position is between $70,000-$75,000 and is commensurate with experience and qualifications. This position comes with a comprehensive benefits package consisting of medical and dental coverage, paid sick leave, vacation, and a retirement plan.']",2020-08-08 13:25:44
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:25:44
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:25:44
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:25:44
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:25:44
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:25:44
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:25:44
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:25:44
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:25:44
Linguistic Engineer,Facebook,4.2 out of 5,"Redmond, WA","['Build datasets, pipelines, and models for ML applications.', 'Clearly communicate with project stakeholders.', 'Identify best practices and improve procedures across data systems.', 'Drive and deliver projects from conceptualization through launch and beyond with continual improvement and support.', 'Design and conduct product experiments.', 'Work in a dynamic, ambiguous work environment.', 'Be self-driven and prioritize multiple work streams.', 'Collaborate seamlessly with cross-functional teams.', '2+ years of work experience as data scientist, software engineer, computational linguist or in similar role.', 'Experience with programming and data analysis with languages and platforms such as Python, SQL, PHP/Hack.', 'Experience with text analysis, scripting, relational database, No SQL databases or similar.', 'Experience shipping multiple products across various platforms.']",2020-08-08 13:26:33
Cloud Modernization Engineer,AlignWorks LLC,N/A,"Wilmington, DE 19802","['Experience moving legacy application, Mainframe, etc. to the Cloud environment & data center migrations. The candidate should have an understanding of both infrastructure and application development', 'Comes from a coding/development background since they will need to often sit with the dev team, whiteboard and solution with them as they work through the migration', 'Experience with Cloud Foundry/AWS', 'This candidate will help modernize and optimize applications to move them into the new data centers', 'Experience working with API gateways and rethinking/rearchitecting them', 'Pivotal Cloud Foundry (PCF), Docker / Kubernetes / Microservices, DDD', 'Cloud Data Centers/Application Migration', 'Experience in Application Design Development on Java/J2EE/SOA/Webservices (SOAP/REST)', 'Hands on Experience in SOAP/REST API Design and Development (Preferred using Spring/Spring Cloud/Netflix-OSS/CICD)', 'Hands on experience with one of the Cloud Platforms: PCF, AWS, Google or Azure', 'Cloud Application Design and Development on PCF or AWS Cloud Platforms using DDD', 'Hands on experience of Container technologies, such as Docker or Kubernetes', 'Enterprise Integration Patterns – especially for Cloud Native applications', 'Proficient in either application, data, or infrastructure architecture disciplines - TOGAFE9 Enterprise Architecture', 'Understanding of DevOps principles, tools and the intersection with cloud architecture', 'Excellent written and oral communication skills and demonstrated ability to interact with all technical and nontechnical members of the organization ""', 'Lead large scale Modernization & Data Center Migration Initiative', 'Hands on Experience in SOAP/REST API Design and Development (Preferred using Spring/Spring Cloud/Netflix-OSS/CICD)', 'Cloud Application Design and Development on PCF or AWS Cloud Platforms using DDD', 'Proficient in either application, data, or infrastructure architecture disciplines – “TOGAFE9 Enterprise Architecture.""', 'Monday to Friday', 'Are you a U.S. citizen or Green Card holder?', 'Likely', 'Yes', 'One location', 'Outcome-oriented -- results-focused with strong performance culture', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'A job for which people with disabilities are encouraged to apply', 'No']",2020-08-08 13:26:33
Data Analyst,Gainful Health,N/A,"New York, NY","['Working with the CTO and COO to discover insights in the data.', 'Plan ways to test and measure the insights from above.', 'Provide suggestions for how to meet our customers needs, keeping in mind business constraints.', 'Support backend and frontend engineers in their data needs', 'Support growth marketing team to help efficiently test and evaluate different initiatives', 'Be an owner of the Looker platform in order to allow other team members to access the data they need', ""Bachelor's Degree or equivalent"", 'Basic understanding of SQL', 'Expert in Excel or another data analysis tool', 'Relentless attitude toward continuous improvement', 'Interest or experience in nutrition, wellness, or food/bev', 'Desire to work on a small team and self-starter to quickly iterate on initiatives', 'Experience in data science tools such as pandas (Python library)', 'Background in financial and/or subscription modeling', 'Gainful will cover 99% of the monthly cost of the Gold plan, or 85% of Platinum', 'If you opt out of group healthcare coverage, Gainful will add $250/month to your salary as a wellness stipend', 'Dental: Guardian EM Dental 10', 'Vision: CA Beam VSP Choice Plan 2', 'Health FSA', 'Dependent Care FSA', 'Commuter', 'Lunch every other Friday', 'Free snacks/beverages of every kind', 'Unlimited Gainful product & swag', 'Macbook Pro and whatever tools you need to do your job']",2020-08-08 13:26:33
"Data Center Capacity Integration, Quality and Reliability Engineer",Facebook,4.2 out of 5,"Washington, DC","['Partner with Operations, Design, Construction, Sourcing, and suppliers to improve overall quality for data centers that are in operation, under construction, as well as future data center designs, and retrofit projects.', ""From post-turnover of the data center to the end of the equipment's lifecycle, lead investigations and communication of equipment quality issues with the cross-function team."", 'Issues Corrective Action Requests (CAR), quality alerts, service bulletins and report out to management the investigation status for equipment failures being addresses by your team.', 'Establish and lead the Continuous Improvement Program for critical equipment suppliers until CARs are closed.', 'Prioritize Component & System Reliability Reports for disposition through the supplier CAR process or to be addressed by our cross functional partners. Create a monthly status report.', 'Upon request, assist data center management during Facility Incident Report meetings by facilitating root cause analysis and identification of corrective and preventive actions.', 'Travel up to 25% of the time to Facebook’s data centers and supplier’s sites.', ""Bachelor's degree in an engineering or technical discipline."", 'Minimum 10 years of experience addressing equipment issues in mission critical operations using quality management tools to identify and solve problems.', 'History of leading cross functional teams with suppliers to achieve successful solutions using project management tools, with proven interpersonal and organizational experience.', 'Can statistically analyze data to identify quality trends, confirm effectiveness of corrective actions, confirm equipment reliability, and to create metrics that drive customer value.', 'Experience reviewing and applying lessons learned to prevent occurrence in future equipment.', 'Experience identifying gaps in a Quality Management System and create department processes, procedures, and standards that are compliant.']",2020-08-08 13:26:33
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 13:26:33
Sr. Data Engineer,Hasbro,4.2 out of 5,"East Providence, RI","['Write routines and build data pipelines to ingest, clean, and prepare data for analysis. Develop views and aggregated datasets that can be easily loaded into analytical tools.', 'Conduct analysis. Using descriptive and exploratory techniques, text analytics, and statistical methods to help answer business questions. Prepare and communicate results to other members of the Advanced Analytics team and to business partners.', 'Expand Hasbro’s data model by incorporating internal Hasbro and external third-party data. Identify data sources and catalog metadata.', 'Provide guidance on appropriate infrastructure and understand how business requirements map onto infrastructure needs and toolset.', 'Support architecture plan to accommodate existing and future datasets. Create business processes for on-boarding new data sources.', '5+ years of experience in Data Engineering, Analytics, Consulting, or a related data/quantitative field.', 'B.S. in a quantitative field (Computer Science, Engineering, Economics). Advanced degree/MS preferred.', 'Hands-on experience with ""big data"" platforms including Hadoop and Spark as well as experience with traditional RDBMS (SQLServer, Oracle).', 'Proficiency with Python, Pyspark, shell scripting, SQL and Hive.', 'Experience with cloud-based data tools and platforms (Azure preferred, Google or AWS are fine).', 'Knowledge of reporting and visualization tools (Tableau, Power BI, Spotfire).', 'Ability to design and build a framework to orchestrate data pipelines.', 'Familiarity with data modeling and data architecture concepts.', 'Project management capabilities, able to take initiative, coordinate and prioritize multiple projects and shifting priorities.', 'Experience in Business Analysis, Business Knowledge, Software Engineering, Data Management and Technical Solution Design.']",2020-08-08 13:26:33
Big Data Engineer,ScienceSoft USA Corporation,N/A,"McKinney, TX 75070","['Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities;', 'Implementing ETL process;', 'Monitoring performance and advising any necessary infrastructure changes;', 'Defining data retention policies.']",2020-08-08 13:26:33
Big Data Engineer,Rackspace,3.8 out of 5,"Denver, CO","['Build complex ETL code', 'Build complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL', 'Work on Data and Analytics Tools in the Cloud', 'Develop code using Python, Scala, R languages', 'Work with technologies such as Spark, Hadoop, Kafka, etc.', 'Build complex Data Engineering workflows', 'Create complex data solutions and build data pipelines', 'Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates', 'Capture and share industry best practices amongst the community', 'Attend and present valuable information at Industry Events', 'Traveling up to 50% of the time', '3+ years design & implementation experience with distributed applications', '2+ years of experience in database architectures and data pipeline development', 'Demonstrated knowledge of software development tools and methodologies', 'Presentation skills with a high degree of comfort speaking with executives, IT management, and developers', 'Excellent communication skills with an ability to right level conversations', 'Technical degree required; Computer Science or Math background desired', 'Demonstrated ability to adapt to new technologies and learn quickly']",2020-08-08 13:26:33
Environmental Scientist or Engineer (Jr. Level),Tetra Tech,3.8 out of 5,"Newark, DE",[],2020-08-08 13:26:33
"Data Engineer, Prime Video",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', '5+ years of relevant experience in business engineer role, including data warehousing and business intelligence tools, techniques and technology, as well as experience in diving deep on data analysis or technical issues to come up with effective solutions', 'BS degree in math, statistics, computer science or equivalent technical field', 'Experience in data mining structured and unstructured data (SQL, ETL, data warehouse, Machine Learning etc.) in a business environment with large-scale, complex data sets', 'Design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for business intelligence analytics in support of prime video content analytics.', 'Implement data structures using best practices in data modeling, ETL/ELT processes, and SQL, Redshift, and OLAP technologies.', 'Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture.', 'Analyze source data systems and drive best practices in source teams.', 'Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance.', 'Produce comprehensive, usable dataset documentation and metadata.', 'Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers.', 'Proven communication (verbal and written) and interpersonal skills', '8+ years’ experience in Datanet or other ETL technologies', '8+ years’ experience in Tableau including advanced dashboarding', '5+ using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies']",2020-08-08 13:26:33
Data Engineer - Analytics,Imperial PFS,3.2 out of 5,"Kansas City, MO","['Develop and maintain a verified analytics database.', 'Work closely with Analysts to prepare data to be used in predictive/prescriptive modeling.', 'Develop data pipelines to feed continuous learning models in a production environment.', 'Assist in transitioning data sources to the Azure cloud.', 'Integrate external data sources to enrich internal data.', 'Explore ways to enhance data quality and reliability.', '4-6 years of experience in similar roles', 'Background in statistics and analytics', 'Technical expertise with data models and data mining', 'Experience in data pipeline and workflow management', 'Hands-on experience with SQL database design', 'Proficient in at least one of the following programming languages: Python, Shell Scripting, Scala, Java', 'Experience with Big Data tools, such as Spark, Kafka, Hadoop, HBase, etc.', 'Experience with tools for authoring ML workflows and pipelines, such as Airflow, Kubeflow, etc.', 'Experience workiing with containers and container orchestration solutions, such as Docker, Kubernetes, Mesos, etc.', 'Experience with Cloud platforms, such as AWS, Azure, Google, etc.', 'Familiarity with Linux', 'Familiarity with the DevOp concepts']",2020-08-08 13:26:33
Validation Engineer,Teva Pharmaceuticals,3.7 out of 5,"West Chester, PA 19380","['The Validation Engineer must have thorough knowledge of global regulatory requirements for validation, including ERES (Part 11 and Annex 11) & current GAMP5 guidelines.', 'Support all aspects of the Validation Life Cycle from design through operation & maintenance to retirement.', 'Responsible for the preparation of site validation documentation such as qualification protocols, validation master plans, risk assessments & periodic reviews.', 'Work closely w/ Process Development, Manufacturing, & Quality Control to generate & execute PPQ protocols for the production facility supporting large molecule testing.', 'Prepare reports using data from Process Validation, In-process Manufacturing testing In-process QC testing & Finished Product QC testing.', 'Ensure validation testing performed by vendors is complete & accurate; work w/ vendors for issue resolution & validation deviation reporting.', 'Represent validation in multi-disciplinary teams focused on production & laboratory equipment & activities (commissioning, validation & computerized system validation).', 'Support the revalidation program.', 'Ensure site alignment with corporate standards & cGxP guidelines.', 'Authoring & revising standard operating procedures within the electronic documentation management system.', 'Technically independent & maintains up-to-date knowledge of validation standards & regulatory compliance requirements.', 'Work independently and/or with subject matter experts (SME) to implement and/optimize key validation and quality initiatives.', 'Work with QA & SME to initiate & implement corrective & preventive actions.', 'Support continuous improvement projects & activities.', 'Ensures training is up to date; provides training for validation contractors.', 'Bachelor of Science degree in Life Science or Engineering', '3+ years Validation experience in Biopharmaceutical products or combination of Validation & Engineering/Commissioning experience', '3+ years of experience of successful interfacing with Scientists, Quality, Operations & Information Technology groups to develop requirements, establish programs & manage day-to-day operation', '3+ years of experience in process performance qualification, manufacturing systems, data integrity & analytical equipment', 'Experience in process validation & continued process verification', '5+ years Validation experience in Biopharmaceutical products or combination of Validation & Engineering/Commissioning exp.']",2020-08-08 13:26:33
Data Analytics Engineer - Mid,CACI,3.8 out of 5,"Washington, DC 20005","['The Data Analytics Engineer - Mid is responsible for providing mid to senior level back-end support for projects related to investigations and litigation cases.', 'This includes managing the design, modeling, and implementation of a variety of databases and applications.', 'The Data Analytics Engineer – Mid will manage or assist with the gathering of a wide variety of data types from primary and secondary sources through diverse channels using a combination of methods that will be populated into the appropriate analytical tools employed by the Data Analytics Management team.', 'Working with and leading junior team members to perform systems and database maintenance are key components of the work to include designing/implementing ETL pipelines, preservation of source data, performance optimization, monitoring, and suggesting improvements.', 'Managing the design, development, implementation, maintenance and optimization of a variety of databases and systems to include designing logical and physical database structures, partitioning of tables, data loading and validation, all aspects of security, monitoring, and performance tuning', 'Maintaining database dictionaries, and monitoring standards and procedures', 'Providing technical guidance to management, the team, and the customer in regards to implementation of highly advanced technical solutions', 'Supporting all dimensions of analysis including data transformations, sourcing, mapping, conversion and loading data', 'Collaborate across teams in order to quickly adapt to emerging and dependent technologies', 'Continually interact with teams to design and implement innovative data solutions that will provide key decision making abilities', 'Establish and maintain documentation for all design, development, and maintenance activities to include database entity relationship diagrams, ETL processes, source code version control, and automated maintenance processes.', 'Perform routine source code reviews of ETL processes for defects, performance tuning, or changes in source data format', 'Deliver assignments by established deadlines. Keep management well-informed on a timely basis of progress, status and/or concerns for each assignment', 'Develop and maintain standards for database implementation, maintenance, and optimization', 'Implement, maintain and test Disaster Recovery methodology for all production databases.', 'Reviews performance and capacity planning reports and makes recommendations to management', ""Bachelor's degree or equivalent, and 6 years of applicable experience."", 'Experience with the design, implementation, administration, and maintenance of a variety of highly complex databases (typically SQL Server, Teradata, DB2, Oracle, MySQL, or PostgreSQL) to include implementing security and access methods', 'Ability to work at OS level on Linux and Windows, writing scripts and configuring storage', 'Experience with ETL of large data sets using Python, Teradata, SSIS, or Talend to source, load, and verify data of various format.', 'Experience working in AWS cloud environments', 'Experience with automated tools for database design and implementation', 'Ability to embrace and lead technological change and development', 'Experience with developing procedures relating to database and application security including procedures by which access is authorized, enabled, changed and withdrawn', 'Experience with identifying and implementing enhancements to improve performance and reliability of existing database systems.', 'Experience with the implementation, testing, and maintenance of Disaster Recovery for various databases.', 'Experience with performing threshold forecasting, sizing, capacity planning, and trend analysis.', 'Experience with performance monitoring and summary table creation.', 'Experience administering databases in AWS environments', 'Experience with ETL and Database management in direct support of Tableau Server', 'Experience with schema development, ETL, and database management in IBM I2 Enterprise Insight Analysis (EIA) Opal w/ I2 Connect', 'Experience with litigation support, investigations, or administering Litigation Support tools', 'Normal demands associated with an office environment.', 'Ability to work on computer for long periods, and communicate with individuals by telephone, email and face to face.', 'Some travel may be required.', 'We’ve been named a Best Place to Work by the Washington Post.', 'Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.', 'We offer competitive benefits and learning and development opportunities.', 'We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.', 'For over 55 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.']",2020-08-08 13:26:33
Sr. Data Engineer - Cloud Services,"2nd Watch, Inc.",N/A,Remote,"['Operates with the highest levels of integrity', 'Thinks Big and takes on Big Challenges', 'Has a continuous thirst for knowledge and is a perpetual learner', 'Strives to make themselves and everyone around them better', 'Has a passion for technology', 'Owning the technical engagement and ultimate success around specific implementation projects.', 'Developing a deep expertise in enterprise cloud technologies and services.', 'Being subject matter expert and taking on a consultative role as it pertains to cloud adoption.', 'Ensure that our applications and infrastructure are designed and implemented to the highest security standards thus maintaining and enhancing customer trust', 'Evangelize security within 2nd Watch and be an advocate for keeping customer information secure', 'Demonstrated ability to think strategically about business, product, and technical challenges', 'Other duties as assigned', 'Demonstrated experience building and maintaining cloud-native data lakes', 'Demonstrated experience providing customer-driven solutions, support or service.', 'In-depth knowledge of SQL or NoSQL and experience using a variety of data stores (e.g. RDBMS, analytic database, scalable document stores)', 'Extensive hands-on Python programming experience, with an emphasis towards building ETL workflows and data-driven solutions.', 'Able to employ design patterns and generalize code to address common use cases. Capable of authoring robust, high quality, reusable code and contributing to the division’s inventory of libraries.', 'Expertise in big data batch computing tools (e.g. Hadoop or Spark), with demonstrated experience developing distributed data processing solutions.', 'Applied knowledge of cloud computing (AWS, GCP, Azure).', 'Familiarity with open source machine learning toolkits, such as sklearn, Keras, or TensorFlow.', 'Applied knowledge of data modeling principles (e.g. dimensional modeling and star schemas).', 'Understanding of relational database internals', 'Experience using tools for infrastructure-as-code (e.g. Docker, CloudFormation, Terraform, etc.)', 'Experience with software engineering tools and workflows (i.e. Jenkins, CI/CD, git).', 'Bachelor’s degree in computer science or related field, or equivalent combination of education and experience.']",2020-08-08 13:26:33
Jr. Data Engineer,IT Concepts Inc.,N/A,"Vienna, VA 22182","['We opened our doors in 2003 and have developed long-standing relationships with our customers, both public and private', 'We’re an SBA 8(a) and CVE certified Service Disabled Veteran Owned Small Business', 'We’re ISO 27001:2013, ISO 20000-1:2011, and ISO 9001:2015 certified and have CMMI DEV and SVC ML3 ratings', 'We’ve been named part of: Inc 5000’s Fastest Growing Private Companies in 2016; Washington Business Journal’s Fastest Growing Companies in 2015, 2016 and 2017; Washington Business Journal’s Best Places to Work in 2015, 2016 and 2017', 'We offer great benefits - Paid Time Off, Medical, Dental and Vision Insurance, 401(k) with company matching', 'We invest in our employees – We offer an annual training budget to our employees and opportunities for growth within the organization', 'We work hard, we play hard – We value work/life balance. We hold seasonal company events and a Washington Nationals Season Tickets lottery', 'Building solutions to give time back to analysts to perform analytics giving them more relevant and accurate data from the various data sources they may not be aware of while maintaining referenceable data provenance.', 'Research and develop categorization, correlation, and learning models for data analysis and data discovery', 'Collaborate with customers and stakeholders to devise possible solutions for data sharing environments', 'Keep up to date with the latest technology trends, communicating results and ideas to key decision makers', 'Implement new statistical or other mathematical methodologies as needed for specific models or analysis', 'Support synergizing data solutions with IT requirements management products for new initiatives to include data modeling', 'Communicate and coordinate with program stakeholders', 'You have', 'BS/BA; 0+ years of relevant experience', 'Experience implementing and building event driven architectures', 'Familiarity with event driven finite state machines', 'High proficiency in SQL to include schema design, data definition, and advanced queries', 'Experience with MPP data warehouses', 'Experience with scripting languages for automating repetitive tasks', 'Experience with creating automated data pipelines for complex systems', 'Extensive linux server management background', 'Can prototype visualizations with lightweight data visualization suites', 'Excellent verbal and written communications skills along with the ability to present technical data and approaches to both technical and nontechnical audiences', 'You value teamwork, demonstrate integrity and honesty, are passionate, innovative and strive for excellence', 'Must have an active Secret clearance.', 'secret (Required)', 'Fully Remote']",2020-08-08 13:26:33
Data Engineer,Next Generation Technology,N/A,"McLean, VA","['Responsible for delivery in the areas of: big data engineering with Hadoop, Python and Spark (PySpark) and a high-level understanding of machine learning', 'Develop scalable and reliable data solutions to move data across systems from multiple sources in real time (Nifi, Kafka) as well as batch modes (Sqoop)', 'Construct data staging layers and fast real-time systems to feed BI applications and machine learning algorithms', 'Utilize expertise in technologies and tools, such as Python, Hadoop, Spark, AWS, as well as other cutting-edge tools and applications for Big Data', 'Demonstrated ability to quickly learn new tools and paradigms to deploy cutting edge solutions.', 'Develop both deployment architecture and scripts for automated system deployment in AWS', 'Create large scale deployments using newly researched methodologies.', 'Work in Agile environment', 'Strong SQL skills to process large sets of data']",2020-08-08 13:27:16
Cloud/Data Integration Engineer (Telecommute),B3 Group Inc,3.9 out of 5,"Herndon, VA 20171","['Bachelor degree in Computer Science or related area', 'Must have at least 3-5+ years Azure experience', '3-5+ years of Data Integration experience with a minimum 4 years of IT enterprise experience', '3-5+ years of experience with system integration API such as Parquet, JSON, XML, XSLT, SQL, XML and VMF (Variable Message Formats)', '3-5+ years of experience with code development interfacing with SQL, NoSQL, other relational and non-relational databases', '3-5+ years experience with ETL using technologies such as Azure Data Factory, SSIS, Polybase, REST, SOAP, Native API, and WSDL, Logstash, Transporter, Python. JavaScript, XML, XSLT, JSON, SQL.', '3-5+ years of experience using technologies such as Spark, Impala, Unix Shell/KSH, control-M, SQL, Hive, and Oracle PL/SQL', 'Hands-on experience with Data Bricks or Azure HDInsight', 'Hands-on experience with process building & deployment, alert framework/exception handling, connectors / listeners', 'Experience in a DevOps model leveraging the following services GitHub, Jenkins, Docker, Kubernetes, Openstack.', 'Excellent communication, and relationship skills to articulate advanced technical topics and build consensus among clients and technical stakeholders • Strong interpersonal and collaborations skills working in a team-oriented environment', 'Strong analytical and problem-solving skills', 'Ability to adhere to defined processes & procedures, and suggest improvements', 'Ability to effectively prioritize and handle multiple tasks simultaneously', 'Strong technical documenting skills', 'Ability to obtain and maintain a public trust clearance', 'Experience supporting Department of Veterans Affairs (VA) and/or other federal organizations', 'Experience with Agile methodology, Scrum approach, SAFe and DevOps', 'Experience with Azure DevOps Services is a plus', 'Advanced SQL, NoSQL query and scripting. Experience with Python, Java', 'Experience with relational database systems (i.e. DB2, SQL Server) and non-relational databases such as (Azure SQL, Amazon RDBS, MongoDB, Hadoop tools)', 'Experience querying and populating Data Lake technologies (Azure Data Lake, Amazon S3)', 'Understanding of data design concepts (i.e. data modeling, data mapping, OLTP and OLAP).', 'Overall strong background in systems engineering, security engineering, architecting, enterprise integration, and interoperability in a complex systems environment; knowledge of emerging cybersecurity technologies', 'Experience modeling data, message, and service interoperability', 'Understanding of technical, operational, and management issues related to design, development, and deployment of complex and distributed systems', 'Understanding of interrelationships between critical infrastructure protection and cybersecurity', 'Terraform experience is a benefit', 'Azure Powershell knowledge is a benefit', 'You strive to be an expert in your field currently and in the future.', ""You take care in learning your customer’s business and drivers in order to ensure solutions meet not only technical needs, but also support their mission properly in a way that meeting their client's mission."", 'You like to make your client look good.', 'You find solutions, where others only see problems.', 'You are proactive, you make and meet commitments, and you perform your duties exceedingly well.', 'You are aware of the client’s needs at all times and are well-versed in what both your team and B3 Group can offer them as a whole.', 'You have the ability to work with diverse, integrated, deliverable-driven teams to accomplish the larger mission.']",2020-08-08 13:27:16
BI and Data Analytics Engineer,"Baker Tilly US, LLP",N/A,"Milwaukee, WI 53202","['You are very well versed in BI and data analytics, SQL, the MS Stack, Azure and other cloud services.', 'You enjoy supporting a variety of industries and embedding yourself with client teams to work together to find a solution.', 'You enjoy being face to face with clients, understand who the key stakeholders on projects are, and positively influence the business need behind the use of data.', 'You are constantly looking to grow your education in technology and staying up to date with the latest trends.', 'You are a team player that encourages collaboration and has an intrapreneurial mind.', 'You enjoy sharing what you learned with the team and are willing to be a mentor to others.', 'You love to learn and enjoy putting yourself out of your comfort zone and have done or at least entertained the idea of speaking at tech events.', 'Enjoy building relationships with your colleagues through social activities and team outings supporting work-life balance.', 'You have and are interested in maintaining different technical certifications.', 'You will be responsible for working within an agile environment to aid in the delivery of a managed service defined by the Architect of Project Manager.', 'Have strong experience building out data warehouses.', 'Lead or support the day to day sprint activities provided to you by your pod leader.', 'Work to understand business processes and possible improvements across an array of industries.', 'Utilize your scoping talents to help identify more areas within the business that our team can successfully impact for future projects.', 'Have hands on experience in Microsoft business intelligence technologies that may include:SQL database serverSQL server integration servicesSQL server analysis services/ Azure analysis servicesSQL server reporting servicesAzure SQL Database (PasS, IaaS, DaaS)Azure SQL Data WarehousePower BITableau', 'Have at least 4 years of experience working within these technologies as well as other backend tech.', 'Apply different data modeling techniques and functional knowledge to both your internal team and external partners.', 'Exhibit responsibility and accountability towards quality completion of projects and consistently hitting project timelines.', 'Strong verbal and written communication skills and are not ashamed to ask questions or raise concern on projects.', 'Outstanding customer service skills following proper business requirements and human resources expectations.', 'Disciplined to be able to work in a variety of business environments.', 'Ability to travel potentially up to 50% of the time.', 'Maintained a Bachelor’s degree in Computer Science, Engineering, Math, Information Technology, or other related discipline.']",2020-08-08 13:27:16
Product Engineer,Mishimoto,3.4 out of 5,"New Castle, DE","[""It's a gearhead's dream – design and develop performance automotive products"", 'We make way for play – join us to blow off steam and play Ping-Pong, Air Hockey, Foos-Ball or use our Large Screen so we can rock Mario-Cart.', 'We take a breather – enjoy an in-house gym, massage chair, and healthy-snack vending machine.', 'Our workplace is beautiful – work in an office designed to stimulate creative thinking.', 'The employee discounts rock – Get exclusive access to Mishimoto products and discounts from our partners.', 'The bennies are covered – medical, dental, vision, paid time off, 401(k) w/ 4% match, Long Term and Short term disability insurance and life insurance paid for by Mishimoto.', 'Dog Days! Bring your dog to work.', 'Your typical week includes product design, fabrication, dyno testing, SolidWorks 3D modeling, and 2D drafting. If finding ways to make cars go faster and run cooler excites you, this may be your new home.', 'Continuous improvement - better-designed products are a result of you and the team brainstorming ideas and then implementing the changes.', 'Problem Solving - manufacturing issues happen. Your keen insight and troubleshooting will help Project Managers and Suppliers during the production process.', 'Data Analysis – an integral part of product design, you will create, analyse, and present data and engineering Reports that will help consumers understand and appreciate the performance and quality of our products.', ""You will also need an ability and willingness to assist in presentation of product discussions for social media video clips and installation videos. We're proud of your work and we want you to be able to share it with others."", 'Be a champion of growth and change for the department and for the company – always excited for a new challenge.', 'Three -five years experience in Orignal Equipment Manufacture; Auto Manufacturing; heat exchangers; Engine Cooling.', 'S. in Mechanical Engineering from an ABET-accredited university, or related degree', 'Proficiency with 3D-modeling software, specifically SolidWorks.', 'Proficiency in developing 2D drawings.', 'Basic and/or in-depth knowledge of automotive components and systems.', 'Knowledge of 3d Scanning equipment and applying to the design process.', 'Knowledge of 3d printers and applying to the product design process.', 'Experience with both fluid dynamics and thermodynamics.', 'Experience with manufacturing and quality control processes, material selection, and assembly methods.', 'Hands-on experience with vehicles and fabrication tools.', 'Timeliness and attention to detail are key.', 'Basic knowledge of Microsoft Excel, Word, and Outlook.', 'Strong communication skills –you know your stuff and you are able to engage with your colleagues in a positive, productive way.', 'An eye for cleanliness and organization (We keep a clean shop)', 'Demonstrated ability to work well with your colleagues.', 'Background in EFI tuning is a plus', 'Electromechanical design experience building custom machinery or test rigs.', ""Bonus points for having a personal passion for auto products and the industry. You'll be able to take your existing consumer mindset and put it to work. Nobody knows what a car enthusiast wants in a product better than a car enthusiast."", 'Must be able to lift 50 lb', 'Must be capable of standing, maneuvering, and working on vehicles for up to 8 hours per day', 'Must be comfortable working in a garage and machine shop environment', 'Light travel (less than 5%) may be required', ""Valid driver's license and ability to drive a manual transmission.""]",2020-08-08 13:27:16
Contract QA Engineer,Linden Lab,3.7 out of 5,Remote,"['Perform thorough testing of all payment and related services during our migration to AWS', 'Be responsible for maintaining test strategies, test cases, scripts and suites', 'Enter and update bugs in our defect tracking system (Jira)', 'Help the team triage defects/issues found throughout the project cycle', 'Work with Software Development Engineers to verify fixes and data integrity', 'Work with QA Engineers, Software Engineers in Test and Performance Engineers to run test automation used for validating accuracy and completeness of functional test cases and/or performance/load testing', 'Ongoing monitoring of web systems using industry standard applications', 'Communicate and coordinate with third party companies to test interactions between payment systems', 'Experience with at least one of the following: Python, Ruby, Javascript, PHP, HTML5, CSS3', 'Experience with Mercurial or Git VCS, and preferably with automated build systems such as TeamCity or similar', 'Experience with UNIX and shell scripting', 'Experience testing multiple platforms: Windows, Mac, Linux (Debian/Ubuntu)', 'Experience testing web applications/services and desktop client/server systems.', 'Experience using automated test tools such as, but not limited to, Selenium, FunkLoad, Behave, Lettuce or similar testing tools', 'Ability to work independently to triage issues and prioritize tasks', 'Familiarity with mySQL is a plus', 'Performance testing experience a huge plus', 'Able to effectively document testing procedures in test plans, wiki pages and web pages', 'Nice to have: experience with New Relic or other performance management systems', 'Proactive, driven individual with a strong work ethic', 'Aptitude to learn quickly and effectively', 'Sharp attention to detail', 'Ability to remain focused in a team-oriented environment', 'Able to multitask and take on multiple assignments at the same time', 'Able to communicate and collaborate effectively with remote teammates in various locations', ""A Bachelor's Degree in Computer Science strongly preferred"", '2+ years as a Software Quality Assurance Engineer with a background in functional, integration, and regression testing of web applications']",2020-08-08 13:27:16
Tableau Data Visualization Engineer,BCC Software LLC,3.4 out of 5,"Rochester, NY 14623","['Create responsive dashboards, reports, and visualization in Tableau.', 'Design and develop performant and scalable Data Sources from SQL, Textual or NoSQL databases to power Tableau visualizations.', 'Be a key contributor in our efforts to position BI customer-facing solutions for growth.', 'Work in an agile team environment to deliver results on a consistent iterative basis.', 'Communicate and keep your team up to date in daily standup meetings, hallway conversations, online team chats, and via documenting your work.', 'Participate in planning and sizing activities.', 'Influence product direction by Review requirements & provide feedback to product owners.', 'Demonstrably experienced in any of the fields of Software Engineering/Architecture, Data Analytics, Big Data, or Database Development/Warehousing.', 'Highly skilled in developing Tableau visualizations.', 'Experienced in scaling Tableau server(s), understanding of its components as well as how to configure and tuning them to achieve optimally performing visualizations.', 'Highly technical with hands-on experience of working with MS SQL Server or like relational and/or non-relational databases; Working knowledge and experience with Microsoft C#/.Net framework is a definite plus.', 'Actively practiced software engineering agile methodology of consistently delivering results.']",2020-08-08 13:27:16
Data engineer (Pyspark),Ace-stack LLC,N/A,"Carlsbad, CA",[],2020-08-08 13:27:16
Data Engineer,Columbia University,4.1 out of 5,"New York, NY","['Requisition no: 503035', 'Work type: Full Time', 'Location: Medical Center', 'School/Department: Biomedical Informatics', 'Grade: Grade 105', 'Categories: Information Technology, Research (Lab and Non-Lab)']",2020-08-08 13:27:16
Cloud Data Engineer III,Businessolver,2.6 out of 5,Colorado,"['Building fault tolerant cloud solutions for Data Engineering', 'Maintaining and Enhancing Existing Data Loads to the Data Warehouse and Data Lake', 'Maintaining Streaming Data from production Systems', 'Managing Backup/Restore/Versioning of Cloud Data Sources', 'Peer Reviewing code', 'May perform other duties as assigned.', 'Degree in Computer Engineering/Science or related field, with 7+ years of professional experience in database/data lake development', 'Proficient with processing data on relational databases like Oracle/SQL Server/MySQL/etc.', 'Proficient with developing on an MPP database Redshift/Teradata/Snowflake', 'Proficient handling large data sets using SQL and databases in a business and engineering environment', 'Proficient with operations in a Public Cloud Environment (AWS/Azure/GCP)', 'Proficient with ETL and Data Warehouse/Lake processes', 'Experience with Architecting Cloud Workflows', 'Experience in leading Multiple sprint project and Epics', 'Excellent verbal and written communication skills', 'Strong troubleshooting and problem-solving skills', 'Thrive in a fast-paced, innovative environment', 'Oracle, Postgres, EMR, Redshift, Linux experience', 'Familiar with computer science fundamentals including object-oriented design, data structures, algorithm design, problem solving, and complexity analysis', 'Experience with Agile Methodologies', 'Experience with complex/large data sets (Big Data)', 'Experience operating a Data Lake', 'Experience with Cloud Architecture/Engineering', 'Competitive pay, great benefits, and vacation time. We are an equal opportunity employer with competitive benefits including medical, dental, life insurance, disability, 401(k) with company match, among others.', 'Smart Casual Dress. No need to suit up, but we also have on-site dry-cleaning services for those that prefer to dress-up!', 'Charity and community involvement. Participate in a variety of ways to support those around us.', 'Learning & Development. Continue to learn about the industry through our online and instructor-led classes.', 'Recognition. Want some swag? Earn tons of it by helping out your co-workers through our employee recognition program.', 'Culture. Want a culture most dream of? Most companies talk about it, we live it. Come find out for yourself!', 'Weekly catered meals.Breakfast every other Mondays, lunch Wednesdays, and afternoon appetizers on Fridays encourage collaboration across our teams.', 'Fully-stocked kitchens.We know it takes fuel to perform, so we provide a kitchen stocked with healthy cereals, fruit, snacks, and beverages to keep you at the top of your game.', 'With a ""work hard/play hard"" atmosphere we all need a little stress relief at times.', 'If you need a boost, visit our fitness facilities to clear your head (Des Moines, Denver, Chicago, Dallas & Louisville)']",2020-08-08 13:27:16
"Data Engineer, Health Strategic Initiatives",Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Job', 'Company', 'Workflow scheduling/orchestration such as Airflow or Oozie', 'Big data warehousing (RDB or MPP DB) such as Oracle, Teradata, Postgress, Hive', 'Strong Python programming skills with an understanding of data analytics, linear algebra, and ML libraries such as Numpy, Scipy', 'Experience with query APIs using JSON, ProtocolBuffers, or XML', 'ML model deployment, serving, and performance monitoring']",2020-08-08 13:27:16
Data Engineer - Advanced Analytics,Blue Cross Blue Shield of Michigan,3.9 out of 5,"Detroit, MI 48226","['Design, develop, document and test advanced data systems that supports the manipulation of structured and unstructured data sets from disparate sources.', 'Identify, integrate and cleanse data source information for processing.', 'Document and communicate opportunities for improvement identified in the data, such as scalability or quality concerns.', 'Write and refine code to ensure performance and reliability of data extraction and programming.', 'Implement data structures using best practices for data modeling and visualizations.', 'Produce comprehensive and usable dataset documentation and metadata.', 'Work on concurrent projects of varying size and scope, adhering to timelines and objectives.', 'Bachelor’s degree in related field is preferred.', 'Three (3) years of advanced programming techniques and application design is required.', 'Experience in systems design and have a solid understanding of development, database development, testing, and integration methodologies is required.', 'Project management experience is preferred.', 'Intermediate knowledge of big data (i.e. Map/Reduce, YARN, HDFS, etc.), query building (i.e. PL/SQL, HIVE, Impala, Spark, etc.), programming (i.e. R, Python, C, Java, Ruby, etc.) and visualization tools (i.e. QlikView, Tableau, Web FOCUS, etc.).', 'Basic statistics modeling skills (i.e. linear regression, logistic regression, decision trees, random forests, etc.)', 'Intermediate skills in Microsoft Access, Word, PowerPoint and Excel.', 'Strong analytical, organizational and problem-solving skills.', 'Ability to effectively interface and present to management at all levels of the organization.', 'Ability to work independently and in a team environment.']",2020-08-08 13:27:16
Data Engineer,Kognetics,N/A,"Gahanna, OH","['Pythondevelopers who can confidently work unassisted and deliver high qualitysolutions:', 'Strongprogramming experience in- Python', 'Strongbackground in data structures, algorithm complexities and object-orientedprogramming in- Python, with knowledge of at least one- Python- web framework(Django).', 'Stronghands-on experience as an individual contributor in Conceptualize.', 'Designand Develop new features in the product Experience with NoSQL technologies.', 'Handson experience with Cassandra and Redis is good to have.', 'Passion,commitment, resourcefulness, and a drive to continue learning are essentialprerequisites. For this role, we’re also looking for someone who meets thefollowing criteria:', ""B. Tech/PhD/ Master's Degree inStatistics, Mathematics, Computer Science, or equivalent; 5+ years of datascience mining experience;""]",2020-08-08 13:27:16
Engineering Standards Engineer,LOCKHEED MARTIN CORPORATION,4 out of 5,"Coatesville, PA 19320",[],2020-08-08 13:27:16
Network Development Engineer,"Amazon Data Services, Inc.",3.6 out of 5,"Seattle, WA","['Job', 'Company', ""Bachelor’s Degree in a technology related field or equivalent experience to a Bachelor's degree"", '3+ years professional experience working in large scale networking environments.', 'Experience with internet routing protocols and concepts: TCP/IP, BGP, MPLS, ISIS and/or OSPF', 'Experience with network operating systems such as Cisco IOS and Junos.', 'Experience working in a Linux/Unix environment', 'Experience in automation via Bash/shell scripting and Perl/Python programming.', 'Deploy, scale and automate our network across multiple global datacenters. This includes existing footprints and greenfield locations.', 'Drive scaling of current network designs to meet the demand of our customers.', 'Create simple, repetitive deployment processes that increase both velocity and quality.', 'Work closely with our internal customers on designs/solutions; bringing those designs/solutions from concept to production.', 'Create and update our network standards and ensure that the network is deployed to these standards.', 'Create and implement changes on the network.', 'Work closely with our automation teams in defining the tools that allow us to scale at unprecedented volume.', 'Knowledge of network analysis fundamentals and robust troubleshooting skills; specifically, network performance analysis', 'Experience working with customers to diagnose a problem, and work toward resolution', 'Excellent verbal and written communication skills', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-08-08 13:27:16
Sr. Data Engineer,BICP,5 out of 5,"Portland, OR","['2+ years of experience with data engineering with emphasis on data analytics and reporting', 'Experience developing with scripting languages such as Shell and Python', 'Strong experience developing with PySpark, preferably leveraging AWS EMR managed service', 'Expert experience with SQL and Relational database engineering (Oracle, SQL Server, Teradata) with expert-level SQL abilities', 'Experience with agile delivery methodologies (Scrum, SAFe, Extreme Programming, etc.)', 'Experience working with source-code management tools such as GitHub and Jenkins', 'Ability to partner with business and technology team members, to understand business requirements and translate those into value-add technology solutions', 'Experience developing solutions in Snowflake', 'Experience with workload automation tools such as Airflow, Autosys.', 'Prior Kubernetes, Lambda, Spark Streaming etc.', 'Prior AWS DevOps knowledge', 'AWS: 1 year (Required)', 'Data Engineering: 1 year (Required)', 'Spark: 1 year (Preferred)', 'Python: 1 year (Preferred)', 'Snowflake: 1 year (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Health insurance', 'Team-oriented -- cooperative and collaborative', 'People-oriented -- supportive and fairness-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Monday to Friday', 'Day shift', 'www.bicp.com', 'Temporarily due to COVID-19']",2020-08-08 13:27:16
Data Engineer,Hawkfish,N/A,"New York, NY","['Develop modern processes for the ingestion, storage, and movement of data', 'Create and support an infrastructure that facilitates those processes as well as the downstream consumption and ethical access of that data', 'Define the interface between Hawkfish and data vendors, making the ingestion of data as easy as possible for both Hawkfish and its vendors', 'Provide guidance for and enforcement of best practices around data isolation and consumption', 'Maintain alerting, monitoring, and documentation to ensure the health, accessibility, and proper use of information', '4+ years of professional experience designing, developing, and releasing high-quality software', 'Strong proficiency in SQL and familiarity with either relational or NoSQL database technologies', 'Experience with Python', 'Experience in the development and execution of ETL or ELT pipelines', 'Demonstrated ability to collaborate with both technical and non-technical stakeholders, collecting requirements and interfacing with many other teams', 'Familiarity with designing large-scale systems with many moving pieces, ideally within a cloud computing framework', 'Broad knowledge and application of healthy code practices and CI/CD paradigms with Git', 'Experience with DBT', 'Experience with Terraform', 'Experience with Google Cloud Platform technologies such as BigQuery, Cloud SQL, Composer, Cloud Functions, Dataflow, and Cloud Storage', 'Working knowledge of Docker', 'Working knowledge of Airflow']",2020-08-08 13:27:57
Azure Data Engineer with Synapse/CosmosDB,Aroopa Inc,N/A,"New York, NY","['Experience in implementing Cosmos DB/Analysis Services/Synapse (or other) as the preferred solution for the item and hierarchy dictionary, loading the data and testing the performance of direct key-based access for storing and reading item hierarchy and item/attribute details.', 'Experience in analyzing data, create data models using various analysis services.', '25% travel required']",2020-08-08 13:27:57
Oracle Data Engineer,iknowvate technologies,N/A,"Boston, MA","['Expertise with Oracle 12c, data movement technologies, Spotfire, and proficiency in designing solutions', 'Excellent Design & Analysis skills with a demonstrated ability to align to long term strategies through interim states', 'Experience working on delivering solutions for globally distributed, large scale Agile software development teams', 'You will serve as an engineer and thought leader within our Engineering team. You will interface directly with business partners to understand problems & opportunities and recommend solutions. You will be a key player as we scale our platform to support forecasted growth.', 'You consistently drive strong collaboration, open communication, and reach across functional borders', 'You are able to understand business problems and able to design scalable solutions', 'You have a relentless commitment to quality and engineering excellence', 'You have an ability to design and build performant solutions that scale and support stringent SLAs', 'You are able to work successfully in an environment that encourages autonomy in the work that you do', 'You are motivated, an excellent communicator, can take initiative to solve problems, and can make decisions based on the value of the solutions we build.', 'You understand engineering best practices and have an aptitude to coach and mentor others on the team', 'As a data engineer, you will play a key role in shaping how our products are designed and developed', 'Bring creativity and innovation, and experiment where needed, to provide solutions that help us deliver for the business.', 'Position the organization for growing the Managed Accounts business']",2020-08-08 13:27:57
Senior Data Engineer,Attentive Mobile,N/A,"New York, NY","['Design, implement, and maintain an ever-growing ETL pipeline using state-of-the-art technology', 'Lead the burgeoning data engineering team', 'Establish best practices and standards for managing large collections of data', 'Discover and integrate with new data sources', 'Work closely with data analysts and data scientists, enabling them to provide insight into key performance metrics of the business', 'Identify ways to improve data reliability, efficiency, and quality', '5+ years of experience designing and developing a data warehouse, Snowflake preferred', 'Experience designing, developing, and maintaining a high-throughput and low-latency ETL pipeline', 'You are knowledgeable about data modeling, data access, and data storage techniques', 'Experience with big data tools such as Kinesis, Kafka, Spark, or Amazon EMR', 'Strong data-modeling skills. Good understanding and experience in building star schema and denormalized data structures.', 'Experience with SQL (MySQL or Postgres preferred), ETL, Python', 'Successfully implemented data applications and pipelines in the public cloud, especially Amazon Web Services', 'Robust health benefits packages including access to a 401k and various medical, dental and vision plans, and $100/month fitness reimbursement', 'Full support for remote work during COVID-19', 'Daily lunch delivery credit and other goodies sent to home', 'Regular company-wide social events (even virtually!)', 'Generous annual education stipend toward job-related external learning opportunities', 'An extremely enthusiastic team that appreciates collaboration']",2020-08-08 13:27:57
Data Engineer,Bombora,3.6 out of 5,"Reno, NV 89501","['Creating and refining bounded (batch) and unbounded (streaming) ETL and ML data pipelines that comprise our production systems', 'Advancing development and integration of our major analytics and ML codebases using modern and rigorous software engineering principles', 'Helping to support and maintain our live production ETL and ML pipelines and systems', 'Mentoring and advancing the development of your colleagues', 'Having fun in an environment of collaboration, curiosity, and experimentation', 'Develop applications, libraries and workflows with Python, Java, Apache Spark, Apache Beam, and Apache Airflow', ""Design and implement systems that run at scale on Google's Dataproc, Dataflow, Kubernetes Engine, Pub/Sub, and BigQuery platforms."", 'Learn, design and implement algorithms and machine learning operations, at-scale, using SciPy, PySpark, Spark Streaming, and MLBase libraries.', 'Learn and advance existing data models for our events, profiles and other datasets', 'Employ test-driven development, performance benchmarking, rapid release schedule, and continuous integration.', 'Participate in daily stand-ups, story planning, reviews, retrospectives, and the occasional outings to nearby local cuisine and / or culture.', 'Your background:', 'Education: B.S. / M.S. in computer science, physics, electrical engineering, applied mathematics, or equivalent experience.', 'Work experience: 3+ years of real-world development experience and 2+ years of experience with cloud and/or big-data platforms, GCP experience preferred.', 'Language Fluency: In Java / Python (at least 2 years of experience on commercial projects) and perhaps a few other languages.', 'Data wrangler: Driven by data and the ability to leverage data to understand systems.', 'Impactful and effective: Live and breathe TDD and agile methodologies in software to great impact', 'Character: Creativity, pragmatism, curiosity, and a good sense of humor', 'Working knowledge of:', 'Algorithms / Data Structures: Design patterns, efficiency, using the right abstraction for the task.', 'Functional Programming: Filters and maps, currying and partial evaluation, group-by and reduce-by', 'OOP: Object paradigms to build components, when needed.', 'Databases: Familiar with both relational (MySQL, PostgreSQL) and NoSQL (HBase, Cassandra, etc).', 'Data Processing at scale: Distributed computations, map-reduce paradigm, and streaming processing, Spark experience is helpful.', 'Build and release toolchains: Experience deploying projects in both Python (conda, setuptools, etc.) and Java (Maven).', 'Git: Comfortable working with git (resolving conflicts, merging, branching, etc).']",2020-08-08 13:27:57
Data Engineer,ECS Federal LLC,3.4 out of 5,"Fairfax, VA 22031","['Work closely with software engineers and architects to extract, transform and standardize data to prepare for ingest into machine learning development environments', 'Design and develop data services and/or pipelines as part of an Agile/Scrum team', 'Support continuous process automation for data ingest', 'Support the development and integration of ML algorithms for testing and operational deployment', 'Support Data enterprise for ML development', 'Work with program management and engineers to implement and document complex and evolving requirements', 'Perform multiple tasks simultaneously and successful perform under changing requirements and deadlines', 'Help cultivate an environment that promotes customer service excellence, innovation, collaboration, and teamwork', 'Secret Clearance', ""A Bachelor's Degree in Data Science, Math, Finance, Statistics, Information Management, Computer Science, Engineering, or equivalent field"", '2-7+ years of hands-on work experience in one of the related areas: Data Science, Computer Science or Computer Engineering', 'Proficient parsing / ETL-ing data into a variety of formats for ML applications, Test & Validation, metrics derivation', 'Proficiency with Python, R, Linux shell and scripting languages', 'Experience using statistical programming languages to extract and manipulate data', 'Technical proficiency with transforming structured and unstructured data sets', 'Familiarity with Hive, Pig, Elastic Search and data analytic tools', 'Excellent communication, and presentation skills with the demonstrated ability to communicate across all levels of the organization and communicate technical terms to non-technical audiences with an impeccable attention to detail', 'Advanced degree (Masters) in a technical discipline', 'Experience working with cloud technologies (Amazon Web Services, Microsoft Azure, etc.)', 'Experience working with Department of Defense (DoD) organizations or performers']",2020-08-08 13:27:57
Engineer I,University of Phoenix,3.7 out of 5,"Phoenix, AZ","[""Bachelor's degree in a technology field; OR"", 'Four (4) years of experience in most phases of IT systems deployments in one or more of the following areas: design and deployment of AWS solutions, experience with advanced business intelligence concepts, database physical structures, performance tuning of complex SQL statements, development and support of ETL processes; OR', 'Completion of Coding / IT Bootcamp', 'Experience working in an agile or scaled agile environment', 'Understanding and knowledge of commonly used concepts, practices and procedures within the Information Technology and Computer Science Field', 'Define, implement, and promote leading Business Intelligence applications applying best practices, development standards and operational guidelines', 'Develop ETL processes using best practice methodologies and in a manner consistent with existing database design objectives, experience with any of the following technologies for data transformation is a plus: Informatica, SSIS, Golden Gate, HVR; Airflow or GLUE', 'Exposure to Data Analytics workflows and technologies including : SQL, Phyton, R, Spark, Hadoop, S3, Redshift, Redshift Spectrum, Athena, RDS, Airflow, GLUE, Lambda, QuickSight, Tableau, or Power BI', 'Excellent oral and written communication skills to effectively interact with internal and external customers and department staff', 'Able to communicate well with others, to perform work in a team environment, direct and act as a resource for less experienced resources and relay necessary information as appropriate', 'Easily adapt to and embrace a fast moving and rapidly changing work environment', 'Demonstrate a growth mindset and exhibit a highly collaborative workstyle']",2020-08-08 13:27:57
"Data Engineer, Data Warehouse",Lighthouse,3.7 out of 5,Remote,"['Build and operate stable, scalable and highly performant data pipelines that cleanse, structure and integrate disparate big data sets into a readable and accessible format for end user analyses.', 'Construct, maintain and optimize data-marts and the Enterprise Data Warehouse to support reporting, analytics and business intelligence.', 'Collaborate with senior management, product development, finance, IT and other stakeholders in the development of optimal data products.', 'Develop tools to monitor, debug, and analyze data pipelines.', 'Design and implement data schemas and models that can scale.', 'Provide technical recommendations regarding buy vs. build decisions for different components of the data analytics infrastructure.', 'Define the simple and complex ETL processes for the EDW.', 'Write SQL queries to extract data and perform complex analytics.', 'Work with internal business customers to define and deliver effective data visualizations and scalable reporting solutions.', 'Serve as owner of the quality of the data as well as how the data is used and leveraged by the business.', 'Have a hands-on approach in bringing data insights to tackle business challenges.', 'Help drive cross-functional projects around enterprise data and analytics solutions.', ""Bachelor's Degree in Computer Science, Data Engineering, Data Analytics, Information Systems, Mathematics or equivalent."", '5+ years of relevant experience in data warehousing, data engineering, data analysis, business intelligence or similar roles.', 'Proficiency in one or more scripting languages.', 'Experience with compliance and certifications relevant to IT operations – ISO 27001, SOC 2 type 2, Sox, PCI, HIPAA', 'Experience with modern data warehouse platforms is a must. Proven track record of implementing data warehouse solutions for large companies. Experience with large scale and/or high performance database systems in an operational environment.', 'Knowledge of principles and practices of enterprise data warehouse development, data modeling, data governance.', 'Experience with data visualization and dashboarding tools such as Power BI, Tableau, etc.', 'Proficiency in normalized and de-normalized data models, data schemas, analytic cubes, etc.', 'Able to thrive in a fast-paced environment and manage competing priorities effectively.', 'Expert analytical and problem solving skills. Extreme attention to detail.', 'Excellent verbal and written communication skills.', 'Experience with ServiceNow, Salesforce.com, QuickBase, Microsoft Dynamics, Adaptive Insights and/or web development is a plus.', 'Experience in e-discovery industry or a service-based businesses is a plus.']",2020-08-08 13:27:57
Data Engineer,ITConcepts Inc.,N/A,"Washington, DC","['We opened our doors in 2003 and have developed long-standing relationships with our customers, both public and private', 'We’re an SBA 8(a) and CVE certified Service Disabled Veteran Owned Small Business', 'We’re ISO 27001:2013, ISO 20000-1:2011, and ISO 9001:2015 certified and have CMMI DEV and SVC ML3 ratings', 'We’ve been named part of: Inc 5000’s Fastest Growing Private Companies in 2016; Washington Business Journal’s Fastest Growing Companies in 2015, 2016 and 2017; Washington Business Journal’s Best Places to Work in 2015, 2016 and 2017', 'We offer great benefits - Paid Time Off, Medical, Dental and Vision Insurance, 401(k) with company matching', 'We invest in our employees – We offer an annual training budget to our employees and opportunities for growth within the organization', 'We work hard, we play hard – We value work/life balance. We hold seasonal company events and a Washington Nationals Season Tickets lottery', 'Building solutions to give time back to analysts to perform analytics giving them more relevant and accurate data from the various data sources they may not be aware of while maintaining referenceable data provenance.', 'Research and develop categorization, correlation, and learning models for data analysis and data discovery', 'Collaborate with customers and stakeholders to devise possible solutions for data sharing environments', 'Keep up to date with the latest technology trends, communicating results and ideas to key decision makers', 'Implement new statistical or other mathematical methodologies as needed for specific models or analysis', 'Support synergizing data solutions with IT requirements management products for new initiatives to include data modeling', 'Communicate and coordinate with program stakeholders', 'You have', 'BS/BA or MS/MA; 7+ years of relevant experience', 'Experience implementing and building event driven architectures', 'Familiarity with event driven finite state machines', 'High proficiency in MySQL, Postgres, RDS, to include schema design, data definition, and advanced queries', 'Experience with MPP data warehouses', 'Experience with scripting languages for automating repetitive tasks', 'Experience with creating automated data pipelines for complex systems', 'Experience providing subject matter expertise with Apache Kafka, Confluent Kafka, NiFi, or Elasticsearch.', 'Extensive Linux server management background', 'Can prototype visualizations with lightweight data visualization suites', 'Excellent verbal and written communications skills along with the ability to present technical data and approaches to both technical and nontechnical audiences', 'You value teamwork, demonstrate integrity and honesty, are passionate, innovative and strive for excellence', 'Must have an active Secret clearance.', 'event driven finite state machines: 3 years (Required)', 'MySQL, Postgres, RDS, to include schema design: 3 years (Required)', 'data engineering: 7 years (Required)', 'implementing and building event driven architectures: 4 years (Required)', ""Bachelor's (Required)"", 'Secret Clearance (Required)', 'Fully Remote', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Work from home', 'Flexible schedule', 'Relocation assistance', 'Professional development assistance', 'Tuition reimbursement', 'No: Not providing sponsorship for this job', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Monday to Friday', '8 hour shift', 'www.useitc.com', 'https://www.facebook.com/itconceptsinc', 'Only full-time employees eligible', 'Yes']",2020-08-08 13:27:57
Data Engineer,Emergere Technologies,N/A,"Chicago, IL","['Create and maintain optimal data pipeline architecture,', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field (Masters Preferred).', '5+ years of experience in a Data Engineer role', 'Experience with healthcare datasets, clinical data, payer/claims data, SDOH data, etc.', 'Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Skilled in problem-solving with strong attention to detail.', 'Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.', 'Excellent follow-up skills paired with the ability to multi-task and determine root causes.', 'Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.']",2020-08-08 13:27:57
Data Engineer,Grid Dynamics,N/A,"Mountain View, CA","['Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation', 'Work closely with data scientists and analysts to create and deploy new features', 'Write efficient and well-organized software to ship products in an iterative, continual-release environment', 'Monitor and plan out core infrastructure enhancements', 'Contribute to and promote good software engineering practices across the team', 'Mentor and educate team members to adopt best practices in writing and maintaining production code', 'Communicate clearly and effectively to technical and non-technical audiences', 'Actively contribute to and re-use community best practices', 'University or advanced degree in engineering, computer science, mathematics, or a related field', 'Strong experience working with a variety of relational SQL and NoSQL databases', 'Strong experience working with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience with at least one cloud provider solution (AWS, GCP, Azure)', 'Strong experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Ability to work in Linux environment', 'Experience working with APIs', 'Strong knowledge of data pipeline and workflow management tools', 'Expertise in standard software engineering methodology, e.g. unit testing, code reviews, design documentation', 'Experience creating ETL processes that prepare data for consumption appropriately', 'Experience in setting up, maintaining and optimizing databases for production usage in reporting, analysis and ML applications', 'Working in a collaborative environment and interacting effectively with technical and non-technical team members equally well', 'Relevant working experience with Docker and Kubernetes preferred', 'Ability to work with ML frameworks preferred', 'Knowledge of CI/CI processes and components', 'Experience with OKTA and Optimizely']",2020-08-08 13:27:57
Data Analytics Engineer - Lead,CACI,3.8 out of 5,"Washington, DC 20005","['The Data Analytics Engineer – Lead is responsible for providing senior level back-end support for projects related to investigations and litigation cases.', 'This includes managing the design, modeling, and implementation of a variety of databases and applications.', 'The Data Analytics Engineer – Lead will provide input into the selection of the appropriate data architecture for analysis and will manage the gathering of a wide variety of data types from primary and secondary sources through diverse channels using a combination of methods that will be populated into the appropriate analytical tools.', 'Working with and leading mid-level and junior team members to perform systems and database maintenance are key components of the work to include designing/implementing ETL pipelines, preservation of source data, performance optimization, monitoring, and suggesting improvements.', 'Managing the design, development, implementation, maintenance and optimization of a variety of databases and systems to include designing logical and physical database structures, partitioning of tables, data loading and validation, all aspects of security, monitoring, and performance tuning', 'Maintaining database dictionaries, and monitoring standards and procedures', 'Providing technical guidance to management, the team, and the customer in regards to implementation of highly advanced technical solutions', 'Supporting all dimensions of analysis including data transformations, sourcing, mapping, conversion and loading data', 'Collaborate across teams in order to quickly adapt to emerging and dependent technologies', 'Continually interact with teams to design and implement innovative data solutions that will provide key decision-making abilities', 'Establish and maintain documentation for all design, development, and maintenance activities to include database entity relationship diagrams, ETL processes, source code version control, and automated maintenance processes.', 'Perform routine source code reviews of ETL processes for defects, performance tuning, or changes in source data format', 'Deliver assignments by established deadlines. Keep management well-informed on a timely basis of progress, status and/or concerns for all team’s assignments', 'Develop and maintain standards for database implementation, maintenance, and optimization', 'Implement, maintain and test Disaster Recovery methodology for all production databases.', 'Reviews performance and capacity planning reports and makes recommendations to management', ""Bachelor's degree or equivalent, and 12 years of applicable experience."", 'Experience with managing/leading a team of ETL/Database Administrators', 'Strong experience with the design, implementation, administration, and maintenance of a variety of highly complex databases (typically SQL Server, Teradata, DB2, Oracle, MySQL, or PostgreSQL) to include implementing security and access methods', 'Strong experience with ETL of large data sets using Python, Teradata, SSIS, or Talend to source, load, and verify data of various formats', 'Ability to work at OS level on Linux and Windows, writing scripts and configuring storage', 'Experience administrating databases in AWS cloud environments', 'Experience with automated tools for database design and implementation', 'Ability to embrace and lead technological change and development', 'Experience with developing procedures relating to database and application security including procedures by which access is authorized, enabled, changed and withdrawn', 'Experience with identifying and implementing enhancements to improve performance and reliability of existing database systems.', 'Experience with the implementation, testing, and maintenance of Disaster Recovery for various databases.', 'Experience with performing threshold forecasting, sizing, capacity planning, and trend analysis.', 'Experience with performance monitoring and summary table creation.', 'Experience with ETL and Database management in direct support of Tableau Server', 'Experience with schema development, ETL, and database management in IBM I2 Enterprise Insight Analysis (EIA) Opal w/ I2 Connect', 'Experience with litigation support, investigations, or administering Litigation Support tools', 'Normal demands associated with an office environment.', 'Ability to work on computer for long periods, and communicate with individuals by telephone, email and face to face.', 'Some travel may be required.', 'We’ve been named a Best Place to Work by the Washington Post.', 'Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.', 'We offer competitive benefits and learning and development opportunities.', 'We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.', 'For over 55 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.']",2020-08-08 13:27:57
Sr. Big Data Engineer,Metistream,N/A,"Vienna, VA 22182","['Identify, recommend, and optimize solutions based on business requirements and customer challenges', 'Design and develop Big Data Hadoop and real-time architectures', 'Support pre-and post- sales activities to support company growth', 'Ensure the success of project engagements and fellow team members', 'Create technical documents and deliverables for MetiStream and customer use', 'Keep current with the Hadoop Big Data ecosystem technologies; continuously look for opportunities to innovate and learn', 'Share expertise and facilitate learning with MetiStream team members, customers, and the community at large', 'Travel at least 50% depending on customer needs', '8+ years’ professional IT experience with emphasis in Java or C++ design and development', '1+ years’ experience with cloud architectures and large data processing / Hadoop environments; ability to set up multi-node Hadoop clusters and write MapReduce jobs', 'Ability to integrate Hadoop Big Data ecosystem / Open Source technologies', 'Familiarity with DW/ETL/BI solutions and implementations', 'Familiarity with system administration and scripting tools such as bash, Python and/or Perl', 'Understanding of various data storage concepts (in-memory, NoSQL, columnar, etc.)', 'Specialized skills in either data visualization or analytics', 'Excellent communication/interpersonal skills including both written and verbal skills', 'Prior experience at top IT consulting company and/or software product company', 'BS/MS in Computer Science or related field', 'Familiarity with Apache Spark / Spark Streaming and associated Spark components', 'Understanding of event processing / real-time streaming concepts and principles', 'Specialized skills in SAS or R', 'Contributed to an Open Source software project, participated in an OS user/dev group, and/or created technical blogs', 'Simple and elegant solutions', 'A fast-paced start-up culture and being the first to take on a challenging task', 'Solving problems and discovering a creative twist that delights the customer']",2020-08-08 13:27:57
eBusiness Data Engineer,Merck KGaA,4.2 out of 5,"St. Louis, MO 63103","['Design, deploy and manage ETL pipelines and data architectures.', 'Build an inventory of data needed to implement architecture and create a vision for how data will flow through the organization.', 'Design, build, and maintain integrated data solutions such as “data lakes” and “data warehouses”.', 'Produce and enforce database development standards.', 'Collaborate with analytics and data science teams to design and plan data engineering solutions.', 'Develop and implement strategies and best practices to ensure appropriate access control and security of stored data.', 'Develop, validate, scale and deliver analytical solutions aimed at maintaining data quality.', 'Leverage system and process analysis skills to produce data strategies that create a seamless and uninterrupted experience for our data products and reports.', 'Implement measures to ensure data accuracy and accessibility, constantly monitoring and optimizing the performance of data management systems.', ""Bachelor's Degree in Computer Science, Data Analytics, Statistics, Applied Math, Data Science or related field"", '4+ years of experience with Structured Query Language (SQL), Relational Database Management Systems and Cloud Databases', '4+ years of experience with ETL Tools: Talend, Pentaho, DataFlow, ...', '4+ years of experience with SQL and NoSQL databases', '3+ years of experience with Programming skills such as R, Python, JavaScript, C/C++', 'Master’s Degree', 'Data Engineering Certification (Google’s Certified Professional-Data-Engineer, IBM Certified Data Engineer – Big Data, or CCP Data Engineer for Cloudera)', 'Digital Analytics tools such as Adobe SiteCatalyst, Google Analytics, Facebook Insights, Twitter Analytics, Optimizely', 'Reporting and Data Visualization tools such as Tableau, Qlik, Google Data Studio', 'Statistical Programming Packages such as R, S, SAS, SPSS', 'Ability conduct complex, important work independently']",2020-08-08 13:27:57
Data Engineer,Entera,N/A,"New York, NY","['Use Python, SQL, and R to improve upon a best-in-class data pipeline and develop our workflows', 'Contribute to cloud-first services that improve our reporting, analysis, and metrics collection efforts', 'Use agile software development processes to iteratively make improvements to our back-end systems', 'Mold front-end and back-end data sources to help draw a more comprehensive picture of user flows throughout our system', 'Deliver on detailed specifications for business intelligence and reporting needs', 'Contribute and further develop our data-driven culture', 'Work with product and engineering in cross-functional teams to deliver on improvements to our systems', 'MS or PhD in Computer Science, Mathematics, Statistics, Physics, Economics, or similar hard-science', '3+ years hands-on experience in Data + Analytics at growing product-driven tech companies', 'Proficiency in cloud services and modern ETL workflows', 'Advanced capabilities across Python, R, and SQL', 'Understanding of Spark', 'Strong analytical and problem solving skills', 'Working knowledge of Python web frameworks like Flask', 'Software development background']",2020-08-08 13:27:57
Radar Instrumentation Engineer,TRAX Test Services,4 out of 5,"Yuma Proving Ground, AZ","['Must have a Bachelor of Science degree in Electronic or Electrical Engineering or Physics or Mathematics with RF emphasis from an Accreditation Board for Engineering and Technology (ABET) accredited college or university and a minimum of two years’ experience in RF or related electronics or electrical field.', 'Must have working knowledge of computer systems and software.', 'Capable of using test equipment and schematics for troubleshooting.', 'Must possess radar theory knowledge and experience.', 'Must have experience conducting and/or evaluating RF measurements on high power transmitters and amplifiers such as power, frequency and modulation.', 'Demonstrated radar experience including target acquisition, tracking and discrimination functions.', 'Must pass a pre-employment drug screening and physical and periodic retests.', 'Must be able to wear appropriate Personal Protective Equipment (PPE) for work tasks assigned.', 'Must be capable of working in extreme weather conditions including summer temperatures peaking around 120 degrees Fahrenheit.', 'Must be able to lift 50 lbs. unassisted.', 'Must meet the physical requirements necessary to perform operations outlined, performed, and stated in the SOPs for Radar Section.', ""Must possess a valid driver's license, without special restrictions."", 'Must have dependable transportation and a dependable means of communication.', 'Must be able speak, write, read, and understand English.', 'Must have a well-mannered customer service attitude.', 'Must use “down-time” effectively to the benefit of test, self, and company.', 'Must be willing to cross-train in other areas.', 'Must be punctual, responsible, and dependable.', 'Must demonstrate motivation, initiative, and reliability.', 'Must be adaptable, flexible, and able to adjust to new or changing instructions.', 'Must have a demonstrated ability to follow instructions and company policy.', 'Must be able to deliver quality products to the customer and be responsive to their needs.', 'Must be safety and security conscious, complying with rules and policies.', 'Must be able to work both as part of a team and independently.', 'Must be able to work independently with minimal supervision.', 'Must be able to work all shifts, weekends, holidays and overtime as needed, sometimes on short notice, to support test missions.', 'Specialized experience with AN/MPS-25, FPS-16, TPQ-39 Acquisition Radar, Weibel Multi-Frequency Long Range Tracking radars and Mortar Tracking Systems.', 'Experience with agile process implementation using tools such as Jira and Confluence.', 'Three plus years of experience in electronics/electrical and/or systems engineering.', 'Master of Science degree in Electronics or Electrical Engineering.', 'Must be a U.S. Citizen and not hold multiple citizenships.', 'Must possess or be able to obtain a security clearance prior to employment and maintain security clearance for the duration of employment.', 'Must be a current TRAX employee or affiliate subcontractor for internal postings.', 'TRAX is an Equal Opportunity Employer - Minorities/Females/Veterans/Disability.', 'TRAX Test Services promotes a drug/alcohol free work environment through the use of mandatory pre-employment drug testing and on-going random drug testing, as per applicable State Laws.', 'Must be able to obtain a security clearance prior to employment and maintain security clearance for the duration of employment.']",2020-08-08 13:28:37
Associate Engineer - Substations,NOVEC,3.6 out of 5,"Manassas, VA 20109","['Assist in the performance of electrical system studies and make recommendations based on results. Assist in conducting studies and surveys to improve the electrical system with emphasis on the application of new materials, equipment and system operation.', 'Assist in preparation of short range and long range plans, including voltage drop studies, sectionalizing studies, maintenance requirements and budget requirements.', 'Assist in the data completion for the evaluation of power outages and other electrical disturbances.', 'Assist in recording, reviewing and analyzing system records and making recommendations for system improvements or solutions to system problems.', 'Assist in the design of electric facilities or substations for new customer line extensions, subdivisions, system improvements, system maintenance and SCADA.', 'Using prescribed methods, perform specific and limited portions of a broader assignment of an experienced engineer. Apply standard practices and techniques in specific situations, adjusts and correlates data, recognizes discrepancies in results and follows operations through a series of related detailed steps or processes.', 'Perform assignments designed to develop professional working knowledge and abilities, requiring application of standard techniques, procedures and criteria in carrying out a sequence of related engineering tasks.', 'Must be able to organize work to meet deadlines.', 'Work requires attention to detail and the completion of reports, which require a high degree of accuracy and detail.', 'Able to apply analytical methodology to problem solving and decision making and relate theoretical and/or technical concepts to practical application.', 'Limited exercise of judgment is required on details of work and in making preliminary selections and adaptations of engineering alternatives.', 'Must be able to apply working knowledge of and ability to operate personal computer and related software systems including, but not limited to, Microsoft Office and IBM compatible office products; operate mechanical equipment including telephone, copier and fax machines.', 'Anticipate and meet rapidly changing customer and business needs by quickly refocusing and realigning strategic and operational direction.', 'Perform job responsibilities in a timely and accurate manner within established guidelines under minimal supervision while providing superior customer service.']",2020-08-08 13:28:37
Design Engineer,"City of Yakima, WA",N/A,"Washington, DC","['Comprehensive medical, dental and vision coverage', 'FREE healthcare clinic!', 'WA State PERS pension plan and employer contribution to a 457 deferred compensation plan', 'Generous accruals for vacation and sick leave', 'Much more!']",2020-08-08 13:28:37
Structural Engineer,Cavalry LLC,N/A,"Brooklyn, NY 11230","['Facilitates an understanding of the project scope and corresponding plans.', 'Works closely and communicates regularly with the Project Associates, drafters, Clients, and fellow engineers.', 'Define clear goals for all aspects of a project and develop steps for their proper execution.', 'Provide detailed specifications for proposed solutions including time and scope involved.', 'Focuses on the identified project strategy and how it progresses during the project, while evaluating any potential risks and future challenges.', 'Monitor project progress and implementation of initiatives.', 'Studies building codes and regulations, and determines how they will affect designs.', 'Visits job sites, as needed, to gather and document data needed to complete designs.', 'Ensures deadlines are maintained and work produced is top quality work.', 'Degree in Structural Engineering/Civil Engineering', 'Relevant work-experience', 'Project development skills', 'Experience with software engineering, customer experience and design architecture', 'Monday to Friday', 'United States (Required)', 'https://www.cavalryassociates.com/', 'No']",2020-08-08 13:28:37
Inbound Logistics Engineer,Volvo Cars,3.9 out of 5,"Charleston, SC","['Set up and run an efficient process for implementation of new / changed material suppliers or shipping locations.', 'Set up and run an efficient process for implementation of new / changed carriers.', 'Gather volumes and requirements and initiate RFQ specifications to transport purchasing.', 'Design the transport network based on plant requirements, volumes, available transport rates and benchmarks', 'Drive implementation based on results from RFQ, including implementation of carriers and setting up network with rates in TMS.', 'Responsible for communication and anchoring of changes with the plant(s)', 'Secure communication of changes and full alignment between information in Transport Management System and Plant MRP system for pick up days, lead-times and time-windows, in a timely manner.', 'Drive X-functional investigations and analysis with Plant Logistics Engineering and Supply Chain Control to balance optimization of transport cost, tied up capital and storage space.', 'Represent IBL as a key member in related projects.', 'Set up KPI structure to track performance and efficiency in both process and network.', 'Manage quarterly tactical meetings with each carrier in relation to performance, volumes & capacity and improvements.', 'Developing tools, models and processes for continues improvements.', 'Keep transport network up to date at all times.', 'Secure implementation of carriers.', 'Ensure through constant improvements that area of responsibility meets the targets (budget, lead-time, frequency, utilization, quality and benchmark costs).', 'Align with overall objectives and secure implementation results.', 'Communicate and align all activities with internal Volvo Cars stake holders.', 'Interface between central functions, local plants and contracted logistic parties.', 'Ensuring up to date master data in (TMS) and full alignment between TMS and Plant MRP.', 'Represent and drive Volvo US Operations interests within the competence area', 'A university degree in Supply Chain/Logistics Management, alternatively, skills and knowledge acquired through a minimum of 5 years of experience of operational transportation management.', 'Strong understanding and experience of Transport Management System and transport network, preferably experience from the automotive industry', 'Strong understanding of carrier operations', 'Excellent communication skills on all levels, ability to explain complex scenarios on a management level, as well as to communicate findings and make recommendations that drive change.', 'Solid project management skills', 'Strong quantitative and analytical skills', 'Strong networking capabilities and team player']",2020-08-08 13:28:37
Process Engineer,Thermo Fisher Scientific,3.5 out of 5,"Cincinnati, OH 45201","['Support troubleshooting and issue resolution for major equipment breakdowns', 'Identifies opportunities for process and optimization improvements not limited to throughput, yield, containment, and cost savings.', 'Serve as primary point of contact as the equipment and process subject matter expert for requests outside of operations to support capital equipment investments, new product development, product proposals and quotes.', 'Analyze operational equipment and maintenance data to drive engineering solutions to support cost reduction, quality, safety, and operational efficiencies.', 'Provide engineering support for new product and process introductions', 'Assist in selection components for capital equipment investments', 'Drive PPI mindset with teams to identify and execute on PPI projects and cost savings initiatives', 'Work closely with maintenance and reliability to align on data driven decisions to improve equipment up time', 'Root cause problem solving and CAPA generation and execution to improve quality', 'Capable of interfacing with customers and external clients to explain technical challenges and propose solutions', 'Collaborates with internal and external customers, as well as original equipment manufacturers to provide technical expertise, recommendations, and continuous improvement efforts on processing equipment', 'Communicates process and equipment performance to the department, identifying opportunities and proposals', 'Conducts risk assessments and collaborates closely with the maintenance and reliability teams', 'Bachelor’s Degree in Engineering (industrial, manufacturing, chemical, electrical and mechanical engineering)', '2+ years previous related experience in engineering, pharmaceutical manufacturing, and process equipment', 'Experience in an FDA regulated or regulated industry beneficial.', 'Broad-based background in pharmaceutical manufacturing with a combination of experience and skills in one or more of the following areas: product/ process development, production support, engineering, validation or quality assurance.', 'Equivalent combinations of education, training, and relevant work experience may be considered.', 'Strong leadership, planning, time management, and attention to detail', 'Advocate for change and process improvements', 'Working knowledge of related pharmaceutical equipment', 'Ability to approach tasks and projects with a sense of urgency', ""Able to work effectively with OEM's to troubleshoot and order parts"", 'Capable of working cross functionally and adjusting priorities to fit the business need', 'Self-starter with demonstrated efficient work methods, analytical &amp; problem solving skills and ability to handle multiple tasks in a fast paced environment.', 'The individual should enjoy working in a fast paced, dynamic and results orientated team environment.', 'Excellent Interpersonal Skills - able to express ideas and collaborate effectively with multidisciplinary teams.', 'Innovative thinker - should be able to envisage new and better ways of doing things.', 'Excellent data analytical skills, ability to plan, organize and implement concurrent tasks.']",2020-08-08 13:28:37
Systems Engineer IV,Infinity Systems Engineering,4.6 out of 5,"Dahlgren, VA","['Lead Integration Efforts of Command and Control or similar systems (data exchange and processing)', 'Address and detect issues that impact projects and implement/develop courses of action (COAs) to mitigate or alleviate the impact to projects', 'Prepare and brief technical presentations at informal and formal meetings', 'Write technical white papers, memorandums and reports', 'Contribute to the development of new principles and concepts to enhance mission operations', 'Perform DoD compatible system engineering lifecycle processes', 'Support critical operations during standard and non-standard working hours', 'Support the project management team by performing technical planning, including cost, risk and supportability and effectiveness analyses for total systems following a defined system design lifecycle process (concept, design, fabrication, test, installation, operation, maintenance and disposal)', 'Develop and execute risk mitigation plans and management of risks on projects', 'Act as a liaison to internal and external stakeholders', 'Knowledgeable in Information and Computer Systems and working knowledge of converged infrastructure and related technologies such as VMware, Networking, and Storage solutions', 'Working knowledge of RMF and cybersecurity requirements', 'Ability to lead efforts to field changes to production systems schedule', 'Experience with requirements analysis and systems design', 'Experience writing specifications, design, ConOps, and Interface Control Documents', 'Previous experience supporting DoD/government customers', 'Hardware/software requirement verification/system validation experience']",2020-08-08 13:28:37
Production Engineer,Kuraray America,3.6 out of 5,"Pasadena, TX 77507","['Create and manage condition sheets, work orders, blend sheets, changeover sheets, checklists, etc.', 'Manage offsite compounding and rework activities', 'Lead customer complaint and wide spec investigations', 'Create and manage production KPIs & reporting tools', 'Manage production schedule with coordination from product management', 'Manage inventory used in production', 'Identify and implement opportunities to improve quality, increase yield, increase capacity, reduce cost, and improve safety', 'Manage data historian, analyze process trends, and implement process changes.', 'Lead new product trials in coordination with TS&D', 'Provide technical support as SME for the EVAL Warehouse', 'Troubleshoot process & production issues', ""Ensure compliance with Kuraray's quality assurance program."", 'Ensure compliance with ISO 9001 & IATF 16949', 'BS. Degree in an Engineering discipline', 'Minimum of two (2) years of relevant engineering/production work experience', 'Expect to spend around 25% of the time on the floor', 'Technical understanding of extrusion', 'Background in PLC controls, reading and updating ladder logic', 'Experience in lean manufacturing methods (e.g. 5S, Six Sigma, Kaizen, TPM)', 'High proficiency in Excel including VBA and macros']",2020-08-08 13:28:37
Field Engineer/Geologist,ConeTec,3.3 out of 5,"Charles City, VA 23030","['Develop a strong working knowledge of site investigation practices and procedures.', 'Build comprehension of soil mechanics, in-situ testing, and geophysical field investigations.', 'Gain experience and exposure as a contractor in several of North America’s largest industries.', 'Expand skill set through training and certifications to become an asset of a larger team.', 'Familiarize with and operate CPTu equipment, VST, sampling systems, numerous geophysical instruments and other in-situ testing equipment in a safe and productive manner.', 'Become trained, company-certified and competent to operate numerous types of drilling equipment and other pieces of equipment within our extensive fleet.', 'Organize logistics for the mobilization and demobilization of equipment in hard-to-access environments.', 'Perform routine maintenance on various pieces of equipment to ensure optimal performance.', 'Perform testing to collect data in a timely, orderly and accurate manner.', 'Compile the collected data, sample logs, etc. daily and submit to the Engineer/Supervisor and/or client for further processing.', 'Collect field notes and photos to guarantee the translation of data from field to office is as highly accurate as possible.', 'Prepare and compile final field report.', 'Identify with and respect ConeTec’s safety culture, first and foremost.', 'Ensure proper preparation and knowledge of all necessary safe operating procedures before beginning any job.', 'Report any safety-related incidents, infractions, or near misses to the Project Manager and the HSE Officer, immediately.', 'Know and follow the incident reporting protocol at all times.', 'Communicate with the Supervisor or Project Manager as to any equipment problems or needs, as well as any field observations that might be of use.', 'Perform other shop functions as required.', 'Bachelor’s Degree in Engineering or Geology', 'Previous field experience is an asset, in addition to the academic experience noted above', 'Experience with Microsoft Excel is an asset', 'Electrical and mechanical skills are an asset but not required', 'Must possess strong work ethic and represent the company in a professional manner.', 'Must be able to establish and maintain effective working relationships.', 'Must be responsible and work well independently or in a team setting with minimal supervision.', 'Must enjoy working outdoors and travelling for extended periods of time.', 'Must enjoy performing a wide variety of duties and be able to manage multiple tasks and priorities.', 'Must have a clean driving record.']",2020-08-08 13:28:37
NPI Project Engineer,Cree Inc,3.4 out of 5,"Durham, NC 27703","['High visibility, cross-functional leadership role in a fast-growing business unit.', 'Exposure and direct interaction with all levels of the organization including marketing, operations, development and business leadership', 'Potential for upward mobility in a growing organization', 'Own, manage and drive the Power New Product Introduction s through the Business Gate approval process, from Concept through Commercialization . Primary Product focus will be discrete packaged products.', 'Ensure the fulfillment of product requirement s including all items for product release. Identify deliverable s and ensure deliverable completion to ensure successful product transition to the Operations team.', 'Forecast, plan, c oordinate and schedule substrate and epi starting material, fab wafer starts, package qualification builds, test, characterization and reliability testing to ensure new product qualification schedule timeliness.', 'Work closely with Marketing and Sales to define product release timelines and strategies.', 'Document, summarize and report on project status to key stakeholders, communicating progress to schedule and highlighting schedule and project risks.', 'Ensure all testing, reliability stress and evaluation is completed in accordance with current and emerging standards and specifications including JEDEC, AEC-Q101, Power Module LV3 24 , AGQ324 and any SiC -specif ic standards .', 'Facilitate DFMEA and DVP&R , ensuring products are effectively identified and documented. Ensure previous lessons learned are incorporated into new product risk analysis.', 'Utilize 8D methodology to ensure Qualification issues are effectively addressed and documented to ensure effective corrective actions and to ensure Lessons Learned are captured for future product development.', 'Support or lead NPI system level improvements to ensure efficient pro duct de finition, approval and release in support of APQP requirements.', 'At least 3 years of industry experience in process engineering , process integration or product engineering in a production semiconductor wafer fabrication facility.', 'Demonstrated project management skills including the ability to effectively multi-task in a complex environment, including strong written and verbal communication skills.', 'Analytical mindset and self-starter to confront difficult problems and challenge the team to high levels of perform ance.', 'Strong p roblem solving skills and problem prevention skills including 8D, FMEA, DOE, and ANOVA.', 'Bachelors degree in engineering , physics or closely related field', 'This position requires the lawful ability to access technical data, information, and areas controlled by United States export control laws and regulations.', 'Experience in silicon carbide based wafer fab process engineering, package processing or process integration.', 'Experience in qualifying products to AEC-Q101 or AEC-Q100 standard', 'Power and Schottky diode semiconductor device physics knowledge', 'Advanced data query scripting abilities or computer programming experience with SQL, JMP, MS Access, or similar database and analysis software', 'Six sigma black belt, green belt or significant Quality system training and experience.']",2020-08-08 13:28:37
Manufacturing Controls Engineer,KMA Consulting,N/A,"Bangor, ME","['Works with other engineers and technicians in developing solutions and improvements in materials, equipment, and process.', 'Analyzes current equipment for process suitability and provides detailed plans for improvement.', 'Executes integration of controls hardware and software into new and existing manufacturing equipment.', 'Designs experiments, validation; completes testing and analysis of data.', 'Creates and revises manufacturing documents, specifications, standard operating procedures (SOPs), safety instructions, validation protocols, risk assessments, and procedures and other technical documents to ensure compliant, efficient, and safe procedures.', ""Must have Bachelor's degree (BS) in engineering."", 'Minimum of 2 years of engineering experience in a manufacturing environment or equivalent combination of education and experience.', 'Previous experience with common manufacturing automation technologies, and architectures (Programmable Logic Controllers, Human Machine Interfaces).', 'Experience with Banner Safety Systems and working in a regulated environment.', 'Health Insurance', 'Monday to Friday', 'One location', 'No']",2020-08-08 13:28:37
Field Engineer IV,FedEx Supply Chain,3.4 out of 5,"Union City, GA","['A strong FedEx brand consistently ranked among the world’s most admired and trusted employers.', 'A top notch leadership team with the experience needed to grow and develop your career.', 'An open mind for new ideas and creative methods.', 'A strong compensation and benefits package, including health, vision, dental, 401k with a strong match and much more!', 'Analyzes performance data within field of specialization. Recommends procedures updates.', 'Analyzes and documents existing processes and large, multi-faceted data sets. Identifies opportunities for improvement and recommends and acts on solutions.', 'Researches and analyzes technical or engineering related information independently. Creates development plan and presents plan information to management.', 'Prepares accurate expenditure proposals and/or cost justification analysis. Monitors expenditures to ensure spending is applied and within budget guidelines. Assists with developing project budgets.', 'Formulates and presents document research, progress, and results. Interacts with team members, customers, and senior management.', 'Applies project management fundamentals and concepts for multiple concurrent projects. Creates and publishes progress reports, meeting minutes, memos, and presentations for management review.', 'Mentors and develops critical skill sets in lower level engineers.', 'Develops and updates engineering plans based on forecasted volume, contingency plans, and historical data.', 'Reviews and compares daily service analysis to previous day activities, develops customized reports for analysis (e.g., root cause analysis) for continuous improvements using engineering principles, and communicates solution(s), operational issue(s), and enhancement(s) to field management.', 'Prepares cost benefit analysis for technology improvements by conducting detailed quantitative and qualitative analysis to determine the feasibility of purchasing new operations equipment; presents analysis to senior management.', 'Conducts observations and makes recommendations to managers on methods to increase productivity and decrease damages.', 'Trains managers on engineering principles, methods, and procedures.', 'Performs various analyses on cost reductions through the utilization of sound engineering principles resulting in productivity and quality enhancements.', 'Monitors staffing plan and modifies engineering plans to meet productivity goals.', 'Leads, trains, and monitors the rollout of new programs for Corporate.', 'Leads operations, Corporate Engineering department and/or cross-functional projects (e.g., Quality Driven Management (QDM)).', 'Leads and/or participates in high profile special projects.', 'Bachelor’s Degree in Engineering and 6+ years of relevant experience.', 'In lieu of degree, high school diploma or GED and 8+ years of relevant experience.', 'Excellent communication and presentation skills; ability to effectively present information and respond to questions from groups of managers, clients, teammates, customers, and the general public.', 'Strong experience with Microsoft Office and other related systems.', 'Experience in an industrial or warehouse operation including demonstrated examples of concept, designing and/or implementing process improvements to safety, quality or productivity metrics.', 'Teamwork skills in resolving problems, discussing issues, and communicating potential solutions and results to wage employees as well as upper management.', 'Ability to follow policies and procedures.', 'Ability to read, write and interpret information.', 'Ability to add, subtract, multiply and divide.', 'Ability to use hands to finger, handle, or feel.', 'Ability to sit/walk/stand for up to 8 hours per day.', 'Must possess visual acuity, i.e., close, distance, and color vision, depth perception and the ability to adjust focus.']",2020-08-08 13:28:37
Validation Engineer,L&T Technology Services,4 out of 5,"Edison, NJ 08817",[],2020-08-08 13:28:37
Highway Engineer Trainee - Division of Highways,State of West Virginia,3.4 out of 5,West Virginia,"['Performs data analysis to determine the posted load limits for bridges.', 'Coordinates construction project activities with utility companies.', 'Determines horizontal and vertical highway alignments.', 'Prepares drainage computations.', 'Performs field inspection of traffic problems.', 'Performs field inspection of construction projects.', 'Prepares preliminary cost estimates for highway projects.', 'Makes detailed design computations for roadways and bridges.', 'Performs field checks at highway construction project sites.', 'Performs design and drafting as required.']",2020-08-08 13:28:37
Application Engineer,Altair Engineering,4.2 out of 5,"Washington, DC","['Design and conduct Altair product presentations and demonstrations, which include but are not limited to question and answer discussions with the customer and partner’s technical staff.', 'Visit on-site with customers to perform technical analysis and qualification of potential customer projects. Discuss the potential sales opportunities with sales team.', 'Maintain contact with prospects, customers, and partners. Discuss current and new-release product features and uses.', 'Propose Altair’s Support Services and Consulting Services to customers who need assistance to resolve challenging problems and build solutions of demanding complexity.', 'Proactively contact prospects and customer in conjunction with Account Management business planning.', 'Manage customer expectations so as to ensure maximum satisfaction with Altair’s products and services.', 'Liaison between customers and development personnel to drive new feature requests into future product releases.', 'Interface with and provide assistance to Altair’s customer support organization with their efforts to assist customers with resolving customer support issues.', 'Bachelor degree in Mechanical Engineering or related required. Master’s degree is a plus.', 'Knowledge and strong interest of Finite Element Analysis (FEA).', '1-3 years of hands on FEA experience preferred.', 'Good communication skills (Oral and Written).', 'Energetic.', 'Strong interpersonal skills.', 'Ability to collaborate with all levels of technical users and management.', 'Excellent presentation skills.', 'Aptitude for solving engineering problems.', 'Willingness to travel throughout region as required.']",2020-08-08 13:28:37
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:29:20
Data Engineer - Contract Opportunity,Westinghouse Electric Company,3.4 out of 5,"Cranberry Township, PA 16066","['Assist with creation of data schemas, stored procedures, data pipelines, and views', 'Help build and maintain technical solutions required for optimal ingestion, transformation, and loading of data from a wide variety of data sources and large, complex data sets', 'Collaborate across roles to embrace best practices in reporting and analysis, including data integrity, test design, validation, and documentation', 'Collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'Build and automate actionable reports', 'Collaborate with data analysts, data scientists, and stakeholders during design discussions to uncover more detailed business requirements related to data engineering', 'Develop strong hypotheses, independently solve problems, and share actionable insights with engineering', 'Partner and develop strong relationships with cross-functional teams']",2020-08-08 13:29:20
Software Development Engineer - AWS - Fully Virtual,"Amazon Web Services, Inc.",3.6 out of 5,Remote,"['5+ years of non-internship professional software development experience with at least one modern language such as Java, Python or Node including object-oriented design', '1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems', 'Implement best practices in modern software engineering: design, implementation, testing, version control, documentation, deployment, monitoring and operations', 'Write high quality code that is robust and can be delivered and maintained by customers', 'Build flexible systems choosing simple, straightforward solutions over more complex ones', 'Possess self-drive to dive deep and maintain progress even in the face of ambiguity and imperfect knowledge (avoid “analysis paralysis”)', 'Encourage and support knowledge-sharing within team and external groups', 'Communicate clearly both verbally and in writing, within team and external groups', 'Actively participate in hiring and mentoring the very best', 'Obtain/maintain AWS Certifications', 'Occasional customer travel (<20%)', 'Can potentially work remotely (can live within 2 hours of Amazon/AWS office).', 'Effective verbal and written communication skills', 'Proficiency in design and analysis of algorithms and data structures that will operate at potentially global scale.', 'Proficiency in the DevOps style of software deployment', 'Proficiency in developing software in a cloud-native environment', 'Knowledge of Application Security principles and how they impact development and deployment of applications.', 'Experience handing off and supporting maintainable code artifacts', 'Experience in an agile development environment', 'Experience with Cloud Operational Excellence practices', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-08-08 13:29:20
Big Data Engineer,"Amazon Web Services, Inc.",3.6 out of 5,"Seattle, WA","[""This position requires a Bachelor's Degree in Computer Science or a related technical field, and 3+ years of meaningful employment experience."", '3+ years of work experience with ETL, Data Modeling, and Data Architecture.', 'Expert-level skills in writing and optimizing SQL.', 'Experience with Big Data technologies such as Hive/Spark.', 'Proficiency in one of the scripting languages - python, ruby, linux or similar.', 'Experience operating very large data warehouses or data lakes.', 'Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.', 'Experience with building data pipelines and applications to stream and process datasets at low latencies.', 'Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.', 'Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.', 'Knowledge of Engineering and Operational Excellence using standard methodologies.', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-08-08 13:29:20
Senior Data Engineer,R&K Solutions,3.8 out of 5,"Roanoke, VA 24017",[],2020-08-08 13:29:20
HADOOP DATA ENGINEER,Emids Technologies Pvt. Ltd.,3.9 out of 5,"Hartford, CT","['Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.', 'Collaborates with other data teams to transform data and integrate algorithms and models into automated processes.', 'Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines.', 'Builds data marts and data models to support Data Science and other internal customers.', 'Analyzes current information technology environments to identify and assess critical capabilities and recommend solutions.', 'Experiments with available tools and advises on new tools in order to determine optimal solution given the requirements dictated by the model/use cases', '3 or more years of progressively complex related experience.', 'Has strong knowledge of large scale search applications and building high volume data pipelines.', 'Experience building data transformation and processing solutions.', 'Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.', 'Ability to understand complex systems and solve challenging analytical problems.', 'Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.', 'Strong collaboration and communication skills within and across teams.', 'Strong problem solving skills and critical thinking ability.', 'Hive', 'Shell Script', 'Unix', 'Hadoop Concepts (Sqoop, YARN, MapReduce ,etc.)', 'Python']",2020-08-08 13:29:20
Sr. Big Data Engineer (Flexible Location),"Pixalate, Inc.",N/A,Remote,"['http://pixalate.com/press', 'Harvard Business Review', 'Buzz Feed', 'Forbes', 'NBC News', 'CNBC', 'Business Insider', 'AdAge', 'AdAge', 'CSO Online', 'Mediapost', 'Mediapost', 'The Drum', 'Mediapost', 'Mediapost', 'We believe in Small teams that produce high output', 'Slack is a way of life, short emails are encouraged', 'Fearless attitude holds high esteem', 'Bold ideas are worshipped', 'Chess players do really well', 'Titles don’t mean much, you attain respect by producing results', 'Everyone’s a data addict and an analytical thinker (you won’t survive if you run away from details)', 'Collaboration, collaboration, collaboration', 'Support existing processes running in production', 'Design, develop, and support of various big data solutions at scale (hundreds of Billions of transactions a day)', 'Find smart, fault tolerant, self-healing, cost efficient solutions to extremely hard data problems', 'Take ownership of the various big data solutions, troubleshoot issues, and provide production support', 'Conduct research on new technologies that can improve current processes', 'Contribute to publications of case studies and white papers delivering cutting edge research in the ad fraud, security and measurement space', 'Bachelors, Masters or Phd in Computer Science, Computer Engineering, Software Engineering, or other related technical field.', 'A minimum of 3 years of experience in a software or data engineering role', 'Excellent teamwork and communication skills', 'Extremely analytical, critical thinking, and problem solving abilities', 'Proficiency in Java', 'Very strong knowledge of SQL and ability to implement advanced queries to extract information from very large datasets', 'Experience in working with very large datasets using big data technologies such as Spark, BigQuery, Hive, Hadoop, Redshift, etc', 'Ability to design, develop and deploy end-to-end data pipelines that meet business requirements.', 'Strong experience in AWS and Google Cloud platforms is a big plus', 'Deep understanding of computer science concepts such as data structures, algorithms, and algorithmic complexity', 'Deep understanding of statistics and machine learning algorithms foundations is a huge plus', 'Experience with Machine Learning big data technologies such as R, Spark ML, H2O, Mahout etc is a plus', 'Experienced leadership and founding team', 'Casual environment', 'Flexible hours', 'High performing team who wants to win and have fun doing it', 'Extremely Competitive Compensation', 'OPPORTUNITY (Pixalate will be what you make it)']",2020-08-08 13:29:20
Junior Business Intelligence Data Engineer,MotorTrend Group,4 out of 5,"El Segundo, CA 90245","['Collaborate with product teams and data analysts to design and build data-forward solutions', 'Build and deploy streaming and batch data pipelines capable of processing and storing petabytes of data quickly and reliably', 'Integrate with a variety of data metric providers ranging from advertising, web analytics, and consumer devices', 'Build and maintain dimensional data warehouses in support of business intelligence tools', 'Develop data catalogs and data validations to ensure clarity and correctness of key business metrics', 'Drive and maintain a culture of quality, innovation and experimentation', 'Deliver strong Python and SQL development and maintenance techniques surrounding data movement to include technologies', 'Investigate and understand different data sources and ability to connect to a wide variety of 3rd party APIs', 'Design, enhance and implement ETL/data ingestion platform on the cloud', 'Development of ETL source and target mapping design/specifications based on the business requirements. Create ETLs/ELTs to take data from various operational systems and create a unified/enterprise data model for analytics and reporting', 'Develop load and transformation processes in support of the requirements, validate that they meet business and technical specifications, manage ongoing maintenance of the system and data, and make recommendations for process improvements to optimize data movement from source to target', 'Provide production and operational support to existing ETL jobs. Monitor and manage production ETL jobs to verify execution and measure performance to assure ongoing data quality and optimization of the system to manage scalability and performance and identify improvement opportunities for key ETL processes.', 'Strong troubleshooting and problem-solving skills in large data environment', 'Capable of investigating, familiarizing and mastering new data sets quickly', ""Bachelor's degree – Computer Science or equivalent"", 'Strong background in scripting language using Python, Bash, Perl, PHP or any other language to solving data problems', 'Experience with relational SQL and NoSQL databases, including Postgres, ,Neo4j and MongoDb', 'Experience with Big Data tools; Hadoop, Spark, Kafka, Hive etc', 'Proficiency with the AWS cloud services : EC2, EMR, RDS, S3, Redshift (spectrum)', 'Proficiency with data exchange types and protocols (json, xml, soap, rest)', 'Experience with Stream Processing systems: Storm ,Spark-Streaming etc', 'Experience with BI tools like Tableau or any other open source BI tools etc.', 'Knowledge of the Python data ecosystem using pandas and numpy', 'Data integration tools', 'Proficiency in SQL, data modeling, and data warehousing', 'Excellent problem solving skills', 'Exposure to cloud platforms (preferably AWS)', 'The ability to sit for prolonged period of time and view computer screen.', 'Microsoft Office Suite (Outlook, Word, Excel, PowerPoint)', 'SQL, MySQL or other relational databases', 'Linux, Python, AWS Stack (EC2,EMR S3, Redshift)', 'Tableau or any other data visualization tool', 'SiteCatalyst (Omniture)/Google Analytics or any other web analytics tools experience (Nice to have)', 'Work is performed in an office environment that is well lit and ventilated.']",2020-08-08 13:29:20
Senior Data Integration Engineer,Northwestern Mutual,3.8 out of 5,"Milwaukee, WI",[],2020-08-08 13:29:20
Data Engineer III,TeleTracking Technologies,4 out of 5,Remote,"['Writing, debugging, unit testing, and performance test code in the data access layer in accordance with TeleTracking standards.', 'As an agile team member, participate in code reviews, design reviews, etc.', 'Utilize domain driven techniques and design patterns to build and contribute to technical design.', 'Develop and maintain strong knowledge of implemented requirements and detailed application behaviors.', 'Assists in the development and training of SE I.', ""Bachelor's computer information technology, computer science, management required"", ""Master's preferred"", '7+ years of experience in a cloud computing environment.', 'Strong understanding and familiarity working in the Linux operating environment.', 'Familiarity and experience executing several software development methodologies and life cycles preferred.', '7+ years of developing software using object-oriented or functional language experience5+ years of SQL', '7+ years working with open source Big Data technology stacks (Apache Nifi, Spark, Kafka, HBase, Hadoop/HDFS, Hive, Drill, Pig, etc.) or commercial open source Big Data technology stacks (Hortonworks, Cloudera, etc.)', '3+ years with document databases (e.g. MongoDB, Accumulo, etc.)3+ years of experience using Agile development processes (e.g. developing and estimating user stories, sprint planning, sprint retrospectives, etc.)', '2+ years of distributed version control system (e.g. git)3+ years of experience in cloud-based development and delivery', 'Familiarity with distributed computing patterns, techniques, and technologies (e.g. ESB)Familiarity with continuous delivery technologies (e.g. Puppet, Chef, Ansible, Docker, Vagrant, etc.)', 'Familiarity with build automation and continuous integration tools (e.g. Maven, Jenkins, Bamboo, etc.)', 'Familiarity with Agile process management tools (e.g. Atlassian Jira)', 'Familiarity with test automation (Selenium, SoapUI, etc.)', 'Good software development and Object Oriented programming skills.', 'Strong analytical skills and the ability to work with end users to transform requests into robust solutions.', 'Excellent oral and written communication skills.', 'Initiative and self-motivation to work independently on projects.']",2020-08-08 13:29:20
Data Engineer,WellNow Urgent Care,2.6 out of 5,"East Syracuse, NY 13057","['Design and develop complex ETL data loading packages.', 'Drive for and create ETL architectural and development standards.', 'Drive ETL development efforts and share knowledge capital.', 'Assist in design, architecture and development of Data Warehouse/Datamart.', 'Adhere to ETL/Data Warehouse/Datamart development best practices.', 'Identify and resolve any performance and/or data related issues', 'Analyze business requirements as a guide to data preparation and modeling', 'Build data models with the flexibility to change when business requirements change', 'Provide documentation (Data Mapping, Technical Specifications, Production Support, data dictionaries, test cases, etc.)', 'Provide Production Support of Data Warehouse as well as ETL jobs used to support the Data Warehouse.', 'Provide support for stakeholders, analysts and report creators.', 'Perform duties & responsibilities specific to department functions & activities and any other assigned task by reporting manager.', 'Bachelor’s degree in Information Technology, Management of Information Systems, or a related field', '5+ Years of experience with MS SQL Server Integration Services (SSIS)', '5+ Years of experience with MS SQL Server Reporting Services (SSRS)', '3+ Years of experience with MS SQL Server Database Design/Development', '3+ Years of Data Warehousing Experience', 'Experience implementing and supporting Enterprise Level Data Warehouse', '2+ Years of experience with MS SQL Server Analytical Services (SSAS)', 'Expert Microsoft SQL Development (T-SQL)', 'Experience in Data Modeling (Erwin, Power designer, etc.)', 'Strong Understanding of Agile Data Warehouse Development, data modeling and data classification', 'Advance knowledge of performance tuning related to ETL Development', 'Strong experience with Source Control (TFS, RedGate, etc.)', 'Strong experience with job automation tools (Autosys, Tidal, BMC, etc.)', 'Strong experience with SQL Server Management Studio & BIDS', 'Strong Leadership, communication (verbal & written) and problem-solving skills', 'Business analyst experience helpful', 'Results/Goal oriented', 'Ability to handle multiple projects and manage time efficiently']",2020-08-08 13:29:20
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:29:20
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:29:20
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:29:20
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:29:20
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:29:20
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:29:20
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:29:20
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:29:20
Data Engineer,Staff Smart,N/A,"Los Angeles, CA","['Build highly scalable resilient data pipelines and models which produce high quality datasets', 'Deliver visualizations that distill clear, actionable insights from large, complex datasets', 'Improve our tooling by building generic data features such as data quality and anomaly detection and drive overall improvements in our data infrastructure', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Contribute to the design and evolution of their cloud data infrastructure platform and overall data engineering tooling', 'Collaborate with product and engineering teams in multiple projects building forward thinking, innovative data solutions that up-level our features and get results in a data driven way', '4+ years of industry experience building highly scalable data pipelines (batch and/or streaming) utilizing Spark, Hive, Presto or other open source frameworks architecture', 'Python and shell scripting experience for automation and data manipulation', 'Prior experience utilizing dashboarding tools such as Tableau, Superset or similar', 'Experience with data visualization tools; preferred: Microsoft Power BI, Tableau, Qlik', 'Experience translating ambiguous business needs to highly scalable data models and datasets', 'Possess advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases', 'Experience with diverse SQL and NoSQL platforms', 'Previous experience with AWS (EC2, EMR, RDS, Redshift) or similar cloud environment', 'Experience preparing large, complex datasets for Machine Learning pipelines a plus', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience with Airflow/Jenkins and similar scheduling CI/CD tools']",2020-08-08 13:30:08
Data Engineer - Early Career,Lawrence Livermore National Laboratory,4.2 out of 5,"Livermore, CA 94550","['Collaborate with stakeholders, software developers, data scientist, and multidisciplinary teams to understand their data access and usage needs to assist with the development of a data infrastructure solution.', 'Architect, develop and deploy moderately complex data pipelines to collect, clean, and store largescale, cross-functional datasets.', 'Assist with the design of optimal storage, data structures, security, and retrieval mechanisms for data at rest in data lakes and analytics data store, or data in motion for real-time processing requirements.', 'Participate in the implementation of a pluggable framework for data ingestion and transformation workflows used on data lakes.', 'Assist with the development of a data infrastructure platform build on top of Kubernetes for our data scientists and big data researchers, in collaboration with your team.', 'Document and version control the data infrastructure platform, using Git and Confluence; track/report work status in tickets using JIRA.', 'Perform other duties as assigned.', 'Bachelor’s degree in Computer Science, Computer Engineering, or related field, or the equivalent combination of education and related experience.', 'Broad experience working in data science teams to provide robust data engineering solutions or a background in Data science, Data mining, Multivariate statistics, Computer vision, or Machine learning.', 'Effective analytical, problem-solving and decision-making skills to develop creative solutions to moderately complex problems and time management, organization, and planning skills with experience prioritizing concurrent technical tasks.', 'Understanding of databases (e.g. SQL, NoSQL, MySQL, Mongo), and high-performance or distributed processing (e.g. using MapReduce, Spark, Pig, Presto, and/or Hive).', 'Broad experience working effectively in a diverse development team environment.', 'Proficient interpersonal skills necessary to interact with all levels of personnel and ability to work independently in a multi-disciplinary team environment.', 'Experience with containerized environments (Docker or Kubernetes).', 'Experience with machine learning and or developing big data applications.']",2020-08-08 13:30:08
Data Engineer,Unity Technologies,4 out of 5,"Framingham, MA","['Participate in designing and maintaining data pools', 'Develop new products and services using the data we collect', 'Ensure consistency and accuracy of data aggregation', 'Work with multiple engineering and business groups on data collection practices and data analysis needs', 'Proven experience in building stable and scalable production services', 'Working knowledge of noSQL data stores and related querying languages, such as lucene, elasticsearch or mongodb, or time series data stores', 'Working knowledge of regular expressions', 'Working knowledge of SQL', 'Efficient communication skills in translating graphs and tables to stories', 'Experience in game development or social / communication services', 'Working experience in one or more of the following:: Python, C/C++, Erlang, Golang', 'Working experience in one or more of the following: ELK stack, TICK stack, BigQuery and related cloud data storage', 'A drive for data integrity and looking for patterns and trends in data', 'An ability to accept confirmed data as it is, and to learn what it may be trying to tell us']",2020-08-08 13:30:08
Data Engineer,WW International,N/A,"New York, NY","['Lead design, development, implementation and support of end-to-end data pipeline for centralized data lake on cloud', 'Design and implement streaming data analytics platform using moder cloud based and open source technologies and Python/JavaScript/Scala programing language', 'Build data catalog, data dictionary and make data searchable for our stakeholders and users', 'Work with various Google Cloud Platform (GCP) technologies, Kafka, Airflow, Metadata Management tool, Data Quality (DQ) tool, Cloud-Native Microservice architecture, CI/CD, Dev/Ops and much more', 'Design and implement data security, access control (including fine-grained) and compliance solutions to safeguard our data', 'Work with high volume (100s of TB), high velocity (real-time stream), high complexity (heterogeneous) data from hundreds of sources e.g. social media, click stream, e-commerce etc.', 'Mentor and guide junior team members, if hired at a senior position', 'Effectively communicate data governance initiatives and values to stakeholders', 'If you have done similar works as above for years, have some of the skillsets from below list and feel passionate and excited doing it again at WW, you have the right experience and skill sets. Let us talk', 'Experienced of architecting and implementing modern data platform (data lake or data warehouse) with batch and streaming data ingestion and processing on GCP or AWS cloud', 'Solid understanding of fundamental architecture and working principle of relational database, NoSQL database, massively parallel processing (MPP) database, distributed processing framework (MapReduce/Spark etc.), pub/sub messaging/streaming platform (e.g. Kafka, Google Pub/Sub, Kinesis)', 'Experienced in SQL query, data manipulation language (DML) and data definition language (DDL) including hands-on experience of managing database tables and views', 'Experienced of building Data App or Data Pipeline using Java/Python/Scala/Go programing language(s)', 'Experienced and willing to lead and manage work for junior data engineers on the team', 'Possess excellent work ethic, positive attitude to work and good verbal communication', 'Can effectively document, present and pursue solution design and idea to stakeholders / teams', 'Excellent work ethic, positive attitude to work and good verbal communication', 'Competitive compensation and profit-sharing plan', 'A 401K plan to help you plan for your future, plus company match', 'Health care coverage starting on your first day', 'Tuition reimbursement and online courses to help you reach your career aspirations', 'Commuter benefits', 'Yearly well-being allowance for your physical, financial, social and emotional well-being', 'Free WW membership for you plus 3 free WW memberships for your friends and 3 for your family', 'Free fruit, snacks and coffee to get you through your day', 'Summer Fridays, happy hours, and company outings', 'Robust employee referral bonuses', 'Developmental opportunities and assignments to grow your career']",2020-08-08 13:30:08
"Data Engineer, Senior",Booz Allen Hamilton,3.9 out of 5,"Herndon, VA","['5+ years of experience with coding using Java, Scala, or Python', 'Experience with developing and deploying ETL pipelines using Apache Spark', 'Experience with data tools', 'Experience in interfacing with modern relational databases, including MySQL or PostgreSQL', 'Experience in working with Big Data platforms, including Hadoop, AWS, Azure, or DataBricks', 'Ability to learn technical concepts quickly and communicate with multiple functional groups', 'Ability to obtain a security clearance', 'BA or BS degree', 'Experience with Agile software development', 'Experience with NoSQL data stores, including HBase, MongoDB, JanusGraph or Neo4J, and Cassandra', 'Experience with ETL tools, including StreamSets, NiFi, and Taland', 'Experience in working with enterprise production systems', 'Ability to display a positive, can-do attitude to solve the challenges of tomorrow', 'Possession of excellent oral and written communication skills', 'BA or BS degree in CS, Information Systems, or a related field preferred; MA or MS degree a plus', 'AWS or related certifications']",2020-08-08 13:30:08
Sr Data Engineer,"Cotiviti, Inc.",3.2 out of 5,"Atlanta, GA","['Program per data transformation specifications to convert source data to be loaded into data lake using proprietary big data processing platform', 'Supports and improves current data ingestion processes for our proprietary healthcare data applications and systems', 'Work as a team member in the creation and maintenance of data engineering processes using a variety of tools including T-SQL, Spark and Scala, and shell scripting. Generally focused on data ingestion for healthcare data management, data validation, statistical report generation, and program validation.', 'Work as a team member to develop tools and techniques for improving process efficiencies and data performance.', 'Review & test the data to ensure accuracy & validity of the data prior to uploading the data to the data lake.', 'Perform data analysis, data mining and investigations and identify root cause of issues using several cutting-edge data analysis tools.', 'Work with Technical Operations to troubleshoot complex database issues related to the entire environment including OS, storage and servers. Provide off hours support to resolve production issues when necessary', 'Mentor junior team members in data engineering and quality best practices.', 'Oversees the delivery of business priorities in a Scaled Agile Framework (SAFe) environment', 'Bachelor’s degree in relevant field such as Computer Science, Engineering, a related field, with 8-10 years of industry experience.', '5+ years’ experience with data aggregation, standardization, linking, quality check mechanisms, and reporting.', '5+ years’ experience with big data technologies like Hadoop and Spark.', '5+ years’ experience with RDBMS (Oracle, MS SQL Server) and using SQL or other data integration/ETL tools.', 'Solid understanding of Linux environments; strong knowledge of shell scripting and file systems.']",2020-08-08 13:30:08
"Data Engineer, Enterprise Data Services",New York City MAYORS OFFICE OF CONTRACT SVCS,N/A,"Manhattan, NY 10007","['Collaborate with the other members of the integration team in the design, implementation and documentation of solutions for daily issues/support, release management, and new projects', 'Assist in architecting, mapping, developing, and testing data movement to data warehouses (Redshift and SQL Server), with emphasis on the ETL process', 'Develop, document, and execute SQL/stored procedures/server scripts as needed to support ETL code', 'Determine ETL requirements and assist with production, setup, and execution of migrations', 'Work closely with BI and PASSPort teams on ETL development efforts including analysis and design of integration solutions, data and reporting needs of internal and external stakeholders, and enhancements', 'Identify and resolve data, technical issues and mediate business impact', 'Collect requirements, design, build and test reports and dashboards across applications and programs', 'Perform ad hoc analysis as required', 'Excellent writing and communication skills', 'Knowledge and interest in computer systems and the latest technologies', 'Familiar with AWS ecosystem including S3, Redshift databases, Lamda, EC2, Matillion and necessary supporting activities', 'The ability to learn new technologies quickly', 'Ability to write complex procedures using SQL (i.e. T-SQL, PL/pgSQL, etc.)', 'Experience in generic object-oriented languages (i.e. C#, Java, etc.)', 'Experience in scripting languages (i.e. Python, PowerShell, etc.)', 'Experience in ETL tools (i.e. Matillion, SSIS, Informatica, ets.)', 'Knowledge of testing tools and techniques and executing test scripts to test performance of ETL procedures', 'Significant experience in development, maintenance, and enhancements of ETL Mappings, Work-flows, and processes', 'Excellent analytical, organization, presentation and facilitation skills; ability to handle multiple tasks under tight deadlines', 'Familiarity with New York City’s data share platforms, including Open Data (DOITT’s DataShare) (FMS, PIP, APT).', 'Working knowledge of database back-end systems (i.e. AWS Redshift, SQL Server, Oracle, PostgreSQL).', 'Familiarity with Data Warehouse concept (Kimball), fact tables, slowly changing dimensions types.', 'Past utilization of code repositories (i.e. GitHub, GitLab or AWS CodeCommit).', 'Analyze user requirements and convert requirements to design documents.', 'Multi-task and change from one task to another without loss of efficiency or composure.', 'Development of technical specifications and plans.']",2020-08-08 13:30:08
Big Data Engineer,Digital dhara,N/A,"McLean, VA","['Big Data: 10 years (Required)', 'S3 + AWS Certification is a Must : 1 year (Required)', ""Bachelor's (Required)""]",2020-08-08 13:30:08
Junior Data Engineer,Mather Economics,4.3 out of 5,"Atlanta, GA 30350","['Designing schemas, data models and data architecture for Hadoop and HBase environments.', 'Implementing data flow scripts using Unix / Hive QL / Oozie scripting', 'Designing, building and support data processing pipelines to transform data using Hadoop technologies', 'Designing, building data assets in HIVE', 'Developing and executing quality assurance and test scripts', 'Working with business analysts to understand business requirements and use cases', ""A Bachelor's degree in Statistics, Industrial Systems and Engineering, Machine Learning, Applied Analytics, Computer Science, or Computer Engineering."", 'Minimum of 2 years of experience in understanding of best practices for building and designing ETL code Strong SQL experience with the ability to develop, tune and debug complex SQL applications is required', 'Strong SQL experience with the ability to develop, tune and debug complex SQL applications is required', 'Hands-on experience in Python object oriented programming (At least 2 years)', 'Knowledge in schema design, developing data models and proven ability to work with complex data', 'Hands-on experience with Hadoop, MapReduce, Hive, Oozie, Airflow, ElasticSearch', 'Understanding Hadoop file format and compressions', 'Familiarity with MapR distribution of Hadoop', 'Understanding of best practices for building Data Lake and analytical architecture on Hadoop', 'Scripting / programming with UNIX, Java, Python, Scala etc.', 'Knowledge in real time data ingestion into Hadoop', 'Experience in working in large environments such as RDBMS, EDW, NoSQL, etc.', 'Experience with Test Driven Code Development, SCM tools such as GIT, Jenkins i', 'Experience with Graph database']",2020-08-08 13:30:08
US Data Engineer,Babylon Health,3.3 out of 5,"Austin, TX","['Build, test and refine data pipelines for data analytics & business intelligence (BI)', 'Data modelling, process design and overall data pipeline architecture', 'Ensure the data quality and consistency with monitoring and support, and play an active role in establishing data governance around company KPIs', 'Work closely with the BI teams to design, build & test end-to-end solutions', 'Work closely with the Data Science team to support processing data into a form suitable for machine learning models', 'Champion SSDLC (Secure Software Development Life Cycle) within Analytics & Data Science and lead by example in building self-service, well tested solutions', 'Champion high engineering standards through comprehensive testing, code reviews, continuous integration and continuous deployment across the team', 'Our technology stack includes Python, dbt, AirFlow and a host of Google Cloud products that run on a range of technologies (GCP/AWS, Docker, GitHub, CircleCI & Jenkins)', ""Bachelor's Degree in Computer Science or related field"", 'Proven ability to looking at solutions unconventionally and explore opportunities and devise innovative solutions', 'Excellent communication skills (verbal and written) and interpersonal skills and an ability to effectively communicate with both business and technical teams', 'Experience gathering complex business requirements and identifying data needs', 'Experience with design & development of relational databases and data warehouses', 'Advanced level of proficiency in SQL development', 'Knowledge & expertise with Python, Shell, Java scripting', 'ETL development experience with large-scale DBs or big data systems such as Hive, BigQuery, AWS Redshift, Snowflake, etc', 'Experience using data transformation tools such as dbt', 'Experience using data orchestration tools such as Apache AirFlow or Apache Beam', 'Experience with using a cloud platform provider (such as AWS/GCP) to develop tools and infrastructure', 'Exposure to a BI reporting tool (such as Looker/Tableau) with an understanding of why they are an important part of the analytics stack', 'Experience analyzing data to identify deliverables, gaps, and inconsistencies.']",2020-08-08 13:30:08
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:30:08
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:30:08
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:30:08
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:30:08
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:30:08
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:30:08
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:30:08
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:30:08
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:30:08
AWS / Cloud Big Data Engineer,Youth Power Technosoft LLC,N/A,"Reston, VA",[],2020-08-08 13:30:57
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 13:30:57
Data Engineer / Software Engineer,Alion Science and Technology,3.7 out of 5,"Linthicum Heights, MD","['Not required to have a current U.S. Government Security Clearance on day one, but must be able to obtain one and therefore all candidates must be a U.S. Citizen. Employee will be processed for a Secret level clearance and possibly higher levels.', 'B.S. degree in Computer Science, Information Technology, Electrical Engineering, Statistics, or equivalent fields. Educational requirements may be adjusted for applicable work experience. Work experience may be adjusted for highly specialized knowledge or uniquely applicable experience.', '5+ years of experience as a developer, analyst, or engineer.', 'Experience with programming languages such as Python and Java.', 'Proficiency with acquisition and understanding of network data and the associated metadata.', 'Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics.', 'Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions).', 'Familiarity with various log formats such as JSON, XML, and others.', 'Ability to decompose technical problems and troubleshoot system and dataflow issues.', 'Experience with NOSQL databases such as Accumulo desired', 'Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer.', 'Experience with Kibana and Elasticsearch.', 'CJ']",2020-08-08 13:30:57
Software Engineer (ETL/Data),Rx Savings Solutions,N/A,"Overland Park, KS 66210","['Bachelor’s degree or greater in Computer Science or related experience', 'Strong analytical skills and attention to detail.', 'Ability to communicate with stakeholders of different backgrounds and skill levels.', 'Understanding of BI concepts and be familiar with relational or multi-dimensional modeling.', 'Demonstrated one or more of the four development areas of Data Management: Integration, Modeling, Analytics, Reporting.', 'Hands-on experience in SQL queries.', 'Highly-motivated, self-directed and flexible.', 'Investigate and resolve data related issues and provide support and troubleshooting expertise.', 'A great attitude with a passion for supporting your team and offering creative solutions.', 'Willingness and enthusiasm to learn new skills and techniques.', '0 - 2 years of work experience in Data.', 'Good understanding/experience in ETL Tools (Talend is a plus).', 'Understanding of RDBMS best practices.', 'Familiarity with Agile and Scrum methodologies.', 'Knowledge of Java or JavaScript.']",2020-08-08 13:30:57
Data Engineer,Vinli,N/A,"Dallas, TX 75201","['Lead data architect for the Vinli analytics team.', 'Integrate multiple data sources and software tools within the Vinli analytics ecosystem.', 'Collaborate with tech leaders across Vinli to ensure data strategy continuously meets all needs both internal and for Vinli customer.', 'Create and deliver executive presentations explaining the complex data in simple easy-to-understand terms that resonates with an executive audience.', 'BS in a STEM field.', 'Advanced design, coding and analytics skills in a big data ecosystem.', 'Expert knowledge of SQL.', 'Experience with other languages such as Python, R, PySpark, Java or Scala.', 'Strong background of data structures and big data tools (Spark, Hive, HDFS, ect.).', 'Data wrangling and ETL tooling experience.', 'Exceptional communication skills between both business and technical teams.', 'MS or higher in a STEM field.', 'Experience managing teams or projects.', 'Demonstrated experience with AWS, GCP or Azure.', 'Experience handling confidential and sensitive data.', 'Demonstrated ability to independently influence and drive outputs, meet deadlines, and set clear expectations and roadmaps.', 'Able to work in a fast-moving environment with high stakes for the company’s success', 'You take pride and responsibility seeing the product you worked on meet the real world for the first time', 'You love to learn and embrace the opportunity to contribute in new areas.']",2020-08-08 13:30:57
Data Engineer - IG Tech,Capital Group,3.9 out of 5,"Los Angeles, CA 90071","['Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like AWS.', 'Design, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems.', 'Design data schema and operate cloud-based data warehouses and SQL/NoSQL/temporal database systems.', 'Write Extract-Transform-Load (ETL) jobs and Spark/Hadoop jobs.', 'Own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.', 'Monitor and troubleshoot operational or data issues in the data pipelines.', 'Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions.', 'Influence your team’s technical and business strategy by making insightful contributions to team priorities and approach.', 'Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area.', 'Building relationships with your customers, partner teams and the engineers on your team.', 'Influence your team’s technical decisions by making insightful contributions to team priorities and approach.', 'You have a background in data and software engineering and a passion to learn.', ""You've made mistakes in the past and have learned a lot from them. You apply this learning regularly."", 'You believe there are generally multiple ways to solve a technical problem, each with different trade-offs.', 'You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you.', 'You believe that a team is strongest when it is diverse and includes multiple perspectives.', ""You are able to put yourself into your customer's shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them."", 'BS in Computer Science or related field, or an equivalent in relevant work experience.', '3+ years experience implementing big data processing technology: Hadoop, Apache Spark, etc.', '3+ years coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.).', 'Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets.', 'Experience in cloud-first design, preferably AWS (VPC, Serverless databases and functions, dynamic autoscaling, container orchestration, etc.).', 'Experience in data architecture, databases (e.g., MySQL, Oracle, PostgreSQL), SQL and DDD/ER/ORM design.', 'Interest and curiosity in emerging technologies on the web like GraphQL, web assembly, Lambda functions, MLaaS etc', 'Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.']",2020-08-08 13:30:57
Data Engineer,Mindtree,3.8 out of 5,"Bellevue, WA","['Azure Databricks: 2 years (Required)', 'Python: 1 year (Required)', 'R programming: 2 years (Required)', 'Temporarily due to COVID-19']",2020-08-08 13:30:57
Big Data Engineer,Quicken Loans,3.8 out of 5,"Detroit, MI 48226","['Job', 'Company', 'Develop ELT processes from various data repositories and APIs across the enterprise, ensuring data quality and process efficiency', 'Develop data processing scripts using Spark', 'Develop relational and NoSQL data models to help conform data to meet users’ needs using Hive and HBase', 'Integrate platform into the existing enterprise data warehouse and various operational systems', 'Develop administration processes to monitor cluster performance, resource usage, backup and mirroring to ensure a highly available platform', 'Address performance and scalability issues in a large-scale data lake environment', 'Provide big data platform support and issue resolutions to Data Scientists and fellow engineers', ""Master's degree in computer science, software engineering or a closely related field"", '2 years of experience with Hadoop distribution and ecosystem tools such as Hive, Spark, NiFi and Oozie', '2 years of experience developing batch and streaming ETL processes', '2 years of experience with relational and NoSQL databases, including modeling and writing complex queries', 'Proficiency in at least one programming language, such as Python or Java', 'Experience with Linux system administration, scripting and basic network skills', 'Excellent communication, analytical and problem-solving skills']",2020-08-08 13:30:57
Principal Big Data Engineer,Cool Minds LLC,N/A,"Durham, NC 27707","['Extract data from multiple sources, integrate disparate data into a common data model, and integrate data into a target database, application, or file using efficient programming processes', 'Document, and test moderate data systems that bring together data from disparate sources, making it available to data scientists, and other users using scripting and/or programming languages', 'Write and refine code to ensure performance and reliability of data extraction and processing', 'Participate in requirements gathering sessions with business and technical staff to distill technical requirement from business requests', 'Develop SQL queries to extract data for analysis and model construction', 'Own delivery of moderately sized data engineering projects', 'Define and implement integrated data models, allowing integration of data from multiple sources', 'Design and develop scalable, efficient data pipeline processes to handle data ingestion, cleansing, transformation, integration, and validation required to provide access to prepared data sets to analysts and data scientists', 'Ensure performance and reliability of data processes', 'Define and implement data stores based on system requirements and consumer requirements', 'Document and test data processes including performance of through data validation and verification', 'Collaborate with cross functional team to resolve data quality and operational issues and ensure timely delivery of products', 'Develop and implement scripts for database and data process maintenance, monitoring, and performance tuning', 'Analyze and evaluate databases in order to identify and recommend improvements and optimization', 'Design eye-catching visualizations to convey information to users', 'Bachelors degree in Computer Science or related field or equivalent experience', '3 years of SQL programming skills (Intermediate to Advance SQL programming skills)', '3 years programming experience in Python, R or other programming language', 'Demonstrated experience working with large and complex data sets', 'Experience with business intelligence tools (Tableau)', 'Able to understand SAS and SQL code, able to convert into Python/PySpark/R knowledge of table creation', 'Teradata knowledge there are a lot of inbound and outbound data transfers', 'Experience with Hadoop, Hive and/or other Big Data technologies', 'Experience with ETL or Data Pipeline tools', 'Experience with query and process optimization', 'Experience working in AWS and/or using Linux based systems', 'Ability to translate task/business requirements into written technical requirements', 'Reliable task estimation skills', 'Excellent quantitative, problem solving and analytic skills', 'Ability to document data pipeline architecture and design', 'Ability to collaborate effectively with business stakeholders, performance consultants, data scientists, and other data engineers', 'Proficient in use of MS Office applications including expert level Excel programming', 'Ability to quickly become an expert in operational processes and data of lines of business', 'Ability to troubleshoot and document findings and recommendations', 'Ability to communicate risks, problems, and updates to leadership', 'Ability to keep up with a rapidly evolving technology space', 'Monday to Friday', 'Big Data Technologies: 10 years (Preferred)', 'What is your visa status and can you work on w2 ?', 'More than 1 year', 'Temporarily due to COVID-19']",2020-08-08 13:30:57
"Software Engineer, Big Data","iHeartMedia, Inc.",3.7 out of 5,"Nashville, TN 37201",[],2020-08-08 13:30:57
Data Engineer - Azure Data Factory,Datasys America,N/A,"Houston, TX","['Monday to Friday', 'Azure: 4 years (Preferred)']",2020-08-08 13:30:57
Senior Data Engineer,The Predictive Index,2.8 out of 5,Massachusetts,"['Streamline the current data landscape and create a visible and reusable architecture to increase transparency and standardization of definitions.', 'Partner with stakeholders and BI Analysts to define and build a centralized data repository purpose-built for reporting.', 'Create and maintain a single source of truth data dictionary.', ""Streamline ETL's into coherent views to support effective and consistent reporting to the business."", ""Work closely with vendors from PI's tech stack to evaluate all API integration options with DOMO."", 'Build historical datasets to eventually leverage them into data science investigations.', 'Work closely with the systems team to understand and develop expertise in a growing range of PI data sources and their applications across the business. Staying up to date on the data lineage is critical.', 'Constitute rules of engagement and governance processes regarding the analytics data landscape.', 'Support and train team members on data architecture and similar concepts.', 'Experience building schema to scale and automate workflows.', 'Experience and knowledge of modern data stores, pipeline and reporting/analytic techniques and tools.', 'Experience building data models and data warehouses is highly desired.', 'Expertise in SQL, MYSQL, Python, and/or R is preferred.', 'Strong analytical skills: Ability to collect, organize, and analyze data; summarize findings and develop conclusions and recommendations.', 'Self-starter who takes initiative and is proactive and able to prioritize multiple projects involving various stakeholders by meeting deadlines and proactively communicating status updates.', 'Ability to communicate at all levels of the organization, from end-users to Senior Management.', ""Bachelor's degree in engineering, mathematics, computer science, or equivalent data engineering work experience, preferred""]",2020-08-08 13:30:57
ASAALT Data Engineer/Architect,Integrated Data Services Inc.,N/A,United States,"['Engineer and implement extract, transform and load (ETL) processes using Talend and PL/SQL.', 'Design and develop RESTFUL API interfaces using the OpenAPI specification and the Apigee Edge API Management Platform.', 'Define the strategy and architecture required to integrate data across multiple systems, improve the existing data warehouse architecture and support our transition to AWS.', 'Implement and optimize physical database design to support performance, scaling, security, backup, and disaster recovery requirements.', 'Creates and enforces technology-specific guidelines, standards, policies and procedures', 'Work closely with application developers and data analysts to design and optimize data access, query, reporting, and analysis strategies.', 'Communicate with the Product Management and development teams to raise issues and identify potential barriers in a timely fashion.', 'This position requires a minimum of 5 years of experience as a data engineer or architect.', 'This position requires a minimum of 5 years of experience developing ETL or ELT solutions.', 'This position requires a minimum of 5 years of experience with Oracle SQL and PL/SQL.', 'This position requires a minimum of 3 years of integrating DoD contracting, acquisition, financial management, program management, logistics management, manpower/personnel management or related data within a DoD organization.', 'Candidates with Talend and Apigee experience are preferred.', ""This position requires a minimum of a Bachelor's degree from an accredited college or university in business management, engineering, computer science, mathematics, accounting, economics or other related discipline."", 'Experience in lieu of education may be considered if the individual has seven (7) or more years equivalent technical training or work experience.', 'Applicants selected for employment will be subject to a Federal background investigation and must meet additional eligibility requirements for access to classified information or materials.', 'Some travel may be required.', 'Normal work schedule hours may vary, Monday through Friday. May be required to work additional hours and/or weekends, as needed, to meet deadlines or to fulfill travel obligations.', 'Commensurate with experience.']",2020-08-08 13:30:57
AWS Cloud Engineer,Integress Inc.,N/A,"Conshohocken, PA 19428","['Architecting and building secure and reliable AWS Ecosystems that support compute, storage, data and application services', 'Setup and configuration of the networking and security environment including Security Group configurations, Amazon Virtual Private Clouds (VPC), subnets, route tables, etc.', 'Setup and configuration of application integration services including AWS Step Functions, Amazon MQ, SNS, SWF and SQS', 'Provide support for multi-tier web architectures with services such as Amazon EC2 Auto Scaling, Amazon Elastic Load Balancing (ELB), AWS Route 53, AWS Lambda, Amazon API Gateway and Amazon Elastic File System (EFS)', 'Usage of infrastructure build tools, containers and container orchestration tools such as AWS CloudFormation, Docker, Amazon ECS, Kubernetes, etc.', 'Provide support for scalable Cloud data solutions using MPP Data Warehouses (Snowflake, Redshift, or Azure Data Warehouse/Synapse), data storage (S3 or Azure Blob Storage) and analytics platforms (i.e. Spark, Databricks, etc.)', 'Provide support for DevOps methodology and tools, such as Puppet, Chef, Git, Docker, etc.', 'Bachelor’s degree, or equivalent experience, in Computer Science, Engineering, Mathematics or a related field. Commensurate work experience will be considered in lieu of degree.', 'Certified AWS Solution Architect', '5+ years of setup, configuration and administration of AWS environments and a solid working knowledge of cloud networking, security and identify and access management', '4+ years of hands on experience of cloud native architecture design, implementation of distributed fault-tolerant enterprise applications on cloud', '3+ years of hands-on experience architecting, developing, and deploying scalable data solutions using MPP databases (Redshift, Snowflake, or Azure Datawarehouse), data storage (S3 or Azure Blob Storage) and analytics platforms (i.e. Spark, Databricks, etc.).', '2+ years of building and deploying applications in AWS (S3, Hive, Glue, EMR, AWS Batch, Dynamo DB, Redshift, Cloudwatch, RDS, Lambda, SNS, SQS etc.)', '4+ years of Java/Python, SQL, SparkSQL, and/or PySpark', 'Experience working with different types of data – structured, unstructured, and semi-structured in batch and real-time', 'Demonstrated technical leadership experience working successfully as part of a large project team', 'Demonstrated ability to communicate highly technical concepts in business terms and articulate business value of adopting cloud data technologies', 'Excellent written and oral communication skills', 'Experience in the use of automation software such as OpsWorks, Puppet, or Chef.', 'Experience in programming languages, such as Bash, JavaScript, Perl, Ruby, and Python, and experience with Node.js, Typescript, and Java.', 'Software or data development background', 'Experience working at a consulting company', '401(k)', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Referral Program', 'Monday to Friday', 'Bonus Pay', 'Client Facing: 2 years (Required)', 'AWS VPC Setup & Configuration: 5 years (Required)', 'building and deploying applications in AWS : 3 years (Required)', 'One location', 'Yes: H-1B work authorization', 'No: Not providing sponsorship for this job', 'Innovative -- innovative and risk-taking', 'Aggressive -- competitive and growth-oriented', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.integress.com', 'https://www.linkedin.com/company/integress-inc./', 'Only full-time employees eligible', 'No']",2020-08-08 13:30:57
Principal Data Engineer,Caserta,N/A,"New York, NY","['Lead teams to develop Cloud enabled Data and Analytics solutions', 'Lead the development of cloud-based and hybrid data warehouses & business intelligence platforms', ""Architect & Design Data Pipelines to ingest structured and unstructured Data with Python, Spark & PySpark API's"", 'Advise customers on ETL Best Practices and independently lead and manage the implementation of Data & Analytics solutions.', '10-15+ years of experience working in Data Engineering or Data Warehousing', 'Hands-on experience with leading commercial Cloud platforms, including AWS, Azure, or Google', 'Experience leading data warehousing, data ingestion, and data profiling activities', ""Advanced SQL & Python skills and experience Architecting, designing and building Streaming Data Solutions with Spark and PySpark API's"", 'Strong aptitude for learning new technologies and analytics techniques', 'Highly self-motivated and able to work independently and lead teams of Data Engineers', 'Understanding of agile project approaches and methodologies', 'Experience working with Business Stakeholders to elicit business requirements', 'Experience building and migrating complex ETL pipelines', 'Deep expertise with quantitative analysis techniques (e.g.,', 'Bachelor’s degree in Business Analytics, Computer Science or a closely related field required, M.S Preferred']",2020-08-08 13:30:57
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:31:43
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:31:43
Data Warehouse Engineer,CareFirst BlueCross BlueShield,3.9 out of 5,"Washington, DC 20002",[],2020-08-08 13:31:43
"Senior Geospatial Data Engineer, AI for Earth - Sustainability",Microsoft,4.2 out of 5,"Redmond, WA","['Design and implement data processing and ingestion pipelines', 'Work with external data providers to manage data preparation, ingestion, and documentation', 'Prepare documentation and examples for geospatial data processing tasks that depend on these data sets', 'Work with external collaborators to ensure that data and documentation are user-friendly', 'Work with our data science team to facilitate the development of machine learning tools and applications on top of our geospatial data archives', 'Fluency with Python required', 'Fluency with geospatial raster analysis tools (e.g. rasterio, GDAL) required', 'Fluency with GIS software (e.g. ArcGIS, QGIS, CARTO, Mapbox) required', 'Fluency with Linux required', 'Fluency with cloud (Azure, AWS, or GCP) infrastructure required', 'Fluency with collaborative platforms (e.g. GitHub, GitLab) required', 'Bachelors or higher in in computer science, software engineering, remote sensing, geography/GIS, or related fields required', 'At least three years of software development experience required', 'Fluency with open-source, cloud-based geospatial analysis tools (e.g. Pangeo, STAC) preferred, but not required', 'Fluency with distributed computing/querying frameworks (e.g. Kubernetes, Hadoop, Spark, Dask, Azure Batch, BigQuery) preferred, but not required', 'Experience with Jupyter preferred, but not required', 'Familiarity with machine learning preferred, but not required', 'Familiarity with R preferred, but not required', 'Interest and comfort in engaging with the environmental science and sustainability communities preferred, but not required']",2020-08-08 13:31:43
Software Engineer - PySpark Developer,"JPMorgan Chase Bank, N.A.",3.9 out of 5,"Newark, DE","['BS/BA degree or equivalent experience', 'Advanced knowledge of application, data, and infrastructure architecture disciplines', 'Understanding of architecture and design across all systems', 'Working proficiency in developmental toolsets', 'Knowledge of industry-wide technology trends and best practices', 'Ability to work in large, collaborative teams to achieve organizational goals', 'Passionate about building an innovative culture', 'Proficiency in one or more modern programming languages', 'Understanding of software skills such as business analysis, development, maintenance, and software improvement']",2020-08-08 13:31:43
Data Visualization Engineer,Ace-stack LLC,N/A,"Seattle, WA",[],2020-08-08 13:31:43
Data Engineer 2,CDO Chief Digital Office,N/A,"Dallas, TX","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Working experience with Tableau, QlikView, Mode, Matplotlib, Jupyter, or similar data visualization tools', 'Extensive experience analyzing data using SQL', '2+ years of Python or Java development experience', '2+ years of SQL experience (NoSQL experience is a plus)', '3+ years of experience with schema design and dimensional data modeling', 'Ability in managing and communicating data warehouse plans to internal clients', '3+ years of relevant experience such as implementing statistical analysis, developing cloud-based data lakes / data warehouses, managing data science projects, developing APIs, developing machine learning models, creating advanced data visualizations.', 'Good communication and writing skills to facilitate productive collaboration with other team members and business units;', 'Strong knowledge of project management principles and concepts;', 'Experience solving problems with an emphasis on product development', 'Experience with predictive modeling and dissemination of research results;']",2020-08-08 13:31:43
Sr. Data Engineer,Vivid Seats,3.4 out of 5,"Chicago, IL 60606","['Expert knowledge of a relational database platform such as MySQL, Postgres, Oracle or SQL Server', 'Experience in either modeling transaction or data warehousing with an interest in learning both methodologies', 'ETL pipeline and tooling experience', 'Coding and scripting experience using Java, Python or Bash', 'Proficiency in working in a Linux environment', 'Cloud experience with either GCP, AWS or Azure and experience running data platforms within a cloud environment', 'A willingness to participating in an on-call rotation', 'Experience with configuration as code tools such as Ansible, Terraform etc.', 'Experience with containerization such as Docker', 'Experience with continuous integration, testing, and deployment using tools such as Jenkins']",2020-08-08 13:31:43
Data Engineer,"Olivine, Inc.",N/A,"Berkeley, CA 94704","['Frame and break down complex problems into key components, design solutions and data analysis tools to derive insights, and recommend practical solutions to achieve results', 'Develop reliable data pipelines to ingest and transform data from a wide variety of sources', 'Perform numerical analysis, data cleansing, energy data modeling, and data visualization', 'Streamline workflows and processes through the development and deployment of code or software', 'Collaborate with a cross-functional team in a fast-changing environment to drive initiatives', 'Demonstrate strong leadership, presentation, and written and spoken communication skills to build internal and external stakeholder relationships', 'Bachelor’s degree with 2+ years of relevant work experience', 'Professional experience and/or significant project course work in energy, data analysis, and programming', 'Demonstrated experience solving engineering and analytical problems using programming languages such as or similar to Python, SQL, R, or MATLAB', 'Experience with Python libraries such as Pandas, NumPy, Scikit-Learn, and Matplotlib', 'Exposure to concepts and methods in electricity markets, distributed energy resources modeling, or other relevant engineering systems modeling', 'Knowledge of distributed energy resource technologies and applications such as battery storage, electric vehicle smart charging and grid integration, and demand response strategies', 'Excellent writing, interpersonal, problem solving, and communication skills', 'Professional experience or project work in optimization and machine learning', 'Experience deriving insights from large data sets', 'Experience with relational databases such as PostgreSQL or Microsoft SQL', 'Experience with a cloud provider solution such as Azure or AWS', '401(k)', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'relevant work: 2 years (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'One location', 'olivineinc.com', 'Temporarily due to COVID-19']",2020-08-08 13:31:43
Data Engineer,Built In,N/A,Illinois,"[""Ownership of Built In's Data Pipeline; this is the data that we pull from our home-built data pipeline and create analytics based on raw events."", 'Must collaborate with other members of the engineering team, whether as mentor or mentee—especially via pair-programming.', 'Is primarily expected to be an individual contributor, focused on writing and reviewing code.', 'Must advocate for focus on technical debt in concert with execution of new features, and has an understanding that doing so allows our team to scale with the demands placed upon us in a stable and robust manner.', 'Be passionate about programming and learning new technologies; focused on helping themselves and the team improve their skills.', 'Must be comfortable with and supporting other other engineering teams by contributing to our service oriented architecture.', '4+ years of experience within the field of data engineering or related technical work.', 'Proven experience with Python. Understanding of Go.', 'Experience with data warehousing and data pipeline tools (examples being Snowflake and Airflow).', 'Exposure to principles of automated testing and commitment to testing as a way of producing robust code.', 'Experience with Git and understanding of our basic workflow (branching for your own work; pull requests to commit work back).', 'Experience with Unix on the command-line, whether via terminal in MacOS or directly on a version of Linux/*BSD, is greatly valued.']",2020-08-08 13:31:43
Azure DevOps Engineer with Hadoop Data,Riya Software Consulting,N/A,"Alpharetta, GA","['Experience of IT service business and engineering of multi-year managed services', 'From 10-15 years plus of demonstrable enterprise level IT delivery experience', 'Cloud (5 years) in an engineering role using service and hosting solutions such as private/public cloud IaaS, PaaS and SaaS platforms. Experience in engineer technical solutions for Microsoft-centric solutions based on industry standards using Azure or other cloud providers IaaS, PaaS and SaaS capabilities. Nice to have Experience with any of the following: Azure, Azure Stack, Azure AD', 'Scripting (5 years) – having knowledge and experience with Microsoft PowerShell (required) and Linux shell scripting (preferred). Being able to understand and use best practices of completing tasks and finding solutions using existing or building new scripts to help automate today’s manual infrastructure and application tasks.', 'Functional knowledge of programming scripting and data science languages such as JavaScript, PowerShell, Python, Bash, SQL, .NET, Java, PHP, Ruby, PERL, C++, R, etc.', 'Understanding of CI/CD delivery using code management, configuration management and automation tools such as GitHub, VSTS, Ansible, DSC, Puppet, Ambari, Chef, Salt, Jenkins, Maven, etc.', 'Configuration Management (3 years) – being able to develop recipes for new solutions to deploy consistent systems, enforce configurations and settings through configuration management systems like PowerShell DSC, Chef or Puppet.', 'Tools & Environment: Hadoop Cloudera Manager, Hadoop Stack (Hive, Ranger, Atlas, Spark, NiFi, Impala), SQL Server 2012/2016, PowerBi Suite, Tableau.', 'Experience setting up a Hadoop Cluster environment, administrating including adding and removing cluster nodes, cluster capacity planning and performance tuning. Experience in running Hadoop jobs for processing multiple records of data, monitoring and sizing clusters, developing Hive queries to perform data analysis for large datasets and supporting various Solution Teams providing guidance around data quality and integrity.', 'Networking (1-3 years) - Have a solid understanding of networking capabilities, including load balancers, web application firewalls, network access control lists (NACLs), security groups, routing, tracing, DNS resolution are key to building efficient and stable solutions that prevent business downtime and provide high availability capabilities.', 'Documentation (2-3 years) - Being able to create technical documents that provide insight into the design and implementation of a solution provides teams with the ability to effectively communicate their needs and requirements across the organization. The candidate has to be able to produce clear and concise architecture and design documentation that can assist his team and other peer groups in understanding of the built solutions. The candidate must also be able to communicate complex technical issues with sensitivity to diverse audiences and people with different level of technical understanding that range from entry level support teams, management, and technical engineering resources.', 'Operational Support awareness (5 years) – A good understanding of what it takes to support the deployed applications and solutions is key to providing great service to the end users. The candidate has to be able to put themselves into a position of understanding of their consumer pain points to be able to figure out creative ways not only to find quick workarounds but also analyze the root cause of the problem and come up with ideas of resolving them in the long term.', 'Source code management (3 years) – Familiarity with source control tools such as Git, Team Foundation Server (TFVC), and SVN are a big part of automation and compliance. Understanding how these tools are and could be used is key to not only provide the proper change control management to new versions of products that are being developed, but also to help provide consistency in deploying those products/solutions throughout environments using automation.', 'Microsoft PowerShell: 5 years (Required)', 'Configuration Management: 3 years (Required)', 'Azure Cloud Engineering: 5 years (Required)', 'Hadoop Cloudera Manager, Hadoop Stack: 2 years (Required)', 'Fully Remote', 'None', 'Monday to Friday']",2020-08-08 13:31:43
Senior Data Engineer,AARG,4.5 out of 5,"Richmond, VA","['Build data pipeline frameworks to automate high-volume and real-time data delivery to our cloud platform', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies', 'Develop and enhance applications using a modern technology stack such as Java, Python, Shell Scripting, Scala, Postgres, Angular JS, React, and Cloud based data warehousing services such as Snowflake', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree; nice to have Accounting / finance business knowledge is a plus', '5+ years of experience building data pipelines and using ETL tools to solve complex business problems in an Agile environment', '5+ years of experience in at least one scripting language (SQL, Python, Perl, JavaScript, Shell)', '3+ year of experience using relational database systems (Snowflake, PostgreSQL, or MySQL)', '3+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink)', '3+ years of experience in big data technologies (MapReduce, Cassandra, Accumulo, HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)', '3+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', 'Monday to Friday', 'Data: 3 years (Preferred)', 'United States (Preferred)', 'Likely', 'Yes', 'Fully Remote']",2020-08-08 13:31:43
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:31:43
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:31:43
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:31:43
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:31:43
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:31:43
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:31:43
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:31:43
Podcast Editor,"iHeartMedia, Inc.",3.7 out of 5,Massachusetts,[],2020-08-08 13:32:35
Industrial Engineer - Supply Chain,Starr & Associates,4.5 out of 5,"Atlanta, GA",[],2020-08-08 13:32:35
Data Engineer,Airlines Reporting Corporation (ARC),3.4 out of 5,"Arlington, VA","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 13:32:35
Software Engineer II - Data Platform,Electronic Arts,3.8 out of 5,"Redwood City, CA 94065",[],2020-08-08 13:32:35
EOS Operations Engineer,KBR,4.1 out of 5,"Greenbelt, MD","['Perform Online Operational shift work for the EOS spacecraft if needed\uf02d', 'Assist with the EOS Operations training and certification plan\uf02d', 'Facilitate process improvements for EOS operations\uf02d', 'Update/Maintenance/Creation of spacecraft documentation\uf02d', 'Coordinate with the FOT Management, Software Development and Ground System Engineering and other mission stakeholders to help maintain ground system hardware/software delivery schedules\uf02d', 'Support EOS Automation development\uf02d', 'Represent the EOS missions at routine, ad hoc, and other periodic meetings, including:', 'Weekly Operations status meetings\uf02d']",2020-08-08 13:32:35
Data Engineer,the NBA,4.2 out of 5,"Secaucus, NJ 07094","['Understands business needs and develop solutions that delight consumers and customers', 'Understands Agile artifacts and develops applications based upon business priority.', 'Collaborate with project partners to ensure all requirements are met.', 'Handles relationships with end-user communities. Interacts regularly with users to gather feedback, listen to their issues and concerns, recommend solutions.', 'Build scalable, fault-tolerant batch and real-time data pipelines to power internal applications, operational workflows, and business intelligence platforms', 'Create and maintain data-driven APIs to support a wide range of integration with NBA partners', 'Recommend and implement best practices for data management and governance', 'Demonstrate your technical abilities and contribute to our overall architecture', 'Help implement the Enterprise Data Architecture for NBA and help implement it in multi-functional alignment with the Data teams that exist across functions like Marketing, Finance, HR etc.', 'Provide insights during application design and development for highly complex or critical machine learning projects across numerous lines of business and shared technology.', 'Ensure alignment to enterprise architecture and usage of enterprise platforms when delivering projects', 'Continuously improve the quality of deliverables and SDLC processes', ""Master's Degree in Computer Science, Engineering, or Management of Info Systems/Technology preferred"", 'Advanced Education in Statistics or Mathematics would be a plus 3+ year of experience in developing ETL and ELT pipelines using SQL and MSFT SSIS 3+ years of experience in developing BigData and/or machine learning solutions 3+ years of experience in a highly regulated industry', '1+ Years of experience defining and/or designing data architectures', '1+ Years of experience leading and/or managing product engineering teams', 'Experience with the MS Cloud stack (Azure) or AWS', 'Experience with SQL, NoSQL, BigData and Graph Technologies along with Programming languages like R, Python, Kafka, Storm etc.', 'Experience building microservices', 'Background in agile SW development and Scaled Agile Frameworks', 'A true believer in measuring success based on working software and in quick prototyping', 'Someone who is a passionate coder and can spin up a snippet of code quickly', 'Strategic thinker with the ability to build and execute innovative digital product, combined with tactical ability to execute simultaneously against multiple contending priorities', 'Someone with an iterative approach, drive to move fast and think big', 'Experience working with and/or managing internal and external teams at the same time, working with multiple brands and digital properties of varying maturities', 'Demonstrated ability to partner and communicate effectively with non-technical team members, resolving contending or contradictory objectives, and unifying disparate ideas into a homogenized solution', 'Ability to be versatile and handle multiple projects and re-prioritizations', 'Possess the ability to influence others, implement change, and standardize processes in a complex business environment', 'A passion for data and growing in your current role', 'Ability to effectively and appropriately interview technical candidates', 'Passion for Automation and Hunger for Acceleration', 'Keen knowledge of Devops as well as RPA is a big plus', 'Experience with Architecting Applications (e.g. Design Patterns, distributed applications etc.) with the aim of reuse would be a big plus', 'Superb communication skills (both written and verbal)', 'Great teammate - should be ready to go beyond to help immediate team and do not be averse to not shy away from asking for help if needed.', 'Ability to translate ideas into solutions based on user and business needs', 'Open Eagerness to learn new technologies and bring new ideas to the table']",2020-08-08 13:32:35
Big Data ETL Engineer/Data Engineer,Tech2i,N/A,"Columbia, MD 21046","['Transition of legacy ETLs with Java and Hive queries to Spark ETLs.', 'Design, develop, test and release ETL solutions including data quality validations and metrics that follow data governance and standardization best practices.', 'Design, develop, test and release ETL mappings, mapplets, workflows using Streamsets, Java, Spark and SQL.', 'Performance tuning of end-to-end ETL integration processes.', 'Analyze and recommend optimal approach for obtaining data from diverse source systems.', 'Work closely with the data architects, who maintain the data models, including data dictionaries/metadata registry.', 'Interface with business stakeholders to understand requirements and offer solutions.', 'Proficient understanding of distributed computing principles and hands on experience in Big Data Analytics and development', 'Good knowledge of Hadoop and Spark ecosystems including HDFS, Hive, Spark MapReduce and Sqoop', 'Experience in designing and developing applications in Spark using Scala that work with different file formats like Text, Sequence, Xml, parquet and Avro', 'Experience of using build tools Ant, SBT Maven', 'Strong SQL coding; understanding of SQL and No SQL statement optimization/tuning.', 'Ability to lead designing and implementation of ETL data pipelines.', 'Experience developing data quality checks and reporting to verify ETL rules and identify data anomalies.', 'AWS development using big data technologies.', 'Techniques for testing ETL data pipelines either manual or using tools.', 'AWS cloud certified', 'CMS experience', 'Experience with Databricks', 'Bachelor’s Degree with 5 years’ experience or10+ years of experience in the software development field.', '5+ years of Bigdata ETL development experience.', '4+ years of AWS big data experience.', '3+ years of experience developing data validation checks and quality reporting.', '4+ years of experience tuning Spark/Java coding, SQL and No SQL.', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Java: 5 years (Preferred)', 'Big Data/HQL: 3 years (Preferred)', 'Multiple locations', 'Dependable -- more reliable than spontaneous', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.tech2i.net']",2020-08-08 13:32:35
Category Manager,Sonoco,3.6 out of 5,Remote,"['Create a clear vision and develop long term strategic plans for the specific category spend area to support overarching category plans.', 'Serve as liaison point for aligned business area (e.g., Flexibles, Closures, Reels etc.)', 'Ensure that the category strategies are highly aligned to current and future business needs (and overall category strategy) and that the supply base is aligned with and capable of supporting these strategies.', 'Drive communication/reporting of strategy to keep internal clients informed of progress and benefits', 'Identify and initiate focused projects (sourcing, demand management, etc) and manage pipeline of projects within selected categories to ensure results meet targets', 'Engage strategic sourcing team and tactical sourcing team to drive execution of projects in support of category strategies', 'Lead supplier relationship management for strategic suppliers within category', 'Define KPIs and Targets and manage scorecards', 'Become subject matter expert in this functional area and provide commodity knowledge to internal clients on spend data, supply base, industry trends, benchmarking, and best practices', 'Bachelor of Science in Engineer, Business, Operations or Supply Management; MBA preferred', '5-7+ or more years of experience in Supply Management Leadership.', 'Experience managing spend of $100MM to $200MM']",2020-08-08 13:32:35
Data Analytics Engineer,Refinitiv,3.6 out of 5,"Brookfield, WI 53005","['Design, develop, implement and support complex solutions using SAS, Domo and Power BI', 'Assist users during requirements gathering, design, testing, and implementation phases', 'Build, manipulate, analyze and verify large and sophisticated datasets', 'Craft reports and visualizations to present the data in ways that are significant, impactful, and understandable', 'Lead output review sessions with internal and external partners in a clear and effective manner', 'Clearly document data workflows and solution runbooks for end users and support teams', 'Support other team member’s growth through information sharing and cross-training', 'Seeks opportunities to expand technical knowledge and explore new methods to tackle problems', 'BS or MS Degree in Computer Science, Mathematics, Statistics, or a related technical field, or equivalent experience', 'Detail oriented with strong analytical and problem-solving skills', '4+ years of development using ETL (Extract, Transform, Load) software, preferably with SAS or Domo', '4+ years using reporting and data visualization tools such as SAS, Domo, Power BI, or Tableau', 'Hands-on working knowledge and experience with SQL and relational databases', 'Practical experience establishing and utilizing data analytics standard methodologies', 'Experience with transactional data processing, ETL, data warehouse, data mart, and operational reporting solutions is preferred', 'Familiarity with BMC’s Control-M and/or Remedy, JIRA, or Salesforce Service model is a plus', 'Exceptional teammate who establishes positive working relationships', 'Proven leadership skills', 'Good communication skills with the ability to express sophisticated concepts effectively', 'Demonstrated ability to multi-task in a dynamic environment']",2020-08-08 13:32:35
Data Engineer,Entera,N/A,"New York, NY","['Use Python, SQL, and R to improve upon a best-in-class data pipeline and develop our workflows', 'Contribute to cloud-first services that improve our reporting, analysis, and metrics collection efforts', 'Use agile software development processes to iteratively make improvements to our back-end systems', 'Mold front-end and back-end data sources to help draw a more comprehensive picture of user flows throughout our system', 'Deliver on detailed specifications for business intelligence and reporting needs', 'Contribute and further develop our data-driven culture', 'Work with product and engineering in cross-functional teams to deliver on improvements to our systems', 'MS or PhD in Computer Science, Mathematics, Statistics, Physics, Economics, or similar hard-science', '3+ years hands-on experience in Data + Analytics at growing product-driven tech companies', 'Proficiency in cloud services and modern ETL workflows', 'Advanced capabilities across Python, R, and SQL', 'Understanding of Spark', 'Strong analytical and problem solving skills', 'Working knowledge of Python web frameworks like Flask', 'Software development background']",2020-08-08 13:32:35
Data Engineer,Strike Social,3.7 out of 5,"Chicago, IL 60606","['Create and maintain optimal data pipeline architecture.', 'Assemble large, complex data sets to meet functional and non-functional business requirements.', 'Author the pipeline code required for optimal extraction, transformation, and loading of data from a wide variety of data sources.', 'Work with Data Scientists and Systems Engineers to design data delivery architecture.', 'Work with stakeholders including the Executive and Product teams to assist with data-related technical issues and support their data insight needs.', 'Create data tools for team members that assist them in building and optimizing our products.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. PostgreSQL administration familiarity a plus.', 'Strong Python scripting skills. Ruby a plus.', 'Familiarity with API endpoint interactions and techniques for handling query complications.', 'Understanding of Containerization, Micro-Service, and Server-less a strong plus.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Working knowledge of message queuing, stream processing, and highly scalable data stores.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'The ideal candidate would have 3+ years of experience in a Data Engineer role, or 5+ years in any Software Engineering role with demonstrable familiarity of the Data Engineering/Science space. Work experience, academic instruction, and/or code portfolio will all considered.']",2020-08-08 13:32:35
Data Engineer,Frontend Arts,N/A,"Seattle, WA","['Good experience in data engineering skills – SQL, data warehousing, ETL and data modeling.', 'Good coding skills (python preferred)', 'Proficient over data structures and algorithms.', 'Strong communication skills to engage people together.', 'Fully proficient in pipeline building and job automation.']",2020-08-08 13:32:35
Data Engineer,Steampunk,N/A,"McLean, VA 22102","['Profile and analyze source system data to determine data relationships, keys, conformed dimensions, and necessary transformations', 'Identify data quality issues', ""Ensure data structures are designed for flexibility to support clients' business needs"", 'Develop strategy and repeatable process for maintaining Enterprise Data Models', 'Design & test integrations to/from data modeling tools', 'Work with developers to create an API access layer for the data', 'Reverse engineer complex, new datasets, and map these new datasets to the existing model.', 'Provide documentation and instruction to data modelers and developers', 'Constantly interact with both ETL developers and end users data analysts to share knowledge, collect feedback, and provide additional implementation requirements.', 'Develop, maintain, and review data processes and architecture for both on-premise and cloud-based data systems', 'You will contribute to the growth of our Data Exploitation Practice.', 'Who wants to do something different......', 'US Citizen Only', 'Ability to hold a position of public trust with the US government.', '5+ years industry experience coding commercial software and a passion for solving complex problems.', '3+ years direct experience in Data Modeling and Data Solution Development', 'Experience with data modeling tools and their integrations', 'Experience developing processes to manage data model development, principles, and standards', 'Experience architecting data warehouses', 'Demonstrated and understanding customer requirements and prioritize for maximum customer / user experience.', 'Demonstrated on-the-job experience as a big data architect/engineer', 'Demonstrated on-the-job experience manipulating structured and unstructured data for analysis', 'Demonstrated on-the-job experience constructing complex queries to analyze results using databases or in a data processing development environment', 'Demonstrated on-the-job experience aggregating results and/or compiling information for reporting from multiple datasets', 'Demonstrated experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels', 'Demonstrated experience translating product requirements into system solutions that take into account technical, schedule, cost, security, and policy constraints', 'Demonstrated experience working in an Agile environment', 'Demonstrated experience providing technical direction to project teams of developers and data scientists who build web-based interfaces, dashboards, and reports', 'Demonstrated experience working with data science tools technologies, particularly Python or SQL', 'Demonstrated experience with Solr, Elasticsearch, or similar tool', ""Bachelor's degree in computer science, information systems, engineering, business, or a scientific or technical discipline""]",2020-08-08 13:32:35
Data Engineer,MASx,N/A,"Brighton, MA 02135","['Build and maintain ETL pipelines using Azure-supported cloud-based tools and technologies', 'Integrate with the API connections of our many 3rd party applications and partners to ensure data can be extracted and stored within our Data Lake environment', 'Perform data cleaning and curation of various data sources in different formats, performing complex joins and defining relationships to unify data as needed', 'Design and implement Data Warehousing solutions and identifying appropriate fact/dimension tables for relevant data models', 'Implement SSAS tabular model cubes for serving up data to our analysts and other areas of the business', 'Draft reports and visualizations for end user consumption', 'Deep knowledge & experience building ETL processes', 'Overall understanding of database development and design, as well as Data Warehousing / Data Lake methodology', 'Experience in defining and developing tabular data models using SSAS and/or Power BI', 'Good understanding of how data helps and drives business', 'Proficiency in various programming/scripting languages', 'SQL, Python; Preferred - DAX, PowerShell, .NET', 'Experience with Azure or AWS and a solid understanding of cloud-based technologies and infrastructure', 'Great verbal and written communication / presentation skills', 'Good understanding of general business terminology and day to day operations', 'Ability to learn new technologies and processes as needs change', 'Experience with Microsoft O365 Power Platform (Power BI, PowerApps, Flow)', 'BS or MS in Engineering, Computer Science, or related field', 'A very supportive team, a culture of ""do your job"" autonomy, and access to all levels of the organization', 'Health insurance (including medical, dental, vision, LTD, STD, and life insurance)', '401(k) with generous employer match', 'Employee stock options', 'Subsidized gym and commuter benefits', 'Unlimited time off policy', 'Professional development opportunities', 'Free ButcherBox each month']",2020-08-08 13:32:35
Data Engineer,Emergere Technologies,N/A,"Chicago, IL","['Create and maintain optimal data pipeline architecture,', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field (Masters Preferred).', '5+ years of experience in a Data Engineer role', 'Experience with healthcare datasets, clinical data, payer/claims data, SDOH data, etc.', 'Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Skilled in problem-solving with strong attention to detail.', 'Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.', 'Excellent follow-up skills paired with the ability to multi-task and determine root causes.', 'Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.']",2020-08-08 13:32:35
Data Engineer,East Bay Community Energy,N/A,"Oakland, CA 94612","['Culture: EBCE fosters a culture of open communication, responsibility, curiosity, accountability, teamwork, and care. We welcome a diversity of experiences and perspectives.', 'Candidates should visit ebce.org for the online application.', 'Location: This position will be based in EBCE headquarters in Oakland, near BART.', 'Employment: As an equal opportunity employer, we are committed to diversity, equity, and inclusion and strongly encourage people of color, women, those who identify as LGBTQ+, non-binary individuals, and those with disabilities to apply.', 'Compensation: Competitive compensation package offered, based on candidate experience. A Data Engineer salary ranges from $107,100 to $131,250, with discretionary changes based upon experience.', 'Benefits: EBCE offers a generous benefits package including', 'Individual, family and domestic partner health insurance', 'Monthly Wellness benefit (ex: stipend for gym or wellness classes)', 'Retirement and Employer Matching Contributions', 'Transit stipend (ex: monthly contribution to Clipper Card)', 'Paid parental and family leave', 'Health and dependent care account', 'Paid Vacation', 'Other benefits', 'Further developing and maintaining the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources (ETL).', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability, among others.', 'Maintaining and versioning internal and external API’s linked to EBCE’s Google Cloud Platform.', 'Implementing and developing best practices for Data Storage and Query optimization, as well as strategies for reducing and/or maintaining GCP’s current cost load.', 'Helping develop and maintain an optimal database versioning internal strategy.', 'Collaborate with EBCE’s Analytics team in preparing and designing systems to provide data to internal and external partners, universities, portals, and websites using the Analytics Google Cloud Platform technology stack.', 'Creating error logging, reporting solutions and preparing required documentation.', 'Collaborate with Analytics team and external partners in assembling large, complex data sets that meet functional / non-functional business requirements.', 'Occasional development of web scraping tools including but not limited to websites, and PDFs.', 'Education: Bachelor’s in computer science or another engineering and/or data-intensive discipline (MS preferred).', 'Experience:', 'Advanced working SQL knowledge and experience working with relational databases,query (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’data stores', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Experience and/or knowledge of energy systems,', 'Experience and/or knowledge of programs and policies to advancing decarbonization strategies as they relate to the energy industry.', 'Extensive experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Extensive experience with Python', 'Extensive experience with cloud services (e.g., Google Cloud Platform, Amazon - EC2)', 'Experience with stream-processing systems', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience in SQL for BigQuery for Google Cloud Platform', 'Monday to Friday', 'SQL: 4 years (Preferred)', 'big data: 2 years (Preferred)', 'python: 4 years (Preferred)', 'One location', 'No: Not providing sponsorship for this job', 'A job for which military experienced candidates are encouraged to apply', 'A job for which all ages, including older job seekers, are encouraged to apply', 'A job for which people with disabilities are encouraged to apply', 'https://ebce.org/join-our-team/', 'Only full-time employees eligible']",2020-08-08 13:33:21
Data Engineer,ZEFR,3.1 out of 5,"Marina del Rey, CA","['Provide seamless and timely data access for your users', 'Build reliable and dependable ETL', 'Build and maintain production machine learning infrastructure', 'Troubleshoot complex issues in distributed systems', 'Debate data processing philosophies and methodologies with your team', ""Bachelor's or Master's degree in Computer Science or related field"", 'Fluency with Python, Java, Kotlin, or Scala', 'Experience with distributed systems', 'Strong foundation in data structures, algorithms and software design', ""Experience with digital media, social media, and video APIs such as YouTube's Data API is a big plus"", 'Thorough testing and code review standards/practices', 'Strong verbal and written communication skills', 'Openness to new technologies and creative solutions']",2020-08-08 13:33:21
Software Engineering Internship,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Strong object-oriented design skills, coupled with a deep knowledge of data structures and algorithms', 'Proficiency in one or more of the following developer skills: Java, C/C++, PHP, Python, Ruby, Unix, MySQL, Clojure, Scala, Java Script, CSS, HTML5', 'Experience in sophisticated methodologies such as Data Modeling, Validation, Processing, Hadoop, MapReduce, Mongo, Pig', 'Experience with web frameworks such as AngularJS, NodeJS, SproutCore', 'Proven experience in application development in Objective-C for OS X or iOS a plus', 'Client-Server protocol & API design Skills', 'Able to craft multi-functional requirements and translate them into practical engineering tasks', 'A fundamental knowledge of embedded processors, with in-depth knowledge of real time operating system concepts.', 'Excellent debugging and critical thinking skills', 'Excellent analytical and problem-solving skills', 'Ability to work in a fast paced, team-based environment', 'Strong verbal and written communication skills and social skills']",2020-08-08 13:33:21
Associate Data Analyst,Hormel Foods,3.7 out of 5,"Austin, MN 55912","['Data Structures and Models', 'Data Pipelines and ELT', 'Data Performance', 'Visualizations and Dashboards', 'Must graduate in August December 2020, May 2021, August 2021 and major in an MIS (or related field) major with a minimum 3.0 cumulative GPA preferred', 'Possess strong analytical and communication skills', 'Demonstrated leadership and persuasive skills are necessary for success in this position', 'Possess strong work ethic and an entrepreneurial spirit', 'Must be a Citizen or National of the United States, a lawful, permanent resident, or have authorization to work in the United States', 'Applicants must not now, or any time in the future, require sponsorship for an employment visa', 'Position is based out of our Corporate Office headquarters in Austin, Minnesota', 'Position is full time']",2020-08-08 13:33:21
Lead Data Streaming Engineer - Multiple locations,U.S. Bank,3.6 out of 5,"Richfield, MN","['Lead collaboration with Business and Product Management to understand requirements, take a product approach to translate requirements into appropriate architecture and system functionality that successfully deliver required business success.', 'Lead and responsible for technical design, work breakdown and estimation, and implementation of required features.', 'Champion within the team along sprint process to be on top of the task and bug management system for timely deliverable or resolution.', 'Apply Dev/Ops mindset, take ownership of production success, optimize operation success via automation/active alerting/self-healing, and lead the resolution of production issues to ensure high-availability and performance.', 'Drive the release planning and execution with end-to-end understanding and insights (effort, risk, priority) of the planned features.', 'Develop high-quality code, define best engineering practice, perform peer code reviews to ensure successful deliverable with engineering excellence.', 'Actively guide and mentor junior developers to develop their technical expertise and lead a few offshore engineers to maximize productivity.', ""Bachelor's degree in Computer Science or related fields, or equivalent work experience"", '8+ years of work experience in Application Development/IT Systems Testing, and team leadership', 'Eight or more years of experience across multiple technology disciplines', 'Three or more years of project/team leadership skills experience', 'Exceptional technical expertise in architectural design, development and implementation with specialization in multiple technology disciplines, platforms and applications', 'Experience developing streaming application solutions', 'Expert in Java development.', 'Knowledge of Scala and other programming languages', 'Expertise with open stack technologies, have prior experience in working with Kafka, Spark/Flink, NiFi, HDFS, Hive, Cassandra, Druid and other big data projects', 'Extensive knowledge in system integration and business process modeling', 'Superior understanding of the enterprise architectural blueprint requirements and the impact on business functions', 'Considerable technical, logical, analytical and problem-solving skills', 'Deep understanding of Private and Public Cloud Architectures', 'Excellent verbal and written communication skills']",2020-08-08 13:33:21
Energy Engineer II,CLEAResult,3.3 out of 5,Remote,"['Medical, Dental and Vision Insurance; we also offer a company paid health care concierge service because we’ve all been there — needing help with our health plan and not knowing where to turn.', '401 (k) with company match', 'Paid vacation, sick and personal time', '10 paid company holidays', 'Paid Volunteer Time; giving back to our communities is important to us', 'Discounts on home and auto insurance', 'Employee Referral Bonus Program', 'Employee Recognition Program – convert your recognition points into gift cards', 'Employee Assistance Program – offers benefits to help you manage daily responsibilities', 'Access to training opportunities to advance further in your career', 'Calculate energy savings for projects in our programs using standard engineering principles including physics, mechanics, fan laws, thermodynamics, algebra, and statistics', 'Effectively apply engineering principles to our program work', 'Perform ASHRAE level II audits, with assistance', 'Develop IPMVP-compliant M&V plans and reports, with technical oversight', 'Develop measures builds for program planning and BD efforts, with technical oversight', 'Develop tools and calculators for use in our programs, with technical oversight', 'Provide design recommendations for prescriptive projects in our programs; develop effective technical training materials related to prescriptive measures', 'Analyze logger and utility data', 'Review filings, utility commission documents, and evaluator documents for technical accuracy and sound engineering practices; communicate findings and recommendations to more senior engineers and program staff', '2+ years experience', 'BS Engineering degree, (or)', '0+ years experience', 'MS Engineering']",2020-08-08 13:33:21
Lead Data Analytics Engineer,People's United Bank,3.4 out of 5,"Bridgeport, CT","['Conduct complex analytical studies, develop advanced quantitative models, and make strategic recommendations to improve performance, drive cost savings & revenue growth, and maximize profits in support of operational, risk, retention, sales, and marketing effectiveness.', 'Gather and analyze data from multiple internal and external sources by using Python, SAS, SQL, Qlik and/or other advanced analytic tools to support data analysis and model development.', 'Leverage analytical techniques & quantitative approaches such as regression, segmentation, decision trees, and clustering, etc. as well as progressive techniques to make data-driven recommendations for business decision making', 'Collaborate with team members across varying functional areas in support of advanced analytics expansion.', 'Identify and explore relevant third-party data sources to enhance customer profiles.', 'Ability to manage projects through to delivery – Document business requirements, methodology and prepare timely reports and results.', 'Minimum of three (3) years of relevant experience in solving complex, data driven problems. Experiences in data analytics and visualization, business intelligence, predictive modelling or analytical consulting – Banking / Financial service experience preferred.', 'Bachelor’s Degree in Economics, Finance, Statistics, Mathematics, Engineering or a related field is required. Master’s Degree in a quantitative or a related field is highly preferred.', 'Knowledge of data analytics tools for data pipelines, cloud storages (AWS), and Hands-on experience with designing and developing dashboards using self-service analytics tools', 'Ability to leverage multiple tools and programming languages to aggregate, standardize, analyze, interpret and manipulate large data sets from disparate data sources or within a data warehouse or decentralized environment.', 'Statistical modelling experience including: GBM, linear and logistic regression, decision tree, and propensity scoring and other advanced quantitative techniques.', 'Excellent written and verbal communication skills, including the ability to convey complex ideas clearly and to communicate with both technical and nontechnical audiences']",2020-08-08 13:33:21
Systems Administrator (Data Integration Engineer),Apex Clean Energy,3.3 out of 5,"Charlottesville, VA 22902","['Build and maintain the ETL processes', 'Develop ETL packages, ensuring that best practices are implemented for data governance, data quality, data cleansing.', 'Development of scalable and robust ETL routines, using ETL tools and external programming and/or scripting languages as necessary.', 'Manage the day-to-day support and maintenance of the data warehouse environment, reports, data integration jobs and job schedules.', 'Collaborate with stakeholders to define business logic for source-to-target mappings and integration workflows.', 'Assisting in production support by resolving source data issues and refining transformation rules when needed.', 'Maintain the existing data warehouses and facilitate aggregation, slicing and dicing of data using dbt.', 'Design and develop data extraction SQL queries that are highly optimized for very large data sets.', 'Creating and maintaining the company data dictionary as well as technical documentation for source-to-target mapping.', 'Follow current trends, their impact on business strategies, and their implications for creating sustainable data warehouse architecture.', ""Analyze the needs and the environment to make sure the solution you're developing considers the current architecture and operating environment as well as future functionality and enhancements."", 'Work closely and collaborate with various cross functional teams to identify, troubleshoot and fix data issues, and resolve data gaps that impact the fulfillment of the business’s functional requirements.', 'Work collaboratively with team members and customers to gather and validate requirements as well as deliver features/enhancements.', 'Collaborate with architects, team leads and team members to architect and design solutions to meet functional and technical requirements.', 'Troubleshoot issues, identify resolutions.', 'Responsible for writing complex SQL queries for mining of operational data.', 'At least two years of experience with complex/large data management and systems integration.', 'Familiar with ETL tools for database / warehouse development. Experience with Azure, preferred.', 'Experience developing ETL packages, ensuring that best practices are implemented for data governance, data quality, data cleansing.', 'Experience in all aspects of project development life cycle such as identifying requirements, design, feasibility analysis, allocating timelines, task prioritization, development, performance, best practices and testing.', 'Hands-on experience performing data modeling and warehousing in a cloud-based data-warehousing system (Snowflake)', 'Experience in day-to-day support and maintenance of the data warehouse environment, reports, data integration jobs and job schedules.', 'Experience performing analysis and reporting from the data warehouse, ideally using PowerBI.', 'Experience setting up data access and visualization tools and systems for non-technical users.', 'Working knowledge of Python and/or SQL.', 'Prior experience with renewable energy and/or SCADA a plus.', 'Experience working in a rapidly evolving environment, adapting quickly to new information and re-prioritizing as needed.', 'Demonstrated interest/passion for renewable energy required.', 'Health Insurance', 'Dental Insurance', 'Vision Insurance', '401(k) Employer Match', '401(k) Pre-tax or Roth Deferrals', 'Health Savings Accounts', 'Flexible Spending Arrangements', 'Short-term Disability Insurance', 'Long-term Disability Insurance', 'Group Term Life Insurance', 'Voluntary Additional Term Life Insurance', 'Paid Time Off (PTO)', 'Holidays', 'Volunteer Time Off', 'Progressive Parental Leave Plan', 'Milk Stork Travel Solution', 'Professional Development Opportunities', 'Employee Referral Program', 'ACAC Fitness and Wellness Center - Corporate Discount', 'Company Paid Cell Phone', 'Company Paid Parking', 'United Van Lines - Relocation Discounts']",2020-08-08 13:33:21
Data Engineer - AWS Product BI,Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","[""Bachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience."", 'A strong grasp of SQL and at least one scripting or programming language.', '5+ years of experience with and detailed knowledge of data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures and hands-on SQL coding.', '3+ years of large IT project delivery for BI oriented projects.', '3+ years of working with very large data warehousing environment', 'Designing, developing, troubleshooting, evaluating, deploying, and documenting data management and business intelligence systems, enabling stakeholders to manage the business and make effective decisions.', 'Building secure, available, scalable, stable, and cost-effective data solutions using data storage technologies, distributed file system, data processing, and business intelligence best practices.', 'Working with business customers in understanding the business requirements and implementing solutions to support analytical and reporting needs.', 'Designing and planning for solutions in the various engineering subject areas as it relates to data storage and movement solutions: data warehousing, enterprise system data architecture, data design (e.g., Logical and Physical Modeling), data persistence technologies, data processing, data management, and data analysis.', 'Ensuring completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements', 'Reviewing and participating in testing of the data design, tool design, data extracts/transforms, networks and hardware selections', 'Experience in designing and delivering cross functional custom reporting solutions.', 'Experience with distributed systems and NoSQL databases', 'Experience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and more!', 'Excellent oral and written communication skills including the ability to communicate effectively with both technical and non-technical stakeholders.', 'Proven ability to meet tight deadlines, multi-task, and prioritize workload', 'A work ethic based on a strong desire to exceed expectations.', 'Strong analytical skills']",2020-08-08 13:33:21
Sr. Data & ML Engineer - Nationwide Opportunities,"Amazon Web Services, Inc.",3.6 out of 5,Remote,"['Bachelor’s degree in Computer Science, Engineering, Mathematics or a related field or equivalent professional or military experience', '8+ years of experience of Data platform implementation', '3+ years of hands-on experience in implementation and performance tuning of Kinesis, Kafka, Spark or similar implementations', 'Hands on experience with building data or machine learning pipeline', 'Experience with one or more relevant tools (Flink, Spark, Sqoop, Flume, Kafka, Amazon Kinesis)', 'Experience developing software code in one or more programming languages (Java, JavaScript, Python, etc)', 'Current experience with hands-on implementation', 'Masters or PhD in Computer Science, Physics, Engineering or Math.', 'Familiar with Machine learning concepts', 'Hands on experience working on large-scale data science/data analytics projects', 'Hands-on experience with technologies such as AWS, Hadoop, Spark, Spark SQL, MLib or Storm/Samza.', 'Experience Implementing AWS services in a variety of distributed computing, enterprise environments.', 'Experience with at least one of the modern distributed Machine Learning and Deep Learning frameworks such as TensorFlow, PyTorch, MxNet Caffe, and Keras.', 'Experience building large-scale machine-learning infrastructure that have been successfully delivered to customers.', 'Experience defining system architectures and exploring technical feasibility trade-offs.', '3+ years experiences developing cloud software services and an understanding of design for scalability, performance and reliability.', 'Ability to prototype and evaluate applications and interaction methodologies.', 'Experience with AWS technology stack.', 'Written and verbal technical communication skills with an ability to present complex technical information in a clear and concise manner to a variety of audiences.']",2020-08-08 13:33:21
Oracle Data Engineer,iknowvate technologies,N/A,"Boston, MA","['Expertise with Oracle 12c, data movement technologies, Spotfire, and proficiency in designing solutions', 'Excellent Design & Analysis skills with a demonstrated ability to align to long term strategies through interim states', 'Experience working on delivering solutions for globally distributed, large scale Agile software development teams', 'You will serve as an engineer and thought leader within our Engineering team. You will interface directly with business partners to understand problems & opportunities and recommend solutions. You will be a key player as we scale our platform to support forecasted growth.', 'You consistently drive strong collaboration, open communication, and reach across functional borders', 'You are able to understand business problems and able to design scalable solutions', 'You have a relentless commitment to quality and engineering excellence', 'You have an ability to design and build performant solutions that scale and support stringent SLAs', 'You are able to work successfully in an environment that encourages autonomy in the work that you do', 'You are motivated, an excellent communicator, can take initiative to solve problems, and can make decisions based on the value of the solutions we build.', 'You understand engineering best practices and have an aptitude to coach and mentor others on the team', 'As a data engineer, you will play a key role in shaping how our products are designed and developed', 'Bring creativity and innovation, and experiment where needed, to provide solutions that help us deliver for the business.', 'Position the organization for growing the Managed Accounts business']",2020-08-08 13:33:21
Apple Media Products - Data Engineer,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['3 - 5+ Experience in high level programming languages such as Java, Scala, or Python', 'Proficiency with databases and SQL is required', 'Proficiency in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce', 'Expertise in Hadoop related technologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig', 'Expertise in developing big data pipelines using technologies like Kafka, Flume, or Storm', 'Experience with large scale data warehousing, mining or analytic systems', 'Ability to work with analysts to gather requirements and translate them into data engineering tasks', 'Aptitude to independently learn new technologies']",2020-08-08 13:33:21
"Senior Software Engineer, Data Platform",Etsy,4.4 out of 5,"Brooklyn, NY 11201","['We build highly-performant systems that are maintainable and easy to understand by selecting and integrating with the best of current technologies.', 'Our team is responsible for developing and monitoring our batch and streaming environments and improving or fixing them over time.', 'We also write ETL code and advise other teams on how to improve theirs.', 'We build a lot of tools and libraries in Java, Scala, or Python.', 'Understand that being an effective software engineer is about communicating with people as much as it is about writing code.', 'Are willing to work with and improve code you did not originally write.', 'Are generous with your time and experience, and can mentor and learn from other engineers.', 'Can tackle unconstrained problems and know when to seek help.', 'Have familiarity with a few of the following: advantages and limitations of distributed systems, writing ETL pipelines, building and monitoring cloud services, and using or maintaining batch data processing environments like Hadoop or Spark in Dataproc, and stream processing systems like Kafka Streams, Spark, or Dataflow']",2020-08-08 13:33:21
Controls Engineer (REMOTE),Raso Solutions,N/A,Remote,"['Contribute to product/platform definition by translating specific project goals into new generalized platform requirements.', 'Bachelor’s, MS Degree in Computer Science, Engineering or comparable field of study', 'Knowledge of industrial engineering and process control is necessary', 'Previous experience working in manufacturing or building software/solutions for manufacturing strongly desired.', 'Previous experience as an OT/automation system integrator with a range of technologies (hardware and software) is highly desired.', 'A strong understanding of manufacturing is required.', 'Past experience or specialization in Food and Beverage applications are ideal.', 'manufacturing - plant operations: 10 years (Preferred)', 'implementation: 10 years (Preferred)', 'IoT: 10 years (Preferred)', 'United States (Required)', 'Yes']",2020-08-08 13:33:21
Data Engineer,General Dynamics Information Technology,3.8 out of 5,"McLean, VA",[],2020-08-08 13:33:21
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:34:05
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:34:05
Senior Data Engineer,Chipotle,3.7 out of 5,"Newport Beach, CA","['Design, develop and maintain scalable data pipelines', 'Develop data ingestion and integrations (REST, SOAP, SFTP, MQ, etc. ) processes', 'Take ownership of building data pipelines', 'Actively engage in technology discovery and implementation for both on-prem and in Cloud (i.e. Azure or AWS) to build solution for future systems', 'Develop high performance scripts in SQL/Python/etc. to achieve objectives of enterprise data, BI and analytics need.', 'Incorporate standards and best practices into engineering solutions', 'Manage code versions in source control and coordinate changes across team', 'Participate in architecture design and discussions', 'Provide logical and physical data design, and database modeling', 'Be part of the Agile team to collaborate and to help shape requirements', 'Solve complex data issues around data integration, unusable data elements, unstructured data sets, and other data processing incidents', 'Supports the development and design of the internal data integration framework', 'Works with system owners to resolve source data issues and refine transformation rules', 'Partner with enterprise teams, data scientist, architects to define requirements and solution', 'Have a B.A./B.S. and 5-8 years of relevant work experience; or an equivalent in education and experience', 'Hands on experience with Microsoft Stack SSIS, SQL, etc.', 'Possess strong analytical skills with the ability to analyze raw data, draw conclusions, and develop actionable recommendations', 'Experience with the Agile development process preferred', 'Proven track-record of excellence and consistently delivered past project successfully', 'Hands on experience with Azure data factory V2, Azure Databricks, SQLDW or Snowflake, Azure analysis services and Cosmos DB', 'Experience with Python or Scala.', 'Understanding of continuous integration and continuous deployment on Azure', 'Experience with large scale data lake or warehouse implementation on any of the public cloud (AWS, Azure, GCP)', 'Have excellent interpersonal and written/verbal communication skills', 'Manage financial information in a confidential and professional manner', 'Be highly motivated and flexible', 'Effectively handle multiple projects simultaneously and pay close attention to detail', 'Have experience in a multi-dimensional data environment']",2020-08-08 13:34:05
Data Engineer,Alion Science and Technology,3.7 out of 5,"Linthicum Heights, MD","['Must have a current Secret level security clearance and therefore all candidates must be a U.S. Citizen.', 'B.S. degree in Computer Science, Information Technology, Electrical Engineering, Statistics, or equivalent fields. Educational requirements may be adjusted for applicable work experience. Work experience may be adjusted for highly specialized knowledge or uniquely applicable experience.', '2+ years of experience as a developer, analyst, or engineer.', 'Experience with programming languages such as Python and Java.', 'Proficiency with acquisition and understanding of network data and the associated metadata.', 'Fluency with data extraction, translation, and loading including data prep and labeling to enable data analytics.', 'Experience with Kibana and Elasticsearch.', 'Familiarity with various log formats such as JSON, XML, and others.', 'Experience with data flow, management, and storage solutions (i.e. Kafka, NiFi, and AWS S3 and SQS solutions).', 'Ability to decompose technical problems and troubleshoot system and dataflow issues.', 'Experience with NOSQL databases such as Accumulo desired', 'Prior Experience supporting cyber and/or network security operations within a large enterprise, as either an analyst, engineer, architect, or developer.']",2020-08-08 13:34:05
Data Engineer,"RIVA Solutions, Inc.",3.6 out of 5,"Washington, DC","['Under little or no supervision, responsible for the development of analytical solutions and databases.', 'Develops specifications for the most efficient database solutions.', 'Supports the evaluation and selection of solutions that meets customer requirements', 'Good working knowledge and hands-on experience with key software platform architectures, web servers, application servers, and relational databases.', 'Performs work involved in one or more of the phases of developing software used in products or services provided to the customer.', 'Designs and implements enterprise infrastructure and platforms required for cloud computing.', 'Analyzes system requirements and ensures that systems will be securely integrated with current applications.', 'Has a deep understanding of system development in cloud environments, including Software as Service (SaaS), Platform as Service (PaaS), or Infrastructure as a Service (IaaS).', 'Designs and builds relational databases for data storage or processing.', 'Develops strategies for warehouse implementation, data acquisition, and archive recovery.', ""May evaluate new data sources for adherence to the organization's quality standards and ease of integration."", 'Provide consultation on complex projects and is considered to be a top-level contributor/specialist', 'Key member of a data science project team supporting analytic development.', 'Eight (8) years relevant experience in applied data science research or big data analytics', 'Bachelor’s Degree in Computer Science, Engineering, Information Systems or related technical discipline. A Master’s degree may be substituted for up to two (2) years of experience. A PhD may be substituted for up to five (5) years of experience.', 'Ability to perform functional and data requirements analysis, and implementation of data engineering projects, analyze customer requirements and provide solution recommendations.', 'Demonstrate knowledge of information engineering methodologies, process improvement, and performance measurement.', 'Ability to support the development of organization-wide data models for use in designing and building integrated, shared software and database systems.']",2020-08-08 13:34:05
"Data Engineer, Site Reliability",Atlassian,4.5 out of 5,"Mountain View, CA","['Work with our seriously large volume of data to understand trends and behaviours', 'Investigate and establish funnel and experience metrics to validate the quality of our releases and features', 'Programming skills (e.g. Python, JavaScript and Java. Python, etc).', 'Proficiency in SQL and understanding of database/data warehousing concepts', 'Strong critical thinking, communication and collaboration skills', 'Spread the love of the measure - build - measure - learn cycle within Atlassian', 'Organized, passionate about the details, and a self starter', 'Knowledge and experience of reporting and BI tools (e.g. Tableau, R, SAS, etc)', 'Hands-on forecasting and financial modeling skills in Excel, with experience in SaaS/recurring/subscription revenue models', 'Experience working on Amazon Web Services (in particular using EMR, Kinesis, RDS and the like).']",2020-08-08 13:34:05
Data Center Engineer,Leaseweb USA,N/A,"Edison, NJ 08837","['configuring layer 3 network devices specifically Juniper, Arista switches', 'configuring power infrastructure APC, Tripp Lite PDU and ATS', 'rack, stack and cable', 'receiving and booking inventory into internal system per established procedures', 'deliver custom build servers to customers', ""cabling (accordance with company's standards)"", 'firmware upgrade servers bios, raid controller, and ipmi', 'firmware upgrade switches and pdus', 'label, patch and run fiber', 'hard drive check, wiping and degaussing drives', 'install Linux and Windows operating systems and configure so system is reachable remotely for troubleshooting and or deployment.', 'install and configure hardware and software raid', 'troubleshoot broken hardware', 'configure IPMI so console is remotely accessible.', 'following detailed instructions by executing instructions with great precision in reasonable amount of time for specified task.']",2020-08-08 13:34:05
Machine Learning Engineer,Proxet,N/A,"Boston, MA","['Good compensation package', 'Insurance Coverage', 'Fully remote flexible hours (voice/video conferences are taking place 2-3 times a week)', 'Courses and professional certifications allowance', 'Personal and professional growth', 'Dental Insurance', 'Health Insurance', 'Professional Development Assistance', 'Referral Program', 'Tuition Reimbursement', 'Monday to Friday', 'Machine Learning: 1 year (Preferred)', 'Fully Remote', 'A job for which people with disabilities are encouraged to apply', 'www.proxet.com', 'Only full-time employees eligible']",2020-08-08 13:34:05
Data Engineer,WorldLink,3.5 out of 5,"Irving, TX","['Build data pipeline frameworks to automate high-volume and real-time data delivery for our Spark and streaming data hub', 'Transform complex analytical models in scalable, production-ready solutions', 'Provide support and enhancements for an advanced anomaly detection machine learning platform', 'Continuously integrate and ship code into our cloud production environments', 'Develop cloud based applications from the ground up using a modern technology stack', 'Work directly with Product Owners and customers to deliver data products in a collaborative and agile environment', 'Building data APIs and data delivery services to support critical operational and analytical applications', 'Contributing to the design of robust systems with an eye on the long-term maintenance and support of the application', 'Leveraging reusable code modules to solve problems across the team and organization', 'Handling multiple functions and roles for the projects and Agile teams', 'Defining, executing and continuously improving our internal software architecture processes', 'Being a technology thought leader and strategist', 'BS/BA degree or equivalent combination of education/experience.', 'Intermediate to senior level experience in an Apps Development role. Demonstrated strong execution capabilities', 'At least 4 years of experience on designing and developing Data Pipelines for Data Ingestion or Transformation using Java or Scala or Python', 'At least4 years of experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC), Resource Management, Distributed Processing and RDBMS', 'At least 4 years of developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps', 'At least 2 years of experience with SQL and Shell Scripting experience', 'Experience of designing, building, and deploying production-level data pipelines using tools from Hadoop stack (HDFS, Hive, Spark, HBase, Kafka, NiFi, Oozie, Apache Beam, Apache Airflow etc).', 'Experience with Spark programming (pyspark or scala or java).', 'Experience troubleshooting JVM-related issues.', 'Experience and strategies to deal with mutable data in Hadoop.', 'Experience with Stream sets.', 'Familiarity with machine learning implementation using PySpark.', 'Experience in data visualization tools like Cognos, Arcadia, Tableau', 'Angular.JS 4 Development and React.JS Development expertise in a up to date Java Development Environment with Cloud Technologies', '1+ years’ experience with Amazon Web Services (AWS), Google Compute or another public cloud service', '2+ years of experience working with Streaming using Spark or Flink or Kafka or NoSQL', '2+ years of experience working with Dimensional Data Model and pipelines in relation with the same', 'Intermediate level experience/knowledge in at least one scripting language (Python, Perl, JavaScript)', 'Hands on design experience with data pipelines, joining data between structured and unstructured data', 'Familiarity of SAS programming will be a plus', 'Experience implementing open source frameworks & exposure to various open source & package software architectures (AngularJS, ReactJS, Node, Elastic Search, Spark, Scala, Splunk, Apigee, and Jenkins etc.).', 'Experience with various noSQL databases (Hive, MongoDB, Couchbase, Cassandra, and Neo4j) will be a plus', 'Experience in Ab Initio technologies including, but not limited to Ab Initio graph development, EME, Co-Op, BRE, Continuous flow', 'Successfully complete assessment tests offered in Pluralsight, Udemy, etc. or complete certifications to demonstrate technical expertise on more than one development platform.', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'One location', 'Yes: H-1B work authorization', 'Temporarily due to COVID-19']",2020-08-08 13:34:05
Data Engineer,BlackLine,3.9 out of 5,"Pleasanton, CA","['Responsible for building and maintaining the machine learning data and development platform.', 'Build, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.', 'Create and maintain scalable data pipeline in the cloud (AWS and GCP).', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement processes automation and data delivery.', 'Build infrastructure for optimal extraction, transformation, and loading of data from a wide variety of data sources.', 'Execute extract, transform and load (ETL) operations on large datasets including data identification, mapping, aggregation, conditioning, cleansing, and analyzing.', 'Build analytics tools to provide actionable insights into business and product performance.', 'Keep data separated, isolated and secured.', 'Assist data scientists in implementing achine learning algorithms and contribute to building and optimizing our product into an innovative industry leader.', 'Participate in establishing best practices while team is transitioning to new technologies, tools and infrastructure. Maintain specifications and metadata; follow the best practices.', 'Recommend and implement process improvements.', 'Maintain specifications and metadata; follow and develop best practices.', 'Coach and technically train data analysts, if needed.', '5+ years as a data engineer.', 'Experience with SQL, Python, R languages.', 'ETL experience using Python.', 'Experience with Hadoop, Spark, Hive. Presto is a plus.', 'Practical experience with GIT version control.', 'Strong familiarity with GCP, AWS, SQL Server.', 'Comfortable working with open source tools in Unix/Linux environments.', 'Data warehousing experience, data modeling and database design.', 'Experience with machine learning packages and various ML algorithms.', 'Experience with predictive and prescriptive analytics, modeling, and segmentation.', 'Experience with data analytics, big data, and analytics architectures.', 'Comfortable handling large amounts of data.', 'Experience ensuring data and modeling accuracy, cleanliness, reliability.', 'Works independently without the need for supervision.', 'Experience translating business requirements into functional, and non-functional requirements.', 'Strong sense systems and data ownership.']",2020-08-08 13:34:05
Solutions Engineer,Relode1,N/A,"New York, NY","['2-4 years of Solution Engineering experience', '2+ years of Python Scripting Language', 'Familiarity with data structures, relational databases, cloud infrastructure', 'Newer Team, so lots of Internal Growth Opportunities', 'Lots of autonomy in this role', 'Great company culture and atmosphere, supportive, always helping one another', 'Must be currently authorized to work in the United States on a full-time basis', 'Work autonomously and creatively in navigating and overcoming obstacles that you encounter', ""Develop software to integrate with client's electronic health record (EHR) data"", 'Role based in New York City with occasional travel to client sites (~1 trip / quarter)', 'An opportunity to work on a platform that is scaling very rapidly with 200,000 engaged patients a day as of May 2020', 'A chance to join a high-growth company at an early stage', 'The ability to impact the growth of our company, we value all comments and suggestions', 'Transparency across teams and interaction with multiple departments', 'Competitive pay, employer-paid healthcare, stock options', 'Daily team lunch and unlimited healthy snacks at our NYC office', '401(k)', 'Health Insurance', 'Paid Time Off', 'Day shift', 'Solution Engineering: 2 years (Required)', 'data structures, relational databases, cloud infrastructure: 1 year (Preferred)', 'Python Scripting Language: 2 years (Required)', 'New York, NY (Preferred)', 'United States (Preferred)']",2020-08-08 13:34:05
Data Warehouse Engineer,Chipotle,3.7 out of 5,"Newport Beach, CA","['Design, develop and maintain scalable data pipelines', 'Develop data ingestion and integrations (REST, SOAP, SFTP, MQ, etc.) processes', 'Take ownership of building data pipelines', 'Actively engage in technology discovery and implementation for both on-prem (MSSQL/SSIS) and in Cloud (Azure) to build solution for future systems', 'Develop high performance scripts in SQL/Python/etc. to achieve objectives of enterprise data, BI and analytics need', 'Incorporate standards and best practices into engineering solutions', 'Manage code versions in source control and coordinate changes across team', 'Participate in architecture design and discussions', 'Provide logical and physical data design, and database modeling', 'Be part of the Agile team to collaborate and to help shape requirements', 'Solve complex data issues around data integration, unusable data elements, unstructured data sets, and other data processing incidents', 'Supports the development and design of the internal data integration framework', 'Works with system owners to resolve source data issues and refine transformation rules', 'Partner with enterprise teams, data scientist, architects to define requirements and solution', 'Have a B.A./B.S. and 2-5 years of relevant data engineering work experience', 'Hands on experience with Microsoft/Azure Stack SSIS, SQL, ADF, etc.', 'Possess strong analytical skills with the ability to analyze raw data, draw conclusions, and develop actionable recommendations', 'Experience with the Agile development process preferred', 'Hands on experience with Azure data factory V2, Data Flows, Azure Databricks, Snowflake, Azure Data Lake, Azure analysis services and Cosmos DB preferred', 'Experience with Python or Scala', 'Understanding of continuous integration and continuous deployment on Azure', 'Experience with large scale data lake or warehouse implementation on any of the public cloud (AWS, Azure, GCP)', 'Have excellent interpersonal and written/verbal communication skills', 'Manage financial and company information in a confidential and professional manner', 'Be highly motivated and flexible', 'Effectively handle multiple projects simultaneously and pay close attention to detail', 'Have experience in a multi-dimensional data environment']",2020-08-08 13:34:05
Data Visualization Engineer II,Blue Margin,N/A,"Fort Collins, CO 80524","['Develop accurate reports in Power BI that are not only visually engaging, but also make customers’ data accessible and actionable', 'Regularly interact with clients for project updates and inquiries', 'Create, enhance and troubleshoot data models in Power BI and Visual Studio', 'Author documentation of customer reporting requirements and finished reports', 'Craft and use T-SQL queries for data validation', '1-2 years of experience in Power BI Desktop creating tables, graphs, drill downs, drillthroughs, bookmarks, and KPIs', 'Working knowledge of Power BI Service and how to configure it', 'Ability to create intermediate to advanced DAX calculations using functions such as Calculate, Summarize and Filter', 'Experience creating T-SQL queries in SSMS', 'Comprehensive grasp of data visualization methods', 'Familiarity with data modeling', 'Broad business experience with a proficient ability to talk to executives in business terms', 'Professional demeanor', 'Experience using Visual Studio 2017/2019, DAX Studio, Tabular Editor, ALM Toolkit', 'Familiarity with tabular data models', 'Comfortable with manipulating data in Power Query Editor', 'Company Core Values: Embrace Transparency, Choose to Be Positive, Be Efficient/Systematize, Pursue Learning, Be Generous', 'Weekly personal and professional development programs for all', 'Teamwork—we maintain company-wide interaction and communication', 'Entrepreneurism – we want everyone on our team to be eager to adapt and evolve with our advancing business. We are looking for someone who is comfortable wearing more than one hat.', 'This job may require moderate physical effort including lifting materials and equipment of less than 50 pounds and involves viewing a CRT or VDT screen more than 80 percent of the time. The job will take place in a normal office environment with controlled temperature and lighting conditions. The position may require some travel and occasional participation in off-site functions. This position requires standing or sitting for long durations.', 'Starting salary for this position is between $70,000-$75,000 and is commensurate with experience and qualifications. This position comes with a comprehensive benefits package consisting of medical and dental coverage, paid sick leave, vacation, and a retirement plan.']",2020-08-08 13:34:05
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:34:05
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:34:05
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:34:05
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:34:05
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:34:05
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:34:05
Senior Data Engineer,The Burgess Group LLC,3.4 out of 5,"Alexandria, VA 22314","['Evaluate business strategies and mandates to establish performance requirements.', 'Plan, design, maintain and execute tests against the entire stack of individual applications as agreed upon for each release.', 'Lead the charge to improve system performance, capacity, reliability, and scalability.', 'Design, draft, cost, and present recommendations to leadership.', 'Collaborate with QA, Development, DevOps, Security and Architecture teams to ensure proper defined performance specifications are maintained.', 'Partner cross functionally and lead development of in-house developed performance testing tools, and maintenance of same.', 'Co-author Performance Guides and standards to be used by IT and Security Engineers for building systems.', 'Perform load tests to validate system performance and stability.', 'Analyze test results and work with Developers and Engineers to perform bug fixes.', 'Perform root cause analysis of performance issues and suggest corrective actions.', 'Oversee system performance lifecycle and identify key metrics for performance improvements.', 'Generate periodic performance reports for management review.', 'Lead, mentor, coach and train junior team members to ensure appropriate growth in skills, knowledge and scalability of the department.', 'US Citizen or Green Card holder', 'Bachelor’s degree in computer science or a related field.', 'Minimum of 8 years’ professional work experience', 'Minimum of 5 years’ experience in a Data Engineer role', 'Minimum of 3 years’ experience in team leadership/management', 'Verifiable, experience with Load Testing tools for .NET applications with options for multiple browsers, Intel physical-server, and Cloud-based infrastructures.', 'Demonstrable skills in Azure Architecture, design and performance testing', 'Demonstrable skills in Windows Server and SQL Server Architecture, design and performance testing.', 'Strong oral and written communication skills including the ability to engage appropriately with executives and author a wide range of technical documents', 'Master’s degree in Computer Science, Mathematics, Statistics, or similar quantitative field.', 'Experience with industry standard version control system tools like Git, Bitbucket.', 'Experience with writing C# tasks in SSIS.', 'Experience with or an interest in alternative implementations of data storage such as MongoDB, Elasticsearch, Cassandra, and Hadoop.', 'Experience with or an interest in reporting technologies such as Tableau, Power BI and if the opportunity presents itself learning MDX and DAX.']",2020-08-08 13:34:54
Data Engineer/Scientist,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Job', 'Company', 'Building analytics systems and delivering at scale.', 'Working in Linux or Unix environments and ability to tune for performance (e.g. disk or memory).', 'Usage of devops and automation tools (e.g. chef, Jenkins).', 'Architecting or storing data in NoSQL, Relational or Big data technologies (e.g. Hadoop, MongoDB/CouchDB, Spark, Redshift).', 'Working with data visualization tools like Tableau and/or Lookr.', 'Implementing and optimizing data pipeline for collecting, cleaning and aggregating data.', 'Dealing with data privacy and security issues related to user information.', 'Java/Scala/Go and run-time configurations.', 'Agile development with code tools like svn and git.', 'ML training to deploying models at scale.', 'Anomoly detection and root cause analytic systems.', 'Aptitude to independently network, learn, and influence multi-functional teams.', 'Good written and communication skills.', 'Ability to organize, plan and deliver against key landmarks.', 'Bachelor’s degree in Computer Science and Engineering or related field with 7+ years of industry experience']",2020-08-08 13:34:54
Engineer Data Center,JLL,3.8 out of 5,"Hagerstown, MD",[],2020-08-08 13:34:54
Data Engineer,Daily Harvest,N/A,"New York, NY 10010","['Design and build data models and new features that enable stakeholders to answer questions about our business and processes', 'Refactor existing data models to fit into our transformation layer while optimizing for cost and performance', 'Build, maintain, and optimize the backend of our business intelligence tool (we use Looker)', 'Develop tooling, testing, and processes to ensure our data infrastructure is robust and observable', 'Build and maintain Python pipelines to load data into our warehouse', 'Translate business asks into technical requirements', 'Strong SQL skills (experience using dbt is a plus)', 'Experience developing LookML', 'Strong communication and stakeholder management skills', 'Ability to thrive in a fast-moving, evolving, and high growth environment', 'Experience using Git and GitHub to collaborate on repositories', 'Experience working with managed ETL services (e.g. Alooma, FiveTran, Stitch)', 'Experience using cloud services (we use Google Cloud Platform, BigQuery experience is a plus)', 'Experience implementing CI / CD to test and deploy repositories', 'Experience using Airflow to orchestrate data pipelines', 'Experience using Docker to deploy tasks', 'Experience using Python to extract, clean, and load data', 'Unlimited Daily Harvest to keep you hustling, not hangry + cold brew (...always stocked)', 'Flexible time-off policy + flexible working hours (Unlimited PTO Plan)', 'Competitive medical, dental, and vision benefits, 401K + equity participation', 'Ancillary benefits: Commuter, Gym membership + Citi Bike discounts', 'Access to everything we make (including recipes in development)', 'Annual company retreat', 'Quarterly team outings, weekly onsite happy hours, + regular DH team gatherings to celebrate our co-workers', 'Book club + running club', 'Showers for post-morning or mid-workday workouts', 'A dynamic, ambitious, and fun work environment + dog friendly!!']",2020-08-08 13:34:54
Jr. Data Engineer (Spark and Scala) - Full Time,Cognizant Technology Solutions,3.9 out of 5,"McLean, VA","['This role is not able to offer visa', 'Artificial Intelligence and Analytics Practice']",2020-08-08 13:34:54
Sr. Data Engineer,BICP,5 out of 5,"Portland, OR","['2+ years of experience with data engineering with emphasis on data analytics and reporting', 'Experience developing with scripting languages such as Shell and Python', 'Strong experience developing with PySpark, preferably leveraging AWS EMR managed service', 'Expert experience with SQL and Relational database engineering (Oracle, SQL Server, Teradata) with expert-level SQL abilities', 'Experience with agile delivery methodologies (Scrum, SAFe, Extreme Programming, etc.)', 'Experience working with source-code management tools such as GitHub and Jenkins', 'Ability to partner with business and technology team members, to understand business requirements and translate those into value-add technology solutions', 'Experience developing solutions in Snowflake', 'Experience with workload automation tools such as Airflow, Autosys.', 'Prior Kubernetes, Lambda, Spark Streaming etc.', 'Prior AWS DevOps knowledge', 'AWS: 1 year (Required)', 'Data Engineering: 1 year (Required)', 'Spark: 1 year (Preferred)', 'Python: 1 year (Preferred)', 'Snowflake: 1 year (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Health insurance', 'Team-oriented -- cooperative and collaborative', 'People-oriented -- supportive and fairness-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Monday to Friday', 'Day shift', 'www.bicp.com', 'Temporarily due to COVID-19']",2020-08-08 13:34:54
Data Engineer - Corporate,American Addiction Centers,3 out of 5,"Brentwood, TN 37027","['Create and Maintain data pipelines between core data systems', 'Help define metrics and best practices around data definitions and data governance', 'Assist the larger analytics team around maximizing usage and value of data', 'Document current data systems', 'Help prioritize business intelligence efforts', 'Maintain relationships across multiple teams to ensure alignment on definitions and access', 'Bachelor’s Degree', 'Strong SQL knowledge required (SQL Server Preferred)', 'Python ETL Skills (familiarity with requests and pandas package preferred, REST APIs)', 'Minimum two (2) years working with data systems or API data connections', 'Strong knowledge of current BI market place and technologies (PowerBI, Sisense, Tableau)', 'AWS knowledge and working knowledge of ETL platforms recommended', 'Able to work quickly and independently', 'Flexibility to deal with constantly changing needs', 'Ability to own and lead the technical side of the BI/Analytics process', 'A team player who understands how to make others around them better', 'A desire to learn and get better', 'Data Warehousing concepts and data modeling skills', 'SSIS ETL Skills', 'Familiarity with Salesforce CRM']",2020-08-08 13:34:54
Data Engineer,Valen Analytics,N/A,"Littleton, CO 80125","['Microsoft SQL Server', 'PostgreSQL', 'MongoDB', 'Microsoft SSIS', 'BIRST BI', 'Valen InsureRight platform', 'Data extraction, transformation, and cleansing', 'Data profiling and visualization', 'Collaborating with data scientists, software engineers, production operations, subject matter experts and customers', 'Fostering continuous delivery pipelines', 'Managing and maintaining metadata', 'Work in a fast-paced environment as part of a small team', 'Collaborate with team members in the development and maintenance of our solutions', 'Identify opportunities to automate data engineering tasks and workflow', 'Fostering continuous delivery pipelines', 'Managing and maintaining metadata', '2+ years Data Engineering experience with TSQL, python, map reduce or functional programming', 'Bachelor’s degree in programming or related technical areas', 'Developing and supporting an end user production system', 'Reporting/data warehousing experience', 'Insurance industry knowledge or experience with insurance data a plus']",2020-08-08 13:34:54
Technical Data Engineer,Valley National Bank,3.2 out of 5,"Wayne, NJ 07470","['Job', 'Company', 'Build scalable databases for the consumption of structured and unstructured data, work with external data providers to maximize competitor data throughout Valley National Bank.', 'Import and export data between an external RDBMS and the Hadoop Cloudera cluster, including the ability to import specific subsets, change the delimiter and file format of imported data during ingest and alter the data access pattern or privileges.', 'Automate data pipelines from various systems to create advanced analytics and Machine Learning.', 'Ingest real-time and near real time (NRT) streaming data into HDFS, including the ability to distribute to multiple data sources and convert data from on ingest from one format to another.', 'Convert data from one file format to another, Evolve an Avro or Parquet schema for performance optimization.', 'Develop RESTful web services.', 'Write query to filter data or to join multiple data sets.', 'Agile project methodology and waterfall where required.', 'Solid track record of data integration showing excellent execution and attention to detail.', 'Programming experience ideally in Spark and a willingness to learn new languages to meet goals and objectives. Experience in Python, Kafka, Java, C, Perl, Javascript or other programming languages is a plus.', 'Experience in SQL, MySQL and SQL Server databases. Experience in MapReduce is a plus.', 'Knowledge of data mining, machine learning, natural language processing or information retrieval. Knowledge of integration concepts as they relate to sourcing data from disparate sources.', 'Experience in a cloud environment (MS Azure preferred).', 'Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.', 'Knowledge of Data warehousing best practices for optimal performance in an MPP environment.', 'Experience with Apache Avro and Apache Parquet. Experience with Impala with Kudo (interactive SQL). Experience with BI Visualization tools like MS PowerBI. Experience with test automation and QA.', 'Knowledge of Machine Learning and Computational Statistics.', 'Ability to communicate both verbally and written to employees in the business units utilizing non-technical language.', 'Willingness to explore new alternatives or options to solve data integration issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.', 'Experience in production support and troubleshooting.', 'Ability to learn to create a data-driven culture and impactful data strategies.', 'B.S in computer science or a related IT degree with a minimum of 2 years of big data engineering experience.', 'Working with Big Data projects.', 'Must have experience developing and integrating solutions for Big Data Platforms, including Azure.', 'Financial Services, Retail Banking, Credit Card data or related domain / industry experience of at least 2 years.', 'Cloudera Pig, Sqoop, HIVEW, MapRedue, Scala, Spark, Trifacta, etc. Cloud (Azure/AWS) experience preferred.']",2020-08-08 13:34:54
"Data Engineer, Prime Video",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['Job', 'Company', '5+ years of relevant experience in business engineer role, including data warehousing and business intelligence tools, techniques and technology, as well as experience in diving deep on data analysis or technical issues to come up with effective solutions', 'BS degree in math, statistics, computer science or equivalent technical field', 'Experience in data mining structured and unstructured data (SQL, ETL, data warehouse, Machine Learning etc.) in a business environment with large-scale, complex data sets', 'Design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for business intelligence analytics in support of prime video content analytics.', 'Implement data structures using best practices in data modeling, ETL/ELT processes, and SQL, Redshift, and OLAP technologies.', 'Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture.', 'Analyze source data systems and drive best practices in source teams.', 'Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance.', 'Produce comprehensive, usable dataset documentation and metadata.', 'Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers.', 'Proven communication (verbal and written) and interpersonal skills', '8+ years’ experience in Datanet or other ETL technologies', '8+ years’ experience in Tableau including advanced dashboarding', '5+ using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies']",2020-08-08 13:34:54
Software Engineer (Backend),Twitter,4.1 out of 5,"New York, NY","['4+ years industry experience working with confidence on a massive scale, microservice-based tech stack that (required) Scala, Java, Kafka, Hadoop/Scalding, Heron, and Aurora/Mesos.', 'You have a track record of implementing simple, elegant solutions / great products across distributed systems.', ""You’ve demonstrated an ability to excel in whatever you pursue (whether it's work, school, competitions, open source contributions, personal projects, etc.—you've always stood out and succeeded)"", 'You have experience with a diverse range of frameworks/technologies, whether through work or side projects, with special interest in batch or streaming data processing technologies', 'You have a sound grasp on OOP concepts, data structures and algorithms.', 'You have a disciplined approach to writing unit and integration tests.', 'MUST have working knowledge of Scala', 'You have knowledge of distributed computing architectures.', 'You easily articulate complex concepts in writing and speech.', 'You’re no stranger to microservices.', 'You have operational knowledge of relational and non-relational databases (e.g. MySQL/Postgres and Cassandra/ElasticSearch).', 'BS, MS, or PhD in Computer Science']",2020-08-08 13:34:54
Data Engineer,Invesco,4 out of 5,"Atlanta, GA 30309","['Work with development teams and other development leads/partners to provide technical solutions that enable business capabilities', 'Maintain a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies', 'Responsible for analyzing, designing, programming, debugging and modifying software improvements and/or new products used in distributed, large scale analytics solutions', 'Build data integration solutions using Informatica data integration platform', 'Develop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services', 'Designs and develops sophisticated and large-scale data structures and pipelines to prioritize, collect and standardize data to generate insight', 'Assist in crafting documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure', 'Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing sophisticated programs, implementing architectures, and enabling automation in these environments', 'Work across teams to deliver meaningful reference architectures that outline architecture principles and standard methodologies for technology advancement', 'Minimum 5 plus years of experience as an architect, must also have prior application development experience', 'Specialist in Multi-tier and Event Driven Programming concepts, with technical project leadership experience', 'Experience with enterprise data-centric technologies (MDM, Data Lake, ESB)', 'Successful experience in utilizing Agile project management methodologies, standard methodologies and processes', '3+ years of experience in data modeling, data warehousing, and big data architectures', '2+ years of experience in Informatica data integration platforms', '1+ years of AWS Cloud Platform (Redshift, RDS, S3, EMR, Kinesis)', 'Strong knowledge and experience in Data warehousing concepts Experience with ETL tool (Informatica, Alteryx etc.)', 'Experience with one programming language (Python, Java, Scala)', 'Strong Data Ingestion techniques (Batch and real time)', 'BS in Computer Science, Applied Mathematics, Physics, Statistics', 'Understanding of JIRA and Agile Project Management software', 'Experience using GitHub, Bit Bucket, or other code repository solution', 'Flexible time off and opportunities for a flexible work schedule', '401(K) matching of 100% up to the first 6% with additional supplemental contribution', 'Health & wellbeing benefits', 'Parental Leave benefits', 'Employee stock purchase plan', '3+ years of experience in data modeling, data warehousing, and big data architectures', '2+ years of experience in Informatica data integration platforms', '1+ years of AWS Cloud Platform (Redshift, RDS, S3, EMR, Kinesis)', 'Strong knowledge and experience in Data warehousing concepts Experience with ETL tool (Informatica, Alteryx etc.)', 'Experience with one programming language (Python, Java, Scala)', 'Strong Data Ingestion techniques (Batch and real time)', 'Strong knowledge and experience in Building API service', 'Experience in building ETL pipelines for data acquisition from CRM, Transactional systems, Google Analytics Big Query/Adobe Analytics, Salesforce Marketing Cloud, Social and 3rd Party Data providers', 'Understanding of Scaled Agile Framework.', 'Proficient in application/software architecture (Definition, Business Process Modeling, etc.)', 'Experience using GitHub, Bit Bucket, or other code repository solution', 'DevOps experience is a plus', 'BS in Computer Science, Applied Mathematics, Physics, Statistics', 'Understanding of JIRA and Agile Project Management software', 'Experience using GitHub, Bit Bucket, or other code repository solution', 'Strong written, verbal communication and presentation skills', 'Ability to explain complex technical issues in a way that non-technical people may understand', 'Able to work in a global, multicultural environment', 'Self-motivated. Capable of working with little or no supervision', 'Ability to react positively under pressure to meet tight deadlines', 'Able to work independently or as a team player', 'Enjoy challenging and thought-provoking work and have a strong desire to learn and progress']",2020-08-08 13:34:54
Data Engineer,MasterControl,4.3 out of 5,"Salt Lake City, UT 84121","['Pull data from all customer databases into S3 and put into a queryable format', 'Model the data for optimal performance (ETL, star-schema like, ORC, partitioning, etc ...)', 'Pull data from a real-time streaming architecture (Kafka) and do near-real-time aggregations and projections of the data, storing the results in S3', 'Help automate the provisioning of AWS Lake Formations, EMR/Spark/S3 and other services in AWS', 'Analyze data to find patterns worthy to expose to the end-user', 'Help tie corporate data to customer data from an OLTP store', 'Help us discover ways to use Big Data technologies in a Machine Learning pipeline (discover, clean, label, train, test)', 'Other assigned duties', 'Scala/Python/SQL/Java', 'Apache Spark with EMR and/or other Big Data tools', 'Kafka Streams experience is big plus', 'Airflow experience is a plus', 'Big Data Mindset (Spark/Hive/Hadoop/HCatalog/Hudi). Understanding of the Big Data landscape.', 'Warehouse Architectures (Star Schema/Snowflake/Vaults/Lakes)', 'Familiarity with AWS and Cloud Formation or Terraform', 'Data Modelling', 'ETL Best Practices', 'Passionate about creatively solving business problems.', 'Effectively prioritize and execute tasks in a high-pressure environment.', 'The ability to non-emotionally coach and mentor others.', ""The ability to not participate in 'techno-arrogant' conversation."", 'Meet multiple, challenging deadlines while communicating expectations clearly.', 'Must be able to work well with people.', 'Ability to operate a computer and work at a desk for extended periods of time.', 'Ability to communicate effectively in writing, in person, over the telephone and in e-mail.', 'Generous PTO package of three weeks, increasing after just three years of employment', 'Competitive compensation with annual merit increase reviews', '100% medical premium coverage (yes, you read that right!)', 'Dental/Vision Plans', '401k Plan', 'Employer Paid Life Insurance Policy ($50K)', 'Great Flexibility', 'Wellness Programs (every employee gets a Fitbit!)']",2020-08-08 13:34:54
Software Engineer - Cloud Data Platform,"JPMorgan Chase Bank, N.A.",3.9 out of 5,"Columbus, OH","['Job', 'Company', 'BS/BA degree or equivalent experience', 'Advanced knowledge of application, data, and infrastructure architecture disciplines', 'Understanding of architecture and design across all systems', 'Working proficiency in developmental toolsets', 'Knowledge of industry-wide technology trends and best practices', 'Ability to work in large, collaborative teams to achieve organizational goals', 'Passionate about building an innovative culture', 'Proficiency in one or more modern programming languages', 'Understanding of software skills such as business analysis, development, maintenance, and software improvement']",2020-08-08 13:34:54
Data Engineer,WisdomTree,N/A,"New York, NY","['Fielding and satisfying the inflow of Ad-Hoc requests of varying size, scope and frequency that originate from all functional areas of the firm', 'Developing and implementing sustainable data-driven solutions relevant to projects at the department level', 'Implementing a “full-stack” approach to each solution with the entire application life-cycle in mind (work Upstream, think Downstream)', 'Satisfy daily ad-hoc requests out of the databases by writing and optimizing T-SQL to ensure quick turnaround', 'Curate robust solutions around work-flow management through the stewardship and maintenance of our daily batch cycles using Control M, SQL Agent, APIs, and SSIS', 'Facilitate the smooth transition of Research projects from dev to production using SSIS, Control-M and Seismic', 'Liaise with the Research team to build solutions slated for daily or monthly automation.', 'Coordinate with Operations and Marketing across divisions to implement website data updates and enhancements', 'Facilitate timely delivery of monthly and quarterly reporting suite (Seismic)', 'Assume various DBA responsibilities to serve an expanding user base (permissions, backups, transactional log jams)', 'Act as point person for nightly entity batch (Fundamentals, Benchmarks, Performance, Lipper)', 'Continue to build and deploy new database-driven solutions devoted to automating daily business operations', '0-3 years of experience; financial services experience preferred', ""Bachelor's Degree required"", 'Proven experience in T-SQL, Python, Microsoft Azure, SSIS, and MSSQL Server 2014', 'Experience with Pandas, NumPy, Git, ETL, RESTful APIs and MongoDB a plus', 'Coachability and receptiveness to direction', 'Familiarity with unstructured databases a plus', 'Positive and open-minded approach to problem-solving', 'Love of learning and a desire for constant self-improvement', 'Ability to navigate ambiguity', '“Humble, hungry, and smart”']",2020-08-08 13:34:54
Informatica IDQ - Data Engineer II,Silicon Valley Bank,3.9 out of 5,"Tempe, AZ 85281","['Architect and design secure, robust, fault-tolerant and highly scalable Informatica Data quality frameworks for Cloud and on premise environments.', 'Develop and deliver MDM/IDQ components as specified in the design, functional and non-functional requirements, within established budget, time and quality standards.', 'Quality and completeness of detailed technical specifications, solution designs, including architecture, design, code development and code reviews as well as adherence to the non-functional requirements.', 'Performing hands-on development work with Informatica IDQ for Data quality and Data transformations for MDM on the cloud and on premise environments.', 'Recommend data governance processes, organizational models, and Informatica IDQ technology platform.', 'Responsible for estimating the effort for work activities and assisting peers and matrix team for successful execution of work activities.', 'Identify, document and communicate technical risks, issues and alternative solutions discovered during project.', 'Develop and unit test data solutions, data integrations, data services.', 'Use agile engineering practices and various data development technologies to rapidly develop creative and efficient data products.', 'Align and integrate well with architects, data analysts, data modelers and other stakeholders.', 'Communicate with other developers across teams, both as ad hoc problem solving, and check-ins and discussions with other initiatives.', 'Mentor and provide direction to data engineers and quality engineers, both on-site and offshore.', 'Minimum 8 years of data engineering experience, with hands-on experience implementing Informatica IDQ on cloud and on premise environments.', 'Minimum of 5+ years is must with implementing Informatica IDQ products suite. Completed at least two Informatica IDQ implementations from the scratch.', 'Strong understanding of IDQ Process & Procedures such as Define, Discovery, Profiling, Remediation, and Monitoring.', 'Experience in using IDQ tool for source data profiling, creating and applying rules.', 'Expertise in implementing data quality processes including transliteration, parsing, analysis, standardization and data enrichment using IDQ transformations.', 'Experience in Design and execute a Data Quality Audit/Assessment and data quality mappings that will cleanse, de-duplicate.', 'Expertise on data profiling to identify data anomalies.', 'Experience in developing human task workflow scenarios and IDQ scorecards to support data remediation.', 'Related work experience in the areas of Master Data Management, Data Governance, deep experience in data warehousing and analysis.', 'Hands-on implementation experience in Big Data technologies is preferred', 'Expertise to ensure data quality and reliability and provide feedback to businesses and IT team on how to improve the quality of the data.', 'Experience in financial domain is a plus']",2020-08-08 13:35:40
Data Engineer,Balfour Beatty,3.7 out of 5,"Dallas, TX","['Medical, Dental, Vision and Life Insurance', 'Health Savings Account', '401(k) with company match', 'Flexible Spending Accounts (Dependent & Medical Reimbursement)', 'Vacation Time', 'Sick Time', 'Holidays', 'Paid Personal Days', 'Paid Volunteer time', 'Tuition Assistance', 'Employee Referral Bonus', 'Develop, construct, test and maintain BI analytics platform', 'Design, implement and enhance ETL (extract, transform and load) processes.', 'Data modeling for data warehouse', 'Create reports/dashboards using visualization tools', 'Identify ways to improve data reliability, efficiency and quality', 'Conduct research for industry and business questions', 'Deliver updates to stakeholders', 'Experience in interpretation of business needs from requests, and rapidly implement effective technical solutions.', 'Four years of work experience in data management disciplines including data integration, data modeling, optimization, and data quality, and/or other areas directly relevant to data engineering responsibilities and tasks', 'Strong experience with popular database programming languages including SQL, PL/SQL and others for relational databases', 'Experience with data quality and data validation processes', 'Experience sourcing data via a variety of sources including REST web services, MS SQL Server and Oracle.', 'Able to manage multiple deadlines in a timely manner, prioritize multiple projects and provide status reports on open projects.', 'Experience building on AWS using S3, Redshift, Lambda, Step Functions, Glue, etc.', '3+ years of Python', 'Experience using software version control tools (Git, Azure DevOps, Subversion, etc.)', 'Experience using CI/CD pipelines', 'Excellent communication skills, both written and verbal', 'AWS certifications or other related professional technical certifications', 'Power BI', 'Experience in Big Data stack environments (EMR, Hadoop, MapReduce, Hive)', 'Experience in both AWS and Microsoft business analytic technical stacks']",2020-08-08 13:35:40
Distributed Systems Data Engineer,iknowvate technologies,N/A,"Beaverton, OR",[],2020-08-08 13:35:40
Data Engineer,Reonomy,N/A,"New York, NY 10017","['Collaborating with the Engineering team to design, build and improve Reonomy’s complex data layer', 'Creating data systems that ensure quality and consistency on our data platform', 'Solving real challenges around creating systems that import, cleanse, structure, and display huge volumes of data', 'Playing a major role in the future architecture of our rapidly expanding backend platform', 'Writing high quality code, participating actively in code reviews, and consistently helping to ship software', '6+ years of experience in a Data Engineering capacity', 'Expertise in building and scaling ETL/batch processing systems that organize data and manage complex rulesets', 'Proven ability leveraging database technologies to solve non-trivial, large-scale problems', 'Advanced/Expert knowledge in SQL and data analysis', 'Experience programming in both typed (Scala, Java, etc..) and non-typed (Python, Ruby, etc..) languages on production projects', 'Experience using Scala libraries such as: Cats, shapeless, fs2', 'Experience building modern, data-driven, web applications with emphasis on strong software design methodologies', 'A serious passion for data', 'History of excellence and responsibility in previous engineering positions', 'Competitive salary', 'Company stock options', '100% coverage on medical, vision and dental health plans', 'Unlimited Vacation', '401k plan and commuter benefits', 'Access to our Continuing Education Stipend', 'Perks: WFH package, FREE ClassPass membership, FREE Headspace premium membership, FREE Citi Bike membership, & team outings!', 'Applicants must be currently authorized to work in the United States on a full-time basis.', 'We do not accept unsolicited resumes from outside recruiters/placement agencies. Reonomy will not pay fees associated with resumes presented through unsolicited means.']",2020-08-08 13:35:40
Computer Vision Engineer,Imidex,N/A,"Denver, CO 80216","['Developing object detection, classification, and image segmentation models.', 'Researching and applying the latest deep learning and computer vision techniques.', 'Developing image quality control architecture to ensure the quality and validity of training and real-time images.', 'Deploying models into a production environment that will be used by radiologists in a real-time setting.', 'Working with our team of scientists, engineers, and clinicians to further refine models.', 'Analyze out of sample and field accuracies and outcomes, provide support for clinical study reporting for FDA regulatory clearance.', 'Experience: Previous employment as a Computer Vision Engineer or similar.', ""Skills: Python, R, Keras / TensorFlow / PyTorch, deep learning / CNN's, mathematical analysis."", ""Education: Bachelor’s or Master's degree in computer science, data science, information systems, mathematics, physics, or engineering."", 'Proven: Have taken a computer vision-based project from the initial concept to production.', 'Knowledge: Foundational knowledge and experience with machine learning, deep learning, computer vision, CNN’s, etc..', 'Expertise and curiosity: In our domain, able to visually inspect medical imaging data, learn how radiologists read medical images, and incorporate models into clinical workflow.', 'Creative problem solver: Must be a self-starter, able to think outside the box, overcome obstacles, and challenge assumptions.', 'Strong communication skills: Able to listen, understand, and convey oral and written concepts within the domains of oncology, radiology, biostatistics, and computer vision.', 'Meticulous attention to detail, as well as big picture thinking.']",2020-08-08 13:35:40
Data Engineer,PreciseTarget,N/A,"Bethesda, MD 20814","['Building and optimizing software programs, algorithms and automated processes to ingest, cleanse, transform and integrate data from multiple disparate sources', 'Leading technical design and delivery on new tools, platforms and products', 'Writing complex and efficient queries to transform data', 'Working with data scientists to refine machine learning and data processing algorithms', 'Proficiency in Python, SQL, and Java', 'Experience with machine learning algorithms (PySpark experience a plus)', '3+ years of experience building simple, scalable, reliable back end systems (ETL pipelines, data analytics, etc.)', 'Familiarity with measuring performance of data products', 'Experience generating and testing hypotheses to explain micro and macro trends and opportunities based on data', 'Strong software engineering fundamentals (data structures, algorithms, distributed systems, information retrieval)', 'Experience with AWS services', 'Excellent communication skills', 'A sense of ownership, the ability to work effectively in close collaboration, and a positive attitude', 'Start-up experience', 'Quantitative marketing experience']",2020-08-08 13:35:40
Digital Quality Assurance Engineer 1099 Contr,ASU Preparatory Academy,2.7 out of 5,"Tempe, AZ 85281","['1 - 3 years proven working experience in a QA Engineering role with active involvement throughout development / testing lifecycles', 'Any equivalent combination of experience, training and/or education from which comparable knowledge, skills and abilities have been achieved.', 'Plans and directs activities concerned with testing of in-house development', 'Implements standards and methods for inspection, testing, and evaluation', ""Assures compliance of organization's products and processes."", 'Assures that products leaving the development organization are effective and free from defects or operational problems or errors.', 'Verifies the accuracy or performance of the product and troubleshoots the correction of any problems or issues.', 'Tests the product, using it both as recommended and not as intended (negative testing).', 'Thinks of how consumers may use the product incorrectly to reduce errors.', 'Possesses creativity and understanding of the product and the goals of the company.', 'Reviews technical publications, articles, and abstracts to stay abreast of technical developments in industry.', 'Assumes responsibility for testing the item under various working conditions or for verifying the information that the item provides.', 'Implements automated tests for regression and validation of production.', 'Additional duties may be assigned as necessary.', 'Ability to work with diverse teams to establish goals, objectives, and action plans.', 'Familiarity of software QA methodologies, tools, and processes.', 'Experience in writing clear, concise, and comprehensive test plans, and test cases.', 'Ability to document and troubleshoot errors for developers.', 'Excellent verbal and written communication in addition to persuasively clear and concise presentation skills.', 'Exceptional strategic, analytical and critical thinking skills with demonstrated ability to interact with diverse audiences.', 'Demonstrated ability to meet quantitative and qualitative objectives.', 'Exceptional project management skills including the ability to handle diverse tasks simultaneous to meeting aggressive project timelines and producing high-quality results.', 'Highly organized, detail-oriented and results-driven focus; highly responsive to feedback and collaboration.', 'Knowledge of K-12 school setting.']",2020-08-08 13:35:40
"Senior Business Intelligence Engineer, I&D Analytics",Amazon.com Services LLC,3.6 out of 5,Remote,"['Bachelor’s degree, or equivalent work experience', '3-5 years of experience in compiling data, report generation and data analysis with an emphasis or basic knowledge of statistics.', 'Proven ability to use data and metrics to back up assumptions, develop business cases, and complete analyses to improve Inclusion & Diversity initiatives', 'Support senior management by managing metrics reporting, performing mathematical and statistical modeling and mining and analyzing large data sets.', 'Expert knowledge of Excel and visualization programs such as Tableau or QuickSight and HR Systems.', 'Leverage centrally-owned Amazon data tools as well as those developed by AWS / AGS HR Analytics to build and maintain scorecards and reporting mechanisms for use with the business across the employee lifecycle; metrics will include (not an exhaustive list): pipeline and interview representation, hires, attrition analysis, headcount growth, talent development/retention/, and employee sentiment and engagement.', 'Provide easily digestible data reports to executives and managers enabling AWS I&D to achieve goals and objectives.', 'Partner to execute projects and initiatives that incorporate data, analysis and identification of areas for action.', 'Contribute to the research of external benchmark information that enables teams to foresee future trends.', 'Build and maintain strong partnerships across AWS.', 'Perform ad hoc and trend analyses to produce actionable information to support decision making.', 'Leverage business intelligence tools, SQL queries and other tools (Excel, Access, etc…) to develop models and reports.', 'Possess an undeniable passion for and proven track record in the field of corporate Inclusion & Diversity.', 'Strong verbal and written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams', 'Adaptable, creative, and thrives in a fast-paced work environment with minimal technical oversight.', 'Strong organizational and program management skills.', 'Strong business acumen and analytical abilities.', 'Possess the creative, and analytical skills needed to connect the quantitative data to insights and effectively deliver timely, insightful and actionable analyses in addition to high quality documents and reports.', 'Ability to drive effective communication and collaboration across multiple disparate groups with competing priorities.', 'Ability to create, maintain and disseminate information to stakeholders for multiple projects/work streams at one time.', 'Ability to work independently, as well as an active member of both business and HR teams.', 'Resilient and able to thrive in a fast paced, entrepreneurial environment with a high level of energy and sense of humor.', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-08-08 13:35:40
Remote Cloud Engineer,JLG,N/A,"Washington, DC","['Work closely with key users and project teams to gather requirements, create APIs, mapping, design specifications, data models, and data flow diagrams to meet business needs', 'Write, design, code, test, implement, debug, and validate applications; document design decisions and develop modular software components; monitor system performance metrics, and identify potential risks/issues', 'Lead the architecture and enabling technologies strategy for data enablement for the organization.', 'Lead the technical planning and requirements gathering phases to estimate, develop, test, manage projects, architect and deliver cutting-edge solutions.', 'Identify emerging information technologies to be assimilated, integrated and introduced within the client environment', 'Solid understanding of REST, containerization, polyglot programming, caching, as well as Event-Driven and Microservice-based architectures', 'Real-world experience designing, developing and defending a modern distributed compute platform at scale (Kubernetes/OpenShift)', 'Expertise with AWS Services: EC2, EMR, RDS, Redshift, Kinesis, Elasticsearch, S3', 'Bachelor’s degree required (in Computer Science, Software Engineering, Information Systems or related field', 'Minimum 8 Years of total IT experience in Java with 2-5 years of hands-on experience developing and implementing AWS Cloud-based Applications', 'Strong hands-on experience with DevSecOps', 'Skilled problem solver with the desire and proven ability to create innovative solutions.', 'Knowledge and experience in developing software using Agile practices.', 'Solid understanding of use cases for relational and non-relational data and experience writing code against several different database platforms (PostgreSQL, Cassandra, Oracle, SQL Server)', 'Comfortable writing code in multiple languages, confident in choosing the right strongly or dynamically typed language for the job. Preferred language familiarity: Java, Python', 'Proficient in authoring, editing and presenting technical documents.', 'Powerful and prolific written and verbal communicator', 'Must be a US citizen.', 'Secret', '401(k)', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Vision Insurance', 'Monday to Friday', 'Secret (Required)', 'Temporarily due to COVID-19']",2020-08-08 13:35:40
"Principal Data Engineer, Core Data & Analytics",Northwestern Mutual,3.8 out of 5,"New York, NY",[],2020-08-08 13:35:40
Data Engineer,The Aerospace Corporation,4 out of 5,"Chantilly, VA 20151","['Independently evaluates, selects, and applies engineering techniques, procedures and criteria, using judgment in making adaptations and modifications. Assignments typically have specified objectives.', 'Contacts are primarily internal, with infrequent inter-organizational and outside customer contacts on routine matters.', 'Works on complex computer science solutions, develop scalable and distributed software systems that require research, awareness, and interactivity.', ""Quickly learns new technical skills to tackle some of technology's greatest challenges."", 'Bachelor’s degree in Computer Science, or a related technical field', 'Eight (8) or more years of relevant work experience in software development. An advanced degree might be used in lieu of years of working experience.', 'Experience with one or more general-purpose programming languages including but not limited to: Java, JavaScript, C++, or Python', ""Present project updates to management to ensure that project development remains aligned with management's vision"", 'Experience working with data analytics tools and reporting platforms', 'Ability to adapt to changing organizational need', 'Current and active Top Secret clearance with SCI access', 'Master’s degree, further education or experience in engineering, computer science or other technical related fields', 'Experience in leading software development teams', 'Knowledge of data analytics tools for data pipelines, cloud storages, and interactive visualization dashboards', 'Knowledge of developing cloud-native applications']",2020-08-08 13:35:40
Data Engineer,Everytown for Gun Safety,2 out of 5,"Washington, DC","['Gather and spec requirements for a successful project;', 'Maintain existing systems, and deliver enhancements;', 'Perform peer code review and quality assurance as part of a team;', 'Build pipelines for automated transforms of data into data marts in order to support reporting, predictive analytics, and targeting.', ""Provide support and training for staff and volunteers on Everytown's suite of tools and best practices for using data effectively;"", 'Make recommendations and provide guidance on ways to make programs, campaigns, and data collection more efficient and effective;', 'Other responsibilities as assigned.', '2-3 Years in SQL;', '2-3 Years in software development languages, Python preferred.', 'Developing and maintaining pipelines to perform ETL;', 'Working with version control systems such as Git;', 'Experience using APIs to construct and maintain data synchronizations', ""Experience training people on a variety of activities, experienced/comfortable at conducting trainings (even if you didn't create them);"", 'Ability to manage several tasks or projects concurrently and prioritize work effectively;', 'Ability to communicate effectively, especially technical ideas to non-technical people, work well under pressure, be detail oriented and meet deadlines;', 'Strong attention to detail, including producing technical documentation.', 'Mapping visualization, D3, GIS applications or R Leaflet;', 'Familiarity with R, Javascript, or other scripting languages;', 'Experience with Civis Analytics Platform;', 'Ability to diagnose and improve database and query performance issues;', 'Digital Campaigning platforms data schemas;', 'Data Visualization & reporting of metrics using tools such as Tableau;', 'Knowledge of CRM & Donation Data Schemas']",2020-08-08 13:35:40
DATA MANAGEMENT / MIGRATION ENGINEER,GRANT THORNTON,3.7 out of 5,"Arlington, VA 22209",[],2020-08-08 13:35:40
"Data Analyst, Logistics",Tesla,3.5 out of 5,"Fremont, CA","['Write queries across our databases and pull data for different stakeholders', 'Work with data engineers to maintain and improve our reporting database', 'Synthesize and structure data, and build visualizations for making business decisions', 'Use mathematics and statistics to build models of logistics, which will enable predictions and theoretical optimizations to govern logistics operations', 'Analyze large data sets, build ETL’s, and collaborate with data engineers', 'Partner with software engineers to build and deploy tools such as machine learning', 'Partner with logistics and adjacent teams to elevate data as a first-class citizen', 'Evidence of exceptional ability in the set (or a subset) of software engineering, applied mathematics, statistics, and operations research.', '2+ years of deep data analysis, building models and developing algorithms for real-world experiments and data-driven optimizations.', 'Familiarity with machine learning, python scripting, and other quantitative tools.', 'Mastery of data access and manipulation across SQL databases.', 'Expertise measuring and iterating to improve model performance.', 'Able to work under pressure while managing competing demands and tight deadlines.', 'Strong communicator, well organized, and strong attention to detail.']",2020-08-08 13:35:40
Data Engineer,Slickdeals,5 out of 5,"Las Vegas, NV 89113","['Work directly with the business users to understand the reporting needs and lead business users to practical solutions', 'Help translate business requirements into specification documents to track and perform analysis of new and existing site features', 'Understand the necessity of data quality and requirement for confidence of accuracy of any reports', 'Develop/monitor/maintain new reports, procedures, data structures and databases', 'Design ETL pipelines for new and existing OLAP Data Cubes', 'Design data schema, perform data transformations and manipulations with efficiency and reusability in mind', 'Planning, conducting and directing the analysis of complex business problems', 'Highly motivated with a great attitude and desire to dive into raw data to understand trends in behavior', 'Excellent at multitasking who can execute multiple requests and reports under tight timelines', 'Inquisitive, self-starter, able to work autonomously', 'Able to work in a fast-paced dynamic environment', 'Detail-oriented tactician who strives for perfection', 'Strong verbal and written communication skills', 'Strong problem-solving skills', 'Understand data structures and algorithms. Understanding of basic statistics (confidence intervals, statistical significance, etc)', 'Experience in working with large size data sets (Billions of rows/Petabytes of data)', 'Experience with building and maintaining ETL pipelines, Data Warehousing and Dimensional Modeling with relational and MPP/distributed systems.', 'Experience in working with various data sources (ODBC, flat files, etc)', 'Experience working with and designing complex data schemas', 'Experience with SQL query performance optimization', 'Experience with Spark performance optimization and troubleshooting', 'Experience with event driven architectures and message processing with message brokers such as Kafka.', 'Implemented Redshift, Snowflake, Azure Data Warehouse, ADLS, S3, Kafka, Presto, EMR, Databricks, or Data Lake Architecture in one or more public clouds.', 'Productionalizing Data Science models at scale.', 'Created Solutions using GCP, Azure, AWS, or other cloud platforms. Docker and Kubernetes a plus.', 'Developed Big Data/Hadoop applications using Spark, Hive, HBase, Presto or Map Reduce.', 'Experience using CI/CD methodologies within the data space.', 'Understands tools like Terraform and how to implement infrastructure as code.', 'Realtime and streaming analytics.', 'Experience with Tableau and or other Self Service Analytical tools.', 'Experience with Web Analytics (Adobe Analytics/Omniture, Google Analytics, Heap Analytics)', 'Build high quality software with a programming language (PHP, Python, ASP, or Scala)', 'Experience with SQL Server Administration,Knowledge of MySQL', 'Knowledge of WhereScape RED ETL tool', 'Advanced experience in SQL Server BI/Enterprise', 'Advanced experience creating and maintaining OLAP Data Cubes', 'Advanced experience designing and developing ETL data pipelines.']",2020-08-08 13:35:40
Data Science and Machine Learning Engineer,Booz Allen Hamilton,3.9 out of 5,"Washington, DC","['1+ years of experience with machine learning, data science, or analytics in professional or academic environments', 'Experience with frequent scripting language use, including Python and R and using packages commonly used in machine learning applications or advanced data analytics', 'Experience with managing diverse data sources, including preprocessing, cleansing, and verifying the integrity of data to develop data marts for data science use cases and machine learning applications', 'Experience with performing data exploration and data analysis on multiple data types, including images, video, and text', 'Experience with feature selection, Computer Vision or Natural Language Processing model building, and optimization using supervised and unsupervised machine learning techniques to support analytic objectives', 'Ability to thrive while working independently to achieve successful results with minimal guidance', 'Ability to articulate workflows and explain technical concepts to non-technical audiences', 'Ability to obtain a security clearance', 'BA or BS degree', 'Experience with operational machine learning applications', 'Experience within a leadership role, including project management and project evaluation', 'Ability to exhibit flexibility and initiative when dealing with ambiguous and fast-paced situations', 'Secret clearance', 'MS degree preferred; PhD degree a plus', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'change the world with the Data Science Bowl—the world’s premier data science for social good competition', 'participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government']",2020-08-08 13:36:26
Windows Systems Engineer,Computer Services Incorporated,3.9 out of 5,"Charlotte, NC 28277","['5+ years of Information Technology (IT) experience supporting very large Enterprise Class Servers in a heterogeneous environment;', 'In depth understanding of Operating Systems including how they interact and utilize hardware platforms;', 'Troubleshooting, diagnosing, and problem-solving (including TCP/IP) skills in high pressure production environments;', 'Ability to work from home with high-speed Internet access;', 'Must be able to think quickly, outside the box and willing to accept and embrace change;', 'Must be detailed orientated and assertive in nature;', 'Must be accustomed to responding quickly and in a controlled manner to emergencies.', 'Microsoft Windows Server Operating Systems;', 'vCenter VM server management;', 'Operating System Maintenance;', 'Enterprise Windows hardening, patch and vulnerability management;', 'Advanced Trouble Shooting (including TCP/IP);', 'Windows Web Services.', 'Containerizations technologies;', 'Server build and application automation;', 'DNS, Hosts files and server routes;', 'LAN/WAN infrastructures, protocols, and technologies;', 'Systems Security;', 'Storage Area Networks (SAN), Network Attached Storage (NAS) and Direct Attached Storage Device (DASD);', 'Database technology – SQL, SQL Best Practices and Query Language;', 'Backup and Recovery techniques;', 'Remote management DRAC/iLO and IPMI', 'Server hardware deployments in a data center environment.', 'Build, deploy, maintain all facets of operating systems;', 'Required to assist in the daily monitoring of servers/systems and respond quickly to alerts;', 'Follow strict Change Management and maintenance windows policies regarding productions changes;', 'Follow proper quality assurance procedures regarding releasing anything into production;', 'Involved in Incident and Problem management;', 'Analyzing, Implementing and monitoring of systems management agent software;', 'Working with Windows industry-based technologies in a maintenance/process improvement capacity;', 'Implementing and monitoring of management software;', 'Perform and assist in the configuration, staging, installation and ongoing support of client server environments;', 'Maintenance and administration of IIS and Application Pool configs;', 'Maintain patch and vulnerability levels to company standards;', 'Disaster Recovery and Incident Response planning and testing;', 'Participate in strategic and tactical weekly meetings as necessary;', 'Participate in team On-Call schedule;', 'Establish and document best-practice procedures in areas of expertise;', 'Create and maintain Systems RUNBOOKS (How-To’s, Visios, troubleshooting procedures, etc…).', 'Technically assist any other departments or divisions of the company as needed;', 'Participate in developing new applications or enhancements of existing products and services;', 'Strong verbal, written, organization and communication skills; must clearly communicate Systems related technical issues with customer/clients and management;', 'Data center operation experience;', 'Working with Windows industry-based technologies in a maintenance/process improvement capacity;', 'Must possess some programming skills in one of the following, PowerShell, VB, WMI, Perl;', 'Previous banking experience preferred or equivalent high speed, high-pressure environments a must;', 'Bachelor’s degree preferred or Information Technologies Certifications at a minimum.', 'MCSA: Window Server or the ability to obtain in the first year of employment;', 'MCSE: Core Infrastructure or the ability to obtain in the first two years of employment.']",2020-08-08 13:36:26
Assistant Chief Engineer,JLL,3.8 out of 5,"Wilmington, DE",[],2020-08-08 13:36:26
Sr. Data Engineer,Hewlett Packard Enterprise,3.8 out of 5,"Phoenix, AZ 85003","['You will be responsible for verifying and implementing the detailed technical design solution to the problem as identified by the Project/Technical Manager.', ""You'll regularly leads in the technical assessment and delivery of specific technical solutions to the customer. Provides a team structure conducive to high performance, and manages the team lifecycle stages."", 'You coordinate implementation of new installations, designs, and migrations for technology solutions in one of the following work domains: networks, applications or platforms.', 'You provide advanced technical consulting and advice to others on proposal efforts, solution design, system management, tuning and modification of solutions.', ""You'll collect and determine data from appropriate sources to assist in determining customer needs and requirements."", 'You have a Bachelor’s degree in Computer Science or a related area of study and relevant experience.', 'You have 8+ years of relevant experience.', 'You have sufficient depth and breadth of technical knowledge in Linux and to design and scope multiple deliverables across a number of technologies.', 'You have led team in the delivery of multiple deliverables across multiple technologies.', ""You have the ability to develop solutions that enhance the availability, performance, maintainability and agility of a particular customer's enterprise."", 'You have frequently used product and application knowledge along with internals or architectural knowledge to develop solutions. A recognized expert in one or more technologies within own technical community and also at regional level. Holds a vendor or industry certification in at least one discipline area.']",2020-08-08 13:36:26
Data Engineer,Dun & Bradstreet,3.7 out of 5,"Waltham, MA 02451","['A Data Engineer’s role involves developing applications designed to accumulate, derive meaning from, and apply stewardship to, large datasets. This Data Engineer will have to both be able to work with the Global People Data team’s internal datasets and tools, as well as be able to coordinate with outside groups to continuously meet their needs. The Data Engineer is expected to be a key developer of Global People Data tools and products, both in maintaining and upgrading existing tools and in developing new products using state of the art techniques and programming concepts.', 'Develop new applications in a variety of programming languages', 'Take ownership of existing applications for further development/improvements', 'Work closely with related groups to ensure business continuity', 'Perform analysis on large datasets to make and implement recommendations for maximizing customer experience', 'Work as a member of one or more agile teams, using lean principles and SCRUM methodology', 'Bachelor’s degree (preferable in computer science or a related field)', '2 - 5 yrs. experience with SQL', '2 - 5 yrs. experience with Python', 'Ability to work closely with others to problem solve', 'Experience with hosted environments (AWS, and Azure recommended)', 'A thorough understanding of software testing methodologies']",2020-08-08 13:36:26
Sr. Data Engineer,"2nd Watch, Inc.",N/A,Remote,"['Operates with the highest levels of integrity', 'Thinks Big and takes on Big Challenges', 'Has a continuous thirst for knowledge and is a perpetual learner', 'Strives to make themselves and everyone around them better', 'Has a passion for technology', 'Owning the technical engagement and ultimate success around specific implementation projects.', 'Developing a deep expertise in enterprise cloud technologies and services.', 'Being subject matter expert and taking on a consultative role as it pertains to cloud adoption.', 'Ensure that our applications and infrastructure are designed and implemented to the highest security standards thus maintaining and enhancing customer trust', 'Evangelize security within 2nd Watch and be an advocate for keeping customer information secure', 'Demonstrated ability to think strategically about business, product, and technical challenges', 'Other duties as assigned', 'Demonstrated experience providing customer-driven solutions, support or service.', 'In-depth knowledge of SQL or NoSQL and experience using a variety of data stores (e.g. RDBMS, analytic database, scalable document stores)', 'Extensive hands-on Python programming experience, with an emphasis towards building ETL workflows and data-driven solutions.', 'Able to employ design patterns and generalize code to address common use cases. Capable of authoring robust, high quality, reusable code and contributing to the division’s inventory of libraries.', 'Expertise in big data batch computing tools (e.g. Hadoop or Spark), with demonstrated experience developing distributed data processing solutions.', 'Applied knowledge of cloud computing (AWS, GCP, Azure).', 'Knowledge of open source machine learning toolkits, such as sklearn, SparkML, or H2O.', 'Applied knowledge of data modeling principles (e.g. dimensional modeling and star schemas).', 'Strong understanding of database internals, such as indexes, binary logging, and transactions.', 'Experience using tools for infrastructure-as-code (e.g. Docker, CloudFormation, Terraform, etc.)', 'Experience with software engineering tools and workflows (i.e. Jenkins, CI/CD, git).', 'Practical experience authoring and consuming web services.', 'Bachelor’s degree in computer science or related field, or equivalent combination of education and experience.']",2020-08-08 13:36:26
Sr. Business Intelligence Engineer,Amazon.com Services LLC,3.6 out of 5,United States,"[""Bachelors or Bachelor's Degree in Computer Science"", '5+ years’ experience with BI/DW/ETL projects.', 'Background in data relationships, data modeling, and data mining', 'Proficiency in SQL and other scripts like R, Python, Java or javascript', 'Experience with Linux, UNIX, UNIX tools', 'Designing structured, multi-source data solutions to deliver the dashboards and reports that make data actionable', 'Drive the collection of new data and the refinement of existing data sources to continually improve data quality', 'Support data analysts and product managers by turning business requirements into functional specifications and then executing delivery', 'Lead the technical lifecycle of data presentation from data sourcing to transforming into user-facing metrics', 'Preferred qualifications', 'Experience with Amazon Web Services (S3, SNS, SQS, RedShift, DynamoDB, RDS, Lambda)', 'Experience with building and maintaining API', 'Experience with Mulesoft', 'Analytical and troubleshooting skills']",2020-08-08 13:36:26
Data Engineer,Invesco,4 out of 5,"Atlanta, GA 30309","['Work with development teams and other development leads/partners to provide technical solutions that enable business capabilities', 'Maintain a broad understanding of implementation, integration, and inter-connectivity issues with emerging technologies to define data strategies', 'Responsible for analyzing, designing, programming, debugging and modifying software improvements and/or new products used in distributed, large scale analytics solutions', 'Build data integration solutions using Informatica data integration platform', 'Develop software to run on cloud native big data infrastructure built on AWS using Spark, Lambda, S3, and other cloud native services', 'Designs and develops sophisticated and large-scale data structures and pipelines to prioritize, collect and standardize data to generate insight', 'Assist in crafting documents that ensure consistency in development across the online organization. Implements and improves core software infrastructure', 'Deep expertise in SQL language, Python, Hadoop ecosystem and/or Spark ecosystem. Strong experience with writing sophisticated programs, implementing architectures, and enabling automation in these environments', 'Work across teams to deliver meaningful reference architectures that outline architecture principles and standard methodologies for technology advancement', 'Minimum 5 plus years of experience as an architect, must also have prior application development experience', 'Specialist in Multi-tier and Event Driven Programming concepts, with technical project leadership experience', 'Experience with enterprise data-centric technologies (MDM, Data Lake, ESB)', 'Successful experience in utilizing Agile project management methodologies, standard methodologies and processes', '3+ years of experience in data modeling, data warehousing, and big data architectures', '2+ years of experience in Informatica data integration platforms', '1+ years of AWS Cloud Platform (Redshift, RDS, S3, EMR, Kinesis)', 'Strong knowledge and experience in Data warehousing concepts Experience with ETL tool (Informatica, Alteryx etc.)', 'Experience with one programming language (Python, Java, Scala)', 'Strong Data Ingestion techniques (Batch and real time)', 'BS in Computer Science, Applied Mathematics, Physics, Statistics', 'Understanding of JIRA and Agile Project Management software', 'Experience using GitHub, Bit Bucket, or other code repository solution', 'Flexible time off and opportunities for a flexible work schedule', '401(K) matching of 100% up to the first 6% with additional supplemental contribution', 'Health & wellbeing benefits', 'Parental Leave benefits', 'Employee stock purchase plan', '3+ years of experience in data modeling, data warehousing, and big data architectures', '2+ years of experience in Informatica data integration platforms', '1+ years of AWS Cloud Platform (Redshift, RDS, S3, EMR, Kinesis)', 'Strong knowledge and experience in Data warehousing concepts Experience with ETL tool (Informatica, Alteryx etc.)', 'Experience with one programming language (Python, Java, Scala)', 'Strong Data Ingestion techniques (Batch and real time)', 'Strong knowledge and experience in Building API service', 'Experience in building ETL pipelines for data acquisition from CRM, Transactional systems, Google Analytics Big Query/Adobe Analytics, Salesforce Marketing Cloud, Social and 3rd Party Data providers', 'Understanding of Scaled Agile Framework.', 'Proficient in application/software architecture (Definition, Business Process Modeling, etc.)', 'Experience using GitHub, Bit Bucket, or other code repository solution', 'DevOps experience is a plus', 'BS in Computer Science, Applied Mathematics, Physics, Statistics', 'Understanding of JIRA and Agile Project Management software', 'Experience using GitHub, Bit Bucket, or other code repository solution', 'Strong written, verbal communication and presentation skills', 'Ability to explain complex technical issues in a way that non-technical people may understand', 'Able to work in a global, multicultural environment', 'Self-motivated. Capable of working with little or no supervision', 'Ability to react positively under pressure to meet tight deadlines', 'Able to work independently or as a team player', 'Enjoy challenging and thought-provoking work and have a strong desire to learn and progress']",2020-08-08 13:36:26
"Data Engineer, SEO",Pinterest,4.2 out of 5,"San Francisco, CA 94103","['Build scalable and reliable systems that efficiently process big data', 'Collaborate with teams across the Growth organization to deliver innovative products that help improve content sharing, user-to-user communication and user retention', 'Ensure we have the right data and work with the team to develop workflows to supply the data', 'Continue to expand our SEO experimentation framework to understand the impact of our content selection, interlinking changes and more', '5+ years of data engineering experience, preferably in Growth teams', 'Strong experience in writing reliable, low-maintenance and powerful code that may be used by many other engineers', 'Desire to understand search engine ecosystems and learn metrics-driven approach to software development']",2020-08-08 13:36:26
IT - Data Center - Computer Operator Trainee,Georgia Farm Bureau,3.6 out of 5,"Macon, GA 31210",[],2020-08-08 13:36:26
BIG Data Engineer,Econtenti Inc,3.8 out of 5,"Jersey City, NJ 07305",['Monday to Friday'],2020-08-08 13:36:26
Data Engineer,Natera,2.8 out of 5,"San Carlos, CA 94070","['Use analytical skills to drive a deep understanding of the various products in our fast changing business.', 'Develop strong hands-on knowledge of our software products and be able to aid in tasks ranging from writing complex SQL queries to documenting and maintaining versions of data models across all of our products.', 'Build effective data pipelines while maintaining data integrity enabling analysts to create dashboards that deliver insightful analytics to business stakeholders.', 'Act as a subject matter expert on the data models used across our software products providing guidance to stakeholders and create a shared understanding among analysts and technical teams.', 'Produce deliverables that facilitate better understanding across all products such as data flow diagrams, data models, ERDs and other illustrations.', 'Build confidence with our business partners by adding value to discussions, being responsive, and following through on action items.', 'Incorporate a focus on quality into data modeling, and work closely with technical product managers, development and software quality assurance teams on data model improvements.', 'Understand both the business processes of the groups we work with, and the technical details of the software to be an effective liaison for our department.', 'Help with troubleshooting of issues by analyzing the underlying data and identifying the business impact for these issues.', 'Support the data warehousing team in the implementation of the data warehouse for the new genomic data platforms.', 'Keep up with industry trends and best practices, advising on new and improved data engineering strategies leading to improvement in data governance across the business, promoting informed decision-making, and ultimately improving overall business performance.', 'Performs other duties as assigned.', 'BS or higher in related major or equivalent industry experience', '2+ years of experience in business intelligence, analytics, or an equivalent data engineer position with experience in writing extensive SQL and analyzing complex data sets.', 'Experience designing and building data pipelines to enable data-driven decisions for the business.', 'Excellent problem solving and analytical skills to easily break down complex problems and deliver simple and effective data modeling solutions.', 'Experience using interactive BI / data visualization platforms such as QlikView / QlikSense, Tableau, Power BI etc.', 'Structured and clear thinking with attention to detail.', 'Effective verbal/written communication skills.', 'Knowledge in following areas of software development:', 'Software database design', 'SDLC process', 'JIRA or similar issue tracking system', 'Desirable technical skills:', 'DB design understanding and strong SQL skills', 'Comfortable with Linux command line usage', 'Ability to read JAVA code is a plus.', 'Cloud/AWS basics.', 'Experience with R or Python scripting is preferred.', 'Comfortable contributing to and leading meetings with business partners in variety of positions and domain areas to receive data requests and guide decision-making', 'Ability to understand and describe technical complexities in a simplified way appropriate to different audiences.', 'Excellent written communication skills to produce clear, concise and correct technical documentation', 'Strong ability to comprehend complex problems and apply knowledge to propose potential solutions', 'Be able to break down large projects into granular milestones and track progress.', 'Performs other duties as assigned', 'Duties are typically performed in an office setting', 'This position requires the ability to use a computer keyboard, communicate over the telephone and read printed material', 'Duties may require working outside normal working hours (evenings and weekends) at times']",2020-08-08 13:36:26
Data Engineer,Saibber LLC,N/A,"Menlo Park, CA","['Around 10 years of experience.', 'Experience in Advance SQL, Python, Tableau or any BI tool.', 'Should be well versed in creating data pipelines using Python.', 'Should be very strong in writing advance SQL queries.', 'Analyze and organize raw data.', 'Build data systems and pipelines.', 'Evaluate business needs and objectives.', 'Interpret trends and patterns.', 'Conduct complex data analysis and report on results.', 'Prepare data for prescriptive and predictive modelling.', 'Build algorithms and prototypes.']",2020-08-08 13:36:26
Healthcare Data Engineer,B.well Connected Health,N/A,"Austin, TX","['Work closely with the various areas of the business to design and implement requirements and develop processes necessary to provide visibility into the data via the data warehouse', 'Ensure data that is brought into the data warehouse is clean, accurate, available and complete', 'Architect, develop, implement and test algorithms that consist of value-add routes and build data warehouse infrastructure for automated interpretation of healthcare data', 'Identify ways to improve data reliability, efficiency and quality. Produce actionable recommendations that address known problems and then implement automated solutions', 'Assist the development teams with business knowledge of various healthcare data that is ingested from various sources', 'You will safeguard sensitive data by following policies and training concerning your security and privacy responsibilities', 'You will safeguard sensitive data by following policies and training concerning your security and privacy responsibilities', '5+ years of professional SQL programming experience', 'In depth experience with SQL and NOSQL databases', '5+ years working with health plan data', 'Strong knowledge of healthcare data, specifically health plan (i.e. medical and Rx claims, eligibility, provider data)', 'Deep understanding with healthcare coding terminologies (CPT, diagnosis, DRG, etc)', 'Experience in designing and building efficient and scalable solutions for big data', 'Experience with query development and optimization', 'Experience with common data warehouse and data lake architecture concepts and best practices', 'Proven work experience with algorithm design and implementation', 'Strong problem solving skills', 'Ability to independently manage all phases of development including requirement documentation, building, configuration, bug tracking, testing, and validation', 'Strong experience with cloud-based infrastructure', 'Strong communication skills between business and technical resources', 'Experience providing database endpoints and/or the creation of RESTful API’s', 'Previous experience in the Python/Django framework', 'Previous knowledge of data integration processes and tools (specifically AWS based)', 'Experience with healthcare data formats (processing 834, 837, X12 file formats)', 'Experience with health system EHR data', 'Experience leveraging Redshift and other AWS data pipelines / tools', 'Advanced degree in Computer Science', 'An active GitHub profile or other public code portfolio']",2020-08-08 13:36:26
Support Engineer,Mux,N/A,"San Francisco, CA","['Become a trusted voice in the world of video by helping developers build better video (using Mux along the way).', 'Support developers using Mux through both one-on-one and public channels.', 'Translate developer questions into improvements to our documentation, guides, examples, and even API design.', 'Speak and write for a developer audience, submit talks, write blog posts, and represent Mux at conferences.', 'Contribute code to a rich ecosystem of plugins, SDKs, and open-source projects built around or on top of Mux.', 'You like helping people!', 'You feel comfortable writing in at least one programming language and are interested in working with more.', ""You're interested in writing for a developer audience."", ""Bonus: You're interested in helping build and maintain communities."", 'Flexible PTO', 'Healthy work-life balance encouraged', 'Competitive health, dental, and vision insurance (99% employee and 50% dependent premium coverage)', 'Employee Assistance Program (EAP)', 'Short-term and long-term disability insurance', 'Group life insurance', '401(k)', 'Paid parental leave', 'Investment in career growth and training', 'Thought leadership and peer recognition program', '“Day of Learning” events', 'Reimbursements for headphones, cell phones, device upgrades, and SVOD services of Mux customers', 'Catered meals and snacks', 'Competitive annual leave policy (25 days annual leave plus 8 paid holidays)', 'Healthy work-life balance encouraged', 'Private Medical Insurance, dental insurance, and a vision stipend program', 'Employee Assistance Program (EAP)', 'Short-term and long-term disability insurance', 'Group life assurance', 'Pension', 'Paid parental leave', 'Investment in career growth and training', 'Thought leadership and peer recognition program', '“Day of Learning” events', 'Pub lunch Fridays']",2020-08-08 13:36:26
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:37:08
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:37:08
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:37:08
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:37:08
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:37:08
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:37:08
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:37:08
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:37:08
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:37:08
Data Engineer,Softtek,3.9 out of 5,"Mexico, IN","['At least 2 years of data engineering experience', 'At least 2 years of experience working with big data technologies including Spark, Hadoop, PostgreSQL, Redshift and/or DynamoDB', 'At least 2 years of experience in Java, Scala, Python and SQL', 'At least 2 years of experience with AWS cloud (EMR, S3, EC2, Glue, Athena etc.) or another cloud platform', 'At least 1 year Experience with open source data pipeline orchestration tools like Airflow/Oozie', '2+ years of experience with Unix/Linux systems including scripting in Shell', '2+ years of experience designing, developing, and implementing ETL', 'At least 1 year of experience with Streaming (Apache Kafka) and/or NoSQL implementation', '1+ years of Terraform Development experience', 'Preferred AWS Certifications (Solutions Architect Associate and Developer Associate)', '2+ years of experience working with Agile development methodologies', 'Very good', 'All Softtek GDC’s in Mexico']",2020-08-08 13:37:08
Data Engineer,"Lokavant, Inc.",N/A,"New York, NY","['Design, develop, and implement data infrastructure and pipelines that ingest and transform data from various external sources, storing it in highly optimized database systems, and making it useful to our application and reporting layers', 'Create automation systems and tools to configure, monitor, and orchestrate data infrastructure and pipelines', 'Create data integration services to help onboard new customers as quickly as possible', 'Maintain ongoing reliability, performance, and support of the data infrastructure, providing solutions based on application needs and anticipated growth', 'Participate in creating and maintaining strict compliance, data privacy and security measures', 'Develop robust and production-level code to implement new product features in collaboration with other engineers and subject matter experts', 'Identify and resolve performance and scalability issues, troubleshoot problems, and improve product quality', 'Collaborate with the Front-End Development team to thread the right information through to forward-facing applications', 'Interface with the Development Operations colleagues to evaluate and implement methodologies and workflows to facilitate the frequent and continuous release of high-quality software', 'Work closely with Data Science colleagues to implement descriptive and predictive algorithms and models using the latest technologies', 'Keep up to date on emerging technology solutions, particularly those on AWS, for continuous improvements in data engineering', 'Help recruit highly capable engineers to the team from diverse backgrounds', 'Mentor and be mentored by engineers of varied experience levels and subject matter areas', '3+ years relevant experience with data engineering', 'Strong proficiency with Python (ideally PySpark) and SQL', 'Experience with AWS S3, EC2, EMR, or an equivalent cloud-hosted infrastructure', 'Experience with cloud-hosted database/data warehouse architecture (e.g. Redshift, Snowflake, etc.)', 'Experience writing and productionizing complex data transformations in SQL and related frameworks', 'Interest in building distributed computing and orchestration frameworks (e.g. Spark, Kubernetes, Airflow, etc.)', 'Experience working in an Agile software development environment', 'Exceptional written and verbal communication skills', 'Strong attention to detail and highly organized, with effective multi-tasking and prioritization skills', 'Proactive, self-motivated and self-directed, with the ability to learn quickly and autonomously', 'Comfortable with ambiguity', 'Superior problem-solving and troubleshooting skills', 'Ability to work as part of a collaborative cross-functional team in a fast-paced environment', 'Sincere interest in working at a rapidly changing start-up and scaling with the company as we grow', 'Bachelor’s degree with strong academic performance in Computer Science, Software Engineering, Applied Science, or equivalent field', 'Experience building and deploying large-scale data processing pipelines', 'Experience integrating data from disparate data sources', 'Experience with continuous integration and automation tools and processes (e.g. Jenkins, Semaphore, etc.)', 'Experience with healthcare data, ideally clinical/operational clinical trial data', 'Knowledge of clinical data standards (e.g. CDISC, FHIR, HL7, etc.)', 'Knowledge of e-clinical systems and technologies (e.g. EDC, CTMS, IRT, etc.)', 'Competitive salary and equity compensation', 'Full medical, dental, and vision benefits', 'One Medical membership', '401(k) plan', 'Flexible PTO policy', 'Generous parental leave', 'Great NYC office located in the heart of Times Square', 'Team events and outings']",2020-08-08 13:37:08
ETL Developer/Data Ingestion Engineer,Booz Allen Hamilton,3.9 out of 5,"Reston, VA","['2+ years of experience with Java', '1+ years of experience with a streaming data framework, including Apache Kafka', '1+ years of experience with web-based architecture, including HTML and JavaScript', '1+ years of experience with ETL development and processes from diverse data sources', '1+ years of experience with the development, maintenance, and enhancement of data mappings, work-flows, and processes', '1+ years of experience in working with Relational Databases', 'Experience with a variety of data feed types, including RSS, SOAP, and REST', 'Experience with data modeling concepts', 'TS/SCI clearance required', 'HS diploma or GED', 'Experience with XML, JSON, and TXT transformations, including writing and applying XSLT to transform data', 'Experience with any of the following technologies: Apache Kafka, NiFi, Airflow, PostgreSQL, Pentaho Data Integration, Accumulo, Solr, Elastic Stack, Firefox, Chromium, or Kubernetes', 'Experience with DoD or IC clients', 'Experience as a database administrator', 'Experience with web scraping, including Document Object Model (DOM) exploration', 'Knowledge of the Agile software development process, including Scrum and Kanban', 'Ability to map and document needed data elements in multiple databases to aggregate them under one schema', 'BA or BS degree preferred', 'Database Administration, ETL, or Business Intelligence-related Certifications preferred', 'DoDD 8570 Compliance Certification, including Security+']",2020-08-08 13:37:08
Data Engineer,Tripoint Solutions,N/A,"Rockville, MD 20850","['Creating and maintaining optimal data pipeline architecture.', 'Assembling large, complex data sets that meet functional / non-functional business requirements.', 'Identifying, designing, and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Building the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Building analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Keeping data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', '5+ years of experience working in a Data Engineer or Data Analysis role.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Experience with Microsoft SQL, database development and design.', 'Experience building processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Demonstrated success in manipulating, processing and extracting value from large disconnected datasets.', 'Experience with AWS tools such as RDS and DMS.', 'Demonstrated advanced working Microsoft SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Demonstrated accomplishments in designing, coding, testing and supporting data analytics and reporting solutions in a cloud environment.', 'Experience working in a secure IT environment.', 'Working knowledge of message queueing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience with AWS cloud services: EMR, RDS, Athena, Redshift, Kinesis, Lake Formation, Glue.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Your talent and innovative thinking bring leading-edge solutions to our customers.', 'Our success is driven by the dedication of our employees.', 'Employee-generated solutions have sustained our continued success and customer satisfaction']",2020-08-08 13:37:08
Software Engineer - Local Candidates Only,"Frontier Scientific, Inc.",N/A,"Wilmington, DE","['Wilmington, DE (Required)', 'English (Required)', 'United States (Required)', 'One location', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'A job for which people with disabilities are encouraged to apply', 'Temporarily due to COVID-19']",2020-08-08 13:37:08
Systems & Data Engineer,3M,4 out of 5,"Clinton, TN 37716","['Job', 'Company', 'Leading systems, data, and technology deployments such as 3M ACE (Factory of the Future), Workflow, and PowerBI for capital projects and existing value streams', 'Leading strategic data systems improvement initiatives for the department', 'Supporting manufacturing and quality systems with both strategic & tactical projects', 'Driving continuous improvement activities for the plant', 'Bachelor’s degree or higher (completed and verified prior to start) from an accredited institution', 'Bachelor’s degree or higher in Chemical, Electrical, Mechanical, or Systems Engineering', 'Two years of experience in a private, public, or military environment in one or more of the following areas: computer security systems, Ethernet Networking, SQL data bases, JAVA, or C++', 'Working knowledge of scripting and automation (VB scripting and SQL)', 'Understanding of Rockwell control systems such as PLCs, HMIs, SCADA', 'Demonstrated and current working knowledge in networks, SQL Databases, SSRS reporting and Cloud Storage', 'Understanding of deployment aspects of upper level manufacturing and business data systems (COMS, IMES, USS, ERC, SAP)']",2020-08-08 13:37:08
Data Engineer,Bisk,3 out of 5,"Tampa, FL 33619","['Design, develop and support database entities, data pipelines and processes required for data integration (ETL/ELT)', 'Implement processes that ensure data quality, code quality, and the confidentiality of all data', 'Possess the ability to learn emerging technologies quickly and apply them effectively', 'Design, develop and implement large-scale, enterprise-wide and complex data projects', 'Define and comply with internal development coding standards, procedural guides, and checklists for the support of the data platform.', 'Provide in-depth troubleshooting skills to assist in resolving errors and performance issues, including tier 2 production support', 'Implement data models, data warehouse models and dimensional models like Star and Snowflake schemas.', 'Understand business requirements, contribute to technical requirements and deliver on time within a SCRUM methodology.', ""Responsible for information security by appropriately preserving the Confidentiality, Integrity, and Availability (CIA) of Bisk information assets in accordance with the company's information security program."", 'Other duties as assigned', '6+ years with relational databases and SQL', '3+ years data warehouse and ELT/ETL experience', '2+ years API integration experience', '1+ year experience performing data integrations or data warehousing in a cloud data platform, preferably AWS.', 'Experience with programming with Python (Pandas and other common libraries)', 'Experience with object-oriented programming experience', 'A broad range of knowledge across Big Data, Azure, Data Vault, Tableau and other emerging technologies.', 'Bachelor’s Degree in Information Systems or related discipline preferred.']",2020-08-08 13:37:08
Data Engineer with looker/lookml,Bitwise INC,3.3 out of 5,"Santa Monica, CA 90401","['ELT SQL to build to populate Redshift models. Basically, loading staging tables and then using Redshift SQL to transform/massage the data. So will need extensive capabilities in SQL coding in Redshift.', 'Python may be required to get the data from source and then load into staging tables by executing basic data standardization. Python will also be used for any analysis request using existing Python libraries.', 'Similarly Airflow is also an option to move data into the staging tables before the ELT is run within Redshift.', 'For Looker modeling they will need expertise in LookerML tool that is used for data exploration with Looker', '401(k)', 'Health Insurance', 'Paid Time Off', '8 Hour Shift', 'Monday to Friday', 'Redshift: 1 year (Preferred)', 'SQL: 5 years (Preferred)', 'Data Engineer: 5 years (Preferred)', 'Airflow: 1 year (Preferred)', 'Python: 5 years (Preferred)', 'PageLooker: 1 year (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 13:37:08
Data Scientist,Infotree Global,N/A,"Creve Coeur, MO","['Design, implement and optimize algorithms for unsupervised and supervised learning based on structured and unstructured data.', 'Develop powerful business insights from social, marketing, industrial data and public policy using advanced machine learning techniques.', 'Work closely with the software engineering team to productize analytic software.', 'Collaborate with system integration and data warehouse engineers on data extraction and data cleaning.', 'Work in a highly interactive, team-oriented environment.', ""Requires a bachelor's degree in a STEM or related field and 5 years of experience, or a Master's degree in same with 3 years, or a PhD."", 'Temporarily due to COVID-19']",2020-08-08 13:37:08
Senior Data Engineer (Remote),NASWA (National Association of State Workforce Agencies),N/A,United States,"['401(k)', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'AWS: 2 years (Required)', 'Data Engineering: 7 years (Required)', 'Database Design: 2 years (Required)', 'ETL production support: 2 years (Required)', 'ETL Implementation: 2 years (Required)', 'AWS RDS: 2 years (Required)', 'AWS/Open Source ETL: 1 year (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'Fully Remote', 'No: Not providing sponsorship for this job', 'Waiting period may apply', 'Yes']",2020-08-08 13:37:08
Staff Engineer Systems,Northrop Grumman,4 out of 5,"Boulder, CO 80301","['Job', 'Company', 'The definitive technical authority for all aspects of engineering on all program elements (hardware/software/support/test) and leads a multi-disciplined engineering team managing the technical performance of the program meeting cost and', 'Serves as the technical point of contact with the customer.', 'Coordinates requirements development, hardware/software design, verification, and validation activities.', 'Ensures that the program is adhering to sound engineering processes in the development, production, test and sustainment of products for our customers and is compliance with company policies, procedures, and quality standards.', 'Collect and provide technical risks or opportunities, and risk mitigation and support Risk and Opportunity Management best practices.', 'Continually coordinates with the engineering discipline team leaders to ensure the execution of program statement of work and baselines.', 'Provides technical direction for developing concepts of operation, architecting, design, development, engineering, interfacing, integration, and testing of all components of complex software/hardware systems.', 'Develops alternative courses of action, workarounds, with a recommended course of action for each risk, and monitors and re-evaluates risks at appropriate milestones using earned value management (EVM) data.', 'Ensures effective, periodic review and control of the evolving configuration of a system, both software and hardware components and associated documentation, during the life of the system.', 'Provide critical technical decisions using a structured approach to investigate design alternatives that consider life cycle cost, reuse, complexity, risk, system expansion, and growth.', 'Works from top-level system requirements to define and organize the detailed tasks/schedule/skills required to meet the requirements within cost and schedule constraints.', 'Possesses excellent communications and organizational capabilities. Must be able to establish and maintain effective customer communication. Must be able to generate and evaluate Engineering inputs to proposals.', 'Additional duties include providing input to personnel performance evaluation, employee development, recruiting, and workload planning/forecasting.']",2020-08-08 13:37:56
Senior Maintenance Engineer,Volvo Group,4.1 out of 5,"Hagerstown, MD 21742","['Participate in the creation and management of a Professional Maintenance (PM) Master Plan for the Volvo Powertrain facility', 'Coach employees to understand the PM pillar in a World Class Manufacturing environment', 'Lead operations maintenance and secure application of proper methods, tools and execution of such to reduce equipment failure related losses', 'Conduct Kaizen improvement activities focused on safety, quality and cost initiatives: Data Analysis and Root Cause Analysis', 'Validate, update and control drawings and prints', 'Machine component evaluations (life cycle)', 'Time based maintenance schedule development and attainment', 'Standard Maintenance', 'Procedure development and evaluation', 'Machine life extension and increased reliability', 'Drive the interface between all areas connected to Professional Maintenance (methods, tools, data)', 'Sustain work processes within the organization', 'Bachelor of Science Degree in Engineering (Electronic, Mechanical or Industrial) and 3 years of experience in any technical manufacturing maintenance occupation', 'Experience must include predictive and preventive maintenance in a manufacturing environment', 'Core understanding of the professional maintenance pillar in a World Class Manufacturing environment', 'Previous experience working with line balancing and improving line automation']",2020-08-08 13:37:56
Liaison Engineer,FCA,4 out of 5,"Kokomo, IN 46902",[],2020-08-08 13:37:56
Principal Human Factors Engineer,Fusion Engineering,N/A,"Naperville, IL 60563","['Assess human interactions with equipment and environments', 'Analyze product designs with respect to human interaction', 'Assess cognitive processing, perception reaction times, human behavior and reactions, occupational safety, warnings, and product literature in a variety of contexts', 'Travel to accident scenes or client sites to perform inspections, gather data, and secure evidence', 'Evaluate existing materials to draw conclusions and/or identify an action plan', 'Manage projects from inception to completion, providing guidance to clients', 'Participate on multi-disciplinary teams to analyze complex issues', 'Prepare concise written reports of analysis and conclusions', 'Provide testimony of findings at deposition or trial', 'Author technical papers for publication in peer-reviewed journals', 'Present at technical conferences', 'Develop client relationships and promote business growth', 'Assist in marketing technical capabilities to clients and the scientific community', 'Master’s degree or PhD in human factors engineering or related field', 'At least 10 years of relevant experience, preferably including experience in consulting and/or testifying', 'Excellent written and verbal communication skills', 'The ability to work at a fast-pace in a team environment and independently', 'Strong organizational skills and ability to manage several projects simultaneously', 'Attention to detail', '401(k)', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Relevant: 7 years (Required)', ""Master's (Required)"", 'Yes']",2020-08-08 13:37:56
Systems Engineer,Amazon.com Services LLC,3.6 out of 5,"Arlington, VA 22202","['Job', 'Company', ""Bachelor's degree in Engineering, Computer Science or equivalent work experience"", '3+ years of experience in 24x7 production environments', '5+ years Linux experience and associated tools/languages', '2+ years experience building scripts, tooling, and automation for large-scale computing environments', '1+ years of experience scripting in any of the following: Python, Javascript, Bash/Shell', 'Current, active US Government Security Clearance of Top Secret or above', 'Excellent problem solving skills with a strong attention to detail', 'Ability to dive deep and understand all layers of a web services technology stack', 'Knowledge of TCP/IP and networking protocols such as HTTP and DNS', 'Experience with tcpdump, wireshark, or other protocol analyzers', 'Experience managing large server fleets', 'Experience with hardware and software load balancing technologies', 'Meets/exceeds Amazon’s leadership principles requirements for this role', 'Meets/exceeds Amazon’s functional/technical depth and complexity for this role']",2020-08-08 13:37:56
Sr. Project Engineer,Project Farma,4.3 out of 5,"Washington, DC","['Manage projects and teams related to the commissioning, qualification, automation, and validation testing on manufacturing utilities and process equipment.', 'Prepare and execute test plans, protocols, initiate controlled documentation, and provide client support for various projects either independently or as part of a larger team.', 'Generate documents such as master plans, design qualification, equipment, facility and utilities commissioning and qualification protocols, cleaning validation, computer validation, sterilization validation, data reviews, SOP development, and development of final reports.', 'Independently initiates, supports, provides direction, execution, and follow up of commissioning, qualification, automation, and validation projects', 'Provide daily work projections and progress reports', 'Facilitate and/or provide the mentoring process for entry-level Project Farma Team Member', 'Effectively communicate with clients and Team Members', 'Provide floor support with manufacturing execution', 'Escalation of exceptional conditions', 'Provide post execution protocol management', 'Author and manage summary reports', 'Bachelor’s degree in Life Science, Engineering, or related discipline and/or comparable military experience', 'A minimum of three (3) years’ experience in pharma and/or biotech', 'Great soft skills, excellent verbal and written communication', 'Experience leading high-performance project teams by serving as the project advocate within the client project.', 'A proactive approach with clients to identify needs and work toward solutions that meet project scope, schedule, cost, risk, and quality expectations and requirements.', 'Proven project and people leader with exceptional skills in planning, organizing, and history of driving and delivering successful results.', 'Expert understanding and work habits compliant with cGMPs and pharmaceutical and biopharmaceutical unit operations.', 'Proficient with Microsoft Word, Excel, Project, with hands-on experience working in a corporate setting, and as a productive and supportive member of a project team.', 'Demonstrate strong personal attributes that include: dedicated work ethic, teamwork, professionalism and the ability to see the “big picture”', 'Competitive salary based on experience', 'Aggressive bonus structure to reward your commitment', 'Paid Time Off', 'Flex-time', 'Company laptop', 'Continuing education (internal and external)', 'Health Insurance', '401k plan with company match and discretionary annual profit sharing', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Referral Program', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', 'Biomedical Engineering: 3 years (Required)', ""Bachelor's (Required)"", 'United States (Required)', '100% (Required)', 'Will you now or in the future require sponsorship for employment visa status (e.g., H-1B visa status)?', 'Multiple locations', 'projectfarma.com', 'facebook.com/projectfarma', 'Waiting period may apply', 'Only full-time employees eligible', 'No']",2020-08-08 13:37:56
"Operations Engineer (Wenatchee, WA)",Apeel Sciences,3.3 out of 5,"Wenatchee, WA","['Support customer sites in a region by proactively monitoring and maintaining the health of Apeel processes/equipment by quickly troubleshooting and resolving problems.', 'Support sites by safely and effectively operating, cleaning, sanitizing, and maintaining the mixing, application, and drying equipment to apply the Apeel product onto produce.', 'Demonstrate leadership behaviors with a clear focus on food safety and occupational health safety of employees, and produce product quality.', 'Support capital project execution, acting as Project Engineer overseeing planning, installation and commissioning of Apeel equipment and startup of commercial operations as needed.', 'Lead continuous improvement projects to drive an increase in productivity and revenue with customers and Apeel Customer Success Managers and Technical Field Specialists.', ""Track projects' statuses, manage list of action items and provide regular updates."", 'Update, train and verify compliance with Standard Operating Procedures.', 'Lead repairs and projects with contractors, Apeel Design Engineers, Apeel EHS Specialists, Quality Assurance staff, and Apeel Technical Field Specialists.', 'Ensure execution of preventive, corrective, and scheduled maintenance programs.', 'Use equipment indicators to monitor reliability, capacity and capability (e.g., OEE).', 'Collect and analyze product quality data on Apeel-treated produce as needed.', 'BS degree in Mechanical, Chemical or Industrial Engineering or similar', '2–5 years of experience in a technical field with a preference for those related to produce, agriculture, food & beverage or chemical manufacturing', 'Excellent interpersonal and communications skills; able to work cross functionally with all departments and customers', 'Extremely detailed and process oriented with the ability to troubleshoot equipment', ""Experience with LEAN, 5-Why's, Root Cause Failure Analysis (RCFA), Six Sigma, Design of Experiments (DOE), etc."", 'Experience with programmable logic controllers (PLCs), automation, and controls systems', 'Integrity, initiative, & team spirit that fits a fast-paced, ever-changing startup environment', 'Ability to multi-task and set priorities according to changing requirements', 'Proficient in Microsoft Office and Google Suite including Excel, Email, Calendar, etc.', 'Ability to work indoors/outdoors in cold and/or hot environments and lift up to 50 lbs', 'Ability to work a flexible schedule, including nights, graveyards, weekends and holidays', 'Willing to travel (regional/national/international as needed) is required (up to 60%)', 'Must possess valid driver license and access to reliable transportation']",2020-08-08 13:37:56
Sorter Project Engineer,Interroll Atlanta,N/A,"Hiram, GA 30141","['Creating and verifying layout, detail, load, structural drawings, schematics and equipment orders as applicable to the project.', 'Plans equipment layout, material flow, and measures to maintain efficient and safe utilization of resources and equipment on projects as assigned.', 'Works with other engineering disciplines in the development and application of material handling equipment and solutions as required in support of project needs. Integrates findings and concepts into design recommendations on projects assigned.', 'May potentially direct and coordinate building of prototypes. Confers with research and other engineers to clarify and resolve problems found during execution; prepares design modifications, as appropriate.', 'Support Installation with instructions and drawings.', 'Oversee a small team of 1 to 2 designers in completing Engineered to Ordered Products to meet customer requirements.', 'Adhere to a schedule to ensure all engineering tasks are completed on time.', 'Support Installation with technical expertise for field modifications.', 'Writes process guidelines and conducts training of reports to comply with process requirements.', 'Creation of Engineering Process Tasks for all Projects.', 'Assist with Corrective Actions for customer complaints.', 'Utilize ERP Systems to release designs to production which meets customer requirements.', 'Performs a variety of calculations (computing angles, weights, and dimensions) and prepares detailed multi-view drawings based on engineering data and standard references.', 'Communication (facilitation and mature communication skills to be able to communicate to all areas of the project team and client when necessary).', 'Accountable for all aspects of the project components from start to completion.', 'Transform conceptual drawings into final engineered installation drawings.', 'Build equipment list and issue purchase orders for project components.', 'Work with project management and install teams with on-site support.', 'Ensure robust design reviews are conducted to improve the quality of output in engineering.', 'Understand, diagnose, and solve real or potential design problems.', 'Display Interroll’s Guiding Principles always:', 'Minimum of a bachelor’s degree in Mechanical Engineering.', 'Master’s degree in Mechanical Engineering Preferred.', '6+ years of engineering experience, ideally in the material handling industry.', 'Analytical and mathematical mind, capable of evaluating and solving various complex problems.', 'Leadership skills necessary to manage and develop a team.', 'Organizational competencies and project management skills to keep projects, processes, and the sorter project team on track.', 'Self-motivated attitude with the ability to multitask and thrive in a timeline-driven environment.', 'Interpersonal communication skills with expertise in distilling complicated topics to a broader audience.', 'Good understanding of budgeting and reporting.', 'Experience in directing and evaluating subordinates.', 'Excellent organizational and communication skills.', 'Excellent Problem-solving abilities.', 'Willingness to learn new technologies.', 'Ability to understand and maintain project schedules.', 'Excellent time management skills.', 'Excellent organizational skills.', 'Excellent verbal communication skills.', 'Excellent technical writing skills.', 'Eagerness to get involved in hands-on work.', 'Able to effectively communicate with engineering and estimating departments, contractors, suppliers, and customers.', 'Able to work well independently and in a team environment.', 'Able to technically define problems and propose solutions.', 'Adaptable to change in a learning environment.', 'Willing and able to work overtime, weekends, and holidays when necessary.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Employee Discount', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Referral Program', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', '8 Hour Shift', 'Monday to Friday', 'Bonus Pay', 'Management: 3 years (Preferred)', 'Engineering: 6 years (Preferred)', ""Bachelor's (Required)"", 'Hiram, GA 30141 (Preferred)', 'United States (Required)', 'www.interroll.com', 'Waiting period may apply', 'No']",2020-08-08 13:37:56
Product Engineer (New Product Development),Philips,4 out of 5,"Reedsville, PA","['Job', 'Company', 'Leading the development of new processes that are highly capable and predictable.', 'Developing and executing design and process verification activities, including statistical analysis, similarity and testing.', 'Identifying and developing automated process solutions to reduce cost and reduce process variation.', 'Managing capital equipment projects and completing necessary process validation.', 'Identifying, analyzing and implementing cost reduction projects, cycle time improvements and lean manufacturing techniques, to improve product cost structure.', 'Providing technical support to resolve manufacturing and quality problems, including yield and nonconforming product.', 'Driving corrective action with appropriate and detailed follow up.', 'Identifying, specifying and coordinating installation of new manufacturing equipment and upgrades for process improvement.', 'B.S. in Mechanical Engineering (highly preferred), other disciplines considered with applicable experience', '5+ years of practical experience applying engineering (ex. developing processes for new products and implementing automated equipment)', 'Strong working knowledge of mechanical drawings, electrical schematics, control systems and data acquisition methods', 'Demonstrated strong analytical and problem solving skills, with the ability to provide technical leadership in ambiguous situations', 'Ability to lead teams across the organization on projects', 'Excellent communication (written and verbal), team leadership, and interpersonal skills', 'Knowledge of Statistical Methods (Process Capability, SPC, Trend Analysis) (a plus)']",2020-08-08 13:37:56
Systems Engineer - Hardware,Linode,N/A,"Philadelphia, PA 19106","['Linux and Tools - Debian, NUMA, resource allocation, CPU pinning, hyperthreading, cgroups', 'Kernel - Debugging, Tuning, Configuring, Building', 'Hardware - Components, Benchmarking, RAID', 'Data Center Engineering - Provisioning and deploying servers, storage, and networking solutions', 'Scripting / Automation - SaltStack, Python, Bash, etc.', 'Infrastructure Services - DHCP, DNS, SSL, NTP, etc.', 'Alerting & Metrics - Nagios, Prometheus, ELK, Grafana', 'Version Control - Git, GitHub', 'Professional experience in a Systems Engineering role, preferably working with and maintaining large production distributed systems', 'Keep abreast of new component releases and trends and make recommendations that influence the Linode hardware roadmap', 'Have a good understanding of the Linux Kernel and experience with compiling and tweaking kernel for performance/stability', 'Create, improve, and maintain testing and burn-in scripts/programs and procedures', 'Perform, compile, and interpret hardware and software benchmarks using industry-standard tools', 'Make component and configuration recommendations based on workload and benchmark results', 'Experience with hardware and systems automation', 'Create the specification for new hardware builds', 'Excellent communication and interpersonal skills', ""Ability to participate in Linode's 24/7 incident response on-call rotation, including being responsive and available to quickly troubleshoot and resolve issues"", 'Familiarity with best practices of systems architecture, design, and high-performance tuning', 'Experience with KVM/QEMU or similar virtualization technologies', 'Experience architecting large scale database server hardware', 'Experience with racking and stacking hardware', 'Experience in a hosting environment or other cloud-based IAAS or SAAS', 'Presence in the open-source world. Contributions to open-source projects as well as your own portfolio to show off is a huge plus', 'Ability to work in an agile organization', 'Philadelphia Office: HQ is one of the coolest tech buildings (https://www.linode.com/press/linode-buys-real-world-bank-for-phila-office) in Philly; join us on N3RD street!', 'Flexible work hours: We offer a flexible work schedule, a generous paid time off package, and two work from home days on a weekly basis.', 'Unbelievable benefits: We provide comprehensive health insurance, 401(k) contributions, a profit-sharing program, and pension plans.', 'Monthly wellness reimbursements: up to $100 towards gym memberships, diet plans, massages, etc.', 'A Macbook Pro: to use around the office and at home.', ""Free hosting service: Take advantage of some Linode service - we'll pick up the tab."", 'Linode Lunch: What goes better with technology than food? Nothing. We bring in a catered lunch every week.', 'Competitive salary: It all begins with fair compensation. We believe in paying people well and rewarding those who go the extra mile.']",2020-08-08 13:37:56
Plant Engineer,Refresco North America,3 out of 5,"Wharton, NJ","['Leads continuous improvement projects in production, quality, maintenance and warehouse', 'Evaluates, recommends and leads improvements resulting in better line performance', 'Analyses performance trends and conducts root cause corrective action to drive improvements', 'Participates in process of problem solving in any department', 'Engages employees through a strong visual presence on the production floor', 'Participates in development of metrics to validate the profitability and feasibility of the site', 'Actively participates in the optimization of the production lines and department work processes', 'Establish and document new methods and working procedures for all departments in the plant', 'Conduct monitoring of the CMOS system to ensure that no gaps exist', 'Lead implementation of special projects including capital work', 'Bachelors or better', 'Thought Provoking: Capable of making others think deeply on a subject', 'Team Player: Works well as a member of a group', 'Loyal: Shows firm and constant support to a cause', 'Leader: Inspires teammates to follow them', 'Detail Oriented: Capable of carrying out a given task with all details necessary to get the task done well', 'Innovative: Consistently introduces new ideas and demonstrates original thinking', 'Functional Expert: Considered a thought leader on a subject', 'Enthusiastic: Shows intense and eager enjoyment and interest', 'Dedicated: Devoted to a task or purpose with loyalty or integrity', 'Growth Opportunities: Inspired to perform well by the chance to take on more responsibility', 'Goal Completion: Inspired to perform well by the completion of tasks', 'Ability to Make an Impact: Inspired to perform well by the ability to contribute to the success of a project or the organization']",2020-08-08 13:37:56
RADAR ENGINEER,PredaSAR Corporation,N/A,"McLean, VA","['Lead and conduct radar systems assessments and trade-studies to explore and set radar system parametrics, including waveform and parameter selection', 'Develop, prototype, and test radar system models in detailed high-fidelity simulations written in MATLAB and other common industry applications to enable assessments, trade studies, and algorithm development', 'Apply SAR image formation and exploitation knowledge to assess and develop signal processing algorithms to support operational implementations and studies', 'Develop test plans, conduct tests, and analyze results to verify, and validate radar sensor and signal processing algorithm requirements and performance', 'Propose and perform engineering studies for government sponsors and commercial customers to innovate and evaluate space-based radar payloads and algorithms', 'Prepare, present, and participate in project design reviews and peer reviews for all phases of radar/SAR development tasks', ""Bachelor's, Master's, or Ph.D. in electrical engineering, math, physics, or related field, depending on position level"", 'Minimum of 5 years of experience in radar systems end-to-end design, development, and/or assessment, through modeling and simulation', 'Experience in developing techniques for radar signal processing, with specific emphasis on Synthetic Aperture Radar (SAR) preferred', 'Demonstrated leadership as well as workload, time, and resource management abilities', 'Proficient at MATLAB application for radar', 'Prior coursework or experience in areas of digital signal processing, probability theory, stochastic signal processing, and electromagnetic theory', 'To comply with U.S. Government space technology export regulations, applicants must be a U.S. citizen, lawful permanent resident of the U.S., protected individual as defined by 8 U.S.C. 1324b(a)(3), or eligible to obtain the required authorizations from the U.S. Department of State', 'Detailed knowledge of the space-based radar systems or space systems', 'Experience supporting Synthetic Aperture Radar (SAR) use cases in the Intelligence Community or Department of Defense', 'Experience in creating efficiencies or novel techniques in collection, processing, and exploitation of Synthetic Aperture Radar (SAR) data', 'Familiarity with open data standards utilized in the common transport and processing of radar data products', 'Familiarity with advanced solution for data storage and analysis', 'Experience with C/C++ and/or Python', '401(K)', 'Employee Stock Program', 'Generous PTO with floating holidays and flexible vacation policy', 'Competitive health benefits including company-paid comprehensive medical, dental, and vision coverage', 'Access to Gradifi Refi tuition refinancing assistance', 'Cross-training and professional development opportunities', 'radar engineer: 10 years (Required)', ""Bachelor's (Required)"", 'TS/SCI clearance (Required)', 'Multiple locations']",2020-08-08 13:37:56
Surface Development Engineer,GENTEX OPTICS INC,3.7 out of 5,"Dudley, MA 01571","['Manage local and global projects involved with optical surface development and support', 'Evaluate new processes, materials, and technologies for the creation of optical tooling surfaces', 'Review, and update engineering processes', 'Design, fabricate and test tooling for optical surfaces', 'Develop and document new surfacing processes', 'Train personnel for use of tooling', 'Participate in the technical forums pertaining to optical surfaces', 'Lead technical projects in development and roll out of optical surfaces for ophthalmic lens application', 'Support global Thermoplastic production', 'Research materials and machinery to be used for fabrication of optical inserts', 'Evaluate materials and machinery for deployment to global manufacturing sites', 'Conduct scientific evaluation of optical surfaces, write technical reports and present findings', 'Train personnel for use of tooling', 'Masters Degree in Engineering including 5 - 10 years experience', 'Strong understanding of lens optics, and fundamental knowledge of the fabrication processes involved in creation of optical surfaces.', 'A good understanding in the state-of-art metrology of optical surface and curvature measurements.', 'A strong background in the interaction between machining of optical surface, material properties of optical surface, replication of optical curves and interaction of the optical surface with the lens manufacturing process, such as injection molding.', 'A strong background in the data manipulation for lens optics calculation using Excel, Matlab, R, Python or other relevant scientific means.', 'Strong interpersonal skills.', 'Good verbal and written communication skills.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Employee Discount', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Referral Program', 'Relocation Assistance', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', '8 Hour Shift', 'Bonus Pay', 'A job for which military experienced candidates are encouraged to apply', 'Open to applicants under 18 years old, provided it is legally allowed for the job and location', 'A job for which all ages, including older job seekers, are encouraged to apply', 'A job for which people with disabilities are encouraged to apply', 'Waiting period may apply', 'No']",2020-08-08 13:37:56
Junior Controls and Information Engineer,Meati Foods,N/A,"Boulder, CO 80301","['Maintain and expand proprietary plant sensor system: Reprogramming, calibrating, and adjusting existing sensor systems as needed as well as the definition and analysis of new needs, new hardware development, analytical troubleshooting, and deployment of hardware and software', 'Develop Business Intelligence Tools: Maintain and upgrade existing informatic tools within existing software and hardware infrastructure, analyze needs to define needs, and design new tools with the aim of bringing powerful information to users. This may include real-time data and automated reporting at all levels of the organization', 'PLC Controls: Maintain existing industrial standard PLC controls, analytically and systematically troubleshoot issues as the come up', 'Work within C++, HTML, PHP, Javascript, Apache Server, and SQL on a fairly regular basis', 'Perform basic database and server management', 'Bachelor’s degree in Electric or Computer Engineering is preferred', 'Bachelor’s degree in Software or Information Engineering will also be considered with required experience', '2 or more years related experience in industry is required', 'Ability to interface to all engineering disciplines', 'Strong interpersonal communication skills and effectiveness working independently and in cross-functional teams', 'Ability to grasp new technical concepts including hardware/software interactions, real-time processing, and concepts of operations', 'Ability to prioritize tasks, set schedules and understand various projects to achieve overall business goals. This will include a level of comfort in “shifting gears” as required to meet needs.', 'Ability to modify and maintain existing software code and architecture and to work within set standards', 'Strong debugging skills, good mechanical aptitude, and hands-on hardware experience', 'Ability to apply sound engineering principles to the development of software and hardware through the full lifecycle', '2 or more years’ experience working with C++, HTML, PHP, Javascript, Apache Server, and SQL Server required', 'Must have C/C++ development experience for embedded systems', '2 or more years’ experience working on efforts that require effective engineering requirements definition and analysis, architecture definition, design, implementation, and testing', '2 or more years’ experience performing analytical troubleshooting and problem solving with software and/or hardware, writing and maintaining documentation, and communicating well with team members on progress', 'Experience in developing business intelligence tools in industry is strongly preferred', 'Experience in analyzing needs, designing solutions, building needed hardware, and programming controllers for deployment is preferred', 'Familiarity with open source microcontroller hardware, software, and peripherals is a plus', '401(k)', 'Health Insurance', 'Monday to Friday', 'Controls: 2 years (Required)', ""Bachelor's (Required)"", 'One location', 'www.meati.com', 'No']",2020-08-08 13:37:56
Professional Structural Engineer,Wood Research and Development,3 out of 5,"Salem, OR","['Salary 75k to 85k Annual DOE', 'Group Health Insurance', 'Vision Insurance', 'Aflac', '6 Paid Holidays', '6 Paid PTO Days', 'Paid Vacation', '401k/Profit Sharing', '401(k)', '401(k) Matching', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'One location', 'woodrandd.com', 'Waiting period may apply', 'No']",2020-08-08 13:37:56
Plastics Process Engineer,Logoplaste,3.5 out of 5,"Martinsburg, WV","['401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Referral Program', 'Vision Insurance', 'Day shift', 'blow molding: 3 years (Required)', 'Manufacturing: 3 years (Preferred)', 'One location', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Aggressive -- competitive and growth-oriented', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.logoplaste.com', 'No']",2020-08-08 13:38:43
Data Engineer,HUNTER Technical Resources,4.7 out of 5,"Atlanta, GA 30346","['Design, build and test a data migration solution.', 'Ensure deployed application meet architect guidelines', 'Act as a strategic thought partner, propose solutions in alignment with objectives and timelines.', 'Communicate complex technical ideas to business units.', '5+ years experience engineering data-related solutions', '3+ years experience building data-related solutions in a cloud platform', 'Strong SQL and relational database experience.', 'Experience with ETL tools', 'Experience with data modeling and analysis', 'Experience with programing languages such as C#, JavaScript, NodeJS, Python, etc.', 'Knowledge of data replication tools', 'Experience with automated code repository and deployment solutions.']",2020-08-08 13:38:43
IT Data Engineer,Holder Construction Group,3.9 out of 5,"Atlanta, GA","['Design and develop ETL processes', 'Develop automated quality assurance processes to monitor the quality of inbound data and to ensure the continued accuracy of data processing within the platform', 'Create and maintain data visualization dashboards and reports', 'Implement appropriate levels of data protection', 'Bachelor’s degree with an Information Technology focus', '2 – 4 experience in the IT field', 'Experience with cloud computing in the Azure environment including Azure Functions, Data Factory, Data Flow, Databricks', 'Experience in dashboard and report development in PowerBI', 'Strong knowledge of data modeling principles and best practices', 'Ability to diagnose and troubleshoot complex data quality issues', 'Ability to translate stakeholder requirements into technical specifications']",2020-08-08 13:38:43
Data Engineer,"Impact Consulting Solutions, Inc.",N/A,"Pittsburgh, PA 15205","['401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Retirement Plan', 'Vision Insurance', '8 Hour Shift', 'Day shift', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'No']",2020-08-08 13:38:43
Manufacturing Data Engineer,Takeda Pharmaceutical,3.8 out of 5,"Social Circle, GA","['Leads complex data analysis, uses and explores data, languages, tools and software to best construct data for predictive modelling, tests the model, trains data to deploy the modelling within the global GMS GQ environment, and embed new capabilities in the global Enterprise Architecture.', 'Manages and develops technical existing and new computer science platforms to design, to analyze and implement complex and new data driven solutions, with an impact on the daily operation of our manufacturing facilities.', 'Interprets and develops advance techniques in partly structured and unstructured big data across different partner organizations.', 'Oversee and guide efforts of Advanced Analytics in a GxP environment from an IT perspective in all US GMS sites and for our collaboration with CMO’s.', 'Determines data analysis approaches, uses different technologies, big data preparations, programming and loading as well as initial exploration in the process of searching and finding data patterns.', 'Oversees data science input and requests, translates these from data exploration - large record (billions) and unstructured data sets - to mathematic algorithms and uses various tooling from programming languages to new tools (artificial and machine learning) to translate, build and optimize models.', 'Leads and conducts ongoing tests in the search for solutions in the data modelling, collects and prepares the training of data, tones the data, optimizes algorithm implementations to test, scale, and deploy future models.', 'Designs/builds/deploys complex data models related to R&D questions independently.', 'Develops technical roadmaps and approaches for data analyses to find patterns, to design data models, to scale the model to a managed production environment within the current or a technical landscape to develop.', 'Influences and guides data exploration from analysis to scalable models, works independently and decides quick on transfers in complex data analysis and modelling.', 'Interprets the impact on IT Structure and Architecture and influences this discipline.', 'Independently use own judgement to identify data requirements and influences the design and implementation of the IS/IT data strategy.', 'Ensures execution and documentation to Takeda Quality Management System (QMS), suggest adjustments to the Software Development Life Cycle (SDLC) and other standards, policies and procedures.', 'Work independently on tough problems with other team members and independently solve, with some guidance, very difficult technology problems.', 'Demonstrates advanced tooling and techniques to other engineers and traditional analytics organizations throughout the company', 'Maintains up-to-data knowledge on modern data technologies, explores new platforms and beta tooling.', 'Represent the team while working on project across R&D and commercial. Is internal and external expert to-go-to in how to drive advanced Computer Science and Engineering skills and techniques.', 'Influences and maintains relationships with partner organizations in support of data analysis, modelling and deployment.', 'Master Degree in Computer Science or equivalent', '2 years or more of relevant experience.', 'Ability to write, speak and lead in the English language', 'Excellent oral and written communications skills, business acumen and excels in problem solving and analytical skills.', 'Have a good understanding of the pharmaceutical industry and experience with validated systems.', 'Up-to-date specialized knowledge of data wrangling, manipulation and management of technologies to affect change across business units.', 'Ability to work in an agile and rapid changing environment with high quality deliverables.', 'Experience Programming Java or Scala (Python?)', 'Understanding of Web Services as well as JSON formats', 'Working knowledge of SQL and Relational Databases', 'Experience with at least one NoSQL datastore (Cassandra, MongoDB, Neo4J, …)', 'Understand the concepts of Hadoop and Spark', 'Experience in Computer Systems Validation GAMP', 'Understanding of AWS (S3, EC2, Redshift, EMR, Athena)', 'Experience with Business Intelligence and Tools (Qlik/PowerBI)', 'Additional Languages: Python, Scala, Chef, R, Javascript', 'Experience with Multiple NoSQL datastores (Cassandra, MongoDB, Neo4J, …)', 'Experience with data formats including Parquet, ORC or AVRO', 'Experience with any of the following Frameworks: Spring, Django, R Shiny, Tensorflow, MXNet', 'Understanding or Application of Machine Learning and / or Deep Learning']",2020-08-08 13:38:43
Engineer,iFrog Digital Marketing,4.3 out of 5,"Washington, DC","['Has 2 years experience working on large scale, well-maintained codebases', 'Is comfortable architecting, designing, implementing, and scaling web-based applications on desktop and mobile', 'Possesses strong leadership, and communication with a desire to put others first', 'Has an innate drive to succeed', 'Is able to effectively deal with ambiguity and evolving, changing requirements', 'Desires to learn new things, ramp-up quickly, and implement new/emerging technology to keep up with evolving trends', 'Bachelor’s degree in Computer Science, related technical field, or equivalent practical experience', '2 years experience working on large scale, well-maintained codebases', '1 or more technologies: Java, JavaScript, Ruby, Python, Kotlin', '1 or more libraries & frameworks (e.g. React, Angular./JS, Ember, Vue, Svelte, PrimeNG, TypeScript)', 'Data modeling & IDE', 'HTML/CSS (e.g. semantics, layout, specificity, cross-browser functionality, accessibility, responsive design)', 'APIs: REST, JSON, XML', 'UML or similar system design modeling', 'NoSQL/SQL databases (e.g. PostgreSQL, MySQL, MongoDB, NoSQL)', 'Performance & Optimization', 'Automation Tools: Chef, Puppet, Ansible', 'Containers: Docker, Kubernetes', 'UX/UI Design', 'Owner of a software product', 'Cloud infrastructure & applications (e.g. AWS, Azure, Google Cloud)', 'Continuous Development/Integration', 'Technical documentation or technical blogging', 'Marketing concepts (e.g. seo, sem, audiences, attribution, Google analytics, adwords)', 'Marketing technology (e.g. dmp, cdp, dsp)', '401(k)', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Referral Program', 'Vision Insurance', 'Monday to Friday', 'Coding: 2 years (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'One location', 'Fully Remote', 'Dependable -- more reliable than spontaneous', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'www.ifrog.com', 'Waiting period may apply', 'Yes']",2020-08-08 13:38:43
Aviation Support - Pennsylvania,iFrog Digital Marketing,N/A,"Washington, DC","['Interviews on the spot', 'Wednesday, August 12, 202010:00 AM - 3:00 PM US/Eastern', ""Interviewing via webYou'll receive an email on how to connect."", '4635 slots left', 'IT - Pennsylvania$50,000.00 - $87,000.00 / year, Full-timeIn the Navy, information technology (IT) plays an important role in everything from electronic mail systems, to shipboard control systems, to Special Intelligence (SI) systems. Navy Information System Technicians are Enlisted Sailors who engage in a broad range of responsibilities, including network administration, database management and computer hardware and software implementation. Their responsibilities include:Operating and maintaining Navy global satellite telecommunications systemsServing as admin on mainframe computers and local and wide area networksImplementing micro-computer systems throughout the FleetServing as an important part of the Information Warfare Community in its mission to gain a deep understanding of the inner workings of adversaries and developing unmatched knowledge of the battlespace during wartimeNo experience needed; paid training provided.', 'Operating and maintaining Navy global satellite telecommunications systems', 'Serving as admin on mainframe computers and local and wide area networks', 'Implementing micro-computer systems throughout the Fleet', 'Serving as an important part of the Information Warfare Community in its mission to gain a deep understanding of the inner workings of adversaries and developing unmatched knowledge of the battlespace during wartime', 'Logistics - Pennsylvania$40,000.00 - $100,000.00 / year, Full-timeThe success and safety of every mission depends on getting needed supplies, materials and equipment at a moment’s notice. The service members of the Purchasing, Supply & Logistics community make sure America’s Navy has what it needs, when it needs it.Officer positions in the Supply Corps are available to college graduates, and Logistics Specialist positions are available to those without a degree.No experience needed; paid training provided.', 'Healthcare - Pennsylvania$40,000.00 - $80,000.00 / year, Full-timeMedical emergencies happen and we need people who can take charge when they do. Whether you’re in a hospital or clinical setting, on a ship or submarine, or out in the field alongside fellow Sailors or Marines, you will use advanced medical training to save lives. The bravest fighters in the world put their lives in your hands. And it’s your job to ensure they have the care they need. In Navy Healthcare, you may:Perform emergency medical treatment on SEALs, Seabees, Marines and other military personnel injured in the fieldPerform emergency dental treatment as well as construct dental crowns and bridges, process dental X-rays and operate X-ray equipmentServe as an operating room technician for general and specialized surgeryHelp administer a wide range of preventive care and medications, including immunizations and intravenous fluidsMaintain patient treatment records, conduct research and perform clinical testsNo experience needed; paid training provided.', 'Perform emergency medical treatment on SEALs, Seabees, Marines and other military personnel injured in the field', 'Perform emergency dental treatment as well as construct dental crowns and bridges, process dental X-rays and operate X-ray equipment', 'Serve as an operating room technician for general and specialized surgery', 'Help administer a wide range of preventive care and medications, including immunizations and intravenous fluids', 'Maintain patient treatment records, conduct research and perform clinical tests', 'Cryptology - Pennsylvania$50,000.00 - $80,000.00 / year, Full-timeEnlisted Sailors in the Navy Cryptology community analyze encrypted electronic communications, jam enemy radar signals, decipher information in foreign languages and maintain state-of-the-art equipment and networks used to generate top secret intel.Their other responsibilities include:Collecting, analyzing and reporting on communication signalsUtilizing computers, specialized computer-assisted communications equipment and video display terminalsServing as an important part of the Information Warfare Community\xa0in its mission to gain a deep understanding of the inner workings of adversaries and develop unmatched knowledge of the battlespace during wartimeNo experience needed; paid training provided.', 'Collecting, analyzing and reporting on communication signals', 'Utilizing computers, specialized computer-assisted communications equipment and video display terminals', 'Serving as an important part of the Information Warfare Community\xa0in its mission to gain a deep understanding of the inner workings of adversaries and develop unmatched knowledge of the battlespace during wartime', 'Electronics - Pennsylvania$60,000.00 - $80,000.00 / year, Full-timeNavy Electronics Technicians are an exclusive group of professionals specially trained in electrical engineering, computers and aerospace electronics. They help operate and manage the electronics systems and subsystems of the world’s most advanced ships and aircraft – as well as on bases ashore.As an ET, you’ll be responsible for maintaining, repairing and adjusting a huge range of cutting-edge electronic equipment. You may work with equipment used for everything from communications, detection and tracking to recognition and identification, navigation, and electronic countermeasures.There are also electronics careers that require advanced nuclear training and involve working with nuclear reactor control, propulsion and power generation on Navy nuclear-powered aircraft carriers.No experience needed; paid training provided.', 'Engineering - Pennsylvania$45,000.00 - $90,000.00 / year, Full-timeEvery year huge investments are made on construction projects that support the Navy’s high-tech fleet of ships, aircraft, equipment and personnel. At the center of these projects are a talented group of engineers who help to ensure that each initiative is conceived, planned and completed on time, in budget and according to specification.In this career path, you can receive unrivaled hands-on experience and advanced training in civil engineering areas including architecture, construction engineering, environmental engineering, water resources engineering, geotechnical engineering, hydraulic engineering, land surveying, structural engineering, transportation engineering and community planning. You’ll quickly find yourself in charge of vital Navy projects, where you might:-Oversee construction of everything from runways to docks to buildings of all kinds-Supervise and manage utilities and other critical services-Manage a variety of skilled construction workers (Seabees)-Arrange budgets and schedules-Approve completed workNo experience needed; paid training provided.', 'Aviation Support - Pennsylvania$21,000.00 - $68,000.00 / year, Full-timeThe successful operation of a flight deck on an aircraft carrier is one of the most complex, high-stakes exercises on the planet. It’s no small task to ensure that each aircraft that leaves the flight deck performs its mission successfully and returns home safely. Navy Aircrewmen, Air Traffic Controllers and Flight Support crewmembers are essential in directing the everyday complexities above and below the flight deck. Their responsibilities include:Performing aircraft tactical duties as a flight engineer, loadmaster and/or reel operatorExecuting handling duties related to the launch and recovery of Naval aircraftInterpreting data shown on radar screens to plot aircraft positionsOperating tactical weapons, sensors and communications equipmentWorking with pilots to operate and control aircraft systemsPerforming detailed maintenance on strike fighter helicoptersHandling explosive ordnance onboard Navy aircraftInspecting and maintaining all internal and external aircraft systemsProviding vital attack, defense and logistic support to the FleetNo experience needed; paid training provided.', 'Performing aircraft tactical duties as a flight engineer, loadmaster and/or reel operator', 'Executing handling duties related to the launch and recovery of Naval aircraft', 'Interpreting data shown on radar screens to plot aircraft positions', 'Operating tactical weapons, sensors and communications equipment', 'Working with pilots to operate and control aircraft systems', 'Performing detailed maintenance on strike fighter helicopters', 'Handling explosive ordnance onboard Navy aircraft', 'Inspecting and maintaining all internal and external aircraft systems', 'Providing vital attack, defense and logistic support to the Fleet', 'Interviews on the spot', 'Wednesday, August 12, 202010:00 AM - 3:00 PM US/Eastern', ""Interviewing via webYou'll receive an email on how to connect."", '4635 slots left', 'United States+1', 'United Kingdom+44', '', 'Afghanistan (\u202bافغانستان\u202c\u200e)+93', 'Albania (Shqipëri)+355', 'Algeria (\u202bالجزائر\u202c\u200e)+213', 'American Samoa+1684', 'Andorra+376', 'Angola+244', 'Anguilla+1264', 'Antigua and Barbuda+1268', 'Argentina+54', 'Armenia (Հայաստան)+374', 'Aruba+297', 'Australia+61', 'Austria (Österreich)+43', 'Azerbaijan (Azərbaycan)+994', 'Bahamas+1242', 'Bahrain (\u202bالبحرين\u202c\u200e)+973', 'Bangladesh (বাংলাদেশ)+880', 'Barbados+1246', 'Belarus (Беларусь)+375', 'Belgium (België)+32', 'Belize+501', 'Benin (Bénin)+229', 'Bermuda+1441', 'Bhutan (འབྲུག)+975', 'Bolivia+591', 'Bosnia and Herzegovina (Босна и Херцеговина)+387', 'Botswana+267', 'Brazil (Brasil)+55', 'British Indian Ocean Territory+246', 'British Virgin Islands+1284', 'Brunei+673', 'Bulgaria (България)+359', 'Burkina Faso+226', 'Burundi (Uburundi)+257', 'Cambodia (កម្ពុជា)+855', 'Cameroon (Cameroun)+237', 'Canada+1', 'Cape Verde (Kabu Verdi)+238', 'Caribbean Netherlands+599', 'Cayman Islands+1345', 'Central African Republic (République centrafricaine)+236', 'Chad (Tchad)+235', 'Chile+56', 'China (中国)+86', 'Christmas Island+61', 'Cocos (Keeling) Islands+61', 'Colombia+57', 'Comoros (\u202bجزر القمر\u202c\u200e)+269', 'Congo (DRC) (Jamhuri ya Kidemokrasia ya Kongo)+243', 'Congo (Republic) (Congo-Brazzaville)+242', 'Cook Islands+682', 'Costa Rica+506', 'Côte d’Ivoire+225', 'Croatia (Hrvatska)+385', 'Cuba+53', 'Curaçao+599', 'Cyprus (Κύπρος)+357', 'Czech Republic (Česká republika)+420', 'Denmark (Danmark)+45', 'Djibouti+253', 'Dominica+1767', 'Dominican Republic (República Dominicana)+1', 'Ecuador+593', 'Egypt (\u202bمصر\u202c\u200e)+20', 'El Salvador+503', 'Equatorial Guinea (Guinea Ecuatorial)+240', 'Eritrea+291', 'Estonia (Eesti)+372', 'Ethiopia+251', 'Falkland Islands (Islas Malvinas)+500', 'Faroe Islands (Føroyar)+298', 'Fiji+679', 'Finland (Suomi)+358', 'France+33', 'French Guiana (Guyane française)+594', 'French Polynesia (Polynésie française)+689', 'Gabon+241', 'Gambia+220', 'Georgia (საქართველო)+995', 'Germany (Deutschland)+49', 'Ghana (Gaana)+233', 'Gibraltar+350', 'Greece (Ελλάδα)+30', 'Greenland (Kalaallit Nunaat)+299', 'Grenada+1473', 'Guadeloupe+590', 'Guam+1671', 'Guatemala+502', 'Guernsey+44', 'Guinea (Guinée)+224', 'Guinea-Bissau (Guiné Bissau)+245', 'Guyana+592', 'Haiti+509', 'Honduras+504', 'Hong Kong (香港)+852', 'Hungary (Magyarország)+36', 'Iceland (Ísland)+354', 'India (भारत)+91', 'Indonesia+62', 'Iran (\u202bایران\u202c\u200e)+98', 'Iraq (\u202bالعراق\u202c\u200e)+964', 'Ireland+353', 'Isle of Man+44', 'Israel (\u202bישראל\u202c\u200e)+972', 'Italy (Italia)+39', 'Jamaica+1', 'Japan (日本)+81', 'Jersey+44', 'Jordan (\u202bالأردن\u202c\u200e)+962', 'Kazakhstan (Казахстан)+7', 'Kenya+254', 'Kiribati+686', 'Kosovo+383', 'Kuwait (\u202bالكويت\u202c\u200e)+965', 'Kyrgyzstan (Кыргызстан)+996', 'Laos (ລາວ)+856', 'Latvia (Latvija)+371', 'Lebanon (\u202bلبنان\u202c\u200e)+961', 'Lesotho+266', 'Liberia+231', 'Libya (\u202bليبيا\u202c\u200e)+218', 'Liechtenstein+423', 'Lithuania (Lietuva)+370', 'Luxembourg+352', 'Macau (澳門)+853', 'Macedonia (FYROM) (Македонија)+389', 'Madagascar (Madagasikara)+261', 'Malawi+265', 'Malaysia+60', 'Maldives+960', 'Mali+223', 'Malta+356', 'Marshall Islands+692', 'Martinique+596', 'Mauritania (\u202bموريتانيا\u202c\u200e)+222', 'Mauritius (Moris)+230', 'Mayotte+262', 'Mexico (México)+52', 'Micronesia+691', 'Moldova (Republica Moldova)+373', 'Monaco+377', 'Mongolia (Монгол)+976', 'Montenegro (Crna Gora)+382', 'Montserrat+1664', 'Morocco (\u202bالمغرب\u202c\u200e)+212', 'Mozambique (Moçambique)+258', 'Myanmar (Burma) (မြန်မာ)+95', 'Namibia (Namibië)+264', 'Nauru+674', 'Nepal (नेपाल)+977', 'Netherlands (Nederland)+31', 'New Caledonia (Nouvelle-Calédonie)+687', 'New Zealand+64', 'Nicaragua+505', 'Niger (Nijar)+227', 'Nigeria+234', 'Niue+683', 'Norfolk Island+672', 'North Korea (조선 민주주의 인민 공화국)+850', 'Northern Mariana Islands+1670', 'Norway (Norge)+47', 'Oman (\u202bعُمان\u202c\u200e)+968', 'Pakistan (\u202bپاکستان\u202c\u200e)+92', 'Palau+680', 'Palestine (\u202bفلسطين\u202c\u200e)+970', 'Panama (Panamá)+507', 'Papua New Guinea+675', 'Paraguay+595', 'Peru (Perú)+51', 'Philippines+63', 'Poland (Polska)+48', 'Portugal+351', 'Puerto Rico+1', 'Qatar (\u202bقطر\u202c\u200e)+974', 'Réunion (La Réunion)+262', 'Romania (România)+40', 'Russia (Россия)+7', 'Rwanda+250', 'Saint Barthélemy+590', 'Saint Helena+290', 'Saint Kitts and Nevis+1869', 'Saint Lucia+1758', 'Saint Martin (Saint-Martin (partie française))+590', 'Saint Pierre and Miquelon (Saint-Pierre-et-Miquelon)+508', 'Saint Vincent and the Grenadines+1784', 'Samoa+685', 'San Marino+378', 'São Tomé and Príncipe (São Tomé e Príncipe)+239', 'Saudi Arabia (\u202bالمملكة العربية السعودية\u202c\u200e)+966', 'Senegal (Sénégal)+221', 'Serbia (Србија)+381', 'Seychelles+248', 'Sierra Leone+232', 'Singapore+65', 'Sint Maarten+1721', 'Slovakia (Slovensko)+421', 'Slovenia (Slovenija)+386', 'Solomon Islands+677', 'Somalia (Soomaaliya)+252', 'South Africa+27', 'South Korea (대한민국)+82', 'South Sudan (\u202bجنوب السودان\u202c\u200e)+211', 'Spain (España)+34', 'Sri Lanka (ශ්\u200dරී ලංකාව)+94', 'Sudan (\u202bالسودان\u202c\u200e)+249', 'Suriname+597', 'Svalbard and Jan Mayen+47', 'Swaziland+268', 'Sweden (Sverige)+46', 'Switzerland (Schweiz)+41', 'Syria (\u202bسوريا\u202c\u200e)+963', 'Taiwan (台灣)+886', 'Tajikistan+992', 'Tanzania+255', 'Thailand (ไทย)+66', 'Timor-Leste+670', 'Togo+228', 'Tokelau+690', 'Tonga+676', 'Trinidad and Tobago+1868', 'Tunisia (\u202bتونس\u202c\u200e)+216', 'Turkey (Türkiye)+90', 'Turkmenistan+993', 'Turks and Caicos Islands+1649', 'Tuvalu+688', 'U.S. Virgin Islands+1340', 'Uganda+256', 'Ukraine (Україна)+380', 'United Arab Emirates (\u202bالإمارات العربية المتحدة\u202c\u200e)+971', 'United Kingdom+44', 'United States+1', 'Uruguay+598', 'Uzbekistan (Oʻzbekiston)+998', 'Vanuatu+678', 'Vatican City (Città del Vaticano)+39', 'Venezuela+58', 'Vietnam (Việt Nam)+84', 'Wallis and Futuna (Wallis-et-Futuna)+681', 'Western Sahara (\u202bالصحراء الغربية\u202c\u200e)+212', 'Yemen (\u202bاليمن\u202c\u200e)+967', 'Zambia+260', 'Zimbabwe+263', 'Åland Islands+358']",2020-08-08 13:38:43
Data Engineer,GuideWell Connect,3.2 out of 5,"Jacksonville, FL 32256","['Create and maintain custom reports and/or data files from multiple access databases', 'Provide oversight for the creation and daily running of mission critical departmental reporting for departmental metric results', 'Design and develop ETL using Toad and SQL Server stored procedures or other tools, functions, and views', 'Translate business needs to data elements in Access Databases and other data marts to source, extract, and match and modify data to enable reporting efforts', 'Extract and aggregate consumer data as needed for reporting', 'Develop, document, and maintain standards for data storage and retrieval within multiple systems to ensure consistency and integrity of all data used for reporting', 'Create and maintain custom dashboards and/or data sources in Tableau (360Connect)', ""4+ years related work experience or 2 years' experience in an Associate Data Engineer role"", ""Related Bachelor's degree or additional related equivalent work experience"", 'Relevant Development Certifications Proficiency writing SQL queries using Toad or SQL Server applications within db2 or similar environments', 'Experience with Microsoft Office Suite to include Excel, Access, and PowerPoint', 'Experience and understanding with unit testing, release procedures, coding design and documentation protocol as well as change management procedures', 'Strong analytical and problem-solving skills; strong attention to detail', 'Strong Business Acumen', 'Demonstrated organizational, analytical and interpersonal skills; flexible team player GuideWell or general health insurance experience', 'Experience with Tableau version 10.5 or higher, preferred', 'Experience as a SharePoint Site steward']",2020-08-08 13:38:43
Sr. Data Integration Engineer,Fidelity & Guaranty Life,3.2 out of 5,"Des Moines, IA 50309","['Develops Informatica code to support existing and future data/ETL deployments', ""Performance tunes existing and future Informatica code to ensure all SLA's are met"", 'Supports team of onshore and offshore Informatica developers to deliver projects, enhancements and defect remediation', 'Performs relational database analysis, modeling, and design of complex systems', 'Create detailed technical design documents in accordance with business requirements', 'Develop complex programs/queries to support transactional processing and regulatory reporting utilizing SQL and Informatica', 'Develops and perform detailed unit, quality assurance and regression tests to validate the readiness of internal developed code for production', 'Creates detailed deployment plans for use in the migration of code from staging to production environments and provide deployment guides to host provider for deployments', 'Performs impact analysis for interface/system changes affecting applications and data environments', 'Works closely with other IT team members to translate business needs into technical solutions', 'Participates in the development of estimates for project and maintenance work', 'Ensures acceptable levels of system performance, integrity and security', 'Supports standards for system architecture, code quality and collaborative team development', 'Participates in change control discussions, code reviews, and provides technical instruction to colleagues', ""Partners with external TPA's and consultants on large scale development efforts and enforces F&G standards for integration and data exchange"", 'Stays abreast of current technology trends and applies them within the F&G environment', ""Bachelor's degree (preferred emphasis in computer science or MIS) or equivalent combination of education and experience"", 'Expert level experience designing/developing, debugging with Informatica Power Center', 'Expert level experience with optimizing Informatica and SQL jobs through performance tuning', 'Minimum 5 years of experience in supporting ETL, production data operations (File processing, data distribution etc.,) including debugging, addressing production issues and performing Root Cause Analysis', 'Minimum 5 years of experience in designing and building large applications utilizing SQL Server', 'Experience in windows batch scripting', 'Experience with Microsoft SSIS a strong plus', 'Experience with Informatica Data Quality, Business Glossary, and Metadata Manager', 'Experience in processing XML data', 'Experience with database design/modeling tools such as Erwin', 'Experience with the Life/Annuity insurance industry', 'Experience with SQL development tools such as SSMS, SQL Navigator or Toad as well as maintaining code in source code control systems', 'Experience in supporting DTCC and data transfers to/from external organizations and internal systems using secure file transfer protocols such as SFTP', 'Experience working with geographically distributed teams (offshore, offsite, etc.)', 'Experience using job scheduling tools, such as JAMS', 'Experience in creating data marts and other data warehousing practices', 'Knowledge of proper database normalization, indexing, transaction protection and locking is essential', 'Strong technical documentation skills', 'Excellent troubleshooting and problem resolution skills', 'Knowledge of Python and other ETL frameworks is a plus', 'Excellent teamwork and relationship building skills', 'Strong time management and organizational skills', 'Excellent verbal and written communication skills', 'Knowledge of data integrity protocols and security requirements and techniques', 'Strong knowledge of software development life cycle methodologies', 'Must be able to work in a fast-paced team environment and handle multiple projects and assignments under tight deadlines', 'Must demonstrate willingness to work flexible hours as needed to accommodate business needs and deliverables', 'Must be able to sit in front of a computer for extended periods of time']",2020-08-08 13:38:43
Senior Data Warehouse – Business Intelligence Engineer,Electric Insurance Company,3.3 out of 5,"Beverly, MA 01915","['Proficiency in design, develop, test, and deploy of Informatica ETL mappings for data movement between operational systems, ODSs, and Data Warehouses', 'Experience in designing/ building cloud end-to-end data solutions (including ELT, Big Data, relational and non-relational data concepts)', 'Design, develop, test, and deploy data supply change solutions that best serve Business Intelligence analytics and reporting needs', 'Develop fundamental understanding of business function and related production systems', 'Develop and maintain proficiency in a wide range of reporting, data mining, and analytic tools including all those chosen for EIC use', 'Create and maintain engineering and operations documentation for all solutions. Ensure operations personnel have the necessary documentation to provide first and second level incident support', 'Ensure designed systems are highly reliable, self-recovering, and require little or no supporting manpower', 'Consistently deliver according to commitments and project plan dates.', 'Help to establish/ evolve/ adopt programming, data management, Change Management and SDLC processes and standards, including naming conventions, formatting and program structure.', 'Lead design review discussion for technical and non-technical audiences.', 'Lead and/or participate in code reviews', 'Mentor and develop technical competency of junior team members.', 'Perform and/or lead necessary tuning of database and ETL systems and objects to ensure timing and performance goals are met', 'Collaborate with existing and prospective users to define Data Warehousing and Business Intelligence requirements.', 'Identify technical opportunities that offer potential to meet departmental / corporate goals.', 'Self-directed ownership of support and maintenance for ETL and Business Intelligence applications', 'Identify strategic opportunities to grow department vision', 'Must have at least 10 years of Data Warehousing experience', '5+ years of ETL experience (Informatica or SAP preferred)', '1+ years of cloud data tools experience desired', 'Proficient relational database experience. The individual must have an excellent command of SQL.', 'Experience in Business Intelligence tools and architecture – Qlikview preferred', 'Comfortable working with senior level business managers', 'BS in Computer Science or a similar technical discipline', 'Comfortable with scripting languages (Python and PowerShell preferred)', 'Takes ownership of own professional development', 'Establishes and maintains effective relationships with key stakeholders by providing a complete and thorough work product', 'Ability to work independently or as a team member', 'Demonstrates Electric Insurance Core Values']",2020-08-08 13:38:43
Data Engineer,Global Atlantic Financial Group,3.2 out of 5,"Boston, MA","['Design and develop enterprise data / data architecture solutions using Hadoop and other data technologies like Spark, Scala, Python, SQL etc.', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Create and maintain optimal data pipeline architecture.', 'Devise and execute continual improvement initiatives in all Data Management Service delivery and technology, with a focus on delivery velocity and quality.', 'Partner with business leaders to determine and prioritize delivery initiatives.', 'Define or influence system, technical and application architectures for major areas of development.', 'Devise and execute in software development life cycle including requirements gathering, development, testing, release management, and maintenance.', 'Engage with business partners to report (formally and informally) on technology strengths, weaknesses, successes and challenges on a regular basis.', 'Ability to do analytical programming in EDW architecture to bridge the gap between a traditional DB architecture and a Hadoop centric architecture.', 'Highly organized and analytic, capable of solving business problems using technology.', 'Ensure appropriate change management and other technology methodologies are carried out on a consistent basis over time.', 'Should be an individual with in-depth technical knowledge and hands-on experience in the areas of Data Management, BI Architecture, Product Development, RDBMS and non-RDBMS platforms.', 'Should have excellent analytical skills, able to recognize data patterns and troubleshoot the data.', 'Will be responsible for design and delivery of data solutions to empower data migration initiatives, BI initiatives, dashboards development etc.', 'Undergraduate degree required, MBA or other advanced degree preferred.', '3+ years of experience as a member of an information technology team.', 'Minimum of 2 years of relevant experience architecting the complete end to end design of enterprise wide solution using latest technologies – Hadoop, Spring boot/Spring Cloud, Rest API, SQL', 'Minimum of 2 years of professional experience in Python, Core Java, Hortonworks, AWS, Rest API, Microservices, Spring Boot, Spring cloud etc.', 'Experience with data modeling, complex data structures, data processing, and data quality and data lifecycle', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', ""Experience building and optimizing 'big data' data pipelines, architectures and data sets."", 'Experience performing root cause analysis on internal and external data and processes to provide solution for specific business requirements.', 'Experience building solutions for streaming applications.', 'Should be able to lead critical aspects of the data management and application management.', 'Experience in UNIX shell scripting, batch scheduling and version control tools.', 'Experience in large scale server-side application development that includes the design and implementation of high-volume data processing jobs.', 'Cultural awareness with excellent interpersonal and relationship building skills.', 'Passion and drive for continuous improvement and transformational change, with a business owner mentality.', 'Strong written and verbal communication skills.']",2020-08-08 13:38:43
Data Engineer,Vaco,3.7 out of 5,"Oviedo, FL","['Automate ETL process as Data Engineer while extracting, transforming, and loading data from various data sources.', 'Use ETL tools to have robust data profiling, data quality, and data management for building and deploying ETL.', 'Manage data from an database integrated environment.', 'Write T-SQL, DML, and DDL within SQL Server RDBMS environment.', 'Recover, manage, and troubleshoot data from SQL Server environment.', 'Analyze business rules to determine workflow rules automation through workflow automation tools.', 'Provide accurate reporting and present on BI dashboard tools such as Tableau.', 'Work within a data warehouse environment on ETL and reporting functions.', '3+ years of ETL and SQL Server database experience.', 'Strong T-SQL, stored procedure, and query optimization experience.', 'BI reporting experience in Tableau is a plus.', 'Workflow automation tool experience.']",2020-08-08 13:38:43
Senior Data Engineer - Remote,SemanticBits LLC,4.2 out of 5,"Herndon, VA 20171","['Strong knowledge of computer science fundamentals: object-oriented design and programming, data structures, algorithms, databases (SQL and relational design), networking', 'Demonstrable experience engineering scalable data processing pipelines.', 'Demonstrable expertise with Python, Scala, Spark, and wrangling of various data formats - Parquet, CSV, XML, JSON.', 'Experience with the following technologies is highly desirable: Redshift (w/Spectrum), Hadoop, Apache NiFi, Airflow, Apache Kafka, Apache Superset, Flask, Node.js, Express, AWS EMR, Tableau, Looker, Dremio', 'Experience with Agile methodology, using test-driven development.', 'Excellent command of written and spoken EnglishSelf-driven problem solver', 'Candidate must reside in the United States', ""Bachelor's degree in technological or related field and a minimum of 5 years of relevant experience or a Master’s degree with a minimum of 3 years experience"", 'Flexible and willing to accept a change in priorities as necessary', 'Experience working in the healthcare industry', 'Federal Government contracting work experience', 'Prior experience working remotely full-time', 'This position is to be performed remotely from an individual’s home office and involves sedentary work. Employees in this role can be expected to exert up to 10 pounds of force on occasion in order to lift, carry, push, pull or otherwise move standard electronic equipment. Employees are expected to make decisions in a timely manner and display emotional intelligence during occasional stressful situations.']",2020-08-08 13:38:43
Apple Music - Software Data Engineer,Apple,4.2 out of 5,"New York, NY","['Experience in designing, implementing and supporting highly scalable data systems and services in Java and/or Scala', 'Experience with Hadoop-ecosystem technologies in particular MapReduce, Spark / Spark-SQL / Spark Streaming, Hive, YARN/MR2', 'Experience building and running large-scale data pipelines, including distributed messaging such as Kafka, data ingest to/from multiple sources to feed batch and near-realtime/streaming compute components', 'Experience in data-modeling and data-architecture optimized for big data patterns, ie. warehousing concepts; efficient storage and query on HDFS; data security and privacy techniques)', 'Knowledgable about distributed storage and network resources, at the level of hosts, clusters and DCs, to troubleshoot and prevent performance issues', 'Experience with low-latency NoSQL datastores and traditional relational databases is desired']",2020-08-08 13:38:43
"Data Engineer (Enterprise Platform, SQL, APIs)",Capital One,3.9 out of 5,"McLean, VA 22101","['Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 2 years of experience in application development', 'At least 1 years of experience in big data technologies', 'At least 2 years of experience in Structured Query Language (SQL)', 'At least 2 years of experience in relational Database Design, Data Analysis, and Performance Tuning', ""Master's Degree"", '3+ years of experience in application development', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '2+ years of experience in at least one scripting language (Python, Perl, JavaScript, or Shell)', '2+ years of experience with UNIX/Linux including basic commands and shell scripting', '3+ years of experience in Structured Query Language (SQL)', '3+ years of experience in relational Database Design, Data Analysis, and Performance Tuning']",2020-08-08 13:38:43
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:39:29
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:39:29
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:39:29
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:39:29
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:39:29
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:39:29
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:39:29
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:39:29
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:39:29
Staff Data Engineer,Infoblox,3.8 out of 5,"Tacoma, WA 98402","['Curate very large-scale data from a multitude of sources into appropriate sets for research and development for data scientists, threat analysts, and developers across the company.', 'Design, test, and implement storage solutions for various consumers of the data.', 'Design and implement mechanisms to monitor data sources over time for changes using summarization, monitoring, and statistical methods.', 'Leverage computer science algorithms and constructs, including probabilistic data structures, to distill large data into sources of insight and enable future analytics.', 'Convert prototypes into production data engineering solutions through disciplined software engineering practices, Spark optimizations, and modern deployment pipelines.', 'Collaborate on the design, implementation, and deployment of applications with the rest of software engineering.', 'Support data scientists and threat analysts in building, debugging and deploying Spark applications that best leverage data.', 'Build and maintain tools for automation, deployment, monitoring, and operations.', 'Create test plans, test cases, and run tests with automated tools.', '5+ years of experience with Python3, and 2+ years experience with Spark. Scala experience is helpful.', '5+ years of experience in data engineering, data science, and related data-centric fields using large-scale data environments.', '3+ years of experience in using SQL and working with modern relational databases, including MySQL or PostgreSQL', '3+ years of experience with developing ETL pipelines and data manipulation scripts', 'Proficient in Object-Oriented Design and S.O.L.I.D principles.', 'Strong emphasis on unit testing and code quality.', 'Proficient with AWS products (EMR S3, Lambda, VPC, EC2, API Gateway, etc).', 'Very strong Python and PySpark experience.', 'Very strong back end development experience.', 'Strong experience with cloud deployments and CI/CD.', 'Experience with virtualization, containers, and orchestration (Docker, Kubernetes, XEN).', 'Experience with NoSQL Non-Relational databases (AWS DynamoDB).', 'MS or BS in Computer Science or a related field, or equivalent work experience required.', 'Work with a world-class technology team in a rapidly growing company', 'A career path with opportunities to grow', 'Discretionary Paid Time Off policy to promote a healthy work/life balance + world-class benefits', 'Brick & Beam style modern office with state of the art amenities located in the heart of Tacoma, close to transportation and city life', 'Cross-functional break rooms stocked with snacks and beverages', 'And many, many more perks!']",2020-08-08 13:39:29
Data Engineer,Cadent,3.6 out of 5,"Philadelphia, PA 19102",[],2020-08-08 13:39:29
Sr Data Platform Engineer,Spreetail,2.7 out of 5,"Lincoln, NE","['Lead the architecture, maintenance, support, and scalability of the enterprise data platform and supporting systems.', 'Build systems that are well-performing, reliable, and trusted by the business.', 'Keep up-to-date on emerging data technologies and plan for the integration of those technologies into our platform.', 'Build systems/components that make the data engineers more efficient (e.g. CI/CD).', 'Maintain strong and effective relationships with analysts throughout the company, ensuring their analytical needs are supported through data systems and the data systems adapt to new analytical needs.', 'Dig into complicated data designs and systems, optimize performance, and design the technical architecture of data systems.', 'Mentor and lead the team using your data expertise.', 'Provide on-call support for the data platform systems.', 'Decompose complex business processes into workable technical pieces for the data platform engineering team.', 'Build a vision and strategy for the delivery of analytics tools for both internal and potential vendor partner use.', '5-10+ years of experience in data warehouse modeling, design, and development.', '5-10+ years of experience in ETL tools (SSIS, DataStage, Informatica, etc.) and OLAP tools.', 'Highly experienced with SQL development skills (stored procedures, views, functions, etc.).', 'Proficient in data warehouse design philosophies (star vs snowflake schemas, etc.).', 'Passionate with on-premises, hybrid, and cloud-based analytical solutions.', 'Proficient with end-user data integration tools (Power Query, Alteryx, etc.).', 'Proficient with data presentation tools (Power BI, Tableau, QlikView, etc.).', 'Quick to learn and adapt to new technologies.', 'Bring a lot of energy and curiosity while working with many teams across the company.', 'Enthusiastic towards contributing to the vision and strategy of the team and company.', 'Actively give and receive feedback in a manner that drives team success.', 'Maintain a positive attitude so your teammates and colleagues look forward to working with you.', 'Able to effectively and influentially communicate across a variety of business functions.', 'Unit Appreciation Rights: Up to 5% of yearly salary; based upon company and team', 'Company Bonus: Up to 5% of yearly salary; based upon company and team performance', 'Health Insurance: Spreetail will pay for your full premium and half for spouse/family', 'Dental Insurance: Spreetail will pay half of the dental coverage for you/spouse/family', '401k: Spreetail partners with ForUsAll to provide the opportunity to invest in your future with pre-tax and post-tax plan options', 'Paid Time Off: untracked time off', 'Wedding Week: Enjoy an additional 5 paid days off before or after your wedding', 'Gym Membership: Spreetail will pay for half of your membership to a specified gym', 'Creating a Home: After 2 years of employment, Spreetail will give you $5,000 when you', 'Year 3 Vacation: After 3 years of employment, you will be eligible for an all-inclusive', 'Year 5 Sabbatical: After 5 years of employment, you will be eligible for a 2-week paid', 'Donation Matching: Spreetail will match your donation dollar for dollar, up to $250 a', 'Community Involvement: Spreetail encourages employees to take time off for volunteer', 'Product Discount: Enjoy a 20% discount on the products we sell']",2020-08-08 13:39:29
Software Engineer/Data Engineer,BlueVoyant,3.5 out of 5,"College Park, MD 20740","['Strong hands-on programming skills, with expertise in multiple implementation languages/frameworks including a subset of Python, Java, and Scala with delivery background in middleware, and backend implementations.', 'Familiarity with large-scale, big data, and streaming data technologies, as well as exposure to a variety of structured (Postgres, MySQL) and unstructured data sources (Elastic, Kafka, and the Hadoop ecosystem) as implemented at Internet-scale.', 'Experience writing and optimizing streaming and batch analytics.', 'Experience with Agile frameworks, secure software design, test-driven development, and modern, container-delivered code deployment in a cloud-based DevOps environment.', 'BS/BA in Computer Science, Engineering, or relevant field experience.', 'Work closely with analysts to transform threat analytics into production-level code.', 'Actively contribute to application architecture and product vision.', 'Participate in requirements gathering and transformation from prototype to product design.', 'Participate in daily development stand-up meetings and regular sprint planning and product demo meetings.', 'Help us stay current on the latest data processing tools and trends.', 'Thrive in our small, fast-paced, product-driven environment', 'Collaborate with teams from across the organization', 'Deliver features and fixes on tight schedules and under pressure', 'Present ideas in business-friendly and user-friendly language', 'Create systems that are maintainable, flexible and scalable', 'Define and follow a disciplined development and engineering workflow', 'Demonstrate ownership of tasks with escalation as needed', 'Be a subject matter expert in one or more of the technologies employed', 'Relentlessly push for successful customer outcomes', 'Possess a strong interest or background in cyber security', 'Participate in all stages of an agile software development lifecycle, including product ideation, requirements gathering, architecture, design, implementation, testing, documentation, and support', 'Refine our software development methodology based on agile/lean practices with continuous feedback and well-defined metrics to drive improvement', 'Maintain up-to-date knowledge of technology standards, industry trends, emerging technologies, and software development best practices', 'Ensure technical issues are quickly resolved and help implement strategies and solutions to reduce the likelihood of reoccurrence', 'Identify competitive offerings and opportunities for innovation including assessments of risk/reward to the company.', 'Jim Penrose, COO, former EVP at Darktrace with 17 years at the NSA in key leadership roles.', 'Robert Hannigan, Chairman of BlueVoyant International, former Director of GCHQ.', 'Gad Goldstein, President BlueVoyant International and Chairman of BlueVoyant Israel, former division head in the Israel Security Agency, Shin Bet.', ""Austin Berglas, Global Head of Professional Services, former head of the FBI's New York Cyber Branch."", 'Milan Patel, Chief Client Officer, former CTO of the FBI Cyber Division.', 'Ron Feler, Global Head of Threat Intelligence and Operations, former Deputy Commander of Unit 8200, the cybersecurity division of the Israel Defense Forces.', 'Mike Wertheimer, Senior Advisor, former Research Director of NSA', 'Bill Crumm, Senior Advisor, former NSA SIGINT Director and former Cybersecurity Head, Morgan Stanley.', 'Jim Bieda, Senior Advisor, former NSA Deputy CTO.']",2020-08-08 13:39:29
Senior Data Engineer,R&K Solutions,3.8 out of 5,"Roanoke, VA 24017",[],2020-08-08 13:39:29
Data Analyst,"Xyntek, a CXV Global Company",N/A,"Philadelphia, PA 19103","['Location: Newtown, PA', 'Department: Engineering', 'Type: Full Time', 'Min. Experience: Mid Level', 'Collect, interpret and analyze complex data sets for specific business needs;', 'Execute clean reports on data for all levels of the organization;', 'Utilize database experience and create reporting dashboards based on various source systems and spreadsheets;', 'Perform Installations, architectural analysis and oversee implementation of Databases;', 'Design and implement architectural solutions to promote a scalable, robust and manageable database environment that meets business requirements;', 'Suggest and provide process improvement initiatives as it relates to the collection and analyzation of data;', 'Experience using PowerBI and Tableau', 'Bachelors / Master’s degree in Data Analytics, Statistics, Computer Engineering, Computer Science, MIS or related IT degrees;', 'Minimum three (3) years of experience in managing and analyzing data, preferably within the Life Sciences Industry;', 'Proven track record of data management and data processing flowcharting techniques;', 'Strong technical writing, communication, statistical analysis and presentation skills;', 'Experience with Reporting Packages and Statistical Software. Specific experience with PowerBI and/or Tableau required;', 'Ability to present ideas in user-friendly language and solve complex problems;', 'Experience with Labs Instrumentation software and Manufacturing execution systems software a plus;', 'Understanding of working in regulated environments.', 'Pharmaceutical / Biotech', 'Medical Device', 'Healthcare (Hospital IT)', 'Government & Department of Defense (DoD)', 'Competitive compensation and growth tracks;', 'Annual performance-based raises and bonuses;', 'Engineering mentorship programs;', 'Technical & management career growth fast tracks.', ""Health Insurance:100% Company-paid insurance premium for employees;No deductions to the employee's paycheck.Dental Insurance:100% Company-paid insurance premium for employees;No deductions to the employee's paycheck.Vision Insurance:100% Company-paid insurance premium for employees;No deductions to the employee's paycheck.Disability Insurance:Short-Term & Long-Term Disability Insurance for illness or injury to provide security when you need it.Premiums paid by the Company.Life Insurance:Term Life Insurance to ensure your loved ones can maintain financial stability if an unexpected death should occur.Voluntary Term Life Insurance program for employee’s contribution to additional needs in the event of an unexpected death."", '401(k) with company matching;', '401(k) enrollment after one (1) year of full employment;', 'Wealth management and financial services education and resources for participants.', 'Paid Holiday Leave:Paid holidays for full-time employees including New Year’s Day, Memorial Day, Independence Day, Labor Day, Thanksgiving Day & the day after, Christmas Eve Day, and Christmas Day.Paid Vacation Leave:Five (5) days of paid vacation earned for every six (6) months worked for full-time employees.', '100% Company-paid lunches when working in the office. Xyntek orders lunch daily at no cost to the employee;', '100% Company-paid snacks. Xyntek provides in-house snacks (free of charge) to the employees;', '100% Company-paid professional events. Xyntek covers all associated fees and expenses for attendance at professional conferences, workshops, trade shows, and training;', 'Company-sponsored social gatherings & events.']",2020-08-08 13:39:29
Data Engineer,Grid Dynamics,N/A,"Mountain View, CA","['Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation', 'Work closely with data scientists and analysts to create and deploy new features', 'Write efficient and well-organized software to ship products in an iterative, continual-release environment', 'Monitor and plan out core infrastructure enhancements', 'Contribute to and promote good software engineering practices across the team', 'Mentor and educate team members to adopt best practices in writing and maintaining production code', 'Communicate clearly and effectively to technical and non-technical audiences', 'Actively contribute to and re-use community best practices', 'University or advanced degree in engineering, computer science, mathematics, or a related field', 'Strong experience working with a variety of relational SQL and NoSQL databases', 'Strong experience working with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience with at least one cloud provider solution (AWS, GCP, Azure)', 'Strong experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Ability to work in Linux environment', 'Experience working with APIs', 'Strong knowledge of data pipeline and workflow management tools', 'Expertise in standard software engineering methodology, e.g. unit testing, code reviews, design documentation', 'Experience creating ETL processes that prepare data for consumption appropriately', 'Experience in setting up, maintaining and optimizing databases for production usage in reporting, analysis and ML applications', 'Working in a collaborative environment and interacting effectively with technical and non-technical team members equally well', 'Relevant working experience with Docker and Kubernetes preferred', 'Ability to work with ML frameworks preferred', 'Knowledge of CI/CI processes and components', 'Experience with OKTA and Optimizely']",2020-08-08 13:39:29
Data Engineer,SpringML,N/A,"Herndon, VA","['Ability to work as a member of a team assigned to design and implement data integration solutions.', 'Build Data pipelines using standard frameworks in Hadoop, Apache Beam and other open source solutions.', 'Learn quickly – ability to understand and rapidly comprehend new areas – functional and technical – and apply detailed and critical thinking to customer solutions.', 'Propose design solutions and recommend best practices for large scale data analysis', 'B.S. or equivalent degree in computer science, mathematics or other relevant fields.', '5-10 years of experience in ETL, Datawarehouse, Visualization and building data pipelines.', 'Strong Programming skills – experience and expertise in one of the following: Java, Python, Scala, C.', 'Proficient in big data/distributed computing frameworks such as Apache Spark, Kafka,', 'Experience with Agile implementation methodologies.']",2020-08-08 13:39:29
Data Engineer,NTT DATA Services,3.5 out of 5,"Charlotte, NC","['Continually collect, process, and report on data findings', 'Create User Journey mappings and data mappings', 'Work with various internal teams to provide consultation and guidance on Data Engineering problems.', 'Become a Data Steward focused on solutioning across multiple industries', '5+ years of experience as a Data Engineer implementing Data Warehouse and ETL Solutions', '3+ years’ experience in Consulting or advocacy', '3+years working in cloud environments (AWS, Azure or Google Cloud/ GCP)', 'Ability to travel with client demand (up to 50%)', 'Bachelor’s Degree in Computer Sciences, Mathematics, computational finance, engineering or Statistics', '3+ years’ experience with Data Visualization tools (PowerBI or Tableau)', '1+ year in Hadoop ecosystems (HDFS, MapReduce, Hive, Pig, Impala Spark or Kafka)', '1+ year in relational database technologies “RDBMS” including SQL Server & Oracle', '1+ year developing RESTful/ REST Web Services', 'Fluent with modern development workflows', 'Specialized knowledge of the challenges Data Engineers are faced with', 'Keen ability to drive initiatives across multiple domains', 'Ability to present and articulate complex concepts to cross-functional teams.']",2020-08-08 13:39:29
Data Engineer,Airlines Reporting Corporation,3.4 out of 5,"Arlington, VA 22201","['Support data pipeline development by contributing to and or leveraging existing architectural patterns to deliver the optimal product related to data; including but not limited to establishing and communicating design patterns, automation, recovery, and operational run books. Mentor other engineers. Cross functional collaboration and provide overall technical and thought leadership to other teams as needed.', 'Partner with product owners and business SMEs to analyze the business need and provide a supportable and sustainable engineered solution. Ensure that the overall technical solution is aligned with the business needs and adheres to ARC’s Architectural Guiding Principals.', 'Help drive the creation and modifications of the product portfolio components, identify and engage all technical resources necessary to contribute to the solution. Ensure the solution is consistent with ARC architecture, design and development standards.', 'Develop data pipelines using industry best practices. Make adjustments to adopt new methodologies that provide the business with increased flexibility and agility.', 'Stay current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Bachelor’s Degree in Computer Science or related field; or equivalent experience', '3+ years of experience with full cycle application development (Full SDLC experience: design, development, delivery, etc.),', '3+ years with Agile, Scrum, DevOps, and Continuous Integration and Continuous Delivery', '3+ years of experience implementing modern applications using:Cloud Based Solutions/Technologies (AWS, Google, Azure). AWS tech stack including, but not limited to, Lambda, API Gateway, DynamoDB, S3, Cloudwatch, SNS/SQS, Step Functions, FargateImplementation of modern application and infrastructure design patterns, including micro-services and containers, disposable, reactive, stateless and distributed patternsOpen source technologies including, but not limited to, NodeJS, OpenJDK, React, Python and NoSQL, DynamoDB database(s)Familiarity with DevOps tools including, but not limited to, Terraform/Cloud formation, CI/CD pipe line tool like Jenkins, GIT, Jira, Confluence, Jenkins, Sonar, Nexus, automated test and deployment toolsData warehouse platforms (such as Snowflake, and Redshift). Expertise with SQL, database design/structures, ETL/ELT design patterns, and datamart structures (star, snowflake schemas, etc.)Experience w/Data Lake concepts and design patters (AWS S3, parquet, python, lambda, java, NoSQLBI Technologies (such as Tableau, Jasper, Cognos, Qlik, Looker, and others)Understanding of Data Management and Data governance best practices', 'Proven ability to lead a group through an architectural development process and collaborate with stakeholders at all levels', 'Experience leading small technical teams to mentor and guide multiple-disciplined (full stack) technical teams', 'Ability to discover and define functional requirements and to transform them into technical requirements and solutions', 'Ability to influence technology strategy and best practices across peer and leadership groups to support an agile development culture', 'Outstanding communication skills (verbal and written) and ability to communicate with internal and external customers and all levels of management, including communicating technical information to nontechnical audiences', 'A strong intellectual curiosity to continually challenge what exists and explore what should be changed to best meet evolving business and market', 'A strong passion to support peers to help meet timelines on larger projects', 'Joining ARC means joining a team that is motivated, diverse, creative, collaborative and solutions-oriented. We think big, embrace challenges, and explore new ideas to lead the way for the travel industry.', 'Our employees value the hands-on learning and professional development opportunities that allow them to expand their skills and grow their career in new, dynamic ways.', 'We offer a highly competitive, comprehensive benefits package so you can worry less and focus on what truly matters.', 'By joining ARC, you will partner with top minds in the industry as we use data and technology to innovate how the world travels.']",2020-08-08 13:39:29
Data Engineer,eXcell,4 out of 5,"Redmond, WA 98052","['Formulates technical requirements, defines overarching solution architecture, and documents specific tasks for effective, reliable, and GDPR compliant telemetry data infrastructure', 'Defines and guides partner product engineering teams on the technical standards of telemetry data pipeline, ensuring high quality and consistent delivery from the partner teams, and supporting ease of collaboration and consistency across products', 'Maintains a deep understanding of multiple internal and external data platforms, technologies, and techniques on which to build data logging, storage, analysis and modeling solutions, and continues to expand and learn as new capabilities emerge', 'Identifies and effectively documents new, innovative data techniques and standards to expand the capability and value offerings of the Experience Analytics team', 'Regularly reviews with the Experience Analytics Lead on team structure, process, technical approach, and effectiveness, and implements improvements as necessary', 'Collaborate with other teams within the wider org, and externally, on shared data-related objectives and solutions', ""Bachelor's degree in computer science or engineering, database systems, mathematics OR 3+ years of industry experience in a data engineering or data solution architect-focused role"", 'Experience designing, implementing, and deploying data pipelines', 'Relational databases and non-relational database, Cosmos, Azure data lake, SQL', 'Previous experience / knowledge in ADF, Databricks / ADL', 'Object oriented programming, e.g. C#', 'Engineering best practices, e.g. DevOps, GIT', 'Self-motivated with a passion for research, learning, and continuous self-improvement', 'Clear communication and effective collaboration', 'Ability to effectively articulate complex concepts and conclusions to non-experts', 'Prioritize clean, sustainable, engineering practices', 'Project management, collaboration, and organizational skills, guiding product teams to improve data infrastructure', 'Leading or mentoring less experienced engineers or data engineers in partner teams', 'Data Science, machine learning, statistical models, concepts, and application', 'Agile development practices', 'Experience working with product design disciplines']",2020-08-08 13:40:19
"STAFF ENVIRONMENTAL ENGINEER, GEOLOGIST, or ENVIRONMENTAL MICROBIOLOGIST",Equipoise Corporation,N/A,"San Clemente, CA 92673","['Support and collaborate with project staff during site assessment and remediation field tasks', 'Drilling and contractor oversight conducted to evaluate subsurface conditions and install groundwater wells', 'Collect soil, soil vapor, and groundwater samples', 'Design, construct, and operate soil and groundwater remediation systems', 'Data analysis, including preparation and interpretation of maps, tables, and figures', 'Prepare technical reports, plans, specifications, and permits', '0 - 3 years of experience in environmental services / consulting', 'B.S. in either engineering, geology, hydrogeology, or environmental microbiology', 'Team player', 'Growth mindset', 'Strong communication, organization, and writing skills', 'Prior internship experience in environmental consulting or related field', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Paid Time Off', 'Parental Leave', 'Retirement Plan', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', ""Bachelor's (Required)"", 'Multiple locations', 'https://www.equipoisecorp.com', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-08-08 13:40:19
MATERIAL CONTROL SPECIALIST B,Northrop Grumman,4 out of 5,"Baltimore, MD 21240",[],2020-08-08 13:40:19
Junior Manufacturing Engineer,LiveView Technologies,4.4 out of 5,"Orem, UT 84058",[],2020-08-08 13:40:19
Cyber Security Engineer,Internal Data Resources,4.1 out of 5,"Dulles, VA","['3+ years’ experience using Qualys for vulnerability management - conducting authenticated and unauthenticated scanning', '3+ years’ experience with vulnerability remediation for Linux and Windows Systems', 'Hands-on experience with Puppet implementing Unix configurations into Puppet modules', '20+ Years of Proven Industry Experience in 4 major markets', 'Employee Stock Ownership Program', 'Dedicated Engagement Manager who is committed to you and your success', 'Medical, Dental, Vision, and Life Insurance', 'ClearlyRated’s Best of Staffing® Client and Talent Award winner 6 years in a row', '401(k)', 'Dental Insurance', 'Health Insurance', 'Vision Insurance', 'Monday to Friday', 'Puppet: 1 year (Required)', 'Qualys: 1 year (Required)', 'More than 1 year', 'Likely', 'Yes', 'Fully Remote']",2020-08-08 13:40:19
Data Engineer - Talent Pool,Colgate-Palmolive,4.3 out of 5,"New York, NY 10022","['Create and maintain optimal data pipeline architecture,', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Assist with data-related technical issues and support their data infrastructure needs.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'We are looking for a candidate with 0-4 years of experience in a Data Engineer role', 'Bachelor’s degree required, Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field is preferred', 'Working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'They should also have experience using the following software/tools:', 'Experience with relational SQL and NoSQL databases: MongoDB, Neo4j, etc', 'Experience with cloud services: GCP, AWS, etc', 'Experience with object-oriented/object function scripting languages: Python, Java, etc.', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience with Data Flow, Data Pipeline and workflow management tools: Cloud Composer, Airflow, Luigi, etc']",2020-08-08 13:40:19
Data Engineer - Computational Oncology Program,Memorial Sloan-Kettering Cancer Center,4.2 out of 5,"New York, NY 10017","['Manage data from high-throughput next-generation sequencing and imaging', 'Contribute to the design of databases as part of bioinformatics data processing and analysis systems', 'Contribute to front end solutions for visualization of data and analyses', 'Maintain and monitor streaming and batch ETLs operating on structured and unstructured sources', 'Maintain a data lake with hundreds of terabytes of data', 'Develop workflows and integrate systems with REST APIs', 'Compile datasets and verify data consistency', 'Communicate with stakeholders of the data and upon request, conduct data query tracking and resolution', 'Identify inefficiencies and work with software engineers to simplify processes, debug systems and automate routine tasks', 'Able to hold yourself and others accountable in order to achieve goals and live up to commitments', 'A good decision-maker, with proven success at making timely decisions that keep the organization moving forward', 'Able to work effectively in an environment notable for complex, sometimes contradictory information', 'Consistently achieving results, even under tough circumstances', 'Adept at planning and prioritizing work to meet commitments aligned with organizational', 'Adept at building partnerships and working collaboratively with others to meet shared objectives and goals', 'An effective communicator, capable of determining how best to reach different audiences and executing communications based on that understanding', 'Resilient in recovering from setbacks and skilled at finding detours around obstacles', 'Able to operate effectively, even when things are not clear or the way forward is not obvious', 'Adept at learning quickly, applying insights from past efforts to new situation', 'At least 3 years of proven experience, preferably with bioinformatics lab information management systems', 'Bachelor’s Degree in Computer Science, Information Systems, or Database Management (or equivalent experience)', 'Experience designing databases and defining system requirements for data collection', 'Experience in Python, and working with SQL and NoSQL data', 'Experience in Linux systems, and shell scripting', 'Experience in software development life cycle (requirements, design, deployment, testing, etc.)']",2020-08-08 13:40:19
"Technical Support Analyst (Glen Mills, PA)",Shared Services - Buckeye Broadband - Telesystem,3.2 out of 5,"Chadds Ford, PA","['Monitoring the network and customer premised equipment for alarm activity and outages.', 'Providing remote testing and troubleshoot DS1, fiber over Ethernet and SONET facilities.', 'Troubleshoot TCP/IP connectivity issues.', 'Providing DNS, Web, email, voice mail and EFAX support Troubleshoot VOIP-related issues (MGCP & SIP)', 'Identifying and taking appropriate action to correct carrier routing issues (local and long distance).', 'Executing change requests and troubleshoot customer configurations on all supported equipment.', 'Coordinating network repairs by dispatching an appropriate vendor or technician to both central offices as well as customer locations.', 'Supporting equipment including but not limited to Adtran and Netvanta routers and voice gateways, Cisco routers and POE switches, Brocade CER and CES devices, Samsung Ubigate, Cisco Firewall Switch Module, Sophos UTM, Edgewater gateways, Aastra/Mitel, Polycom, and more.', 'Utilizing tools including Metaswitch Windows Explorer, Metaview SAS and EAS service to support dedicated voice and hosted PBX customers.', 'Documenting all customer interaction with effective and clear communication.', 'Providing limited remote training with customers.', 'Using an internal ticketing system to create, update, close, and view customer records.', 'Testing and detecting problems using a variety of methods and approaches. Suggesting appropriate solutions and anticipates problems and helps prevent them.', 'Following and enforcing the Company’s policies and procedures, including the EEO guidelines and safety, at all times;', 'Performing any miscellaneous duties as needed.', 'HS diploma / Equivalent - required', 'Two years’ practical work experience in telecommunications or networking or related field – required', 'Two years working knowledge and troubleshooting experience of SIP, RTP, UDP, TCP, and NAT technologies – required', 'Two years advanced working knowledge, troubleshooting, and configuration experience with Adtran and Cisco equipment and technologies – preferred', 'Two years troubleshooting experience with carriers for access and last mile facilities - preferred', 'Two years working knowledge and troubleshooting experience with premise based firewalls – preferred', 'BA or BS degree with a telecommunications or networking concentration – preferred', 'CCENT, CCNA, or other related certifications - preferred', 'Two years working knowledge, troubleshooting, and configuration experience with Edgewater and Samsung premise based routers and switches, Netvanta routes and voice gateways, Brocade CER and CES devices, Samsung Ubigate, Cisco Firewall Switch Module, Sophos UTM, Aastra/Mitel, Polycom, and more – preferred', 'Two years working knowledge, troubleshooting and configuration experience with Metaswitch and Broadsoft voice technologies – preferred', 'Two years working knowledge of DNS, Web, email, voice mail, and eFax – preferred', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Day shift', 'Night Shift', 'On Call', 'Telecommunications: 2 years (Required)', 'One location']",2020-08-08 13:40:19
Teradata Cloud Engineer,BICP,5 out of 5,"Portland, OR","['Minimum of 3+ years hands-on Teradata expertise including 1 project supporting Teradata Cloud environment.', 'Advanced SQL expertise in addition to strong hands-on BTEQ expertise.', 'Experience building ETL pipelines and working with large data volumes', 'Knowledgeable of data modeling concepts and methodologies (logical, physical, dimensional, canonical)', 'Familiarity with Teradata load utilities (FastLoad, FastExport, TPump, MultiLoad)', 'Experience in Analysis, Design, Development, Implementation, Testing and Support of DW solutions and ETL data pipelines', 'Experience with Lean / Agile development methodologies', 'Prior cloud-based Data Engineering experience', 'Experience with Python, Spark, Hive etc.', 'Familiarity with AWS and Snowflake', 'Strong Communication, articulation, Analytical Skills', 'Desire to work collaboratively with your teammates to come up with the best solution to a problem', 'Ability to work closely with key business partners to identify, troubleshoot and resolve data issues', 'Demonstrated experience and ability to deliver results in a fast-paced, agile environment', 'Excellent problem-solving and interpersonal communication skills', 'Strong desire to learn and share knowledge with others', 'Dental Insurance', 'Health Insurance', 'Vision Insurance', 'Monday to Friday', 'BTEQ: 1 year (Required)', 'SQL: 3 years (Required)', 'Python: 1 year (Preferred)', 'Teradata: 3 years (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'Team-oriented -- cooperative and collaborative', 'People-oriented -- supportive and fairness-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'www.bicp.com', 'Temporarily due to COVID-19']",2020-08-08 13:40:19
Downstream Engineer II,Takeda Pharmaceutical,3.8 out of 5,"Cambridge, MA 02139",[],2020-08-08 13:40:19
Data Engineer,Allstate,3.8 out of 5,"San Francisco, CA",[],2020-08-08 13:40:19
Data Engineer - Senior Level,USAA,3.9 out of 5,"Fair Oaks Ranch, TX 78015",['Qualifications may warrant placement in a different job level*'],2020-08-08 13:40:19
Database Engineer - Junior,Perspecta,3.3 out of 5,"Washington, DC 20022","['Experience with designing, developing and managing enterprise-level databases using relational dabased such as SQL Server or MySQL', 'Experience with Data Warehouse, Data Management Reporting including dashboard development.', 'Experience with ETL tools like MSFT SSIS, Informatica, Pentaho', 'Experience with Business Intelligence tools like Tableau or Power BI', 'Strong understanding of data engineering, structure, formatting, conditioning and analysis.', 'Knowledge of database tools and current data science processes.', 'Full-stack development experience.', 'Experience with improving performance on enterprise applications with large data', 'Experience in Test Driven and Behavior Driven Development frameworks', 'Thorough/Working knowledge of research designs.', 'Thorough/Working knowledge of collection methods, capabilities and tasking process.', 'Intellectual curiosity; creativity and innovation to go beyond current tools to deliver the best solution to complex problems.', 'Strong analytical and critical thinking skills']",2020-08-08 13:40:19
Quality Engineer,Nekoosa Coated Products,3.3 out of 5,"South Plainfield, NJ 07080","['Achieve ‘meets or exceeds expectations’ (3.0 or higher) Halogen Performance Management ratings for all Manage by Objectives (MBO’s) and Key Responsibilities', 'Interface effectively with other functions to maximize success and increase expertise across the entire organization this is measured by annual 360-degree feedback.', 'Actively participate in all safety and wellness programs.', 'Meet or exceed site Quality metric.', 'Drive continuous improvement projects for systemic/trending issues to reduce YOY impact by 15%.', 'Implement and facilitate corrective actions for internal and external customer complaints.', 'Urgently respond to all customer technical and/or quality concerns. New inquiries < 24 hours. Claim closure < 30 days', 'Communicate and manage claim investigation, including providing response timelines expectations, with customers and internal team (BDMs, operations manager and customer service).', 'Inform department managers of all quality non-conformances that was tied to their department, working as necessary to facilitate corrective actions.', 'Authorize, disposition and track MRB material (targeting < 48 hour disposition).', 'Partner with purchasing to facilitate cross-functional investigations regarding supplier complaint resolution.', 'Document and formally report all quality complaints monthly, including current status and steps taken to prevent re-occurrence (customer complaints, material held in impound, supplier claims, project updates, etc.)', 'Develop a robust knowledge of products, applications, and end-use processes.', 'Utilizes knowledge of Operations and end-use application to effectively disposition any non-conformances and speak to customers.', 'Develop and implement a Quality Management System (QMS).', 'Provide the voice of the customer and write control plans for product development, new suppliers and any acquisitions that are supported by the site.', 'Write and implement procedures and process flows for job duties and specifications.', 'Control plans are written and maintained for all products and machines.', 'Engineering degree.', 'Professional, Positive Attitude, Team Worker, Computer Skills – Windows Office Programs (Outlook, Excel, Word), Communication Skills (Verbal/Written), Problem Solver, Organized, Data-driven.', '401(k)', 'Dental Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Monday to Friday', 'Bonus Pay', 'Quality: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Multiple locations', 'www.nekoosa.com', 'Waiting period may apply', 'No']",2020-08-08 13:40:19
Data Scientist,Northrop Grumman,4 out of 5,"McLean, VA 22102",[],2020-08-08 13:40:19
Principal Engineer - Big Data,Indeed,4.3 out of 5,"Austin, TX 78731","['Consult with product teams across Indeed to advise on data platform and data integration best practices', 'Partner with data infrastructure and product teams on the development of prototypes, as well as designs for future integrations.', 'Analyze existing solutions and requirements, perform cost/benefit and scalability analysis, and make recommendations for platform consolidation', 'Collect feedback on current data infrastructure gaps and opportunities for improvement and bring back to Data Infrastructure leadership for prioritization.', 'Provide documentation, training, and consulting for data infrastructure users', 'Provide input and feedback to support continuous improvement in team processes', 'Drive projects and coordinate cross-team efforts in an independent and self-directed way', '10+ years in a Data Engineering or Data Platforms role', '10+ years coding experience (java or python preferred)', '8+ years hands on experience with AWS and big data technologies (Hadoop, Spark, Presto, Kafka, and similar)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of data lake fundamentals and building efficient data pipelines', 'Strong communication, collaboration, and multi-tasking abilities', 'Experience with Agile methodologies', 'View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits']",2020-08-08 13:41:02
Network and Server Engineer,United Medical Center,3.6 out of 5,"Washington, DC 20032","['Configure, test, and maintain various network devices and services (e.g., routers, switches, firewalls, load balancers, VPN, QoS, BGP)', 'Perform network maintenance and system upgrades including service packs, patches, hot fixes and security configurations', 'Monitor performance and ensure system availability and reliability', 'Coordinate the timely deployment of new, updated or enhanced software (including patches, service packs, etc.) to network devices, performing thorough testing, change management request(s), verification, and documentation of suitability.', 'Maximize network performance by monitoring performance; troubleshooting network problems and outages; scheduling upgrades; collaborating with network architects on network optimization.', 'Create and maintain documentation as it relates to network configuration, network mapping, processes, and service records.', 'Provide design, engineering, and technical expertise regarding integration of new and existing technology into IT systems architecture', 'Interface with internal, partner, and third-party teams for configuration, integration and deployment activities and projects', 'Provide Tier-3 support for Windows and Linux based systems and services (e.g., Exchange, AD, DNS, DHCP)', 'Design and develop support tools, infrastructure monitoring capabilities, and automation of deployment/troubleshooting routines', 'Consolidate and aggregate data from disparate systems to provide intelligence that proactively addresses infrastructure capacity and utilization concerns', 'Develop and maintain comprehensive support documentation targeted to multiple operational levels (Tier 1 through 3)', 'Develop script based solutions such as Microsoft PowerShell and VBS scripting languages', 'Implement best practice security measures to protect the confidentiality, integrity and availability of customer data', 'Conduct routine hardware and software audits to ensure compliance with established standards, policies and configuration guidelines', 'Document, schedule, conduct and test system changes in accordance with operational guidelines', 'Manage end-to-end of virtualization environment, capacity planning and performance management, identifying opportunities for quality improvements, automation, and cost savings.', 'Design, Build and migrate solutions to the cloud across the organization working with various teams. Responsible for Automation, Virtual networking/security and access in Cloud Services.', 'Lead efforts to support and integrate our on premise Virtualization, Cloud infrastructure and systems with external cloud as needed. Ensure on premise and off premise workloads work well together. Develop reproducible migration plans for workloads and applications', 'Oversee delivery of all virtual-related projects. Track, report, and resolve issues in a timely manner to ensure delivery of services and projects.', 'Develop and implement the virtual server, virtual storage, virtual networking and virtual backup infrastructure strategy.', 'Support the architecture, preliminary design, analysis, implementation, and operations of the server, storage, and backup infrastructure.', 'Design, re-engineer, implement, manage & develop monitoring tools, such as Solarwinds, WhatsUp GOLD, etc. that will be used to support business decisions for monitoring systems heart rate and capability. Solarwinds expertise is given priority.', 'Setup and utilize tools to discover and monitor a large IT network for potential problems. Problems could include network performance, power, malware intrusion, server faults, bandwidth capacity, storage capacity, server disk utilization, middleware, application performance, as well as memory and processor utilization.', 'Monitor the performance and capacity of network and computer systems using a variety of monitoring tools', 'Ensure the monitoring systems operate efficiently and are kept at the most current stable version/release using vendor-supplied updates and patches. Perform research and testing to verify impact of installing all updates. Coordinates vendor support and ensures positive relationships are maintained.', 'Develop robust reporting performance analysis from various performance reports for internal and external distribution.', 'Proactively identify system deficiencies and assist in root cause analysis of system issues to minimize impact and future occurrence. Escalate issues as warranted.', '3-5 years hands-on work experience in the Networking and server field required', 'Current technical certifications in Network and server fields (e.g., CCNA, CCNP, etc.)', ""Bachelor's degree, ideally in computer systems design or computer science (or equivalent work experience)"", 'Skilled in Microsoft enterprise software and platforms required; valid Microsoft certifications preferred', 'Skilled in VMWare switching and Cisco catalyst hardware; valid VM certifications preferred', 'Skilled in designing, installing, configuring and administering Microsoft Active Directory Services and PowerShell scripting', 'Experience managing Storage Area Networks (LUN creation, zoning and multi-pathing)', 'Experience designing high availability and disaster recovery (COOP) solutions', 'Are you a current or previous United Medical Center employee?', 'No']",2020-08-08 13:41:02
MATERIAL CONTROL SPECIALIST B,Northrop Grumman,4 out of 5,"Baltimore, MD 21240",[],2020-08-08 13:41:02
Cyber Security Engineer,Internal Data Resources,4.1 out of 5,"Dulles, VA","['3+ years’ experience using Qualys for vulnerability management - conducting authenticated and unauthenticated scanning', '3+ years’ experience with vulnerability remediation for Linux and Windows Systems', 'Hands-on experience with Puppet implementing Unix configurations into Puppet modules', '20+ Years of Proven Industry Experience in 4 major markets', 'Employee Stock Ownership Program', 'Dedicated Engagement Manager who is committed to you and your success', 'Medical, Dental, Vision, and Life Insurance', 'ClearlyRated’s Best of Staffing® Client and Talent Award winner 6 years in a row', '401(k)', 'Dental Insurance', 'Health Insurance', 'Vision Insurance', 'Monday to Friday', 'Puppet: 1 year (Required)', 'Qualys: 1 year (Required)', 'More than 1 year', 'Likely', 'Yes', 'Fully Remote']",2020-08-08 13:41:02
Mechanical Engineer,"Critical Process Filtration, Inc.",2.7 out of 5,"Nashua, NH 03060","['Researches and analyzes data such as internal and customer design proposals, specifications, and manuals to determine feasibility of design or application.', 'Designs products or systems such as instruments, controls, machines, and parts for injection moldings.', 'Plans and performs the fabrication of test control apparatus and equipment, and development of methods and procedures for testing products or systems.', 'Coordinates and performs fabrication and installation activities to ensure products and systems conform to engineering design and customer specifications.', 'Coordinates and performs operation, maintenance, and repair activities to obtain optimum utilization of machines and equipment.', 'Designs products and systems to interface machines, hardware, and software.', 'Recommends design modifications to eliminate machine or system malfunctions.', 'Bachelor’s degree in related field with 2 + years of experience.', 'Experience in a Manufacturing setting preferred.', 'Knowledge of plastics and injection moldings preferred.', 'Strong attention to detail.', 'Ability to understand and apply work methods that drive accuracy and speed.', 'Generates suggestions for improving work; Develops innovative approaches and ideas.', 'Establish and maintain cooperative and effective working relationships with team members.', 'Work independently with little supervision.', 'Ability to lift and/or carry up to 50 lbs.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Referral Program', 'Retirement Plan', 'Vision Insurance', '8 Hour Shift', 'Monday to Friday', 'Plastics Injection Molding: 2 years (Preferred)', 'Manufacturing: 2 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', 'https://www.criticalprocess.com/', 'Only full-time employees eligible', 'No']",2020-08-08 13:41:02
"Technical Support Analyst (Glen Mills, PA)",Shared Services - Buckeye Broadband - Telesystem,3.2 out of 5,"Chadds Ford, PA","['Monitoring the network and customer premised equipment for alarm activity and outages.', 'Providing remote testing and troubleshoot DS1, fiber over Ethernet and SONET facilities.', 'Troubleshoot TCP/IP connectivity issues.', 'Providing DNS, Web, email, voice mail and EFAX support Troubleshoot VOIP-related issues (MGCP & SIP)', 'Identifying and taking appropriate action to correct carrier routing issues (local and long distance).', 'Executing change requests and troubleshoot customer configurations on all supported equipment.', 'Coordinating network repairs by dispatching an appropriate vendor or technician to both central offices as well as customer locations.', 'Supporting equipment including but not limited to Adtran and Netvanta routers and voice gateways, Cisco routers and POE switches, Brocade CER and CES devices, Samsung Ubigate, Cisco Firewall Switch Module, Sophos UTM, Edgewater gateways, Aastra/Mitel, Polycom, and more.', 'Utilizing tools including Metaswitch Windows Explorer, Metaview SAS and EAS service to support dedicated voice and hosted PBX customers.', 'Documenting all customer interaction with effective and clear communication.', 'Providing limited remote training with customers.', 'Using an internal ticketing system to create, update, close, and view customer records.', 'Testing and detecting problems using a variety of methods and approaches. Suggesting appropriate solutions and anticipates problems and helps prevent them.', 'Following and enforcing the Company’s policies and procedures, including the EEO guidelines and safety, at all times;', 'Performing any miscellaneous duties as needed.', 'HS diploma / Equivalent - required', 'Two years’ practical work experience in telecommunications or networking or related field – required', 'Two years working knowledge and troubleshooting experience of SIP, RTP, UDP, TCP, and NAT technologies – required', 'Two years advanced working knowledge, troubleshooting, and configuration experience with Adtran and Cisco equipment and technologies – preferred', 'Two years troubleshooting experience with carriers for access and last mile facilities - preferred', 'Two years working knowledge and troubleshooting experience with premise based firewalls – preferred', 'BA or BS degree with a telecommunications or networking concentration – preferred', 'CCENT, CCNA, or other related certifications - preferred', 'Two years working knowledge, troubleshooting, and configuration experience with Edgewater and Samsung premise based routers and switches, Netvanta routes and voice gateways, Brocade CER and CES devices, Samsung Ubigate, Cisco Firewall Switch Module, Sophos UTM, Aastra/Mitel, Polycom, and more – preferred', 'Two years working knowledge, troubleshooting and configuration experience with Metaswitch and Broadsoft voice technologies – preferred', 'Two years working knowledge of DNS, Web, email, voice mail, and eFax – preferred', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', 'Day shift', 'Night Shift', 'On Call', 'Telecommunications: 2 years (Required)', 'One location']",2020-08-08 13:41:02
Database Engineer - Junior,Perspecta,3.3 out of 5,"Washington, DC 20022","['Experience with designing, developing and managing enterprise-level databases using relational dabased such as SQL Server or MySQL', 'Experience with Data Warehouse, Data Management Reporting including dashboard development.', 'Experience with ETL tools like MSFT SSIS, Informatica, Pentaho', 'Experience with Business Intelligence tools like Tableau or Power BI', 'Strong understanding of data engineering, structure, formatting, conditioning and analysis.', 'Knowledge of database tools and current data science processes.', 'Full-stack development experience.', 'Experience with improving performance on enterprise applications with large data', 'Experience in Test Driven and Behavior Driven Development frameworks', 'Thorough/Working knowledge of research designs.', 'Thorough/Working knowledge of collection methods, capabilities and tasking process.', 'Intellectual curiosity; creativity and innovation to go beyond current tools to deliver the best solution to complex problems.', 'Strong analytical and critical thinking skills']",2020-08-08 13:41:02
Quality Engineer,Nekoosa Coated Products,3.3 out of 5,"South Plainfield, NJ 07080","['Achieve ‘meets or exceeds expectations’ (3.0 or higher) Halogen Performance Management ratings for all Manage by Objectives (MBO’s) and Key Responsibilities', 'Interface effectively with other functions to maximize success and increase expertise across the entire organization this is measured by annual 360-degree feedback.', 'Actively participate in all safety and wellness programs.', 'Meet or exceed site Quality metric.', 'Drive continuous improvement projects for systemic/trending issues to reduce YOY impact by 15%.', 'Implement and facilitate corrective actions for internal and external customer complaints.', 'Urgently respond to all customer technical and/or quality concerns. New inquiries < 24 hours. Claim closure < 30 days', 'Communicate and manage claim investigation, including providing response timelines expectations, with customers and internal team (BDMs, operations manager and customer service).', 'Inform department managers of all quality non-conformances that was tied to their department, working as necessary to facilitate corrective actions.', 'Authorize, disposition and track MRB material (targeting < 48 hour disposition).', 'Partner with purchasing to facilitate cross-functional investigations regarding supplier complaint resolution.', 'Document and formally report all quality complaints monthly, including current status and steps taken to prevent re-occurrence (customer complaints, material held in impound, supplier claims, project updates, etc.)', 'Develop a robust knowledge of products, applications, and end-use processes.', 'Utilizes knowledge of Operations and end-use application to effectively disposition any non-conformances and speak to customers.', 'Develop and implement a Quality Management System (QMS).', 'Provide the voice of the customer and write control plans for product development, new suppliers and any acquisitions that are supported by the site.', 'Write and implement procedures and process flows for job duties and specifications.', 'Control plans are written and maintained for all products and machines.', 'Engineering degree.', 'Professional, Positive Attitude, Team Worker, Computer Skills – Windows Office Programs (Outlook, Excel, Word), Communication Skills (Verbal/Written), Problem Solver, Organized, Data-driven.', '401(k)', 'Dental Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Monday to Friday', 'Bonus Pay', 'Quality: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Multiple locations', 'www.nekoosa.com', 'Waiting period may apply', 'No']",2020-08-08 13:41:02
"STAFF ENVIRONMENTAL ENGINEER, GEOLOGIST, or ENVIRONMENTAL MICROBIOLOGIST",Equipoise Corporation,N/A,"San Clemente, CA 92673","['Support and collaborate with project staff during site assessment and remediation field tasks', 'Drilling and contractor oversight conducted to evaluate subsurface conditions and install groundwater wells', 'Collect soil, soil vapor, and groundwater samples', 'Design, construct, and operate soil and groundwater remediation systems', 'Data analysis, including preparation and interpretation of maps, tables, and figures', 'Prepare technical reports, plans, specifications, and permits', '0 - 3 years of experience in environmental services / consulting', 'B.S. in either engineering, geology, hydrogeology, or environmental microbiology', 'Team player', 'Growth mindset', 'Strong communication, organization, and writing skills', 'Prior internship experience in environmental consulting or related field', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Paid Time Off', 'Parental Leave', 'Retirement Plan', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', ""Bachelor's (Required)"", 'Multiple locations', 'https://www.equipoisecorp.com', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-08-08 13:41:02
Junior Manufacturing Engineer,LiveView Technologies,4.4 out of 5,"Orem, UT 84058",[],2020-08-08 13:41:02
Data Analyst,Amida Technology Solutions,N/A,"Washington, DC 20006","['Prepare and conduct analyses and studies, needs assessment, and requirements analysis to align systems and solutions', 'Apply analytical methodologies and principles to meet client needs.', 'Prepare forecast and analyze trends, develops and analyze metrics, and prepares reports and recommendations.', 'You will also be responsible for focusing on business performance, project analysis, internal control, risk assessment, and support of project objectives.', 'B.S. and/or M.S. in a quantitative field such as Computer Science, Statistics, or Mathematics', 'Minimum 4 years of recent professional experience in data science, data mining, data analysis, business process analysis, and/or healthcare analytics', 'Minimum 3 years of experience in data mapping and data profiling', 'Minimum 3 years of experience using SQL to evaluate data (preferred MSSQL)', 'Minimum 2 years of programming experience in a subset of Python (at least Jupyter Notebooks, sqlalchemy, and pandas)', 'Prior experience working with Healthcare data, or in the Healthcare field', 'Ability to conduct data profiling and predictive analysis using a variety of standard tools', 'Familiarity with Machine Learning and/or Natural Language Processing (particular Named Entity Recognition) methodologies', 'Experience with data visualization tools and methodologies', 'Ability to communicate concisely and effectively with software engineers and clients', 'Ability to obtain a Public Trust security clearance', 'Exposure to Amazon Web Services (AWS) and cloud-based systems', 'Previous experience working with government clients such as Dept. of Defense (DoD) or Dept. of Veterans Affairs (VA)', 'Prior experience with metadata management to include meta-tagging', 'Previous experience working in an Agile Team setting and using Agile management tools such as Jira', 'Experience conducting business process analysis to identify gaps and inefficiencies', 'Ability to uncover data-driven insights using statistical analysis or predictive analytics', 'Experience with machine learning, natural language, and statistical analysis methods to include classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and/or validation methods', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Employee Discount', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Night Shift', 'Data Mining: 2 years (Preferred)', 'Python: 2 years (Required)', 'Data Analysis: 2 years (Required)', ""Bachelor's (Required)"", 'Washington, DC 20006 (Required)', 'United States (Required)', 'Bonuses', 'www.amida.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:41:02
Data Scientist,Amida Technology Solutions,N/A,"Washington, DC 20006","['Prepare and conduct analyses and studies, needs assessment, and requirements analysis to align systems and solutions', 'Apply analytical methodologies and principles to meet client needs.', 'Prepare forecast and analyze trends, develops and analyze metrics, and prepares reports and recommendations.', 'Implement NLP models for extracting medical information from unstructured notes.', 'You will also be responsible for focusing on business performance, project analysis, internal control, risk assessment, and support of project objectives.', 'M.S. and/or PhD in a quantitative field such as Computer Science, Statistics, or Mathematics (or related)', '8+ years of recent professional experience in data science, data mining, data analysis, business process analysis, and/or healthcare analytics', '3+ years of experience using SQL to evaluate data', '5+ years working with Machine Learning and/or Natural Language Processing (particular Named Entity Recognition) methodologies', '5+ years of programming experience in a subset of Python', 'Prior experience working with Healthcare data, or in the Healthcare field', 'Ability to conduct data profiling and predictive analysis using a variety of standard tools', 'Experience with data visualization tools and methodologies', 'Excellent ability to communicate concisely and effectively with software engineers and clients', 'Ability to obtain a Public Trust security clearance', 'Exposure to Amazon Web Services (AWS) and cloud-based systems', 'Previous experience working with government clients such as Dept. of Defense (DoD) or Dept. of Veterans Affairs (VA)', 'Prior experience with metadata management to include meta-tagging', 'Previous experience working in an Agile Team setting and using Agile management tools such as Jira', 'Experience conducting business process analysis to identify gaps and inefficiencies', 'Ability to uncover data-driven insights using statistical analysis or predictive analytics', 'Experience with machine learning, natural language, and statistical analysis methods to include classification, collaborative filtering, association rules, sentiment analysis, topic modeling, time-series analysis, regression, statistical inference, and/or validation methods', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Employee Assistance Program', 'Employee Discount', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', 'Data Mining: 5 years (Preferred)', 'Python: 4 years (Required)', 'NLP: 5 years (Preferred)', 'Data Analysis: 5 years (Required)', ""Bachelor's (Required)"", 'Washington, DC 20006 (Required)', 'United States (Required)', 'Bonuses', 'www.amida.com', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:41:02
Site Reliability Engineer,Genoa Telepsychiatry,N/A,"New York, NY 10010","['Ensure 99.999% uptime for all of our production applications and services', 'Build performance monitors and alerts designed to manage SLAs and minimize outage incidents', 'Maintain, tune, troubleshoot and continuously improve operation of application infrastructure, monitoring and code pipelines', 'Lead the response of any uptime issues by bringing together various teams and stakeholders, and provide robust communication and visibility to the organization during such incidents', 'Create a culture of always-on services by working with Software Engineering teams to evaluate, provision, and support the delivery of application infrastructure', 'Work with development teams to coordinate and automate software deployments, common system operational and maintenance tasks', 'Optimize our deployment footprint/system architecture to increase the cost efficiency of supporting our systems', 'Plan and execute data security protocols, including component security/deprecation/lifespan of CI/CD pipeline and backup/disaster recovery', 'Provide Root Cause Analysis for failures', 'Ensure system architecture and deployment is well-documented', 'Bachelor’s degree in computer science, engineering or a similar field of study, or equivalent experience', 'Demonstrated expertise deploying, maintaining and monitoring in a public cloud environment', 'Proficient with one or more non-bash scripting languages like Python, Ruby, Go, etc.', '2+ years working professionally with IT operational automation and configuration management tools and DevOps practices, processes and tools (Git, CICD, etc.).', '2+ years of experience implementing infrastructure monitoring, application monitoring and telemetry systems.', '2+ years of experience packaging, deploying and managing containerized workloads running in common PaaS solutions (i.e. Docker, Kubernetes)', 'Demonstrated intellectual curiosity and pursuit of continued learning', 'Willingness to learn about Genoa Telepsychiatry’s business model and be a champion of telepsychiatry', 'Individuals with a desire to work at a fast-growing health-tech company. A passion for working in healthcare', 'AWS Certified DevOps Engineer, Docker Certified Associate, or similar professional certifications', 'Bonuses', 'Other forms', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Paid time off', 'Work from home', 'Flexible schedule', 'Parental leave', 'Tuition reimbursement', 'Monday to Friday', 'http://genoatelepsychiatry.com/', 'Temporarily due to COVID-19']",2020-08-08 13:41:02
Downstream Engineer II,Takeda Pharmaceutical,3.8 out of 5,"Cambridge, MA 02139",[],2020-08-08 13:41:02
Quality Engineer,Matsuo Industries USA Inc,3.5 out of 5,"Jefferson Cty, TN 37760","['401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Tuition Reimbursement', 'Vision Insurance', '10 Hour Shift', 'Monday to Friday', 'Quality Engineer: 3 years (Required)', 'One location', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Autonomous/Independent -- enjoys working with little direction', 'High stress tolerance -- thrives in a high-pressure environment', 'Waiting period may apply', 'No']",2020-08-08 13:41:02
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:41:47
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:41:47
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:41:47
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:41:47
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:41:47
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:41:47
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:41:47
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:41:47
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:41:47
Data Engineer - Brand Program,Amazon.com Services LLC,3.6 out of 5,"Tempe, AZ","[""Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline"", '3~6 years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets', 'Demonstrated strength in data modeling, ETL development, and data warehousing', 'Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, Elastic Search, etc.)', 'Experience using business intelligence reporting tools (Tableau, Business Objects, Cognos, etc.)', 'Knowledge of data management fundamentals and data storage principles', 'Knowledge of distributed systems as it pertains to data storage and computing', 'Experience working with AWS big data technologies (Redshift, S3)', 'Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', 'Experience providing technical leadership and mentoring other engineers for best practices on data engineering', 'Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations']",2020-08-08 13:41:47
Analytics Data Engineer,Unsupervised,N/A,"Boulder, CO 80301","['Be comfortable in Python', 'Have solid computer science fundamentals, with strong competencies in data structures, algorithms, and software design/architecture', 'Have used different storage formats like Parquet, Avro, and Feather (some, not all)', 'Have used different database paradigms (document, relational, graph, etc.)', 'Have written code processing large datasets', 'Developed distributed software', 'Worked with machine learning', 'Know who Edgar Codd is', 'Developed database components such as query engines, storage engines, etc.', 'Consider performance implications and limitations of code', 'Great health vision, and dental care', 'Competitive compensation', '401K match', 'Unlimited vacation']",2020-08-08 13:41:47
Data Engineer,Entera,N/A,"New York, NY","['Use Python, SQL, and R to improve upon a best-in-class data pipeline and develop our workflows', 'Contribute to cloud-first services that improve our reporting, analysis, and metrics collection efforts', 'Use agile software development processes to iteratively make improvements to our back-end systems', 'Mold front-end and back-end data sources to help draw a more comprehensive picture of user flows throughout our system', 'Deliver on detailed specifications for business intelligence and reporting needs', 'Contribute and further develop our data-driven culture', 'Work with product and engineering in cross-functional teams to deliver on improvements to our systems', 'MS or PhD in Computer Science, Mathematics, Statistics, Physics, Economics, or similar hard-science', '3+ years hands-on experience in Data + Analytics at growing product-driven tech companies', 'Proficiency in cloud services and modern ETL workflows', 'Advanced capabilities across Python, R, and SQL', 'Understanding of Spark', 'Strong analytical and problem solving skills', 'Working knowledge of Python web frameworks like Flask', 'Software development background']",2020-08-08 13:41:47
"Conversion, Associate Engineer Mechanical",Northrop Grumman,4 out of 5,"Northridge, CA","['Performs a variety of duties in the electronic, mechanical, electromechanical, or optical areas.', 'Constructs, troubleshoots, calibrates, adjusts, tests, and maintains equipment, components, devices, or systems.', 'Works from engineering drawings and written or verbal instructions. Operates related equipment; conducts tests and reports data in prescribed format.', 'Performs calibration and alignment checks; makes adjustments, modifications, and replacements as directed; prepares prescribed compounds and solutions. Exclude technicians working in Production or Quality Assurance']",2020-08-08 13:41:47
Data Engineer,Vinli,N/A,"Dallas, TX 75201","['Lead data architect for the Vinli analytics team.', 'Integrate multiple data sources and software tools within the Vinli analytics ecosystem.', 'Collaborate with tech leaders across Vinli to ensure data strategy continuously meets all needs both internal and for Vinli customer.', 'Create and deliver executive presentations explaining the complex data in simple easy-to-understand terms that resonates with an executive audience.', 'BS in a STEM field.', 'Advanced design, coding and analytics skills in a big data ecosystem.', 'Expert knowledge of SQL.', 'Experience with other languages such as Python, R, PySpark, Java or Scala.', 'Strong background of data structures and big data tools (Spark, Hive, HDFS, ect.).', 'Data wrangling and ETL tooling experience.', 'Exceptional communication skills between both business and technical teams.', 'MS or higher in a STEM field.', 'Experience managing teams or projects.', 'Demonstrated experience with AWS, GCP or Azure.', 'Experience handling confidential and sensitive data.', 'Demonstrated ability to independently influence and drive outputs, meet deadlines, and set clear expectations and roadmaps.', 'Able to work in a fast-moving environment with high stakes for the company’s success', 'You take pride and responsibility seeing the product you worked on meet the real world for the first time', 'You love to learn and embrace the opportunity to contribute in new areas.']",2020-08-08 13:41:47
Senior Data Engineer (Data ELT/ETL Engineer),Safelite Group Inc,3.4 out of 5,"Columbus, OH 43235","['Migrate data and tools (modernize) from on premise to Cloud technologies', 'Design and create data models/semantic layers', 'Design, develop, automate, monitor and maintain ELT applications using Safelite preferred tools and techniques', 'Performance tune ELT to manage high volume batch data transfer to and from internal and external system locations', 'Recommend solutions and lead team through the process', 'Interact with cross-functional teams, project managers and agile teams to estimate development efforts and ensure complete delivery of solutions and accurate requirement fulfillment', 'Influence the business and leadership on processes and procedures that will drive value within the business and across the technical landscape', 'Communicate effectively and efficiently both written and verbally', ""Bachelor's Degree (BA/BS/BFA) or Equivalent"", '7-10 years related work experience', 'Experience with AWS technologies with, preferably, Snowflake as the backend', 'Extensive experience with delivery using ELT tools and techniques (i.e., Informatica, DataStage, SSIS, Talend, etc)', 'Expert understanding of data warehouse and master data management approaches, ELT industry standards and best practices', 'Experience building Data Vault and/or Star Schema models', 'Experience with BI reporting tools a plus such as Tableau or Looker', 'Possess strong communication skills and the ability to work with technical teams and business teams']",2020-08-08 13:41:47
Software Engineer,Dimagi,N/A,Massachusetts,"['Build new features using modern best-practices such as version control, continuous integration, automated tests, and daily deploys', 'Collaborate with our multicultural development and implementation teams around the globe', 'Build software usable by groups of people facing unique challenges (remote locations, low levels of literacy, no experience with technology, etc.)', 'Participate in agile process, code reviews, and release testing', 'Comfortable developing enterprise-quality software in a high-level language such as Python or Ruby', 'Background in building software for the web', 'Fluency in written and spoken English', 'Ability to quickly learn development technologies (Python, Django, Postgres, CouchDB, Elasticsearch, Javascript, and HTML)', 'Excellent verbal and written communication skills', 'Strong analytical skills and desire to write clean, correct, and efficient code', 'Authorized to work in South Africa', 'Familiarity with some components of our tech stack. We use Python, Django, Postgres, CouchDB, Elasticsearch, Javascript, and HTML.', 'Enthusiasm about working in public health and international development']",2020-08-08 13:41:47
HADOOP DATA ENGINEER,Emids Technologies Pvt. Ltd.,3.9 out of 5,"Hartford, CT","['Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.', 'Collaborates with other data teams to transform data and integrate algorithms and models into automated processes.', 'Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines.', 'Builds data marts and data models to support Data Science and other internal customers.', 'Analyzes current information technology environments to identify and assess critical capabilities and recommend solutions.', 'Experiments with available tools and advises on new tools in order to determine optimal solution given the requirements dictated by the model/use cases', '3 or more years of progressively complex related experience.', 'Has strong knowledge of large scale search applications and building high volume data pipelines.', 'Experience building data transformation and processing solutions.', 'Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.', 'Ability to understand complex systems and solve challenging analytical problems.', 'Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.', 'Strong collaboration and communication skills within and across teams.', 'Strong problem solving skills and critical thinking ability.', 'Hive', 'Shell Script', 'Unix', 'Hadoop Concepts (Sqoop, YARN, MapReduce ,etc.)', 'Python']",2020-08-08 13:41:47
Engineer I,IR.Tools,N/A,"Crofton, MD 21114","['Bachelor’s degree in Mechanical or Industrial engineering or other related field required. Students close to graduation may be considered.*', 'Intermediate computer skills*', 'Proven trustworthiness and honesty*', 'Flexible and team player*', 'Design custom products according to customer requirements*', 'Create drawings of new products*', 'Maintain and improves quality results by completing quality assurance tests*', 'Ensures the operations of the production equipment by performing routine preventive maintenance and coordination repair services*', 'Prepares engineering reports by collecting, analyzing & summarizing data*', 'Supports the evaluation and development of new manufacturing processes*', 'Assist the Engineering Manager in achieving corporate goals*', 'Capable of using spreadsheet, word processing, illustrator and standard office software*', 'Ability to communicate effectively & efficiently, both written and verbally*', 'Basic knowledge of AutoCAD*', 'Possess effective organizational and multitasking skills*', 'Organized, attention to detail, sound problem solving skills and general computer knowledge*', 'Physical demands: While performing the duties of this job, the employee is required to accurately see a color, lift packages routinely up to 15 lbs, use hands, see, walk, talk or hear.', 'Work environment: While performing the duties of this job, the noise level in the work environment is usually minimal to moderate and it may be cooler than usual.', 'Monday to Friday', 'mechanical engineering: 1 year (Preferred)', 'High school or equivalent (Preferred)', 'United States (Preferred)', 'One location', 'https://irtools.bamboohr.com/jobs/view.php?id=4&source=aWQ9Mg%3D%3D', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:41:47
Power & Performance Data Engineer,Apple,4.2 out of 5,"San Diego, CA","['Excellent programming skills in C, C++, Python or Java', 'Prior experience developing production software', '2 years minimum experience with Linux system administration and command line tools', 'Strong analytical thinking', 'Self-motivated and able to work independently', 'Excellent spoken and written communication skills']",2020-08-08 13:41:47
Manufacturing Engineer,"Schenker, Inc.",3.4 out of 5,"Carlisle, PA 17013","['Tips', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Monday to Friday']",2020-08-08 13:42:36
Data Engineer,BOEING,4 out of 5,"Herndon, VA 20192","['Work with a teammate on data integration requirements.', 'Write code on ETL platform to transform data to a suitable formats as defined by IC ITE initiatives.', 'Add features to ETL platform to shorten timelines for future data integration efforts.', 'Develop, maintain code, and integrate software into a fully functional software system.', 'Participate in daily scum meetings, sprint retrospectives, and other agile processes.', 'Work with external teams to validate data ingest.', 'Provide and maintain documentation of system architecture, development, and enhancements.', ""Bachelor’s Degree and 6 or more years’ experience or Master's Degree with 3 or more years' experience from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry."", '6+ years of software development experience', 'Linux/Unix experience', 'Object Oriented programming language', 'Possess strong verbal and written communication skills', 'Possess strong analytical skills, with excellent problem solving abilities in the face of ambiguity', 'Expertise in data ingestion, data transformation (ETL), and data modeling.', 'Experience with Java, Ruby, or Python', 'Experience in Agile/SCRUM enterprise-scale software development', '3 years’ experience working with one of the following batch-processing and tools (eg, Nifi, Midpoint, MapReduce, Yarn, Pig, Hive, HDFS, Oozie)', '1 year working with Restful web services', 'Experience with code development, deployment, versioning, and build tools (eg, Eclipse, git, svn, maven, Jenkins)']",2020-08-08 13:42:36
Machine Learning Engineer,Triplebyte,5 out of 5,"New York, NY","['Psychometrics', 'Recommender systems', 'Time series analysis', 'Survival analysis', 'Bayesian inference', 'Probabilistic programming', ""Robust exploratory/experimental skills. We have a novel dataset of candidate profiles and interview outcomes from our candidate screening process and our hiring marketplace. You'll be responsible for designing and evaluating experiments to predict downstream outcomes."", 'Ability to implement models from research. Some of our best improvements in both speed and predictiveness has come from doing literature surveys and implementing novel techniques from research papers.', ""Engineering skills. This is a hybrid research/engineering role. You'll be responsible for productionizing your pipelines/models and integrating against our back-end services."", '401(k)', 'Dental Insurance', 'Disability Insurance', 'Flexible Schedule', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Parental Leave', 'Professional Development Assistance', 'Referral Program', 'Relocation Assistance', 'Retirement Plan', 'Vision Insurance', 'Monday to Friday', 'Fully Remote', 'Yes: H-1B work authorization', 'Yes: Immigrant visa sponsorship (e.g., green card sponsorship)', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'A job for which military experienced candidates are encouraged to apply', 'Open to applicants under 18 years old, provided it is legally allowed for the job and location', 'Open to applicants who do not have a high school diploma/GED', 'A good fit for applicants with gaps in their resume, or who have been out of the workforce for the past 6 months or more', 'A good job for someone just entering the workforce or returning to the workforce with limited experience and education', 'A job for which all ages, including older job seekers, are encouraged to apply', 'Open to applicants who do not have a college diploma', 'https://triplebyte.com/', 'https://triplebyte.com/company/public/facebook', 'Only full-time employees eligible', 'Yes']",2020-08-08 13:42:36
Data Management Engineer,Strategic Employment Partners,5 out of 5,"New York, NY 10017","['Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'One location', 'No: Not providing sponsorship for this job', 'Dependable -- more reliable than spontaneous', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Temporarily due to COVID-19']",2020-08-08 13:42:36
Software Engineer - Entry to Experienced Level (Multiple Locations,National Security Agency,4.2 out of 5,"Fort Gordon, GA",[],2020-08-08 13:42:36
Software Engineer Intern,"Darwin Global, LLC",N/A,"Oklahoma City, OK 73112","['Participates in Release and Iteration Planning meetings with testers, engineers, and users.', 'Employs organizational design patterns to develop application logic.', 'Pairs with other engineers to solve complex problems.', 'Designs Unit Tests as part of Test-Driven Development.', 'Participates in the design and development of Object-Oriented software solutions.', 'Analyzes users’ needs, and designs, creates, and modifies general computer applications software or specialized utility programs.', 'Develops/analyzes algorithms that solve programmatic problems.', 'Employs software configuration management tools (e.g., Mercurial, GIT).', 'Develops and deploys web applications based on MVC4 and 5 as well as Windows client applications.', 'Develops and deploys solutions based on SOAP and RESTful webservices.', 'Applies skills in one or more object-oriented languages: C#, C++, VB .Net, VBScript, JavaScript, and Java.', 'Designs and implements maintainable and scalable database schemes.', 'Tests and coordinates changes to databases.', 'Queries and manipulates relational data using Structured Query Language (SQL).', 'Assists in planning and coordinating security measures.', 'Solves technical problems pertaining to database design, internet-based application development, and multimedia-based training delivery.', 'Performs any and all other duties, as assigned.', 'Performs any and all other duties, as assigned.', 'The practical application of engineering science and technology. This includes applying principles, techniques, procedures, and equipment to the design and production of various products and services.', 'Must have the ability to learn Microsoft Word and Excel;', 'Must have the ability to learn Google Docs, Sheets, and Slides;', 'Must have the ability to learn Mercurial and MS SQL Server.', 'C#', 'HTML', 'ECMA JavaScript', 'Microsoft Structured Query Language (SQL)', 'VB.net', 'VBScript', 'Mercurial', 'Java', 'Selenium', 'Gives full attention to what other people are saying, takes time to understand the points being made, asks questions as appropriate, does not interrupt at inappropriate times, and conveys awareness.', 'Interacts in a positive way with persons of various social, cultural, economic, and educational backgrounds.', 'Builds constructive working relationships with clients/customers, other work units, community organizations and others to meet mutual goals and objectives; behaves professionally and supportively when working with individuals from a variety of ethnic, social, and educational backgrounds.', 'To perform this job successfully, an employee should have the following work-related competencies:', 'Participates as an active and contributing member of a team to achieve team goals; works cooperatively with other team members, involves others, shares information as appropriate, and shares credit for team accomplishments.', 'Monitors and checks work to meet quality standards; demonstrates a high level of care and thoroughness; checks work to ensure completeness and accuracy.', 'Sets high standards and well-defined, realistic goals for one’s self; displays a high level of effort and commitment towards completing assignments in a timely manner; works with minimal supervision; is motivated to achieve.', 'A criminal background investigation and Social Security Number trace;', 'A registered sex offender search.', 'Pay', 'No: Not providing sponsorship for this job', 'nexportsolutions.com', 'Only full-time employees eligible', 'Yes']",2020-08-08 13:42:36
Business Intelligence Engineer I,Cardinal Financial,3.4 out of 5,Remote,"['Follow documented procedures to acquire and publish data from or to multiple sources', 'Make modifications to spreadsheets and minor changes to SQL scripts as required for changes to existing processes', 'Maintain procedure documentation to ensure it matches the actions being performed', 'Investigate data issues and identify the root cause. Resolve or escalate any issues as needed', 'Assist with the testing of changes to the data load process', 'Assist with general Business Intelligence issues, as directed.', 'Equivalent experience or Bachelor’s Degree in Business, Accounting and/or Information Systems', 'Experience or college level coursework related to data analysis and/or database programming', 'Spreadsheet skills (advanced formulas and/or macros) e.g. Excel or Google Sheets', 'Experience with writing SQL Queries', 'Understanding of financial services such as banking or mortgage lending is a plus.', 'Can complete work in a highly collaborative environment by being proactive in working with your supervisor and other colleagues to resolve questions, issues, or concerns', 'Able to manage sensitive and confidential information', 'Excellent communication skills, ability to speak to people at all levels within the organization.', 'Good business writing skills', 'Strength, Stability, and Vision', 'Highly engineered proprietary technology that is revolutionizing the mortgage industry', 'An empowered culture where your ideas are important and your voice matters', 'Opportunity for career growth', 'Benefits that become effective the first day of the month following your start date including - Medical, Dental, Vision, and much more.', '401K w/ 50% match up to a maximum employee contribution of 5% - Effective the 1st of the month following 30-days of employment.']",2020-08-08 13:42:36
Model Operations Engineer,USAA,3.9 out of 5,"Norfolk, VA 23529",[],2020-08-08 13:42:36
Data Engineer,eNGINE,N/A,"Pittsburgh, PA 15222","['Pittsburgh, PA (Required)', 'United States (Required)', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:42:36
Hybrid DevOps Engineer with Java/Python Coding,CompGain LLC,N/A,"Rockville, MD 20850",['Temporarily due to COVID-19'],2020-08-08 13:42:36
Tableau Developer+Data Engineer,Pacific Data Integrators,N/A,"Jackson, MI","['Proven in Relative estimation, Story-based development', 'Proficient in leading Iteration/sprint planning meeting, Conflict Resolution', 'Strong into Business Analysis planning and monitoring, Enterprise Analysis, Requirement management and communication', 'Provide objective guidance without personal or political considerations', 'Experienced in implementing agile techniques in different cultures and environments', 'Experience with Python Programming.', 'Data Engineer: 5 years (Preferred)', 'SAP: 2 years (Preferred)', '1 year', 'Yes', 'One location', 'Multiple locations']",2020-08-08 13:42:36
Sr. Data Engineer/Architect - ELK stack,Vaco,3.7 out of 5,"West Palm Beach, FL","['Architect, design, create, and support ETL, Logstash data pipelines, and data governance.', 'Integrate data with ETL tool available.', 'Advise and create ETL standards, rules, and processes to absorb, transform, and load quality data with strong integrity that can be dynamically stored, distributed, and replicated.', 'Ensure high availability database systems and safeguards for database tolerance.', 'Write Python script to automate redundant data processes.', 'Build database utility programs to provide business solutions.', 'Provide data architecture, data structure, workflow, and proper design to best serve data integrity, quality, and efficiency.', 'Write simple, clean, and effective code to meet query optimization goals.', 'Encourage use of change management software to encourage solid change control within software development and data warehousing.', '5+ years of ETL and data integration expertise.', 'Knowledge of ELK stack.', 'Experience with data visualization tools such as Kibana.', 'AWS services including RDS', 'Experience with relational distrubuted database and ETL data pipelines.', 'Strong knowledge of data governance and query optimization.', 'Python scripting is a plus', 'Knowledge of HIPAA compliance is a plus']",2020-08-08 13:42:36
Staff Software Engineer,Indeed,4.3 out of 5,"Austin, TX 78731","['BS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field with 5+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl;', 'MS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field 3+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl.', 'Minimum 5 years of experience building applications using at least one of the following: web application technologies including: HTML, CSS, or Javascript; OR Databases, for example: Mysql, Mongo, or a similar program; OR a collection of systems connected and communicating via a network connection', 'Minimum 2 year of experience mentoring more junior Engineers', 'Significant experience with large scale, high-performance systems']",2020-08-08 13:42:36
Entry Level Metrologist / Engineer,East Coast Metrology,N/A,"Topsfield, MA 01983","['Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'eastcoastmetrology.com']",2020-08-08 13:42:36
Data Scientist,HP,4 out of 5,"San Diego, CA 92127","['You have deep interests in customer and market behavior and methods to measure and anticipate it', 'You are passionate about unveiling answers to most difficult questions using data and models', 'You feel accomplished seeing your pricing recommendations being implemented while shopping for yourself', 'You can’t stop thinking about learning something new every day and enjoy being surrounded by highly talented people', 'Develop and apply statistical methods and experimentation to analyze the effect of pricing and sales decisions on business performance', 'Collaborate with internal stakeholders to design and deploy pricing initiatives based upon analytical findings', 'Present results and recommendations to relevant stakeholders, including senior leadership', 'At least 3 years’ working experience in data science, ideally in a consumer-focused setting', 'Experience in designing, deploying, and analyzing in-market experiments and/or AB tests', 'Ability to think creatively and invent original solutions to business and modelling challenges', 'Proficiency with R and/or Python is required', 'Proficiency in Microsoft Excel and Microsoft PowerPoint', 'Excellent written and verbal communication skills with an ability to influence key decision makers', ""Master's or PhD degree in Quantitative Marketing, Business, Statistics, Economics, Psychology, or other relevant quantitative discipline"", 'Interest in pricing, economics, and consumer behavior', 'Experience in deploying data science in a retail environment', 'Understanding of CRM and customer segmentation', 'Knowledge of price optimization approaches, price discrimination models and a general knowledge of main concepts from the industrial organization literature', 'Basic understanding of finance and product economics', 'Experience in project and/or product management']",2020-08-08 13:42:36
Entry Level Metrologist / Engineer,East Coast Metrology,N/A,"Topsfield, MA 01983","['Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'eastcoastmetrology.com']",2020-08-08 13:43:20
Data Engineer,Pitney Bowes,3.6 out of 5,"Austin, TX 73301","['Are passionate about client success.', 'Enjoy collaborating with others.', 'Strive to exceed expectations.', 'Move boldly in the quest for superior and best in market solutions.', 'Develop and maintain data pipelines in and out of data warehouse using combination of Python, Snaplogic, SQL Server, and Snowflake SnowSQL with a focus on performance, reliability, durability, data quality, security and SLA expectations.', 'Work with cloud streaming technologies, like Kinesis and Kafka', 'Analyze, design, build, test, implement and automate integration technology solutions', 'Approach tasks from DataOps point of view; automate data audit, validation and monitoring processes', 'Write SQL queries against MS SQL and Snowflake databases', 'Provide production support for Data Warehouse issues such data load problems, transformation translation problems', 'Ensure accurate and timely data availability to meet business SLA, especially around critical time periods', 'Document data pipelines and data warehouse processes and flows', 'Work closely with business analysts to understand requirements and develop solutions', 'Experience with Snowflake cloud-based data warehouse or any columnar database is a big plus', '3-5 years of experience with data streaming, ingest, ETL, and data warehousing technologies', '2+ years of experience with Cloud-computing services, such as Amazon Web Services', '1+ experience developing Python based code that reads/writes data into databases', '3-5 years of experience with working in a data engineering role', 'Strong understanding of various data formats such as CSV, XML, JSON, AVRO etc.', 'Provide the opportunity to grow and develop your career', 'Offer an inclusive environment that encourages diverse perspectives and ideas', 'Deliver challenging and unique opportunities to contribute to the success of a transforming organization', 'Offer comprehensive benefits globally (pbprojectliving.com)']",2020-08-08 13:43:20
Product Engineer,HCL America Inc,2.3 out of 5,"Newark, DE","['Product Engineer: 2 years (Required)', 'Product Development: 2 years (Required)', 'Medical: 2 years (Required)']",2020-08-08 13:43:20
Hybrid DevOps Engineer with Java/Python Coding,CompGain LLC,N/A,"Rockville, MD 20850",['Temporarily due to COVID-19'],2020-08-08 13:43:20
Data Engineer,BOEING,4 out of 5,"Herndon, VA 20192","['Job', 'Company', 'Work with a teammate on data integration requirements.', 'Write code on ETL platform to transform data to a suitable formats as defined by IC ITE initiatives.', 'Add features to ETL platform to shorten timelines for future data integration efforts.', 'Develop, maintain code, and integrate software into a fully functional software system.', 'Participate in daily scum meetings, sprint retrospectives, and other agile processes.', 'Work with external teams to validate data ingest.', 'Provide and maintain documentation of system architecture, development, and enhancements.', ""Bachelor’s Degree and 6 or more years’ experience or Master's Degree with 3 or more years' experience from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry."", '6+ years of software development experience', 'Linux/Unix experience', 'Object Oriented programming language', 'Possess strong verbal and written communication skills', 'Possess strong analytical skills, with excellent problem solving abilities in the face of ambiguity', 'Expertise in data ingestion, data transformation (ETL), and data modeling.', 'Experience with Java, Ruby, or Python', 'Experience in Agile/SCRUM enterprise-scale software development', '3 years’ experience working with one of the following batch-processing and tools (eg, Nifi, Midpoint, MapReduce, Yarn, Pig, Hive, HDFS, Oozie)', '1 year working with Restful web services', 'Experience with code development, deployment, versioning, and build tools (eg, Eclipse, git, svn, maven, Jenkins)']",2020-08-08 13:43:20
Data Scientist,HP,4 out of 5,"San Diego, CA 92127","['You have deep interests in customer and market behavior and methods to measure and anticipate it', 'You are passionate about unveiling answers to most difficult questions using data and models', 'You feel accomplished seeing your pricing recommendations being implemented while shopping for yourself', 'You can’t stop thinking about learning something new every day and enjoy being surrounded by highly talented people', 'Develop and apply statistical methods and experimentation to analyze the effect of pricing and sales decisions on business performance', 'Collaborate with internal stakeholders to design and deploy pricing initiatives based upon analytical findings', 'Present results and recommendations to relevant stakeholders, including senior leadership', 'At least 3 years’ working experience in data science, ideally in a consumer-focused setting', 'Experience in designing, deploying, and analyzing in-market experiments and/or AB tests', 'Ability to think creatively and invent original solutions to business and modelling challenges', 'Proficiency with R and/or Python is required', 'Proficiency in Microsoft Excel and Microsoft PowerPoint', 'Excellent written and verbal communication skills with an ability to influence key decision makers', ""Master's or PhD degree in Quantitative Marketing, Business, Statistics, Economics, Psychology, or other relevant quantitative discipline"", 'Interest in pricing, economics, and consumer behavior', 'Experience in deploying data science in a retail environment', 'Understanding of CRM and customer segmentation', 'Knowledge of price optimization approaches, price discrimination models and a general knowledge of main concepts from the industrial organization literature', 'Basic understanding of finance and product economics', 'Experience in project and/or product management']",2020-08-08 13:43:20
Tableau Developer+Data Engineer,Pacific Data Integrators,N/A,"Jackson, MI","['Proven in Relative estimation, Story-based development', 'Proficient in leading Iteration/sprint planning meeting, Conflict Resolution', 'Strong into Business Analysis planning and monitoring, Enterprise Analysis, Requirement management and communication', 'Provide objective guidance without personal or political considerations', 'Experienced in implementing agile techniques in different cultures and environments', 'Experience with Python Programming.', 'Data Engineer: 5 years (Preferred)', 'SAP: 2 years (Preferred)', '1 year', 'Yes', 'One location', 'Multiple locations']",2020-08-08 13:43:20
AWS Engineer with Data Visualization,"CGI Group, Inc.",3.6 out of 5,"Lafayette, LA 70593","['Manages, Performs and delivers the IT service with which she or he is associated', 'Develops and implements Enterprise Cloud & Hybrid Cloud Strategies leveraging AWS', 'Executes cloud migrations including Application Rationalization and Modernization strategies', 'Work with CGI Architects and Experts to build solution according to requirements', 'Manages and Prepares technical deliverables and/or provides input to other deliverables related to the IT service', 'Troubleshoot technical and business issues and provide options for resolution', 'Strong knowledge of AWS cloud technologies required', 'Design, development, coding, testing, and debugging of software', 'Ensures that software meets or exceeds specified standards and end-user requirements', 'Communicating with stakeholders', 'Working in Agile methodologies', 'Positive attitude with high degree of professionalism and unwavering commitment to client satisfaction', 'Desire to learn new technologies', 'Self-motivated and can work with very little supervision in a team environment', '5 - 8 years of experience in software development', 'Hands on experience in web applications', 'Hands on experience in Web Services (Restful) using Flask, SQLAlchemy, etc.', 'Hands on experience in front end application development', 'Experience with developer tools such as Git, SVN and Maven', 'Should have hands on working experience with RDBMS/SQL and schema design', 'Knowledge in UNIX/Linux', 'Strong written and communication skills', 'Networking (DNS, Firewall)', 'Continuous Integration and Continuous Delivery Experience', 'Source Control (Git)', 'Agile delivery experience', 'AWS at least 3+ years working in Cloud environment', 'Experience and understanding of the following core component of AWS (client, storage, compute, virtualization, CloudWatch, Lambda, VPC, Security Roles [IAM], Cloud Formation, Redshift)', 'Experience implementing Data strategies tailored to cloud and hybrid cloud implementations', 'Experience with complex data model supporting multi-faceted business process', 'Strong understanding of DevOps practices', 'Expertise in Agile delivery', 'Experience with AWS Glue, Redshift, Lambda, S3, data pipeline, node.js and Python is required', 'Good to have knowledge on CloudBees, AWS Event Bridge and Okta.', 'Self-motivated and highly professional', 'Effective verbal and written communications skills', 'Able to meet deadlines working independently and directing others', 'Effective interaction with peers, team members and business partners', 'Demonstrates application delivery experience as part of a project team', 'Strong organizational and prioritization skills', 'Web Services', 'GIT', 'GIT', 'Jenkins', 'Oracle', 'SQL Server']",2020-08-08 13:43:20
Staff Software Engineer,Indeed,4.3 out of 5,"Austin, TX 78731","['Job', 'Company', 'BS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field with 5+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl;', 'MS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field 3+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl.', 'Minimum 5 years of experience building applications using at least one of the following: web application technologies including: HTML, CSS, or Javascript; OR Databases, for example: Mysql, Mongo, or a similar program; OR a collection of systems connected and communicating via a network connection', 'Minimum 2 year of experience mentoring more junior Engineers', 'Significant experience with large scale, high-performance systems']",2020-08-08 13:43:20
Polymer Engineer,Idexcel,4.3 out of 5,"King of Prussia, PA","['Testing: Prepare test specimens and perform mechanical tests including weathering, notched izod, Dynatup dart impact, melt flow rate etc. Perform measurements including optics, haze, gloss, etc', 'Processing: Extrude, injection mold, compression mold, etc. polymer formulations.', 'Data: Collect and work up data and present to scientists in a coherent, useful manner.', 'Support the site HES policy and complies with all regulatory and internal requirements', 'Participate in HES activities provided by site management and client. (e.g., Behavioral Base Safety, SafeStart, etc.)', 'Support and promotes the reporting of all health, safety, environmental, near-miss, accident or injury incidents', 'Limited Travel (<5%)', 'High school Diploma with 5+ years of experience in polymer R&D laboratories and good laboratory practices or BS/BA degree with 2+ years polymer processing experience and good laboratory practice', 'preferred experience in weathering', 'preferred experience in injection molding, extrusion, and other polymer processing equipment.', 'Demonstrated expertise in sample preparation and mechanical testing.', 'Demonstrated expertise in generating accurate and reliable data in a timely manner.', 'Demonstrated ability to work independently.', 'Work with multiple R&D engineers/scientists generating accurate and reliable data for specific projects.', 'Maintain documentation system including lab notebooks and standard operating procedures for owned equipmentWork safely and actively participate in the KOP safety program']",2020-08-08 13:43:20
Senior Data Scientist,ALTEN Calsoft Labs,3.6 out of 5,Remote,"['https://www.topuniversities.com/university-rankings/usa-rankings/2020', 'https://www.topuniversities.com/university-rankings-articles/india/top-10-universities-india-2020', 'At least 3-4 years of experience as Data Scientist.', 'Must come from a IT Product or Media Company.', 'Data analysis experience working with large-scale data.', 'Strong experience using Python & SQL for analysis, modeling, and data visualization.', 'Advanced statistics, data mining and modeling knowledge.', 'Partner with product, technology, and ops leaders to turn business problems into data problems and demonstrate creativity by using existing data to solve those problems.', 'Years of experience in applied data science and analytics, including hands-on development and deployment of predictive modeling/machine learning models.', 'Collaborate with business partners to identify opportunities, understand objectives, and rationalize efforts to support strategic business objectives with both short-term and long-term deliveries in an environment with high SLA expectations.', 'Machine-learning engineer or applied data scientist who wants to work on exciting algorithmic and deep infrastructure issues.', 'Knowledgeable in one or more of the following: machine learning, information retrieval, recommendation systems, social network analysis.', 'Number of years of experience in applied data science and analytics, including hands-on development and deployment of predictive modeling/machine learning models.', 'Advanced Python for Data Science (descriptive / predictive models) + Strong Stats background Own the end to end data science process, from initiation to deployment, and through ongoing communication and collaboration, sharing of results to partners and leadership.', 'Drive personalization, real-time decision-making, causal inference, and predictive analytics capabilities through the application of Machine Learning, Deep Learning, NLP, and Simulation in an agile development framework.', 'Conduct quantitative analysis of experimental, and textual data to generate insights and drive decision making (ANOVA, Regression, Chi-Sq, AB, pre-post etc..) Working knowledge of SQL, Tableau, Hadoop, BigQuery, Presto, Vertica Write well documented code that can be shared and used across teams, and can scale to be used in existing products', ""Bachelor's (Preferred)"", 'Yes']",2020-08-08 13:43:20
Sr. Manager Data Engineer,Capital One,3.9 out of 5,"McLean, VA 22101","['Demonstrate both effective people management and disciplined software and data engineering leadership.', 'Work with product owners to understand desired application capabilities and testing scenarios - continuously improving software engineering practices.', 'Lead Agile teams to design/implement cutting-edge technologies, and support technical solutions across a full-stack cloud technologies with operational disciplines.', 'Bring a passion to stay on top of tech trends, experiment with and learn new technologies, and encourage innovation.', 'Engage in internal & external technology communities, and mentor members of the engineering community.', 'Collaborating as part of a cross-functional Agile team to create and enhance technology solutions that enables state of the art, next generation Big Data applications.', 'Lead, manage and grow multiple teams of product focused software and data engineers', 'Mentor and guide the professional and technical development of engineers on your team', 'Drive long-term strategy for the HR Data Warehouse Platform', 'Manage the development pipeline of distributed computing Big Data applications using Open Source frameworks like Apache Spark, Scala and Kafka on AWS Cloud', 'Utilizing programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift', 'Leveraging DevOps techniques and practices like Continuous Integration, Continuous Deployment, Test Automation, Build Automation and Test Driven Development to enable the rapid delivery of working code utilizing tools like Jenkins, Maven, Nexus, Chef, Terraform, Ruby, Git and Docker', 'Enforce company policies in areas of development methodology, architecture, security, change and configuration management, and compliance.', 'Ensure quality testing and conduct reviews with other team members to make sure code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Enable and promote custom solutions with a “You Build, You Own” philosophy.', 'Bachelor’s Degree', 'At least 6 years of experience in software development', 'At least 5 years of experience in data warehousing or analytics', 'At least 1 year of experience with data engineering', 'At least 1 year of experience with data modeling', 'At least 1 year of experience deploying, monitoring and maintaining a Cloud-based application', '5 years of experience building software including systems and application design, code development and testing.', '3 years of experience in scripting language (Python, Perl, JavaScript, Shell)', '3 years of experience with UNIX/Linux environments', '1 year of experience in Python, Scala, or R for data analysis', '1 year of experience with the Hadoop Stack', '1 year of experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink)', '1 year of experience with Amazon Web Services (AWS) or Microsoft Azure or another public cloud', '1 year of experience with the Hadoop stack (MapReduce, Pig, Hive and Hbase)', '1 year of experience with MySQL, Postgres, Redshift, Snowflake.']",2020-08-08 13:43:20
Ab Initio Data Engineer,ITI Data,N/A,United States,"['401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Multiple locations']",2020-08-08 13:43:20
Sr. Data Engineer/Architect - ELK stack,Vaco,3.7 out of 5,"West Palm Beach, FL","['Architect, design, create, and support ETL, Logstash data pipelines, and data governance.', 'Integrate data with ETL tool available.', 'Advise and create ETL standards, rules, and processes to absorb, transform, and load quality data with strong integrity that can be dynamically stored, distributed, and replicated.', 'Ensure high availability database systems and safeguards for database tolerance.', 'Write Python script to automate redundant data processes.', 'Build database utility programs to provide business solutions.', 'Provide data architecture, data structure, workflow, and proper design to best serve data integrity, quality, and efficiency.', 'Write simple, clean, and effective code to meet query optimization goals.', 'Encourage use of change management software to encourage solid change control within software development and data warehousing.', '5+ years of ETL and data integration expertise.', 'Knowledge of ELK stack.', 'Experience with data visualization tools such as Kibana.', 'AWS services including RDS', 'Experience with relational distrubuted database and ETL data pipelines.', 'Strong knowledge of data governance and query optimization.', 'Python scripting is a plus', 'Knowledge of HIPAA compliance is a plus']",2020-08-08 13:43:20
Big Data Engineer (Hadoop / AWS Cloud),"Ntelicor, L.P.",4.4 out of 5,"Dallas, TX 75202","['Monday to Friday', 'More than 1 year', 'Likely', 'No: Not providing sponsorship for this job', 'Yes']",2020-08-08 13:43:20
Data Engineer,BOEING,4 out of 5,"Herndon, VA 20192","['Work with a teammate on data integration requirements.', 'Write code on ETL platform to transform data to a suitable formats as defined by IC ITE initiatives.', 'Add features to ETL platform to shorten timelines for future data integration efforts.', 'Develop, maintain code, and integrate software into a fully functional software system.', 'Participate in daily scum meetings, sprint retrospectives, and other agile processes.', 'Work with external teams to validate data ingest.', 'Provide and maintain documentation of system architecture, development, and enhancements.', ""Bachelor’s Degree and 6 or more years’ experience or Master's Degree with 3 or more years' experience from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry."", '6+ years of software development experience', 'Linux/Unix experience', 'Object Oriented programming language', 'Possess strong verbal and written communication skills', 'Possess strong analytical skills, with excellent problem solving abilities in the face of ambiguity', 'Expertise in data ingestion, data transformation (ETL), and data modeling.', 'Experience with Java, Ruby, or Python', 'Experience in Agile/SCRUM enterprise-scale software development', '3 years’ experience working with one of the following batch-processing and tools (eg, Nifi, Midpoint, MapReduce, Yarn, Pig, Hive, HDFS, Oozie)', '1 year working with Restful web services', 'Experience with code development, deployment, versioning, and build tools (eg, Eclipse, git, svn, maven, Jenkins)']",2020-08-08 13:44:06
Data Scientist,HP,4 out of 5,"San Diego, CA 92127","['You have deep interests in customer and market behavior and methods to measure and anticipate it', 'You are passionate about unveiling answers to most difficult questions using data and models', 'You feel accomplished seeing your pricing recommendations being implemented while shopping for yourself', 'You can’t stop thinking about learning something new every day and enjoy being surrounded by highly talented people', 'Develop and apply statistical methods and experimentation to analyze the effect of pricing and sales decisions on business performance', 'Collaborate with internal stakeholders to design and deploy pricing initiatives based upon analytical findings', 'Present results and recommendations to relevant stakeholders, including senior leadership', 'At least 3 years’ working experience in data science, ideally in a consumer-focused setting', 'Experience in designing, deploying, and analyzing in-market experiments and/or AB tests', 'Ability to think creatively and invent original solutions to business and modelling challenges', 'Proficiency with R and/or Python is required', 'Proficiency in Microsoft Excel and Microsoft PowerPoint', 'Excellent written and verbal communication skills with an ability to influence key decision makers', ""Master's or PhD degree in Quantitative Marketing, Business, Statistics, Economics, Psychology, or other relevant quantitative discipline"", 'Interest in pricing, economics, and consumer behavior', 'Experience in deploying data science in a retail environment', 'Understanding of CRM and customer segmentation', 'Knowledge of price optimization approaches, price discrimination models and a general knowledge of main concepts from the industrial organization literature', 'Basic understanding of finance and product economics', 'Experience in project and/or product management']",2020-08-08 13:44:06
Tableau Developer+Data Engineer,Pacific Data Integrators,N/A,"Jackson, MI","['Proven in Relative estimation, Story-based development', 'Proficient in leading Iteration/sprint planning meeting, Conflict Resolution', 'Strong into Business Analysis planning and monitoring, Enterprise Analysis, Requirement management and communication', 'Provide objective guidance without personal or political considerations', 'Experienced in implementing agile techniques in different cultures and environments', 'Experience with Python Programming.', 'Data Engineer: 5 years (Preferred)', 'SAP: 2 years (Preferred)', '1 year', 'Yes', 'One location', 'Multiple locations']",2020-08-08 13:44:06
AWS Engineer with Data Visualization,"CGI Group, Inc.",3.6 out of 5,"Lafayette, LA 70593","['Manages, Performs and delivers the IT service with which she or he is associated', 'Develops and implements Enterprise Cloud & Hybrid Cloud Strategies leveraging AWS', 'Executes cloud migrations including Application Rationalization and Modernization strategies', 'Work with CGI Architects and Experts to build solution according to requirements', 'Manages and Prepares technical deliverables and/or provides input to other deliverables related to the IT service', 'Troubleshoot technical and business issues and provide options for resolution', 'Strong knowledge of AWS cloud technologies required', 'Design, development, coding, testing, and debugging of software', 'Ensures that software meets or exceeds specified standards and end-user requirements', 'Communicating with stakeholders', 'Working in Agile methodologies', 'Positive attitude with high degree of professionalism and unwavering commitment to client satisfaction', 'Desire to learn new technologies', 'Self-motivated and can work with very little supervision in a team environment', '5 - 8 years of experience in software development', 'Hands on experience in web applications', 'Hands on experience in Web Services (Restful) using Flask, SQLAlchemy, etc.', 'Hands on experience in front end application development', 'Experience with developer tools such as Git, SVN and Maven', 'Should have hands on working experience with RDBMS/SQL and schema design', 'Knowledge in UNIX/Linux', 'Strong written and communication skills', 'Networking (DNS, Firewall)', 'Continuous Integration and Continuous Delivery Experience', 'Source Control (Git)', 'Agile delivery experience', 'AWS at least 3+ years working in Cloud environment', 'Experience and understanding of the following core component of AWS (client, storage, compute, virtualization, CloudWatch, Lambda, VPC, Security Roles [IAM], Cloud Formation, Redshift)', 'Experience implementing Data strategies tailored to cloud and hybrid cloud implementations', 'Experience with complex data model supporting multi-faceted business process', 'Strong understanding of DevOps practices', 'Expertise in Agile delivery', 'Experience with AWS Glue, Redshift, Lambda, S3, data pipeline, node.js and Python is required', 'Good to have knowledge on CloudBees, AWS Event Bridge and Okta.', 'Self-motivated and highly professional', 'Effective verbal and written communications skills', 'Able to meet deadlines working independently and directing others', 'Effective interaction with peers, team members and business partners', 'Demonstrates application delivery experience as part of a project team', 'Strong organizational and prioritization skills', 'Web Services', 'GIT', 'GIT', 'Jenkins', 'Oracle', 'SQL Server']",2020-08-08 13:44:06
Staff Software Engineer,Indeed,4.3 out of 5,"Austin, TX 78731","['BS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field with 5+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl;', 'MS in Computer Science, Computer Engineering, Electrical Engineering, Mathematics or a closely related computer technical field 3+ years experience programming with at least one of the following languages: Java, C++, C#, Python, Go, or Perl.', 'Minimum 5 years of experience building applications using at least one of the following: web application technologies including: HTML, CSS, or Javascript; OR Databases, for example: Mysql, Mongo, or a similar program; OR a collection of systems connected and communicating via a network connection', 'Minimum 2 year of experience mentoring more junior Engineers', 'Significant experience with large scale, high-performance systems']",2020-08-08 13:44:06
Polymer Engineer,Idexcel,4.3 out of 5,"King of Prussia, PA","['Testing: Prepare test specimens and perform mechanical tests including weathering, notched izod, Dynatup dart impact, melt flow rate etc. Perform measurements including optics, haze, gloss, etc', 'Processing: Extrude, injection mold, compression mold, etc. polymer formulations.', 'Data: Collect and work up data and present to scientists in a coherent, useful manner.', 'Support the site HES policy and complies with all regulatory and internal requirements', 'Participate in HES activities provided by site management and client. (e.g., Behavioral Base Safety, SafeStart, etc.)', 'Support and promotes the reporting of all health, safety, environmental, near-miss, accident or injury incidents', 'Limited Travel (<5%)', 'High school Diploma with 5+ years of experience in polymer R&D laboratories and good laboratory practices or BS/BA degree with 2+ years polymer processing experience and good laboratory practice', 'preferred experience in weathering', 'preferred experience in injection molding, extrusion, and other polymer processing equipment.', 'Demonstrated expertise in sample preparation and mechanical testing.', 'Demonstrated expertise in generating accurate and reliable data in a timely manner.', 'Demonstrated ability to work independently.', 'Work with multiple R&D engineers/scientists generating accurate and reliable data for specific projects.', 'Maintain documentation system including lab notebooks and standard operating procedures for owned equipmentWork safely and actively participate in the KOP safety program']",2020-08-08 13:44:06
Senior Data Scientist,ALTEN Calsoft Labs,3.6 out of 5,Remote,"['https://www.topuniversities.com/university-rankings/usa-rankings/2020', 'https://www.topuniversities.com/university-rankings-articles/india/top-10-universities-india-2020', 'At least 3-4 years of experience as Data Scientist.', 'Must come from a IT Product or Media Company.', 'Data analysis experience working with large-scale data.', 'Strong experience using Python & SQL for analysis, modeling, and data visualization.', 'Advanced statistics, data mining and modeling knowledge.', 'Partner with product, technology, and ops leaders to turn business problems into data problems and demonstrate creativity by using existing data to solve those problems.', 'Years of experience in applied data science and analytics, including hands-on development and deployment of predictive modeling/machine learning models.', 'Collaborate with business partners to identify opportunities, understand objectives, and rationalize efforts to support strategic business objectives with both short-term and long-term deliveries in an environment with high SLA expectations.', 'Machine-learning engineer or applied data scientist who wants to work on exciting algorithmic and deep infrastructure issues.', 'Knowledgeable in one or more of the following: machine learning, information retrieval, recommendation systems, social network analysis.', 'Number of years of experience in applied data science and analytics, including hands-on development and deployment of predictive modeling/machine learning models.', 'Advanced Python for Data Science (descriptive / predictive models) + Strong Stats background Own the end to end data science process, from initiation to deployment, and through ongoing communication and collaboration, sharing of results to partners and leadership.', 'Drive personalization, real-time decision-making, causal inference, and predictive analytics capabilities through the application of Machine Learning, Deep Learning, NLP, and Simulation in an agile development framework.', 'Conduct quantitative analysis of experimental, and textual data to generate insights and drive decision making (ANOVA, Regression, Chi-Sq, AB, pre-post etc..) Working knowledge of SQL, Tableau, Hadoop, BigQuery, Presto, Vertica Write well documented code that can be shared and used across teams, and can scale to be used in existing products', ""Bachelor's (Preferred)"", 'Yes']",2020-08-08 13:44:06
Sr. Manager Data Engineer,Capital One,3.9 out of 5,"McLean, VA 22101","['Demonstrate both effective people management and disciplined software and data engineering leadership.', 'Work with product owners to understand desired application capabilities and testing scenarios - continuously improving software engineering practices.', 'Lead Agile teams to design/implement cutting-edge technologies, and support technical solutions across a full-stack cloud technologies with operational disciplines.', 'Bring a passion to stay on top of tech trends, experiment with and learn new technologies, and encourage innovation.', 'Engage in internal & external technology communities, and mentor members of the engineering community.', 'Collaborating as part of a cross-functional Agile team to create and enhance technology solutions that enables state of the art, next generation Big Data applications.', 'Lead, manage and grow multiple teams of product focused software and data engineers', 'Mentor and guide the professional and technical development of engineers on your team', 'Drive long-term strategy for the HR Data Warehouse Platform', 'Manage the development pipeline of distributed computing Big Data applications using Open Source frameworks like Apache Spark, Scala and Kafka on AWS Cloud', 'Utilizing programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift', 'Leveraging DevOps techniques and practices like Continuous Integration, Continuous Deployment, Test Automation, Build Automation and Test Driven Development to enable the rapid delivery of working code utilizing tools like Jenkins, Maven, Nexus, Chef, Terraform, Ruby, Git and Docker', 'Enforce company policies in areas of development methodology, architecture, security, change and configuration management, and compliance.', 'Ensure quality testing and conduct reviews with other team members to make sure code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Enable and promote custom solutions with a “You Build, You Own” philosophy.', 'Bachelor’s Degree', 'At least 6 years of experience in software development', 'At least 5 years of experience in data warehousing or analytics', 'At least 1 year of experience with data engineering', 'At least 1 year of experience with data modeling', 'At least 1 year of experience deploying, monitoring and maintaining a Cloud-based application', '5 years of experience building software including systems and application design, code development and testing.', '3 years of experience in scripting language (Python, Perl, JavaScript, Shell)', '3 years of experience with UNIX/Linux environments', '1 year of experience in Python, Scala, or R for data analysis', '1 year of experience with the Hadoop Stack', '1 year of experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink)', '1 year of experience with Amazon Web Services (AWS) or Microsoft Azure or another public cloud', '1 year of experience with the Hadoop stack (MapReduce, Pig, Hive and Hbase)', '1 year of experience with MySQL, Postgres, Redshift, Snowflake.']",2020-08-08 13:44:06
Ab Initio Data Engineer,ITI Data,N/A,United States,"['401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', ""Bachelor's (Preferred)"", 'Multiple locations']",2020-08-08 13:44:06
Sr. Data Engineer/Architect - ELK stack,Vaco,3.7 out of 5,"West Palm Beach, FL","['Architect, design, create, and support ETL, Logstash data pipelines, and data governance.', 'Integrate data with ETL tool available.', 'Advise and create ETL standards, rules, and processes to absorb, transform, and load quality data with strong integrity that can be dynamically stored, distributed, and replicated.', 'Ensure high availability database systems and safeguards for database tolerance.', 'Write Python script to automate redundant data processes.', 'Build database utility programs to provide business solutions.', 'Provide data architecture, data structure, workflow, and proper design to best serve data integrity, quality, and efficiency.', 'Write simple, clean, and effective code to meet query optimization goals.', 'Encourage use of change management software to encourage solid change control within software development and data warehousing.', '5+ years of ETL and data integration expertise.', 'Knowledge of ELK stack.', 'Experience with data visualization tools such as Kibana.', 'AWS services including RDS', 'Experience with relational distrubuted database and ETL data pipelines.', 'Strong knowledge of data governance and query optimization.', 'Python scripting is a plus', 'Knowledge of HIPAA compliance is a plus']",2020-08-08 13:44:06
Big Data Engineer (Hadoop / AWS Cloud),"Ntelicor, L.P.",4.4 out of 5,"Dallas, TX 75202","['Monday to Friday', 'More than 1 year', 'Likely', 'No: Not providing sponsorship for this job', 'Yes']",2020-08-08 13:44:06
Senior Data Engineer,UCLA Health,4 out of 5,"Los Angeles, CA 91403","['7 or more years of software development experience with multiple programming languages, technologies, and frameworks', 'Demonstrated experience on the data processing side of the software development cycle and deep understanding of choosing the right Data Structures and right Algorithms for data processing', 'Hands on experience running bioinformatics pipelines on genomics and clinical data', 'Good understanding of Genomics tools and technologies like PLINK, VCF, FASTA, GATK and GenomicsDB; exposure to different genomics datasets like WGS, WES, and RNASeq highly desired', 'Familiarity with Software Development Life Cycle, software unit testing and version control (preferably Git)', 'Hands-on experience designing and delivering solutions involving computationally intensive steps using technologies such as Hadoop-Map reduce, Spark or HPC', 'Expertise and working knowledge of Linux/Unix operating systems, command line tools and clusters', 'Strong industry experience in programming languages such as Python, C# or Java, with the ability to pick up new languages and technologies quickly; understanding of cloud and distributed systems principles and experience with large-scale, big data methods', 'Experience designing, developing and consuming performant REST APIs for data abstractions', 'Experience working with Data Scientists, Researchers and DevOps engineers to build, deploy and operationalize code at scale', 'Good understanding of Object oriented and Functional programming paradigms', 'Bachelor’s degree in Computer Science, Computer Engineering, Life sciences or related field from an accredited college or university; Master’s Degree in Computational Biology, BioInformatics preferred']",2020-08-08 13:44:06
Big Data Engineer,"Adil Business Systems, Inc.",3.5 out of 5,"Charlotte, NC 28216","['5+ years with Data Engineering', '4+ years of Solutions with Hadoop, Hive, Map Reduce, Sqoop, Oozie, Java', '1-2 years of Spark Scala', '1 years of Rest API', '1 year of cloud', 'Code, test, and analyzing 2-tier, 3-tier, or N-tier client/server applications.', 'Support existing business systems applications.', 'Consult with business analysts to identify business needs and appropriate technical solutions.', 'Design and document technical requirements for business applications.', 'Assist with the design, development, testing, and documentation of web sites/pages.', 'Support production and maintenance of existing applications.', 'Assist with the development of client business requirements and preparation of specifications, attend meetings and reply to users with basic information.', 'HTML programming and Web page development.', 'Java development skills', 'Design and document technical requirements for complex business applications.', 'Perform design, coding and testing on complicated revisions to Web applications, and creates efficient and maintainable new applications Utilize databases that support access by Web-based clients, including Oracle, DB2, and Microsoft SQL Server.', 'Extensive coding using servlets, CGI scripting, ODBC, JDBC.', 'Utilizes HTML and graphical tools to create or enhance the functionality of the web sites.', 'Confer with clients to identify requirements (e.g., data, information needs, processing, specific output, functional and development of test data), and determine desired outcomes in order to formulate the design of the system and/or offer alternative solutions in a timely manner.', 'Provide technical guidance and expertise during implementation.', 'Mentor new or junior staff on business knowledge, system peculiarities, and complex technical issues.', 'Analyze, design, and document information to create the applicable statement of work and the associated deliverables.', 'Proactively analyze and review emerging technologies', 'Bachelor’s Degree in Computer Science, CIS, or related field preferred', '3 to 5 years of experience in Web application development or equivalent total experience.', 'Proficient using Java for multi-tiered web-based applications.', 'Demonstrate an understanding of HTML–based programming, including understanding of HTML authoring tools to implement these functions.', '5 years of progressive, post-bachelor’s experience in Data Engineering/Management, or Analytics.', 'Experience with using build tools including one or more of the followings: Ant, Maven, Gradle.', 'Strong experience with using IDE’s and Software development environments including one or more of the followings: Eclipse, NetBeans and Intellij Idea.', '4 years of experience in Big Data Solutions using technologies including one or more of the followings: Hadoop, Hive, HBase, MapReduce, Spark, Sqoop, Oozie, Java.', '2 years of experience applying Agile development practices and working with distributed, component-based architectures.', '2 Years of experience in Spark/Scala.', '1-2 years of experience with REST API development  * 1 year of experience on Cloud platforms such as Azure or GCP  * Strong experience in performance Tuning, troubleshooting application issues & analyzing production issues.', ""Bachelor's Degree in computer science, Engineering or related field"", 'Hive: 4 years (Required)', 'Data Engineering: 5 years (Required)', 'Oozie: 4 years (Preferred)', 'Spark/Scala: 2 years (Required)', 'Rest API: 1 year (Required)', 'Java: 4 years (Preferred)', 'Hadoop: 4 years (Required)', 'Cloud: 1 year (Required)', ""Bachelor's (Required)"", 'Charlotte, NC 28262 (Required)', 'United States (Required)', 'Possible', 'No', 'None', 'Monday to Friday', 'No']",2020-08-08 13:44:06
Data Engineer Senior (ETL),USAA,3.9 out of 5,"La Coste, TX 78039",['Qualifications may warrant placement in a different job level*'],2020-08-08 13:44:06
Data Engineer,Ursus,N/A,"San Jose, CA 95110","['Maintain and build solutions on top of the AEM, Scene 7, DAM and SoCo modules', 'Provide technical responses to product questions reported via client care support, or at times direct from customers of AEM.', 'Manage customer expectations of response time and issue resolution Troubleshoot and reproduce the technical problems reported by customers and define workarounds.', 'Work with the development team on the more complex issues', 'Deliver software patches and upgrades to resolve customer issues', 'Provide product feedback to reduce the number of issues experienced by the customer', ""Back up and assist the solutions and applications engineering team when they're in the field delivering projects"", 'Create and integrate content-driven applications on top of the CQ core platform, and integrate with other systems', 'Must: Good understanding on UI technologies like PHP, JQuery, Java Script, HTML 5, CSS, Pearl, Curl.', 'Must: Good understanding of backend technologies like Java EE, Servlets, JSP, Tag libraries, and JSTL skills, combined with a good understanding of Enterprise Java frameworks such as Spring and Hibernate', 'Must: Solid experience in problem analysis and resolution of technical problems.', 'Must: Ability to handle clients professionally during all interfaces.', 'Must: Ability to work in different working hour shifts including Night shift and week end hours.', 'Must: Strong written and verbal communication skills.', 'Preferred: Knowledge in Day CQ foundational concepts, including the CRX repository, the CQ platform, the use of core frameworks such as Apache Sling and Apache Felix, a solid understanding of all Day CQ building blocks including templates, components, dialogs, widgets, etc, and the CQ development and deployment process.', 'Preferred: Application development, distributed application development and Internet or Intranet based database applications', 'Overall experience of 1 to 3 years with 1-2 years of web content management system experience working with one or more CMS packages is a big plus']",2020-08-08 13:44:06
Master Data Engineer,Capital One,3.9 out of 5,"McLean, VA 22101","['Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies', 'Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems', 'Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Snowflake', 'Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community', 'Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment', 'Perform unit tests and conducting reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Bachelor’s Degree', 'At least 6 years of experience in application development', 'At least 2 years of experience in data and streaming technologies (Spark, PySpark, Kafka, Flink, Kinesis, or Snowflake)', ""Master's Degree"", '8+ years of experience in application development', '3+ year experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink', '1+ years of experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service', '2+ years of experience with Ansible / Terraform', '3+ years of experience with Agile engineering practices', '2+ years of experience with NoSQL implementation (Mongo, Cassandra)', '3+ years of experience developing Java, Scala, or Python based software solutions', '4+ years of experience developing software solutions to solve complex business problems']",2020-08-08 13:44:52
Sr. Data Engineer,Kaygen,3.3 out of 5,"San Diego, CA","['4+ years working experience in data integration and pipeline development.', 'BS degree in CS, CE or EE.', '2+ years of Experience with AWS Cloud on data integration with Apache Spark, EMR, Glue, Kafka, Kinesis, and Lambda in S3, Redshift, RDS, MongoDB/DynamoDB ecosystems', 'Strong real-life experience in python development especially in pySpark in AWS Cloud environment.', 'Design, develop test, deploy, maintain and improve data integration pipeline.', 'Experience in Python and common python libraries.', 'Strong analytical experience with database in writing complex queries, query optimization, debugging, user defined functions, views, indexes etc.', 'Strong experience with source control systems such as Git, Bitbucket, and Jenkins build and continuous integration tools.', 'Databricks or Apache Spark Experience is a plus.', 'Monday to Friday', 'AWS: 2 years (Required)', 'Spark: 3 years (Required)', 'pyspark: 3 years (Required)', 'databricks: 1 year (Required)', 'Likely', 'One location', 'kaygen.com', 'Temporarily due to COVID-19']",2020-08-08 13:44:52
Network Engineer,Gridiron IT,4 out of 5,"Washington, DC","['Scope', 'End-to-End WAN/LAN Network Architecture Design and Implementation', 'Current circuit information for all locations including:', 'Circuit Provider', 'Current Bandwidth and Utilization', 'Needs for Additional Bandwidth or Possible Circuit Consolidation', 'Failure Analysis and Stakeholders Related to Each Circuit', 'Risk Analysis and Mitigation Procedures Related to the Transport Circuits', 'Recovery Procedures in the Event of a Failure', 'Network Optimization and Design Recommendations (hardware agnostic)', 'End-to-End WAN/LAN Network Design Validation', 'A review of the current network security measures in place through both the MPLS network and the MTIPS firewalls.', 'A review of vulnerabilities in the network that affect stability and reliability.', 'A detailed analysis of the current utilization of each circuit, including not only the bandwidth utilization, but actual application utilization and recommendations to improve availability and performance.', 'An overview of application dependencies that are related to the network circuits and equipment from the server all the way to the end user, identifying the related equipment, potential failure points, and recommendations for improvement.', 'A complete and verified map of the customer’s network.', 'An overall health assessment of the network.', 'End-to-End Evaluation of Network Alternative to Improve Performance', 'The state of the customer’s network in relation to current industry standards and best practices.', 'Recommendations for new and emerging technology that can be implemented that can increase efficiency, increase reliability, and decrease costs.', 'Recommendations for topology and design changes that can improve overall network reliability.', 'The risks and rewards associated with each of the recommendations provided to the customer.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Schedule', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Network Engineering: 4 years (Required)', 'LAN/WAN Network Architecture: 4 years (Required)', ""Bachelor's (Required)"", 'Secret (Required)', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:44:52
Backend Software Engineer,"Appfigures, Inc.",N/A,"New York, NY 10002","['You have mastered a programming language of your choice. You are likely sick and tired of writing Fizz Buzz. We mainly use C# and Python, but it’s okay if you don’t know them. We think that being a capable developer in one language implies you’d be able to get comfortable with most languages or environments. We are always open to trying new things to figure out what the best tool for the job is and hope you are too.', 'You have a disciplined approach to development, testing, and quality assurance. We know perfection isn’t possible, but we think about the trade-offs inherent in our designs and guard against them up front. Folks rely on our data to run their businesses, so it’s important that we get it right.', 'You recognize that sometimes you need to throw away the prototype (and sometimes you need to ship it). We think it’s OK to experiment and we understand that sometimes you don’t know if something will work until you try it. And sometimes that thing you tried just didn’t work.', 'You can write clean, fast, and efficient code while keeping in mind the bigger context of what we are doing and why. We wouldn’t do this if it weren’t fun, but we know that at the end of the day the software we build is to simplify the lives of our customers.', 'You’re looking forward to getting to know our users. We rotate escalated support duties across the team. It’s an opportunity for everyone to see how our users interact with the platform, what they need next, and what could be improved.', 'You’re willing to try new things in a collaborative environment. We’re a small team so responsibilities are flexible. We are a place where initiative beyond the job description is rewarded. We want you to feel empowered to commit or critique in any part of our codebase or company. We want you to feel empowered to take features from an idea all the way to our users. We think every team member’s perspective and opinion is important, and taken together will help make the best product we can.', 'A BS / MS in Computer Science or related field-- a degree means less to us than proven ability.', 'Contributions to open source projects, blogs, books, and StackOverflow or work experience.', 'Experience with the web, the software and hardware behind it, scraping, and performance analysis.', 'Integrating a new datasource or API integration to ingest new datasets mobile app developers need to run their businesses.', 'Scaling a critical scraping service.', 'Diagnosing and fixing performance issues in our API.', 'Working with sales, marketing, and others on the product and engineering teams to envision and create new products and features for our users.', 'Helping the data science team turn ML models into production-grade products.', 'Great medical, dental, and vision insurance', '401(k) retirement plan', 'Pre-tax transit benefits, subsidized gym memberships and excellent discounts on hundreds of other well-known services and products', 'Plenty of paid time-off and flexible remote work policy', 'Awesome work station with whatever you need to be happy and productive', 'A fully stocked kitchen with a variety of snacks and drinks', 'Monthly personal project days', 'Weekly catered lunches', 'Events for employees and members', 'Software Development (not including school): 1 year (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)']",2020-08-08 13:44:52
"Senior Systems Administrator (Washington, D.C. or U.S. Remote)",Wallethub,N/A,"Washington, DC 20006","['10+ years of total work experience', '3+ years of experience in supporting AWS-based production infrastructure', '3+ years of experience administering UNIX/Linux server required (or equivalent work experience)', '3+ years of experience with Apache, Tomcat and any other Java application servers and relational database servers like MySQL (LAMP experience is highly preferred)', 'Experience with configuring and securing mission-critical production servers', 'Experience with configuring load balancers and data', 'Experience in Scripting, with experience implementing automation and monitoring using shell scripting and Python', 'Experience in analysis and system performance tuning', 'Critical thinking skills in a complex IT environment to analyze, troubleshoot, and resolve problems without direction', 'Outstanding organizational skills and the ability to handle multiple projects simultaneously while meeting deadlines', 'Excellent verbal and written communication skills', ""Bachelor's or Master’s degree in Computer Science (or equivalent work experience)"", 'Willingness to work hard (55hrs per week min.)', 'Experience with monitoring tools like Nagios, tripwire, aide and other custom monitoring tools', 'Ensure proper security, monitoring, alerting and reporting for the infrastructure and be the on-call for production servers', 'Develop security monitoring and other tools to ensure the integrity and availability of our applications, server resources, reviewing system and application logs', 'Work with the incident team to diagnose and recover from hardware or software failures working with or as the Incident Commander to coordinate and communicate with our internal customers', 'Assist project teams with technical issues during development efforts', 'Gather system requirements and support several project teams in evolving, testing, and rolling-out new products and services, then transitioning the site or product to post launch operations activities throughout the life of the product or service', 'Work with the application development team and other systems engineers to make improvements to current infrastructure', 'Document processes and procedures and follow a formal change management procedure', 'Very competitive salary based on prior experience and qualifications', 'Potential for stock options after the first year', 'Raise and advancement opportunities based on periodic evaluations', 'Health benefits (if working from our office in Washington, D.C.)', 'Visa sponsorship (if working from our office in Washington, D.C.)']",2020-08-08 13:44:52
Lead Data Engineer (AWS),TalentoHCM,4.3 out of 5,"Miami, FL","['Develop large scale data structures and pipelines to collect, organize, and standardize data that helps generate insights and addresses analytics and reporting needs with AWS Big Data Services such as: EMR, Glue, Kinesis, Lambda, KMS, S3, etc', ""You'll use Pyspark to integrate and work with RDD for real live computation"", 'Lead and mentor a team of Data Engineers in design and development in the Data Lake pipeline stories in an Agile team.', ""You'll coach team members in development and analysis of complex data pipeline scenarios"", 'Collaborate with data science, business intelligence, supply chain and other business units to transform data and integrate algorithms and models into automated processes', 'Experiment and Run Proof of Concepts with available tools and advise on new tools in order to determine optimal solution', '10+ years of experience in Data Engineering, Data Analytics with at least 3 years serving as a Lead or hands-on Manager', '5+ years of experience with AWS Big Data ecosystem, Scala, and Python', 'Strong knowledge in spark-python, knowledge of big data testing']",2020-08-08 13:44:52
"Big Data Engineer, Digital Innovation Team",TSYS,3.4 out of 5,"Alpharetta, GA","['Deep knowledge and experience designing and maintaining relational databases including PL/SQL , Oracle, MySQL, Postgres or SqlServer', 'Experience developing and supporting complex mission-critical production database systems', 'Broad awareness of customer workloads and use cases, including performance, availability and scalability', 'Experience analyzing issues holistically, from the application tier through the database, down to the storage', 'Awareness of emerging technologies and approaches in IT', 'Working knowledge of relational database internals (locking, consistency, serialization, recovery paths)', 'Working knowledge of at least one scripting language (shell, Python, Perl)', 'Coding skills in the procedural language for at least one database engine a must (PL/SQL, T-SQL etc.)', 'Proven track record of automating tasks', 'Root cause analysis of production-related database issues', 'On-call for production databases - daily maintenance, monitoring, problem resolution and internal customer and dev support', 'Excellent SQL and DB performance tuning skills', 'RDBMS (Postgres, Oracle, MySQL), Distributed SQL Engines (Cassandra, Foundation DB, Cockroach DB), NoSQL (Mongo DB), Hadoop, Data and Software Migration off/to RDBMS, AWS DBs (RDS, DynamoDB, EMR, Redshift, Aurora, etc.), Data Information Lifecycle Management, Data Security, Big Data....', 'Working with one or more streaming platforms, such as Apache Kafka, Spark Streaming, Storm, or AWS Kinesis', 'Track record of engineering performance and availability solutions', 'Exposure to cloud environments and architectures', 'experienced in various Clustering and Sharding architectures', 'Experience in Kubernetes will be a plus', ""Bachelor's Degree"", 'Relevant Experience or Degree in: Computer Science, Management Information Systems, Business or related field', 'Typically, Minimum 4 + Years Relevant Exp', 'Four-year college degree and 4 or more years, and/or a high school diploma with 8 or more years professional experience in full life cycle design and development to include IT architecture, banking industry experience, and understanding client requirements', ""Bachelor's Degree"", 'Relevant Experience or Degree in: Computer Science, Management Information Systems, Business or related field', 'Typically Minimum 8+ Years Relevant Exp', 'Four-year college degree and 8 or more years, and/or a high school diploma with 10 or more years professional experience in full life cycle design and development to include IT architecture, banking industry experience, and understanding client requirements']",2020-08-08 13:44:52
Principle Network Engineer,The Denzel Group,N/A,"Mechanicsburg, PA",[],2020-08-08 13:44:52
Data Engineer,OmniData Insights,N/A,"Portland, OR 97201","['You must be humble, hungry and a fast learner. OmniData and our clients place a high value on inventiveness.', '1+ years of experience in Analytics and Data Warehousing, with Azure knowledge a plus.', 'A technical mindset and strong business acumen.', ""Willingness to travel and work with a consultant's diligence."", 'The position will report directly to a founding partner of the company. As a consultant, you are also responsible to our clients.', 'We operate according to a methodology we call the Modern Data Estate Framework.', 'SQL Experience is required and Microsoft Azure experience is a plus.', 'Data Warehousing and Data Warehouse Automation', 'Azure, SQL Server, SSAS', 'Power BI, DAX', 'Requirements Analysis and Project Delivery methodology', 'Salary and benefits commensurate with experience.', 'High growth potential for those with an entrepreneurial spirit.']",2020-08-08 13:44:52
Data Analytics Engineer,Summa Health System,3.6 out of 5,"Akron, OH","['Bachelor’s degree in computer science, applied mathematics, statistics, or related discipline', 'Five (5) years of experience in a previous analytics role in healthcare domain involving healthcare data analysis to optimize business operations', 'Knowledgeable about the workings of integrated healthcare systems, health plan, research, and community programs', 'Experience in analyzing healthcare data using statistical methods to optimize business operations and communicating their findings using data visualization and detailed reports', 'Analytical mindset with good problem-solving skills', 'Excellent written and verbal communication skills', 'Acumen for analytics needs of an integrated health system how to use data to achieve those needs.', 'Ability to effectively interact with populations of patients/customers with an understanding of their needs for self-respect and dignity', 'Ability to summarize results and develop effective business presentations.', 'Ability to interact with populations both technical and non-technical, with an understanding of their needs for self-respect and dignity', 'Strong, critical thinker with ability to extend knowledge of information systems and applications to business processes and to cross team collaboration. Ability to explain complex, technical concepts to lay audiences and non-IT staff.', 'Basic knowledge of data warehousing, data marts', 'Experience with one or more Summa application platforms is desirable including Soarian Financials, DSS, HQ/HI, Epic/CarePATH and tools (RWB, Clarity, Caboodle, Radar, SlicerDicer, Registries), CostFlex, e-ClinicalWorks, GE Centricity, Lawson, Pentaho, SAS, Tableau.']",2020-08-08 13:44:52
Data Integration Engineer,"CGI Group, Inc.",3.6 out of 5,"Fairfax, VA 22038","['Design and develop utilities to extract data from applications using either API or directly from application database.', 'Design and develop utilities to transform, enhance and clean data in preparation for loading to target data-lake such a relational database or Elasticsearch.', 'Design and develop stored procedures for data validation.', 'Parse disparate data sources including XLS, XML, JSON and CSV files and load/output to similar formats.', 'Build logic to clean-up data and ensure compliance to defined data-dictionary.', 'Research on published APIs for identified tools with an intent to extract the data using right APIs and access points.', 'Test and debug custom data extraction utilities and validate the data feed requirements that are part of the data pipeline.', 'Update and maintain the data extraction utilities to comply with the changes in data sources.', 'Due to the nature of the government contract requirements and/or clearance requirements, US citizenship is required.', 'Candidates must have ability to obtain and maintain a DHS EOD/Public Trust clearance.', 'Knowledge of Security Content Automation Protocol (SCAP) data models.', 'Experience in data mapping, extraction and integration in the context of SCAP validated products, e.g. Tenable, Qualys and Tripwire.', '3-5 years of experience in developing applications/utilities using Python, JavaScript PowerShell and SQL.', 'Thorough understanding and experience in data formats including JSON and XML.', 'Experience in data extraction using APIs.', 'Experience in application integration.', 'Experience developing client applications using data APIs.', 'Experience with functional, regression and load/performance testing.', 'Experience with relational databases.', 'Experience working in an Agile environment.', 'Prior experience working for/on federal client sites.']",2020-08-08 13:44:52
Healthcare Data Engineer,UnitedHealth Group,3.7 out of 5,"Raleigh, NC 27601","['Job', 'Company', 'Maintain, improve, clean, and manipulate data in the business’s operational and analytics databases', 'Design and deploy data platforms across multiple domains ensuring operability', 'Transform data for meaningful analyses', 'Improve data efficiency, reliability and quality', 'Create data enrichment', 'Build high performance', 'Ensure data integrity', 'Create and manage data stores at scale', 'Ensure data governance - security, quality, access and compliance', 'BS/BA or equivalent experience', '5+ years of experience designing, coding and supporting distributed, data intensive systems at scale', '4+ years of experience in Agile Delivery', 'Experience with healthcare data', 'Knowledge and understanding of health care privacy and security practices', 'Hands-on experience with data transformations / ETL', 'Experience and working exposure in cloud environment, preferably Azure.', 'Hands-on experience of big data and streaming frameworks - Kafka , Hadoop, Hive, spark, HDFS.', 'Hands-on experience on using PAAS like - Kubernetes, Openshift', 'Hands-on experience on working on CI/CD platform and monitoring - namely Github, Jenkins, Grafana, Prometheus.', 'Hands-on experience on programming languages - Go, python, scala, java.', 'Hands-on experience in full automated testing framework (unit & integration),cucumber, spock, Go unit test, Junit.', 'Excellent communication skills with ability to describe data/capability stories and explain value to customers']",2020-08-08 13:44:52
ETL Data Engineer (BHJOB1435_25285) - CZ,Astyra Corporation,4.3 out of 5,"Richmond, VA","['Design, Develop and maintain secure, consistent and reliable ETL solutions supporting critical business processes across the various Business Units.', 'Ensure data solutions are compliant with enterprise security standards', 'Work in complex multi-platform environments on multiple project assignments.', 'Develop and perform tests and validate data flows and prepare ETL processes to meet complex business requirements, including designing and implementing of complex end-to-end solutions using BI platforms.', 'Coordinate with analysts and developers to ensure jobs designed and developed meet minimum support standards and best practices before migration into the production environment.', 'Partner with various infrastructure teams, application teams, and architects to generate process designs and complex transformations to various data elements to provide the Business with insights into their business processes.', 'Uses strategies such as Indexing and partitioning to fine tune the data warehouse and big data environments to improve the query response time and scalability.', 'Define and capture metadata and rules associated with ETL processes.', 'Assist production support team in providing resolutions to production job failures, data issues and performance tuning ETL Development and Process Support, may require weekend/off business hours work.', 'Strong understanding of Data warehousing (Dimensional Modeling, ETL etc.) and RDBMS concepts', 'Minimum 5 years working experience with ETL tools such as Talend, Informatica, Data Stage etc', 'Minimum 5 years working experience in SQL, Stored Procedures and Table Design', 'Minimum 5 years working experience in SQL Query optimization and ETL Data loading Performance', 'Experience as a Data Engineer in Hadoop Platforms on components like HIVE, KAFKA, NiFi, Spark etc is a big plus.', 'Minimum 2 years working experience in shell scripting', 'Experience in real time streaming technologies is preferred', 'Experience deploying machine learning models and automating processes in production is a plus', 'Experience with cloud technologies(AWS, Azure, GCP) is big plus', 'Dental Insurance', 'Health Insurance', 'Vision Insurance', 'Day shift', 'Monday to Friday', 'ETL: 5 years (Required)', 'Are you a U.S. Citizen or Permanent Resident?', 'Possible', 'One location', 'No: Not providing sponsorship for this job', 'Waiting period may apply']",2020-08-08 13:44:52
Researcher,BBE Marketing Inc,N/A,"Fort Worth, TX","['Research contact information utilizing different tools', 'Create and manage guides for different tasks', 'Create and optimize processes for different tasks', 'Verify and perform quality control on the data in our database', 'Collaborate with other team members in meeting goals', 'Excellent time management skills', 'Very Strong Attention To Detail', 'Solid organizational skills', 'Strong Communication skills', 'Strong writing abilities', 'Ability to work effectively within a team.', 'Strong work ethic', 'Need to be available to respond to inquiries outside of hours', 'Courage to give honest feedback and also take honest feedback', 'Take ownership, and come up with ideas to improve our company', 'Take time to learn about our industry, customers, and our partners', 'You are thoughtful and clear in your writing.', 'You have strong problem solving skills and critical thinking abilities.', 'Must be fluent in English (Required)', 'English (Required)', 'Why do you believe you are a good fit for this position?', 'Likely', 'Fully Remote', 'Monday to Friday', '8 hour shift', 'Yes']",2020-08-08 13:44:52
Software Quality Engineer,Pearson,3.8 out of 5,"Boston, MA",[],2020-08-08 13:44:52
Sr. Manager Data Engineer,Capital One,3.9 out of 5,"McLean, VA 22101","['Demonstrate both effective people management and disciplined software and data engineering leadership.', 'Work with product owners to understand desired application capabilities and testing scenarios - continuously improving software engineering practices.', 'Lead Agile teams to design/implement cutting-edge technologies, and support technical solutions across a full-stack cloud technologies with operational disciplines.', 'Bring a passion to stay on top of tech trends, experiment with and learn new technologies, and encourage innovation.', 'Engage in internal & external technology communities, and mentor members of the engineering community.', 'Collaborating as part of a cross-functional Agile team to create and enhance technology solutions that enables state of the art, next generation Big Data applications.', 'Lead, manage and grow multiple teams of product focused software and data engineers', 'Mentor and guide the professional and technical development of engineers on your team', 'Drive long-term strategy for the HR Data Warehouse Platform', 'Manage the development pipeline of distributed computing Big Data applications using Open Source frameworks like Apache Spark, Scala and Kafka on AWS Cloud', 'Utilizing programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift', 'Leveraging DevOps techniques and practices like Continuous Integration, Continuous Deployment, Test Automation, Build Automation and Test Driven Development to enable the rapid delivery of working code utilizing tools like Jenkins, Maven, Nexus, Chef, Terraform, Ruby, Git and Docker', 'Enforce company policies in areas of development methodology, architecture, security, change and configuration management, and compliance.', 'Ensure quality testing and conduct reviews with other team members to make sure code is rigorously designed, elegantly coded, and effectively tuned for performance', 'Enable and promote custom solutions with a “You Build, You Own” philosophy.', 'Bachelor’s Degree', 'At least 6 years of experience in software development', 'At least 5 years of experience in data warehousing or analytics', 'At least 1 year of experience with data engineering', 'At least 1 year of experience with data modeling', 'At least 1 year of experience deploying, monitoring and maintaining a Cloud-based application', '5 years of experience building software including systems and application design, code development and testing.', '3 years of experience in scripting language (Python, Perl, JavaScript, Shell)', '3 years of experience with UNIX/Linux environments', '1 year of experience in Python, Scala, or R for data analysis', '1 year of experience with the Hadoop Stack', '1 year of experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink)', '1 year of experience with Amazon Web Services (AWS) or Microsoft Azure or another public cloud', '1 year of experience with the Hadoop stack (MapReduce, Pig, Hive and Hbase)', '1 year of experience with MySQL, Postgres, Redshift, Snowflake.']",2020-08-08 13:45:35
Software Development Engineer II Data,Audible,4 out of 5,"Newark, NJ 07175","['Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet business needs', 'Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices', 'Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications', 'Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines', 'Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts', 'Peer review work. Actively mentor other members of the team, improving their skills, their knowledge of our systems and their ability to get things done']",2020-08-08 13:45:35
"Manager, Technical Program Management - Staff Augmentation",Indeed,4.3 out of 5,Remote,"['Lead and improve the Outpost Delivery Program which is focused on staff augmentation for Product and Engineering teams. Drive delivery of project work through other project managers, Indeed and 3rd party vendors.', 'Step in to manage projects or aspects of projects within the programs you own, as needed.', 'Partner with the program sponsor and stakeholders to help define the program OKRs and roadmap.', 'Demonstrate proficiency in program strategy and execution within the business domain.', 'Understand and evangelize your program’s strategy and its benefits for Indeed.', 'Anticipate and mitigate risk by conducting assessments across the program to determine if the implementation plans meet stakeholder requirements and will achieve strategic objectives.', 'Apply analysis based on in-depth research and interpretive thinking. Evaluate and recommend solutions from various options.', 'Lead your program team and deliver strategic value. Collaborate across Indeed with senior stakeholders and other program managers.', 'Use communications effectively to inform and influence your intended audiences. Proactively network with relevant stakeholders across Indeed to advocate for the needs and success of your program.', 'Identify core problems or opportunities within business processes. Understand the root cause and impacts for the project and other teams. Communicate and collaborate with the right people to implement timely solutions.', 'Help your program team or other more junior program and project managers to refine their individual project management skills and behaviors. Provide opportunities to others to help close their skill gaps.', 'Coach and advocate for your program team at the leadership level on a quarterly basis outlining value delivered and career development next steps, and be able to align them to organizational goals and objectives.', 'Ensure standards for communications and reporting are being followed. Monitor and provide feedback on communications of your team. Maintain a cultural awareness in your communications.', 'Influence across the team leadership level to solve problems affecting how the teams we work with get their work done.', 'Make data-driven decisions', 'You have significant agile/lean experience in organizations leveraging lean/agile methodologies and in-depth experience with specific agile methodologies such as Scrum, Kanban, or SAFE.', 'You have led multiple technical programs for a technology company, leading cross-functional teams to take products to market, ensuring success metrics are informing future efforts, and fine tuning the program as needed.', 'You have executed corporate-wide initiatives: defined project plans, coordinated resources, managed implementation activities, and developed all processes associated with program rollout and ongoing support.', 'You capable of elicit high-level requirements from both business and technical stakeholders, and can translate those into a detailed, prioritized backlog of work actionable by systems engineers and software developers.', 'You develop innovative solutions and collaborate with global counterparts and cross-functional teams to implement them.', 'You love decomposing and defining workflows and processes.', 'You have experience defining and reporting on operational metrics and generating problem statements that are supported by data you have compiled.', 'You can analyze information to find trends or diagnose problem areas.', 'You have a bias for action and work comfortably with ambiguity.', 'You are respectful and influential; you have the ability to push back when needed and can approach work rationally.', 'You are successful at getting buy-in for your ideas with a demonstrated affinity for metrics.', 'You are comfortable talking about technical matters with business people and business matters with technical people.', 'You can assess project risks and identify appropriate mitigation strategies.', 'You can identify and implement process design and re-engineering to achieve both incremental and transformational business impact.', 'You have experience influencing senior management and setting expectations for major cross-functional initiatives.', 'You have worked closely with software engineers, QA, product managers and other engineering teams to get high-quality products and features through the software project lifecycle (build, test and release on time).', 'You have 3+ years experience working with third party engineering resources embedded with development teams, particularly in a client services environment.', 'You have 8+ years experience working as a software project manager with experience leading complex cross-functional projects in a technology company and preferably, a degree in engineering.']",2020-08-08 13:45:35
Quality Assurance Engineer,TechServe,N/A,"Plano, TX 75093","['Assist in QA defect management process, monitor and report on defect resolution to management. Apply corrective action/remediation measures as needed for process/quality improvement utilizing action plans and Lean Six Sigma tools', 'Analyze data (findings, defects, trending, etc.) making recommendations on areas for improvement and best practices. Identify gaps in business processes, documentation and or training and provide solutions/recommendations to management', 'Develop test scripts/new audits utilizing comprehensive business requirements, functional documentation and processes', 'Design test cases and execute all types of testing (e.g. functional, integration, end-to-end) on a variety of platforms (e.g. mobile, web, portal frameworks)', 'Assist project teams in determining appropriate quality goals and acceptance criteria', 'Coordinate with project teams on the timing and priority of QA testing needs', 'Understand and implement automated testing scenarios using software Identify and track bugs, regression issues, and enhancement requests', 'Keep track of and report on testing progress and results', 'Understand deployment strategy and testing environments', 'Ability to create test plans and test cases', 'Perform manual and automated testing', 'Review user interfaces for consistency and functionality', 'Working knowledge of technology best practices, methodologies and processes (e.g., ITIL, CMM, Agile, Scrum, DevOps)', 'General experience or knowledge of relational database concepts, software design concepts, and database modeling preferred.', 'Solid understanding of SQL and queries preferred.', 'Experience in Tolling industry a plus', ""Minimum 5 years' experience in SDLC Process with a focus on test planning, test execution and defect management."", 'Day shift', 'Monday to Friday', 'Coordinate Measuring Machine: 5 years (Preferred)', 'SDLC: 5 years (Preferred)', 'SQL: 5 years (Preferred)', 'Tableau: 5 years (Preferred)', 'Business Intelligence: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'Plano, TX 75093 (Preferred)', 'United States (Required)', 'Likely', 'One location', 'www.techiservice.com', 'No']",2020-08-08 13:45:35
Data Architect,UnitedLex,3.7 out of 5,"Atlanta, GA","['Minimum total of 8 years in information technology', 'Minimum 4 years hands-on experience in BI/DW design, development, and implementation', 'Strong ability to design and deliver enterprise data warehouse and business intelligence platforms', 'Ability to collaborate with technical and non-technical individuals to solve complex business problems', 'Ability to understand needs within the context of a specific organization and identify appropriate technology solutions to maximize ROI with the solutions that are implemented', 'In-depth understanding of a wide range of database systems and architecture practices', 'In-depth experience with designing, administering and maintaining Microsoft SQL Server and Databases', 'Experience with architecting star, snowflake galaxy schemas for data modeling', 'Experience in analysis and selection of BI platforms based on the data topography and needs of an organization', 'Experience with a major ETL tool, preferably Azure Data Factory', 'Experience with OLAP model and OLTP database models', 'Experience with Azure Data Bricks/Azure Synapse / Azure Analysis Services / (DW)/ADLS preferred', 'Experience with self-service BI tools, preferably PowerBI and the DAX language', 'Experience with cloud and hybrid data topographies', 'Experience working with various third-party data sources (MS Dynamics AX, HR/ERP systems, Salesforce, etc.) and connections to these through APIs as well as direct-to-DB and flat files', 'Experience maintaining data quality and integrity in a complex and ever-changing data environment', 'Experience maintaining source code in Git and managing a CI/CD pipeline, preferably with Azure DevOps', 'Experience with Python and R programming languages is a plus', 'Firm understanding of web applications and/or other distributed application architectures', 'Exposure to unstructured/semi-structured data systems (NoSQL) is preferred', 'Strong organization skills and high attention to detail', 'Ability to multi-task with good decision-making, analytical and problem-solving abilities', 'Ability to learn the intricacies of a new industry and move through new topics at a rapid pace', 'Excellent oral, written, presentation and interpersonal communications skills; Ability to effectively exercise tact, discretion, judgment and diplomacy when interacting and/or negotiating with internal and external customers', 'Ability to present and explain technical information in a way that establishes rapport, persuades others, and gains understanding', 'Ability and willingness to accept responsibility, willingness to challenge established practices and draw relevant conclusions, including the persistence and willingness to take calculated risk, to stimulate, market and sell new ideas within the organization.', 'Bachelor’s degree (preferably in Computer Science, MIS, or a related field) OR equivalent work experience required', 'Analyze BI needs, recommend BI solutions and strategy, design and implement an enterprise BI platform', 'Map out enterprise data systems/objects and define/design required ETL systems/processes', 'Document and maintain architectural design, technical configuration and mapping', 'Document and maintain best practices, standards, and processes for managing the BI/DW systems and services', 'Recommend on-going improvements to business and technology processes related to BI needs and solutioning', 'Lead, provide technical guidance, and serve as a mentor to other team members', 'Participate in technology leadership meetings to provide feedback and recommendations to the other leaders', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', 'Azure: 4 years (Preferred)', 'Business Intelligence: 4 years (Preferred)', 'One location', 'Fully Remote', 'www.unitedlex.com', 'Yes']",2020-08-08 13:45:35
Network Engineer,Gridiron IT,4 out of 5,"Washington, DC","['Scope', 'End-to-End WAN/LAN Network Architecture Design and Implementation', 'Current circuit information for all locations including:', 'Circuit Provider', 'Current Bandwidth and Utilization', 'Needs for Additional Bandwidth or Possible Circuit Consolidation', 'Failure Analysis and Stakeholders Related to Each Circuit', 'Risk Analysis and Mitigation Procedures Related to the Transport Circuits', 'Recovery Procedures in the Event of a Failure', 'Network Optimization and Design Recommendations (hardware agnostic)', 'End-to-End WAN/LAN Network Design Validation', 'A review of the current network security measures in place through both the MPLS network and the MTIPS firewalls.', 'A review of vulnerabilities in the network that affect stability and reliability.', 'A detailed analysis of the current utilization of each circuit, including not only the bandwidth utilization, but actual application utilization and recommendations to improve availability and performance.', 'An overview of application dependencies that are related to the network circuits and equipment from the server all the way to the end user, identifying the related equipment, potential failure points, and recommendations for improvement.', 'A complete and verified map of the customer’s network.', 'An overall health assessment of the network.', 'End-to-End Evaluation of Network Alternative to Improve Performance', 'The state of the customer’s network in relation to current industry standards and best practices.', 'Recommendations for new and emerging technology that can be implemented that can increase efficiency, increase reliability, and decrease costs.', 'Recommendations for topology and design changes that can improve overall network reliability.', 'The risks and rewards associated with each of the recommendations provided to the customer.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Flexible Schedule', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Network Engineering: 4 years (Required)', 'LAN/WAN Network Architecture: 4 years (Required)', ""Bachelor's (Required)"", 'Secret (Required)', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:45:35
Data Analytics Engineer,Summa Health System,3.6 out of 5,"Akron, OH","['Bachelor’s degree in computer science, applied mathematics, statistics, or related discipline', 'Five (5) years of experience in a previous analytics role in healthcare domain involving healthcare data analysis to optimize business operations', 'Knowledgeable about the workings of integrated healthcare systems, health plan, research, and community programs', 'Experience in analyzing healthcare data using statistical methods to optimize business operations and communicating their findings using data visualization and detailed reports', 'Analytical mindset with good problem-solving skills', 'Excellent written and verbal communication skills', 'Acumen for analytics needs of an integrated health system how to use data to achieve those needs.', 'Ability to effectively interact with populations of patients/customers with an understanding of their needs for self-respect and dignity', 'Ability to summarize results and develop effective business presentations.', 'Ability to interact with populations both technical and non-technical, with an understanding of their needs for self-respect and dignity', 'Strong, critical thinker with ability to extend knowledge of information systems and applications to business processes and to cross team collaboration. Ability to explain complex, technical concepts to lay audiences and non-IT staff.', 'Basic knowledge of data warehousing, data marts', 'Experience with one or more Summa application platforms is desirable including Soarian Financials, DSS, HQ/HI, Epic/CarePATH and tools (RWB, Clarity, Caboodle, Radar, SlicerDicer, Registries), CostFlex, e-ClinicalWorks, GE Centricity, Lawson, Pentaho, SAS, Tableau.']",2020-08-08 13:45:35
2020 Software Engineer Intern,Bloomberg,3.9 out of 5,"New York, NY","['Take ownership of projects under the guidance of your mentor', 'Be a collaborative member of your team', 'Have a deep understanding of data structures and algorithms', 'Be an excellent problem solver', 'Have programming experience in C, C++, Java or Python', 'Have a minimum GPA of 3.0', 'Be working toward a BA, BS, MS or PhD in Computer Science']",2020-08-08 13:45:35
Healthcare Data Engineer-Telecommute considered,UnitedHealth Group,3.7 out of 5,"Raleigh, NC 27601",[],2020-08-08 13:45:35
Remote Data Engineer / ETL,Kforce,3.8 out of 5,"Dallas, TX","['Work under data/solution architects to deliver enterprise class data structures and solutions and/or integration into custom product development', 'Help define data matrices, data dictionaries, data structures across various topologies (SQL Server 2016, Hadoop/Cloudera stacks, etc.)', 'Complete product technical design and prototyping, data design/development, support and problem remediation', 'Understand data design patterns and enterprise design regarding data in the Payments Industry (banking, credit unions, bill pay, EFT, etc.) within both commercial off the shelf (COTS) and custom solutions', 'Provide both individual, team, and budget-level tasks and product effort estimates/costs and overall LOE regarding data efforts', 'Document technical designs, using flow charts, class diagrams, sequence diagrams, activity diagrams, data flow diagrams, database schemas, descriptive software component documentation, wireframes', 'Develop and test applications based on business requirements and industry best practices', 'Creates required technical documentation, use cases, white papers, system and deployment architecture, and technical process/pro', ""Bachelor's degree preferred; business, software and infra engineering, or computer science degree preferred"", 'Minimum of 8 years hands-on experience with enterprise class database development, focused on transactional environments w/focus around SQL 2012/2014/2016; including redundancy modeling (Disaster Avoidance/Recovery), cross data center high availability, always on, horizontal and vertical scalability, and various forms of data movement (log shipping, replication modeling, Always On, etc.)', 'Minimum of 6 years of technical experience in data modeling and design, or development', ""5 years'+ experience with analytics, dashboard tooling, and ETL toolsets in large enterprise-based payments/banking industry"", 'Experience in Banking/EFT/Financial Institution domain and based technologies; along with data layer experience w/ ISO8583 in a cutting-edge enterprise', '6+ years hands-on understanding enterprise systems, infrastructure, software design and development, database design and development, and system integration experience', 'Experience working collaboratively with Stakeholders, Business Analysts, Project Managers, Designers and DBAs with the common goal of delivering value to the business', 'Encryption based development via Host Security Modules and adherence to PCI compliance and requirements', 'Focused on innovation and cutting-edge technologies within a five nines environment (99.999% uptime)', 'Experience with Continuous Integration and Test-Driven Development techniques']",2020-08-08 13:45:35
Data Engineer - Teradata,PNC Financial Services Group,3.6 out of 5,"Pittsburgh, PA 15233","['BS in a STEM related degree plus 3+ years of related experience.', 'Working knowledge and experience with ETL & Teradata framework', 'Teradata Graf Database & query optimization techniques', 'Develop Teradata engineering practice & capabilities in PNC’s Adhoc Lab environment', 'Assist user community during platform on-boarding process', 'Building and monitoring surveillance to address platform stability issues', 'Support the closure of audit, regulatory and other control function finding', 'Understand the PNC-IRM risk management practices.', 'Experience in Hadoop & Python is a plus but not required.', 'Data Integration: Applications for acquiring data, interpreting the data, and applying logic to transform data into relational analytics objects.', 'Data Processing (including Data Science): Consume enterprise data to produce actionable insights to drive business functions. Integrate Data Science capabilities to enhance decision-making and enable autonomous learning.', 'Data Management: Manage the content of the analytics ecosystem, including data lineage, metadata management, data quality, data patterns, and more.', 'Data Presentation: Prepare data for human consumption through BI data visualizations', 'Data Services: Applications for presenting data for programmatic consumption, including complex analytical data.', 'Collaborate with architects and other engineers on application design and framework enhancements.']",2020-08-08 13:45:35
Backend Software Engineer,"Appfigures, Inc.",N/A,"New York, NY 10002","['You have mastered a programming language of your choice. You are likely sick and tired of writing Fizz Buzz. We mainly use C# and Python, but it’s okay if you don’t know them. We think that being a capable developer in one language implies you’d be able to get comfortable with most languages or environments. We are always open to trying new things to figure out what the best tool for the job is and hope you are too.', 'You have a disciplined approach to development, testing, and quality assurance. We know perfection isn’t possible, but we think about the trade-offs inherent in our designs and guard against them up front. Folks rely on our data to run their businesses, so it’s important that we get it right.', 'You recognize that sometimes you need to throw away the prototype (and sometimes you need to ship it). We think it’s OK to experiment and we understand that sometimes you don’t know if something will work until you try it. And sometimes that thing you tried just didn’t work.', 'You can write clean, fast, and efficient code while keeping in mind the bigger context of what we are doing and why. We wouldn’t do this if it weren’t fun, but we know that at the end of the day the software we build is to simplify the lives of our customers.', 'You’re looking forward to getting to know our users. We rotate escalated support duties across the team. It’s an opportunity for everyone to see how our users interact with the platform, what they need next, and what could be improved.', 'You’re willing to try new things in a collaborative environment. We’re a small team so responsibilities are flexible. We are a place where initiative beyond the job description is rewarded. We want you to feel empowered to commit or critique in any part of our codebase or company. We want you to feel empowered to take features from an idea all the way to our users. We think every team member’s perspective and opinion is important, and taken together will help make the best product we can.', 'A BS / MS in Computer Science or related field-- a degree means less to us than proven ability.', 'Contributions to open source projects, blogs, books, and StackOverflow or work experience.', 'Experience with the web, the software and hardware behind it, scraping, and performance analysis.', 'Integrating a new datasource or API integration to ingest new datasets mobile app developers need to run their businesses.', 'Scaling a critical scraping service.', 'Diagnosing and fixing performance issues in our API.', 'Working with sales, marketing, and others on the product and engineering teams to envision and create new products and features for our users.', 'Helping the data science team turn ML models into production-grade products.', 'Great medical, dental, and vision insurance', '401(k) retirement plan', 'Pre-tax transit benefits, subsidized gym memberships and excellent discounts on hundreds of other well-known services and products', 'Plenty of paid time-off and flexible remote work policy', 'Awesome work station with whatever you need to be happy and productive', 'A fully stocked kitchen with a variety of snacks and drinks', 'Monthly personal project days', 'Weekly catered lunches', 'Events for employees and members', 'Software Development (not including school): 1 year (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)']",2020-08-08 13:45:35
Quality Assurance Engineer - BM,BioMedtrix,4 out of 5,"Whippany, NJ 07981","['Assist in establishing, implementing, and maintaining the quality management system.', 'Root cause analysis and implementation of corrective action for process-related concerns.', 'Develop training to build quality awareness.', 'Interface with Engineering and Operations to ensure transfer to Production of new products are in accordance with approved data.', 'Conduct audits, including closing out audit findings, creating audit finding reports and determine proper corrective and preventive actions.', 'Analyze failure, corrective and preventive action to respond to customer complaints.', 'Create and maintain company quality documentation, such as quality manuals, quality procedures, etc.', 'Ensure timely resolution of supplier failure, corrective actions and preventive actions.', 'Manage suppliers’ performance and conduct audits.', 'Preparation of QA reports.', 'Continual improvement activities to enhance the quality system, such as Six Sigma, 5S, Kaizen lean methods, etc.', 'Validation functions', 'Establish, implement and direct validation and revalidation activities in accordance with appropriate regulatory agency validation requirements, internal company procedures, and current industry practices.', 'Support and conduct validation studies, qualifications, technology transfer activities, process characterization studies, statistical analysis of results using Minitab or equivalent to identify critical parameters and improve process capability and gauge R&R studies within the Manufacturing Process.', 'Contribute to the preparation and review of the Validation Master Plan', 'Provide guidance on project teams as a technical subject matter expert on validation regulations/procedures for equipment/process validation requirements for new product development projects. Coordinate the execution of validations in accordance with defined protocols by Operations, Quality Control, and R&D teams.', 'Support/conduct IQ, OQ, PQ validation studies of equipment and processes, utilities, and software validations.', 'Liaise with contract manufacturers and suppliers to develop protocols, coordinate validation activities, and compose reports where appropriate for equipment qualifications and process validations.', 'Develop/review and approve validation protocols and final reports.', 'Ensuring completion of validation protocols.', 'Generate and resolve protocol discrepancies or deviations.', 'Optimize the Quality System Validation program.', 'Organize and maintain the validation documentation system in conjunction with document control personnel.', '401(k)', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Quality Assurance: 3 years (Required)', 'Medical Device : 1 year (Required)', 'Solid Works: 1 year (Required)', ""Bachelor's (Required)"", 'ASQ Certified Quality Engineer (Preferred)', 'Six Sigma or Lean (Preferred)', 'One location', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'A job for which military experienced candidates are encouraged to apply', 'www.vetimplants.com', 'Waiting period may apply', 'No']",2020-08-08 13:45:35
Lead Data Engineer (AWS),TalentoHCM,4.3 out of 5,"Miami, FL","['Develop large scale data structures and pipelines to collect, organize, and standardize data that helps generate insights and addresses analytics and reporting needs with AWS Big Data Services such as: EMR, Glue, Kinesis, Lambda, KMS, S3, etc', ""You'll use Pyspark to integrate and work with RDD for real live computation"", 'Lead and mentor a team of Data Engineers in design and development in the Data Lake pipeline stories in an Agile team.', ""You'll coach team members in development and analysis of complex data pipeline scenarios"", 'Collaborate with data science, business intelligence, supply chain and other business units to transform data and integrate algorithms and models into automated processes', 'Experiment and Run Proof of Concepts with available tools and advise on new tools in order to determine optimal solution', '10+ years of experience in Data Engineering, Data Analytics with at least 3 years serving as a Lead or hands-on Manager', '5+ years of experience with AWS Big Data ecosystem, Scala, and Python', 'Strong knowledge in spark-python, knowledge of big data testing']",2020-08-08 13:45:35
Sr. Data Engineer,Kaygen,3.3 out of 5,"San Diego, CA","['4+ years working experience in data integration and pipeline development.', 'BS degree in CS, CE or EE.', '2+ years of Experience with AWS Cloud on data integration with Apache Spark, EMR, Glue, Kafka, Kinesis, and Lambda in S3, Redshift, RDS, MongoDB/DynamoDB ecosystems', 'Strong real-life experience in python development especially in pySpark in AWS Cloud environment.', 'Design, develop test, deploy, maintain and improve data integration pipeline.', 'Experience in Python and common python libraries.', 'Strong analytical experience with database in writing complex queries, query optimization, debugging, user defined functions, views, indexes etc.', 'Strong experience with source control systems such as Git, Bitbucket, and Jenkins build and continuous integration tools.', 'Databricks or Apache Spark Experience is a plus.', 'Monday to Friday', 'AWS: 2 years (Required)', 'Spark: 3 years (Required)', 'pyspark: 3 years (Required)', 'databricks: 1 year (Required)', 'Likely', 'One location', 'kaygen.com', 'Temporarily due to COVID-19']",2020-08-08 13:45:35
Sr. Data Engineer,Brooksource,3.8 out of 5,"Wyoming, MI","['Data engineering background working with data pipelines and GCP infrastructure (or underlying open source products)', 'Experienced in an Agile development environment (SAFe would be a bonus)', 'Strong experience with Python Scripting', '5+ years’ experience working with Oracle Database and SQL Server.', 'Must be able to extract large amount of data and move large amounts of data', '5+ years’ experience with SQL Scripting and ability to write both simple and complex SQL Queries', 'This role will be working directly with the data lake team to build out the data platform infrastructure as well as the data pipelines to move data from the source into the data platform (GCP).', 'Extract data from legacy systems supported on Oracle Database/SQL Server into Google Cloud Platform (GCP)', 'Interface with various technical teams including core data application team and database/ data services teams.', 'Help build out the governance strategy on the data platform.', 'Must have a willingness to learn and the ability to pick up new concepts quickly. They must be able to build tools incrementally instead of in a “big bang” manner. Developers must be an advocate for the business value behind the technical work. Can take direction from the lead while working independently towards a result', 'Opportunity to join a very innovative technical team utilizing cutting edge technologies.', 'Collaborative, Agile work environment', 'Family-oriented organization; Contractors treated as FTE’s', 'Health, Dental, and Vision Insurance', 'Dental Insurance', 'Health Insurance', 'Vision Insurance', 'Monday to Friday', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:46:22
Data Engineer,AccruePartners,3.8 out of 5,"Huntersville, NC","['Supply Chain & Technology leader redefining a consumer market with $60B in direct industry output (US)', 'Private-equity backed with massive transformation occurring across the company', 'Engaged leadership from Fortune 100 companies; creating a world-class company culture', 'Exciting career adventure - chance to be at the forefront of the business transformation and expected to play a key support role in the on-going process', 'Professional development; company is hiring A++ players across the company', 'Great exposure; this person will be building relationships at all levels including the executive team and C-level daily', 'Excellent benefits and work environment', 'Work with data scientists to architect and flood static data models to enable the development of Machine Learning and other statistical models', 'Build ETL jobs and streaming processes based on jointly defined requirements for the data pipeline', 'Identify, analyze, and interpret trends or patterns in complex data sets o Translate insights into predictive power by assisting data scientists with feature engineering in Python', 'Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality', 'Support the bug fixing and performance analysis along the data pipeline o Analyze and manage 3rd Party and other external data sets', 'Follow an agile development methodology', '1-3 years of experience of data models, database design development, data mining and data cleaning techniques', 'Strong experience with Python/R, SQL and shell script', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'Understanding of the fundamentals of statistics and machine learning o Experience with database design and development', 'Knowledge of Cloud environment', 'Experience in UNIX or Unix-like system', 'Experience working in start-up environment or organizations with an agile culture', 'Professional attitude and service orientation; superb team player']",2020-08-08 13:46:22
BI Solutions Engineer,Fidelity TalentSource,3.7 out of 5,"Boston, MA 02210","['5+ years of industry experience as a BI solutions engineer and developer.', 'B.S. degree in math, statistics, computer science, or equivalent technical field', 'Experience with report development, data science, business analytics, business intelligence or comparable data engineering role, including data warehousing and business intelligence tools, techniques and technology.', 'Skills in developing interactive dashboards and impactful visualizations with OBIEE and Tableau.', 'Knowledge of ETL and data warehouse concepts and processes.', 'Knowledge of SQL to write sophisticated, highly-optimized queries across large volumes of data.', 'Experience with R, Python and D3 will be a plus. Familiarity with Spotfire will be useful for transitioning the legacy reports to Tableau.', 'You can explain complicated or technical information in a simple way to non-technical audiences.', 'You have an ability to set realistic expectations and prioritize within a dynamic and shifting environment', ""You are sensitive to clients' needs and have an ability to develop relationships and engage users."", 'You have curiosity and passion about data, visualization and solving problems.', 'You have creativity to determine the best solution for a real-world problem with quantitative data.', 'You have willingness to question the validity, accuracy of data and assumptions.', 'Understanding your business user’s objectives, the metrics and visualizations that are the most important to them, and how to best deliver impactful insights.', 'Recommending the right BI tool and implementation strategy given the problem statement.', 'Turning business requirements into technical requirements.', 'Coding reports, dashboards, and visualizations to help your partners gain insight.', 'Learning from and sharing knowledge and skills with your peers to grow BI’s total impact to the organization.', 'Crafting, building, deploying and maintaining BI solutions (primarily with Tableau and OBIEE).']",2020-08-08 13:46:22
Software Engineer,TakeOut7 Inc.,N/A,"Hartford, CT 06103","['Excellent programming skills with a strong interest in web application development', 'Strong knowledge of data structures and algorithms', 'Multiple web tech stack experience especially with TypeScript, JavaScript, CSS, HTML5, is required.', 'Experience with Angular, React or any other TypeScript application framework is highly desirable.', 'Experience with one or more of the followings – Unix/Linux, MS-Windows, C#, .NET, Microsoft SQL Server, Xamarin, iOS & Android platforms, Amazon Web Services is a plus.', 'Experience with Cloud Native AWS applications and solutions like API Gateway, Lambdas, Cognito and DynamoDB are a major plus.', 'Interest in internet e-commerce', 'Technology and problem solving aligned to solving real world business problems', 'Excellent communication, analytical, interpersonal, and organization skills required', 'Organizational and time management skills with the ability to adjust to changing priorities in a fast-paced environment', 'Entrepreneurial/Start-up mindset', 'Applies functional knowledge and techniques necessary to gather or draw out requirements from data analysis, research and discussions with stakeholders.', 'Analytical thinking and problem-solving abilities and ability to manage multiple projects and stakeholder expectations', 'Empathy and willingness to support non-technical staff resolve customer issues', 'Ability to adapt to change and willing to learn and develop new skill sets as applicable', 'Ability to work and communicate effectively with both business and technical communities', 'Write end to end testing scripts using Selenium to automate all functional testing and to build regression test suites', 'Interest in Object Oriented Programming, Functional Programming, Distributed Programming & Micro Services', 'Develop Web front ends using HTML5, CSS, TypeScript leveraging Angular.', 'Write AWS serverless Lambda TypeScript code leveraging Node.js', 'Write C# code leveraging .NET, ASP.NET, Core etc.', 'Write mobile apps using C# and Xamarin for the iOS & Android platforms', 'Familiarity with Unix', 'Interest in Relational DBMS & NoSQL DBMS', 'Pride of ownership & burning desire to write high quality high performance code', 'Intellectual curiosity coupled with a desire to exceed customer expectations', 'Effective self-starter with a can-do attitude who takes ownership and accountability for project deliverables with a demonstrated ability to multitask.', 'Deliver Outcomes – Demonstrate a bias for speed and execution that serves our stakeholders and customers', 'Operate as a Team Player – Work together to drive solutions for the good of TakeOut7 and its customers', 'Build Strong Partnerships – Demonstrate integrity and build trust with others in our organization', 'Strive for Excellence – Motivate yourself and others to achieve high standards and continuously improve', 'Bachelor degree - Recent grads highly considered', 'A Preference for a cumulative GPA of 3.0 or higher (out of 4.0 scale or equivalent) at the time of graduation', 'Desired majors include: Computer Science & Applied Mathematics', 'Prefer working knowledge of programming in any of the high level programming languages like Python, Java, C#, C++, Scala, Lisp, etc.', 'Prefer working knowledge of database concepts and SQL skills on Databases like Oracle, Microsoft SQL Server or NoSQL Databases', 'Understanding of current and emerging IT products, services, processes and methodologies', 'Prefer working familiarity with Operating Systems like Unix, MS-Windows and networking concepts', 'Equal Opportunity Employer/Females/Minorities/Veterans/Disability/Sexual Orientation/Gender Identity or Expression', 'Day Job - Remote worker not an option – subject to Covid-19 restrictions', 'Health insurance reimbursed up to $600 monthly max', 'Incentive Stock Options in Company offered', 'Paid Time Off', 'Day shift', 'Monday to Friday', 'On Call', 'JavaScript: 1 year (Preferred)', ""Bachelor's (Required)"", 'United States (Required)', 'No: Not providing sponsorship for this job', 'www.takeout7.com', 'Temporarily due to COVID-19']",2020-08-08 13:46:22
Remote Chief Data Architect,Darwin Recruitment,N/A,"Virgin Island, WI","['You must be able to work around/during the UK (GMT) and US (PT) time zones', 'You must have a proven experience working in a customer-facing role.', '5+ years of data architecture leadership experience, including multiple years guiding or leading enterprise projects in a professional services or consulting environment.', 'Deep knowledge of working with various front-end technologies that are used to build web sites', 'Strong experience of designing scraping solutions and dealing with blocking technologies', 'Mastery of one or more of the following disciplines: Data Science, NLP, Machine Learning, Business Intelligence, Big Data Analytics', 'Expert understanding of business and processes, and the ability to identify and implement data solutions that significantly improve the status quo.', 'Ability to communicate their value to help uncover additional opportunities at the client account.', 'Ability to apply your knowledge to extract data from multiple online sources, cleanse it, parse it, and build APIs that are consumable by large enterprises to use daily, weekly, monthly on their mission-critical projects.', 'Ability to envisage, design and build large scale, automated data harvesting projects - operating on a platform that monitors data integrity, data-pipeline health and reliability.', 'Deep understanding of the vast data sources on the web (e.g. Amazon) and demonstrate the ability to recognize how, when, and which data to collect, parse and store.', 'Experience of working with cloud platforms like AWS and GCP', ""Develop an architecture to automate and operate constant (24x7) flow of data from some of the world's most frequented websites."", 'Mentor and guide project teams and engineers on our delivery and engineering teams to develop optimal solutions for client data and business challenges.', 'Educate the client on the most effective way to integrate web data into their business process for maximum impact with minimum investment.', 'Advise the client through the delivery process and find optimal paths for Import.io data to solve the organizational and business needs.', 'Participates in client engagements with ownership of data schema, delivery and technical content.', 'Displays strong executive presence and builds trusted relationships with the highest level employees at target organizations.', 'Works closely with sales and delivery to develop proposals and presentations around process and solution options, clearly explaining technical concepts to audiences.', 'Delivers strategic thought leadership by leading multiple client engagements simultaneously.']",2020-08-08 13:46:22
"MTS Software Engineer, Data Infras",eBay Inc.,3.9 out of 5,"Rancho Cordova, CA 95670",[],2020-08-08 13:46:22
Jr. Software Engineer,UCLA Health,4 out of 5,"Los Angeles, CA 91403",[],2020-08-08 13:46:22
Big Data Engineer,"Adil Business Systems, Inc.",3.5 out of 5,"Charlotte, NC 28216","['5+ years with Data Engineering', '4+ years of Solutions with Hadoop, Hive, Map Reduce, Sqoop, Oozie, Java', '1-2 years of Spark Scala', '1 years of Rest API', '1 year of cloud', 'Code, test, and analyzing 2-tier, 3-tier, or N-tier client/server applications.', 'Support existing business systems applications.', 'Consult with business analysts to identify business needs and appropriate technical solutions.', 'Design and document technical requirements for business applications.', 'Assist with the design, development, testing, and documentation of web sites/pages.', 'Support production and maintenance of existing applications.', 'Assist with the development of client business requirements and preparation of specifications, attend meetings and reply to users with basic information.', 'HTML programming and Web page development.', 'Java development skills', 'Design and document technical requirements for complex business applications.', 'Perform design, coding and testing on complicated revisions to Web applications, and creates efficient and maintainable new applications Utilize databases that support access by Web-based clients, including Oracle, DB2, and Microsoft SQL Server.', 'Extensive coding using servlets, CGI scripting, ODBC, JDBC.', 'Utilizes HTML and graphical tools to create or enhance the functionality of the web sites.', 'Confer with clients to identify requirements (e.g., data, information needs, processing, specific output, functional and development of test data), and determine desired outcomes in order to formulate the design of the system and/or offer alternative solutions in a timely manner.', 'Provide technical guidance and expertise during implementation.', 'Mentor new or junior staff on business knowledge, system peculiarities, and complex technical issues.', 'Analyze, design, and document information to create the applicable statement of work and the associated deliverables.', 'Proactively analyze and review emerging technologies', 'Bachelor’s Degree in Computer Science, CIS, or related field preferred', '3 to 5 years of experience in Web application development or equivalent total experience.', 'Proficient using Java for multi-tiered web-based applications.', 'Demonstrate an understanding of HTML–based programming, including understanding of HTML authoring tools to implement these functions.', '5 years of progressive, post-bachelor’s experience in Data Engineering/Management, or Analytics.', 'Experience with using build tools including one or more of the followings: Ant, Maven, Gradle.', 'Strong experience with using IDE’s and Software development environments including one or more of the followings: Eclipse, NetBeans and Intellij Idea.', '4 years of experience in Big Data Solutions using technologies including one or more of the followings: Hadoop, Hive, HBase, MapReduce, Spark, Sqoop, Oozie, Java.', '2 years of experience applying Agile development practices and working with distributed, component-based architectures.', '2 Years of experience in Spark/Scala.', '1-2 years of experience with REST API development  * 1 year of experience on Cloud platforms such as Azure or GCP  * Strong experience in performance Tuning, troubleshooting application issues & analyzing production issues.', ""Bachelor's Degree in computer science, Engineering or related field"", 'Hive: 4 years (Required)', 'Data Engineering: 5 years (Required)', 'Oozie: 4 years (Preferred)', 'Spark/Scala: 2 years (Required)', 'Rest API: 1 year (Required)', 'Java: 4 years (Preferred)', 'Hadoop: 4 years (Required)', 'Cloud: 1 year (Required)', ""Bachelor's (Required)"", 'Charlotte, NC 28262 (Required)', 'United States (Required)', 'Possible', 'No', 'None', 'Monday to Friday', 'No']",2020-08-08 13:46:22
"DevOps Engineer (AWS, Python) - high profile, large scale CI/CD environment",Who... a staffing company,N/A,"Baltimore, MD","['Fine-tune and improve a variety of sophisticated software implementation projects', 'Gather and analyze system requirements, document specifications, and develop software solutions to meet client needs and data', 'Analyze and review enhancement requests and specifications', 'Implement system software and customize to client requirements', 'Prepare the detailed software specifications and test plans', 'Code new programs to client’s specifications and create test data for testing', 'Modify existing programs to new standards and conduct unit testing of developed programs', 'Create migration packages for system testing, user testing, and implementation', 'Provide quality assurance reviews', 'Perform post-implementation validation of software and resolve any bugs found during testing', ""Bachelor's degree in a technical field such as computer science, computer engineering or related field required"", '10+ years’ experience required', 'A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design', 'Large systems software design and development experience', 'Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems', 'Experience in programming and experience with problem diagnosis and resolution', '401(k)', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Monday to Friday', 'DevOps: 3 years (Preferred)', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:46:22
Data Center Technician,Randstad Technologies,N/A,"Bear, DE 19701","['Certifications: A+, Server+, or Network+', 'Technical writing and documentation skills are preferred', 'Proficient in Microsoft Office', 'Network Technician: 1 year (Required)', 'United States (Required)', 'More than 1 year', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Professional development assistance', 'Retirement plan', 'High stress tolerance -- thrives in a high-pressure environment', 'Dependable -- more reliable than spontaneous', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', '12 hour shift', 'No']",2020-08-08 13:46:22
"Various Consultant, Analyst, Engineer and Writer Positions",IMSG/NOAA,N/A,"Rockville, MD 20850","['401(k)', '401(k) Matching', 'Dental Insurance', 'Flexible Spending Account', 'Health Insurance', 'Paid Time Off', 'Referral Program', 'Relocation Assistance', 'Tuition Reimbursement', 'Vision Insurance', 'https://careers-imsg.icims.com']",2020-08-08 13:46:22
Water Treatment Engineer/Scientist,"MIH Water Treatment, Inc.",N/A,"Ontario, CA 91761","['Monday to Friday', 'On Call', ""Bachelor's (Required)"", '8AM', '4PM', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'mihwater.com', 'Temporarily due to COVID-19']",2020-08-08 13:46:22
"Data Engineer (Python, Spark, CI/CD, AWS)",Ursus,N/A,"Richmond, VA","['Partner with product owners, peers, and end users to understand business requirements.', 'Provide technical guidance concerning business implications of application development projects.', 'Utilize ETL programming skills in Unix, Python, Spark, and Scala.', 'Handle Cloud computing across the AWS platform as well as work across AWS native technologies (S3, EMR/EC2, and Lambda functions).', 'Leverage DevOps techniques and practices like Continuous Integration, Continuous Deployment, Test Automation, Build Automation, and Test Driven Development', 'Research and develop cutting edge technologies to accomplish goals across the organization, with a passion to learn and grow', ""Bachelor's Degree"", 'At least 4 years of experience in software development', 'At least 2 years of experience in data warehousing or analytics', 'At least 1 year of experience with data engineering', 'At least 1 year of experience with data modeling', 'At least 1 year of experience deploying, monitoring and maintaining a Cloud-based application', '3 years of experience building software including systems and application design, code development and testing.', '3 years of experience in scripting language (Python, Perl, JavaScript, Shell)', '2 years of experience with UNIX/Linux environments', '1 year of experience in Python, Scala, or R for data analysis', '1 year of experience with the Hadoop Stack', '1 year of experience working on streaming data applications (Spark Streaming, Kafka, Kinesis, and Flink)', '1 year of experience with Amazon Web Services (AWS) or Microsoft Azure or another public cloud']",2020-08-08 13:46:22
Chemist,Idexcel,4.3 out of 5,"King of Prussia, PA","['Provide formulation, characterization and processing support in R&D programs directed toward preparing and processing new composite resin formulations working with product development scientists and engineers.', 'Obtain training and experience in an array of processing and characterization methods.', 'Composite liquid resin preparation, characterization and evaluation including viscosity, cure kinetics and stability', 'Polymer composite processing including infusion and resin transfer molding', 'Composite characterization and evaluation including: mechanical, optical, thermal, UV and chemical resistance properties', 'Organize, report and give initial analysis of data and suggestions for future experiments based on results', 'Participate in team meetings to discuss results/ plan for future experiments', 'Research on and evaluation of formulation changes (additives, comonomers, polymer alloys) to improve processing or physical properties of composite materials', ""Bachelor's Degree or above in Chemistry, Material Sciences, Polymers or similar."", 'Previous experience dealing with chemical synthesis, polymers or composites is a plus', 'Fluent in English.', 'Demonstrated strong problem solving skills.', 'Good interpersonal skills and will be able to create strong relationships with your colleagues']",2020-08-08 13:46:22
Data Visualization Engineer,Ursus,N/A,"San Jose, CA 95110","['Lead cross-functional projects and long-term analytic development initiatives, managing multiple projects with competing priorities simultaneously', 'Engage broadly with the organization to frame, structure and prioritize business problems where analytic projects or tools can have the biggest impact', 'Collaborate with other analysts, subject matter experts, and decision-makers to develop data-driven models or decision-support tools to improve the efficiency', 'Draw from a breadth of analytical methods to choose the right tool and right level of complexity appropriate to solving the business problem', 'Partner with the business teams to set business objectives (KPIs), build dashboards that support ongoing reporting and analysis and be a key contributor to the sales team to drive strategic decisions and investments in sales programs', 'Drive development of tools, reporting improvements, automation, and create new innovative and insightful data science products', ""Bachelor's Degree (STEM) or Master's with 3 - 5 years of experience"", 'Strong JavaScript D3/HTML/CSS and knowledge of core web technologies', 'Modern web dev tools/patterns/idioms (e.g. npm, webpack, etc; loading optimization, knowledge of cloud deployment strategies)', 'Experience with React, Angular, Vue, etc.', 'Interface and UX Design', 'Strong proficiency in querying and manipulating large data sets for analytical purposes using SQL/Python and experience with business intelligence tools like Tableau, Power BI, etc.']",2020-08-08 13:46:22
"MTS Software Engineer, Data Infras",eBay Inc.,3.9 out of 5,"Rancho Cordova, CA 95670",[],2020-08-08 13:47:05
Data Engineer,AccruePartners,3.8 out of 5,"Huntersville, NC","['Supply Chain & Technology leader redefining a consumer market with $60B in direct industry output (US)', 'Private-equity backed with massive transformation occurring across the company', 'Engaged leadership from Fortune 100 companies; creating a world-class company culture', 'Exciting career adventure - chance to be at the forefront of the business transformation and expected to play a key support role in the on-going process', 'Professional development; company is hiring A++ players across the company', 'Great exposure; this person will be building relationships at all levels including the executive team and C-level daily', 'Excellent benefits and work environment', 'Work with data scientists to architect and flood static data models to enable the development of Machine Learning and other statistical models', 'Build ETL jobs and streaming processes based on jointly defined requirements for the data pipeline', 'Identify, analyze, and interpret trends or patterns in complex data sets o Translate insights into predictive power by assisting data scientists with feature engineering in Python', 'Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality', 'Support the bug fixing and performance analysis along the data pipeline o Analyze and manage 3rd Party and other external data sets', 'Follow an agile development methodology', '1-3 years of experience of data models, database design development, data mining and data cleaning techniques', 'Strong experience with Python/R, SQL and shell script', 'Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy', 'Understanding of the fundamentals of statistics and machine learning o Experience with database design and development', 'Knowledge of Cloud environment', 'Experience in UNIX or Unix-like system', 'Experience working in start-up environment or organizations with an agile culture', 'Professional attitude and service orientation; superb team player']",2020-08-08 13:47:05
Quality Assurance Engineer,TechServe,N/A,"Plano, TX 75093","['Assist in QA defect management process, monitor and report on defect resolution to management. Apply corrective action/remediation measures as needed for process/quality improvement utilizing action plans and Lean Six Sigma tools', 'Analyze data (findings, defects, trending, etc.) making recommendations on areas for improvement and best practices. Identify gaps in business processes, documentation and or training and provide solutions/recommendations to management', 'Develop test scripts/new audits utilizing comprehensive business requirements, functional documentation and processes', 'Design test cases and execute all types of testing (e.g. functional, integration, end-to-end) on a variety of platforms (e.g. mobile, web, portal frameworks)', 'Assist project teams in determining appropriate quality goals and acceptance criteria', 'Coordinate with project teams on the timing and priority of QA testing needs', 'Understand and implement automated testing scenarios using software Identify and track bugs, regression issues, and enhancement requests', 'Keep track of and report on testing progress and results', 'Understand deployment strategy and testing environments', 'Ability to create test plans and test cases', 'Perform manual and automated testing', 'Review user interfaces for consistency and functionality', 'Working knowledge of technology best practices, methodologies and processes (e.g., ITIL, CMM, Agile, Scrum, DevOps)', 'General experience or knowledge of relational database concepts, software design concepts, and database modeling preferred.', 'Solid understanding of SQL and queries preferred.', 'Experience in Tolling industry a plus', ""Minimum 5 years' experience in SDLC Process with a focus on test planning, test execution and defect management."", 'Day shift', 'Monday to Friday', 'Coordinate Measuring Machine: 5 years (Preferred)', 'SDLC: 5 years (Preferred)', 'SQL: 5 years (Preferred)', 'Tableau: 5 years (Preferred)', 'Business Intelligence: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'Plano, TX 75093 (Preferred)', 'United States (Required)', 'Likely', 'One location', 'www.techiservice.com', 'No']",2020-08-08 13:47:05
Chemist,Idexcel,4.3 out of 5,"King of Prussia, PA","['Provide formulation, characterization and processing support in R&D programs directed toward preparing and processing new composite resin formulations working with product development scientists and engineers.', 'Obtain training and experience in an array of processing and characterization methods.', 'Composite liquid resin preparation, characterization and evaluation including viscosity, cure kinetics and stability', 'Polymer composite processing including infusion and resin transfer molding', 'Composite characterization and evaluation including: mechanical, optical, thermal, UV and chemical resistance properties', 'Organize, report and give initial analysis of data and suggestions for future experiments based on results', 'Participate in team meetings to discuss results/ plan for future experiments', 'Research on and evaluation of formulation changes (additives, comonomers, polymer alloys) to improve processing or physical properties of composite materials', ""Bachelor's Degree or above in Chemistry, Material Sciences, Polymers or similar."", 'Previous experience dealing with chemical synthesis, polymers or composites is a plus', 'Fluent in English.', 'Demonstrated strong problem solving skills.', 'Good interpersonal skills and will be able to create strong relationships with your colleagues']",2020-08-08 13:47:05
Water Treatment Engineer/Scientist,"MIH Water Treatment, Inc.",N/A,"Ontario, CA 91761","['Monday to Friday', 'On Call', ""Bachelor's (Required)"", '8AM', '4PM', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'People-oriented -- supportive and fairness-focused', 'mihwater.com', 'Temporarily due to COVID-19']",2020-08-08 13:47:05
Warehouse IT Support Engineer,Wayfair,3.2 out of 5,"McDonough, GA 30252","['Build relationships with our Warehouse Operations team by spending time on the warehouse floor to learn their workflows so we can better assist them with technical issues.', 'Responsible for troubleshooting a wide variety of technical issues ranging from Windows server, network connectivity, and warehouse equipment issues.', 'Analyze production or workflow issues by creating and running SQL queries or utilize our proprietary warehouse management system.', 'Prioritize tickets on ServiceNow to ensure our local and remote end users receive updates and resolutions in a timely manner.', 'Collaborate across cross functional engineering and business teams to solve high impact incidents with a sense of urgency by providing quality and accurate information.', 'Proactively identify recurring technical issues and fix their root causes to enhance business productivity.', 'Display accountability and ownership by employing a strong work ethic to solve complex problems from start to finish.', 'Perform research independently by asking clarifying questions, gather relevant data, and resolve the manner using a data driven approach', 'Be a team player and assist other members to achieve overall team goals.', 'Flexibility to provide support to 24/7 fulfillment center and participating on a rotational or on-call shift, if needed.', '2+ years of relevant work experience in a support engineering or service-oriented IT role.', 'Bachelors or Associates Degree in Computer/IT related field or equivalent work experience.', 'Prior experience providing technical support in a warehouse or experience with warehouse management systems.', 'Proficiency in writing and troubleshooting SQL queries.', 'Experience troubleshooting Windows Server 2016 and Active Directory Issues (Group Policy and User profiles)', 'Experience troubleshooting DNS, DHCP, VoIP, VPN and Cisco/Aruba networking device issues', 'Experience with deploying software\\imaging using SCCM', 'Experience troubleshooting warehouse device equipment such as RF Barcode Scanners, Zebra label printers, and other peripherals/devices.', 'Understand production architecture and operating system best practices.', 'Strong customer service and organizational skills while keeping attention to detail.', 'Proven ability to handle multiple tasks concurrently and prioritize accordingly.', 'Excellent communication, interpersonal and team-building skills.', 'Being a team player who is dedicated to providing the best results possible.', 'Having a strong work ethic and desire to be a life-long learner.', 'Scripting ability, specifically with Powershell, VBScript and/or PHP', 'Familiarity with email, FTP and HTTP troubleshooting']",2020-08-08 13:47:05
"DevOps Engineer (AWS, Python) - high profile, large scale CI/CD environment",Who... a staffing company,N/A,"Baltimore, MD","['Fine-tune and improve a variety of sophisticated software implementation projects', 'Gather and analyze system requirements, document specifications, and develop software solutions to meet client needs and data', 'Analyze and review enhancement requests and specifications', 'Implement system software and customize to client requirements', 'Prepare the detailed software specifications and test plans', 'Code new programs to client’s specifications and create test data for testing', 'Modify existing programs to new standards and conduct unit testing of developed programs', 'Create migration packages for system testing, user testing, and implementation', 'Provide quality assurance reviews', 'Perform post-implementation validation of software and resolve any bugs found during testing', ""Bachelor's degree in a technical field such as computer science, computer engineering or related field required"", '10+ years’ experience required', 'A solid foundation in computer science, with strong competencies in data structures, algorithms, and software design', 'Large systems software design and development experience', 'Experience performing in-depth troubleshooting and unit testing with both new and legacy production systems', 'Experience in programming and experience with problem diagnosis and resolution', '401(k)', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Monday to Friday', 'DevOps: 3 years (Preferred)', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:47:05
Data Engineer,"CorTech, LLC",3.2 out of 5,"Hartford, CT 06106",[],2020-08-08 13:47:05
Software Development Engineer II Data,Audible,4 out of 5,"Newark, NJ 07175","['Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet business needs', 'Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices', 'Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications', 'Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines', 'Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts', 'Peer review work. Actively mentor other members of the team, improving their skills, their knowledge of our systems and their ability to get things done']",2020-08-08 13:47:05
2020 Software Engineer Intern,Bloomberg,3.9 out of 5,"New York, NY","['Take ownership of projects under the guidance of your mentor', 'Be a collaborative member of your team', 'Have a deep understanding of data structures and algorithms', 'Be an excellent problem solver', 'Have programming experience in C, C++, Java or Python', 'Have a minimum GPA of 3.0', 'Be working toward a BA, BS, MS or PhD in Computer Science']",2020-08-08 13:47:05
BHJOB15656_15057 – Data Engineer,Myticas Consulting,N/A,"Chicago, IL","['5+ years of experience working with enterprise data platforms, building and managing data lakes and using big data technologies', '2+ years of experience with Spark using Python/Scala. Experience with Spark streaming, building real time data pipelines is preferred', '2+ years of experience working with AWS platform. Experience with solutioning on AWS infrastructure using services like AWS S3, Lambda, EMR, Redshift (or Snowflake)', 'Experience with automating and orchestrating jobs on a big data platform using Oozie, Airflow, Jenkins or something similar', 'Good understanding and experience working with various products in the Big data ecosystem like Hive, HDFS, Presto, NoSQL databases like Cassandra, DynamoDB', 'Experience with setting up and using Kafka for real time streaming is a big plus', 'Has to be a team player and open to working with newer technologies as well as supporting legacy systems', 'Prior experience with working in a SQL server based environment and using SSIS, SSRS, TSQL is a plus.', 'Prior experience with traditional ETL tools like Talend Open Studio, Pentaho or something similar is a plus']",2020-08-08 13:47:05
Remote Data Engineer / ETL,Kforce,3.8 out of 5,"Dallas, TX","['Work under data/solution architects to deliver enterprise class data structures and solutions and/or integration into custom product development', 'Help define data matrices, data dictionaries, data structures across various topologies (SQL Server 2016, Hadoop/Cloudera stacks, etc.)', 'Complete product technical design and prototyping, data design/development, support and problem remediation', 'Understand data design patterns and enterprise design regarding data in the Payments Industry (banking, credit unions, bill pay, EFT, etc.) within both commercial off the shelf (COTS) and custom solutions', 'Provide both individual, team, and budget-level tasks and product effort estimates/costs and overall LOE regarding data efforts', 'Document technical designs, using flow charts, class diagrams, sequence diagrams, activity diagrams, data flow diagrams, database schemas, descriptive software component documentation, wireframes', 'Develop and test applications based on business requirements and industry best practices', 'Creates required technical documentation, use cases, white papers, system and deployment architecture, and technical process/pro', ""Bachelor's degree preferred; business, software and infra engineering, or computer science degree preferred"", 'Minimum of 8 years hands-on experience with enterprise class database development, focused on transactional environments w/focus around SQL 2012/2014/2016; including redundancy modeling (Disaster Avoidance/Recovery), cross data center high availability, always on, horizontal and vertical scalability, and various forms of data movement (log shipping, replication modeling, Always On, etc.)', 'Minimum of 6 years of technical experience in data modeling and design, or development', ""5 years'+ experience with analytics, dashboard tooling, and ETL toolsets in large enterprise-based payments/banking industry"", 'Experience in Banking/EFT/Financial Institution domain and based technologies; along with data layer experience w/ ISO8583 in a cutting-edge enterprise', '6+ years hands-on understanding enterprise systems, infrastructure, software design and development, database design and development, and system integration experience', 'Experience working collaboratively with Stakeholders, Business Analysts, Project Managers, Designers and DBAs with the common goal of delivering value to the business', 'Encryption based development via Host Security Modules and adherence to PCI compliance and requirements', 'Focused on innovation and cutting-edge technologies within a five nines environment (99.999% uptime)', 'Experience with Continuous Integration and Test-Driven Development techniques']",2020-08-08 13:47:05
Distinguished Data Engineer - Director,Capital One,3.9 out of 5,"Vienna, VA 22183","['Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices', 'Visionaries, collaborating on Capital One’s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates', 'Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community', 'Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities', 'Leaders who gain the trust and confidence of those around them, from hands on engineers to executives', 'Design and develop cutting-edge solutions, using existing and emerging technology platforms used to deliver and optimize data enterprise services', 'Provide technical leadership, evaluation and recommendations for data consumption engines and new technologies that can be used to advance new features and capabilities around analytics and use derived data sets', 'Leverage sound judgment and problem solving to tackle some of Capital One’s most critical problems and connect the dots to broader implications of the work', 'Build awareness, increase knowledge and drive adoption of modern technologies and architecture patterns, sharing customer and engineering benefits to gain buy-in', 'Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team', 'Promote a culture of engineering excellence and being well-managed, using opportunities to reuse and innersource solutions where possible', 'Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization', 'Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an integrated manner', 'Design, architect, and help implement a recommendation engine to help Capital One engineering teams comply with open source software version policies and procedures', 'Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an integrated manner', 'Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent', 'Bachelor’s Degree', 'At least 8 years of data engineering experience', 'At least 5 years of experience developing in Spark, Python, SQL, Java, or Scala', 'At least 2 years of experience with data science Notebooks (Jupyter, Zeppelin, or RStudio)', 'Masters’ Degree', '15+ years of data engineering experience', '10+ years of data governance and security controls', '8+ years of data architecture design', '4+ years of experience with workflow automation', '4+ years of experience with AWS', '2+ years of experience with Databricks and Presto']",2020-08-08 13:47:05
Entry Level R&D Engineer 1,Gamma,3.6 out of 5,"Shakopee, MN","['Gather the technical input to assigned problems and make specific recommendations on the solution within the R&D and Engineering team', 'Conduct designed experiments and process collected data to comprehensible records and overviews', 'Provide detailed evidence to support the recommended solutions, which may include but not necessarily be limited to: Demonstration for the recommended solution, detailed test reports, technical specifications and descriptions', 'To use rigorous problem-solving techniques and methods using appropriate tools and methods', 'To use experimental techniques and methods in product development by application of the most relevant and up to date methods and equipment resulting in rigorous and time-efficient results', 'Information seeking and self-development to enhance knowledge, innovation and share it with team', 'Adherence to project plans, gates and deadlines', 'Adhere to company processes to ensure Quality, Safety and Business needs are met and enhanced', 'Other duties as assigned', 'Bachelors degree in Science, Engineering or related field required.', 'Experience with vacuum equipment or related field preferred. Internships & Coursework considered.', 'Confident grasp of fundamental technical matters, indicated by speed, accuracy and quality of work.', 'Ability to carry out standard tasks correctly, without needing to seek assistance.', 'Awareness of broader business and company strategic goals,', 'Acquires and applies specialist knowledge in practical situations.', 'Analytical thinking, identifies root cause and propose / implement effective solutions.', 'HW/SW/Measurement knowledge, quality tools experience', 'Fluent in English', 'PC literacy (MS Office), statistical software basics will be required', 'Hard working, stress resistant, communicative', 'Self-driven and motivated team player']",2020-08-08 13:47:05
Quality Assurance Engineer - BM,BioMedtrix,4 out of 5,"Whippany, NJ 07981","['Assist in establishing, implementing, and maintaining the quality management system.', 'Root cause analysis and implementation of corrective action for process-related concerns.', 'Develop training to build quality awareness.', 'Interface with Engineering and Operations to ensure transfer to Production of new products are in accordance with approved data.', 'Conduct audits, including closing out audit findings, creating audit finding reports and determine proper corrective and preventive actions.', 'Analyze failure, corrective and preventive action to respond to customer complaints.', 'Create and maintain company quality documentation, such as quality manuals, quality procedures, etc.', 'Ensure timely resolution of supplier failure, corrective actions and preventive actions.', 'Manage suppliers’ performance and conduct audits.', 'Preparation of QA reports.', 'Continual improvement activities to enhance the quality system, such as Six Sigma, 5S, Kaizen lean methods, etc.', 'Validation functions', 'Establish, implement and direct validation and revalidation activities in accordance with appropriate regulatory agency validation requirements, internal company procedures, and current industry practices.', 'Support and conduct validation studies, qualifications, technology transfer activities, process characterization studies, statistical analysis of results using Minitab or equivalent to identify critical parameters and improve process capability and gauge R&R studies within the Manufacturing Process.', 'Contribute to the preparation and review of the Validation Master Plan', 'Provide guidance on project teams as a technical subject matter expert on validation regulations/procedures for equipment/process validation requirements for new product development projects. Coordinate the execution of validations in accordance with defined protocols by Operations, Quality Control, and R&D teams.', 'Support/conduct IQ, OQ, PQ validation studies of equipment and processes, utilities, and software validations.', 'Liaise with contract manufacturers and suppliers to develop protocols, coordinate validation activities, and compose reports where appropriate for equipment qualifications and process validations.', 'Develop/review and approve validation protocols and final reports.', 'Ensuring completion of validation protocols.', 'Generate and resolve protocol discrepancies or deviations.', 'Optimize the Quality System Validation program.', 'Organize and maintain the validation documentation system in conjunction with document control personnel.', '401(k)', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Quality Assurance: 3 years (Required)', 'Medical Device : 1 year (Required)', 'Solid Works: 1 year (Required)', ""Bachelor's (Required)"", 'ASQ Certified Quality Engineer (Preferred)', 'Six Sigma or Lean (Preferred)', 'One location', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'A job for which military experienced candidates are encouraged to apply', 'www.vetimplants.com', 'Waiting period may apply', 'No']",2020-08-08 13:47:05
Industrial Engineer,HRU Technical Resources,N/A,"Wentzville, MO","['Dental Insurance', 'Health Insurance', 'Vision Insurance', 'Monday to Friday', 'Likely', 'Yes', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'No']",2020-08-08 13:47:50
Biostatistical Programmer,The Denzel Group,N/A,"Newark, DE",[],2020-08-08 13:47:50
Software Engineer,PeopleCaddie,N/A,"Charlotte, NC","['Work as part of an Agile/Scrum team to design, implement, manage and modernize MarkLogic Datahub usage as part of a Medicaid Enterprise system development project.', 'Leverage knowledge of database design and implementation of complex, ambiguous technical and functional challenges with little guidance.', 'Demonstrate experience with structured and unstructured data, streaming and batch data processing, ETL, data wrangling, data ingest, and data access.', 'Develop and maintain content ingestion, validation, and transformation, populating the MarkLogicXML repository', 'Develop XQuery modules and Rest APIs to support complex searches against the database', 'Develop XQuery, JavaScript and REST modules on the MarkLogic technology stack', 'Utilize the MarkLogic library to support initiatives', '5+ years of experience with MarkLogic', 'Experience with Medicaid and or Healthcare regulations and compliance preferred', 'Experience with developing data architectures', 'Experience with MarkLogic in AWS', 'Knowledge of data replication between MarkLogic', 'Knowledge of ETL procedures and data loading', 'Strong analytical and design skills, including the ability to understand business requirements and translate them into efficient and effective technical designs that work well within large-scale, well-structured enterprise environments', 'Direct experience with commonly accepted industry architectures/technologies including J2EE, .NET, XML, XSLT, SOA/Web Services, SQL, HTML, HTTP, JavaScript, REST', 'Experience working as part of an Agile/Scrum team', 'Experience supervising other developers and serving as a MarkLogic subject-matter expert', 'Experience with developing an Enterprise Data Model', 'Possession of excellent oral and written communication skills']",2020-08-08 13:47:50
Data Modeling Engineer - Remote,Advantage Resourcing,3.7 out of 5,"Saint Petersburg, FL 33701","['Develop the logical data model in ERWIN data modeler', 'Start with the CEDW4 model and the feedback from above validation with data owners', 'Complete any outstanding validation of CEDW4 data model', 'Develop the new logical data model to meet current business needs and rules', 'Obtain approval of the logical data model from the data owners and tech team', 'Provide knowledge transfer and support of logical data model to tech team', 'Experience working with ERWIN Data Modeler', 'Experience with Snowflake platform or Azure Synapse platform', 'Experience with MDM (master data management)', 'Experience with Data Visualization', 'Experience in eliciting business definitions and rules and data quality requirements from stakeholders and data owners, designing logical data models, and documenting data management metadata within the data model']",2020-08-08 13:47:50
"Software Engineer (Java, Python, Data/Machine Learning!)",Who... a staffing company,N/A,"Baltimore, MD","['401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Java: 3 years (Preferred)', 'Python: 3 years (Preferred)', 'Bonuses', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:47:50
Data Engineer,PennyMac,3.1 out of 5,"Agoura Hills, CA","['Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability', 'Create and maintain optimal data pipeline architecture', 'Assemble large, complex data sets that meet business requirements', 'Build analytics tools that utilize the data pipeline to provide actionable insights into operational efficiency, financial reports and other key business performance metrics', 'Work with stakeholders including the Engineering and Analytic teams to assist with data-related technical issues and support their data infrastructure needs', 'Create data tools to support business informational technology process', 'Work with the data analytics team to strive for greater functionality in our data systems', 'Perform other related duties as required and assigned', 'Demonstrate behaviors which are aligned with the organization’s desired culture and values', 'Moderate experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Moderate knowledge of AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with object-oriented/object function scripting languages: Python, Java, C++', 'Experience building and optimizing AWS data pipelines, architectures and data sets.', 'Strong project management and organizational skills.', 'Moderate skill in business intelligence tools such as Tableau or Qlik', 'Moderate skills with MS Office, including Excel & PowerPoint', 'Must be a team player with strong attention to detail and able to work independently', 'Proven track record at delivering timely and accurate information in a fast-paced environment', 'Excellent critical thinking, problem solving, and mathematical skills, and sound judgment', 'Strong business acumen and ability to interface with executive management']",2020-08-08 13:47:50
Software Engineer (Data Team - Parsing),SpyCloud,N/A,"Austin, TX 78704","['Create efficient and scalable ways of parsing large amounts of (un)structured data', 'Add to and improve our data parsing pipeline', 'Work closely with our security researchers who are collecting breach data', 'Participate in a fast-paced environment', 'New college grad with a degree in Computer Science or a related field OR at least 2 years of professional experience as a software developer', 'Experience with Python', 'An understanding of data structures and algorithms', 'Experience with a database (relational or NoSQL)', 'Experience with Linux', 'Excellent communication skills', 'Be self-motivated and be able to switch contexts as business needs change', 'Familiarity with an MVC web framework (e.g. Pyramid, Django, Ruby on Rails, etc)', 'Familiarity with front-end development (e.g. HTML, CSS, JavaScript)', 'Familiarity with building REST APIs', 'Familiarity with Bash scripting', 'Familiarity with AWS', 'Familiarity with a version control system. We use Git.', '401(k)', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Parental Leave', 'Referral Program', 'Vision Insurance', 'Monday to Friday', 'Software Development: 2 years (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Innovative -- innovative and risk-taking', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.spycloud.com', 'Temporarily due to COVID-19']",2020-08-08 13:47:50
Director of Data Engineer - Remote,Kforce,3.8 out of 5,"New York, NY 10018","['Lead, manage and grow a team of data engineers to ensure a high level of performance and efficacy', 'Provide guidance to the team (set goals, measure progress) in key architectural, design, and product decisions of large initiatives', 'Oversee large volumes of health plan claims data (150M records and growing) efficiently and to ensure data integrity and support reporting to the enterprise and to our clients', 'We have several new products on our roadmap that will contribute to data growth', ""Partner with Data Scientist and healthcare data analysts to manage the process of running multiple predictive/targeting algorithms which identify members who could benefit from the company's programs and services"", 'Partner with other remote stakeholders in the business (engagement centers, finance, clinical operations and other areas of the company) to support their data needs', 'Implement data handling policies and processes developed by the Data Governance Committee With engineering and data leadership', ""Bachelor's (or Masters) in Computer Science, Mathematics, Operations Research, or other related discipline or equivalent work experience"", '5+ years of healthcare industry experience running highly available production systems especially involving healthcare claims data 4+ years coding in Python and SQL; Experience with workflow management platforms and frameworks such as Airflow or Luigi', '5+ years experience managing data engineers in an agile environment (Scrum, Kanban, SAFe)', '5+ years of applying common architectural patterns and frameworks (EDI, HL7) in a Healthcare Industry', 'Experience working with either Google Cloud Platform or AWS with experience in data systems deployment patterns', 'You are a collaborator; You build and maintain strong, productive working relationships with internal stakeholders and external customers', 'You are an engineer at heart; You have a strong sense of architectural patterns (and anti-patterns) and an intuition of what it takes to get complex projects shipped', 'You are a coach; You derive deep satisfaction in helping engineers develop new skills and advance in their careers', ""You lead by example; You get on the front lines to understand your team's strengths and weaknesses and are able to set the right context and scope for excellent teamwork"", 'You have an eye for talent; You have successfully recruited and developed great people on your teams', ""You hustle; You don't need to wait for people to tell you what to work on"", ""You are empathetic; You seek to understand each individual's diversity of background and experience to build great teams""]",2020-08-08 13:47:50
Lead Data Engineer,"Yoh, A Day & Zimmermann Company",3.8 out of 5,"Wayne, PA 19087","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and enabling data-driven decisions across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate, secure, and available for key stakeholders and business processes that depend on it.', 'Contributes to engineering communities of practice, and documents work.', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Works closely with a team of frontend and backend engineers, product managers, and analysts.', 'Defines company data models, uses ELT pipeline and data streaming tools to populate data models.', 'Designs data integrations and data quality framework.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'BS or MS degree in Computer Information Science or related technical field', '8-10 years of Information Technology experience with data management', '5+ years of software engineering experience in Python, Scala, Java, or .NET', '5+ years of experience with schema design, dimensional data modeling, and data storage technology', '5+ years of multiple kinds of database experience (SQL and No-SQL)', 'Proven ability in managing and communicating data warehouse plans to internal clients', 'Experience designing, building, and maintaining secure, reliable batch and real time data pipelines', 'Experience with cloud data ingestion, data lake, and modern warehouse solutions (Azure is a plus)', 'Experience with event streaming platforms like Kafka or Azure Event Hubs', 'Ability to provide data architecture and engineering thought leadership across business and technical dimensions solving complex business cases', 'Possesses a deep understanding of enterprise software patterns and how they may be leveraged in modern data management', 'Knowledge of best practices and IT operations in an always-up, always-available service', 'Experience with or knowledge of Agile Development methodologies (SAFe is a plus)', 'Excellent analytical problem solving and troubleshooting skills', 'Excellent oral and written communication skills with a keen sense of customer service', 'Excellent team player with proven ability to influence', 'Highly adaptable to a continuously changing environment', 'Able to give and receive open, honest feedback and to foster a feedback environment', 'Outstanding communication, interpersonal, relationship building skills for team development', 'Possible Travel (10%)', 'Experience within financial services is a plus']",2020-08-08 13:47:50
Global MDR Submission Analyst II,Olympus Corporation of the Americas,N/A,"Center Valley, PA 18034","['Review incoming complaints to determine the facts of the case.', 'Verify information including information available in ancillary systems data sources. (For example: Datasweep, SAP)', 'Performs follow-up to obtain additional information for Adverse Events by collaborating with Field Specialists, Sales Representatives, Engineers, Technicians, Clinicians, and Customers directly.', 'Conducts timely initial MDR reportable assessment/ submission per 21CFR803.', 'Conducts timely re-assessments when new information has been received to determine if an initial or supplemental MDR is required per 21CFR803.', 'Assist with preparation and submission of FDA Additional Information responses, and associated documentation to the FDA and Manufacturing Business Centers (MBCs).', 'Assist Global MDR Submission Management in the successful identification and resolution of quality issues associated with complaints.', 'Key Team player working closely with other Global MDR Submission Associates.', 'Perform other duties as assigned. Job Requirements', 'Bachelor of Science degree with 1-3 years medical device experience or Associate degree with scientific discipline with 3-5 years medical device experience (i.e. Associate RN, X-Ray technician, Biomedical technician)', 'Effective communication skills - both written and verbal English language.', 'Ability to effectively prioritize and manage workload.', 'Knowledge/ ability to utilize various software/ database sources.', 'Complaint Handling/ Customer Service experience in the Medical Device/ Pharmaceutical required.']",2020-08-08 13:47:50
Entry level Business Analyst/Software Eng,Agama Solutions,3.8 out of 5,"Charlotte, NC","['Analyze science, engineering, business, and other data processing problems to implement and improve computer systems.', 'Analyze user requirements, procedures, and problems to automate or improve existing systems and review computer system capabilities, workflow, and scheduling limitations.', 'May analyze or recommend commercially available software. Responsible for change control and stakeholder management.', 'Provide business analysis for technology projects.', 'Acts as senior liaison between client area, technical organization, and other affected areas of planning, conducting, and directing the analysis of highly complex business problems to be solved through strategic e-commerce-based solutions (e.g. Intranet and Internet).', 'Act as a Business and Systems Analysis for Technology Projects.', 'Act as a senior level internal consultant within technology and business groups by evaluating current processes and recommending e-commerce solutions that reduce costs or extent current capabilities.', 'Completing Functional System Design.', 'Collaborate with a multitude of professionals across the organization in order to gain a shared understanding of the needs of the initiative.', 'Create or modify code to implement the needs of the initiative.', 'Ensure that the technical details of the initiative meet performance, reliability, stability, quality, security, and testability standards.', 'Create or modify a suite of tests to exercise the initiative’s functionality in an automated manner.', 'Modify existing software to correct errors, adapt it to updated versions, or to upgraded interfaces and improve performance.', 'Consult with other departments and functions on project status, proposals and technical issues such as software system design and maintenance.', 'Analyze the needs of the initiative with respect to desired outcome in order to determine the technical feasibility while balancing time and cost constraints.', 'Additional responsibilities as assigned.', ""Bachelor's (Required)"", 'United States (Required)', '25% (Preferred)', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Paid time off']",2020-08-08 13:47:50
Administrative Assistant,"H&K Group, Inc.",N/A,"Hazleton, PA 18201","['Job Cost data entry and analyzation.', 'Daily/Weekly employee time sheet entry', 'Archiving daily records', 'Sub-Contractor solicitation', 'Preparation of Bid Documents/Bonds/Bid Forms', 'Estimator Support', 'Miscellaneous duties as assigned']",2020-08-08 13:47:50
Data Engineer,WPS Health Solutions,2.2 out of 5,"Madison, WI","['Improve/maintain/create various data loading/data cleaning packages to ensure data integrity and speed.', 'Work with engineering, data science and product management teams to build and manage a wide variety of data sets.', 'Build and support tools and services for the management and productization of our data.', 'Build and curate data models, along with connected ingestion and harmonization scripts.', 'Work with BI and Data Architects to build application extensions adherent to standards.', 'Author analytics tools for business partners and data scientists to support operational optimization and product innovation.', 'Work closely with Product and Executive leadership to identify and prioritize backlog items to support data infrastructure demands.', 'Author and extend modular, re-usable data pipeline tools that connect disparate source systems into canonical formats.', 'Extract, transform and load data using SQL and NoSQL technologies.', 'Champion SDLC processes and improvements by building and supporting an automated DevOps landscape.', 'Utilize test-driven development to achieve comprehensive quality coverage.', 'Are an innovative, forward-thinking, and self-motivated individual with a strong work ethic and the ability to thrive in a fast-paced environment.', 'Are driven individual with strong written and verbal communication skills, excellent analytical / problem solving abilities.', 'Have strong technical aptitude and customer service skills with an eagerness to learn business processes and needs.', 'Have the ability to execute day-to-day responsibilities with strong attention to detail, quality, and thorough follow-through with stakeholders.', 'Have the ability to work both independently and in conjunction with clients, management, peers, and project resources.', 'Demonstrate the ability to effectively communicate in technical and non-technical terms, at all levels, both within and outside the organization.', 'Are able to design, architect, and maintain a data warehouse that supports a rapidly changing product with our analytics and data service teams.', 'Developing new processes and procedures to enhance data engineering practices.', 'Evaluating new industry data engineering technologies and practices.', 'Working within a focused, energetic, and agile organization', 'Taking a data leadership role on highly complex projects and provide guidance to less experienced staff.', 'Ensuring completeness of all development artifacts, including technical business requirements, technical design, completed code, and implementation.', 'Training and assisting business users or clients in creating critical data access points', 'Working in an environment that serves our Nation’s military, veterans, Guard and Reserves along with their families.', 'U.S. citizenship is required for this position due to Department of Defense restrictions.', ""Bachelor's Degree in related field or equivalent post high school and/or related work experience"", 'Development experience working with third party data ingestion.', 'Experience working within existing frameworks as well as building brand new applications.', 'Experience building ETL data pipelines in a programming language like Python or Scala.', 'Experience with Data Harmonization.', 'Experience designing, building, and maintaining a data warehouse that seamlessly stitches together data from production databases and external APIs to serve consumers', 'Excellent ability to understand the needs of and collaborate with stakeholders in other functions, especially analytics teams.', 'Strong data modelling skills with solid knowledge of various industry standards such as dimensional modelling, star schemas etc.', 'Proficiency in writing performant SQL to work with large data volumes.', 'Experience designing and operating very large Data Warehouses.', 'Experience working with SQL for data exploration, debugging, and performant data access.', 'Experience with developing dashboards and reports on data from sales, call center, and custom software applications.', 'Experience with designing and implementing canonical models.', 'Experience with leveraging MarkLogic search APIs to build RESTful services.', 'Any automated code/data deployments to MarkLogic.', 'Data hub framework (DHF) experience.', 'Eligible for annual Performance Bonus Program', '401(k) with dollar-per-dollar match up to 6% of salary', 'Competitive paid time off', 'Health and dental insurance start DAY 1', 'Vision insurance', 'Flexible spending, dependent care, and health savings accounts', 'Short- and long-term disability, group life insurance', 'Dress for your day', 'Innovative professional and cognitive development programs', 'Life', 'Disability', 'Dental', 'Vision', 'Voluntary benefits']",2020-08-08 13:47:50
MongoDB Sr. DBA,Matrix Resources,4 out of 5,"Harrisburg, PA","['Understanding of NoSQL DBMS and RDBMS concepts', 'Installation, upgrade and management of MongoDB Enterprise Server', 'MongoDB scaling via Replica Sets and Sharding', 'Data modeling and flexible schema concepts', 'MMS/OpsManager monitoring, backup and automation', 'Data movement tools including mongoexport, mongodump, mongoimport, mongorestore, etc', 'Database monitoring tools including mongostat, mongotop, etc', 'MongoDB Connector for BI', 'MongoDB for both on-premises and AWS cloud environments', 'Database security management', 'Database performance evaluations and recommendations', 'Troubleshooting all aspects of MongoDB', 'Disaster recovery planning and implementation', 'Unix shell scripting', 'JSON data and scripting']",2020-08-08 13:47:50
QA Test Engineer (Manual),eNGINE,N/A,"Robinson Township, PA","['Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday']",2020-08-08 13:47:50
Data Warehouse Engineer,TargetCW,4 out of 5,"Denver, CO","['Partner with Enterprise data leadership, product managers, analysts and other engineers to ensure they have the right information to engage with the central data warehouse team and ensure happy customers.', 'Listen to your customers’ challenges, identify opportunities, craft solutions, and deliver the right value at the right time.', 'Demonstrate excellent verbal and written communication - ensure that complex ideas, thoughts, and vision can be communicated simply and effectively.', 'Thrive in a highly collaborative environment.', 'Forge the vision for the central data warehouse platform and how it can make an impact.', 'Bachelors/Masters degree in Computer Science required, or equivalent experience', '3-5 years of data warehouse, integrations and etl development experience in a fast paced company that delivers software', 'Knowledge of all phases of software development including requirements analysis, design, coding, testing, debugging, implementation, and support.', 'Strong analytical and dimensional modeling background', 'Experience in MPP data warehouse systems such as Snowflake, Redshift etc. or similar', 'Experience in ETL tools such as Informatica, Talend, FiveTran, Segment etc. or similar', 'Experience working in agile environment and iterative development', 'Possess strong business acumen-you can communicate effectively with business users', 'Possess strong technical acumen–you can communicate effectively with engineers', 'Collaborative mindset and ability to work with distributed, cross-functional teams', 'Solid communication skills and the ability to clearly articulate your point of view', 'Experience in one or more Hadoop distributions such as Cloudera, MapR etc.', 'Distributed computing experience in environments like Spark, Presto etc.', 'Knowledge and experience with NoSQL databases such as Cassandra, DynamoDB etc.', 'Experience with modern BI tools such as Looker, Tableau etc.', 'Please submit your resume for consideration!']",2020-08-08 13:48:34
Data Engineer,Matlen Silver,N/A,"Charlotte, NC 28202","['8 Hour Shift', 'Monday to Friday', 'Oracle / Informatica: 6 years (Required)', 'Big Data Technologies: 5 years (Required)', 'Data Analysis: 3 years (Required)', 'Data Warehouse/ BI Delivery: 2 years (Preferred)', 'Charlotte, NC 28202 (Required)', 'Yes', 'No: Not providing sponsorship for this job', 'https://www.matlensilver.com/', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-08-08 13:48:34
Software Engineer,RedStream Technology,N/A,"New York, NY 10165","['Contract role in NYC', 'Well-versed in Linked Data, Metadata, SPARQL, OWL, Knowledge Representation, Web Standards, W3C, Digital Libraries, Resource Description Framework (RDF), Semantic Technologies, Ontologies & taxonomies', 'Monday to Friday']",2020-08-08 13:48:34
Senior Data Engineer,Seven Resourcing,N/A,California,"['Design systems that reliably and efficiently provide interactive query performance on large amounts of multi-modal data', 'Build systems that handle scale', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a variety of data sources using SQL and AWS ‘big data’ technologies', 'Collect, parse, analyze, and visualize large sets of data', 'Turn data into insights', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product', 'Experience with large-scale data and query optimization techniques', 'Experience with ETL to data warehouse systems', 'Experience with AWS cloud services: EC2, RDS, Redshift, Aurora', 'Expert in SQL, NoSQL, and RDBMS', 'Knowledge in multiple scripting languages (e.g. Python)', 'Knowledge of cloud, distributed systems, and stream-processing systems', 'Passionate about learning new technologies and solving hard problems in a fast-paced environment', 'Has a Computer Science degree', 'Is a ""student of the game"" and thrives on new challenges', ""Enjoys learning from teammates, and isn't afraid to teach others at the same time"", 'Sees the glass half-full. This is a new industry space...your vision could make all the difference!', 'Wants to make a lasting impact and lifelong connections, this is not just another paycheck', '401(k)', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Professional Development Assistance', 'Vision Insurance', 'Monday to Friday', 'Where have you used data insights to build software products?', 'Bonuses', 'Fully Remote', 'Yes']",2020-08-08 13:48:34
Data - Data Engineer (ETL),"Quadrant, Inc.",3.9 out of 5,"Reston, VA 20191",[],2020-08-08 13:48:34
AWS Sr. Data Engineer,Sparkle Soft LLC,N/A,"Atlanta, GA 31156",[],2020-08-08 13:48:34
Azure Data Engineer,Oxford Global Resources,3.6 out of 5,"Cincinnati, OH 45242",['Monday to Friday'],2020-08-08 13:48:34
Disaster Recovery Solutions Engineer,Brooksource,3.8 out of 5,"Louisville, KY","['Review daily DR operations reports and escalate anomalies of concern in a managed service vault environment', 'Work with data governance, IT security and engineering teams to develop and apply data protection pattern standards', 'Able to facilitate discussion with business and IT to establish target candidates for vaulting service', 'Assist in the development and execution of operations manual, disaster recovery test plans and recovery process', 'Support development of recovery strategies', 'Actively participate and support cloud transformation for DR', 'Review and evaluate point solutions and technologies for disaster recovery', 'Engage in both on-prem and cloud DR testing through all faces of test lifecycle', 'In conjunction with other Disaster recovery team members, produce periodic gap analysis reports', 'Bachelor’s Degree in Computer Science, Information Technology or equivalent experience', 'At least three years of IT Operations experience', 'Prior experience with data backup functions and technologies including Dell Data Domain, Avamar and Rubrik', 'Prior experience with VMware vSphere and Site Recovery Manager', 'Knowledgeable of Dell and Pure data storage technologies', 'Microsoft Azure Fundamentals certification', 'Proficient with MS Word, Excel, PowerPoint, Visio and Access', 'Prior experience creating and executing disaster recovery or cyber recovery test plans', 'Microsoft Azure Solutions Architect Expert certification', 'Experience with Terraform templates', 'Day shift', 'Monday to Friday', 'One location', 'Fully Remote', 'Yes', 'Ops Manager', '8AM', '5PM', 'Yes']",2020-08-08 13:48:34
BI Engineer (Tableau & Looker),TargetCW,4 out of 5,"Mountain View, CA 94043","['2+ years of professional experience in developing technical BI data solutions and providing business intelligence in a fast paced industry', 'Expert level experience working with SQL and relational and multidimensional database schemas and designs', 'Experienced with Tableau including site management, user group management, cloud migration', 'Experienced with Looker including LookML, cloud migration', 'Familiar with analytics infrastructure such as AWS, python/R environment.', 'Experience with data warehousing and/or ETL processes, and distributed computing (Hive/Presto) and Snowflake', 'Experience with user access control, data governance', 'Experienced with BI tool architectures, functions and features']",2020-08-08 13:48:34
Data Architect | Hiring Now,Vaco,3.7 out of 5,"Richmond, VA 23219","[""Work directly with our clients and internal executives in presale and client delivery environments to architect sustainable data solutions, design data engineering delivery plans and mentor our data engineers build and maintain these solutions.Leverage your advanced software engineering expertise including experience analyzing transactional and reporting system data and available cloud and on-prem storage and retrieval options. Design interactions with large-scale processing systems, develop real-time integrations leveraging RESTful APIs, and develop scalable data structures to address our client's most pressing data engineering needs.Partner with clients and provide leadership to our data engineering team members in developing, constructing, testing and maintaining first-class data architectures.Share your experience supporting real-time data, data streaming, scalability of the platform and management of large volumes of data.Use your mastery of a variety of languages and tools to marry systems and data while recommending ways to improve current systems and data reliability, efficiency and quality.Provide thought leadership internally and externally, always staying abreast of the very latest tools and technology available.Leverage your deep expertise in data engineering best practices, serving as mentor and coach to team members, sharing the expertise throughout our team.Create sophisticated analytics programs, machine learning and statistical methods to prepare data for use in predictive analytics.Bring a focus to automating our clients' work through the use of the solutions you develop.Collaborate with API developers to build data-driven microservices for our clients"", 'Designing, developing, scaling, and maintaining data using Spark, Kafka, Hive, Python or Scala.Experience with modern ETL and workflow capabilities such as Apache Airflow, Luigi and Jenkins.Experience designing and implementing SQL and NoSQL systems of record.Experience designing and implementing various data hub architectures, supporting a variety of business use cases.Hadoop DeveloperPutting modern data platforms into use, including platform as a service variant.Providing expertise with humility; communicating complex ideas with clients?and technical staff.Using Git or Github in a CI/CD development workflow.Developing microservices using languages like Java, Python or JavaScript?and using REST?APIs.Writing?effective technical documentation and thought leadership artifacts (best practices, blogs, client documentation).Automating deployments using DevOps tools like Docker, Ansible, Terraform, or Kubernetes.']",2020-08-08 13:48:34
Service Engineer,Eastern Staffing & Recruiting,3.8 out of 5,"Ladson, SC 29456","['Trains customers and internal employees on products, performance improvements and quality standards to ensure total customer satisfaction.', 'Follows up with customers on performance by evaluating data-driven metrics and output results.', 'Performs installations and support utilizing hand tools, multimeter, ability to read wiring schematics, mechanical skillset, and PLC ladder logic understanding.', 'Performs system analysis of current workflow and proposed setup to improve customer efficiency and system effectiveness, including proposals to add, remove, or modify existing configurations and supporting peripherals.', 'Consults with customers and internal management for final approval of proposed modifications and documentation.', 'Assists the engineering department in the testing of new software and hardware.', 'Develops recommendations to enhance or replace existing hardware and/or software based on customer experience.', 'Submits written and accurate reports in a timely manner.', 'Interacts with customers to analyze and solve hardware and software issues', 'Disassembles and reassembles machines to repair or replace worn or malfunctioning components and consumables.', 'Provides excellent customer service, listening carefully to customer concerns and addressing issues until the customer is satisfied', 'Writes accurate and timely reports.', 'Makes recommendations to the Customer Service management team to improve customer service or workflow efficiency.', 'Assists in the testing, development of new software and hardware to enhance quantitative and qualitative customer needs.', 'Drives continuous improvement for all customer service implementation and activities while upholding the highest standards of quality and professionalism.', 'Gathers data, creates, composes, and edits user instructions and customer reports.', 'Ensures that all related work is performed properly, efficiently, and in a cost-effective manner.', 'College degree within an engineering concentration preferred. e.g. Mechanical, Industrial, Electrical, or Computer Sciences.', '3+ years of experience in electro-mechanical or engineering role.', 'Advanced technician level knowledge of installing, troubleshooting, and repairing electro-mechanical systems.', 'Must have the ability to read blueprints, wiring schematics, and PLC controls.', 'The ideal candidate will be self-motivated, highly organized, and possess high attention to detail.', 'Must have excellent communication skills – both written and verbal.', 'Software Experience: MS 365, MS upgrades, Networks, Servers, and a basic understanding of MS SQL.', 'Mechanical Experience: hand tools, power tools: drills, electric saws, rivet guns, and pallet jacks.', 'Ability to lift up to 50 lbs.', '10 Hour Shift', '8 Hour Shift', 'Day shift', 'Monday to Friday', 'troubleshooting: 3 years (Required)', 'mechanical: 3 years (Required)', 'electrical: 3 years (Required)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Weekly', 'A job for which military experienced candidates are encouraged to apply']",2020-08-08 13:48:34
Data Integration Software Engineer,HealthCare,N/A,"Boston, MA","['Design, Code, and Test back-end Ruby on Rails systems for transforming and ingesting patient data', 'Implement automated tests with RSpec', 'Work with Product and Engineering teams to understand and contribute to functional and technical requirements', 'Collaborate with Customer Support team to research, understand, and resolve data integrity problems', 'Collaborate with Integration team to analyze new data sources and implement systems to ingest data into the CarePort platform', 'Implement logic for segmenting patient data according to customer-defined rules', 'Ensure all work is peer reviewed to ensure code quality and to develop a shared understanding of the work that is being done', 'Peer review and sign-off of others work', 'Timely and accurate reporting of project status', 'Escalate product issues and suggest product improvements', 'Escalate all issues in a timely fashion', 'Mentor junior team members in best practices and standards', 'Proficiency and recent experience building applications with Ruby on Rails', 'Proficiency in database design and querying, both with SQL and Active Record', 'Proficiency in writing automated tests with RSpec or similar testing framework', 'Experience using git and GitHub for source code management and peer review', 'Experience building systems for parsing and transforming data, including HL7,XML, delimited flat files', 'Experience working with containerized deployment environments (eg, Docker)', 'Experience transporting data through various protocols including REST APIs,', ""Successful completion of a Bachelor's Degree or relevant Technical / Business Experience."", 'Ruby on Rails: 6 years (Required)', 'SQL: 5 years (Required)', 'RSpec: 6 years (Preferred)', 'No']",2020-08-08 13:48:34
"Data Architect | $130-160k | Direct-Hire | Richmond, VA",Vaco,3.7 out of 5,"Richmond, VA 23219","[""View your clients' success as your ownAre passionate about what you doLove to teach yourself new skillsSeek opportunities to learnThrive in ambiguityEnjoy working on a teamEasily adapt to new project requirements and client expectations"", ""Work directly with our clients and internal executives in presale and client delivery environments to architect sustainable data solutions, design data engineering delivery plans and mentor our data engineers build and maintain these solutions.Leverage your advanced software engineering expertise including experience analyzing transactional and reporting system data and available cloud and on-prem storage and retrieval options. Design interactions with large-scale processing systems, develop real-time integrations leveraging RESTful APIs, and develop scalable data structures to address our client's most pressing data engineering needs.Partner with clients and provide leadership to our data engineering team members in developing, constructing, testing and maintaining first-class data architectures.Share your experience supporting real-time data, data streaming, scalability of the platform and management of large volumes of data.Use your mastery of a variety of languages and tools to marry systems and data while recommending ways to improve current systems and data reliability, efficiency and quality.Provide thought leadership internally and externally, always staying abreast of the very latest tools and technology available.Leverage your deep expertise in data engineering best practices, serving as mentor and coach to team members, sharing the expertise throughout our team.Create sophisticated analytics programs, machine learning and statistical methods to prepare data for use in predictive analytics.Bring a focus to automating our clients' work through the use of the solutions you develop.Collaborate with API developers to build data-driven microservices for our clients"", 'Designing, developing, scaling, and maintaining data using Spark, Kafka, Hive, Python or Scala.Experience with modern ETL and workflow capabilities such as Apache Airflow, Luigi and Jenkins.Experience designing and implementing SQL and NoSQL systems of record.Experience designing and implementing various data hub architectures, supporting a variety of business use cases.Hadoop DeveloperPutting modern data platforms into use, including platform as a service variant.Providing expertise with humility; communicating complex ideas with clients?and technical staff.Using Git or Github in a CI/CD development workflow.Developing microservices using languages like Java, Python or JavaScript, and using REST APIs.Writing?effective technical documentation and thought leadership artifacts (best practices, blogs, client documentation).Automating deployments using DevOps tools like Docker, Ansible, Terraform, or Kubernetes.']",2020-08-08 13:48:34
"AWS Cloud Engineer with Java, Python",Concepts Beyond,N/A,"Washington, DC","['Develop Web Services (SOAP/REST), XML Messaging Services in Java, Python, and other languages', 'Design, architect AWS cloud services and security solutions', 'Design, develop real-time, large-scale data processing and streaming functions using Apache Flink , Lambda functions, Amazon Glue, NiFi, Kafka, Apache Spark, and other technologies', 'Prepare architecture documents, user guides, diagrams, and briefings to convey complex technical information to a wide range of audiences', 'Architect, setup, and develop scalable Big Data solutions including AWS EMR, Spark, Hadoop, and Internet of Things applications', 'Design and develop algorithms, tools, and software for various aviation applications, flight data processing, and data analyses', 'Bachelor’s degree or higher in Computer Science, Engineering or related technical field from a US accredited institution', '3+ years of development experience (Java, Python) in enterprise messaging system architectures (Service Oriented Architecture, Microservices, etc.)', 'AWS Certification', 'Experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.', 'Experience performing data Management, modeling, and warehousing', 'Experience with cloud data and application migration', 'Experience using Agile software development methods in a DevOps environment', 'Experience with J2EE full stack development, Java Messaging Services, Web Services', 'Experience with automated unit testing (such as JUnit)', 'Excellent communication and writing skills', 'Ability to work independently and understand complex technical terms/materials', 'Familiarity with Agile/Scrum process', 'Knowledge with User Interface using AngularJS/JSF/ReactJS', 'Experience with backend development in PostgreSQL and Oracle 12c Databases – 3+ years', 'Experience with IDE, SQL tools, and build tool –ANT, Maven, Netbeans', 'Experience in FAA systems, cloud, GovCloud, architecture, security, NIST standards', 'Experience with Big Data, Apache NiFi, Spark, Hive, Elasticsearch, Hortonworks, IoT, Muelsoft Integration Platform', 'Experience with Data Analytics, Global Aviation Exchange Models (AIXM, FIXM, iWXXM), Air Traffic Management (ATM) knowledge, AMHS', 'Monday to Friday', 'AWS: 3 years (Preferred)', 'Java Development: 3 years (Preferred)', ""Bachelor's (Required)"", 'Washington, DC (Preferred)', 'http://conceptsbeyond.com', 'Temporarily due to COVID-19']",2020-08-08 13:48:34
Clinical Data Analyst (Remote),Kelly,3.9 out of 5,California,"['Maintain architecture for device generated data pipeline', 'Assemble and report on large, complex data sets that meet business requirements', 'Identify, design, and implement internal process improvements: automating and optimizing manual processes, data extraction, transformation, loading of the data, and data delivery', 'Work with stakeholders including the data managers, statistical programmers, and the statisticians to assist with device data-related technical issues and support their data infrastructure needs.', 'Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or related quantitative field. Advanced degree preferred.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing data pipelines, architectures and data sets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'A successful history of manipulating, processing and extracting value from large datasets', 'Strong project management and organizational skills', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Experience in medical device or pharmaceutical environment preferred', 'At least 3years of experience in a Data Engineer role, with experience using the following software/tools: Big data tools: Hadoop, Spark, etc.', 'Relational SQL and NoSQL databases (Experience with Hive preferred)', 'Analysis and visualization software such as R, RStudio, Python, and Tableau', 'Data pipeline and workflow management tools', 'benefits to be received upon meeting eligibility requirements']",2020-08-08 13:48:34
"Sr Software Engineer, Data",Ally Financial Inc.,3.6 out of 5,"Charlotte, NC 28217","['Architect and build to enhance an ever-expanding data platform supporting business process needs for internal and external integration via APIs, data models, self-serve reporting solutions, and interactive querying', 'Define, build, test, document and audit data platform artifacts including data models, data flow processes, integrations, etc.', 'Develop best practices and frameworks for unit, functional and integration tests around data pipelines, and drive the team towards increased overall test coverage', 'Design Continuous integration and deployment processes and best practices for the production data pipelines', 'Work with the latest and greatest technologies in the Microsoft cloud stack including Azure SQL, Synapse, Data Lake, Data Factory, Databricks, Azure function, Service Bus, etc.', 'Collaborate and influence Users, Engineers and Products stakeholders to ensure our data infrastructure meets constantly evolving requirements', 'Identifies opportunities to adopt innovative technologies that fuels company vision', ""4-year / bachelor's degree in computer science or equivalent field from an accredited college or university"", '2+ years of relevant work experience', 'Experience working with cloud platforms such as Azure or AWS', 'Working knowledge of real-time data processing, data pipelines, transformation and modeling using traditional and distributed systems', 'Experience with development of test automation solutions', 'Detailed knowledge of Relational, Multi-Dimensional databases and No-SQL solutions', 'The successful candidate will have strong programming skills, especially in SQL, data modeling and related data processing concepts', 'Experience with OO programming language like C#, Java or Python', 'Experience with developing and architecting data ingestion models, ETL jobs, and alerting to maintain high availability and data integrity', 'Time Away: competitive holiday and flexible paid-time-off, including time off for volunteering and voting.', 'Planning for the Future: benefits to help you plan for the near and long term including an industry-leading 401K retirement savings plan with matching and company contributions, student loan and 529 educational assistance programs, tuition reimbursement and other financial well-being programs.', 'Supporting your Health & Well-being: flexible health and insurance options including dental and vision, pre-tax Health Savings Account with employer contributions and a total well-being program that helps you and family stay on track physically, socially, emotionally and financially.', 'Building a Family: adoption, surrogacy and fertility support as well as benefits that help you take care of your family - parental and caregiver leave, back-up child and adult/elder day care program and child-care discounts.', 'Work-Life Integration: other benefits including LifeMatters® Employee Assistance Program, subsidized and discounted Weight Watchers® program and other employee discount programs.']",2020-08-08 13:49:21
Workflow Engineer,"Broomall, PA",N/A,N/A,"['A great team player', 'A good communicator', 'Passionate about their work and customer success', 'Security-conscious at all times.', '2 years’ enterprise programming experience', '2 years’ actual experience building Software-as-a-Service:', 'Debugging complex problems', 'Automated regression testing', 'Optimizing application <-> database communication', 'Profiling memory and performance concerns for optimization', 'Troubleshooting connectivity problems (network / app server / certificates / authentication)', 'SQL query construction and best practices', 'Reading/writing XML and JSON', 'Creating complete documentation for support and release management', 'Experience in both Waterfall and Agile development', 'Excellent analytical and critical thinking skills', 'The capacity to multitask and excel in a fast-paced, evolving environment', 'Strong written, verbal and demonstrative communication skills', 'Attentive to detail', 'Seeking challenges and growth', 'Able to travel domestically and internationally, as needed (typically less than 25%).', 'A degree in computer science, mathematics or philosophy', 'Experience in billing (i.e. financial systems, payment processors, tax engines, etc.)', 'Experience handling PCI data in a secure manner', 'Experience in business process and business rules automation', 'Experience developing mission-critical, high capacity, high availability SaaS applications for enterprise', 'Experience integrating with multiple SaaS services', 'Experience integrating systems over HTTPS', 'Experience developing rules-based process automation', 'Fluency with Decision Model and Notation', 'Fluency with Business Process Model and Notation.']",2020-08-08 13:49:21
Blue Seal Stationary Engineer,System One,3.6 out of 5,"Township of Ewing, NJ","['Under direction of the Chief Operating Engineer, takes a leading part in the operation, maintenance, adjustment, and minor repair of the Central Utilities Plant, including co-generation, steam, and chiller plants and all associated auxiliary equipment', 'Serves as shift engineer in charge of the operation of the co-generation plant, boilers, turbines, generators, chillers, and auxiliary equipment used in the Central Utilities Plant', 'Operates, maintains, and makes repairs to the co-generation plant, generators, boilers, chillers, feed and vacuum pumps, fans, compressors, governors, and chemical treatment equipment', 'Makes periodic comprehensive tests and takes readings of fuel consumption, pressure, room circulating units, draft conditions, temperature and steam flow, and other recordings', 'Performs water quality tests and chemically treats plant water systems', 'Analyzes campus load requirements and makes appropriate adjustments to co-generation plant KW import set-point relative to total load', 'Ensures plant operation maintains environmental compliance with NJ DEP and US EPA requirements cited in Title V Air Permit', 'Must have the ability to work day and night shift, weekends and rotating shifts', 'High School Diploma or GED required', '2+ years of broad experience in commercial/industrial environment as an Operating Engineer', 'A minimum of a Blue Seal License required', ""Possession of valid driver's license in good standing issued by state of residence is required"", 'Prior experience with the operation and maintenance of boilers, engines, motors, turbines, and auxiliary equipment used in power generation, heating plants, and chiller plants', 'Ability to read, write, speak, understand, and communicate in English sufficiently to perform the duties of this position', ""Knowledgeable of plant's operating and regulatory compliance requirements, and has the ability to record, report and file information relative to operational data"", 'Ability to work rotating shifts, days and nights, including weekends, holidays and overtime as needed.']",2020-08-08 13:49:21
Administrative Assistant,"H&K Group, Inc.",N/A,"Hazleton, PA 18201","['Job Cost data entry and analyzation.', 'Daily/Weekly employee time sheet entry', 'Archiving daily records', 'Sub-Contractor solicitation', 'Preparation of Bid Documents/Bonds/Bid Forms', 'Estimator Support', 'Miscellaneous duties as assigned']",2020-08-08 13:49:21
Security Engineer Policy Exceptions (remote). 72.00 per hour on w2.EE,Lenmar Consulting,3.5 out of 5,"Jersey City, NJ 07302","['Monday to Friday', 'sales: 1 year (Preferred)', 'Security: 1 year (Preferred)', 'High school or equivalent (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 13:49:21
Jr. Data Warehouse Developer,Brooksource,3.8 out of 5,"Richardson, TX","['Assists the team with technical direction for the design, development, testing, implementation, and maintenance of DW solutions', 'Hands-on experience and knowledge of Data Warehouse best practices, Teradata, and Informatica ETL.', 'Assists the technical team in identification and resolution of Data Quality issues', 'Experience in configuration management and software release principles as well as change management concepts', 'Work effectively with technical personnel (Development Team, Systems Analysts, Testers), and clearly translate business priorities and objectives into technical solutions.', ""1-2 years' experience working within Data Warehousing"", 'Experience utilizing SQL in a professional environment', 'Hands on ETL (e.g., Informatica/DataStage) experience', 'Experience working with Teradata or related Appliance']",2020-08-08 13:49:21
Data Engineer,Insight Global,4 out of 5,"Hartford, CT 06103","['5+ year experience as Data Engineer or Data Architect', 'Expert in big data tools: Hadoop, Spark, etc.', 'Experience with relational SQL and NoSQL database architecture.', 'Experience with Business Intelligence (BI) tools: Business Objects, Tableau, etc.', 'High proficiency in Microsoft Office (Word, Excel and Visio) is required.', 'Minimum 3 years of experience in financial services. Experience in insurance, annuity or investment banking is required.', '401(k)', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Vision Insurance', 'Monday to Friday', 'Yes', 'People-oriented -- enjoys interacting with people and working on group projects', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Innovative -- innovative and risk-taking', 'Stable -- traditional, stable, strong processes', 'Temporarily due to COVID-19']",2020-08-08 13:49:21
Python or GO Developer - AWS & Data Structures,Computer Enterprises Incorporated,N/A,"Philadelphia, PA 19103","['Continue development of the MachineQ API by providing testable and easily maintainable code in Go', 'Cooperate with other front-end and back-end developers', 'Coordinate deployment strategy and system changes with operations', 'Participate in architectural design discussions and planning sessions', 'Interface and extract information from managers, team leaders, and stake holders to come up with appropriate technical solutions for the business.', 'Assist with timeline planning and release schedules to ensure timely execution of all deliverables', 'Strong leadership skills required.', 'Strong organizational and technical skills.', 'Ability to adapt to changing product requirements and manage deadlines.', 'Interface with business, product, and other engineering teams.', 'Designs and develops scripts, applications, and automation required for large scale infrastructure management, automation, and monitoring.', 'Support incident management for operational issues including availability for support after hours.', 'Identify opportunities for system enhancements that will deliver enhanced functionality and/or simplify system administration.', 'Work closely with BA/QA team members to ensure that issues are properly identified, fixed, and tested.', 'Comfortable giving demonstrations of technical products and systems.', 'Willingness to travel (up to 10% of time).', 'Experience with building and maintaining modern rest web services.', 'Experience with GRPC or protocol buffers.', 'Experience with at least one compiled language (Go strongly preferred).', 'Experience with at least one interpreted language (Python, Ruby, Perl).', 'Proficiency with PostgreSQL or other modern RDB.', 'Experience with message brokers or other data structure stores (redis, mqtt, amqp, kafka).', 'Experience with distributed, cloud-native systems.', 'Experience with Git and modern software engineering practices.', 'Experience with CI/CD systems.', 'Strong proficiency with Linux.', 'Strong proficiency with Terraform, Helm, or Ansible.', 'Ability to work in a collaborative environment and coach other team members on coding practices, design. principles, and implementation patterns that lead to high-quality maintainable solutions.', 'Exposure to distributed, large-scale back-end design and implementation.', 'Experience with Kubernetes.', 'Experience in database design and optimization.', 'Experience with authentication/authorization techniques.', '401(k) Matching', 'Health Insurance', 'Life Insurance', 'Monday to Friday', 'Python: 5 years (Preferred)', 'One location', 'Yes']",2020-08-08 13:49:21
Data Engineer,Ascent Services Group,3.7 out of 5,"Westminster, CO 80234",[],2020-08-08 13:49:21
Big Data Engineer,Robert Half,3.9 out of 5,"Boston, MA 02110","['Minimum BS in Computer Science, Electrical Engineering or equivalent', 'Minimum 5+ years experience building large scale, cost effective and robust data processing platforms', 'Demonstrable experience creating multi tenant databases and ETL pipelines', 'Strong experience in database schema design, analytics data modeling', 'Strong SQL programming and query optimization', 'Experience with Spark, EMR, Presto, Hive, Scala, Redshift, Pentaho, SQL, etc.', 'Experience with Linux, Shell Script and Python', 'Experience with AWS and/or Azure cloud', 'Good understanding of data security and encryption', 'Healthcare Insurance Domain experience strongly preferred', 'Ability to work effectively as part of a team, with strong interpersonal and communication skills']",2020-08-08 13:49:21
Full Stack Engineer,Brooksource,3.8 out of 5,"Franklin Lakes, NJ 07417","['Bachelor’s Degree in Computer Science or related field', '2+ year of Java development experience', '2+ years of professional experience with React.js', '2+ years of professional experience with SQL and/or Relational Databases such as Oracle, MySQL, Teradata', 'Knowledge of Agile Methodology and general cloud systems', 'Create, develop, and perform maintenance applications to meet the business needs of the organization', 'Design and write high performance, reliable, reusable and easily maintained Java code', 'Perform software testing, debugging, documentation and installation teaks', 'Monitor and continually improve the content, quality, and documentation of all applications', 'Support existing solutions and provide solution support after implementation in the form of production support', 'Work closely with internal employees across departments to gather, analyze and document business requirements', 'Opportunity to work at a Fortune 13 Health Care Company', 'Mentorship by senior leadership', 'Ongoing technology training', 'Weekly paychecks', 'Onsite cafeteria', 'Monday to Friday']",2020-08-08 13:49:21
"Software Engineer, Data Platform (Go)",New Relic,3.3 out of 5,"Portland, OR 97204","['3+ years of professional experience deploying and shipping software in a software production environment.', 'Fluency in a statically-typed, compiled backend language; Go preferred but Java, C, or C++ are acceptable.', '1+ years of experience with Kubernetes.', 'Experience using the command line to manage, investigate, and fix things when they’re broken.', 'Willingness to be on-call for the software you build and a genuine desire to learn from mistakes.', 'Experience working in the public cloud.', 'Knowledge of fundamentals required to build and operate highly-available software at scale, including data structures, architectural patterns, and distributed systems.', 'Experience or interest in DevOps, infrastructure automation, and/or high-throughput software.', 'Experience on distributed teams. Our team is currently based out of the Portland office, but we are part of a group that is distributed across North America and Europe. An ability to work well asynchronously and communicate your thoughts in writing will be a big asset.']",2020-08-08 13:49:21
Plant Logistics Engineer,"HTI - Human Technologies, Inc.",3.5 out of 5,"Chattanooga, TN","['Ensure that safety policies are understood and respected within his area of responsibilities  * Implement corporate supply-chain best practices in the plant', 'Prepares the supply-chain KPIs and update the related action plans for review by the Plant Logistics Manager  * Maintain and optimize supply-chain systems (production planning, EDI)', 'Design and implement improvements in the supply-chain (upstream, internal and downstream physical and information flows) based on Lean principles.', 'Contribute to the TPM Supply-Chain Pillar (and/or to others) - Lead or participate to workshops, kaizen…  * * Define optimum stock levels at each step of the production process', 'Work with engineering and logistics to develop and implement optimum flow , storage and layout solutions (for new products and changes of process and as continuous improvement for existing flows)', 'Do time studies', 'Update the book of flows', 'Specify the requirements in term of information systems and communicate them to the ITS Manager and System Controller', 'Packaging', 'Manage rack repairs', 'Build training modules and lead training actions', ""High School Diploma/GED, Bachelor's Degree preferred"", 'Dedication to Safety', 'Computer literacy (SAP, Excel, Access) - Data analysis', 'TPM & Lean principles', 'logistics engineering: 3 years (Preferred)', 'SAP: 2 years (Preferred)', ""Bachelor's (Preferred)"", 'No']",2020-08-08 13:49:21
Software Engineer,Tausight,N/A,United States,"['Design, implement, test, and scale major components of our data processing pipeline', 'Develop user-facing features for our Web UI application', 'Work closely with product teams implementing wireframes and feedback into high quality code', 'Be proactive as a developer who builds testable, resilient software', 'Effectively use tools and ingenuity to identify and fix defects', 'BS in Computer Science or related technical field involving coding', '3+ years of software engineering experience', 'Experience with Javascript as well as an object-oriented language such as Java or C++', 'Understand engineering tradeoffs, valuing pragmatism over idealism.', 'Analytical approach coupled with strong communication skills', 'Shares the values of ownership, diversity of thought, and empathy for our users and coworkers', 'MS in Computer Science or related technical field involving coding (e.g., Mathematics)', 'Experience maintaining and debugging distributed systems in production environments', 'Experience with Google Cloud Platform technologies such as Pub/Sub, Dataflow, Datastore, BigQuery, or Kubernetes', 'Experience with Node, React, or GraphQL', 'Experience with CI/CD and testing automation frameworks', 'Data security is one of the fastest growing segments of the $3 trillion healthcare industry', 'Already backed by two leading healthcare technology VCs, Flare Capital and Polaris Partners', 'Cutting-edge platform, Google-powered streaming analytics, and novel predictive intelligence', 'Highly experienced team to learn from and to help develop your personal growth', 'Unlimited vacation; company holidays; medical/dental/eyecare', 'Stock options - early is the best time to get them', 'We work remotely. Already committed to remain this way through at least July 2021', 'DIVERSITY - Our organization will be stronger and more resilient when we encompass a variety of experiences, opinions, and backgrounds. We will aim for a Tausight community of employees, board members, advisors, and partners that resembles the broader and far more diverse socio-economic and global world that we live in. Specifically, we will grow into a team of passionate, healthcare-dedicated individuals that span age, ethnicity, gender identity, sexual orientation, and race.', 'EQUITY - We will work toward fair outcomes for people and groups by treating them in ways that address their unique advantages or barriers.', 'BELONGING - All members of our community will feel equally valued and their voices and points of view are to be heard and respected. We will take deliberate actions to cultivate an atmosphere where all employees feel included, can contribute, and thrive.', 'Health Insurance', 'Paid Time Off', 'Referral Program', 'Monday to Friday', 'Software Engineer: 3 years (Required)', 'Multiple locations', 'Fully Remote', 'tausight.com']",2020-08-08 13:49:21
Sr. Data Engineer/Scientist,Insight Global,4 out of 5,"Bentonville, AR 72716","['Previous Professional Experience in BOTH Data Engineering & Data Science', '3 to 6 years of experience in Data Engineering', 'Ability to make use of raw data in order to develop, construct, test, and maintain architecture', 'Develop data set processes', ""Complete pipeline ingestion's"", 'Build Kafka streamlines', 'Spark, SQL, Hive', 'At least 1 year of professional experience as Data Scientist', 'Extensive research to answer business questions', 'Statistical data analysis, data mining & data modeling', 'Forecasting and optimization (using data to create predictive models)', ""Knowledge and understanding of Machine learning (doesn't need to be high level)"", 'Python', 'At least 3 years of experience doing Statistical modeling (forecasting, linear programming )', 'Familiarity Azure and GCP environment', 'CICD – what are they doing with it?', 'Industry experience in Supply Chain', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Relocation Assistance', 'Vision Insurance', 'Monday to Friday', 'Bonuses', 'Other forms', 'Dependable -- more reliable than spontaneous', 'People-oriented -- enjoys interacting with people and working on group projects', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Achievement-oriented -- enjoys taking on challenges, even if they might fail', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'High stress tolerance -- thrives in a high-pressure environment', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'Team-oriented -- cooperative and collaborative', 'Temporarily due to COVID-19']",2020-08-08 13:49:21
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:50:04
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:50:04
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:50:04
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:50:04
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:50:04
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:50:04
"Engineer, Data",SiriusXM,3.6 out of 5,"New York, NY","['Build and deploy streaming and batch data pipelines capable of processing and storing petabytes of data quickly and reliably.', 'Collaborate with product teams, data analysts and data scientists to design and build data-forward solutions.', 'Gather and process all types of data including raw, structured, semi-structured, and unstructured data.', 'Integrate with a variety of data providers ranging from marketing, web analytics, and consumer devices including IoT and Telematics.', 'Build and maintain dimensional data warehouses in support of business intelligence tools.', 'Develop data catalogs and data validations to ensure clarity and correctness of key business metrics.', 'Design, code, test, correct and document programs and scripts using agreed standards and tools to achieve a well-engineered result.', 'Derive an overall strategy of data management, within an established information architecture (including both structured and unstructured data), that supports the development and secure operation of existing and new information and digital services.', 'Plan effective data storage, security, sharing and publishing within the organization.', 'Ensure data quality and implement tools and frameworks for automating the identification of data quality issues.', 'Collaborate with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings.', 'Provide ongoing support, monitoring, and maintenance of deployed products.', 'Drive and maintain a culture of quality, innovation and experimentation.', 'None', 'Advanced degree in relevant field of study strongly desirable, particularly in computer science or engineering level programs.', 'Minimum 2 years professional experience working with data extract/manipulation logic.', 'Minimum 2 years professional experience with object-oriented programming, functional programming, and data design.', '1-3 years working with a public cloud big data ecosystem (certification in AWS a plus).', '1-3 years working with MPP databases, distributed databases, and/or Hadoop.', 'Passion for data engineering, able to excite and lead by example.', 'Hungry and eager to learn new systems and technologies.', 'Self-directed and enjoys the challenge and freedom of deciding what is the most impactful thing to work on next.', 'Ability to deliver exceptional results through iterative improvement rather than initial perfection.', 'Excellent communication and presentation skills and ability to interact appropriately with all levels of the organization, including: business users, technical staff, senior level colleagues, vendors, and partners.', 'An extensive track record that demonstrates effectiveness in driving business results through data and analytics.', 'The ability to develop and articulate a compelling vision and generate necessary consensus.', 'A successful history of translating business objectives and problems into analytic problems, and analytic solutions into actionable business solutions.', 'A proven ability to influence decision making across large organizations.', 'A proven ability to hire, develop, and effectively lead deeply technical resources.', 'Demonstrate and foster a sense of urgency, strong commitment, and accountability while making sound decisions and achieving goals.', 'Articulate, inspire, and engage commitment to a plan of action aligned with organizational mission and goals.', 'Create an environment where people from diverse cultures and backgrounds work together effectively.', 'Experience deploying and running AWS-based data solutions and familiar with tools such as Cloud Formation, IAM, Athena, and Kinesis.', 'Experience engineering big-data solutions using technologies like EMR, S3, Spark and an in-depth understanding of data partitioning and sharding techniques.', 'Experience loading and querying both on premise and cloud-hosted databases such as Teradata and Redshift.', 'Building streaming data pipelines using Kafka, Spark, or Flink.', 'Familiarity with binary data serialization formats such as Parquet, Avro, and Thrift.', 'Experience deploying data notebook and analytic environments such as Jupyter and Databricks.', 'Knowledge of the Python data ecosystem using pandas and numpy.', 'Experience building and deploying ML pipelines: training models, feature development, regression testing.', 'Experience with graph-based data workflows using Apache Airflow a plus.', 'Knowledge of data profiling, data modeling, and data pipeline development.', 'Strong knowledge with high volume heterogeneous data, preferably with distributed systems.', 'Strong knowledge writing distributed, high-volume services in Python, Java or Scala.', 'Familiar with metadata management, data lineage, and principles of data governance.', 'Knowledge of data modeling, data access, and data storage techniques.', 'Appreciation of agile software processes, data-driven development, reliability, and responsible experimentation.', 'professional role in one or more of the following: Development, Engineering, R&D or Information Technology', 'ETL/ELT Tools', 'BI tools', 'MDM / Reference Data', 'RDBMS, NoSQL and NewSQL', 'MS Office Suite']",2020-08-08 13:50:04
Data Engineer,Emergere Technologies,N/A,"Chicago, IL","['Create and maintain optimal data pipeline architecture,', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Strong analytic skills related to working with unstructured datasets.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field (Masters Preferred).', '5+ years of experience in a Data Engineer role', 'Experience with healthcare datasets, clinical data, payer/claims data, SDOH data, etc.', 'Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Skilled in problem-solving with strong attention to detail.', 'Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.', 'Excellent follow-up skills paired with the ability to multi-task and determine root causes.', 'Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.']",2020-08-08 13:50:04
Data Engineer,PulsePoint,3.9 out of 5,"New York, NY","['Design, build and maintain reliable and scalable enterprise level distributed transactional data processing systems for scaling the existing business and supporting new business initiatives', 'Optimize jobs to utilize Kafka, Hadoop, Presto, Spark Streaming and Kubernetes resources in the most efficient way', 'Monitor and provide transparency into data quality across systems (accuracy, consistency, completeness, etc)', 'Increase accessibility and effectiveness of data (work with analysts, data scientists, and developers to build/deploy tools and datasets that fit their use cases)', 'Collaborate within a small team with diverse technology backgrounds', 'Provide mentorship and guidance to junior team members', 'Installation, upkeep, maintenance and monitoring of Kafka, Hadoop, Presto, RDBMS', 'Ingest, validate and process internal & third party data', 'Create, maintain and monitor data flows in Hive, SQL and Presto for consistency, accuracy and lag time', 'Maintain and enhance framework for jobs(primarily aggregate jobs in Hive)', 'Create different consumers for data in Kafka using Spark Streaming for near time aggregation', 'Train Developers/Analysts on tools to pull data', 'Tool evaluation/selection/implementation', 'Backups/Retention/High Availability/Capacity Planning', 'Review/Approval - DDL for database, Hive Framework jobs and Spark Streaming to make sure they meet our standards', '24*7 On call rotation for Production support', 'Airflow - for job scheduling', 'Docker - Packaged container image with all dependencies', 'Graphite/Beacon - for monitoring data flows', 'Hive - SQL data warehouse layer for data in HDFS', 'Impala- faster SQL layer on top of Hive', 'Kafka- distributed commit log storage', 'Kubernetes - Distributed cluster resource manager', 'Presto - fast parallel data warehouse and data federation layer', 'Spark Streaming - Near time aggregation', 'SQL Server - Reliable OLTP RDBMS', 'Sqoop - Import/Export data to RDBMS', 'BA/BS degree in Computer science or related field', '5+ years of software engineering experience', 'Knowledge and exposure to distributed production systems i.e Hadoop is a huge plus', 'Knowledge and exposure to Cloud migration is a plus', 'Proficiency in Linux', 'Fluency in Python, Experience in Scala/Java is a huge plus', 'Strong understanding of RDBMS, SQL;', 'Passion for engineering and computer science around data', 'Willingness to participate in 24x7 on-call rotation', '401(k) Match and free access to a financial advisor', 'Generous paid vacation/company holidays', 'Vacation reimbursement (we give you $500 to take vacation), sabbatical, pawternity leave, marriage leave, honeymoon bonus', 'Comprehensive healthcare with 100%-paid medical, vision, life & disability insurance', '$2,000 annual training and development budget', 'Complimentary annual memberships to One Medical, NY Citi Bike and SF Ford GoBike', 'Monthly chair massages', 'Free fitness classes (spin, yoga, boxing)', 'Gym reimbursement, local gym membership discounts', 'Onsite flu shots, dental cleanings and vision exams', 'Annual company retreat', 'Paid parental leave and a lot of new parent perks', 'Emergency childcare credits', 'Volunteer Time Off and Donation Matching, ongoing group volunteer opportunities', 'Team lunches, Sip & Social Thursdays, Game Nights, Movie Nights', 'Healthy snacks and drinks']",2020-08-08 13:50:04
Data Engineer,"Clearsense, LLC",4 out of 5,"Jacksonville, FL 32224","['The Data Engineer will support the design and development of data workflows, ETL-like processes, SQL queries, and Visualizations of various clinical and non-clinical databases in the Clearsense Data Ecosystem. They must also demonstrate advanced analytical skills, technical and business knowledge and have a strong understanding of how to leverage industry standard tools and methods to solve problems.The Data Engineer will work closely with Software Engineers by providing data mapping and wrangling expertise and Data Scientists by helping to determine and provide data sets needed for analysis. They often wrestle with problems associated with database integration and messy, unstructured data sets. Their ultimate aim is to provide clean, usable data to whomever may require it.Responsibilities:Research opportunities for data acquisition and new uses for existing dataDevelop data set processes for data modeling, mining and productionEmploy a variety of languages and tools (e.g. scripting languages) to merge data togetherRecommend ways to improve data reliability, efficiency and qualityDefine and Develop Clearsense Data Governance PoliciesAggregate and analyze various data sets to provide actionable insightDevelop reports, dashboards, and tools for business-usersPerform detailed analysis of Customer data sourcesWrite complex SQL queries across multiple data sourcesQualifications:Must have 5+ years within a data management role performing implementation, integration and/or technical development, with a heavy focus on SQL and relational databasesA nice to have is prior use of Data Governance tools and processesA nice to have background would involve knowledge and experience with healthcare data exchange platforms and data aggregation tools and healthcare interoperability and messaging standards, including but not limited to HL7 2.x, HL7 3.x, HL7 FHIR, IHE integration profilesA nice to have background would be an understanding of general medical terminology and healthcare clinical code sets such as LOINC, CPT, ICD, RxNorm, etc.A nice to have background would be a demonstrated advanced knowledge in Healthcare data, HL7 scripting and two or more programming languages, Healthcare operations, process improvement, and application of technology to improve patient outcomes.A nice to have background would be as a highly skilled and proficient knowledge of and experience with build tools of the electronic medical record, and other clinical systems.Self-starter, self-motivated, high level of initiative within a fast-paced, constantly evolving data management environmentResult focused, ability to solve complex problems and resolve conflicts in a timely mannerAbility to travel to Customer sites (up to 10%)REQUIRED:Bachelor’s degree in Data Informatics, Computer Science, Business or related field.Must have experience:SQL, scripting languages, ETL tools and Data workflow tools']",2020-08-08 13:50:04
Software Engineering Internship,Apple,4.2 out of 5,"Santa Clara Valley, CA 95014","['Strong object-oriented design skills, coupled with a deep knowledge of data structures and algorithms', 'Proficiency in one or more of the following developer skills: Java, C/C++, PHP, Python, Ruby, Unix, MySQL, Clojure, Scala, Java Script, CSS, HTML5', 'Experience in sophisticated methodologies such as Data Modeling, Validation, Processing, Hadoop, MapReduce, Mongo, Pig', 'Experience with web frameworks such as AngularJS, NodeJS, SproutCore', 'Proven experience in application development in Objective-C for OS X or iOS a plus', 'Client-Server protocol & API design Skills', 'Able to craft multi-functional requirements and translate them into practical engineering tasks', 'A fundamental knowledge of embedded processors, with in-depth knowledge of real time operating system concepts.', 'Excellent debugging and critical thinking skills', 'Excellent analytical and problem-solving skills', 'Ability to work in a fast paced, team-based environment', 'Strong verbal and written communication skills and social skills']",2020-08-08 13:50:04
Software Development Engineer - Big Data,Expedia.com,3.9 out of 5,"Seattle, WA 98119","['Be a part of our development team and actively participate in all phases of the software development lifecycle, including requirements gathering, functional and technical design, development, testing and roll-out, and support.', 'Solve complex business problems by utilizing disciplined development methodology, producing scalable, flexible, efficient and supportable solutions using appropriate technologies', 'Experience developing code in java or python, with a BS in Computer Science or equivalent.', 'Experience in big data technologies Hadoop, Hive, Spark.', 'Experience in real time distributed computing with Storm, Kafka.', 'Experience in object oriented programming, especially Java or Scala, design patterns, etc.', 'Computer science fundamentals in data structures, algorithm design, problem solving, and complexity analysis.', 'Familiarity with SQL-based databases (Oracle, MySQL, etc.)', 'Familiarity with distributed systems and computing at scale.', 'LI-AN1']",2020-08-08 13:50:04
SR. DATA PLATFORM ENGINEER,"Foot Locker, Inc.",3.9 out of 5,"Camp Hill, PA 17011","['Build and operationalize cloud-based platform components', 'Utilize container based technologies to help support a micro service based architecture', 'Build automation, using Python modules, to support our product development and data science initiatives', 'Have experience with DevOps / Automation tools to help minimize operational overhead for our platform', 'Achieve maximum uptime of our platform utilizing cloud technologies such as Kubernetes, Helm charts, Terraform, Docker, etc.', 'Must be able to contribute to self-organizing teams with minimal supervision working within the Agile / Scrum project methodology', 'Build production quality ingestion pipelines with automated quality checks to help enable the business to access all of our data sets in one place', 'Participate in a collaborative, peer review based environment fostering new ideas via cross team guilds / specialty groups', 'Maintain comprehensive documentation around our processes / decision making', 'Bachelors Degree in Computer science or related field', '3+ years of related information technology experience', '1+ years of strong experience building complex ETL pipelines with dependency management utilizing File Watchers, APIs, etc.', '2+ years of strong experience directly related to Big Data technologies', 'Industry recognized certifications (simiar to below):', 'Demonstrated experience with the Scrum Agile methodology', 'Deep familiarity with PaaS services, containers, orchestrations specifically around Docker and Kubernetes.', 'Strong ability to learn new technologies in a short time.', 'Must possess well-developed verbal and written communication skills.', 'Previous experience at a fortune 500 company', 'Public cloud experience, preferably Azure or AWS', 'Experience using CI / CD tools and project build automation']",2020-08-08 13:50:04
REMOTE- Test Engineer,MKS2 Technologies,N/A,Remote,"['Experience with test plan and test case writing, test case executing, and test report writing', 'Experience with Agile development methods', 'Experience with test automation and scripting', 'Experience with functional testing and regression test execution', 'Experience with JIRA and defect reporting or trouble tickets', 'Knowledge of QA processes and methods', 'Ability to obtain a security clearance', 'BS degree in Computer Engineering or Computer Science or 2 years of experience with designing, developing, and implementing testing methods and equipment in lieu of a degree', 'Possession of excellent oral and written communication skills']",2020-08-08 13:50:04
Big Data Engineer,ScienceSoft USA Corporation,N/A,"McKinney, TX 75070","['Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities;', 'Implementing ETL process;', 'Monitoring performance and advising any necessary infrastructure changes;', 'Defining data retention policies.']",2020-08-08 13:50:04
Senior Data Engineer,SquareTrade,3 out of 5,"Lowell, MA","['Confer with product managers, engineers, programmers and others to design system and to obtain information on project limitations and capabilities, performance requirements and data pipeline (ETL/ELT) interfaces.', 'Modify existing data pipeline (ETL/ELT) to correct errors, allow it to adapt to new data pipeline (ETL/ELT), or to improve its performance.', 'Analyze Merchant Integration, Finance and Supply chain Stakeholders and product managers needs and data requirements to determine feasibility of design within time and cost constraints.', 'Consult with Merchant Integration, Finance and Supply Chain Stakeholders about data system design and maintenance.', 'Design, develop and modify data systems, using scientific analysis and mathematical models to predict and measure outcome and consequences of design.', 'Develop and direct data system testing and validation procedures, programming, and documentation.', 'Analyze information to determine, recommend, and plan data system reports and layouts, and modifications.', 'You love (and can effectively) work with different technology stacks: We believe in using the best tool to get the job done which may be developing out our Java app, writing Python (our your favorite scripting language), laying out Informatica ETL mappings, or prototyping a problem with Hadoop and Spark.', 'You develop for scalability: you’re able to solve both high-level architectural and in-depth problems.', 'You’re curious and want to learn: We believe in continual improvement, and we want teammates who share our vision of growing technology and people.', 'You’ve got a solid foundation: This role requires both a broad and deep understanding of data; you must have an advanced understanding of MPP databases, data modeling & schema design, large-scale data processing frameworks and experience building data pipelines from disparate sources.', 'Bachelor’s in Computer Science, Computer Engineering, or related is required', '5+ years of relational database experience (Postgres preferred); strong analytical SQL skills necessary', '5+ years of experience w/ custom or structured ETL design, implementation and maintenance', '1+ years of dynamic scripting (Python preferred) development experience', '3+ years of shell scripting experience', '1+ years of experience working with big data technologies (Kafka, Spark, Hive, Hadoop)', '1+ years of Java development experience required', 'Informatica Cloud Platform or Python base Framework.', 'Data Ingestion and Integration from/To between Flat file, Databases, ERP, SFTP, CRM.', 'Strong SQL Skills for Data Analysis', 'Tableau Desktop 9.0 for Reporting business metrics', 'Not feeling stuck! This role has exposure to many different parts of the business, making transitioning easy...we work on developing careers based on what people enjoy!', 'Competitive salaries', 'Benefits (medical, dental, vision)', 'Growth Options', '401k matching (up to 5%)', 'Tuition Reimbursement', 'Generous Paid Time Off Policy', 'Respect for your work-life balance', 'A paid volunteer day to give back to the community', 'And More!!!']",2020-08-08 13:50:04
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:50:49
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:50:49
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:50:49
Systems Administrator (Data Integration Engineer),Apex Clean Energy,3.3 out of 5,"Charlottesville, VA 22902","['Build and maintain the ETL processes', 'Develop ETL packages, ensuring that best practices are implemented for data governance, data quality, data cleansing.', 'Development of scalable and robust ETL routines, using ETL tools and external programming and/or scripting languages as necessary.', 'Manage the day-to-day support and maintenance of the data warehouse environment, reports, data integration jobs and job schedules.', 'Collaborate with stakeholders to define business logic for source-to-target mappings and integration workflows.', 'Assisting in production support by resolving source data issues and refining transformation rules when needed.', 'Maintain the existing data warehouses and facilitate aggregation, slicing and dicing of data using dbt.', 'Design and develop data extraction SQL queries that are highly optimized for very large data sets.', 'Creating and maintaining the company data dictionary as well as technical documentation for source-to-target mapping.', 'Follow current trends, their impact on business strategies, and their implications for creating sustainable data warehouse architecture.', ""Analyze the needs and the environment to make sure the solution you're developing considers the current architecture and operating environment as well as future functionality and enhancements."", 'Work closely and collaborate with various cross functional teams to identify, troubleshoot and fix data issues, and resolve data gaps that impact the fulfillment of the business’s functional requirements.', 'Work collaboratively with team members and customers to gather and validate requirements as well as deliver features/enhancements.', 'Collaborate with architects, team leads and team members to architect and design solutions to meet functional and technical requirements.', 'Troubleshoot issues, identify resolutions.', 'Responsible for writing complex SQL queries for mining of operational data.', 'At least two years of experience with complex/large data management and systems integration.', 'Familiar with ETL tools for database / warehouse development. Experience with Azure, preferred.', 'Experience developing ETL packages, ensuring that best practices are implemented for data governance, data quality, data cleansing.', 'Experience in all aspects of project development life cycle such as identifying requirements, design, feasibility analysis, allocating timelines, task prioritization, development, performance, best practices and testing.', 'Hands-on experience performing data modeling and warehousing in a cloud-based data-warehousing system (Snowflake)', 'Experience in day-to-day support and maintenance of the data warehouse environment, reports, data integration jobs and job schedules.', 'Experience performing analysis and reporting from the data warehouse, ideally using PowerBI.', 'Experience setting up data access and visualization tools and systems for non-technical users.', 'Working knowledge of Python and/or SQL.', 'Prior experience with renewable energy and/or SCADA a plus.', 'Experience working in a rapidly evolving environment, adapting quickly to new information and re-prioritizing as needed.', 'Demonstrated interest/passion for renewable energy required.', 'Health Insurance', 'Dental Insurance', 'Vision Insurance', '401(k) Employer Match', '401(k) Pre-tax or Roth Deferrals', 'Health Savings Accounts', 'Flexible Spending Arrangements', 'Short-term Disability Insurance', 'Long-term Disability Insurance', 'Group Term Life Insurance', 'Voluntary Additional Term Life Insurance', 'Paid Time Off (PTO)', 'Holidays', 'Volunteer Time Off', 'Progressive Parental Leave Plan', 'Milk Stork Travel Solution', 'Professional Development Opportunities', 'Employee Referral Program', 'ACAC Fitness and Wellness Center - Corporate Discount', 'Company Paid Cell Phone', 'Company Paid Parking', 'United Van Lines - Relocation Discounts']",2020-08-08 13:50:49
Kronos Data Engineer,Procyon Technostructure,N/A,"Dallas, TX",['Yes'],2020-08-08 13:50:49
Data Engineer,PreciseTarget,N/A,"Bethesda, MD 20814","['Building and optimizing software programs, algorithms and automated processes to ingest, cleanse, transform and integrate data from multiple disparate sources', 'Leading technical design and delivery on new tools, platforms and products', 'Writing complex and efficient queries to transform data', 'Working with data scientists to refine machine learning and data processing algorithms', 'Proficiency in Python, SQL, and Java', 'Experience with machine learning algorithms (PySpark experience a plus)', '3+ years of experience building simple, scalable, reliable back end systems (ETL pipelines, data analytics, etc.)', 'Familiarity with measuring performance of data products', 'Experience generating and testing hypotheses to explain micro and macro trends and opportunities based on data', 'Strong software engineering fundamentals (data structures, algorithms, distributed systems, information retrieval)', 'Experience with AWS services', 'Excellent communication skills', 'A sense of ownership, the ability to work effectively in close collaboration, and a positive attitude', 'Start-up experience', 'Quantitative marketing experience']",2020-08-08 13:50:49
Data Engineer - Advanced Analytics,Blue Cross Blue Shield of Michigan,3.9 out of 5,"Detroit, MI 48226","['Design, develop, document and test advanced data systems that supports the manipulation of structured and unstructured data sets from disparate sources.', 'Identify, integrate and cleanse data source information for processing.', 'Document and communicate opportunities for improvement identified in the data, such as scalability or quality concerns.', 'Write and refine code to ensure performance and reliability of data extraction and programming.', 'Implement data structures using best practices for data modeling and visualizations.', 'Produce comprehensive and usable dataset documentation and metadata.', 'Work on concurrent projects of varying size and scope, adhering to timelines and objectives.', 'Bachelor’s degree in related field is preferred.', 'Three (3) years of advanced programming techniques and application design is required.', 'Experience in systems design and have a solid understanding of development, database development, testing, and integration methodologies is required.', 'Project management experience is preferred.', 'Intermediate knowledge of big data (i.e. Map/Reduce, YARN, HDFS, etc.), query building (i.e. PL/SQL, HIVE, Impala, Spark, etc.), programming (i.e. R, Python, C, Java, Ruby, etc.) and visualization tools (i.e. QlikView, Tableau, Web FOCUS, etc.).', 'Basic statistics modeling skills (i.e. linear regression, logistic regression, decision trees, random forests, etc.)', 'Intermediate skills in Microsoft Access, Word, PowerPoint and Excel.', 'Strong analytical, organizational and problem-solving skills.', 'Ability to effectively interface and present to management at all levels of the organization.', 'Ability to work independently and in a team environment.']",2020-08-08 13:50:49
Big Data ETL Engineer/Data Engineer,Tech2i,N/A,"Columbia, MD 21046","['Transition of legacy ETLs with Java and Hive queries to Spark ETLs.', 'Design, develop, test and release ETL solutions including data quality validations and metrics that follow data governance and standardization best practices.', 'Design, develop, test and release ETL mappings, mapplets, workflows using Streamsets, Java, Spark and SQL.', 'Performance tuning of end-to-end ETL integration processes.', 'Analyze and recommend optimal approach for obtaining data from diverse source systems.', 'Work closely with the data architects, who maintain the data models, including data dictionaries/metadata registry.', 'Interface with business stakeholders to understand requirements and offer solutions.', 'Proficient understanding of distributed computing principles and hands on experience in Big Data Analytics and development', 'Good knowledge of Hadoop and Spark ecosystems including HDFS, Hive, Spark MapReduce and Sqoop', 'Experience in designing and developing applications in Spark using Scala that work with different file formats like Text, Sequence, Xml, parquet and Avro', 'Experience of using build tools Ant, SBT Maven', 'Strong SQL coding; understanding of SQL and No SQL statement optimization/tuning.', 'Ability to lead designing and implementation of ETL data pipelines.', 'Experience developing data quality checks and reporting to verify ETL rules and identify data anomalies.', 'AWS development using big data technologies.', 'Techniques for testing ETL data pipelines either manual or using tools.', 'AWS cloud certified', 'CMS experience', 'Experience with Databricks', 'Bachelor’s Degree with 5 years’ experience or10+ years of experience in the software development field.', '5+ years of Bigdata ETL development experience.', '4+ years of AWS big data experience.', '3+ years of experience developing data validation checks and quality reporting.', '4+ years of experience tuning Spark/Java coding, SQL and No SQL.', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Java: 5 years (Preferred)', 'Big Data/HQL: 3 years (Preferred)', 'Multiple locations', 'Dependable -- more reliable than spontaneous', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.tech2i.net']",2020-08-08 13:50:49
Data Engineer,Everytown for Gun Safety,2 out of 5,"Washington, DC","['Gather and spec requirements for a successful project;', 'Maintain existing systems, and deliver enhancements;', 'Perform peer code review and quality assurance as part of a team;', 'Build pipelines for automated transforms of data into data marts in order to support reporting, predictive analytics, and targeting.', ""Provide support and training for staff and volunteers on Everytown's suite of tools and best practices for using data effectively;"", 'Make recommendations and provide guidance on ways to make programs, campaigns, and data collection more efficient and effective;', 'Other responsibilities as assigned.', '2-3 Years in SQL;', '2-3 Years in software development languages, Python preferred.', 'Developing and maintaining pipelines to perform ETL;', 'Working with version control systems such as Git;', 'Experience using APIs to construct and maintain data synchronizations', ""Experience training people on a variety of activities, experienced/comfortable at conducting trainings (even if you didn't create them);"", 'Ability to manage several tasks or projects concurrently and prioritize work effectively;', 'Ability to communicate effectively, especially technical ideas to non-technical people, work well under pressure, be detail oriented and meet deadlines;', 'Strong attention to detail, including producing technical documentation.', 'Mapping visualization, D3, GIS applications or R Leaflet;', 'Familiarity with R, Javascript, or other scripting languages;', 'Experience with Civis Analytics Platform;', 'Ability to diagnose and improve database and query performance issues;', 'Digital Campaigning platforms data schemas;', 'Data Visualization & reporting of metrics using tools such as Tableau;', 'Knowledge of CRM & Donation Data Schemas']",2020-08-08 13:50:49
Data Engineer,WisdomTree,N/A,"New York, NY","['Fielding and satisfying the inflow of Ad-Hoc requests of varying size, scope and frequency that originate from all functional areas of the firm', 'Developing and implementing sustainable data-driven solutions relevant to projects at the department level', 'Implementing a “full-stack” approach to each solution with the entire application life-cycle in mind (work Upstream, think Downstream)', 'Satisfy daily ad-hoc requests out of the databases by writing and optimizing T-SQL to ensure quick turnaround', 'Curate robust solutions around work-flow management through the stewardship and maintenance of our daily batch cycles using Control M, SQL Agent, APIs, and SSIS', 'Facilitate the smooth transition of Research projects from dev to production using SSIS, Control-M and Seismic', 'Liaise with the Research team to build solutions slated for daily or monthly automation.', 'Coordinate with Operations and Marketing across divisions to implement website data updates and enhancements', 'Facilitate timely delivery of monthly and quarterly reporting suite (Seismic)', 'Assume various DBA responsibilities to serve an expanding user base (permissions, backups, transactional log jams)', 'Act as point person for nightly entity batch (Fundamentals, Benchmarks, Performance, Lipper)', 'Continue to build and deploy new database-driven solutions devoted to automating daily business operations', '0-3 years of experience; financial services experience preferred', ""Bachelor's Degree required"", 'Proven experience in T-SQL, Python, Microsoft Azure, SSIS, and MSSQL Server 2014', 'Experience with Pandas, NumPy, Git, ETL, RESTful APIs and MongoDB a plus', 'Coachability and receptiveness to direction', 'Familiarity with unstructured databases a plus', 'Positive and open-minded approach to problem-solving', 'Love of learning and a desire for constant self-improvement', 'Ability to navigate ambiguity', '“Humble, hungry, and smart”']",2020-08-08 13:50:49
Big Data Engineer,Rite Pros,4.8 out of 5,"Portland, ME 04101","['Define the end to end solution architecture for large scale technology projects and deep technical expertise in distributed processing, real-time and scalable systems.', 'Architect, Design and Develop Big Data streaming applications to use high performance and highly available NoSQL Key Value store Redis for check pointing.', 'Design and Develop Spark applications in Scala that use DOM/SAX parsers for parsing incoming raw string/XML data.', 'Design and develop AWS Cloud deployment scripts using AWS Cloud Formation Templates, Terraform and Ansible.', 'Design, develop and troubleshoot Hive, Pig, Flume, Mango DB, Sqoop, Zookeeper, Spark, MapReduce2, YARN, HBase, Kafka and Strom.', 'Fine tune applications and systems for high performance and higher volume throughput and Pre-Process using Hive and Pig.', 'Translate load and exhibit unrelated data sets in various formats and sources like JSON, text files, Kafka queues and log data.', 'Install and configure Docker images for Telegraf, InfluxDB, Grafana, Kapacitor on AWS cloud monitoring EC2.', 'Design and Develop Kapcitor scripts for alerting as push notifications, SMS, Email and Slack alerts.', 'Define Technology/Big Data strategy and roadmap for client accounts, and guides implementation of that strategy within projects.', 'Drive excellent management skills are required to deliver complex projects, including effort/time estimation, building detailed work breakdown structure (WBS), managing critical path, and using PM tools and platforms.', 'Build scalable client engagement level processes for faster turnaround & higher accuracy.', 'Run regular project reviews and audits to ensure that projects are being executed within the guardrails agreed by all stakeholder.', 'Manage the team-members, to ensure that the project plan is being adhered to over the course of the project.', 'Manage the client stakeholders, and their expectations, with a regular cadence of weekly meetings and status updates.', 'Knowledge of variety and advanced architecture, tools and concepts across all layers of the modern distributed technology stack (Hadoop, Spark, Kafka, Cassandra, MongoDB and similar).', 'Knowledge and experience in cloud architectures and cloud tools (Azure/GCP/AWS).', 'Knowledge and experience of deploying and maintaining large scale advanced systems in production environments.', 'Ability to independently manage client engagements from start to finish, delivering actionable insight within established timelines and budget.', 'Demonstrate ability in driving business impact through the application of technology and data science. Understanding and leveraging the connection between data structures, analytical methods, and business applications.', 'Experience working in a consultative capacity (internal or external) and across the sales-to-project closure process.', 'Strong analytical thinking skills. Ability to creatively solve business problems, innovating new approaches where required.', 'Strong organizational awareness and the ability to work effectively at multiple levels within an organization. Equally comfortable in discussing technical/analytical details with technical thought leaders as explaining technical subject matter with a non-technical audience, in particular, high-level executives.', 'Outstanding verbal and written communication skills & must have excellent project management skills and have experience managing multiple work streams and projects at one time.', 'Building - and, when necessary, rebuilding - and leading high performance teams.', 'Proven track record of identifying and developing technology talent and leading a team of high-performance personnel.', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift.', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', '4+ years of experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.']",2020-08-08 13:50:49
Junior Test Engineer,Battelle,3.8 out of 5,"Crystal City, VA","['The candidate must have a BS in engineering, operations research, mathematics, or physical science from an accredited college or university and a minimum of 0-2 years of experience or a minimum of 4 years of experience with no degree.', 'Sole US Citizenship with the eligibility and willingness to obtain and maintain a DOD Secret Security Clearance and to obtain TSA Security Suitability.', 'Experience with Acceptance Testing.', 'Experience with Explosive Detection Technologies and/or Baggage Handling Systems (BHS).', 'Already possess a Secret Security Clearance.', 'Already possess TSA Security Suitability.']",2020-08-08 13:50:49
Data Engineer,Telaria,N/A,"Mountain View, CA 94041","['Having a large stake and impact on the product and business direction and bottom-line', 'Collaborating with innovative and goal-focused engineering and business teams', 'Working with data scientists, data analysts, and product managers to identify and use the data that is most relevant to the problem at hand', 'Building systems that can effectively stream, store, and crunch vast amounts of data to help inform customers and power business analytics', 'Solving complex problems revolving around real-time strategic decision-making and large data systems', 'Developing, deploying, and maintaining robust and high-performance systems and features', 'You have strong verbal and written communication skills that help you express your work in meaningful ways to cross functional teams', 'You are passionate about learning different technologies, exploring engineering challenges, and working in a dynamic and collaborative environment', 'You have working experience and skills designing and coding in Java/Scala and/or Python', 'You are proficient in writing efficient and well-structured SQL queries and have experience with database schemas and design', 'You have experience with big data technologies (Spark, Presto, Druid, etc.)', 'You have knowledge of UNIX/Linux and scripting with Perl, Shell, etc.', 'Degree in Computer Science or a related field', 'Bonus: Experience working in a data science / machine learning environment', 'Bonus: Experience working with AWS Services (Redshift, Kinesis, Glue, etc.)', 'We are a technology and data-driven business', 'We embrace analytical thinking, kind, and results driven people', 'We have a plethora of challenging and interesting problems to solve', 'We help and support each other in creating a productive work/life balance']",2020-08-08 13:50:49
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:50:49
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:50:49
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:50:49
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:50:49
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:50:49
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:50:49
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:51:40
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:51:40
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:51:40
Data Engineer - Advanced Analytics,Blue Cross Blue Shield of Michigan,3.9 out of 5,"Detroit, MI 48226","['Design, develop, document and test advanced data systems that supports the manipulation of structured and unstructured data sets from disparate sources.', 'Identify, integrate and cleanse data source information for processing.', 'Document and communicate opportunities for improvement identified in the data, such as scalability or quality concerns.', 'Write and refine code to ensure performance and reliability of data extraction and programming.', 'Implement data structures using best practices for data modeling and visualizations.', 'Produce comprehensive and usable dataset documentation and metadata.', 'Work on concurrent projects of varying size and scope, adhering to timelines and objectives.', 'Bachelor’s degree in related field is preferred.', 'Three (3) years of advanced programming techniques and application design is required.', 'Experience in systems design and have a solid understanding of development, database development, testing, and integration methodologies is required.', 'Project management experience is preferred.', 'Intermediate knowledge of big data (i.e. Map/Reduce, YARN, HDFS, etc.), query building (i.e. PL/SQL, HIVE, Impala, Spark, etc.), programming (i.e. R, Python, C, Java, Ruby, etc.) and visualization tools (i.e. QlikView, Tableau, Web FOCUS, etc.).', 'Basic statistics modeling skills (i.e. linear regression, logistic regression, decision trees, random forests, etc.)', 'Intermediate skills in Microsoft Access, Word, PowerPoint and Excel.', 'Strong analytical, organizational and problem-solving skills.', 'Ability to effectively interface and present to management at all levels of the organization.', 'Ability to work independently and in a team environment.']",2020-08-08 13:51:40
Big Data ETL Engineer/Data Engineer,Tech2i,N/A,"Columbia, MD 21046","['Transition of legacy ETLs with Java and Hive queries to Spark ETLs.', 'Design, develop, test and release ETL solutions including data quality validations and metrics that follow data governance and standardization best practices.', 'Design, develop, test and release ETL mappings, mapplets, workflows using Streamsets, Java, Spark and SQL.', 'Performance tuning of end-to-end ETL integration processes.', 'Analyze and recommend optimal approach for obtaining data from diverse source systems.', 'Work closely with the data architects, who maintain the data models, including data dictionaries/metadata registry.', 'Interface with business stakeholders to understand requirements and offer solutions.', 'Proficient understanding of distributed computing principles and hands on experience in Big Data Analytics and development', 'Good knowledge of Hadoop and Spark ecosystems including HDFS, Hive, Spark MapReduce and Sqoop', 'Experience in designing and developing applications in Spark using Scala that work with different file formats like Text, Sequence, Xml, parquet and Avro', 'Experience of using build tools Ant, SBT Maven', 'Strong SQL coding; understanding of SQL and No SQL statement optimization/tuning.', 'Ability to lead designing and implementation of ETL data pipelines.', 'Experience developing data quality checks and reporting to verify ETL rules and identify data anomalies.', 'AWS development using big data technologies.', 'Techniques for testing ETL data pipelines either manual or using tools.', 'AWS cloud certified', 'CMS experience', 'Experience with Databricks', 'Bachelor’s Degree with 5 years’ experience or10+ years of experience in the software development field.', '5+ years of Bigdata ETL development experience.', '4+ years of AWS big data experience.', '3+ years of experience developing data validation checks and quality reporting.', '4+ years of experience tuning Spark/Java coding, SQL and No SQL.', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Java: 5 years (Preferred)', 'Big Data/HQL: 3 years (Preferred)', 'Multiple locations', 'Dependable -- more reliable than spontaneous', 'Adaptable/flexible -- enjoys doing work that requires frequent shifts in direction', 'Detail-oriented -- would rather focus on the details of work than the bigger picture', 'Autonomous/Independent -- enjoys working with little direction', 'Innovative -- prefers working in unconventional ways or on tasks that require creativity', 'Innovative -- innovative and risk-taking', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.tech2i.net']",2020-08-08 13:51:40
Data Engineer,Everytown for Gun Safety,2 out of 5,"Washington, DC","['Gather and spec requirements for a successful project;', 'Maintain existing systems, and deliver enhancements;', 'Perform peer code review and quality assurance as part of a team;', 'Build pipelines for automated transforms of data into data marts in order to support reporting, predictive analytics, and targeting.', ""Provide support and training for staff and volunteers on Everytown's suite of tools and best practices for using data effectively;"", 'Make recommendations and provide guidance on ways to make programs, campaigns, and data collection more efficient and effective;', 'Other responsibilities as assigned.', '2-3 Years in SQL;', '2-3 Years in software development languages, Python preferred.', 'Developing and maintaining pipelines to perform ETL;', 'Working with version control systems such as Git;', 'Experience using APIs to construct and maintain data synchronizations', ""Experience training people on a variety of activities, experienced/comfortable at conducting trainings (even if you didn't create them);"", 'Ability to manage several tasks or projects concurrently and prioritize work effectively;', 'Ability to communicate effectively, especially technical ideas to non-technical people, work well under pressure, be detail oriented and meet deadlines;', 'Strong attention to detail, including producing technical documentation.', 'Mapping visualization, D3, GIS applications or R Leaflet;', 'Familiarity with R, Javascript, or other scripting languages;', 'Experience with Civis Analytics Platform;', 'Ability to diagnose and improve database and query performance issues;', 'Digital Campaigning platforms data schemas;', 'Data Visualization & reporting of metrics using tools such as Tableau;', 'Knowledge of CRM & Donation Data Schemas']",2020-08-08 13:51:40
Data Engineer,WisdomTree,N/A,"New York, NY","['Fielding and satisfying the inflow of Ad-Hoc requests of varying size, scope and frequency that originate from all functional areas of the firm', 'Developing and implementing sustainable data-driven solutions relevant to projects at the department level', 'Implementing a “full-stack” approach to each solution with the entire application life-cycle in mind (work Upstream, think Downstream)', 'Satisfy daily ad-hoc requests out of the databases by writing and optimizing T-SQL to ensure quick turnaround', 'Curate robust solutions around work-flow management through the stewardship and maintenance of our daily batch cycles using Control M, SQL Agent, APIs, and SSIS', 'Facilitate the smooth transition of Research projects from dev to production using SSIS, Control-M and Seismic', 'Liaise with the Research team to build solutions slated for daily or monthly automation.', 'Coordinate with Operations and Marketing across divisions to implement website data updates and enhancements', 'Facilitate timely delivery of monthly and quarterly reporting suite (Seismic)', 'Assume various DBA responsibilities to serve an expanding user base (permissions, backups, transactional log jams)', 'Act as point person for nightly entity batch (Fundamentals, Benchmarks, Performance, Lipper)', 'Continue to build and deploy new database-driven solutions devoted to automating daily business operations', '0-3 years of experience; financial services experience preferred', ""Bachelor's Degree required"", 'Proven experience in T-SQL, Python, Microsoft Azure, SSIS, and MSSQL Server 2014', 'Experience with Pandas, NumPy, Git, ETL, RESTful APIs and MongoDB a plus', 'Coachability and receptiveness to direction', 'Familiarity with unstructured databases a plus', 'Positive and open-minded approach to problem-solving', 'Love of learning and a desire for constant self-improvement', 'Ability to navigate ambiguity', '“Humble, hungry, and smart”']",2020-08-08 13:51:40
Big Data Engineer,Rite Pros,4.8 out of 5,"Portland, ME 04101","['Define the end to end solution architecture for large scale technology projects and deep technical expertise in distributed processing, real-time and scalable systems.', 'Architect, Design and Develop Big Data streaming applications to use high performance and highly available NoSQL Key Value store Redis for check pointing.', 'Design and Develop Spark applications in Scala that use DOM/SAX parsers for parsing incoming raw string/XML data.', 'Design and develop AWS Cloud deployment scripts using AWS Cloud Formation Templates, Terraform and Ansible.', 'Design, develop and troubleshoot Hive, Pig, Flume, Mango DB, Sqoop, Zookeeper, Spark, MapReduce2, YARN, HBase, Kafka and Strom.', 'Fine tune applications and systems for high performance and higher volume throughput and Pre-Process using Hive and Pig.', 'Translate load and exhibit unrelated data sets in various formats and sources like JSON, text files, Kafka queues and log data.', 'Install and configure Docker images for Telegraf, InfluxDB, Grafana, Kapacitor on AWS cloud monitoring EC2.', 'Design and Develop Kapcitor scripts for alerting as push notifications, SMS, Email and Slack alerts.', 'Define Technology/Big Data strategy and roadmap for client accounts, and guides implementation of that strategy within projects.', 'Drive excellent management skills are required to deliver complex projects, including effort/time estimation, building detailed work breakdown structure (WBS), managing critical path, and using PM tools and platforms.', 'Build scalable client engagement level processes for faster turnaround & higher accuracy.', 'Run regular project reviews and audits to ensure that projects are being executed within the guardrails agreed by all stakeholder.', 'Manage the team-members, to ensure that the project plan is being adhered to over the course of the project.', 'Manage the client stakeholders, and their expectations, with a regular cadence of weekly meetings and status updates.', 'Knowledge of variety and advanced architecture, tools and concepts across all layers of the modern distributed technology stack (Hadoop, Spark, Kafka, Cassandra, MongoDB and similar).', 'Knowledge and experience in cloud architectures and cloud tools (Azure/GCP/AWS).', 'Knowledge and experience of deploying and maintaining large scale advanced systems in production environments.', 'Ability to independently manage client engagements from start to finish, delivering actionable insight within established timelines and budget.', 'Demonstrate ability in driving business impact through the application of technology and data science. Understanding and leveraging the connection between data structures, analytical methods, and business applications.', 'Experience working in a consultative capacity (internal or external) and across the sales-to-project closure process.', 'Strong analytical thinking skills. Ability to creatively solve business problems, innovating new approaches where required.', 'Strong organizational awareness and the ability to work effectively at multiple levels within an organization. Equally comfortable in discussing technical/analytical details with technical thought leaders as explaining technical subject matter with a non-technical audience, in particular, high-level executives.', 'Outstanding verbal and written communication skills & must have excellent project management skills and have experience managing multiple work streams and projects at one time.', 'Building - and, when necessary, rebuilding - and leading high performance teams.', 'Proven track record of identifying and developing technology talent and leading a team of high-performance personnel.', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift.', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', '4+ years of experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.']",2020-08-08 13:51:40
Junior Test Engineer,Battelle,3.8 out of 5,"Crystal City, VA","['The candidate must have a BS in engineering, operations research, mathematics, or physical science from an accredited college or university and a minimum of 0-2 years of experience or a minimum of 4 years of experience with no degree.', 'Sole US Citizenship with the eligibility and willingness to obtain and maintain a DOD Secret Security Clearance and to obtain TSA Security Suitability.', 'Experience with Acceptance Testing.', 'Experience with Explosive Detection Technologies and/or Baggage Handling Systems (BHS).', 'Already possess a Secret Security Clearance.', 'Already possess TSA Security Suitability.']",2020-08-08 13:51:40
Data Engineer,Telaria,N/A,"Mountain View, CA 94041","['Having a large stake and impact on the product and business direction and bottom-line', 'Collaborating with innovative and goal-focused engineering and business teams', 'Working with data scientists, data analysts, and product managers to identify and use the data that is most relevant to the problem at hand', 'Building systems that can effectively stream, store, and crunch vast amounts of data to help inform customers and power business analytics', 'Solving complex problems revolving around real-time strategic decision-making and large data systems', 'Developing, deploying, and maintaining robust and high-performance systems and features', 'You have strong verbal and written communication skills that help you express your work in meaningful ways to cross functional teams', 'You are passionate about learning different technologies, exploring engineering challenges, and working in a dynamic and collaborative environment', 'You have working experience and skills designing and coding in Java/Scala and/or Python', 'You are proficient in writing efficient and well-structured SQL queries and have experience with database schemas and design', 'You have experience with big data technologies (Spark, Presto, Druid, etc.)', 'You have knowledge of UNIX/Linux and scripting with Perl, Shell, etc.', 'Degree in Computer Science or a related field', 'Bonus: Experience working in a data science / machine learning environment', 'Bonus: Experience working with AWS Services (Redshift, Kinesis, Glue, etc.)', 'We are a technology and data-driven business', 'We embrace analytical thinking, kind, and results driven people', 'We have a plethora of challenging and interesting problems to solve', 'We help and support each other in creating a productive work/life balance']",2020-08-08 13:51:40
Senior Big Data Engineer,Brickred,N/A,"Seattle, WA","['5+ years of relevant work experience in Big data engineering, ETL, Data Modeling, and Data Architecture.', 'Expert-level skills in writing and optimizing SQL.', 'Experience with Big Data technologies such as Hive/Spark, AWS EMR, AWS Glue, AWS Lambda and Kinesis.', 'Proficiency in one of the scripting languages - python, ruby, java or similar.', 'Experience operating very large data warehouses, data lakes and building streaming data pipelines.', 'A real passion for technology. We are looking for someone who is keen to demonstrate their existing skills while trying new approaches.', ""Master's or Bachelor degree in Computer Science, Engineering, or related field"", 'Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.', 'Experience with building data pipelines and applications to stream and process datasets at low latencies.', 'Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.', 'Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.', 'Knowledge of Engineering and Operational Excellence using standard methodologies.']",2020-08-08 13:51:40
Data Engineer,Freestar,4.3 out of 5,"Phoenix, AZ","['Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.', 'Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.', 'Writes unit/integration tests, contributes to engineering wiki, and documents work.', 'Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.', 'Works closely with a team of frontend and backend engineers, product managers, and analysts.', 'Defines company data assets (data models), SQL, Airflow to populate data models.', 'Designs data integrations and data quality framework.', 'Build dashboards that concisely and succinctly convey business metrics.', 'Designs and evaluates open source and vendor tools for data lineage.', 'Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.', 'Knowledge of best practices and IT operations in an always-up, always-available service', 'Experience with or knowledge of Agile Software Development methodologies', 'Excellent problem solving and troubleshooting skills', 'Process oriented with great documentation skills', 'Excellent oral and written communication skills with a keen sense of customer service', 'Ample relevant knowledge and experience. You either have a BS or MS degree in Computer Science or a related technical field, OR certification from a data science bootcamp + 2 years of experience in a role as a data engineer', 'Proficiency in Python and Java, Scala, or Go development experience', '4+ years of SQL experience (Strong SQL required)', 'Familiarity with BI reporting tools like Tableau, Looker.', '4+ years of experience with schema design and dimensional data modeling', 'Ability in managing and communicating data warehouse plans to internal clients', 'Experience designing, building, and maintaining data processing systems', 'Experience working with either a Map Reduce or an MPP system on any size/scale', 'Experience/knowledge of cloud computing platforms like AWS/GCP would be a plus', 'Excellent interpersonal and problem solving skills with the ability to communicate with team members to deliver actionable results', 'Comfortable interacting across multiple teams and management levels within the organization', 'Previous background in the ad tech or media landscape (linear, digital, or social) is a plus', 'Full-Time, Salaried Position', 'Medical, Dental, and Vision benefits', '401K with company match, vested immediately', 'The opportunity to be part of something BIG']",2020-08-08 13:51:40
Data Engineer,General Dynamics Information Technology,3.8 out of 5,"McLean, VA",[],2020-08-08 13:51:40
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:51:40
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:51:40
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:51:40
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:51:40
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:51:40
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Job', 'Company', 'Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:51:40
Data Engineer,NSM Insurance Group,2.8 out of 5,"Conshohocken, PA 19428","['Participate in design, documentation and development of best-in-class Insurance Enterprise Data Warehouse and serve as liaison to IT.', 'Solve business and data engineering problems by utilizing best practices to create and enhance data models and ETL pipelines.', 'Architect the data infrastructure and model deployment solutions utilizing best practices.', 'Assist with developing automated solutions to data problems.', 'Collaborate with analyst to further understand business problems.', 'Mentor and training opportunity to train data model designing to less experienced analysts.', 'Assist Director in building out DevOps best practices within the Analytics team.', 'Coordinate and build strong working relations with various internal stakeholder groups, including IT, Marketing, and Underwriting.', 'Bachelors-degree in computer science, computer engineering, or similar area', 'Minimum 5 years of experience in data integration, management and warehouse design required.', 'Minimum 3 years of experience with Python/R required.', 'Minimum 3 years of experience utilizing database cloud platforms such as Azure, Teradata, Databricks, AWS, etc.', 'Previous Insurance experience required.', 'Previous experience designing, enhancing, and/or modifying data warehouses.', 'Advanced data processing programming skills across SQL-based and Hadoop-based technologies.', 'Previous experience using Microsoft suite of Extract Transform Load (ETL) tools such as SSIS and Azure Data Factory.', 'Previous experience utilizing business intelligence visualizations tools such as MS Power BI, Tableau, Qlik, etc.', 'Demonstrated project management skills and ability to work independently to prioritize workload and handle multiple responsibilities, deadlines, etc.', 'Strong organizational, problem-solving, and critical thinking abilities.', 'High attention to detail to identify, evaluate and resolve data quality issues and conduct data sanity check.', 'Thrives in a team-oriented, results-driven environment.', 'Excellent oral presentation and written communication skills.']",2020-08-08 13:52:29
Senior Data Engineer,SecurityScorecard,5 out of 5,New York State,"[""Bachelor's degree or higher in a quantitative/technical field such as Computer Science, Engineering, Math"", '6+ years of data pipeline software development experience', 'Exceptional skills in at least one high-level programming language (Scala, Java, Go, Python or equivalent)', 'Actively using and a strong understanding of big data technologies such as Kafka, Spark, Storm, Apache Flink, Databricks toolkit and Cassandra', 'Experience with Dataflow orchestration in Google Cloud Flow, Airflow, or Conductor', 'Experience with AWS services including EMR, S3, Redshift, and RDS', 'Excellent communication skills to collaborate with cross-functional partners and independently drive projects and decisions', 'Previous experience working in distributed teams. We are a remote-first company!', 'Located in the U.S. or Canada', 'Phone conversation with Talent Acquisition to learn more about your experience and career objectives', 'Video interview with the hiring manager', 'Technical video interviews with two data engineers', 'Video interview with Engineering VP and Chief Architect', 'Competitive base salary', 'Full health benefits', 'Stock options', 'MacBook', 'You are always welcome to work from home', '$3000 per year education fund', '#1 Ranked Cybersecurity Analytics company in the word']",2020-08-08 13:52:29
Sr Data Engineer,Aktify,N/A,"Draper, UT 84020","['Translate the vision from product and technology into working systems.', 'Create both real-time and batch system architecture and data infrastructure.', 'Implement efficient real-time streaming and data lake batch processes that preserve data correctness.', 'Create reactive, independent microservices connected by REST APIs and Kafka.', 'Create regression tests to support continuous deployments and assure operational integrity.', 'Contribute your vision and ideas to improve our conventions, processes, software, products and customer experience.', 'Debug both real-time and batch process systems.', 'Automate processes with Ansible, Terraform and shell scripts.', 'Work well with others & help build good team chemistry.', 'Willing to disambiguate poorly defined requirements and research solutions.', 'Be a self starter who can take initiative and blaze your own trail when required.', 'Be part of a well-funded startup with an ambitious culture.', 'Collaborate with other brilliant people to create visionary solutions.', 'Competitive salary and stock option grants.', 'Dental, medical, vision for you & your family.', 'Company-paid life insurance policy.', 'Generous PTO and flex scheduling.', 'Company-sponsored outings and meals.', 'Paid parental leave.', 'Fast paced, collaborative, and fun environment.', 'Preferred: Bachelors or Masters in Computer Science or equivalent experience.', '3+ years experience with data engineering on a major platform (Horton, Cloudera, Amazon AWS, Google GCP, etc).', 'Experienced with Python, Scala, or Java.', 'Expert with data lake design, data modeling and massive data sets.', 'Experience with Docker and microservices.', 'Expert with various data sources (PostgreSQL, REST APIs, Kafka).', 'Experienced with Spark or Beam.', 'Experienced with Agile methodology.', 'Knowledge of data structures and algorithms.', 'Excellent verbal and written communication skills.', 'Responsible and meets delivery date commitments on assigned projects.', 'You collaborate well with others.', 'Willing to work at our Draper, UT office.', 'Experience with Google Cloud or another major provider (AWS, Azure).', 'Experience with DevOps, DataOps, Ansible, Terraform, and shell scripting.', 'Experience with Kubernetes.', 'Experience with CI/CD pipeline automation.', 'Experience with PostgreSQL, Redis and KVS (e.g. Cassandra, Cloud Datastore).', 'Experience collaborating with data science or implementing machine learning.', 'Experience with FaaS.']",2020-08-08 13:52:29
R&D Leadership Development Program – Internship Summer 2021,Johnson & Johnson Family of Companies,4.2 out of 5,"West Chester, PA","['Improve your industry knowledge through open forum conversations with senior company leaders and shadowing of senior engineers.', 'Create or improve your personal brand through skills building workshops and internship networking events.', 'Have the power to connect and support our local towns through community activities.', 'Work in a fast-paced cross functional, technologically advanced corporate environment in an internship program focused on developing individual engineers capable of pursuing careers across medical device businesses and high-volume manufacturers.', 'Have the opportunity to learn about anatomy, disease states, and deformities and the surgical procedures and products used to address these conditions.', 'Be involved in the design, development, manufacturing and commercialization of new products or product modifications.', 'Assist with the development of advanced materials, process improvements, risk management, and/or mechanical testing or advance a medical device through the development process.', 'Utilize solid modeling to design products, create drawings and tolerance analyses of mating components.', 'Become familiar with design control documentation required by regulatory governing bodies.', 'Present to leadership your learnings and development experience.', 'Currently enrolled in an Engineering Graduate Program (Master’s Degree or PhD) graduating in the Fall 2021 or Spring 2022.', 'The following engineering disciplines or specialties are preferred: Mechanical, Robotics, Electrical, Computer, Systems, Software, Materials Science, Biomedical and Computer Science.', 'The following concentration fields and/or skills are strongly preferred: Machine Learning, IoT, Embedded Software, Deep Machine Learning, Prototyping, Robot Design, Systems Reliability, Firmware and hardware integration.', 'A minimum GPA of 3.3 is strongly preferred.', 'Validated leadership experience through extra-curricular activities, employment and/or previous internship experiences is required. R&D Internships highly preferred.', 'Team player with the ability to work closely with technical and non-technical personnel is required.', 'Excellent communication skills and the ability to influence others is required.', 'Ability to demonstrate excellent problem-solving skills, intellectual curiosity and a dedicated approach to achieving success is required.', 'Proactive self-starter and have the courage to take a leadership position to help deliver robust results is required.', 'Ability to relocate across the United States as required by the internship program.']",2020-08-08 13:52:29
Data Engineer - IG Tech,Capital Group,3.9 out of 5,"Los Angeles, CA 90071","['Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like AWS.', 'Design, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems.', 'Design data schema and operate cloud-based data warehouses and SQL/NoSQL/temporal database systems.', 'Write Extract-Transform-Load (ETL) jobs and Spark/Hadoop jobs.', 'Own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.', 'Monitor and troubleshoot operational or data issues in the data pipelines.', 'Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions.', 'Influence your team’s technical and business strategy by making insightful contributions to team priorities and approach.', 'Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area.', 'Building relationships with your customers, partner teams and the engineers on your team.', 'Influence your team’s technical decisions by making insightful contributions to team priorities and approach.', 'You have a background in data and software engineering and a passion to learn.', ""You've made mistakes in the past and have learned a lot from them. You apply this learning regularly."", 'You believe there are generally multiple ways to solve a technical problem, each with different trade-offs.', 'You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you.', 'You believe that a team is strongest when it is diverse and includes multiple perspectives.', ""You are able to put yourself into your customer's shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them."", 'BS in Computer Science or related field, or an equivalent in relevant work experience.', '3+ years experience implementing big data processing technology: Hadoop, Apache Spark, etc.', '3+ years coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.).', 'Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets.', 'Experience in cloud-first design, preferably AWS (VPC, Serverless databases and functions, dynamic autoscaling, container orchestration, etc.).', 'Experience in data architecture, databases (e.g., MySQL, Oracle, PostgreSQL), SQL and DDD/ER/ORM design.', 'Interest and curiosity in emerging technologies on the web like GraphQL, web assembly, Lambda functions, MLaaS etc', 'Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.']",2020-08-08 13:52:29
"Data Engineer, Prime Video",Amazon.com Services LLC,3.6 out of 5,"Seattle, WA","['5+ years of relevant experience in business engineer role, including data warehousing and business intelligence tools, techniques and technology, as well as experience in diving deep on data analysis or technical issues to come up with effective solutions', 'BS degree in math, statistics, computer science or equivalent technical field', 'Experience in data mining structured and unstructured data (SQL, ETL, data warehouse, Machine Learning etc.) in a business environment with large-scale, complex data sets', 'Design, develop, implement, test, document, and operate large-scale, high-volume, high-performance data structures for business intelligence analytics in support of prime video content analytics.', 'Implement data structures using best practices in data modeling, ETL/ELT processes, and SQL, Redshift, and OLAP technologies.', 'Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions that work well within the overall data architecture.', 'Analyze source data systems and drive best practices in source teams.', 'Participate in the full development life cycle, end-to-end, from design, implementation and testing, to documentation, delivery, support, and maintenance.', 'Produce comprehensive, usable dataset documentation and metadata.', 'Evaluate and make decisions around dataset implementations designed and proposed by peer data engineers.', 'Proven communication (verbal and written) and interpersonal skills', '8+ years’ experience in Datanet or other ETL technologies', '8+ years’ experience in Tableau including advanced dashboarding', '5+ using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologies']",2020-08-08 13:52:29
Data Engineer,Stevens Capital Management LP,N/A,"Philadelphia, PA","['Implement robust solutions for adoption, storage and management of large volumes of data', 'Develop quality assurance systems in support of high integrity data sets', 'Assist quantitative analysts in crafting custom, bespoke data sets', 'Support timely and fault tolerant data systems in support of production trading algorithms', 'Meet tight deadlines in an efficient manner', 'Bachelor’s degree in Computer Science or applicable degree and very strong exposure to programming and computer systems', 'Experience with Python and C++', 'Experience with data storage and manipulation using approaches such as HDF5, Pandas, and RDBMS/SQL', '2+ years professional experience in data management role', 'The desire to work in a fast-paced, hardworking and committed environment with a talented team', 'Strong problem solving skills, critical thinking and clear written and verbal communications', 'Financial industry, market data and cloud data environment experience are beneficial']",2020-08-08 13:52:29
Data Engineer,Reonomy,N/A,"New York, NY 10017","['Collaborating with the Engineering team to design, build and improve Reonomy’s complex data layer', 'Creating data systems that ensure quality and consistency on our data platform', 'Solving real challenges around creating systems that import, cleanse, structure, and display huge volumes of data', 'Playing a major role in the future architecture of our rapidly expanding backend platform', 'Writing high quality code, participating actively in code reviews, and consistently helping to ship software', '6+ years of experience in a Data Engineering capacity', 'Expertise in building and scaling ETL/batch processing systems that organize data and manage complex rulesets', 'Proven ability leveraging database technologies to solve non-trivial, large-scale problems', 'Advanced/Expert knowledge in SQL and data analysis', 'Experience programming in both typed (Scala, Java, etc..) and non-typed (Python, Ruby, etc..) languages on production projects', 'Experience using Scala libraries such as: Cats, shapeless, fs2', 'Experience building modern, data-driven, web applications with emphasis on strong software design methodologies', 'A serious passion for data', 'History of excellence and responsibility in previous engineering positions', 'Competitive salary', 'Company stock options', '100% coverage on medical, vision and dental health plans', 'Unlimited Vacation', '401k plan and commuter benefits', 'Access to our Continuing Education Stipend', 'Perks: WFH package, FREE ClassPass membership, FREE Headspace premium membership, FREE Citi Bike membership, & team outings!', 'Applicants must be currently authorized to work in the United States on a full-time basis.', 'We do not accept unsolicited resumes from outside recruiters/placement agencies. Reonomy will not pay fees associated with resumes presented through unsolicited means.']",2020-08-08 13:52:29
Undergraduate Internship/Co-op Program - Digital Forensics Engineer,Central Intelligence Agency,4.3 out of 5,"Washington, DC","['Full-time student pursuing an undergraduate degree in one of the following fields or related studies:', 'GPA of at least 3.0 on a 4-point scale', 'Availability to work two 90-day tours prior to graduation', 'Attending school on a full-time basis before/following this internship', 'Innovative and creative', 'Problem solving skills', 'Strong initiative', 'Ability to write script/code', 'A thorough medical and psychological exam', 'A polygraph interview', 'A comprehensive background investigation']",2020-08-08 13:52:29
Business Intelligence Analyst,Payability,N/A,"New York, NY","['Partner with the business stakeholders and employees to define and design business intelligence solutions focused on optimizing the use of data in the organization while maximizing user-adoption and data literacy growth in the organization.', 'Develop, implement, and maintain all key BI and data management policies and procedures, including those for BI/DW architecture, documentation required for the change control process as well as developing, maintaining and enforcing the data dictionary across the entire company..', 'Act as a point of contact between various internal business units (Finance, Customer Service, Marketing, etc.), executive level stakeholders (CEO, CMO, CTO, etc.), and overall product management team for collecting and prioritizing incoming reporting needs. Provide training to stakeholders to independently generate reports and dashboards.', 'Partner with technology counterparts (engineers, project managers) to understand Payability’s underlying data structure to source data effectively to display to end-users and/or communicate necessary changes required to close data gaps.', 'Oversee all aspects of data collection pipelines and replication of data to a data lake and data warehouse.', 'Capable to single-handedly deliver reports out of data visualization tools (Looker, Google Data Studios, etc.) and/or database tools (PyCharm, etc.) for internal stakeholders, executive-level stakeholders, or for internal projects', 'Appropriately display requested data in user-friendly consumable formats such as reports, graphs, dashboards in tools such as Heap, Looker, Data Studio.', 'Regularly provide updates to stakeholders on outstanding requests and maintain a tight feedback loop.', 'Leverage SQL to retrieve and analyze data from databases and practice ETL processes to manage large volumes of data.', 'Self-motivated and willing to quickly dive in to understand Payability’s data structure, business model, and overall technology platform.', 'Able to prioritize requests and stories according to overall company goals and manage expectations for the backlog of incoming requests.', 'Capable of working with stakeholders to concisely define required solutions to meet stakeholder needs.', 'Work extensively within data visualization tools and/or database tools to generate and deliver reports for stakeholders in a timely manner', 'Partner with engineering to efficiently source data from the system and communicate gaps in data required in order to implement reporting.', 'Manage and maintain any existing data visualizations within the data visualization tool', 'Ability to work from home during the pandemic', 'Bachelor degree in Computer Science, Information Systems, Economics, or a related field', '3+ years of SQL development and analytical experience', 'Familiarity with data modeling, ETL, and/or data warehousing', 'Experience with Redshift or BigQuery', 'Experience with Python or other scripting languages', 'Experience using a BI tool like Looker, Tableau, Periscope, MicroStrategy etc', 'Expert Excel / Google Sheets']",2020-08-08 13:52:29
Data Analytics Engineer - Lead,CACI,3.8 out of 5,"Washington, DC 20005","['The Data Analytics Engineer – Lead is responsible for providing senior level back-end support for projects related to investigations and litigation cases.', 'This includes managing the design, modeling, and implementation of a variety of databases and applications.', 'The Data Analytics Engineer – Lead will provide input into the selection of the appropriate data architecture for analysis and will manage the gathering of a wide variety of data types from primary and secondary sources through diverse channels using a combination of methods that will be populated into the appropriate analytical tools.', 'Working with and leading mid-level and junior team members to perform systems and database maintenance are key components of the work to include designing/implementing ETL pipelines, preservation of source data, performance optimization, monitoring, and suggesting improvements.', 'Managing the design, development, implementation, maintenance and optimization of a variety of databases and systems to include designing logical and physical database structures, partitioning of tables, data loading and validation, all aspects of security, monitoring, and performance tuning', 'Maintaining database dictionaries, and monitoring standards and procedures', 'Providing technical guidance to management, the team, and the customer in regards to implementation of highly advanced technical solutions', 'Supporting all dimensions of analysis including data transformations, sourcing, mapping, conversion and loading data', 'Collaborate across teams in order to quickly adapt to emerging and dependent technologies', 'Continually interact with teams to design and implement innovative data solutions that will provide key decision-making abilities', 'Establish and maintain documentation for all design, development, and maintenance activities to include database entity relationship diagrams, ETL processes, source code version control, and automated maintenance processes.', 'Perform routine source code reviews of ETL processes for defects, performance tuning, or changes in source data format', 'Deliver assignments by established deadlines. Keep management well-informed on a timely basis of progress, status and/or concerns for all team’s assignments', 'Develop and maintain standards for database implementation, maintenance, and optimization', 'Implement, maintain and test Disaster Recovery methodology for all production databases.', 'Reviews performance and capacity planning reports and makes recommendations to management', ""Bachelor's degree or equivalent, and 12 years of applicable experience."", 'Experience with managing/leading a team of ETL/Database Administrators', 'Strong experience with the design, implementation, administration, and maintenance of a variety of highly complex databases (typically SQL Server, Teradata, DB2, Oracle, MySQL, or PostgreSQL) to include implementing security and access methods', 'Strong experience with ETL of large data sets using Python, Teradata, SSIS, or Talend to source, load, and verify data of various formats', 'Ability to work at OS level on Linux and Windows, writing scripts and configuring storage', 'Experience administrating databases in AWS cloud environments', 'Experience with automated tools for database design and implementation', 'Ability to embrace and lead technological change and development', 'Experience with developing procedures relating to database and application security including procedures by which access is authorized, enabled, changed and withdrawn', 'Experience with identifying and implementing enhancements to improve performance and reliability of existing database systems.', 'Experience with the implementation, testing, and maintenance of Disaster Recovery for various databases.', 'Experience with performing threshold forecasting, sizing, capacity planning, and trend analysis.', 'Experience with performance monitoring and summary table creation.', 'Experience with ETL and Database management in direct support of Tableau Server', 'Experience with schema development, ETL, and database management in IBM I2 Enterprise Insight Analysis (EIA) Opal w/ I2 Connect', 'Experience with litigation support, investigations, or administering Litigation Support tools', 'Normal demands associated with an office environment.', 'Ability to work on computer for long periods, and communicate with individuals by telephone, email and face to face.', 'Some travel may be required.', 'We’ve been named a Best Place to Work by the Washington Post.', 'Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.', 'We offer competitive benefits and learning and development opportunities.', 'We are mission-oriented and ever vigilant in aligning our solutions with the nation’s highest priorities.', 'For over 55 years, the principles of CACI’s unique, character-based culture have been the driving force behind our success.']",2020-08-08 13:52:29
Data Warehouse Engineer,Indeed,4.3 out of 5,"New York, NY 10036","['Design and implement efficient data pipelines (ETLs) in order to integrate data from a variety of sources into Indeed’s Data Warehouse', 'Design and implement data model changes that align with warehouse standards', 'Design and implement backfill or other warehouse data management processes', 'Develop and execute testing strategies to ensure high quality warehouse data', 'Provide documentation, training, and consulting for data warehouse users', 'Perform requirement and data analysis in order to support warehouse project definition', 'Provide input and feedback to support continuous improvement in team processes', '5+ years in a Data Engineering or Data Warehousing role', '5+ years coding experience (java or python preferred)', '3+ years hands on experience with big data technologies (Snowflake, Redshift, Hive, or similar technologies)', 'Master’s Degree (or a B.S. degree with relevant industry experience) in math, statistics, computer science, or equivalent technical field', 'Expert level understanding of ETL fundamentals and building efficient data pipelines', 'Solid understanding of Kimball design methodologies (star schema) desired', 'Strong communication and collaboration skills', 'Experience with Agile methodologies']",2020-08-08 13:52:29
Associate Data Engineer (remote),CareCentrix,2.8 out of 5,"Stamford, CT 06902","['Design, code, test, debug and document complex data base queries.', 'Troubleshoot and resolve complex production issues.', 'Design relational database models for small and large applications.', 'Provide data analysis and validation.', 'Work with teams for identification of performance issues in production.', 'PL/SQL and SQL Tuning and Optimizations of newly develop and existing applications.', 'Work effectively with the Infrastructure architects and DBA teams to ensure that all approved development and deployment procedures are followed.', 'Work with internal and external users to understand the requirements, explain issues and prioritize work', 'Follow and adopt SDLC process', ""Bachelor's Degree in Computer Science or within a STEM related subject plus 1-3 years of relative experience required"", 'Solid software engineering principles (Data structures, OO, design patterns)', 'Database programming/development skills using PL/SQL, T-SQL (package, procedures, functions, triggers)', 'Strong knowledge about RDBMS Concepts', 'Knowledge about scripting (Python, Shell etc)', 'Understanding logical and physical data models', 'Comfortable with best practices around Test Driven Design, source control management.', 'Self-motivated and comfortable making day-to-day decisions', 'Strong analytical and communications skills', 'Ability to work well in a fast paced, constantly changing environment', 'Exposure to big data technologies are plus', 'Experience/Exposure to Agile methodology', 'This role can be worked remotely from home.']",2020-08-08 13:52:29
Operations Planning Engineer,Kuehne + Nagel,3.7 out of 5,"Aberdeen, MD 21001","['Analyze the utilization of facilities, equipment, materials and personnel to improve the efficiency of operations.', 'Provide daily shift labor plans based on analysis of inbound forecasts', 'Assess the value of existing processes and workflows as a whole and propose streamlining recommendations or alternatives.', 'Extract data and generate reports that assist in performance tracking and decision making', 'Develop designs, generate cost estimates and cost comparisons for proposed changes, including any corporate-mandated changes such as customer-specific requirements.', 'Coordinate with the Operations team to implement changes.', 'Use/adapt analytical methods to understand, forecast and/or improve logistics operations and processes. Assist in the development of training and procedures to ensure quality and cost control.', 'Use knowledge of logistics planning techniques to analyze processes and identify improvements to optimize labor, space, accuracy and safety throughout the process.', 'Work with the Transportation team to determine logistics and timing of shipments for efficiency improvements.', 'Manage projects within the operation including specifying equipment, updating processes, monitoring installation and training associates to ensure changes are seamless to our customers and achieve desired outcomes.', 'Provide design layout and proposal drawings and models.', 'Support productivity management tools (GRIP) within the site to ensure consistent measurement and monitoring of productivity at process and site level.', 'Educated to degree standard or the equivalent experience', 'Certified Lean Six Sigma BB or relevant Lean experience (Min 3 years) Lean Six Sigma GB (4 Yrs)', 'Contract logistics management experience preferred', 'Can demonstrate experience as a process improvement delivery specialist', 'Has experience in delivering Kaizen or Rapid Improvement activities based on Value Stream Mapping preferred', 'Demonstrates a passion for continuous improvement and the ability to energise and inspire others', 'Excellent communication and inter personal skills', 'Self starter with ability to work on own initiative', 'Negotiation skills', 'Be able to work well in a fast-paced environment and under stress', 'Show leadership and motivational capabilities and the ability to work with multi-disciplinary teams', 'Certified Lean Six Sigma Black Belt', 'Negotiation skills', 'Experience in the delivery of lean six sigma and continuous improvement programmes', 'Can demonstrate a rounded business acumen including P & L management and budgeting', 'Advanced skills in MS office tools including Excel, Word, Powerpoint, MS project and MS Visio', 'An advanced level Minitab user version 14 or above', 'CAD Drawing software experience preferred', 'Willingness to travel within country', 'English written and oral skills preferred']",2020-08-08 13:52:29
Business Data Engineer,ConvergeMarketing,N/A,"Mount Kisco, NY 10549","['analytics: 5 years (Preferred)', 'data engineering: 5 years (Preferred)', 'SQL, SPSS, AWS, Java, Python/R: 5 years (Preferred)', 'One location', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Parental leave', 'Monday to Friday', 'Temporarily due to COVID-19']",2020-08-08 13:52:29
Jr. Big Data Engineer,Enhance IT,3.4 out of 5,Pennsylvania,"['Degree in Computer Science, Information Systems or equivalent quantitative field and 3+ years of experience in a similar Big Data Engineer role.', 'Demonstrated ability to build processes that support data transformation, data structures, metadata, dependency and workload management', 'Strong interpersonal skills and ability to project manage and work with cross-functional teams', 'Working SQL knowledge with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Relational SQL and NoSQL databases', 'Object-oriented/Object function scripting languages such as Python, Scala, etc.', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off']",2020-08-08 13:52:29
B&P - Shift Engineer 1ST GR,"American Sugar Refining, Inc.",3.1 out of 5,"Baltimore, MD","['Involved in the startup and shutdown of all equipment in a safe and orderly manner', 'Instructs and aids the Power House mechanic in his duties to maintain all equipment', 'Maintains records including a Power House log and collects pertinent data every hour', 'Reports any problems with operating or equipment conditions', 'Talks with process supervisors throughout the refinery to identify power or steam deficiencies', 'Monitors and helps troubleshoot processes and conditions', 'Notifies appropriate personnel in the refinery when alarm signals sound', 'Familiar with boiler and cooling water chemistry and treatment', 'Performs minor mechanical repairs', 'Thorough understanding of boilers, turbines, generators, pumps and auxiliary equipment', 'Must hold a valid Maryland First Grade Stationary Engineer License', 'Shift work, some overtime and vacation coverage is required', 'Formal training and experience in the operation of high pressure boilers and steam-driven turbine generators', 'Experience with energy improvement programs and utility switching is a plus', 'High school diploma or GED required', '5 years of experience with Boiler/Powerhouse Utilities and any processes that involve both high pressure steam generation and power generation along with Utility Conservation expertise preferred']",2020-08-08 13:52:29
Virtual Hosting Environment Engineer,"Computational Physics, Inc.",N/A,"Washington, DC","['Provide direct support to the Precise Time, Celestial Reference Frame, Earth Orientation, and Astronomical Applications Departments at USNO.', 'Work with USNO Information Assurance staff to ensure compliance with DoD cybersecurity requirements.', 'Prepare and maintain associated documentation.', 'Five or more years of experience managing Virtual Hosting environments.', 'VMware Certified Professional Certification (6.0 or higher is preferred).', 'Security+ certification or any DoD-accepted equivalent.', 'Data center experience is highly desirable.', 'Experience in DoD cyber security is highly desirable.', 'U.S. citizenship is required by our contract with the Navy.', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Monday to Friday', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Outcome-oriented -- results-focused with strong performance culture', 'Stable -- traditional, stable, strong processes', 'People-oriented -- supportive and fairness-focused', 'Team-oriented -- cooperative and collaborative', 'www.cpi.com', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:52:29
Data Engineer,SageSure,3.2 out of 5,Remote,"['Create, maintain, and enhance ETL development, including but not limited to, SSIS integration packages and SSRS report distributions', 'Experience with the following sources and targets: XML, JSON, REST API, SOAP API, AWS S3, MS SQL, Postgres', 'Contribute to the design and implementation of reporting data architecture(s) and data model design', 'Enhance current Data Management operations processes to improve efficiency and stakeholder relationships', 'Develop database solutions to store and retrieve company information', 'Analyze structural requirements to support data from new software and applications', 'Coordinate with Analytics Functions to identify future needs and requirements', 'Gain insights into customer pain points, challenges, and needs for data consumption', 'Evaluate business value opportunities and deliver quality solutions', 'Design and manage a repository of documentation related to data architecture standards, protocols, frameworks, technique, and opportunities for documentation improvement', 'Migrate data from legacy systems to new solutions', 'Actively develops skills, knowledge, and abilities to maintain currency with new developments in data architecture, as well as related areas such as data integration, application programming interfaces, and data management', '3-5 years’ relevant experience working in Business Intelligence teams', 'Strong understanding of data modeling, master data management, enterprise data warehousing, ETL, reporting, querying, requirements, analysis, and data integration techniques', 'Familiar with data warehousing, data marts, and data lakes, including implementations in a hybrid environment', 'Ability to develop strong relationships and support resources across company functions to achieve results', 'Excellent customer service and communication skills', 'Strong project manager', 'Ability to motivate and encourage others to action', 'Thrive in a fast-paced environment']",2020-08-08 13:52:29
Process Engineer,Career Transitions,3.3 out of 5,"Port Jervis, NY 12771","['One of largest contract manufacturers of consumer goods', 'Strong employee culture', 'Proven history of growth with sales more than doubling over the last 5 years!', 'Review all specifications and procedures for new products', 'Meet with customers and review specifications and requirements and ensure what is agreed to is implemented', 'Make necessary adjustments on pilot batches to insure good product', 'Identify and interpret variations in product, equipment, and procedures, which may affect results', 'Set up standard laboratory equipment, run testing, obtain results, and accurately record the results', 'Contribute suggestions for improving laboratory methods and procedures', 'Offer proven experience with functions and operation of all laboratory and production equipment in area of responsibility', 'Work with manufacturing and production personnel on problem products when assigned, and record and report data', 'Assist in the formula input system for assigned area and implement batch pack', 'Offer proven experience within manufacturing and production procedures and GMPs', 'Understand and adhere to safety policies and procedures', 'Offer solid knowledge of raw materials and chemicals use in products', 'Flexibility and ability to prioritize other duties assigned by immediate supervisor', 'Bachelor of Science Degree in and Engineering discipline or Chemistry', '3+ years of manufacturing plant experience preferably in the cosmetic industry; otherwise, pharmaceuticals or closely related industry', 'Experience working within a highly regulated GMP work environment and following environmental, safety and quality control procedures', 'Excellent communication skills including verbal, written and interpersonal', 'Good public relations skills for interfacing with customers and outside plant vendors']",2020-08-08 13:53:13
Electrical Engineer (Manufacturing),"Opportunity Search, Inc.",N/A,"Bowling Green, OH 43402","['Update, modify, and continuously improve existing controls systems including robotic programs, ladder logic programs, relay logic, electrical distribution, motor controls, operator interface, hydraulics, and pneumatics distribution and control', 'Design and develop new machine controls including robotic, electrical, electronic, hydraulic, pneumatic and vision systems', 'Coordinate with engineering and maintenance on existing machine control modifications to robotic, electrical, electronic, hydraulic, pneumatic and vision systems', 'Create, maintain and keep current all hard copies and electronic data bases: all electrical, hydraulic, and pneumatic schematics; panel layouts; PLC, operator display, operator interface, and robot programs; machine power distribution and all related vendor controls component part documentation', 'Schedule and complete backups of all electronic machine control and robotic programs on set schedule', 'Implement and maintain data collection system from shop floor processing equipment', 'Maintain and expand existing plant floor machine control to Ethernet gateways, links and connections', 'Maintain all sub machine control data highways', 'Maintain and update controls portion of machine standards', 'Coordinate with and aid company systems personnel with plant floor Ethernet machine drop routing and Ethernet message traffic control', 'Complete correspondence, forms and reports using personal computer and applicable software', 'Participate in Continual Improvement activities', 'Perform other duties as assigned', ""Bachelor's degree in a related discipline, i.e. Electrical Engineering, Industrial Technology, etc., or equivalent experience and education"", 'Siemens S7 experience required', 'Electrical controls engineering background desired', 'Complete knowledge of and ability to design and use relay logic, ladder logic, pneumatic logic and hydraulic logic', 'Complete knowledge of and ability to use RS232, RS422, DH485, Ethernet, DH+, Device Net, Control Net and remote I/O communications protocol', 'Understanding of and ability to use java C+, C++ and Visual Basic', 'Complete understanding and ability to use Excel, Word, Access, Acad 2000 or Acad 2000LT, and all related computer software for machine programming, backup and monitoring', 'Experience with Allen Bradley Processors, Motoman Robots and Fanuc Robots a plus', 'Able to demonstrate understanding of how job performance affects product quality and customer satisfaction', 'Able to work well with others; build and maintain positive Team Member relations', 'Able to prepare, read and interpret written reports, instructions, procedures and guidelines', 'Able to effectively present information and respond to questions from management, Team Members, suppliers and customers', 'Able to read and interpret blueprints and schematics', '401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Day shift', 'Night Shift', 'One location', 'No']",2020-08-08 13:53:13
Manufacturing Engineer - Plastic Injection Molding,MBS Advisors,N/A,"Charlotte, NC","['You will use a broad spectrum of skills related to launching and maintaining responsibility for engineering of assigned parts for their lifetime, from inception through manufacturing.', 'You will lead or assist in putting the mold together from its components.', 'You will be responsible for measuring the tool and resulting parts and comparing to spec, as well as running and troubleshooting the molding machine to assure manufacturability of all parts.', 'Maintain communication with manufacturing for ongoing improvement of process and product.', 'Our client is a leader in providing passive components for high density optical interconnects. The company was founded to expand the use of MT style multifiber technology through the design, manufacturing and sales of high precision fiber optic components.', 'Our client provides industry leading components that enable high bandwidth systems such as cloud computing, core routing of the Internet, and fiber-to-the-home.', 'Our client consistently invests in product design, development, and manufacturing to support the growth of new and more cost effective applications. The company actively participates in worldwide standards and implementation forums to drive broad support for new technology.', 'Today, our client’s brands span the globe, delivering cost effective technology solutions for data center and enterprise structured cabling, public networks, circuit board interconnect, and industrial and military markets worldwide.', 'The successful candidate will have at least two years of engineering experience working for an injection molder that produces precision parts. Experience with engineering resins is preferred.', 'The ideal candidate will be hands-on, detailed, have a doer mentality, and have a working familiarity with coordinate measuring machines (CMM) and other metrology technologies.', 'Possess necessary soft skills, a willingness to learn and be trained, patience, teamwork and have a positive attitude.', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Plastic Injection Molding: 2 years (Required)', 'One location', 'Detail-oriented -- quality and precision-focused', 'Innovative -- innovative and risk-taking', 'Stable -- traditional, stable, strong processes', 'https://recruiting.mbsadvisors.com/jobs/view/manufacturing-engineer-plastic-injection-molding/', 'No']",2020-08-08 13:53:13
Process and Material Engineer,Employbridge Search Group,N/A,"San Diego, CA 92121","['Serve as the team’s materials and process engineer for development projects or multiple simultaneous projects.', 'Work closely with other development engineers, designing with a system-wide perspective.', 'Performs detailed chemical analysis of thermoplastics as well as research activities related to substitute and/or new materials.', 'Develops and coordinates the performance of tests and/or evaluation procedures pertaining to materials selection, specifications, testing, and processing. May collaboratively support process improvement efforts.', 'Serves as an adviser to product engineering, purchasing and reliability personnel on matters pertaining to material specifications and appropriate processes.', 'Surveys and evaluates new and advanced materials engineering techniques and concepts, equipment and processes. Will collaboratively support teams on more complex or inter-related processes.', 'Leads supply management in technical expertise related to material and process-based issues of quality, reliability, performance, substitution, etc.', 'Identifies and implements material and process improvements that support strategic initiatives including cost reduction and quality improvement.', 'Performs failure analysis of new and test components to determine root cause and recommend actions.', 'Bachelor’s Degree in Polymer Chemistry or Chemical Engineering, from an accredited university', '4 plus of engineering and project experience in a manufacturing environment', '3 plus years of experience in the development of plastic materials and products and their associated processing technologies, e.g., extrusion and injection molding', 'Experience in planning, organizing and implementing engineering projects', 'Project management experience in a cross-functional environment', 'Ability to work with cross-disciplinary teams', 'Knowledge of plastic materials and engineering with an expert understanding of the principles, can apply the information to complex situations, solve complex problems, conduct research, break new ground, develop new applications and provide expert support', 'Technical knowledge to conduct destructive and non-destructive testing and evaluation of plastic materials', 'Analyze data, develop trends, and create actionable steps', 'Manage and prioritize multiple projects.', 'Ability to communicate effectively.', 'Working knowledge of SAP or other ERP/MRP systems']",2020-08-08 13:53:13
Stress Analysis Engineer,Belcan,3.6 out of 5,"Phoenix, AZ",[],2020-08-08 13:53:13
Automation Engineer,NewCareers,N/A,"Rochester, NY","['Bachelors degree in Computer Science, Biochemical/Chemical Engineering, Electrical Engineering or Mechanical Engineering.', 'Experience with Rockwell and ABB Automation/Distributed Control Systems.', 'Process Safety Management (PSM) knowledge and/or experience.', 'Must have experience working in a large manufacturing facility.', 'Must have experience working with organic processes, chemical synthesis, working with tanks, pumps and fluids.', 'Experience in Automated Data Management Systems or Process Mapping.', 'Strong interpersonal skills and ability to work well in a team environment.', 'Strong verbal, written and analytical skills.', 'Strong project organizational skills is a must have.', 'Will be responsible for programming and troubleshooting systems with: Rockwell PLC, Inbatch Software, ABB 800xA, SAP Enterprise Resource Planning (ERP) Information System, Historian software, and Wonderware System Platform.', 'Management of hardware systems to support all software requirements.', 'Participate in PSM programs', 'Site PSM leader for Safety Instrumented Systems and Interlocks.']",2020-08-08 13:53:13
Logistics Engineer,"Apollo Professional Solutions, Inc",3.8 out of 5,"Nashua, NH 03064","['Individual should be an agile thinker and executor of Product Support able to move between the strategic and implementation levels during interactions with multiple disciplines, audiences and groups.', 'Skilled in supporting technical proposal activities including Technical Volume development, Basis Of Estimate creation, and manpower estimations.', 'Good working knowledge of Reliability, Maintainability, and Product Safety to ensure emphasis is placed on designing for high levels of supportability and availability', 'Must have excellent written and verbal communication skills.', 'Highly proficient with Microsoft Word, PowerPoint and Excel.', 'Demonstrated hands-on experience with logistics engineering tools and processes to prepare models and documents meeting DoD standards.', 'Ability to perform Spares analysis using COMPASS, SESAME and OPUS-10 for Provisioning', 'Hands-on experience with Logistics tools such as SLICWave and Eagle to develop Level of Repair Analyses (LORA)s, Logistic Product Data (LPD), and Logistics Maintenance Information (LMI).', 'Familiarity with principles of Contractor Logistics Support and Performance Based Logistics', 'User expertise in the use of PLM for engineering records', 'Familiarity with Technical Manuals and Training development requirements', '10 years experience using development tools to execute the principles and requirements associated with product support and logistics engineering', 'Experience with new start development projects.', 'Experience with life cycle sustainment planning and execution. Experience with managing development teams', 'Experience with Earned Value Systems and Cost Account Management Demonstrated confidence in presentations to customer or management audiences', 'Familiarity or experience with life cycle cost analysis.', 'Must have a Bachelors degree from an accredited university', 'Able to obtain SECRET level clearance', '401(k)', 'Dental Insurance', 'Health Insurance', 'Monday to Friday', 'logistics: 10 years (Preferred)', ""Bachelor's (Required)"", 'United States (Required)', '1 year', 'One location', 'Every week', 'Weekly', 'No']",2020-08-08 13:53:13
Manufacturing Engineer,Advantage Resourcing,3.7 out of 5,"Memphis, TN 38116","['Job', 'Company']",2020-08-08 13:53:13
Biological Research Technician,Staffing Resource Group,N/A,"West Chester, PA","['Responsible for product-related operations in cell culture/fermentation and bioreactor operations. Primarily focused on cell culture activities; secondary focus and small scale inoculum preparation.', 'Operates and maintains production equipment as it relates to cell culture – fermentation. Including, but not limited to: calibrations, preventative maintenance, initiating work orders, etc.', 'Performs a variety of complex tasks under general guidance and in accordance with current GMPs.', 'Experienced with drafting, executing, documenting and reviewing data, and approval of SOP’s and batch records according to GMP guidelines.', 'Maintain records to comply with regulatory requirements and performs daily in-process testing.', 'Provides detailed observations, analyzes data, and interprets results.', 'Initiates deviations, assesses product quality impact, and proposes and executes Corrective and Preventative Actions (CAPA).', 'Change owner for implementation or revision of equipment, documentation, and material specifications.', 'Maintains daily workload schedule and relevant resource requirements.', 'Proposes implementation of production procedures to optimize manufacturing processes. Monitor processes and results and suggest methods to ensure process success.', 'Preferred BS degree in Chemical Engineering, Biotechnology, Biology, Chemistry or related Engineering discipline with 2-4 years mammalian cell culture experience, or MS with at least 1 years’ experience in upstream mammalian cell culture and cGMP manufacturing.', 'Single use bioreactor and single use media preparation experience.', 'Ability to observe technical issues and directs troubleshooting of process and equipment problems.', 'Ability to operate with minimal supervision of complex systems and equipment and optimizes their use in manufacturing in accordance with GMP’s.', 'Ability to work on complex assignments of diverse scope and ability to exercise judgment within defined procedures and practices to determine appropriate actions.', 'Mammalian Cell Culture: 2 years (Required)', 'GMP (Good Manufacturing Practice): 1 year (Required)', ""Bachelor's (Required)"", 'Possible', 'One location', 'Health insurance', 'Vision insurance']",2020-08-08 13:53:13
Lab Project Engineer,United Staffing Associates,3.8 out of 5,"San Luis Obispo, CA 93401","['Assist lab manager in developing proposals/cost estimates for testing and prototype work', 'Work with Engineers and lab manager to develop test plans for standard tests and custom experimental work.', 'Assist lab technicians and schedule work in the lab.', 'Assist with set up, execution, fabrication, assembly and cleanup of tests.', 'Review and process test data for presentation to clients Assist project engineers with report preparation for test work.', 'Assist with lab activities as needed, including sample shipping, receiving and sample tracking.', 'Assist with improvement of existing lab equipment and test methods and development of new test equipment and methods.', 'BS in Mechanical Engineering or equivalent knowledge/experience.', 'Experience working in a lab or shop environment with mechanical equipment, instrumentation or in a process plant environment.', 'Familiarity with fabrication/building with metal, wood and plastics.', 'Ability to monitor experiments and document observations.', 'Ability to solve problems and troubleshoot unexpected test behavior.', ""Well organized, able to keep accurate records, develop and follow written instructions and SOP's."", 'Well versed in Microsoft Excel and Word.', 'Labview experience a plus, but not required.', 'Familiar with instrumentation including pressure transducers, flow meters, load cells and Thermocouples', 'Familiar with forklift and crane operation and rigging.', 'Excellent verbal and communication skills.', 'SDS knowledge, familiarity working with hazardous material is beneficial.', 'Must be able to life 50 lbs or more.', 'Monday to Friday', 'Laboratory: 4 years (Preferred)', 'Mechanical Engineering: 4 years (Preferred)', ""Bachelor's (Preferred)"", 'https://www.unitedwestaff.com/', 'https://www.facebook.com/UnitedWeStaff/', 'Only full-time employees eligible', 'No']",2020-08-08 13:53:13
Packaging Engineer- II,System One,3.6 out of 5,"Raritan, NJ","['The Packaging Engineer will design, test, and implement the packaging designs that are required to meet new or existing in vitro diagnostic product requirements.', 'A large portion of their responsibility will be container closure integrity testing, which consists of establishing the appropriate application and removal torques for changes to cap or pipette attributes; new mold, liner, bulb, etc. Also, consists of executing routine testing, vibration, vacuum leak and removal torque, after specified durations.', 'They will apply extensive theoretical and technical expertise to independently address complex problems to complete assigned projects under limited direction.', 'They will be a key member on project teams to deliver high-quality packaging on schedule.', 'The engineer will participate in the Change Control Process to update packaging specifications, Bills of Material, Master Data, and Labeling.', 'Assist in driving improvements throughout supply chain/cold chain', 'Generate Package Testing Protocols and Reports aligning to ASTM and ISTA standards.', 'Develop Packaging specifications, Packaging Work Instructions, and Bills of Material.', 'Designing Packaging for Manufacturability, performance, at optimum cost.', 'Work with Packaging Vendors to create mock-ups of new design concepts.', 'Provide technical feedback on equivalency of replacement materials due to cost or obsolescence issues.', 'Track and report progress at project and departmental meetings.', 'Awareness of packaging trends, process improvements, and new technologies.', 'Communicate and introduce as applicable.', 'Will be a member of multidisciplinary project teams and be called on to lead teams for tasks that are focused on packaging issues.', 'BS in Package Engineering or Equivalent', '3+ years of relevant Package Engineering experience preferred in the regulated medical device industry', 'Minimum 3 years relevant Package Engineering experience', 'Knowledge of glass vial, labels, folding carton, corrugated, and transport packaging.', 'Strong written and verbal communication skills', 'Strong analytical, problem solving, insight generation and critical thinking skills', 'Self-initiator, results driven and detail oriented', 'Familiarity with GS1 Barcoding Standards a plus.', 'Familiarity with Adobe Illustrator a plus.', 'Proficiency with Microsoft Office programs including Word, Outlook, Power Point, and Excel.', 'Strong project / program management skills', 'Ability to effectively work within a cross functional team to expedite completion of critical project tasks. In addition, can work independently with minimal supervision.', 'Working knowledge of the validation requirements for Medical Devices.', 'Ability to select and execute the appropriate statistical tools and provide the practical conclusions and inferences during the process development and validation activities.', 'Working knowledge of Six Sigma/Process Excellence Tools (DMAIIC, DMADV, or Lean) which include Design of Experiments, capability analysis, sampling statistics and techniques, CTQ flow down, C/E Matrix, pFMEA, fish bone diagrams, etc.', 'Candidates with experience using Minitab are preferred.', 'A very good understanding of part prints and drawings.', 'Demonstrated experience in the development and execution of project plans.', 'Excellent communication skills; making complex issues easy for others to understand and the ability to prepare communications for team and project documentation.']",2020-08-08 13:53:13
Manufacturing Process Engineer,"Plastic Executive Recruiters, LLC",N/A,"Charlotte, NC","['This client is family-owned manufacturing company with a steady record of growth.', 'You will be challenged to continue learning and expanding your skill set.', 'This company is flexible and agile in responding to customer and market demands.', 'You will be listened to and appreciated by a leadership team that strives to make this company the place to be.', 'Contribute to manufacturing a stable of well-known brand name goods.', 'Competitive pay, low cost of living and relocation expenses, if applicable.', 'Troubleshoot new and existing issues involving product design, materials and processes.', 'Evaluate all machinery and equipment and the relative operation conditions. Make changes where necessary.', 'Design finished good testing.', 'Assist in new machine installation and commissioning.', 'Provide regular updates on project progress and prepare forecasts when necessary.', 'Engage Continuous Improvement methods to enhance quality, reliability and efficiency.', 'Perform root cause analysis and develop design, material or process recommendations.', 'Evaluate and adjust manufacturing processes moving forward.', 'Work closely with Maintenance on PM development and execution to eliminate downtime.', 'Assist in training production operators after machine commissioning.', 'Work closely with Tool Shop on the design and development of new tooling.', 'Must have polystyrene extruding experience, preferably in packaging.', 'Paper goods manufacturing process experience is a plus.', 'Formal Process Engineering experience required.', '4-year college degree in relevant technical field preferred, or 2-year degree with strong experience in a similar role.', 'Project management experience of 3-4 years. Background using Microsoft Project, Gantt Charts, or other timeline tools would be helpful.', 'Experienced with process improvement data gathering and document generation.', 'Strong-hands on mechanical ability.', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Process Engineering: 5 years (Preferred)', 'EPS foam extrusion: 5 years (Required)', ""Bachelor's (Preferred)"", 'United States (Required)']",2020-08-08 13:53:13
"Sr. Environmental, Health and Safety Specialist",CSL Behring,3.3 out of 5,"King of Prussia, PA 19406","['Job', 'Company', 'Responsible for planning and implementing safety, environmental, and related compliance programs and/or projects', 'Ensures compliance with federal, provincial and municipal regulations and corporate policy and guidelines', 'May analyze test data and develop or prepare charts, matrices and test specifications', 'Undertakes most difficult projects, assessments and solutions', 'May be assisted by technicians', 'Fall Protection', 'Hazard Communication', 'Powered Industrial Trucks', 'Electrical Safety', 'Lockout/Tagout', 'Hot Work', 'Radiation Safety', 'Biological Safety', 'Chemical Handling & Hygiene', 'Oversees the responsibilities of the contract chemical and biohazardous waste management companies.', 'Reviews and signs waste manifests, or arranges site delegate.', 'Outlines training requirement to staff.', 'Ensures regulatory compliance and site conformance to procedures and policies.', 'Provides guidance, as needed, on proper segregation, collection, and disposal of waste.', 'Reviews and categorizes incident reports, investigations, and CAPA.', 'Reviews incident investigations and outlines areas for improvement or additional mitigation efforts.', 'Tracks incident and CAPA metrics.', 'Assists with incident notifications and safety alerts.', 'Environmental and sustainability program management', 'Assesses workplace hazards.', 'Development of technical documents including EHS procedures, programs, and training.', 'Fleet management.', 'Owns the development and execution of emergency response plans and drills.', 'Works with staff and managers throughout the organization.', 'Scope of the role is primarily associated with the lab, office and distribution locations across N. America.', 'May provide technical input into the development of EHS strategies.', 'Accountable for all programs assigned via site EHS Director - Americas', 'This position will interact primarily throughout all levels of the organization with a focus on providing support and ensuring ongoing compliance and sustainment of EHS programs and processes.', 'Position will influence staff and managers and is expected to negotiate with them.', 'This position will interact with regulatory bodies during compliance inspections.', 'Must have the ability to write procedures, policies, reports, and correspondence.', 'Must be comfortable with delivering presentations to audiences of 5 to 20 5-200 people (ex. training, presentation of data or results)', 'Ability to read and interpret documents such as safety rules, operating and maintenance instructions, and procedures and policies.', 'Must have excellent interpersonal skills and be able to interact and form strong working relationships with individuals from all disciplines.', 'Ability to solve practical problems.', 'Ability to interpret written and oral instructions.', 'Proficient in the use of Excel, Word, PowerPoint, and Microsoft Outlook.', 'Detail oriented.', 'Ability to multitask.', 'Bachelor degree in Occupational Safety, Environmental Engineering, Environmental Sciences, Chemical Engineering or equivalent', ""7 years' relevant experience including experience at a manufacturing site"", 'Thorough knowledge of safety and environmental regulations', 'Large pharmaceutical or chemical manufacturing experience']",2020-08-08 13:53:13
Semiconductor Engineer/Product Specialist at an Intl Financial Firm,Access Staffing LLC,N/A,United States,"['Bachelor’s degree strongly preferred', 'Five or More (5 or more) years of experience working for an Original Equipment Manufacturer or Device Manufacturer in the Semiconductor Industry', 'An understanding of the semiconductor manufacturing process with in-depth knowledge of deposition equipment is crucial', 'Strong engineering background enabling you to comprehend different deposition process control variables, for example chemistries, flow and power and their impact on device shrinks and yield', 'Aware of how automated handling impacts deposition productivity and apply the limitations of all these variables over time', 'Provide equipment valuations and desirability in the secondary market', 'Provide recommended list pricings and review equipment data sheets for technical accuracy', 'Identify sales strategies and potential buyers to provide leads to sales staff', 'Coordinate and provide direction to operations for all equipment moves', 'Compare client equipment demand inquiries with availability to match technical specs and offer model alternatives', 'Provide key stakeholders with up to date market information', 'Provide support by drafting lease agreements, reviewing documents, and assisting with internal audits', 'Holidays', 'Monday to Friday', 'Bonus Pay', 'See ""Custom Question (very important)"": 5 years (Required)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Fully Remote', 'Only full-time employees eligible', 'Yes']",2020-08-08 13:53:13
BOM Coordinator / Material Coordinator / Engineering Change Coordinator,Datamatics Global Services Limited,3.5 out of 5,"Dayton, OH 45414","['Determine and Validate correct material master data for all materials for all products.', 'Work with Industrial Engineers to capture and validate master labor data for all products.', 'Respond to requests from data users to analyze and help resolve BOM data problems that may be causing', 'Receive and implement requests for changes to material/labor master data.', 'Documents attached to the proper location, revision levels are correct', '8 Hour Shift', 'Monday to Friday', 'Change Management: 3 years (Preferred)']",2020-08-08 13:53:13
Data Architect | Hiring Now,Vaco,3.7 out of 5,"Richmond, VA 23219","[""Work directly with our clients and internal executives in presale and client delivery environments to architect sustainable data solutions, design data engineering delivery plans and mentor our data engineers build and maintain these solutions.Leverage your advanced software engineering expertise including experience analyzing transactional and reporting system data and available cloud and on-prem storage and retrieval options. Design interactions with large-scale processing systems, develop real-time integrations leveraging RESTful APIs, and develop scalable data structures to address our client's most pressing data engineering needs.Partner with clients and provide leadership to our data engineering team members in developing, constructing, testing and maintaining first-class data architectures.Share your experience supporting real-time data, data streaming, scalability of the platform and management of large volumes of data.Use your mastery of a variety of languages and tools to marry systems and data while recommending ways to improve current systems and data reliability, efficiency and quality.Provide thought leadership internally and externally, always staying abreast of the very latest tools and technology available.Leverage your deep expertise in data engineering best practices, serving as mentor and coach to team members, sharing the expertise throughout our team.Create sophisticated analytics programs, machine learning and statistical methods to prepare data for use in predictive analytics.Bring a focus to automating our clients' work through the use of the solutions you develop.Collaborate with API developers to build data-driven microservices for our clients"", 'Designing, developing, scaling, and maintaining data using Spark, Kafka, Hive, Python or Scala.Experience with modern ETL and workflow capabilities such as Apache Airflow, Luigi and Jenkins.Experience designing and implementing SQL and NoSQL systems of record.Experience designing and implementing various data hub architectures, supporting a variety of business use cases.Hadoop DeveloperPutting modern data platforms into use, including platform as a service variant.Providing expertise with humility; communicating complex ideas with clients?and technical staff.Using Git or Github in a CI/CD development workflow.Developing microservices using languages like Java, Python or JavaScript?and using REST?APIs.Writing?effective technical documentation and thought leadership artifacts (best practices, blogs, client documentation).Automating deployments using DevOps tools like Docker, Ansible, Terraform, or Kubernetes.']",2020-08-08 13:54:01
Service Engineer,Eastern Staffing & Recruiting,3.8 out of 5,"Ladson, SC 29456","['Trains customers and internal employees on products, performance improvements and quality standards to ensure total customer satisfaction.', 'Follows up with customers on performance by evaluating data-driven metrics and output results.', 'Performs installations and support utilizing hand tools, multimeter, ability to read wiring schematics, mechanical skillset, and PLC ladder logic understanding.', 'Performs system analysis of current workflow and proposed setup to improve customer efficiency and system effectiveness, including proposals to add, remove, or modify existing configurations and supporting peripherals.', 'Consults with customers and internal management for final approval of proposed modifications and documentation.', 'Assists the engineering department in the testing of new software and hardware.', 'Develops recommendations to enhance or replace existing hardware and/or software based on customer experience.', 'Submits written and accurate reports in a timely manner.', 'Interacts with customers to analyze and solve hardware and software issues', 'Disassembles and reassembles machines to repair or replace worn or malfunctioning components and consumables.', 'Provides excellent customer service, listening carefully to customer concerns and addressing issues until the customer is satisfied', 'Writes accurate and timely reports.', 'Makes recommendations to the Customer Service management team to improve customer service or workflow efficiency.', 'Assists in the testing, development of new software and hardware to enhance quantitative and qualitative customer needs.', 'Drives continuous improvement for all customer service implementation and activities while upholding the highest standards of quality and professionalism.', 'Gathers data, creates, composes, and edits user instructions and customer reports.', 'Ensures that all related work is performed properly, efficiently, and in a cost-effective manner.', 'College degree within an engineering concentration preferred. e.g. Mechanical, Industrial, Electrical, or Computer Sciences.', '3+ years of experience in electro-mechanical or engineering role.', 'Advanced technician level knowledge of installing, troubleshooting, and repairing electro-mechanical systems.', 'Must have the ability to read blueprints, wiring schematics, and PLC controls.', 'The ideal candidate will be self-motivated, highly organized, and possess high attention to detail.', 'Must have excellent communication skills – both written and verbal.', 'Software Experience: MS 365, MS upgrades, Networks, Servers, and a basic understanding of MS SQL.', 'Mechanical Experience: hand tools, power tools: drills, electric saws, rivet guns, and pallet jacks.', 'Ability to lift up to 50 lbs.', '10 Hour Shift', '8 Hour Shift', 'Day shift', 'Monday to Friday', 'troubleshooting: 3 years (Required)', 'mechanical: 3 years (Required)', 'electrical: 3 years (Required)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Weekly', 'A job for which military experienced candidates are encouraged to apply']",2020-08-08 13:54:01
Data Integration Software Engineer,HealthCare,N/A,"Boston, MA","['Design, Code, and Test back-end Ruby on Rails systems for transforming and ingesting patient data', 'Implement automated tests with RSpec', 'Work with Product and Engineering teams to understand and contribute to functional and technical requirements', 'Collaborate with Customer Support team to research, understand, and resolve data integrity problems', 'Collaborate with Integration team to analyze new data sources and implement systems to ingest data into the CarePort platform', 'Implement logic for segmenting patient data according to customer-defined rules', 'Ensure all work is peer reviewed to ensure code quality and to develop a shared understanding of the work that is being done', 'Peer review and sign-off of others work', 'Timely and accurate reporting of project status', 'Escalate product issues and suggest product improvements', 'Escalate all issues in a timely fashion', 'Mentor junior team members in best practices and standards', 'Proficiency and recent experience building applications with Ruby on Rails', 'Proficiency in database design and querying, both with SQL and Active Record', 'Proficiency in writing automated tests with RSpec or similar testing framework', 'Experience using git and GitHub for source code management and peer review', 'Experience building systems for parsing and transforming data, including HL7,XML, delimited flat files', 'Experience working with containerized deployment environments (eg, Docker)', 'Experience transporting data through various protocols including REST APIs,', ""Successful completion of a Bachelor's Degree or relevant Technical / Business Experience."", 'Ruby on Rails: 6 years (Required)', 'SQL: 5 years (Required)', 'RSpec: 6 years (Preferred)', 'No']",2020-08-08 13:54:01
"Data Architect | $130-160k | Direct-Hire | Richmond, VA",Vaco,3.7 out of 5,"Richmond, VA 23219","[""View your clients' success as your ownAre passionate about what you doLove to teach yourself new skillsSeek opportunities to learnThrive in ambiguityEnjoy working on a teamEasily adapt to new project requirements and client expectations"", ""Work directly with our clients and internal executives in presale and client delivery environments to architect sustainable data solutions, design data engineering delivery plans and mentor our data engineers build and maintain these solutions.Leverage your advanced software engineering expertise including experience analyzing transactional and reporting system data and available cloud and on-prem storage and retrieval options. Design interactions with large-scale processing systems, develop real-time integrations leveraging RESTful APIs, and develop scalable data structures to address our client's most pressing data engineering needs.Partner with clients and provide leadership to our data engineering team members in developing, constructing, testing and maintaining first-class data architectures.Share your experience supporting real-time data, data streaming, scalability of the platform and management of large volumes of data.Use your mastery of a variety of languages and tools to marry systems and data while recommending ways to improve current systems and data reliability, efficiency and quality.Provide thought leadership internally and externally, always staying abreast of the very latest tools and technology available.Leverage your deep expertise in data engineering best practices, serving as mentor and coach to team members, sharing the expertise throughout our team.Create sophisticated analytics programs, machine learning and statistical methods to prepare data for use in predictive analytics.Bring a focus to automating our clients' work through the use of the solutions you develop.Collaborate with API developers to build data-driven microservices for our clients"", 'Designing, developing, scaling, and maintaining data using Spark, Kafka, Hive, Python or Scala.Experience with modern ETL and workflow capabilities such as Apache Airflow, Luigi and Jenkins.Experience designing and implementing SQL and NoSQL systems of record.Experience designing and implementing various data hub architectures, supporting a variety of business use cases.Hadoop DeveloperPutting modern data platforms into use, including platform as a service variant.Providing expertise with humility; communicating complex ideas with clients?and technical staff.Using Git or Github in a CI/CD development workflow.Developing microservices using languages like Java, Python or JavaScript, and using REST APIs.Writing?effective technical documentation and thought leadership artifacts (best practices, blogs, client documentation).Automating deployments using DevOps tools like Docker, Ansible, Terraform, or Kubernetes.']",2020-08-08 13:54:01
"AWS Cloud Engineer with Java, Python",Concepts Beyond,N/A,"Washington, DC","['Develop Web Services (SOAP/REST), XML Messaging Services in Java, Python, and other languages', 'Design, architect AWS cloud services and security solutions', 'Design, develop real-time, large-scale data processing and streaming functions using Apache Flink , Lambda functions, Amazon Glue, NiFi, Kafka, Apache Spark, and other technologies', 'Prepare architecture documents, user guides, diagrams, and briefings to convey complex technical information to a wide range of audiences', 'Architect, setup, and develop scalable Big Data solutions including AWS EMR, Spark, Hadoop, and Internet of Things applications', 'Design and develop algorithms, tools, and software for various aviation applications, flight data processing, and data analyses', 'Bachelor’s degree or higher in Computer Science, Engineering or related technical field from a US accredited institution', '3+ years of development experience (Java, Python) in enterprise messaging system architectures (Service Oriented Architecture, Microservices, etc.)', 'AWS Certification', 'Experience with distributed scalable Big Data storage, including AWS EMR, Spark, etc.', 'Experience performing data Management, modeling, and warehousing', 'Experience with cloud data and application migration', 'Experience using Agile software development methods in a DevOps environment', 'Experience with J2EE full stack development, Java Messaging Services, Web Services', 'Experience with automated unit testing (such as JUnit)', 'Excellent communication and writing skills', 'Ability to work independently and understand complex technical terms/materials', 'Familiarity with Agile/Scrum process', 'Knowledge with User Interface using AngularJS/JSF/ReactJS', 'Experience with backend development in PostgreSQL and Oracle 12c Databases – 3+ years', 'Experience with IDE, SQL tools, and build tool –ANT, Maven, Netbeans', 'Experience in FAA systems, cloud, GovCloud, architecture, security, NIST standards', 'Experience with Big Data, Apache NiFi, Spark, Hive, Elasticsearch, Hortonworks, IoT, Muelsoft Integration Platform', 'Experience with Data Analytics, Global Aviation Exchange Models (AIXM, FIXM, iWXXM), Air Traffic Management (ATM) knowledge, AMHS', 'Monday to Friday', 'AWS: 3 years (Preferred)', 'Java Development: 3 years (Preferred)', ""Bachelor's (Required)"", 'Washington, DC (Preferred)', 'http://conceptsbeyond.com', 'Temporarily due to COVID-19']",2020-08-08 13:54:01
Clinical Data Analyst (Remote),Kelly,3.9 out of 5,California,"['Job', 'Company', 'Maintain architecture for device generated data pipeline', 'Assemble and report on large, complex data sets that meet business requirements', 'Identify, design, and implement internal process improvements: automating and optimizing manual processes, data extraction, transformation, loading of the data, and data delivery', 'Work with stakeholders including the data managers, statistical programmers, and the statisticians to assist with device data-related technical issues and support their data infrastructure needs.', 'Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or related quantitative field. Advanced degree preferred.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Experience building and optimizing data pipelines, architectures and data sets', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'A successful history of manipulating, processing and extracting value from large datasets', 'Strong project management and organizational skills', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Experience in medical device or pharmaceutical environment preferred', 'At least 3years of experience in a Data Engineer role, with experience using the following software/tools: Big data tools: Hadoop, Spark, etc.', 'Relational SQL and NoSQL databases (Experience with Hive preferred)', 'Analysis and visualization software such as R, RStudio, Python, and Tableau', 'Data pipeline and workflow management tools', 'benefits to be received upon meeting eligibility requirements']",2020-08-08 13:54:01
Python Developer,New York Technology Partners,4.1 out of 5,"New York, NY 10036","['Determining operational feasibility by evaluating analysis, problem definition, requirements, solution development, and automation', 'Producing relevant project documentation that ensures governance throughout the agile process whilst also demonstrating the implementation of lessons learned and best practices', 'Designing and implementing of low-latency, high-availability, performant applications', 'Working pro-actively to resolve issues in a timely manner in order to drive customer satisfaction', 'Research, learn, and apply new technologies that can improve performance and minimize operational downtime', 'Collaborating with Enterprise Technology to manage requests and apply standards to work efforts', 'Technical consulting on our data and cloud based systems and tools', 'Troubleshoot, debug, and patch application and platform issues', 'Strong understanding of databases, cloud computing, and software development lifecycle', 'Programming fluency in Python, YAML, PL/SQL , ETL and VBA', 'Experience with relational and object databases (SQL/Mongo)', 'Ability to create and maintain database schemas that represent and support business processes', 'Proficient understanding of code versioning tools (GIT, VSS)', 'Knowledge of user authentication and authorization between multiple systems, servers, and environments', 'Experienced problem solver with strong appetite for continuous improvement', 'Degree in computer science or engineering', 'Strong debugging and unit testing skills', '5+ years of relevant work experience', 'Excellent verbal and written communication skills', 'Experience in a market risk setting at a large corporate entity', 'Understanding of agile based development methodologies', 'Full stack engineer with backend experience', 'Experience with building APIs and services using REST, SOAP, etc.', 'Understanding of asset/liability management analytics and bond/derivative instruments', 'Monday to Friday', 'Multiple locations']",2020-08-08 13:54:01
Tableau Software Engineer 2 – (Remote),The Maxis Group,N/A,United States,"['Monday to Friday', 'Gathering and interpreting user requirements: 1 year (Required)', 'test scenario creation: 1 year (Required)', 'analysis, design, and coding related to Tableau : 4 years (Required)', ""Bachelor's (Preferred)"", 'Monday (Required)', 'Tuesday (Required)', 'Wednesday (Required)', 'Thursday (Required)', 'Friday (Required)', 'Do you have a deep understanding of and experience with Tableau?', '3 - 4 months', 'Possible', 'Fully Remote', 'Yes']",2020-08-08 13:54:01
Sr. Data Scientist/Machine Learning Engineer,Brooksource,3.8 out of 5,"Boston, MA 02210","['Job', 'Company', 'Graduate degree (MS or PhD) in Electrical Engineering, Computer Science, Mathematics or Physics', 'Specialization in machine translation, time series analysis, signal processing, or machine learning', '5+ years of industry experience in predictive modeling and analysis', '5+ years of development experience, graphing databases, and deep learning', 'Collaborate with software engineers to integrate successful experiments into large scale production services', 'Advance exploratory research projects in machine learning and related fields to create highly innovative customer experiences', 'Analyze large amounts of data to discover patterns, find opportunities, and develop highly innovative, scalable algorithms to seize these opportunities', 'Technically lead and mentor scientists', 'Work closely with software engineering teams to build scalable prototypes for testing, and integrate successful models and algorithms in production systems at very large scale', 'Interact with security engineers and related domain experts to dive deep into the types of challenges that need innovative solutions', '401(k)', 'Dental Insurance', 'Flexible Schedule', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Data Science: 4 years (Preferred)', 'AWS: 1 year (Preferred)', 'Machine Learning: 2 years (Preferred)', 'Business Intelligence: 1 year (Preferred)', 'Boston, MA 02210 (Preferred)', 'United States (Preferred)', 'Yes', 'One location', 'Waiting period may apply', 'Temporarily due to COVID-19']",2020-08-08 13:54:01
Test Automation Engineer,ALTEN Calsoft Labs,3.6 out of 5,Remote,['Yes'],2020-08-08 13:54:01
"Quality Engineer (CAPA, NCMR)",Datamatics Global Services Limited,3.5 out of 5,"Plano, TX","['8 Hour Shift', 'CAPA: 1 year (Required)', 'Knowledge in QSRs and ISO 13485: 1 year (Preferred)', 'Support non-conformance activities (NCMRs): 1 year (Preferred)', 'Plano, TX (Preferred)', 'USC or GC Holder (Required)']",2020-08-08 13:54:01
Data Manager,eNGINE,N/A,"Pittsburgh, PA 15222","['401(k)', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:54:01
Industrial Engineer,Reliance One+,3.7 out of 5,"Wentzville, MO 63385","['Assists in establishing operational methods and work standards using various measurement techniques', 'Analyzes existing operations and proposes cost justified improvements', 'Optimizes use of floor space, materials, personnel and equipment', 'Assists in planning new facilities, operations and/or relocation of same', 'Provides information for various management systems', 'Monitors adherence to recommended safety procedures and good housekeeping', 'Auto cad experience', 'Knowledge of standard time data systems (MTM, UAS, Mod apps or GM standard time data)', ""Bachelor's Degree in engineering or a related field (preferably industrial engineering but mechanical and manufacturing would perform well as well)"", '0-5 years of experience', 'Industrial Engineering: 1 year (Preferred)', 'No']",2020-08-08 13:54:01
$90/hr | .REMOTE | NET/Azure (Spec Databricks) Engineer,Vaco,3.7 out of 5,"Nashville, TN 37027","['Ability to drive the architecture, design along with experience in leading the team technically', '3+ years hands-on experience on AZURE Platform with depth in Databricks specifically', '10+ years of .NET/C# development']",2020-08-08 13:54:01
"Production Engineer, Machining Specialist",Gem Care,N/A,"Clinton, TN","['CNC programming', 'JIG design', 'Read and interpret blueprints, sketches, drawings, manuals, specifications, etc', 'Machine troubleshooting', 'Creating cutting paths/use of cutting tools', 'Leak testing', 'Confers with vendors to make machining determinations.', 'Evaluates products according to specifications and quality standards.', 'Supports initial process flow development and identifies manufacturing processes and equipment', 'Makes recommendations on the best methods for part gauging, handling, cleaning, tooling, etc.', 'Supports manufacturing operations', 'Other duties may be assigned.', 'LANGUAGE SKILLS: Ability to read, analyze, and interpret general business periodicals, professional journals, technical procedures, or governmental regulations. Ability to write reports, business correspondence, and procedure manuals. Ability to effectively present information and respond to questions from groups of managers, clients, customers, and the general public.', 'MATHEMATICAL SKILLS: Ability to calculate figures and amounts such as discounts, interest, commissions, proportions, percentages, area, circumference, and volume. Ability to apply concepts of basic algebra and geometry.', 'REASONING SKILLS: Ability to define problems, collect data, establish facts, and draw valid conclusions. Ability to interpret an extensive variety of technical instructions in mathematical or diagram form and deal with several abstract and concrete variables.', '401(k)', '401(k) Matching', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', 'Day shift', 'Monday to Friday', 'Engineering: 4 years (Required)', 'automotive industry: 3 years (Preferred)', ""Bachelor's (Preferred)"", 'One location', 'Bi weekly or Twice monthly', 'No']",2020-08-08 13:54:01
Data Engineer III,"Cercacor Laboratories, Inc.",N/A,"Irvine, CA 92618","['401(k)', 'Dental Insurance', 'Disability Insurance', 'Flexible Spending Account', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'Bonus Pay', 'One location', 'Only full-time employees eligible', 'No']",2020-08-08 13:54:48
Junior QA Product Test/Validation Engineer,"ETS, Inc",3.7 out of 5,"Mount Laurel, NJ 08054","['401(k)', '401(k) Matching', 'Dental Insurance', 'Disability Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Retirement Plan', 'Tuition Reimbursement', 'Vision Insurance', 'Monday to Friday', ""Bachelor's (Required)"", 'United States (Required)']",2020-08-08 13:54:48
Payroll Clerk,BCP Engineers & Consultants,N/A,"Gretna, LA","['Monday to Friday', 'Microsoft Dynamics and Excel: 1 year (Preferred)', 'Payroll: 1 year (Preferred)', 'High school or equivalent (Required)', 'One location', '30-39', 'Detail-oriented -- quality and precision-focused', 'https://bcpengineers.com/', 'https://www.facebook.com/BCPEngineersandConsultants']",2020-08-08 13:54:48
Level 1 Software Engineer in Test,Ascendo Resources,3.3 out of 5,"Alpharetta, GA","['401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Monday to Friday', 'Weekends', 'software engineering: 3 years (Required)', 'Scrum: 3 years (Required)', 'Agile: 3 years (Required)', 'SQL: 3 years (Required)', 'Kanban: 3 years (Required)', ""Bachelor's (Preferred)"", 'United States (Required)', 'Fully Remote', 'No: Not providing sponsorship for this job']",2020-08-08 13:54:48
Jr. DevOps Engineer,Brooksource,3.8 out of 5,"Nashville, TN 37205","['Ensure that all cloud solutions follow internally defined security and compliance controls', 'Configure ARM (Azure Resource Manager) templates, evaluate extensibility to account for newer Azure offerings', 'Configure build and release pipelines for both cloud and on-premise solutions', 'Monitor and support the deployment of both cloud and on-prem applications via automation tools and practices', 'Respond to service requests in your team’s queue', 'Champion Agile best-practices, processes, and tools in support of DevOps processes', 'Participate in on call rotations that occur during normal hours within your time zone', 'Bachelor’s degree in Computer Science or IT-related field or a minimum of 1+ years of relevant, IT experience.', 'Build and deployment automation of .NET applications using one or more platforms such as Bamboo, Jenkins, TFS/VSTS, TeamCity, UrbanCode, etc.', 'Basic understanding and application of Continuous Integration and Continuous Delivery concepts', 'Working experience on IIS admin (7.5, 8.0 preferred) (MUST HAVE), Windows Server (2008/2012 preferred)', 'Demonstrates a strong working understanding of troubleshooting techniques and strategies including an ability to use troubleshooting tools.', 'Demonstrates an ability to manage multiple project deliverables on multiple projects effectively.', 'Strong communication and interpersonal skills with an ability to extract, translate and communicate meaningful information with management and peers', '1+ years of build and deployment automation (Continuous Integration/Delivery) experience using industry-standard platforms', 'Scripting experience, PowerShell is preferred', 'Experience with Agile/Scrum methodologies', 'Working experience in Azure, AWS, or Google cloud platforms a plus', 'Dental Insurance', 'Health Insurance', 'Vision Insurance', '8 Hour Shift', 'Monday to Friday', 'DevOps: 1 year (Required)', ""Bachelor's (Required)"", 'United States (Required)', 'Yes', 'One location', 'Temporarily due to COVID-19']",2020-08-08 13:54:48
Data Engineer/Power BI,Kelly,3.9 out of 5,"Renton, WA 98057","['SSIS, SQL, PowerBI', 'Work in ambiguous environment', 'Able to handle the project from inception to completion']",2020-08-08 13:54:48
Data Engineer II,Kelly,3.9 out of 5,"Mountlake Terrace, WA 98043","['Looking for a strong data engineer with excellent SQL and Data Warehousing skill-set with experience in at least one ETL tool (Informatica, Wherescape, Datastage etc.).', 'Software Development Experience in JAVA building APIs to interact with large volumes of data is a huge plus.', 'Healthcare experience is preferred but not required.', 'Solve business and data science problems using data centric programming and scripting skills to create data models and pipelines.', 'Work closely with the business to create understanding of the needs, pace and direction for our business partners. Translate these needs into requirements and specifications, and maintain contact with the customers throughout project completion.', 'Troubleshoot issues as they arise and solve problems independently and collaboratively.', 'Develop code to complete effective solutions using applicable technology.', 'Perform thorough peer design and code reviews.', 'Use developing data ETL experience to develop data pipelines to support data product automation.', 'At a minimum, candidates must possess the equivalent in education, experience, and skills of a', 'Familiarity with healthcare specific regulatory requirements for data management. (Preferred)', 'Experience providing data integration services within healthcare organizations. (Preferred)', 'Knowledge of Tableau, SAS, R, and other analytic tools. (Preferred)', 'Good problem definition, analytical, problem solving skills, and technical writing skills.', 'Strong data processing programming skills across SQL-based and Hadoop-based technologies.', 'Good written and verbal communication skills and ability to deal with management of various levels and communicate information and ideas in writing so others will understand.', 'Knowledge of Agile and Scrum project methodologies utilizing TFS, Jira/Confluence.', 'Ability to use Extract Transform Load (ETL) tools (SSIS, Data Stage, Cask)', 'Ability to use Kimball methodology for dimensional data modeling, 3rd Normal form DW.']",2020-08-08 13:54:48
DataStage/ Informatica PowerCenter Developer,Epitec,3.5 out of 5,"Dearborn, MI 48126","[""This position is for a Software Engineer with experience in delivering ETL solutions. The software engineer will have significant opportunity to contribute to the company's migration of Global Data Warehouse."", 'Work with Business teams to understand requirements for PDO Backlog features and deliver ETL solutions with high business value using Agile.', 'Work with Data Architects (DAs) to define, create and modify EDW/GDW data models', 'Assist with analyzing commonality in EDW/GDW information models and identify needs for Extract, Transform and Load (ETL)', 'Participate in PDO product team ceremonies such as Standups, Iteration Planning, Demo Days and Release Planning', '5+ years ETL development and integration experience with IBM InfoSphere (DataStage v11.5)', '5+ years ETL development experience with Informatica PowerCenter', '5+ years SQL development experience', 'Bachelors degree in Information Technology or a related discipline', 'ETL development experience with IBM InfoSphere (DataStage v11.5)', 'ETL and development experience with Informatica PowerCenter', 'SQL experience involving multiple, complex queries', 'Good understanding of data modeling and data quality solutions for large programs', 'Exceptional analytical experience of complex applications and data relationships', 'Team oriented with strong interpersonal skills and able to work as part of a product team', 'Strong written/oral communication skills', 'Strong drive for results and ability to work independently', 'Self-starter with proven innovation skills', 'Demonstrated commitment to quality and project timing', 'Demonstrated ability to document complex systems', 'Demonstrated ability to multi-task and adjust resources/assignments based on changing priorities', 'Experience in creating and executing detailed test plans', 'Medical, Dental, PTO, Holiday tailored to meet your needs. 401K/Match, $15,000 Life Insurance, Award-Winning Employee Care Program. Established and highly regarded reputation with Green Card and H1 processing.', '401(k)', 'Dental Insurance', 'Health Insurance', 'Paid Time Off', 'Vision Insurance', '8 Hour Shift', 'Monday to Friday', 'PowerCenter: 4 years (Preferred)', 'MDM: 1 year (Preferred)', 'Datastage 11.3 +: 5 years (Preferred)', 'Teradata: 1 year (Preferred)', 'ETL: 5 years (Preferred)', ""Bachelor's (Preferred)"", 'Likely', 'https://epitec.com/']",2020-08-08 13:54:48
Quality Engineer - Entry Level,Datamatics Global Services Limited,3.5 out of 5,"Plano, TX 75024","['8 Hour Shift', 'Day shift', 'Monday to Friday', 'CAPA regulations: 1 year (Required)', 'Medical Devices: 1 year (Preferred)', 'NCMR OR ""Non-conformance of materials: 1 year (Required)', 'Quality Assurance: 1 year (Required)', ""Bachelor's (Required)"", 'Plano, TX 75024 (Required)', 'United States (Required)', '7 - 11 months', 'Varies', 'Yes', 'www.datamatics.com', 'Temporarily due to COVID-19']",2020-08-08 13:54:48
SR Data Analyst/Engineer,Oxford Global Resources,3.6 out of 5,"Pittsburgh, PA 15237","['Yes', 'Multiple locations', 'Health insurance', 'Dental insurance', 'Vision insurance', 'Retirement plan', 'Paid time off', 'Monday to Friday']",2020-08-08 13:54:48
data entry/clerical,Advantage Resourcing,3.7 out of 5,"Houston, TX 77090",[],2020-08-08 13:54:48
QA Engineer,Insight Global,4 out of 5,"Basking Ridge, NJ 07946","['Dental Insurance', 'Health Insurance', 'Vision Insurance', 'Day shift', 'Monday to Friday', 'Child Welfare Services: 1 year (Required)', 'State Implementation : 1 year (Required)', 'ALM: 1 year (Required)', 'Healthcare Industry: 5 years (Required)', 'Quality Assurance: 5 years (Required)', ""Bachelor's (Required)"", 'Waiting period may apply', 'No']",2020-08-08 13:54:48
Software Engineer,Apartments247.com,3.5 out of 5,"Las Vegas, NV","['Work with other members of the Apartments247 team to design, architect, and implement solutions to problems in the multihousing marketing industry.', 'Participate in peer-code reviews to give and receive feedback on code changes.', 'Experience with a high-level programming language such as Python, Go, Java or JavaScript.', 'Experience working with a RDBMS, like MySQL or PostgreSQL.', 'Knowledge of NoSQL databases, such as MongoDB or DynamoDB.', 'Comfortable working on the command line in Linux or OSX.', 'Comfortable working with REST APIs and JSON. Experience with SOAP and XML a plus!', 'Familiarity with cloud service providers, like Amazon Web Services a huge plus!', 'Experience using Git for version control. If you’ve got a GitHub, send us a link to your profile!', 'Solid computer science fundamentals, including algorithms and data structures.', 'Dental Insurance', 'Health Insurance', 'Life Insurance', 'Paid Time Off', 'Vision Insurance', 'Monday to Friday', 'web development: 1 year (Preferred)', ""Bachelor's (Preferred)"", 'United States (Required)', 'One location', 'No: Not providing sponsorship for this job', 'Detail-oriented -- quality and precision-focused', 'Team-oriented -- cooperative and collaborative', 'Open to applicants who do not have a college diploma', 'https://www.apartments247.com/', 'Waiting period may apply', 'Only full-time employees eligible', 'Temporarily due to COVID-19']",2020-08-08 13:54:48
Systems Engineer,Retail company with Matlen Silver,N/A,"Parsippany, NJ","['Deliver reusable automation solutions to improve operational consistency of FDC products', 'Technically participate in the design and delivery the of automation beyond automating the steps of delivery', 'Understand/ Reverse engineer applications, processes and infrastructure, previous experience as developer or sys admin or architecture mandatory C/C++/Java/Python etc', 'Ability to design, build and implement complex scripting solutions for automation - Puppet/Salt required', 'Be able to manage delivery without rigid supervision', 'Document implementation architecture for automation', 'Self-starter and able to work independently under general guidance', 'Experience with large global enterprise scale infrastructure and datacentres;', 'Development and/or Systems background', 'Ability to script a solution to certificate management use cases', 'Java, SQL, better yet C/C++/C#/ Python, Salt dev experience', 'Understanding Certificate management and deployment', 'Experience with System and Software architecture', 'Experience with automation and configuration management', 'Experience with large global enterprise scale infrastructure', 'Minimum BSc and/or 10 years experience in system engineering with emphasis on Scripting and coding solutions', 'Monday to Friday', 'Coding: 4 years (Required)', 'Scripting: 4 years (Required)', 'Data Center: 1 year (Required)', 'C++: 1 year (Preferred)', 'systems engineer: 1 year (Required)', 'Infrastructure: 1 year (Required)', 'Certificate Management: 1 year (Required)', 'Python: 1 year (Preferred)', 'Temporarily due to COVID-19']",2020-08-08 13:54:48
Testing Specialist,Meridian Technologies,3.7 out of 5,"Jacksonville, FL 32246","['Creates a test approach, identifying scope of testing with risk-based approach for each feature or scope of work in a project effort identifying test environments, dependencies, constraints, prioritizing test cases and scheduling time for the testing.', 'Responsible for ensuring end to end testing methodology including all appropriate documentation and requirements.', 'Sets up software and hardware in the test lab, per specs.', 'Ensures test results are accurate, thorough and appropriately documented.', 'Communicates results and coordinates logistics to the Systems Analysts, Developers, and other key IT staff and leadership as appropriate.', 'Documents problems or results inconsistent with expected results.', 'Performs quality assurance tests on all work and performs detailed analysis on test results.', 'Certifies application for release to the next testing stage or to the production environment. Generates and distributes periodic status reports for testing.', 'Sets up and executes complex scripts independently.', 'Sets up test data beds based on data matching specific test conditions.', 'Creates and executes moderately complex SQL queries.', 'Executes automated test scripts.', 'Writes/coordinates resolution of system defects. Ensures appropriate hand-offs and re-testing', 'May provide technical guidance to other IT Testing Specialists.', 'Participates in requirements gathering sessions or solicits information on incomplete requirements.', 'Participates in facilitation and coordination of user acceptance testing.', 'Design tests to aid learning and mitigate risks.', 'Work with developers to create automated tests.', 'Work with business analysts and business stakeholders to undertake exploratory testing.', 'Ensures stories contain specific acceptance test conditions which communicate objectives to both technical and non-technical stakeholders.', 'Knowledge of performance and security vulnerability testing is a plus.', 'Assist product owner in coming up with the acceptance criteria for user stories.', 'Must have strong knowledge of SDLC', 'Must have strong knowledge of STLC', 'Must have strong knowledge of Testing concepts', 'Must be able to create and execute test cases', 'Thorough understanding of the business process(s) and flows involved in the system capabilities being tested', ""Thoroughly understands As-Is and To-Be business processes to understand what's changing"", 'Ability to communicate with the business in business language and with developers in technical language', 'Must have strong PC skills and demonstrated proficiency in the MS Office Suite products', 'Experience with testing management tools:', 'Must have the ability to extract data utilizing moderately complex SQL queries', 'Ability to read logical and physical data models and understand the relationship between various tables', 'Ability to clearly identify data needs and requirements for the respective test efforts', 'Ability to execute automated test scripts as needed', 'Ability to read various system input/output files; XML, Flat, 834, 835, etc', 'Must have the ability to create unique test scenarios', 'Various Domain experience; Health Care, Financial, etc', 'Experience using Agile, Waterfall, or hybrid methodology', 'Specific tools, languages and specialty skills may vary', 'Monday to Friday', 'End to End Testing: 3 years (Required)', 'PL/SQL: 2 years (Required)', 'vendor testing & association testing: 2 years (Required)', 'Plan testing: 2 years (Required)', 'development or testing: 3 years (Required)', 'Are you a US Citizen or Green card holder? If not please do not apply.', 'Temporarily due to COVID-19']",2020-08-08 13:54:48
