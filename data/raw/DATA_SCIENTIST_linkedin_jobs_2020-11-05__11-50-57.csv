job_title,company,location,date_posted,applicants,job_text,seniority_level,employment_type,job_function,industries,date_scraped
Data Scientist,Tinder,"Los Angeles, CA",1 hour ago,Be among the first 25 applicants,"['', 'Ability to think objectively and interpret meaningful themes from quantitative and qualitative data', 'Ability to execute on complex analytics projects where you have to determine salient questions in a complex ecosystem and present action-oriented conclusions', 'Proficiency with SQL required', 'Responsibilities:', 'Integrate captured event data with other sources of customer data, such as surveys, ad publishers and app store data', ' Tremendous opportunity to seek some of the industry’s most exciting problems', '3+ years of relevant experience', ' Working with an outstanding team of creative, fun and highly motivated people', 'Ability to build constructive and effective relationships with a broad and diverse group of business partners', ' Comprehensive health coverage, competitive salary, and 401(k) match', 'Support reporting and business intelligence needs of the entire Marketing team', 'Knowledge of statistics, specifically experimental design and analysis', 'Skills Required:', 'Proficiency in Microsoft Excel and Microsoft PowerPoint', 'Perform ongoing ad-hoc analyses to evaluate the efficiency of our marketing spend, building reporting infrastructure, and assisting in making budgeting recommendations to optimize growth', 'Familiarity with common KPIs, metrics, and growth experiments', 'Build models to better understand the value and churn behavior of our users', 'Scripting skills, preferably in Python. Strong Python/NumPy/PANDAS skills a plus', 'Find the “story” in the data and communicate insights and opportunities with executive and other internal teams', ' The hustle of a startup with the impact of a global business', 'Master and own the analytical understanding of customer behavior and business performance ', 'As part of our team, you’ll enjoy:']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Junior Data Scientist,hand2mind,"Vernon Hills, IL",3 hours ago,Be among the first 25 applicants,"['', 'Provide data science support for analysis of large data sets.', 'Experience using reporting packages such as Tableau, PowerBI or Crystal Reports.', 'Excellent written and verbal communication skills', 'Scope of Responsibilities: ', 'Help with various data analysis and modeling projects.', '1 - 3 Years of Experience in data or analytics role (excluding internships)', 'Assist with the integration of both structured and unstructured data sets.', 'Bachelor’s degree in Computer Science, Statistics or related field1 - 3 Years of Experience in data or analytics role (excluding internships)Advanced Microsoft Office skillsExperience working with several the following tools: Microsoft Visual Studio, Microsoft SQL Server, Java, R, Python, SQL, C/C++. Experience using reporting packages such as Tableau, PowerBI or Crystal Reports.Applicant needs to be local to the Vernon Hills, IL area', 'Strong attention to detailStrong Analytic and critical thinking skillsExcellent written and verbal communication skillsAbility to organize and set priorities', 'Standing - up to 10% of the timeSitting - up to 90% of the timeComputer usage - up to 90% of the timeTravel - not more than 5%', 'Computer usage - up to 90% of the time', 'Monitor and manage data flow for use in future analysis', 'Experience working with several the following tools: Microsoft Visual Studio, Microsoft SQL Server, Java, R, Python, SQL, C/C++. ', 'Sitting - up to 90% of the time', 'Position Description', 'Applicant needs to be local to the Vernon Hills, IL area', 'Work as contributor, assisting cross-functional teams in answering actionable business questions.', 'Strong Analytic and critical thinking skills', 'Standing - up to 10% of the time', 'Physical Demands', 'Utilize advanced tools and computational skills to make discoveries in varying sets of data.', 'Communicate with other departments to ensure accurate details of information', 'Travel - not more than 5%', 'The Individual In This Role Will', 'Strong attention to detail', 'Advanced Microsoft Office skills', 'Ability to organize and set priorities', 'Ideal Attributes', 'Requirements/Preferences', 'Provide data science support for analysis of large data sets.Utilize advanced tools and computational skills to make discoveries in varying sets of data.Assist with the integration of both structured and unstructured data sets.Monitor and manage data flow for use in future analysisWork as contributor, assisting cross-functional teams in answering actionable business questions.Help with various data analysis and modeling projects.Communicate with other departments to ensure accurate details of information', 'Bachelor’s degree in Computer Science, Statistics or related field']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Data Scientist I,Caterpillar Inc.,"Peoria, IL",7 hours ago,Be among the first 25 applicants,"['', 'Experience with version control such as Git', 'Must be proficient with c#/.net programming language', 'Experiences with different types of database tools such as DB2 and Snowflake', 'Basic Requirements:', ""Bachelor's degree required – preferably in Bachelor's of Science in Informational Systems."", 'Product Support and Logistics Division', 'Must be proficient with MS Office', 'Minimum 2-5 years of professional experience utilizing quantitative analysis and Supply Chain knowledge', 'Description', 'Iterative, agile development style to support adapting business requirements', 'Experience with version control such as GitAbility to work on increasingly more complex assignments and will have demonstrated strong leadership, initiative, interpersonal skills, and the ability to communicate effectivelyExcellent analytical skills are essential&#12288;Ability to work independently&#12288;Must have ability to communicate effectively with team members and others in the work group, as well as other internal partners&#12288;Iterative, agile development style to support adapting business requirements', 'innovating', 'Additional Information', 'Top Candidates Will Also Have', 'one team', 'committed', 'Qualifications', 'Gather, develop, document business procedures and guidelines for defining data.', 'Experience building and maintaining ETL data pipelines and workflows such as SSIS and Snaplogic', 'Excellent analytical skills are essential&#12288;', 'Develop and deliver training guidelines for operations and product group personnel to be fully effective in both existing and future systems, visualizations, and applications.', 'Job Duties/Responsibilities May Include, But Are Not Limited To', ""Bachelor's degree required – preferably in Bachelor's of Science in Informational Systems.Minimum 2-5 years of professional experience utilizing quantitative analysis and Supply Chain knowledgeMust be proficient with MS OfficeExperience writing programs/queries with data analysis tools such as SAS, SQL, Python, Snowflake, Thoughtspot, Tableau, or AlteryxMust be proficient with c#/.net programming languageExperience building and maintaining ETL data pipelines and workflows such as SSIS and SnaplogicExperience developing dashboards in visualization tools such as Tableau or Power BiExperiences with different types of database tools such as DB2 and Snowflake"", 'Experience writing programs/queries with data analysis tools such as SAS, SQL, Python, Snowflake, Thoughtspot, Tableau, or Alteryx', 'Analyze large quantities of data from various data sets, recommend solutions, make timely decisions, and communicate effectively with internal teams.', 'Experience developing dashboards in visualization tools such as Tableau or Power Bi', 'Must have ability to communicate effectively with team members and others in the work group, as well as other internal partners&#12288;', 'Ability to work on increasingly more complex assignments and will have demonstrated strong leadership, initiative, interpersonal skills, and the ability to communicate effectively', 'Participate in transformation and improvement projects of functional support processes and maintaining high visibility to the customers’ goals to consult on process options and head off potential data and reporting problems.', 'Ability to work independently&#12288;', ' Gather, develop, document business procedures and guidelines for defining data.Develop and deliver training guidelines for operations and product group personnel to be fully effective in both existing and future systems, visualizations, and applications.Participate in transformation and improvement projects of functional support processes and maintaining high visibility to the customers’ goals to consult on process options and head off potential data and reporting problems.Provide team support for implemented solutions and analysis.Analyze large quantities of data from various data sets, recommend solutions, make timely decisions, and communicate effectively with internal teams. ', 'Provide team support for implemented solutions and analysis.']",Not Applicable,Full-time,Engineering,Construction,2020-11-05 11:32:32
Junior Data Scientist,Learning Resources,"Vernon Hills, IL",11 hours ago,27 applicants,"['', 'Provide data science support for analysis of large data sets.', 'Experience using reporting packages such as Tableau, PowerBI or Crystal Reports.', 'Excellent written and verbal communication skills', 'Scope of Responsibilities: ', 'Help with various data analysis and modeling projects.', '1 - 3 Years of Experience in data or analytics role (excluding internships)', 'Assist with the integration of both structured and unstructured data sets.', 'Bachelor’s degree in Computer Science, Statistics or related field1 - 3 Years of Experience in data or analytics role (excluding internships)Advanced Microsoft Office skillsExperience working with several the following tools: Microsoft Visual Studio, Microsoft SQL Server, Java, R, Python, SQL, C/C++. Experience using reporting packages such as Tableau, PowerBI or Crystal Reports.Applicant needs to be local to the Vernon Hills, IL area', 'Strong attention to detailStrong Analytic and critical thinking skillsExcellent written and verbal communication skillsAbility to organize and set priorities', 'Standing - up to 10% of the timeSitting - up to 90% of the timeComputer usage - up to 90% of the timeTravel - not more than 5%', 'Computer usage - up to 90% of the time', 'Monitor and manage data flow for use in future analysis', 'Experience working with several the following tools: Microsoft Visual Studio, Microsoft SQL Server, Java, R, Python, SQL, C/C++. ', 'Sitting - up to 90% of the time', 'Position Description', 'Applicant needs to be local to the Vernon Hills, IL area', 'Work as contributor, assisting cross-functional teams in answering actionable business questions.', 'Strong Analytic and critical thinking skills', 'Standing - up to 10% of the time', 'Physical Demands', 'Utilize advanced tools and computational skills to make discoveries in varying sets of data.', 'Communicate with other departments to ensure accurate details of information', 'Travel - not more than 5%', 'The Individual In This Role Will', 'Strong attention to detail', 'Advanced Microsoft Office skills', 'Ability to organize and set priorities', 'Ideal Attributes', 'Requirements/Preferences', 'Provide data science support for analysis of large data sets.Utilize advanced tools and computational skills to make discoveries in varying sets of data.Assist with the integration of both structured and unstructured data sets.Monitor and manage data flow for use in future analysisWork as contributor, assisting cross-functional teams in answering actionable business questions.Help with various data analysis and modeling projects.Communicate with other departments to ensure accurate details of information', 'Bachelor’s degree in Computer Science, Statistics or related field']",Entry level,Full-time,Engineering,Logistics and Supply Chain,2020-11-05 11:32:32
Data & Applied Scientist,Microsoft,"Atlanta, GA",3 hours ago,Be among the first 25 applicants,"['', 'Monitor and analyze protection data to uncover gaps', 'Conduct data studies, propose and implement predictive modeling experiments', 'Identify performant features and models and make them universally accessible to our team and partners across Microsoft.', 'Qualifications', 'Monitor and analyze protection data to uncover gapsIdentify performant features and models and make them universally accessible to our team and partners across Microsoft.Architect and implement ML systems to protect our customersConduct data studies, propose and implement predictive modeling experiments', 'Architect and implement ML systems to protect our customers', '1+ years of professional experience in a technical role in the areas of applied machine learning', 'Moderate coding skills. SQL or similar required.', '1 year experience in Python, and/or other statistics/ML tools.', 'Some exposure to building ML models on cloud technologies such as Azure', '1+ years of implementing and successfully deploying ML solutions at scale for real-world problems', 'PhD in a quantitative field (engineering, computer science, statistics etc.) with relevant coursework in Data Science, Machine Learning, Statistics & Deep Learning', 'Preferred', 'Responsibilities', 'Masters degree with relevant coursework toward Data Science, Statistics and Machine Learning', 'Moderate coding skills. SQL or similar required.Some exposure to building ML models on cloud technologies such as AzurePhD in a quantitative field (engineering, computer science, statistics etc.) with relevant coursework in Data Science, Machine Learning, Statistics & Deep Learning', '1+ years of professional experience in a technical role in the areas of applied machine learning1+ years of implementing and successfully deploying ML solutions at scale for real-world problems1 year experience in Python, and/or other statistics/ML tools.Masters degree with relevant coursework toward Data Science, Statistics and Machine Learning']",Not Applicable,Full-time,Other,Computer Hardware,2020-11-05 11:32:32
Data Scientist - Analytics,Spin (Ford Mobility),"San Francisco, CA",13 hours ago,29 applicants,"['About Spin', '', 'Unlimited PTO for salaried roles', 'Benefits & Perks', 'Minimum of 7+ years of relevant experience in data science or analytics role', 'A degree in a quantitative field like statistics, economics, engineering, or applied math preferred', 'Responsibilities', 'Design and analyze experiments', 'Strong oral and written communication skills, and ability to collaborate with cross-functional partners to build the business', 'Monthly cell phone bill stipend', 'Experience in R or Python and data science and visualization libraries', "" Opportunity to join a fast-growing startup and help shape and establish the company's industry leadership Competitive health benefits Unlimited PTO for salaried roles Pre-tax commuter benefits Monthly cell phone bill stipend Wellness perk for salaried roles "", 'Develop dashboards and frameworks to monitor business and product performance', ' Set business metrics that measure the health of our business and product Collaborate with operations Find opportunities for growth and efficiency Design and analyze experiments Develop dashboards and frameworks to monitor business and product performance ', 'Proficient in SQL', 'Competitive health benefits', 'Set business metrics that measure the health of our business and product', 'Pre-tax commuter benefits', 'Qualifications', 'About The Role', ""Opportunity to join a fast-growing startup and help shape and establish the company's industry leadership"", 'Wellness perk for salaried roles', ' A degree in a quantitative field like statistics, economics, engineering, or applied math preferred Minimum of 7+ years of relevant experience in data science or analytics role Proficient in SQL Experience in R or Python and data science and visualization libraries Strong oral and written communication skills, and ability to collaborate with cross-functional partners to build the business ', 'Collaborate with operations', 'Find opportunities for growth and efficiency']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Associate Data Scientist,Coursera,"Mountain View, WY",12 hours ago,31 applicants,"['', 'Demonstrating new skills and rapid learning through showcase projects and increasing responsibilities supporting the Content team', '(Marketing): Experience working with or on marketing teams(Content): Experience working in fast pacing environment with multiple cross-functional teams', '(Content) Responsibilities', 'Increasing your technical and interpersonal skills as a Data Scientist by making consistent progress through a series of online and live trainings', 'Designing and analyzing experiments to measure the impact of new marketing initiatives', 'Successful completion of IBM Data Science Professional CertificateExcellent communication skills, particularly in explaining technical concepts to non-technical audiencesStrong analytical intuition and demonstrated interest in answering business questions using dataStrong time management skills and passion for learningFoundational skills in at least one scripting language (e.g. Python)Foundational knowledge of probability and statistics', 'Preferred Qualifications', '(Content): Experience working in fast pacing environment with multiple cross-functional teams', 'Successful completion of IBM Data Science Professional Certificate', 'Demonstrating new skills and rapid learning through showcase projects and increasing responsibilities supporting the marketing team', 'Basic Qualifications', '(Marketing): Experience working with or on marketing teams', 'Designing and analyzing experiments to measure the impact of new marketing initiativesProviding impact estimates for proposed marketing initiatives to help teams prioritize the most promising projectsSupporting marketing channel teams in executing data-powered strategies, e.g. through custom audiences and lifecycle emailsIncreasing your technical and interpersonal skills as a Data Scientist by making consistent progress through a series of online and live trainingsDemonstrating new skills and rapid learning through showcase projects and increasing responsibilities supporting the marketing team', '(Content):', 'Designing and analyzing experiments to measure the impact of new initiatives in areas of Learner Experience, Contents and SkillsDesign, build, and share internal reporting for Data Scientists and cross-functional partners to identify content opportunities and drive product insights.Providing impact estimates for proposed initiatives to help teams prioritize the most promising projectsSupporting cross-functional teams (e.g., Content Strategy, Skills) in executing data-powered strategies, e.g. through custom audiences and lifecycle emailsIncreasing your technical and interpersonal skills as a Data Scientist by making consistent progress through a series of online and live trainingsDemonstrating new skills and rapid learning through showcase projects and increasing responsibilities supporting the Content team', 'Providing impact estimates for proposed initiatives to help teams prioritize the most promising projects', 'Design, build, and share internal reporting for Data Scientists and cross-functional partners to identify content opportunities and drive product insights.', 'Strong time management skills and passion for learning', 'Designing and analyzing experiments to measure the impact of new initiatives in areas of Learner Experience, Contents and Skills', '(Marketing)', '(Marketing) Responsibilities', 'Supporting marketing channel teams in executing data-powered strategies, e.g. through custom audiences and lifecycle emails', 'Foundational knowledge of probability and statistics', 'Providing impact estimates for proposed marketing initiatives to help teams prioritize the most promising projects', 'Marketing:', 'Strong analytical intuition and demonstrated interest in answering business questions using data', 'Supporting cross-functional teams (e.g., Content Strategy, Skills) in executing data-powered strategies, e.g. through custom audiences and lifecycle emails', 'Excellent communication skills, particularly in explaining technical concepts to non-technical audiences', 'Foundational skills in at least one scripting language (e.g. Python)', 'Content:']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,AMEND Consulting,"Cincinnati, OH",2 hours ago,Be among the first 25 applicants,"['', 'Education: Minimum of bachelor’s degreePreference for graduate degree in an analytics-based field such as statistics or business analyticsProficiency in analytical programming languages such as R or PythonProficiency in data management and querying via SQLHigh proficiency in all standard Microsoft products such as Word, Excel, Visio, PowerPoint, and OutlookGood command of soft skills including:', 'JOB TASKS', 'OVERVIEW', 'Education: Minimum of bachelor’s degree', 'KEY COMPETENCIES', 'Design, develop, and deliver audience training and adaption methods and materials', 'REQUIRED', 'High proficiency in all standard Microsoft products such as Word, Excel, Visio, PowerPoint, and Outlook', 'Proficiency in analytical programming languages such as R or Python', 'Create predictive and prescriptive models with the intent to aid clients in optimizing profit (price, cost, acquisition and retention), scheduling (labor, production) and forecasting', 'Articulate the What, Why and So What of model development and output', 'Development of interactive tools to allow clients to scenario plan based on modeling output', 'Create, implement and scale modeling techniques', 'Generation and communication of insights derived from modeling', 'Delegation of tasks to appropriate resources as project requirements dictate', 'Desire to build analytical competencies in others within the business', 'Ability to interface with multiple other business functions (internally and externally)', '*Applicants must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of employment Visa at this time.*', 'The Data Scientist consultant role is an incredibly exciting position in the fastest growing segment of AMEND. You will be working to solve real-world problems by designing cutting edge analytic solutions while surrounded by a team of world class talent.\xa0You will be entering an environment of explosive growth with ample opportunity for development. We are looking for predictive and prescriptive model builders who are the combination of a change agent, technical leader and passionate about transforming companies for the better.\xa0', 'RECOMMENDED', 'Good command of soft skills including:', 'Understand client operational and strategic business objectives by studying business functions across multiple industries, documenting project requirements and end user needsDefine project requirements by identifying project milestones, phases and deliverablesAct as the lead data scientist, identifying and integrating relevant datasets that can be sourced from internal and external systemsExecute project plan, report progress, identify and resolve problems and recommend further actionsDelegation of tasks to appropriate resources as project requirements dictateAnalysis of large data sets as required by projects or business necessities and presentation of findings along with recommended solutions and next stepsCreate, implement and scale modeling techniquesCreate predictive and prescriptive models with the intent to aid clients in optimizing profit (price, cost, acquisition and retention), scheduling (labor, production) and forecastingGeneration and communication of insights derived from modelingDevelopment of interactive tools to allow clients to scenario plan based on modeling outputArticulate the What, Why and So What of model development and outputDesign, develop, and deliver audience training and adaption methods and materials', 'Creativity to devise out-of-the-box solutions', 'Preference for graduate degree in an analytics-based field such as statistics or business analytics', 'Experience: Graduate Degree in Data Science related field or 3 years of experience with predictive modeling', 'Define project requirements by identifying project milestones, phases and deliverables', 'Act as the lead data scientist, identifying and integrating relevant datasets that can be sourced from internal and external systems', 'Understand client operational and strategic business objectives by studying business functions across multiple industries, documenting project requirements and end user needs', 'Curiosity to ask questions and challenge the status quo', 'Analysis of large data sets as required by projects or business necessities and presentation of findings along with recommended solutions and next steps', 'Business Understanding, Predictive Analytics and Insights Generation', 'Execute project plan, report progress, identify and resolve problems and recommend further actions', 'Proficiency in data management and querying via SQL', 'Ability to interface with multiple other business functions (internally and externally)Desire to build analytical competencies in others within the businessCuriosity to ask questions and challenge the status quoCreativity to devise out-of-the-box solutions']",Associate,Full-time,Engineering,Management Consulting,2020-11-05 11:32:32
Data Scientist- Analytics,OkCupid,"New York, NY",1 hour ago,Be among the first 25 applicants,"['', 'Basic familiarity with Machine Learning concepts', 'Extra points for:', ' Generous maternity and/or paternity leave and contributions towards fertility preservation', 'Strong analytical skills and the ability to turn unstructured problems into easily digestible analyses and conclusions', 'Own experimentation for your product team by designing and implementing AB tests and network effect tests', 'We’re looking for:', ' Paid attendance to conferences', 'Bachelor’s degree in Economics, Computer Science, Mathematics, or other related fields a plus', ' Competitive salary and full benefits, including Medical, Dental, Vision, and 401k', 'Prepare trend analysis and investigative reporting for product teams and senior management', 'About the Team:', '3+ YOE using SQL with any database', ' Discounted membership to some amazing NYC facilities including Chelsea Piers Gym', ' Company funded happy hours/events', ' Workstation and tools of your choice', ' A sunny office full of incredibly curious and friendly people', 'Partner with Product Managers and Senior leadership to recommend appropriate actions', ' Daily complimentary catered lunch from some of NYC’s top restaurants, and an endless supply of snacks & drinks', 'Ability to operate independently and proactively, we don’t just want you generating reports, we want you helping drive the business forwards', 'What’s in it for you?', '3+ YOE with at least one statistical programming language: Python, R, SAS, Julia (Python Preferred)', 'Utilize statistical modelling techniques where appropriate to drive business decisions', 'Experience with at least one BI tool (Tableau, Looker, Periscope, etc)', 'In this role, you will:', 'Previous experience analyzing behavior at an internet company, preferably in a B2C environment', 'Advanced statistical knowledge', 'Analyze company performance across Product, Marketing, Finance, and more as needed']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
DATA SCIENTIST,Gap Inc.,"San Francisco, CA",7 hours ago,74 applicants,"['', 'Synthesize findings, prepare presentations and assist in presenting findings to all levels of management', 'Merchandise discount for our brands: 50% off regular-priced merchandise at Gap, Banana Republic and Old Navy, 30% off at Outlet and 25% off at Athleta for all employees.', 'Employee stock purchase plan.*', 'Build, validate, and maintain Operations Research (OR) and/or AI( Machine Learning (ML) /Deep learning), models', 'ABOUT THE ROLE', 'WHO YOU ARE', 'Skills to collaborate with cross-functional teams and influence product and analytics roadmap', 'Proven experience in areas of optimization, statistics, machine learning, and inventory theory', 'Masters in Operations Research, Statistics, Math, Computer Science, Industrial Engineering or related field. PhD is a plus.Proven experience in areas of optimization, statistics, machine learning, and inventory theoryAbility to develop and apply analytic solutions to solve business problemsSkills to collaborate with cross-functional teams and influence product and analytics roadmapHands-on experience with data analysis, statistical, optimization and simulation packages (SQL, Python, SAS, Tensorflow, Hive, etc)', 'Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.*', 'Our brands bridge the gaps we see in the world.\u202fOld Navy democratizes style to ensure everyone\u202fhas access to quality fashion at every price point. Athleta unleashes the potential of every woman,\u202fregardless of body size, age or ethnicity. Banana\u202fRepublic believes in sustainable luxury for all. And Gap\u202finspires the world to bring individuality to modern, responsibly made\u202fessentials.\xa0', 'Work with large quantities of data in scripting languages', 'See more\xa0of the benefits we offer.', '\xa0', 'Ability to develop and apply analytic solutions to solve business problems', 'The Product Analytics Team at Gap Inc. is a research team that applies techniques from operations research and machine learning to drive business benefits for Gap Inc. and its brands.', 'Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.*', 'Medical, dental, vision and life insurance.*', 'The team’s focus is creating analytical capabilities to support product operations at Gap Inc. Areas of expertise include demand forecasting, inventory replenishment, inventory and supply chain optimization, pricing, product testing, product attributes, flexible inventory and supply chain initiatives.', '*For eligible employees', 'Build, validate, and maintain Operations Research (OR) and/or AI( Machine Learning (ML) /Deep learning), modelsWork with large quantities of data in scripting languagesSynthesize findings, prepare presentations and assist in presenting findings to all levels of managementProvide framework/methodology for measurement and feedback mechanism for modelsCollaborate within the team and outside the team to solve complex problems', 'One of the most competitive Paid Time Off plans in the industry.*', 'BENEFITS AT GAP INC.', 'Collaborate within the team and outside the team to solve complex problems', 'Merchandise discount for our brands: 50% off regular-priced merchandise at Gap, Banana Republic and Old Navy, 30% off at Outlet and 25% off at Athleta for all employees.One of the most competitive Paid Time Off plans in the industry.*Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.*Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.*Employee stock purchase plan.*Medical, dental, vision and life insurance.*See more\xa0of the benefits we offer.', 'This simple idea—that we all deserve to belong,\u202fand on our own terms—is core to who we are as a\u202fcompany and how we make decisions.\u202fOur team\xa0is made up of thousands of people across the globe who take risks, think big, and do good for our customers, communities, and the planet.\u202fReady to learn fast, create with audacity\u202fand lead boldly? Join our team.', 'ABOUT GAP INC.', 'Masters in Operations Research, Statistics, Math, Computer Science, Industrial Engineering or related field. PhD is a plus.', ""WHAT YOU'LL DO"", 'Provide framework/methodology for measurement and feedback mechanism for models', 'Gap Inc. is an equal-opportunity employer and is committed to providing a workplace free from harassment and discrimination. We are committed to recruiting, hiring, training and promoting qualified people of all backgrounds, and make all employment decisions without regard to any protected status. We have received numerous awards for our long-held commitment to equality and will continue to foster a diverse and inclusive environment of belonging. This year, we’ve been named as one of the\xa0Best Places to Work by the Humans Rights Campaign\xa0for the fourteenth consecutive year and have been included in the\xa02019 Bloomberg Gender-Equality Index\xa0for the second year in a row.', 'Hands-on experience with data analysis, statistical, optimization and simulation packages (SQL, Python, SAS, Tensorflow, Hive, etc)']",Mid-Senior level,Full-time,Supply Chain,Retail,2020-11-05 11:32:32
Data Scientist,Nintendo,"Redmond, WA",21 hours ago,84 applicants,"['', 'Transition proof of concept models into scalable productionalized solutions for consumer facing experiences', 'Expertise in causal inference preferred ', 'Passion and depth of knowledge for video games, technology, and entertainment market', 'Help educate, influence, and inspire adoption of data science best practices', 'Ability to speak and write fluent Japanese a strong plus, but not required', 'We are an equal opportunity employer of individuals with disabilities and protected veterans....valuing diversity…celebrating strengths.', 'Experience working in digital marketing, CRM, or related domain is highly desirable', '2 - 4 years of experience working in an industry setting in a data-driven centric role', 'Continuously identify new data sources; explore, consolidate unstructured and diverse data, and incorporate into analyses and models. Work with engineering colleagues to onboard data as needed', 'Support exploration of new technologies and analysis methods to identify growth / efficiency opportunities ', 'Experience utilizing cloud computing platforms to handle Big Data preferred', '2 - 4 years of experience working in an industry setting in a data-driven centric role1+ year hands-on experience building predictive models on real-world dataSolid understanding in statistical modeling (regression, sampling, MLE, etc.)Proficient with utilizing statistical learning algorithms from open source software (e.g. R, Python, etc.); should be able to write own code as needed to customize solutionsComfortable getting and preparing data; this includes using SQL as well as dealing with unstructured data that might require calling APIs, or writing custom scriptsTake ownership of work and operate under minimal supervisionExperience working in digital marketing, CRM, or related domain is highly desirablePassion and depth of knowledge for video games, technology, and entertainment marketExperience utilizing cloud computing platforms to handle Big Data preferredExpertise in causal inference preferred Ability to speak and write fluent Japanese a strong plus, but not requiredGraduate degree (or equivalent knowledge) in a quantitative field requiredMasters or PhD preferred', 'Comfortable getting and preparing data; this includes using SQL as well as dealing with unstructured data that might require calling APIs, or writing custom scripts', 'Masters or PhD preferred', 'Nintendo of America Inc.', 'Proficient with utilizing statistical learning algorithms from open source software (e.g. R, Python, etc.); should be able to write own code as needed to customize solutions', 'Gain deep insight into player behavior and business impact; present findings to internal stakeholders', 'Develop and refine models to predict consumer behavior and help prescribe actions to improve forecasting, personalization, customer engagement, and monetization ', 'Interacts with product, marketing, and service teams to identify questions and issues for data analysis and experiments.', 'Graduate degree (or equivalent knowledge) in a quantitative field required', '1+ year hands-on experience building predictive models on real-world data', 'Summary Of Requirements', 'Take ownership of work and operate under minimal supervision', 'Solid understanding in statistical modeling (regression, sampling, MLE, etc.)', 'Develop and refine models to predict consumer behavior and help prescribe actions to improve forecasting, personalization, customer engagement, and monetization Continuously identify new data sources; explore, consolidate unstructured and diverse data, and incorporate into analyses and models. Work with engineering colleagues to onboard data as neededTransition proof of concept models into scalable productionalized solutions for consumer facing experiencesGain deep insight into player behavior and business impact; present findings to internal stakeholdersSupport exploration of new technologies and analysis methods to identify growth / efficiency opportunities Interacts with product, marketing, and service teams to identify questions and issues for data analysis and experiments.Help educate, influence, and inspire adoption of data science best practices', 'Description Of Duties']",Not Applicable,Full-time,Business Development,Computer Games,2020-11-05 11:32:32
Data Scientist,Analytic Recruiting Inc.,Cincinnati Metropolitan Area,2 hours ago,Be among the first 25 applicants,"['REQUIREMENTS ', 'REQUIREMENTS', 'Bachelor’s degree in a quantitative field such as math, physics, computer science, or economics. Advanced degree preferred. Knowledge of and experience with machine learning and model development using SAS, R, Python, etc. coupled with the ability to work with large, complex data sets Prior experience in the P&C or life insurance industry preferred but not required Strong communication, interpersonal and organizational skills and the ability to work with stakeholders across the organization', 'Data Scientist with strong proficiency building machine learning algorithms, predictive models using SAS, R, Python, etc. sought by Cincinnati-based insurance company to join its newly created Advanced Analytics and Innovation team reporting to the Director. This a great opportunity to work on cutting-edge analytic solutions to solve problems across the enterprise ranging from agency relationship, marketing and risk selection, pricing, underwriting, loss control and risk mitigation, service and operation, retention, claims, and fraud. Ideal should be highly proficient with statistical tools such as SAS, Python, R, etc. and be able to work collaboratively across the organization. Prior insurance experience is not required but is helpful ', 'Bachelor’s degree in a quantitative field such as math, physics, computer science, or economics. Advanced degree preferred. ', 'Knowledge of and experience with machine learning and model development using SAS, R, Python, etc. coupled with the ability to work with large, complex data sets ', 'Prior experience in the P&C or life insurance industry preferred but not required ', 'Strong communication, interpersonal and organizational skills and the ability to work with stakeholders across the organization', ' ']",Mid-Senior level,Full-time,Analyst,Financial Services,2020-11-05 11:32:32
Data Scientist,Datadog,"New York, NY",16 minutes ago,Be among the first 25 applicants,"['', 'You can explain complex ideas and algorithms in understandable ways.', ' Present the latest academic research papers to your team. Research and benchmark the latest algorithms that can be used for our particular use-cases. Apply machine learning algorithms and statistical techniques to build new product features. Deploy a new feature to production, instantly affecting customers with your work. Mentor other data scientists on your team. Explore and find meaning in extremely high volumes of data. Investigate and fix a production issue from a service your team owns. ', 'About Datadog', 'You have significant experience applying machine learning to real business problems.', 'Apply machine learning algorithms and statistical techniques to build new product features.', 'Present the latest academic research papers to your team.', 'You want to work in a fast, high-growth startup environment and thrive on autonomy.', 'Explore and find meaning in extremely high volumes of data.', ' You have 2 + years professional experience You are fluent with SQL / relational algebra. You have mastered working with data in a language such as Python, R, or Julia. You’ve done data science at high scale with tools like Hadoop and Spark. You have backend programming experience in one or more languages. You have significant experience applying machine learning to real business problems. You want to work in a fast, high-growth startup environment and thrive on autonomy. You care about code simplicity and performance. You have a BS/MS/PhD in a scientific field or equivalent experience. You can explain complex ideas and algorithms in understandable ways. ', 'You have 2 + years professional experience', 'You Will', 'Research and benchmark the latest algorithms that can be used for our particular use-cases.', ' You’ve written production data pipelines. You’re familiar with time series analysis.', 'You have backend programming experience in one or more languages.', 'You’re familiar with time series analysis.', 'Requirements', 'Deploy a new feature to production, instantly affecting customers with your work.', 'The Opportunity', 'You have a BS/MS/PhD in a scientific field or equivalent experience.', 'You are fluent with SQL / relational algebra.', 'Mentor other data scientists on your team.', 'Investigate and fix a production issue from a service your team owns.', 'You’ve written production data pipelines.', 'You care about code simplicity and performance.', 'You have mastered working with data in a language such as Python, R, or Julia.', 'Bonus Points', 'You’ve done data science at high scale with tools like Hadoop and Spark.']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,FootBridge Consulting,"Acton, MA",13 hours ago,Be among the first 25 applicants,"['', 'Job Description', 'Experience with Salesforce.com, Marketing Cloud, and a knowledge of conversion funnel using SFDC', 'The Right Candidate Will Possess', 'Ability to write and run SQL database queries', 'Scripting languages such as Python, R or MATLAB', 'Experience with BI tools such as Tableau or Spotfire a must', ""Experience taking raw data and transforming it into visualization/insights for SME' s"", 'Experience in data wrangling, data cleaning, and machine learning', "" 3+ years of experience serving as a Data Scientist/BI Developer Experience taking raw data and transforming it into visualization/insights for SME' s Experience with Salesforce.com, Marketing Cloud, and a knowledge of conversion funnel using SFDC Experience with BI tools such as Tableau or Spotfire a must Scripting languages such as Python, R or MATLAB Ability to write and run SQL database queries Experience in data wrangling, data cleaning, and machine learning "", 'Data Scientist', '3+ years of experience serving as a Data Scientist/BI Developer']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,ZenPoint Solutions LLC,"Alexandria, VA",16 hours ago,78 applicants,"['The applicant will help perform analysis on large unstructured data sets (billions of documents) to provide insight into the data as well as to create production usable models to perform tasks such as topic modeling, entity extraction, entity linking, clustering, classification, etc. The individual should be willing to work in a team environment and be open to using tools and libraries needed to get models and analysis into production.  ', 'Experience with data transport and transformation APIs and technologies such as JSON and REST ', 'Location: Alexandria, VA.  ', 'Ability to make discoveries in the world of big data Ability to utilize advanced tools and computational skills to interpret, connect, predict and make discoveries in complex data and deliver recommendations for business and analytic decisions Experience with Python required, experience with .NET/C# is helpful Experience with data transport and transformation APIs and technologies such as JSON and REST Experience with entity extraction and conceptual search technologies such as LSI, LDA, NLP, NER, NEL, etc Experience with machine learning, algorithm analysis, and data clustering Experience with ML.NET, ONNX, PyTorch, TensorFlow, etc. is a plus, but not required', 'Experience with ML.NET, ONNX, PyTorch, TensorFlow, etc. is a plus, but not required', 'Ability to utilize advanced tools and computational skills to interpret, connect, predict and make discoveries in complex data and deliver recommendations for business and analytic decisions ', 'Ability to make discoveries in the world of big data ', 'Clearance: Applicants must be US citizens and able to obtain at least a Secret clearance. The candidate selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. ', 'Experience with Python required, experience with .NET/C# is helpful ', 'Required qualifications to be successful in this role: ', 'Experience with entity extraction and conceptual search technologies such as LSI, LDA, NLP, NER, NEL, etc ', ' ', 'Experience with machine learning, algorithm analysis, and data clustering ']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Brunel,"Houston, TX",2 hours ago,Be among the first 25 applicants,"['Collaborating with model developers to implement and deploy scalable solutions. ', 'Responsibilities:', 'Requirements:', '\xa0 ', 'What We Offer:', 'Conducting advanced statistical analysis to provide actionable insights, identify trends, and measure performance. ', '\xa0', 'Evidence of well-developed written and verbal communications skills. Ability to communicate technical contents to non-technical audience. ', 'Attitude to thrive in a fun, fast-paced start-up like environment. ', 'Deep knowledge of machine learning, statistics, optimization or related field as evident through a tertiary higher education degree and/or several years of industry experience. ', '5-7 years’ experience in a statistical and/or data science role with emphasis on solving large-scale industrial size problems. Bachelor’s degree in quantitative field like Statistics, Computer Science, Engineering, Mathematics or related field required.  Advanced degree is a strong plus. Deep knowledge of machine learning, statistics, optimization or related field as evident through a tertiary higher education degree and/or several years of industry experience. Experience working with large data sets, simulation/ optimization and distributed computing tools. Experience in working with large datasets, relational databases (SQL), and distributed systems (Hadoop, Hive). Experience Proficiency in R, Python, C++, Java and/or SAS; additional knowledge of other statistical software (SPSS, RapidMiner, etc.) is helpful. Advanced knowledge of statistical techniques, data mining, machine learning (regression, decision trees, clustering, random forests, generalized linear models, etc.) Excellent scientific computing skills, including creativity in the design and development of efficient algorithms. Experience or interest in working in a team environment, with ability to manage competing deadlines. Evidence of well-developed written and verbal communications skills. Ability to communicate technical contents to non-technical audience. Attitude to thrive in a fun, fast-paced start-up like environment. ', 'Brunel has a reputation for working with some of the best in the business. That’s what we continually strive for. Over 45 years, we’ve created a global network of interesting clients and talented individuals working together through a vast array of services. Join us today.', 'Understanding business problems and designing end-to-end analytics use cases. Developing complex models and algorithms that drive innovation throughout the organization. This may include improving on-time performance, network planning, etc. Conducting advanced statistical analysis to provide actionable insights, identify trends, and measure performance. Collaborating with model developers to implement and deploy scalable solutions. Collaborating with product software teams to ensure model functionality using cloud solutions and monitoring the quality and effectiveness of the models in operations. Providing thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders. ', 'Understanding business problems and designing end-to-end analytics use cases. ', '5-7 years’ experience in a statistical and/or data science role with emphasis on solving large-scale industrial size problems. ', 'About Us:', 'Providing thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders. ', ' ', 'Experience in working with large datasets, relational databases (SQL), and distributed systems (Hadoop, Hive). ', 'Excellent scientific computing skills, including creativity in the design and development of efficient algorithms. ', 'Experience Proficiency in R, Python, C++, Java and/or SAS; additional knowledge of other statistical software (SPSS, RapidMiner, etc.) is helpful. ', 'We’re currently hiring an experienced Data Scientist to join our client’s new team within their organization. The Data Scientist will be critical in the successful development and implementation of machine learning- and model-based digital solutions and products, as model-based decision making is at the heart of the Digital Factory solutions.  ', 'Experience or interest in working in a team environment, with ability to manage competing deadlines. ', 'What We Offer: ', 'Experience working with large data sets, simulation/ optimization and distributed computing tools. ', 'Bachelor’s degree in quantitative field like Statistics, Computer Science, Engineering, Mathematics or related field required.  Advanced degree is a strong plus. ', 'Advanced knowledge of statistical techniques, data mining, machine learning (regression, decision trees, clustering, random forests, generalized linear models, etc.) ', 'About Us: ', 'Responsibilities: ', 'Why work with Brunel? We are proud to offer exciting career opportunities from over 100 offices globally in 42 countries. Advancing your career takes time and effort – let us match you to your ideal position. ', ' Requirements:  ', 'Developing complex models and algorithms that drive innovation throughout the organization. This may include improving on-time performance, network planning, etc. ', 'Collaborating with product software teams to ensure model functionality using cloud solutions and monitoring the quality and effectiveness of the models in operations. ']",Mid-Senior level,Full-time,Information Technology,Oil & Energy,2020-11-05 11:32:32
Associate Data Scientist,Insulet Corporation,"Acton, MA",9 hours ago,Be among the first 25 applicants,"['', 'Goal-driven mentalityExperience in one or more analytic software tools, such as Python, R, Matlab, PySpark.Demonstrated proficiency in SQL and one or more relational databases, such as Oracle, Teradata, Microsoft SQL Server, etcExperience in MongoDB or analyzing data from non-relational sources is a plus.Experience in Business Intelligence tools, such as Tableau, Spotfire, Cognos.Demonstrated knowledge of software engineering principles and practices.Ability to work independently without detailed guidance, while maintaining effective communications with leaders and stakeholders.Ability to communicate effectively and document objectives and procedures.', 'Clearly communicate findings to a broad audience, in relation to business objectives.', '0-2 years of work experience on machine learning, artificial intelligence, or statistical inferences.', 'Experience in MongoDB or analyzing data from non-relational sources is a plus.', 'Responsibilities', 'Work with IT and cross functional teams to identify data sources, design data ingestion, clean up, and pre-processing scripts as needed.Leverage cloud computing and automation technologies for machine learning and analytics pipelines, such as Azure, AWS, GCP, etc.Explore data patterns using existing data science tools and self-created programs.Perform statistical analysis, predictive modeling, and generate automated reporting as required.Support software V&V and IQ/OQ/PQ effortsClearly communicate findings to a broad audience, in relation to business objectives.Assist in training other teams in usage of analytics tools and best practicesPerforms other duties as required.', 'Goal-driven mentality', 'Assist in training other teams in usage of analytics tools and best practices', 'Bachelors or Master’s degree in Mathematics, Computer Science, Electrical and Computer Engineering, or a closely related field is required.', 'Performs other duties as required.', 'Explore data patterns using existing data science tools and self-created programs.', 'Manager/Supervisor: ', 'Demonstrated proficiency in SQL and one or more relational databases, such as Oracle, Teradata, Microsoft SQL Server, etc', 'Ability to communicate effectively and document objectives and procedures.', 'Position Overview', 'Support software V&V and IQ/OQ/PQ efforts', 'Skills/Competencies', 'Experiences in manufacturing, medical device, and/or healthcare industries is desirable.', 'Bachelors or Master’s degree in Mathematics, Computer Science, Electrical and Computer Engineering, or a closely related field is required.0-2 years of work experience on machine learning, artificial intelligence, or statistical inferences.Experiences in manufacturing, medical device, and/or healthcare industries is desirable.', 'Perform statistical analysis, predictive modeling, and generate automated reporting as required.', 'Ability to work independently without detailed guidance, while maintaining effective communications with leaders and stakeholders.', 'Demonstrated knowledge of software engineering principles and practices.', 'Leverage cloud computing and automation technologies for machine learning and analytics pipelines, such as Azure, AWS, GCP, etc.', 'FLSA Status: ', 'Experience in one or more analytic software tools, such as Python, R, Matlab, PySpark.', 'Education And Experience', 'Job Title: ', 'Experience in Business Intelligence tools, such as Tableau, Spotfire, Cognos.', 'Work with IT and cross functional teams to identify data sources, design data ingestion, clean up, and pre-processing scripts as needed.', 'Department: ', 'SOP Group: ']",Entry level,Full-time,Engineering,Medical Devices,2020-11-05 11:32:32
Staff Data Scientist - Commerce ,LinkedIn,"Sunnyvale, CA",15 hours ago,105 applicants,[''],Not Applicable,Full-time,Analyst,Internet,2020-11-05 11:32:32
Data Scientist - 100% Remote Available,Wiley Job Network,"Bulverde, TX",14 hours ago,Be among the first 25 applicants,"['', 'Preferred Requirements', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree."", 'Relocation', 'Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions.', 'Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.', 'Works with IT to research architecture for new products, services, and features.', ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization."", 'Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.', 'Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.', 'Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.', 'Develops algorithms and supporting code such that research efforts are based on the highest quality data.', 'Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required.', 'Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree.4 or more years of related experience and accountability for complex tasks and/or projects required.Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required."", 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.', '4 or more years of related experience and accountability for complex tasks and/or projects required.', ""Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation."", ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization.Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation.Works with IT to research architecture for new products, services, and features.Develops algorithms and supporting code such that research efforts are based on the highest quality data.Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions."", 'available', 'Minimum Requirements', 'Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).', 'PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).', 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).', 'Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.', 'Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).']",Entry level,Full-time,Engineering,Higher Education,2020-11-05 11:32:32
Data Scientist,CGN Global,"Chicago, IL",2 hours ago,Be among the first 25 applicants,"['', 'Financial analysis and business case creation including market opportunity, investments, ROI, NPV, phased roadmap, and sensitivity analysis', 'Minimum 5 years in a leadership role', 'Create the culture and capabilities needed to drive change, with the understanding that people transformation is the most essential priority', 'Job Responsibilities:', '*This position is open to all locations nationwide. Applicants do not need to be in the Chicago area. Ideal candidates will be experienced and compatible with a consulting lifestyle, and be flexible to travel as needed. Travel could be up to 100%.', 'Experience developing financial business cases', '5+ years of relevant professional experience', 'Design, develop, and deploy advanced analytics solutions, including predictive and prescriptive modeling, to enhance customer experience, revenue generation, and other business outcomes', '\xa0', 'professional development', 'Education & Experience (Qualifications):', 'Collaborate directly with clients to frame, structure, analyze, and solve business problems for profitable growth, efficient operations, and new business models', 'Coordinate with different functional teams to implement models and monitor outcomes', 'Proven experience in Project Management', 'Experience in digital strategy and execution preferred', ""Bachelors or Master's degree in Business Analytics, Data Science, Statistics, Mathematics, Digital Strategy, Computer Science, Finance, Economics or related degree. Master’s degree preferred"", 'Excellent written and verbal communication and presentation skills', 'Ability to think and work independently, solve problems, and recommendations', 'Skilled in framing, structuring, analyzing, and solving business problems using data', 'We are actively recruiting for a Senior Consultant who specializes in Data Science who has the drive and desire to join a growing team and be a valuable member of this multi-dimensional organization. We look for people who strive for professional success in a diverse, entrepreneurial culture, that provides the flexibility to navigate a career path tailored to your talents and interests. We value\xa0professional development\xa0and continued learning, keeping you at the\xa0cutting edge\xa0of your field.', 'Obtain market and competitive intelligence, generate insights and shape growth strategy', 'Experience in growth strategy, market and competitive intelligence, including primary interviews, is a big plus', 'cutting edge\xa0', 'Work with stakeholders across different functions of the organization to identify opportunities for leveraging company data to drive business performance', 'Strong experience using statistical computer languages (R, Python, etc.) to manipulate data and draw insights from large data sets', 'Collaborate directly with clients to frame, structure, analyze, and solve business problems for profitable growth, efficient operations, and new business modelsDesign, develop, and deploy advanced analytics solutions, including predictive and prescriptive modeling, to enhance customer experience, revenue generation, and other business outcomesObtain market and competitive intelligence, generate insights and shape growth strategyFinancial analysis and business case creation including market opportunity, investments, ROI, NPV, phased roadmap, and sensitivity analysisWork with stakeholders across different functions of the organization to identify opportunities for leveraging company data to drive business performanceCoordinate with different functional teams to implement models and monitor outcomesCreate the culture and capabilities needed to drive change, with the understanding that people transformation is the most essential priority', 'Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications', ""Bachelors or Master's degree in Business Analytics, Data Science, Statistics, Mathematics, Digital Strategy, Computer Science, Finance, Economics or related degree. Master’s degree preferred5+ years of relevant professional experienceMinimum 5 years in a leadership roleSkilled in framing, structuring, analyzing, and solving business problems using dataStrong experience using statistical computer languages (R, Python, etc.) to manipulate data and draw insights from large data setsKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applicationsExperience developing financial business casesExcellent written and verbal communication and presentation skillsAbility to think and work independently, solve problems, and recommendationsProven experience in Project ManagementExperience in digital strategy and execution preferredExperience in growth strategy, market and competitive intelligence, including primary interviews, is a big plus""]",Associate,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
Data Scientist,My3Tech Inc,"Pierre, SD",,N/A,"['', 'Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)', '\xa0', 'Analyze raw data: assessing quality, cleansing, structuring for downstream processing ', 'Qualifications', 'Collaborate with engineering team to bring analytical prototypes to production ', ""Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.) At least 1 - 2 years' of experience in quantitative analytics or data modeling Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms Fluency in a programming language (Python, C,C++, Java, SQL) Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)"", 'Fluency in a programming language (Python, C,C++, Java, SQL) ', 'Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms ', ""The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\xa0"", ""At least 1 - 2 years' of experience in quantitative analytics or data modeling "", 'Design accurate and scalable prediction algorithms ', 'Analyze raw data: assessing quality, cleansing, structuring for downstream processing Design accurate and scalable prediction algorithms Collaborate with engineering team to bring analytical prototypes to production Generate actionable insights for business improvements', 'Responsibilities', 'Generate actionable insights for business improvements', ""Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.) ""]",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist, Product",Splice,"New York, NY",13 hours ago,92 applicants,"['', 'Hands-on experience with self-service product-analytics tools (e.g., Looker, Mixpanel, Amplitude, Heap).', 'Exposure to data sets used by Product teams. Chiefly, large-scale event data (e.g., Mixpanel, Segment, Snowplow, server logs) and normalized transactional databases (e.g., e-commerce and subscription datasets).', 'Additional Comments', 'Splice is an equal opportunity employer, committed to diversity and inclusion. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age.', ""Skills We're Looking For"", 'Training in statistics, econometrics, or machine learning, with plenty of real-world experience applying these methodologies.', 'Equal Opportunity Employer:', 'e.g.', 'About The Role', 'Regular usage of a programming language typically used for statistical analysis and machine learning (ideally Python). ', 'Tooling expectations', 'Strong experience with analytical SQL (ideally BigQuery, Snowflake, or a similar MPP data-warehouse technology).', ' Regular usage of a programming language typically used for statistical analysis and machine learning (ideally Python).  Strong experience with analytical SQL (ideally BigQuery, Snowflake, or a similar MPP data-warehouse technology). Hands-on experience with self-service product-analytics tools (e.g., Looker, Mixpanel, Amplitude, Heap). Training in statistics, econometrics, or machine learning, with plenty of real-world experience applying these methodologies. Exposure to data sets used by Product teams. Chiefly, large-scale event data (e.g., Mixpanel, Segment, Snowplow, server logs) and normalized transactional databases (e.g., e-commerce and subscription datasets). ']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Data Scientist (remote),deepwatch,"Denver, CO",18 hours ago,54 applicants,"['', 'Solving difficult data problems while embracing cyber security challenges with open armsGathering and processing data at scale, writing scripts and queries, and building and calling APIsVisualize threat signal data and uncover how bad actors use security vulnerabilities, malware, and patterns to spread across networks and drive analytic development to build libraries for persistent detectionDrive the development of Machine Learning use cases to detect malicious activity in customer environments with regular content updatesProvide documentation to Threat Hunt, Research and Analyst teams around data analytics and mathematical decisions, with actionable workflows for threat investigation of ML alertsEnsure data quality and normalization throughout all stages of acquisition and processingClean, analyze and select data to achieve goals that create desired security outcomes for deepwatch customersBuild models that elevate the customer experience and track value of security outcomes for deepwatch customers over timeCollaborate with colleagues from Product, Delivery, Content, and Threat Hunting teamsPresent proposals and results in a clear manner backed by data and coupled with actionable conclusions that drive analytics, content libraries, and automation outcomesWork with engineers to develop efficient data analysis and data modeling infrastructure', ""Master's degree or PhD in relevant field(s) such as computer science, mathematics, or data scienceHistory of diving into data to discover hidden patterns and of conducting error/deviation analysisAbility to develop both experimental and analytical plans for data modeling processes, use of scaling baselines (trends)Strong ability to accurately determine cause and effect relationshipsUnderstands relevant statistical measures such as mathematical modeling, confidence intervals, significance of error measurements, development and evaluation data setsAn ability to work successfully across a globally distributed team and geographical boundaries to deliver joint initiatives"", '10 Company Holidays', 'Gathering and processing data at scale, writing scripts and queries, and building and calling APIs', 'History of diving into data to discover hidden patterns and of conducting error/deviation analysis', ""Bachelor's Degree with an emphasis in Data Science or related field such as Mathematics or Computer Science2+ years-experience with various data analysis and visualization toolsAWS/Azure/Google Cloud data engineering experienceProficiency in Python and other programming / scripting languagesExperience with various machine learning techniques and parameters that affect technique/model outputs and performanceDeep understanding of machine learning techniques and algorithms, such as Random Forests, Gradient Boosting, Ridge/Lasso, SVM, time series techniques et. al.Exceptional numerical and statistical ability, with excitement for applying analytics to client challenges and significant experience using analytic / database software and languages such as SAS, SQL, SPSS, R, Python, et. al.Experience with analytics programming languages (Python, Ruby, Shell) and automation tools (Ansible, Chef, Puppet etc.)Exemplified critical thinking and creative problem solving skillsCompetency with common data science toolkits, such as NumPy, pandas, sparkML, scikitLearn, et. al.Capable of leading and executing on data acquisition, cleansing, and storage for individual initiativesWilling to tackle big problems that have unknown solutions at the outsetStrong oral and written communication skills, including the ability to communicate effectively to non-technical audiencesTeam player with a passion for coaching colleagues and customers in the areas of data science"", '401k retirement plan with employer match', 'Willing to tackle big problems that have unknown solutions at the outset', 'A highly collaborative environment with very bright minds and inquisitive thinking', 'Competency with common data science toolkits, such as NumPy, pandas, sparkML, scikitLearn, et. al.', 'Company paid Life Insurance, Short Term Disability and Long Term Disability', 'Attractive referral bonus program', 'Significant annual allowance per employee for Professional Development', 'Responsibilities', 'Strong ability to accurately determine cause and effect relationships', 'An ability to work successfully across a globally distributed team and geographical boundaries to deliver joint initiatives', 'Description', 'Exemplified critical thinking and creative problem solving skills', 'Capable of leading and executing on data acquisition, cleansing, and storage for individual initiatives', 'Career paths and the opportunity to do cool and different things as our growth continues', 'Ensure data quality and normalization throughout all stages of acquisition and processing', 'Deep understanding of machine learning techniques and algorithms, such as Random Forests, Gradient Boosting, Ridge/Lasso, SVM, time series techniques et. al.', 'Exceptional numerical and statistical ability, with excitement for applying analytics to client challenges and significant experience using analytic / database software and languages such as SAS, SQL, SPSS, R, Python, et. al.', 'deepwatch is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, marital status, sexual orientation, gender identity, genetic information, protected veteran status, or any other characteristic protected by law. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.', 'Visualize threat signal data and uncover how bad actors use security vulnerabilities, malware, and patterns to spread across networks and drive analytic development to build libraries for persistent detection', 'A highly collaborative environment with very bright minds and inquisitive thinkingAwesome benefits - we pay a significant portion of our employees’ medical and dental premiums (100% for the HDHP plan) and a very generous portion for dependentsFSA (medical and dependent) and HSA with employer contributionCompany paid Life Insurance, Short Term Disability and Long Term Disability401k retirement plan with employer matchPaid Time Off (PTO)10 Company HolidaysPaid time off for votingAs a fully remote company, we offer the responsible balancing of your time between work & lifeAll employees are paid a generous mobile phone and home internet allowanceApple productsAttractive referral bonus programCareer paths and the opportunity to do cool and different things as our growth continuesSignificant annual allowance per employee for Professional Development', 'Build models that elevate the customer experience and track value of security outcomes for deepwatch customers over time', 'Understands relevant statistical measures such as mathematical modeling, confidence intervals, significance of error measurements, development and evaluation data sets', 'Work with engineers to develop efficient data analysis and data modeling infrastructure', 'Required Experience, Skills and Knowledge', 'Paid Time Off (PTO)', 'Experience with various machine learning techniques and parameters that affect technique/model outputs and performance', 'Awesome benefits - we pay a significant portion of our employees’ medical and dental premiums (100% for the HDHP plan) and a very generous portion for dependents', 'Clean, analyze and select data to achieve goals that create desired security outcomes for deepwatch customers', 'Present proposals and results in a clear manner backed by data and coupled with actionable conclusions that drive analytics, content libraries, and automation outcomes', 'deepwatch Offers', 'Strong oral and written communication skills, including the ability to communicate effectively to non-technical audiences', 'As a fully remote company, we offer the responsible balancing of your time between work & life', 'Collaborate with colleagues from Product, Delivery, Content, and Threat Hunting teams', 'Requirements', 'Preferred Experience, Skills And Knowledge', 'FSA (medical and dependent) and HSA with employer contribution', 'Ability to develop both experimental and analytical plans for data modeling processes, use of scaling baselines (trends)', 'Who We Are', 'Data Scientist', 'Provide documentation to Threat Hunt, Research and Analyst teams around data analytics and mathematical decisions, with actionable workflows for threat investigation of ML alerts', 'Proficiency in Python and other programming / scripting languages', 'Drive the development of Machine Learning use cases to detect malicious activity in customer environments with regular content updates', 'Equal Opportunity Employer', 'Experience with analytics programming languages (Python, Ruby, Shell) and automation tools (Ansible, Chef, Puppet etc.)', 'Apple products', ""Master's degree or PhD in relevant field(s) such as computer science, mathematics, or data science"", '2+ years-experience with various data analysis and visualization tools', 'Solving difficult data problems while embracing cyber security challenges with open arms', 'Team player with a passion for coaching colleagues and customers in the areas of data science', ""Bachelor's Degree with an emphasis in Data Science or related field such as Mathematics or Computer Science"", 'Paid time off for voting', 'AWS/Azure/Google Cloud data engineering experience', 'All employees are paid a generous mobile phone and home internet allowance']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Asana,"San Francisco, CA",18 hours ago,60 applicants,"['', ' Proficiency with relational data modeling and SQL ', ' 3+ years of experience in applying data science techniques to drive technical product development and decision-making ', 'About Us', ' Strong technical background in computer science, statistics, math, information science, or another quantitative field ', ""What You'll Achieve"", ' Experience with distributed data processing systems (e.g. Spark, Redshift) ', ' Building models to predict the growth trajectory of different customer segments ', ' Investigating high-level questions like “What are the collaborative patterns of the most successful teams using Asana?” ', ' Expertise in statistical methods and experimental design and analysis ', ' Experience with measurement techniques for search ranking/relevance/quality', ' Designing and analyzing experiments to measure the impact of new product features ', ' Fluency in at least one modern language useful for data processing (e.g. Python, Scala) ', 'Data Scientist', 'About You', ' Adding new metrics and aggregations to our data warehouse to make new classes of questions answerable ', '  Designing and analyzing experiments to measure the impact of new product features   Investigating high-level questions like “What are the collaborative patterns of the most successful teams using Asana?”   Adding new metrics and aggregations to our data warehouse to make new classes of questions answerable   Building models to predict the growth trajectory of different customer segments  ', ' Bachelor Degree in Computer Science, Math, Statistics, Engineering, a related quantitative field, or equivalent experience.  3+ years of experience in applying data science techniques to drive technical product development and decision-making   Strong technical background in computer science, statistics, math, information science, or another quantitative field   Fluency in at least one modern language useful for data processing (e.g. Python, Scala)   Proficiency with relational data modeling and SQL   Expertise in statistical methods and experimental design and analysis   Experience with measurement techniques for search ranking/relevance/quality  Experience with distributed data processing systems (e.g. Spark, Redshift)   Background in advanced statistical modeling (e.g. GLM, mixed effects) and/or machine learning  ', 'Bachelor Degree in Computer Science, Math, Statistics, Engineering, a related quantitative field, or equivalent experience.', ' Background in advanced statistical modeling (e.g. GLM, mixed effects) and/or machine learning ']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Booz Allen Hamilton,"Annapolis Junction, MD",9 hours ago,Be among the first 25 applicants,"['', 'Ability to program in modern scripting languages, including Python, R, and JavaScript', 'Experience with Natural Language Processing techniques', 'Build Your Career', 'Experience with machine learning and natural language processing', 'BA or BS degree', 'Ability to obtain a security clearance', 'Experience with rapid prototyping machine learning models', 'You Have', 'The Challenge', 'MA or MS degree', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'Ability to discern between various machine learning approaches', 'Knowledge of Agile software development', 'Nice If You Have', 'Experience with machine learning and natural language processingExperience with Natural Language Processing techniquesKnowledge of Agile software developmentAbility to program in modern scripting languages, including Python, R, and JavaScriptAbility to discern between various machine learning approachesAbility to obtain a security clearanceBA or BS degree', 'Secret clearance', 'participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunkchange the world with the Data Science Bowl—the world’s premier data science for social good competitionparticipate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Job Number: R0094638', 'Clearance', 'Experience with rapid prototyping machine learning modelsKnowledge of DevOps, API design, and other modern software delivery approachesSecret clearanceMA or MS degree', 'Knowledge of DevOps, API design, and other modern software delivery approaches', 'change the world with the Data Science Bowl—the world’s premier data science for social good competition']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Confidential,"Hartford, CT",17 hours ago,35 applicants,"['', '• Linux Environment background', '• Experience with machine learning.', 'Location: Hartford CT / Remote', 'One of our clients is looking for:\xa0\xa0', '\xa0', '• Strong communication skills and customer management skills.\xa0\xa0', '• Significant hands-on industry experience in data science\xa0\xa0', '• Data Sourcing, Data Manipulation, Data Pipeline, strong data analytics background\xa0', 'Greymattertech, Corp is a leading boutique consulting & Staffing organization at the intersection of Industry, Technology and all things digital.\xa0\xa0', '• Perform large-scale data analysis on cloud-based data platforms\xa0', '• Expertise in AWS or Google cloud preferred.', 'Data Scientist', 'Job Description:\xa0', '• Expertise in Python and associated data analysis libraries.\xa0', '• Expertise in SQL/databases and/or Hadoop/Spark.', '• Experience in one or more of: natural language processing, deep learning, geospatial, or time series analysis.', 'Duration: 6-12 months', '• GIT & Jenkins knowledge']",Executive,Contract,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Hire Velocity,"Vienna, VA",9 hours ago,Be among the first 25 applicants,"['', 'Experience Level', 'Experience working in a cloud based environment', 'SQL Database experience.', 'Leverage technical and analytical expertise to explore and examine data from multiple disparate sources with the goal of discovering patterns and previously hidden insights, providing process efficiencies, or addressing a pressing business problem.', 'Experience leveraging programming languages to script the extraction, formatting, and transformation of data from a wide variety of organizational system.', 'MS Access, SQL Server, SharePoint, and Visual Basic programming knowledge is a plus', 'Excellent written and verbal communication skills', 'Experience with Business Intelligence Tools like Alterix, Tableau, or similar - Desired', 'Complete ad hoc data extract and reporting tasks as requested by organizational leaders.', 'Required Education/Experience/Skills', 'Experience leveraging programming languages to script the extraction, formatting and transformation of data from a wide variety of organizational systems', 'Microsoft Project, Excel and PowerPoint', 'Investigate and implement new scientific analysis and methodologies to support data analytics efforts and stay current with evolving technologies and capabilities.', 'Microsoft Project, Excel and PowerPoint.', 'Master’s Degree in Computer Science, Engineering, Mathematics, or other related fields.Experience with Business Intelligence Tools like Alterix, Tableau, or similar.Big data and cloud processing experience.SQL Database experience.DoD/Federal Government experience.', 'Experience with Business Intelligence Tools like MS Excel, Advana, Qlik, R, Python, or similar - Required', 'Experience with Business Intelligence Tools like MS Excel, Advana, Qlik, R, Python, or similar - RequiredExperience with Business Intelligence Tools like Alterix, Tableau, or similar - DesiredExperience leveraging programming languages to script the extraction, formatting and transformation of data from a wide variety of organizational systemsBig data and cloud processing experienceExperience working in a cloud based environmentMicrosoft Project, Excel and PowerPointMS Access, SQL Server, SharePoint, and Visual Basic programming knowledge is a plus', 'Perform data extracts and loads from source data systems to analytical data stores.', 'Strong problem solving and troubleshooting skills with experience exercising mature judgment', 'Bachelor’s Degree in Computer Science, Engineering, Mathematics, or other related fields.', 'Position Responsibilities', 'Apply expertise in computer science, software development, and the latest technologies to design and implement analysis infrastructure and tools, analytic workflow processes, automations, and complex data visualizations.', 'Leverage technical and analytical expertise to explore and examine data from multiple disparate sources with the goal of discovering patterns and previously hidden insights, providing process efficiencies, or addressing a pressing business problem.Apply expertise in computer science, software development, and the latest technologies to design and implement analysis infrastructure and tools, analytic workflow processes, automations, and complex data visualizations.Apply technical and analytical techniques to explore and examine data from multiple disparate sources with the goal of discovering patterns and previously hidden insights, providing process efficiencies, or addressing a pressing business problem.Apply expertise in computer science, software development, and the latest technologies to design and implement analysis infrastructure and tools, analytic workflow processes, automations, and complex data visualizations.Create informational briefings that explain methodologies and analytical findings to peers and customer stakeholders.Document and visualize data both temporally and spatially, and present data to managers.Create and provide informational briefings that are required to explain methodologies and analytical findings to peers and customer stakeholders.Investigate and implement new scientific analysis and methodologies to support data analytics efforts and stay current with evolving technologies and capabilities.Complete ad hoc data extract and reporting tasks as requested by organizational leaders.Perform data extracts and loads from source data systems to analytical data stores.Work with business leaders to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results.', 'Active DoD Secret security clearance.Bachelor’s Degree in Computer Science, Engineering, Mathematics, or other related fields.2+ years of relevant work experience.Strong team-building skills as well as confidence when working with senior leadership and peers.Experience with Business Intelligence (BI) Tools such as MS Excel, Advana, Qlik, R, Python, or similar.Experience leveraging programming languages to script the extraction, formatting, and transformation of data from a wide variety of organizational system.Microsoft Project, Excel and PowerPoint.', 'Work with business leaders to solve business problems by understanding, preparing, and analyzing data to predict emerging trends and provide recommendations to optimize business results.', 'Proven experience effectively prioritizing workload to meet deadlines and work objectives', 'Position Overview', 'Big data and cloud processing experience.', 'DoD/Federal Government experience.', 'Experience with Business Intelligence Tools like Alterix, Tableau, or similar.', 'Applies technical and analytical techniques to explore and examine data from multiple disparate sources with the goal of discovering patterns and previously hidden insights, providing process efficiencies, or addressing a pressing business problem.Apply expertise in computer science, software development, and the latest technologies to design and implement analysis infrastructure and tools, analytic workflow processes, automations, and complex data visualizations.Creates informational briefings that explain methodologies and analytical findings to peers and customer stakeholders.', 'Document and visualize data both temporally and spatially, and present data to managers.', 'Desired Education/Experience/Skills', 'Creates informational briefings that explain methodologies and analytical findings to peers and customer stakeholders.', '2+ years of relevant consulting or industry experience, DoD/Federal Government experience preferred.', 'Experience interacting with Senior Leadership', 'Applies technical and analytical techniques to explore and examine data from multiple disparate sources with the goal of discovering patterns and previously hidden insights, providing process efficiencies, or addressing a pressing business problem.', 'Proven ability working successfully in a collaborative and diverse environment', 'Apply technical and analytical techniques to explore and examine data from multiple disparate sources with the goal of discovering patterns and previously hidden insights, providing process efficiencies, or addressing a pressing business problem.', 'Big data and cloud processing experience', 'Strong team-building skills as well as confidence when working with senior leadership and peers.', 'Tools And Proficiency Level', 'Master’s Degree in Computer Science, Engineering, Mathematics, or other related fields.', 'Bachelor’s Degree Computer Science, Engineering, Mathematics or other business-related field, Master’s Degree preferred', 'Experience with Business Intelligence (BI) Tools such as MS Excel, Advana, Qlik, R, Python, or similar.', '2+ years of relevant work experience.', 'Overview', 'Secret Security Clearance and above for this role', 'Bachelor’s Degree Computer Science, Engineering, Mathematics or other business-related field, Master’s Degree preferred2+ years of relevant consulting or industry experience, DoD/Federal Government experience preferred.Strong problem solving and troubleshooting skills with experience exercising mature judgmentProven experience effectively prioritizing workload to meet deadlines and work objectivesExcellent written and verbal communication skillsDemonstrated ability to write clearly, succinctly, and in a manner that appeals to a wide audienceProven ability working successfully in a collaborative and diverse environmentExperience interacting with Senior LeadershipSecret Security Clearance and above for this role', 'Create and provide informational briefings that are required to explain methodologies and analytical findings to peers and customer stakeholders.', 'Demonstrated ability to write clearly, succinctly, and in a manner that appeals to a wide audience', 'Active DoD Secret security clearance.', 'Create informational briefings that explain methodologies and analytical findings to peers and customer stakeholders.']",Associate,Full-time,Engineering,Construction,2020-11-05 11:32:32
Data Scientist (remote),SoLo Funds,Los Angeles Metropolitan Area,,N/A,"['', 'Experience with financial data is a plus ', 'A passion for Solo’s mission ', '1-3 years of industry experience ', 'BS in Computer Science, Mathematics, Economics or a related field. (MS a plus) A passion for Solo’s mission 1-3 years of industry experience Experience with ownership of the full lifecycle of machine learning models Proficiency in SQL and Python (and respective ML packages) Familiarity with AWS strongly preferred, particularly with Sagemaker Experience with financial data is a plus Ability to manage multiple priorities, working independently or collaboratively, in a fast-paced, dynamic environment Reliability and attention to detail Strong written and verbal communication', 'Develop ML models (full lifecycle) to power our credit and fraud risk evaluation Measure & monitor the performance of models in production Perform exploratory data analysis on potential data sources Support development of key success metrics Assist with deep-dive data analyses ', 'Perform exploratory data analysis on potential data sources ', 'Reliability and attention to detail ', 'Strong written and verbal communication', 'Requirements ', 'Ability to manage multiple priorities, working independently or collaboratively, in a fast-paced, dynamic environment ', 'Familiarity with AWS strongly preferred, particularly with Sagemaker ', 'Assist with deep-dive data analyses ', 'Proficiency in SQL and Python (and respective ML packages) ', 'Develop ML models (full lifecycle) to power our credit and fraud risk evaluation ', 'The ideal candidate would combine a deep technical background with experience handling financial data and strong alignment with our mission. ', 'BS in Computer Science, Mathematics, Economics or a related field. (MS a plus) ', ' ', 'We are looking for a driven Data Scientist with 1-3 years of experience to join our growing data team. This role will work closely with our lead data scientist and data engineers, and will focus primarily on the credit and fraud risk models which are essential to our platform. You will be exploring potential new data sources, engineering features, building models, and monitoring them in production. ', 'Support development of key success metrics ', 'Responsibilities: ', 'Experience with ownership of the full lifecycle of machine learning models ', 'Measure & monitor the performance of models in production ']",Associate,Full-time,Engineering,Financial Services,2020-11-05 11:32:32
Data Scientist NGSE,Zoetis Inc.,"Parsippany, NJ",10 hours ago,Be among the first 25 applicants,"['', '*Software development / engineering experience a plus', 'EDUCATION AND EXPERIENCE', 'Fluency in English required', '*Experience in data engineering a plus', 'TECHNICAL SKILLS REQUIREMENTS', '*Experience working in a cloud environment (Azure, AWS, Google Cloud)', '*Minimum of two years of professional experience working as a Data Scientist', 'Generate buy-in and engagement by effectively communicating results through presentations and visualizations', 'To be successful, the ideal candidate will demonstrate a thirst for knowledge and natural curiosity to enable rapid learning of the Zoetis business model and data infrastructure at a scale to support a growing $2b region. The position involves working with structured and unstructured real-world data, requiring a candidate who is comfortable thinking independently about solving business problems. Candidates must be self-motivated, detail-oriented, have the ability to work with limited supervision, and must be comfortable in an environment of changing priorities. Candidates should have a strong business acumen, with evidence of delivered business value, preferably in a commercial setting', '*Strong statistics acumen including design of experiments', '*Experience working in Microsoft tech stack including SQL Server and Azure preferred', '*Tableau / data visualization experience a plus', '*Excellent interpersonal, written, and verbal communication skills; demonstrated ability to effectively communicate complex ideas to a non-technical audience', '*Strong analytical mind and business acumen; ability to translate mathematical models and results into business concepts', 'Perform predictive analytics to identify core opportunities to drive business value, utilizing machine learning techniques such as logistic regression, random forests, collaborative filtering, sentiment analysis and topic modeling', '*Experience in large-scale/distributed computing and analytics (Hadoop, Spark)', '*Experience in building predictive models in R or Python (Pandas/PySpark)', '*Knowledge of SQL', '*Experience in scaled model testing, integration, and deployment (DevOps) a plus', 'POSITION RESPONSIBILITIES', ' ', '*Experience with source control and collaboration tools (e.g. Git)', ""This role has been created to support the US Petcare Organization. The role will directly enable the development of an advanced-analytics enabled enhancement of the go-to-market sales strategy. The candidate will produce insightful analytic data models to capture and explain performance trends of the Zoetis Sales Force, while driving optimization opportunities and proactive direction for the Sales Organization. The candidate will interface across the organization to answer challenging analytical questions and highlight customer-related insights, such as revenue generation ideas and strategies to detect and prevent potential customer defection. The candidate will also produce creative solutions to complex business problems using advanced analytical techniques, while leveraging both internal and external data sources. The role will involve frequent interaction with key stakeholders across the sales and marketing organizations and provide the candidate with an exceptionally broad view of every aspect of Zoetis' business, while serving as critical support for the US Petcare division."", 'POSITION SUMMARY', 'Build predictive models to inform advanced insights, account prioritization, next-best-action, campaign optimization, and commercial test-and-learn for NGSE', 'Position is based in Parsippany, NJ', '*Masters from an accredited college/university in Computer Science, Statistics, Mathematics, Operations Research, or related field', '*Demonstrated experience building deployed prediction models to create business value, preferably in sales and marketing applications']",Entry level,Full-time,Analyst,Pharmaceuticals,2020-11-05 11:32:32
Machine Learning Researcher,Comcast,"Schaumburg, IL",10 hours ago,Be among the first 25 applicants,"['PhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. Strong programming and software skills, with Python experience preferred. Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. ', 'Has excellent interpersonal skills and can communicate effectively. Chart a solid research path given available requirements. Quickly understands entertainment media and its semantic and technical structure. Is innovative and can find unique solutions to problems. Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. Plans, organizes, and time-manages independently. Prioritizes and assesses the implications of decisions. ', 'Preferred Skills', 'Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. ', 'Computer Science, Engineering, Applied Mathematics, or Statistics', 'Strong programming and software skills, with Python experience preferred. ', 'Other duties and responsibilities as assigned. ', 'PhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. ', 'Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. ', 'Research and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. ', 'Prioritizes and assesses the implications of decisions. ', 'Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. ', ""Understand our Operating Principles; make them the guidelines for how you do your jobOwn the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and servicesKnow your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiencesWin as a team - make big things happen by working together and being open to new ideasBe an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joininghuddles, making call backs and helping us elevate opportunities to do better for our customersDrive results and growthRespect and promote inclusion and diversityDo what's right for each other, our customers, investors and our communities"", 'Bachelor’s Degree', 'Consistent exercise of independent judgment and discretion in matters of significance. ', 'Chart a solid research path given available requirements. ', 'Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. ', 'Is innovative and can find unique solutions to problems. ', 'Job Summary:', ""Job Summary:Research and implement new detection capabilities for use within our Media Analysis Framework (MAF). You will rely on your experience in computer vision, signal processing, machine learning, and deep learning to extract insightful metadata from the video. You will create algorithms for multi-modal analysis of video. Additionally, you’ll ensure that your components are well-tested, production-ready, and performant at scale. The position is open in for placement in either Chicago or Washington, DC. We feature an innovative, informal, open atmosphere, and cultivate a start-up culture with the backing of a Fortune 50 company. To better serve our community, we believe the diversity of our team should reflect the diversity of our customers.Employees At All Levels Are Expected ToUnderstand our Operating Principles; make them the guidelines for how you do your jobOwn the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and servicesKnow your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiencesWin as a team - make big things happen by working together and being open to new ideasBe an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joininghuddles, making call backs and helping us elevate opportunities to do better for our customersDrive results and growthRespect and promote inclusion and diversityDo what's right for each other, our customers, investors and our communitiesCore ResponsibilitiesResearch and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. Consistent exercise of independent judgment and discretion in matters of significance. Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. Other duties and responsibilities as assigned. Desired QualificationsPhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. Strong programming and software skills, with Python experience preferred. Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. Preferred SkillsThe preferred candidate will have the following skills and qualities:Has excellent interpersonal skills and can communicate effectively. Chart a solid research path given available requirements. Quickly understands entertainment media and its semantic and technical structure. Is innovative and can find unique solutions to problems. Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. Plans, organizes, and time-manages independently. Prioritizes and assesses the implications of decisions. Job SpecificationBachelor’s DegreeComputer Science, Engineering, Applied Mathematics, or StatisticsGenerally requires 5-8 years related experience.Comcast is an EOE/Veterans/Disabled/LGBT employer"", 'Research and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. Consistent exercise of independent judgment and discretion in matters of significance. Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. Other duties and responsibilities as assigned. ', 'Quickly understands entertainment media and its semantic and technical structure. ', 'Core Responsibilities', 'Has excellent interpersonal skills and can communicate effectively. ', 'Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. ', 'Desired Qualifications', 'Plans, organizes, and time-manages independently. ', 'Drive results and growth', 'Business Unit', 'Generally requires 5-8 years related experience.', 'huddles, making call backs and helping us elevate opportunities to do better for our customers', 'Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. ', 'Employees At All Levels Are Expected To', 'Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences', 'Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services', 'Respect and promote inclusion and diversity', 'The position is open in for placement in either Chicago or Washington, DC.', 'Win as a team - make big things happen by working together and being open to new ideas', 'Job Specification', 'Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. ', 'Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining', 'Understand our Operating Principles; make them the guidelines for how you do your job', 'Bachelor’s DegreeComputer Science, Engineering, Applied Mathematics, or StatisticsGenerally requires 5-8 years related experience.', ""Do what's right for each other, our customers, investors and our communities"", 'Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. ']",Not Applicable,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist, Discover",Snap Inc.,"San Francisco, CA",7 hours ago,27 applicants,"['', ' Experience with a programming language, such as Python ', ' Bachelor’s degree in math, statistics, computer science, or other quantitative field  3+ years of experience in quantitative analysis & data science or a related field  Fluency in SQL or other big data querying language ', ' 3+ years of experience in quantitative analysis & data science or a related field ', ' Use your quantitative skill sets to present data in an organized way that goes beyond the numbers and articulates how Snapchat Users interact with our products  Set product goals, design and evaluate experiments, monitor the health of our products and understand changes to our KPIs  Partner with Product, Design and Engineering to influence and inform our roadmap, strategy and product launches  Exploratory analysis that influence longer-term thinking including understanding how our products impact the broader ecosystem and user behavior trends ', ' Strong statistical knowledge ', 'Minimum Qualifications', 'Preferred Qualifications', ' Use your quantitative skill sets to present data in an organized way that goes beyond the numbers and articulates how Snapchat Users interact with our products ', ' A team player who can collaborate with engineers, product managers, designers and other cross-functional teams ', 'Knowledge, Skills, Abilities', ' Experience with analytical packages such as SciPy or R ', 'What You’ll Do', ' Excellent verbal and written communication skills, with high attention to detail ', ' Excellent verbal and written communication skills, with high attention to detail  Strong statistical knowledge  Ability to initiate and drive projects to completion with minimal guidance  A team player who can collaborate with engineers, product managers, designers and other cross-functional teams ', ' Bachelor’s degree in math, statistics, computer science, or other quantitative field ', ' Experience with causal inference techniques, experimental design and/or A/B testing ', ' Ability to initiate and drive projects to completion with minimal guidance ', ' Experience in a product-focused role at a social media and/or mobile technology company ', ' Fluency in SQL or other big data querying language ', ' Master or Ph.D degree in math, statistics, computer science, or other quantitative field ', ' Master or Ph.D degree in math, statistics, computer science, or other quantitative field  Experience with causal inference techniques, experimental design and/or A/B testing  Experience with analytical packages such as SciPy or R  Experience with a programming language, such as Python  Experience in a product-focused role at a social media and/or mobile technology company ', ' Exploratory analysis that influence longer-term thinking including understanding how our products impact the broader ecosystem and user behavior trends ', ' Partner with Product, Design and Engineering to influence and inform our roadmap, strategy and product launches ', ' Set product goals, design and evaluate experiments, monitor the health of our products and understand changes to our KPIs ']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
eCommerce Data Scientist,PepsiCo,"New York, NY",11 hours ago,36 applicants,"['', 'Auto req ID:', 'Experience with Marketing analytics and/or Mixed Market Modeling (MMM)', 'What PepsiCo Data Science & Analytics Does', 'Provide statistical analysis assistance for business requests, build automated tools in support of these requests', 'Responsibilities', ""ROI Engine – An interpretable sales forecaster implemented in TensorFlow. We execute a distributed hyperparameter search, across thousands of instances, to select the most plausible explanatory models using a heuristic we've designed in collaboration with our business stakeholders. We love autodiff, linear algebra, and domain-knowledge based regularization."", 'Familiarity with mathematical models underlying data science methods', 'Put the Power of Data to Work.', 'Experience with Marketing analytics and/or Mixed Market Modeling (MMM)Linear AlgebraExperience or knowledge of low-level TensorFlow APIs', 'Bachelor’s Degree in Data/Computer Science, an engineering or scientific disciple, or equivalent experience', 'Data Platform – Comprised of multiple layers in the cloud to help aggregate, sort and store information from both internal sources and external vendors. We are regularly implementing new tools/methodologies to help empower our data engineering efforts. ', '#LI DNI', 'Marketing Automation– Empowering our Marketing team by enabling them to execute and automate a large number of marketing campaigns in our many customer retail platforms (i.e., Instacart, Amazon, Walmart, etc.). ', 'Nice to have', 'eCom Data Scientist ', 'Bachelor’s Degree in Data/Computer Science, an engineering or scientific disciple, or equivalent experienceDevelopment and/or deployment experience in Python on Docker and AWSExperience and or familiarity NumPy, Pandas, Pytorch, PostgresSQL, MSSQL, MySQLFamiliarity with mathematical models underlying data science methodsDemonstrated ability to effectively and concisely communicate with both business and technical audiences', 'Linear Algebra', 'eCommerce Data Scientist', 'Experience or knowledge of low-level TensorFlow APIs', 'Relocation Eligible:', 'Work within the data science team to analyze large data sets and assist in the development of custom models/algorithms to uncover trends, patterns and insightsWrite clean, organized machine learning code using standard software engineering methodologiesProvide statistical analysis assistance for business requests, build automated tools in support of these requests', 'Data & Security – Building an efficient infrastructure and ETL pipeline to process Terabytes of data every day ensuring quality and eliminating duplication ', 'Job Type:', 'Job Description', 'Qualifications/Requirements', 'Experience and or familiarity NumPy, Pandas, Pytorch, PostgresSQL, MSSQL, MySQL', 'Work within the data science team to analyze large data sets and assist in the development of custom models/algorithms to uncover trends, patterns and insights', 'Write clean, organized machine learning code using standard software engineering methodologies', 'Development and/or deployment experience in Python on Docker and AWS', 'Demonstrated ability to effectively and concisely communicate with both business and technical audiences']",Mid-Senior level,Full-time,Engineering,Consumer Goods,2020-11-05 11:32:32
Data Scientist – Manage and Analyze,DocuSign,"Walnut Creek, CA",8 hours ago,Be among the first 25 applicants,"['', 'Masters or PhD in computer science, data science, machine learning, applied mathematics, or an equally computational field.', 'Our agreement with employees', 'Data Scientist – Manage and Analyze', 'Understand, assist and improved the existing training data maintenance and enrichment process', 'Experience with Python programming, especially in the context of established deep learning frameworks', 'Strong desire to stay ahead of industry trends & technologies with a commitment to continuous research and learning.', 'Preferred Qualifications', 'Feature extraction and data preparation', 'Responsibilities', 'About Us', 'This position', 'Basic Qualifications', 'Natural curiosity and hand-on attitude', 'Understanding of the entire software development end-to-end process as well as the product code and release management process', 'Demonstrated experience with text-based deep learning (NLP, NLU).', ' Experience with containerization and orchestration of machine learning models in production. Masters or PhD in computer science, data science, machine learning, applied mathematics, or an equally computational field. Demonstrated experience with text-based deep learning (NLP, NLU). Demonstrated experience in extracting, cleansing, and manipulating large, diverse unstructured datasets. Strong desire to stay ahead of industry trends & technologies with a commitment to continuous research and learning. ', 'Algorithm development and evaluation of existing and emerging NLP/ML methods and technologies that could be effectively applied to contractual/legal data', 'Demonstrated experience in extracting, cleansing, and manipulating large, diverse unstructured datasets.', 'Apply ML algorithms and technologies to NLP tasks such as Named Entity Recognition, POS tagging, Parsing, Sentiment Analysis, Clustering, etc.', 'Experience with containerization and orchestration of machine learning models in production.', ' Feature extraction and data preparation Algorithm development and evaluation of existing and emerging NLP/ML methods and technologies that could be effectively applied to contractual/legal data Apply NLP techniques to maintain and extend the current rule-based, supervised and unsupervised models Apply ML algorithms and technologies to NLP tasks such as Named Entity Recognition, POS tagging, Parsing, Sentiment Analysis, Clustering, etc. Understanding of the entire software development end-to-end process as well as the product code and release management process Understand, assist and improved the existing training data maintenance and enrichment process Natural curiosity and hand-on attitude ', '3+ years of experience in designing, developing, deploying and monitoring models, specifically in the context of text processing/NLP', 'Apply NLP techniques to maintain and extend the current rule-based, supervised and unsupervised models', 'The team', 'Bachelor’s degree in computer science, data science, applied mathematics, or an equally computational field', ' 3+ years of experience in designing, developing, deploying and monitoring models, specifically in the context of text processing/NLP Experience with Python programming, especially in the context of established deep learning frameworks Bachelor’s degree in computer science, data science, applied mathematics, or an equally computational field ']",Entry level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Health Analytics Data Scientist,Berkeley Research Group LLC,"Washington, DC",21 hours ago,Be among the first 25 applicants,"['', 'Responsibilities', ' Manage client relationships and communicate results and work product as appropriate.', ' Keen interest in economic or financial analysis and research.', ' Commitment to producing high quality analysis and attention to details.', ' Demonstrate creativity and efficient use of relevant software tools, analytical methods and computer models to develop solutions.', ' Plan and manage of all aspects of small to medium sized client engagements and discrete segments of larger projects.', ' A degree (e.g., BS, BBA, MBA, M.A., M.S., etc.) with a focus in business analytics (accounting, finance, economics, information systems) or equivalent experience.', ' 2-6 years of work experience with a focus on data analytics.', ' Strong verbal and written communication skills.', 'Qualifications', ' Participate in group practice meetings, contribute to business development initiatives and office functions such as staff training and recruiting.', 'BRG is an Equal Employment Opportunity/Affirmative Action Employer. All qualified candidates will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, disability, or protected veteran status.', ' A degree (e.g., BS, BBA, MBA, M.A., M.S., etc.) with a focus in business analytics (accounting, finance, economics, information systems) or equivalent experience. 2-6 years of work experience with a focus on data analytics. Proven capability with MS Excel and relational database program(s) (e.g., SAS, SPSS, Stata, MS SQL Server, MS Access). A desire to expand those capabilities is required, as is the ability to train others to use such tools. Desire and ability to manage processes and projects. Commitment to producing high quality analysis and attention to details. Keen interest in economic or financial analysis and research. Strong verbal and written communication skills. Desire to work within a team environment.', 'Candidate must be able to submit verification of his/her legal right to work in the United States, without company sponsorship.', ' Proven capability with MS Excel and relational database program(s) (e.g., SAS, SPSS, Stata, MS SQL Server, MS Access). A desire to expand those capabilities is required, as is the ability to train others to use such tools.', ' Desire to work within a team environment.', 'Overview', ' Delegate assignments to staff, instruct and monitor progress, and review work product for completeness and accuracy.', ' Develop analyses and financial models using transactional data and/or financial data.', ' Desire and ability to manage processes and projects.', ' Plan and manage of all aspects of small to medium sized client engagements and discrete segments of larger projects. Delegate assignments to staff, instruct and monitor progress, and review work product for completeness and accuracy. Develop analyses and financial models using transactional data and/or financial data. Generate client deliverables and make valuable contributions to expert reports. Manage client relationships and communicate results and work product as appropriate. Demonstrate creativity and efficient use of relevant software tools, analytical methods and computer models to develop solutions. Participate in group practice meetings, contribute to business development initiatives and office functions such as staff training and recruiting. Prioritize assignments and responsibilities in order to meet goals and deadlines.', ' Generate client deliverables and make valuable contributions to expert reports.', ' Prioritize assignments and responsibilities in order to meet goals and deadlines.']",Entry level,Full-time,Engineering,Management Consulting,2020-11-05 11:32:32
Data Scientist,Tapad,"New York, NY",12 hours ago,28 applicants,"['', 'Master’s degree in a quantitative discipline (e.g. Computer Science, Engineering, Mathematics, Statistics, Physics, Chemistry, etc.) ', 'Python, SQL, Scala', 'Tapad does not accept resumes from unsolicited search firms nor recruiters. In no event shall fees be paid to any unsolicited search firms nor recruiters, regardless of whether the candidate is made an offer or accepts a placement at Tapad. All resumes received through any channels will be considered the sole property of Tapad.', 'More About Tapad', 'Strong communication skills, both verbal and written', 'Check out our #TapadLife page to see what our employees have to say', 'Scala School (we’ll teach you!), Coursera, LinkedIn Learning, peer-led professional development, and an abundance of resources to help you stay sharp', 'Discounts on gym memberships 😉', 'Understanding of programming concepts and experience with programming languages, such as Python, R, Java, Scala, MATLAB', 'Tapad Perks', '401k matching, Life, LTD & STD Insurance, dental, vision, and telehealth plan with 24/7 access to a dedicated team of physical and mental healthcare providers', 'We are looking for candidates who meet some of the following qualifications:', 'Google Cloud Platform (GCP), BigQuery, Apache Airflow', 'Collaborate with product managers and business partners to understand market needs and to help identify new opportunities for Tapad', 'Experience using cloud computing technologies ', ' Python, SQL, Scala Spark, SparkML, SciKit Learn, AutoML, BigQuery ML, TensorFlow Extended (TFX) Google Cloud Platform (GCP), BigQuery, Apache Airflow ', 'Design experiments and apply appropriate metrics to measure the impact of the developed models ', 'You will use machine learning (e.g. deep learning), clustering, statistical modeling, and other advanced techniques to infer connections from petabytes of data', 'Foosball, ping pong, diversity and inclusion group, book club, Tough Mudder, push-up challenges, and tons of other extra-curricular activities that will make you feel like part of the Tapad family (virtual game nights and happy hours until we’re back in the office)', 'Ph.D. in a quantitative discipline', 'Spark, SparkML, SciKit Learn, AutoML, BigQuery ML, TensorFlow Extended (TFX)', 'Experience working in a large-scale, distributed system environment', 'Bonus Qualification & Experience', "" Generous PTO - no accruing necessary  401k matching, Life, LTD & STD Insurance, dental, vision, and telehealth plan with 24/7 access to a dedicated team of physical and mental healthcare providers Scala School (we’ll teach you!), Coursera, LinkedIn Learning, peer-led professional development, and an abundance of resources to help you stay sharp Unlimited snacks and beverages, collaboration catered lunches (virtual lunches until we're back in the office) Discounts on gym memberships 😉 Foosball, ping pong, diversity and inclusion group, book club, Tough Mudder, push-up challenges, and tons of other extra-curricular activities that will make you feel like part of the Tapad family (virtual game nights and happy hours until we’re back in the office) Check out our #TapadLife page to see what our employees have to say Find more about our engineering culture HERE "", ""Unlimited snacks and beverages, collaboration catered lunches (virtual lunches until we're back in the office)"", 'Tapad is proud to be an equal opportunity employer and will consider all qualified applicants regardless of age, sex, race, religion, national origin, sexual orientation, gender identity, marital or family status, disability, or any other legally protected status.', '3+ years experience in applying machine learning techniques, advanced analytics, and statistics, either in an academic setting or as a data scientist', 'Find more about our engineering culture HERE', 'Small Teams; Big Data', 'Are you up for the challenge?', 'A day in the life as a Tapad Data Scientist:', 'Employ predictive modeling, data mining, graph algorithms, and other data science techniques to contribute to and enhance our cross-device identity resolution portfolio', 'Data Scientist', ' Master’s degree in a quantitative discipline (e.g. Computer Science, Engineering, Mathematics, Statistics, Physics, Chemistry, etc.)  3+ years experience in applying machine learning techniques, advanced analytics, and statistics, either in an academic setting or as a data scientist Experience working with large data sets using SQL, Spark, Hadoop, or MapReduce Understanding of programming concepts and experience with programming languages, such as Python, R, Java, Scala, MATLAB Strong communication skills, both verbal and written Experience working in a large-scale, distributed system environment ', 'Partner with other data scientists and engineers to turn various machine learning, clustering, and statistical solutions into viable and scalable products ', ' Ph.D. in a quantitative discipline Experience using cloud computing technologies  ', 'Technologies we use at Tapad (don’t worry, we’ll teach you):', 'Generous PTO - no accruing necessary ', ' You will use machine learning (e.g. deep learning), clustering, statistical modeling, and other advanced techniques to infer connections from petabytes of data Employ predictive modeling, data mining, graph algorithms, and other data science techniques to contribute to and enhance our cross-device identity resolution portfolio Design experiments and apply appropriate metrics to measure the impact of the developed models  Partner with other data scientists and engineers to turn various machine learning, clustering, and statistical solutions into viable and scalable products  Collaborate with product managers and business partners to understand market needs and to help identify new opportunities for Tapad ', 'Experience working with large data sets using SQL, Spark, Hadoop, or MapReduce']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Data Scientist,Analog Devices,"Wilmington, MA",21 hours ago,37 applicants,"['', ' Natural curiosity—you enjoy digging deeper to find the big picture', ' Provide programming support to data science projects and tasks that may include data visualization, predictive analytics, machine learning, and natural language processing Apply a wide array of advanced data mining techniques (including supervised and unsupervised methods, dimension reduction methods, and social network analysis methods) in support of research and operational analytic projects Write programs in Python to extract, clean, and format data and to create variables for use in analysis Work with Web developers to build intelligence into customer-facing and internal smart applications Construct datasets and prepare data files from various sources Interpret data outputs and articulate findings Use SQL and NoSQL to manage large structured and unstructured data sources', "" Bachelors or Master's degree in economics, data science, data analytics, computer science, statistics, mathematics, natural sciences or other relevant field Solid foundation in statistics Knowledge of data analytics, data visualizations, data mining, predictive modeling, machine learning, or other data intensive analytical role Experience with open source programming languages like Python and Julia"", "" Bachelors or Master's degree in economics, data science, data analytics, computer science, statistics, mathematics, natural sciences or other relevant field"", ' Work with Web developers to build intelligence into customer-facing and internal smart applications', ' Write programs in Python to extract, clean, and format data and to create variables for use in analysis', ' Always be the person who takes on any project', 'EEO Is The Law', ' Interpret data outputs and articulate findings', ' Eagerness and desire to learn', ' Solid foundation in statistics', 'Travel Required', ' Natural curiosity—you enjoy digging deeper to find the big picture Eagerness and desire to learn Enthusiasm about helping others, especially team members Always be the person who takes on any project Flexibility in dynamic environments', ' Construct datasets and prepare data files from various sources', ' Provide programming support to data science projects and tasks that may include data visualization, predictive analytics, machine learning, and natural language processing', ' Use SQL and NoSQL to manage large structured and unstructured data sources', ' Apply a wide array of advanced data mining techniques (including supervised and unsupervised methods, dimension reduction methods, and social network analysis methods) in support of research and operational analytic projects', ' Experience with open source programming languages like Python and Julia', ' Knowledge of data analytics, data visualizations, data mining, predictive modeling, machine learning, or other data intensive analytical role', ' Enthusiasm about helping others, especially team members', ' Flexibility in dynamic environments', 'Education Level']",Not Applicable,Full-time,Engineering,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Data Scientist,Unite Us,"New York, NY",20 hours ago,43 applicants,"['', ' Experience scaling work from R&D to a production predictive pipeline built on a modern stack. ', ' 3+ years experience with modern programming languages (Python, R, SQL) and tools/libraries (pandas, scikit-learn, TensorFlow, etc) used in data science.   Robust understanding of the statistical foundation of machine learning and experience with experiment design and causal inference.   Comfort with geospatial analysis techniques.   Experience scaling work from R&D to a production predictive pipeline built on a modern stack.   Experience with healthcare data and analytics is preferred.   You\'re a kind, passionate and collaborative problem-solver who seeks and gives candid feedback, and values the chance to make an important impact.   You love numbers, and have an orientation to find practical solutions to complex problems   You like to teach others, have strong communication skills and experience briefing leadership on outcomes and recommendations   You are flexible and excited to work in a fast-paced environment with evolving needs   You have a passion for working with data and understanding how it can be turned into products.   You have a ""get it done"" mentality, self-motivated and comfortable with ambiguity  You thrive in a cross-functional environment, and enjoy working collaboratively with a diverse team of individuals with different backgrounds and skill sets  You are a strong communicator with an ability to adapt communication style across stakeholders, both internal and external, with varying levels of seniority  ', 'Environmental Job Requirements & Working Conditions: ', ' You have a passion for working with data and understanding how it can be turned into products. ', 'Education and Experience: ', ' You have a ""get it done"" mentality, self-motivated and comfortable with ambiguity', "" You're a kind, passionate and collaborative problem-solver who seeks and gives candid feedback, and values the chance to make an important impact. "", ' Robust understanding of the statistical foundation of machine learning and experience with experiment design and causal inference. ', ' You are flexible and excited to work in a fast-paced environment with evolving needs ', ' Transform data captured by our health systems partners to power the Unite Us platform by identifying key insights.', 'Description: ', ' 3+ years of work experience in Analytics or Data Science, including experience managing teams. Growth company experience is highly preferred.   Experience working with health data, or in a healthcare related field preferred.   Degree in quantitative field such as statistics, computer science, math, data science. Advanced degree preferred.  ', ' Experience working with health data, or in a healthcare related field preferred. ', '  This position is remote  This position requires 10% travel  ', '  Identify data benchmarks and social care ROI that can be leveraged across the company - you will be supporting Sales, Marketing and Customer Success  Develop predictive analytics capabilities by identifying and leveraging both internal and external data sources and creating tools that support referral decision-making, calculate risk scores and identify client needs.   Transform data captured by our health systems partners to power the Unite Us platform by identifying key insights.  Partner with Business Development, Product and Engineering to understand our partners and the health and social care data landscape.  This role provides a unique opportunity to be part of the founding team focused on social data expansion across the country; helping health systems, health plans and CBOs realize their SDOH data strategy. ', '3+ years experience with modern programming languages (Python, R, SQL) and tools/libraries (pandas, scikit-learn, TensorFlow, etc) used in data science. ', ' You like to teach others, have strong communication skills and experience briefing leadership on outcomes and recommendations ', ' Partner with Business Development, Product and Engineering to understand our partners and the health and social care data landscape.', ' This position is remote', ' Develop predictive analytics capabilities by identifying and leveraging both internal and external data sources and creating tools that support referral decision-making, calculate risk scores and identify client needs. ', 'Who we are:', ""What's Required: "", ""What You'll Do:"", ' Degree in quantitative field such as statistics, computer science, math, data science. Advanced degree preferred. ', ' This position requires 10% travel ', ' You thrive in a cross-functional environment, and enjoy working collaboratively with a diverse team of individuals with different backgrounds and skill sets', ' You love numbers, and have an orientation to find practical solutions to complex problems ', ' Comfort with geospatial analysis techniques. ', '3+ years of work experience in Analytics or Data Science, including experience managing teams. Growth company experience is highly preferred. ', ' Identify data benchmarks and social care ROI that can be leveraged across the company - you will be supporting Sales, Marketing and Customer Success', ' This role provides a unique opportunity to be part of the founding team focused on social data expansion across the country; helping health systems, health plans and CBOs realize their SDOH data strategy.', ' You are a strong communicator with an ability to adapt communication style across stakeholders, both internal and external, with varying levels of seniority ', ' Experience with healthcare data and analytics is preferred. ']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,FraudScope,Atlanta Metropolitan Area,24 hours ago,119 applicants,"['', 'Preferred Skills', 'Lead the creation of new detection solutions driven by exploratory data analysis from complex and disparate healthcare datasetsExecute analytical approaches to design, develop, and evaluate methodologies and advanced algorithms that result in the extraction of optimal value from dataInvestigate various data, technologies, and methodologies to determine their applicability in solving current problemsKeep abreast of developments within machine learning and apply where appropriateWork both independently and in a team', 'FraudScope is an AI-assisted platform that accelerates the identification of fraud, waste, and abuse in Healthcare which costs the nation $270B annually. FraudScope is rapidly growing and has won numerous awards. We are seeking exceptional talent to achieve our goal of ensuring that our scarce healthcare dollars go to real patient care.', 'Investigate various data, technologies, and methodologies to determine their applicability in solving current problems', 'Lead the creation of new detection solutions driven by exploratory data analysis from complex and disparate healthcare datasets', 'Work both independently and in a team', 'Familiarity with the use of cloud computing platforms (e.g., Amazon Web Services)', 'PLEASE NOTE BEFORE APPLYING: THIS ROLE IS LOCATED IN ATLANTA, GA AND THE CHOSEN CANDIDATE MUST BE LOCATED/RELOCATE HERE AS WELL. IN ADDITION, FRAUDSCOPE IS NOT ABLE TO OFFER SPONSORSHIP OR ACCOMMODATE ANY CANDIDATES THAT ARE CURRENLTY BEING SPONSORED NOW OR IN THE FUTURE', 'Experience with healthcare data', 'Strong knowledge of machine learning models and know their applicability and an understanding of their limitations\xa0', 'Experience with the design, implementation, and evaluation of statistical predictive models using large datasets', 'Experience with large-scale data processing technologies', 'Keep abreast of developments within machine learning and apply where appropriate', 'Strong knowledge of machine learning models and know their applicability and an understanding of their limitations\xa0MS or PhD in a relevant discipline (Math, Statistics, Computer Science or Engineering\xa0Experience with the design, implementation, and evaluation of statistical predictive models using large datasetsExpert familiarity with machine learning technologiesProficiency working in a Linux environment and software development in Python', 'Has work experience with building and maintaining big data and mastering techniques of parallel processing on big dataSeveral years of experience in advanced analyticsFamiliarity with the use of cloud computing platforms (e.g., Amazon Web Services)Experience with large-scale data processing technologiesExperience with healthcare data', 'We are seeking a talented Data Scientist with experience in statistical data analytics, working with advanced machine learning algorithms, and solving complex problems. We have built a web-based application that is supported by a large dataset of healthcare data, where various reports are made available to users that have results generated by a variety of machine learning algorithms.', 'Proficiency working in a Linux environment and software development in Python', 'Has work experience with building and maintaining big data and mastering techniques of parallel processing on big data', 'Basic Qualifications\xa0', 'Expert familiarity with machine learning technologies', 'Key Responsibilities', 'Several years of experience in advanced analytics', 'MS or PhD in a relevant discipline (Math, Statistics, Computer Science or Engineering\xa0', 'Execute analytical approaches to design, develop, and evaluate methodologies and advanced algorithms that result in the extraction of optimal value from data']",Associate,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,"Significance, Inc.","Arlington, VA",21 hours ago,25 applicants,"['', 'Active/Current DoD Secret Clearance (or higher);Bachelor’s Degree in IT/Computer Science/Finance/Accounting or similar;Data Analytics Certification;Must have 6 years of experience data mining and data analysis;Strong understanding of Excel, SQL, and R or Python;Preferred qualification: visualization experience with R and/or Tableau;Outstanding organizational skills, time management, and attention to detail;Strong analytical and problem-solving abilities.', 'Bachelor’s Degree in IT/Computer Science/Finance/Accounting or similar;', 'Open-door policy between employees and leadership to ensure direct lines of communication;', 'Coordinate with stakeholders across the Air Force to gain access and insights into key data sources needed for aircraft and manning initiatives;', 'Coordinate and engage with force development leadership, action officers, and other Air Force officials to brainstorm innovative ways to tell stories with data.', 'Significance.', 'Data Analytics Certification;', 'R or Python', '\ufeff***PLEASE NOTE - THIS ROLE WILL MOST LIKELY BE REMOTE UNTIL 2021 DUE TO COVID 19.***', 'Management team that is committed to your success and growth through mentorship, tuition assistance, and promotion opportunities;', 'Significance fosters a diverse, collaborative, and innovative culture;', 'Must have 6 years of experience data mining and data analysis;', 'data analysis', 'Desired Skills & Experience: ', 'Strong understanding of Excel, SQL, and R or Python;', 'Iterate current and develop new compelling visuals and dashboards, enabling leadership to make insight driven decisions about the Air Force maintenance force and aircraft;', 'Significance Inc,', 'data mining', 'Significance fosters a diverse, collaborative, and innovative culture;Management team that is committed to your success and growth through mentorship, tuition assistance, and promotion opportunities;Open-door policy between employees and leadership to ensure direct lines of communication;Leadership understands the importance of striking a work/life balance.', 'Leadership understands the importance of striking a work/life balance.', 'Why Significance?', 'Preferred qualification: visualization experience with R and/or Tableau;', 'Lead the aggregation, cleansing, and manipulation of manpower and aircraft data to provide quantitative analyses to support initiative recommendations;', 'SQL', 'Significance Inc. is looking for a Data Scientist to join the Financial Improvement Audit Readiness (FIAR) Team for the Air Force in Rosslyn. The right candidate will have six years of experience of data mining, data analysis and a strong knowledge of Excel, SQL, and R or Python. The ideal candidate will also have an active or current DoD security clearance. If you do not have a clearance, you will not be considered for the position.', 'Data Scientist', 'Excel', 'Significance Inc, a management consulting firm providing innovative solutions and best practices to government and commercial organizations recently received the Best Places to Work in Greater Washington by the #WashingtonBusinessJournal for the second year in a row. Join us at Significance.', 'Active/Current DoD Secret Clearance (or higher);', 'Lead the aggregation, cleansing, and manipulation of manpower and aircraft data to provide quantitative analyses to support initiative recommendations;Coordinate with stakeholders across the Air Force to gain access and insights into key data sources needed for aircraft and manning initiatives;Iterate current and develop new compelling visuals and dashboards, enabling leadership to make insight driven decisions about the Air Force maintenance force and aircraft;Coordinate and engage with force development leadership, action officers, and other Air Force officials to brainstorm innovative ways to tell stories with data.', 'Strong analytical and problem-solving abilities.', 'Outstanding organizational skills, time management, and attention to detail;', 'Responsibilities: ']",Associate,Full-time,Analyst,Management Consulting,2020-11-05 11:32:32
Data Scientist,Appen,"Plano, TX",22 hours ago,54 applicants,"['', ' Ability to translate analysis results into business recommendations, and excellent written and verbal communication skills. ', ' Passionate about learning new skills and technologies. ', ' Explore and operationalize the use of scoring such as inter-rater reliability, precision and recall, confusion matrices, etc. ', ' Design and prepare periodic and ad hoc reports, presentations, and exploratory analysis that are designed to use raw data to provide key insights to members of the Client Services organization. ', 'You Are', ' Flexible, independent, motivated self-starter who can establish a course of action for self and others and drive initiatives to completion. ', ' Experience with statistical and machine learning methods, including the full modelling lifecycle. ', ' a thought leader with a mission to drive efficiencies and improve processes that result in higher quality data delivered to our Clients. ', ' Exceptional time management and organizational skills with acute attention to detail. ', ' Innovative thinker who drives self and others in the development and implementation of new ideas; unafraid of taking risks to accomplish corporate level goals. ', ' Interest and aptitude in data, metrics, analysis and trends and applied knowledge of measurement, statistics and program evaluation. ', 'Required Knowledge, Skills And Abilities', 'Qualifications', ' Able to effectively coach and train peers and team members. ', ' Consolidate, cleanse and transform data to prepare for reporting and analyses.  Explore and operationalize the use of scoring such as inter-rater reliability, precision and recall, confusion matrices, etc.  Design and prepare periodic and ad hoc reports, presentations, and exploratory analysis that are designed to use raw data to provide key insights to members of the Client Services organization.  Work side-by-side with the client teams, advise on strategy optimization, and seek improved methods and processes for assessing the quality of data utilized both internally and delivered to customers.  Where necessary, complete additional tasks as assigned. ', ' Consolidate, cleanse and transform data to prepare for reporting and analyses. ', ' Demonstrated ability to make difficult decisions by researching and carefully weighing all options. ', ' Experience managing client relationships with a demonstrated focus on delivering high level customer service and quality improvement. ', ' a truth seeker. You ask why, and you question every assumption. You probe assumptions, question the status quo, and follow up on unexpected data results.  a thought leader with a mission to drive efficiencies and improve processes that result in higher quality data delivered to our Clients. ', ' Work side-by-side with the client teams, advise on strategy optimization, and seek improved methods and processes for assessing the quality of data utilized both internally and delivered to customers. ', ' Experience with business intelligence tools such as Tableau, PowerBI or Mode Analytics.', ' Experience with statistical and machine learning methods, including the full modelling lifecycle.  Interest and aptitude in data, metrics, analysis and trends and applied knowledge of measurement, statistics and program evaluation.  Ability to translate analysis results into business recommendations, and excellent written and verbal communication skills.  Flexible, independent, motivated self-starter who can establish a course of action for self and others and drive initiatives to completion.  Innovative thinker who drives self and others in the development and implementation of new ideas; unafraid of taking risks to accomplish corporate level goals.  Exceptional time management and organizational skills with acute attention to detail.  Passionate about learning new skills and technologies.  Experience managing client relationships with a demonstrated focus on delivering high level customer service and quality improvement.  Demonstrated ability to make difficult decisions by researching and carefully weighing all options.  Able to effectively coach and train peers and team members. ', ' Where necessary, complete additional tasks as assigned. ', ' Industry experience with statistical software (e.g., R, Python) and database languages (e.g., SQL). ', 'Position Summary : ', 'Key Responsibilities', ' a truth seeker. You ask why, and you question every assumption. You probe assumptions, question the status quo, and follow up on unexpected data results. ', ' Advanced degree in Business, Operation Research, Applied Mathematics, Statistics, or other Data Sciences; or an equivalent combination of education and 3+ years experience. ', ' Advanced degree in Business, Operation Research, Applied Mathematics, Statistics, or other Data Sciences; or an equivalent combination of education and 3+ years experience.  Industry experience with statistical software (e.g., R, Python) and database languages (e.g., SQL).  Experience with business intelligence tools such as Tableau, PowerBI or Mode Analytics.']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist/Machine Learning,Juniper Networks,"Cupertino, CA",5 hours ago,Be among the first 25 applicants,"['', ' Familiar with one or more machine learning or statistical modeling tools such as Numpy, ScikitLearn, MLlib, Tensorflow', 'Desired Experience:', ' Strong hands-on coding skills (preferably in Python) processing large-scale data set and developing machine learning models', ' 3+ years experiences building data science-driven solutions including data collection, feature selection, model training, post-deployment validation', ' Experience with AWS, S3, Flink, Spark, Kafka, ElasticSearch', ' Excellent understanding of machine learning techniques and algorithms, including clustering, anomaly detection, optimization, neural network etc', ' MS or PhD in Computer Science, Electrical Engineering, Statistics, Applied Math or equivalent fields with strong mathematical background', ' Good team worker with excellent communication skills written, verbal and presentation', ' Knowledge and experience with NLP technology', ' Previous work in a start-up environment', 'Qualifications/Requirements:']",Entry level,Full-time,Engineering,Computer & Network Security,2020-11-05 11:32:32
Data Scientist,Tata Consultancy Services,"Redmond, WA",23 hours ago,69 applicants,"['Mandatory Technical Skills', '', '• Build and maintain key predictive, regression, causal, time-series, optimization & \xa0\xa0customer segmentation, capacity constraint models.', 'Degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics, Operations Research, Management Science.', 'Prior knowledge of data modeling and processing techniques for big data systems', 'Experience working with unstructured big data (Hadoop and/or Cosmos)', '• Communicate final recommendations and drive decision making.', 'Desirable Functional Skills', 'Understand the internals of R and Python (Who can perform root cause analysis for the issues encountered in production)', 'Industry experience in Data Analytics/BI, Forecasting modeling and visualization, Optimization, and statistics.', 'Ability to influence diverse audiences and build strong partnerships with stakeholders', '• Work cross-functionally to define problem statements, collect data, find key insights, \xa0\xa0\xa0build analytical models, and make recommendations.', '5 or more years of overall IT/DBMS/Data Store experience.', '• Business reporting', '• Superior communication skills, both verbal and written', 'Self-motivated, agile and driven to think out-of-the-box', 'Good knowledge of Cloud Architecture (Public and Private Clouds) – AZURE, AWS', 'Solid understanding of BI and data solutions, including Power-pivots, cubes, and datamarts.', 'Data Scientist / Redmond, WA', 'Prior experience with cloud services or cloud data services and/or data analytics projects preferred - Platform knowledge (Azure, Windows, and Linux)', '• Ability to work independently or to manage a virtual team that will research innovative solutions to challenging business problems', '• Leverage tools like R, PHP, Python, Hadoop & Azure Data Bricks, ADF, ADLS, and Azure Analysis Service to drive efficient analytics.', 'Experts in advanced Excel functions (e.g., creating formulas, pivot tables) and PowerBI', 'Expert in querying and analyzing big data using Hive, Python, SQL, Scope and/or C#Experience working with unstructured big data (Hadoop and/or Cosmos)Experts in advanced Excel functions (e.g., creating formulas, pivot tables) and PowerBIPrior knowledge of data modeling and processing techniques for big data systemsSolid understanding of BI and data solutions, including Power-pivots, cubes, and datamarts.Self-motivated, agile and driven to think out-of-the-boxAbility to influence diverse audiences and build strong partnerships with stakeholders', 'Three or more years of experience in, big data, data caching, data federation and data virtualization management', 'Total Experience Required 7+ Years', 'Expert in querying and analyzing big data using Hive, Python, SQL, Scope and/or C#', '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0', '• Ability to collaborate with the team and drive analytic projects end to end,', '• Attention to detail and data accuracy', 'Degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics, Operations Research, Management Science.Hands-on experience in building machine learning models using algorithms such as K-Means, SVM, KNN, Tree-Based Methods as well as different forecasting techniques.Industry experience in Data Analytics/BI, Forecasting modeling and visualization, Optimization, and statistics.5+ years of Scripting with one of these languages (R, PYTHON).5 or more years of overall IT/DBMS/Data Store experience.Three or more years of experience in, big data, data caching, data federation and data virtualization managementUnderstand the internals of R and Python (Who can perform root cause analysis for the issues encountered in production)Prior experience with cloud services or cloud data services and/or data analytics projects preferred - Platform knowledge (Azure, Windows, and Linux)Good knowledge of Cloud Architecture (Public and Private Clouds) – AZURE, AWS', 'Key Responsibilities', '5+ years of Scripting with one of these languages (R, PYTHON).', 'GRS 161371', 'Hands-on experience in building machine learning models using algorithms such as K-Means, SVM, KNN, Tree-Based Methods as well as different forecasting techniques.']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist - Grimlock,ManTech,"Chantilly, VA",23 hours ago,Be among the first 25 applicants,"['', 'Must possess the required DoD Directive 8570.1 IAT Level II or higher certification', 'Experience with COTS technologies used in a Cybersecurity Engineering environment desiredStrong Windows experience is highly desired', 'Apply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvement', 'Secure our Nation, Ignite your Future', 'Generate and test hypotheses and analyze and interpret the results of product experiments', 'CentOS/Linux', 'AWS Cloud', 'Strong team player, capable of working collaboratively in customer teams', 'CentOS/LinuxAWS Cloud', 'The person in this position frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations', 'May provide work leadership to junior level employees', 'Produce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasets', 'Use a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the data', 'Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.', 'Preferred Qualifications', 'Previous experience using the following:CentOS/LinuxAWS Cloud', 'Support resilient applications design -applications that leverage more than one section of the cloud for residency and fault tolerance', 'Must be able to multi-task, work independently and as part of a team, share workloads, and deal with sudden shifts in project priorities', 'Basic Qualifications', 'Must be able to remain in a stationary position 50%Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.The person in this position frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations', 'Ability to make decisions and resolve problems effectively – seek out information and data to evaluate, prioritize and formulate best solution or practice', 'Security Clearance Requirements', 'Experience with COTS technologies used in a Cybersecurity Engineering environment desired', 'Support cloud automation scripting – AWS cloud automation scripting and service interaction', 'Strong Windows experience is highly desired', 'Support advanced cloud application architecture – experience in designing and implementing complex multi-component cloud application solutionsSupport resilient applications design -applications that leverage more than one section of the cloud for residency and fault toleranceSupport big data analytics – this is a broad field that includes machine learning, data curation, building data pipelines, etc.Provide Linux appliance maintenance – CentOS based Linux appliance managementSupport cloud automation scripting – AWS cloud automation scripting and service interactionSupport elastic stack operations and maintenance – this is specific to the Elastic stack more recent versions which include the machine learning and big data analytics applicationsProduce innovative solutions driven by exploratory data analysis from complex and high-dimensional datasetsApply knowledge of statistics, machine learning, programming, data modeling, simulation, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries leading to prototype development and product improvementUse a flexible, analytical approach to design, develop, and evaluate predictive models and advanced algorithms that lead to optimal value extraction from the dataGenerate and test hypotheses and analyze and interpret the results of product experimentsWork with product engineers to translate prototypes into new products, services, and features and provide guidelines for large-scale implementationMay provide work leadership to junior level employees', 'Support big data analytics – this is a broad field that includes machine learning, data curation, building data pipelines, etc.', 'TS/SCI w/ Poly', 'Responsibilities Include, But Are Not Limited To', 'Master’s Degree in Engineering, Computer Science, Information Technology, or Science, Technology, Engineering and Mathematics (STEM) related field with three years of experience or a Bachelor’s Degree in Engineering, Computer Science, Information Technology, or Science, Technology, Engineering and Mathematics (STEM) related field with at least five years of experience ', 'Excellent verbal and written communication skills', 'Support elastic stack operations and maintenance – this is specific to the Elastic stack more recent versions which include the machine learning and big data analytics applications', 'Must be able to remain in a stationary position 50%', 'Ability to effectively interact with various levels of senior management is necessary', 'Previous experience using the following:CentOS/LinuxAWS CloudExcellent verbal and written communication skillsStrong team player, capable of working collaboratively in customer teamsAbility to effectively interact with various levels of senior management is necessaryAbility to make decisions and resolve problems effectively – seek out information and data to evaluate, prioritize and formulate best solution or practiceMust be able to multi-task, work independently and as part of a team, share workloads, and deal with sudden shifts in project priorities', 'Support advanced cloud application architecture – experience in designing and implementing complex multi-component cloud application solutions', 'Provide Linux appliance maintenance – CentOS based Linux appliance management', 'Work with product engineers to translate prototypes into new products, services, and features and provide guidelines for large-scale implementation', 'Physical Requirements']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Machine Learning Data Scientist,Intel Corporation,"Santa Clara, CA",11 hours ago,Be among the first 25 applicants,"['', 'Job Description', 'Position of Trust', ' Natural language processing Neuro-symbolic AI Neural networks and deep learning Knowledge representation and reasoning Knowledge graphs Intelligent systems', 'Posting Statement', 'Qualifications', ' Knowledge graphs', 'Other Locations', ' Intelligent systems', 'Preferred Qualifications', ' Neural networks and deep learning', ' Neuro-symbolic AI', ' Knowledge representation and reasoning', 'Inside this Business Group', ' Natural language processing']",Associate,Full-time,Other,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Data Analyst,Public Health Institute,"Washington, DC",14 hours ago,Be among the first 25 applicants,"['', 'Assist USAID/HIV subject matter experts with data-focused analytical thinking for improved planning, monitoring, evaluation, and reporting of HIV/PEPFAR programs', ' Minimum Qualifications', ' Provide training and analytic support to strengthen HQ and Mission capacity to effectively manage and analyze PEPFAR data, including data stemming from data quality assessments and non-routine data activities for the purposes of program accountability, oversight, and management. Facilitate the sharing of best practices across USG programs vis-a-vis strategic information in different countries. Other duties as assigned Participate in professional continuing education, skills training and professional meetings to enhance relevant technical skills and career development Complete and execute an Individual Learning and Training Plan and Annual Work Plan ', 'Credence Management Solutions, LLC and Public Health Institute are Equal Opportunity Employers. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, or disability.', ' Clearance Required', ' Master’s degree and 5 years relevant experience or a Bachelor’s degree and 7 years of relevant experience or equivalent combination of education and experience. At least 5 years of professional experience with two or more public health or related technical disciplines such as data science; statistics; epidemiology; date analytics; HIV AIDS, etc) Demonstrated experience in and understanding of issues relating to HIV programming data in developing country context. Demonstrated skills in data analysis and visualization, strategic planning, monitoring systems, program coordination and implementation, and evaluation within a developing country context. Proficiency in statistical software (i.e. R (preferred), Stata, SAS, SPSS) and data visualization tools (i.e. Excel, Tableau (preferred), Power BI). Strategic thinker with a strong track record of taking a proactive approach to problem identification and solution. Demonstrated ability to multitask in a variety of projects/tasks at a time. Must have excellent analytical, written and oral communication skills. Willingness to travel internationally up to 30%. S. citizenship or U.S. permanent residency with the ability to obtain and maintain Facility Access required. ', ' Essential Duties & Responsibilities', ' Summary Statement', 'Provide SI-related technical assistance for programs at the country-level, and support for program evaluation to ensure USG investments reflect the efficient use of resources.', 'Support monitoring and evaluation through data analyses and visualization (including GIS, Tableau) across the HIV clinical cascade and other areas of HIV programming, including triangulation of survey, surveillance, and other non-routine country data sources as appropriate.', 'Facilitate the sharing of best practices across USG programs vis-a-vis strategic information in different countries.', 'Strategic thinker with a strong track record of taking a proactive approach to problem identification and solution.', 'Willingness to travel internationally up to 30%.', 'Support OHA country Points of Contact (POCs) and Missions to conduct and integrate analyses of USAID program data with relevant HIV epidemiological data and other data sources to advance their description of program performance through visual analytics and customized graphics that describe how they are reaching and sustaining epidemic control.', 'Maintain in-depth knowledge of PEPFAR reporting requirements, PEPFAR-related data systems, data use strategies in order to provide informed program quality and partner performance improvement.', ' Conduct complex data analyses and provide technical assistance relevant to Measurement, Evaluation, and Results (MER), program expenditures, Site Improvement through Monitoring System (SIMS), and Surveys, Research and Evaluation (SREs). Conduct trend analysis of PEPFAR program data and partner performance and provide data visualization support, including but not limited to integrated analysis of data on results, service quality, and expenditures across OUs, partners and technical areas. Maintain in-depth knowledge of PEPFAR reporting requirements, PEPFAR-related data systems, data use strategies in order to provide informed program quality and partner performance improvement. Collaboration with program/technical stakeholders to facilitate interpretation and dissemination of HIV-related data, analytic products and evidence for program decision making. Assist USAID/HIV subject matter experts with data-focused analytical thinking for improved planning, monitoring, evaluation, and reporting of HIV/PEPFAR programs Support monitoring and evaluation through data analyses and visualization (including GIS, Tableau) across the HIV clinical cascade and other areas of HIV programming, including triangulation of survey, surveillance, and other non-routine country data sources as appropriate. Design, develop and deliver high-quality visualization and information products to support USAID operations at all stages of the development programming cycle. Translate complex data analysis concepts and requirements into clear, digestible, and useable information for both technical and non-technical USAID/PEPFAR team members. Contribute to the HIV knowledge base by preparing reports and publications, including, but not limited to, technical updates for field missions, peer-reviewed manuscripts, and by presenting internally and at international meetings/conferences, as needed. ', ' Facility Access Clearance ', 'Contribute to the HIV knowledge base by preparing reports and publications, including, but not limited to, technical updates for field missions, peer-reviewed manuscripts, and by presenting internally and at international meetings/conferences, as needed.', 'Provide training and analytic support to strengthen HQ and Mission capacity to effectively manage and analyze PEPFAR data, including data stemming from data quality assessments and non-routine data activities for the purposes of program accountability, oversight, and management.', 'At least 5 years of professional experience with two or more public health or related technical disciplines such as data science; statistics; epidemiology; date analytics; HIV AIDS, etc)', 'Facility Access Clearance', 'Demonstrated experience in and understanding of issues relating to HIV programming data in developing country context.', ' Job Requirements', 'Position Identification', 'Conduct analyses on and/or compile data related to PEPFAR data quality assessments, root cause analyses, Surveys, Research and Evaluation (SRE) for program and technical stakeholders at USAID Missions and OHA', 'Technical Support and Analytic Services (45% Level of Effort):', 'Demonstrated skills in data analysis and visualization, strategic planning, monitoring systems, program coordination and implementation, and evaluation within a developing country context.', 'Conduct trend analysis of PEPFAR program data and partner performance and provide data visualization support, including but not limited to integrated analysis of data on results, service quality, and expenditures across OUs, partners and technical areas.', 'Master’s degree and 5 years relevant experience or a Bachelor’s degree and 7 years of relevant experience or equivalent combination of education and experience.', 'The Primary Duties Of The Data Analyst Include', 'Design, develop and deliver high-quality visualization and information products to support USAID operations at all stages of the development programming cycle.', 'Demonstrated ability to multitask in a variety of projects/tasks at a time.', 'Translate complex data analysis concepts and requirements into clear, digestible, and useable information for both technical and non-technical USAID/PEPFAR team members.', 'S. citizenship or U.S. permanent residency with the ability to obtain and maintain Facility Access required.', 'Proficiency in statistical software (i.e. R (preferred), Stata, SAS, SPSS) and data visualization tools (i.e. Excel, Tableau (preferred), Power BI).', 'Capacity Building, Strategic Planning, and Support (10% Level of Effort):', 'Please note: The Public Health Institute (PHI) and its partner, Credence Management Solutions, are both employers for the Global Health Technical Professionals (GHTP) project which provides expertise in support of USAID global health programs. The hiring of this position will be through the PHI and as such the selected person will become a PHI employee. Your applicant data will be shared with both organizations.', ' Support OHA country Points of Contact (POCs) and Missions to conduct and integrate analyses of USAID program data with relevant HIV epidemiological data and other data sources to advance their description of program performance through visual analytics and customized graphics that describe how they are reaching and sustaining epidemic control. Conduct analyses on and/or compile data related to PEPFAR programs, expenditures, and surveys, and HIV epidemiologic data for key deliverables and reports for program and technical stakeholders at USAID Missions and OHA Conduct analyses on and/or compile data related to PEPFAR data quality assessments, root cause analyses, Surveys, Research and Evaluation (SRE) for program and technical stakeholders at USAID Missions and OHA Strengthen the capacity of Mission staff to analyze and synthesize country-specific data in order to facilitate communication and guide decision-making on program performance and strategic planning. Provide SI-related technical assistance for programs at the country-level, and support for program evaluation to ensure USG investments reflect the efficient use of resources. ', 'Complete and execute an Individual Learning and Training Plan and Annual Work Plan', 'Participate in professional continuing education, skills training and professional meetings to enhance relevant technical skills and career development', 'Strengthen the capacity of Mission staff to analyze and synthesize country-specific data in order to facilitate communication and guide decision-making on program performance and strategic planning.', 'This position described in this announcement falls under a contract with USAID, and therefore is subject to the provisions put forward in OMB Circular A-76 which prohibit contractors from performing inherently governmental functions. Specifically, TPs placed in USAID positions will not perform inherently governmental functions, nor supervise any employees other than the contractor’s own staff, nor make final decisions or sign documents that commit the U.S. Government.', 'Must have excellent analytical, written and oral communication skills.', 'Conduct complex data analyses and provide technical assistance relevant to Measurement, Evaluation, and Results (MER), program expenditures, Site Improvement through Monitoring System (SIMS), and Surveys, Research and Evaluation (SREs).', 'Technical Assistance to the Field (45% Level of Effort):', 'Other duties as assigned', 'Collaboration with program/technical stakeholders to facilitate interpretation and dissemination of HIV-related data, analytic products and evidence for program decision making.', 'Conduct analyses on and/or compile data related to PEPFAR programs, expenditures, and surveys, and HIV epidemiologic data for key deliverables and reports for program and technical stakeholders at USAID Missions and OHA']",Entry level,Full-time,Information Technology,Nonprofit Organization Management,2020-11-05 11:32:32
Quantitative Researcher ,EvolveAI,"New York, United States",,N/A,"['', 'Combine quantitative processes with fundamental insights to identify industry key performance indicators, develop sector-specific signals, build conviction on a call, predict stock returns, and track company-specific risks etc.', 'Strong verbal and written communication skills; able to present quant solutions clearly to both internal and external clients', 'Required criteria:', 'EvolveAI has been retained by a leading institutional investor to help build its Quantitative Research team based in New York/Remote. Our client is looking for a talented Quant Researcher who is well versed in Alternative Data to conduct innovative quantamental research by working with the equity analyst teams.', '3-5 years’ experience in statistics/econometrics modeling, proficiency working with a large dataset, machine learning, data mining, and numerical methods', 'Combine quantitative processes with fundamental insights to identify industry key performance indicators, develop sector-specific signals, build conviction on a call, predict stock returns, and track company-specific risks etc.Develop, backtest, and implement statistics/machine learning models to test the efficacy of sector data; Explore, and evaluate alternative data to gain insights into new alphaHelp build out and expand our data and quant framework. Develop tools to load, process, clean, query, analyze data, and work closely with the technology team to ensure data quality and manage data processActively source new ideas and collaborate with other research teams; Partner closely with sales/marketing, providing quant proof statements to both internal and external clients', 'Strong creative thinking and problem-solving skills; able to decompose complex problems into manageable pieces', 'Help build out and expand our data and quant framework. Develop tools to load, process, clean, query, analyze data, and work closely with the technology team to ensure data quality and manage data process', 'New York', '$150k - $200k', 'Role Responsibilities:', 'Develop, backtest, and implement statistics/machine learning models to test the efficacy of sector data; Explore, and evaluate alternative data to gain insights into new alpha', 'Advanced degree in quantitative field such as statistics, computer science, engineering, mathematics or finance, PhD preferred', 'Quant Researcher - Alt Data', 'Actively source new ideas and collaborate with other research teams; Partner closely with sales/marketing, providing quant proof statements to both internal and external clients', 'Strong programming skills including Python, C/C++, R, and scripting languages', 'Experience working with database, web-scraping, or dealing with alternative data a major plus', 'Advanced degree in quantitative field such as statistics, computer science, engineering, mathematics or finance, PhD preferred3-5 years’ experience in statistics/econometrics modeling, proficiency working with a large dataset, machine learning, data mining, and numerical methodsStrong programming skills including Python, C/C++, R, and scripting languagesExperience working with database, web-scraping, or dealing with alternative data a major plusStrong creative thinking and problem-solving skills; able to decompose complex problems into manageable piecesStrong verbal and written communication skills; able to present quant solutions clearly to both internal and external clients']",Mid-Senior level,Full-time,Information Technology,Staffing and Recruiting,2020-11-05 11:32:32
Data Scientist,Dataiku,"New York, NY",19 hours ago,123 applicants,"['', 'Exposure to the latest, open source technologies that Dataiku integrates', 'Provide data science expertise to customers and internally to Dataiku’s sales, marketing teams', 'Exposure to a wide range of enterprise customers across industries. Examples of Dataiku’s hundreds of customers include GE, Unilever, Comcast, Ubisoft, OVH, Santander, and Capgemini', 'Just as the non-technical skills are important, so too are the technical. Our Data Scientists work in the DSS platform every day. Aside from the visual tools of DSS, our team uses mostly python, with occasional work in other languages (e.g., R, SQL, pyspark, JavaScript, etc.). An ideal candidate is comfortable learning complex new technologies and modeling techniques while being able to explain their work to other data scientists and clients.', 'The role of a Data Scientist at Dataiku is quite unique; our Data Scientists not only code up solutions to real-world problems, but also participate in client-facing endeavors throughout the customer journey: supporting their discovery of the platform, helping integrate DSS with other tools and technologies, training users, and co-developing data science projects from design to deployment.', 'You may be a good fit for the role if you have:', 'Familiarity with data visualization in python, R, and/or JavaScript', 'To fulfill its mission, Dataiku is growing fast! In 2019, we achieved unicorn status, went from 200 to 400 people and opened new offices across the globe. Spanning from Sydney to Frankfurt, Denver to London, geography doesn’t stop Dataikers from working closely together and sharing experiences. Collaboration is key within our product and culture. We strive to create a sense of belonging and community while fostering diverse thinking by encouraging cross-team, cross-office interactions like our annual company offsite or Paris onboarding. Fly over to\xa0Twitter,\xa0LinkedIn, and\xa0Instagram\xa0to read stories about our culture, people, and success.\xa0', 'Curiosity and a desire to learn new topics and skillsEmpathy for others and an eagerness to share your knowledge and expertise with your colleagues, Dataiku’s customers, and the general publicThe ability to clearly explain complex topics to technical as well as non-technical audiences1-3 years of experience with python or R1-3 years of experience with machine learningFamiliarity with data visualization in python, R, and/or JavaScriptFamiliarity with relational data structures and/or SQL.', '1-3 years of experience with python or R', 'Analyze and investigate various kinds of data and machine learning applications across industries and use cases', 'Dataiku allows enterprises to create value with their data in a human-centered way while breaking down silos and encouraging collaboration. One of the most unique characteristics of our product, Data Science Studio (DSS), is the breadth of its scope and the fact that it caters both to technical and non-technical users. Through DSS, we aim to empower people through data and democratize data science.', 'Curiosity and a desire to learn new topics and skills', '1-3 years of experience with machine learning', 'Trips to Paris (our European HQ) and other locations worldwide for company-wide and team summits', 'Technical skills that may help you in the role:', 'Experience with PySpark, SparkR, or Scala', 'Co-develop production-level data science projects with our customers', 'Experience developing WebApps in Javascript, RShiny, or Dash', 'Benefits:', 'The ability to clearly explain complex topics to technical as well as non-technical audiences', 'Experience with or passion for teaching and/or public speaking.', 'Competitive compensation package, equity, health benefits, and paid vacation', 'Experience using cloud products and services from AWS, GCP, Azure, and/or Kubernetes', 'Exposure to a wide range of enterprise customers across industries. Examples of Dataiku’s hundreds of customers include GE, Unilever, Comcast, Ubisoft, OVH, Santander, and CapgeminiA wide diversity of projects and tasks ensures that no two days will be alikeOpportunity to contribute to the core vision of our company and product: simplify and democratize the way people work with data and use Artificial IntelligenceExposure to the latest, open source technologies that Dataiku integratesSee our release notes for our latest developments:\xa0https://doc.dataiku.com/dss/latest/release_notes/index.htmlCompetitive compensation package, equity, health benefits, and paid vacationTrips to Paris (our European HQ) and other locations worldwide for company-wide and team summitsOpportunity to work with a smart, passionate and driven team in hypergrowth modeDataiku has a strong culture based on key values: Transparency, Ambition, Excellence, Humility, and Empathy.', 'Empathy for others and an eagerness to share your knowledge and expertise with your colleagues, Dataiku’s customers, and the general public', 'Opportunity to work with a smart, passionate and driven team in hypergrowth mode', 'Develop custom python or R-based “plugins” in collaboration with R&D and product teams, to enhance DSS’s functionality.', 'Co-develop production-level data science projects with our customersAnalyze and investigate various kinds of data and machine learning applications across industries and use casesHelp users discover and master the Dataiku platform, DSS, via user trainings, office hours, and ongoing consultative supportProvide data science expertise to customers and internally to Dataiku’s sales, marketing teamsDevelop custom python or R-based “plugins” in collaboration with R&D and product teams, to enhance DSS’s functionality.', 'A wide diversity of projects and tasks ensures that no two days will be alike', ""In this role, you'll help the team:"", 'Familiarity with relational data structures and/or SQL.', 'Our practices are rooted in the idea that everyone should be treated with dignity, decency and fairness. Dataiku also believes that a diverse identity is a source of strength and allows us to optimize across the many dimensions that are needed for our success. Therefore, we are proud to be an equal opportunity employer.\xa0All employment practices are based on business needs, without regard to race, ethnicity, gender identity or expression, sexual orientation, religion, age, neurodiversity, disability status, citizenship, veteran status or any other aspect which makes an individual unique or protected by laws and regulations in the locations where we operate. This applies to all policies and procedures related to recruitment and hiring, compensation, benefits, performance, promotion and termination and all other conditions and terms of employment.', 'See our release notes for our latest developments:\xa0https://doc.dataiku.com/dss/latest/release_notes/index.html', 'Experience with PySpark, SparkR, or ScalaExperience developing WebApps in Javascript, RShiny, or DashExperience building APIsExperience using cloud products and services from AWS, GCP, Azure, and/or KubernetesExperience with or passion for teaching and/or public speaking.', 'Experience building APIs', 'Help users discover and master the Dataiku platform, DSS, via user trainings, office hours, and ongoing consultative support', 'Opportunity to contribute to the core vision of our company and product: simplify and democratize the way people work with data and use Artificial Intelligence', 'Dataiku’s promise to our customers is to provide them with the software and support needed to accelerate their data science and machine learning maturity. Dataiku’s Data Science team is responsible for delivering on that promise. Internally, we call the team the DataFab — ask us about it!', 'Dataiku has a strong culture based on key values: Transparency, Ambition, Excellence, Humility, and Empathy.']",Associate,Full-time,Consulting,Computer Software,2020-11-05 11:32:32
Data Scientist (Marketing Insights),MadHive,"New York, NY",2 hours ago,27 applicants,"['', 'Food All Day:\xa0Fully stocked refrigerator, and lunch provided everyday!', '\ufeffThe Perks!', 'Commuter Benefits:\xa0Madhive offers Wageworks commuter benefits. Plus, we’re centrally located just a couple blocks from New York City’s Penn Station.\xa0', 'ABOUT MADHIVE:', 'Responsibilities:', 'Unlimited Vacation:\xa0We offer Unlimited PTO, plus additional paid company holidays.', 'The key goal for this person will be to apply modeling techniques relevant to media mix modeling (MMM) optimization and multi-touch attribution (MTA) to our marketing efforts to connect the impact of marketing activities on business outcomes.', 'Build prototypes and MVPs of services and applications that improve effectiveness of campaigns, creatives, ad networks and/or user segments.', 'MadHive is a dynamic, diverse, innovative and friendly place to work. We embrace our differences and believe they fuel our creativity. We come from varied backgrounds and think that’s important. But whether it’s taking ideas from previous lives and applying them in different ways or creating something completely new, we are all trail-blazing team players who think big and want to make an impact.\xa0', 'Build and deploy models that enable marketers to allocate budgets to various channels in order to drive cross-channel optimization by product and by business objectives.', 'Media and advertising experience is a Plus!', 'Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.', 'Provide insights and suggestions on customer campaign optimization problems and product/platform optimization problems through statistical data analysis when needed.', 'Health, Dental & Vision Insurance:\xa0Your health is number 1, so we offer 100% company-paid health, dental, and vision insurance starting on day 1, \u200bwith additional plan options available with minimal employee contribution.', 'Develop models that drive personalization for member interactions on owned and paid marketing channels.', 'We’re looking for someone with 5-7 years of experience manipulating data sets and building statistical models, has a Master’s or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with cloud software/tools in GCP.', 'Here are just some of the many benefits of becoming a MadHive employee:', 'Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.Knowledge\xa0of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.', 'Experience using statistical computer languages ( Python, SQL.) to manipulate data and draw insights from large data sets.', 'Self-starter, and unafraid of ambiguous goals, worked or have experience in a start-up like organization, where structure is continuously defined and valued\xa0Self-motivated and able to take initiative without needing a high level of supervisionExperience visualizing/presenting data for stakeholders using: Business Objects, D3, ggplot,\xa0etc.', ""MadHive is an end-to-end advertising solution that leverages cryptography, blockchain and AI to power modern media. MadHive's advertising suite provides tools for audience forecasting, precision targeting and activation, and cross-screen attribution against its proprietary OTT-first device graph. Customers include advertisers that leverage MadHive's next-generation cryptography to prevent fraud and increase margins, and broadcast giants that leverage the platform to power their digital TV offerings."", 'Parental Leave:\xa0We believe that family comes first, so we provide parental leave to all new parents.\xa0']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Data Scientist,Netskope,"Seattle, WA",17 hours ago,27 applicants,"['', 'Mining data from primary and secondary sources, then reorganizing the data in a format that can be easily read by either human or machine.', 'Great team player who has a strong desire to change the way people use their data and have a huge impact on a small team', 'Collaborating with programmers, engineers, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance.', 'About This Role', 'Excellent communication and presentation skills', 'Education', 'Data Scientist ', 'Core skills: SQL, R, or Python', 'Experience with Big Data e.g. Hadoop, MapR', ' Mining data from primary and secondary sources, then reorganizing the data in a format that can be easily read by either human or machine. Using statistical tools to interpret data sets, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts. Preparing reports for executive leadership that effectively communicate trends, patterns, and predictions using relevant data. Collaborating with programmers, engineers, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance. Creating appropriate documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary. ', 'Working knowledge of NoSQL databases e.g. MongoDB', 'Using statistical tools to interpret data sets, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts.', ' BSCS or equivalent required, MSCS or equivalent strongly preferred', 'Required Skills', 'Responsibilities Include', 'BSCS or equivalent required, MSCS or equivalent strongly preferred', 'Creating appropriate documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary.', 'Preparing reports for executive leadership that effectively communicate trends, patterns, and predictions using relevant data.', 'About Netskope', ' Core skills: SQL, R, or Python Working knowledge of NoSQL databases e.g. MongoDB Experience with Big Data e.g. Hadoop, MapR Excellent communication and presentation skills Great team player who has a strong desire to change the way people use their data and have a huge impact on a small team ']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist  (100% Remote ),Macy's,Atlanta Metropolitan Area,18 hours ago,68 applicants,"['', 'BA/BS Degree required (MS or PhD preferred).', 'Familiarity with modern approaches to computer vision problems is a plus (RESNet, transfer learning, Inception, etc.)', 'Experience with building systems from scratch, and putting them into production, and performing A|B Testing', 'Familiarity with Agile, experience with Agile is a plus', 'Lead research initiatives into state-of-the-art methodologies that will enhance current models and power future personalized models', 'Strong preference for hands-on experience with Scikit-learn, Pandas,\xa0\xa0and at least one of the deep learning frameworks: PyTorch, Keras, or\xa0\xa0TensorFlow', 'Education/Experience:', '\xa0', 'Lead and work with ML engineers and data scientists to develop recommendation system using advanced machine learning techniques such as deep learning and reinforcement learning.', 'Essential Functions:', '8+ years of hands on industry experience in leveraging data science (including ML) and analytics to solve business problems(preferably ecommerce)', 'A plus to have working knowledge of Google Cloud Platform (Big Query, Big Table, Pub/Sub, DataFlow, DataProc), real-time and batch processing', ""Macy's is looking for a passionate, talented, and innovative Lead Data Scientist with a strong machine learning background to help build industry-leading AI/ML enabled applications for retail/commerce platform. As Lead Data Scientist you can be part of the team shaping the future of retail/commerce, revolutionize how millions of customer shop online, store and other channels, you'll partner with technology and business teams to build new AI/ML enabled smart services that surprise and delight our customers. You will be working with big data (text, images, audio & other) to solve real-world problems for customers & partners. You will design and run experiments, research new AI/ML algorithms & techniques, and find new ways of optimizing risk, opportunities, profitability, and customer experience. As a Lead Data Scientist your work involves performing applied ML in the areas of feature engineering, deep learning, machine learning, data insights and analytics. Our ML applications include computer vision, search and discovery systems, recommender systems, and more. Successful candidate will work on heterogeneous data sets (behavioral, transaction and click stream data) and focuses on solving applied problems using Machine Learning. The ideal candidate will have a nice blend of applied math, data science and engineering skills, proven track record of solving critical business problems through data science and strong analytical/quantitative and engineering skills.\xa0The candidate will be expected to be strong at communication and capable of cross group collaborations. As a Lead Data Scientist, you will work on smart services that improve our operations and customer experience. You will marry state-of-art AI/ML algorithms with distributed systems engineering to build systems that drive efficiencies & improve customer engagement in our retail/commerce platform. Perform other duties as assigned."", 'Extensive experience in Python and SQL(Nice to have Scala)', 'Work with business stakeholders to define business requirements including KPI and acceptance criteria.', 'Collaborate with data engineers, ML engineers and Data Scientists in building real-time and batch machine learning pipelines that include data preprocessing, feature engineering, model training, model validation, serving, and evaluating results of A/B test.', 'Drive work on improving the codebase and machine learning lifecycle infrastructure', 'Experience in leading teams and being a lead data scientist on large scale projects driving value for the business', 'Experience with Machine Learning orchestration frameworks (Kubeflow, Airflow, MLflow)', 'Qualifications:', 'Mentoring and growing talent, as well as hiring, will be a critical part of the job\xa0', 'Thought leader in data science and analytics who\xa0can help the business define their business problem, create solutions to address it, plan and execute the implementationWork with business stakeholders to define business requirements including KPI and acceptance criteria.Lead and work with ML engineers and data scientists to develop recommendation system using advanced machine learning techniques such as deep learning and reinforcement learning.Lead research initiatives into state-of-the-art methodologies that will enhance current models and power future personalized modelsCollaborate with data engineers, ML engineers and Data Scientists in building real-time and batch machine learning pipelines that include data preprocessing, feature engineering, model training, model validation, serving, and evaluating results of A/B test.Drive work on improving the codebase and machine learning lifecycle infrastructureMentoring and growing talent, as well as hiring, will be a critical part of the job\xa0', '5+ years of industry experience in Machine Learning or related field.', 'Strong preference for programming experience in Spark framework and PySpark.', 'Thought leader in data science and analytics who\xa0can help the business define their business problem, create solutions to address it, plan and execute the implementation', 'BA/BS Degree required (MS or PhD preferred).8+ years of hands on industry experience in leveraging data science (including ML) and analytics to solve business problems(preferably ecommerce)5+ years of industry experience in Machine Learning or related field.Experience in leading teams and being a lead data scientist on large scale projects driving value for the businessExtensive experience in Python and SQL(Nice to have Scala)Strong preference for programming experience in Spark framework and PySpark.Strong preference for hands-on experience with Scikit-learn, Pandas,\xa0\xa0and at least one of the deep learning frameworks: PyTorch, Keras, or\xa0\xa0TensorFlowFamiliarity with modern approaches to computer vision problems is a plus (RESNet, transfer learning, Inception, etc.)Experience with different recommender systems(Sequential recommenders, Content recommenders, RL recommenders etc.) and recommender frameworks(Ex : PredictionIO)Experience with building systems from scratch, and putting them into production, and performing A|B TestingA plus to have working knowledge of Google Cloud Platform (Big Query, Big Table, Pub/Sub, DataFlow, DataProc), real-time and batch processingExperience with Machine Learning orchestration frameworks (Kubeflow, Airflow, MLflow)Familiarity with Agile, experience with Agile is a plus', 'Experience with different recommender systems(Sequential recommenders, Content recommenders, RL recommenders etc.) and recommender frameworks(Ex : PredictionIO)']",Director,Full-time,Engineering,Retail,2020-11-05 11:32:32
Data Scientist,Anchor Loans LP,"Thousand Oaks, CA",20 hours ago,34 applicants,"['', 'Experience writing and optimizing SQL', 'Experience with AWS data technologies such as Redshift, S3, Data Pipeline', 'Proficient in either Python and R', 'Analyze our existing data model/structure and provide recommendations to the Tech team for optimization to support our data strategy', 'Knowledge of machine learning frameworks and toolsets', 'Explain data analytics and data science findings and machine learning models to internal and external stakeholders', 'Expert level SQL experience; deep experience with statistical packages such as Python and R.', 'Preferred Qualifications', 'Experience with MS PowerBI', 'Ability to provide guidance to other program and project managers', '\xa0B.S. or M.S. in computer science, Mathematics, Statistics, Physics, Economics or equivalent experience', 'Responsibilities', '4+ years of industry experience in data analytics', 'Ability to resolve conflicts and negotiate agreement', '4+ years of industry experience in predictive analysis and modeling, data analysis and science', '\xa0', 'Work with Data Analysts, Product Managers and Software Engineers to gather data insight requirements, set goals and influence the product roadmap', 'Ability to translate business problems into data questions, create solutions and drive results', 'Experience building ML models', 'Experience using ML libraries', 'Experience presenting data findings', 'Ability to aggregate and analyze data from multiple data sources and build a holistic view', 'Ability to think critically', 'Ability to proactively identify impediments in project/program delivery and craft solutions', '\xa0B.S. or M.S. in computer science, Mathematics, Statistics, Physics, Economics or equivalent experience4+ years of industry experience in predictive analysis and modeling, data analysis and science3+ years of industry experience in data analyticsKnowledge of data engineering, database architecture and ETL processExperience building ML modelsProficient in either Python and RExperience using ML librariesKnowledge of machine learning frameworks and toolsetsExperience writing and optimizing SQLExperience using data visualization toolsExperience presenting data findings', 'Ability to think criticallyAbility to translate business problems into data questions, create solutions and drive resultsAbility to aggregate and analyze data from multiple data sources and build a holistic viewAbility to build clear visualizations to explain complex ideas and analysis result to executives and business unit leadersAbility to provide guidance to other program and project managersAbility to resolve conflicts and negotiate agreementAbility to proactively identify impediments in project/program delivery and craft solutions', '6+ years of industry experience in predictive analysis and modeling, data analysis and science', 'Proven ability to tackle business problems with data science solutions', 'Ability to build clear visualizations to explain complex ideas and analysis result to executives and business unit leaders', 'We are constantly improving processes and efficiencies for our operations staff.\xa0The\xa0primary focus of this position is to be an integrated quality resource for project\xa0teams on our biggest products. Anchor is an entrepreneurial company and this\xa0position will have significant impact on the future of the business and its technology\xa0solutions as we grow and expand our operations nationwide.', 'Skills and Competencies', '\xa0Deliver on data analytics and insights by planning and performing end-to-end analysis: including aggregating and processing data, exploring data, building and validating predictive models, and presenting to business', 'Ability to develop analytic plans for data modeling process', 'Knowledge of data engineering, database architecture and ETL process', 'Ability to accurately determine correlations', '\xa0Minimum Qualifications', ""Understand business stakeholders' needs and translate those into a data insights program with solutions for each stakeholder"", 'Experience using data visualization tools', ""Understand business stakeholders' needs and translate those into a data insights program with solutions for each stakeholder\xa0Deliver on data analytics and insights by planning and performing end-to-end analysis: including aggregating and processing data, exploring data, building and validating predictive models, and presenting to businessAnalyze our existing data model/structure and provide recommendations to the Tech team for optimization to support our data strategyDesign and implement statistical algorithms and predictive analysisExplain data analytics and data science findings and machine learning models to internal and external stakeholdersWork with Data Analysts, Product Managers and Software Engineers to gather data insight requirements, set goals and influence the product roadmap"", '3+ years of industry experience in data analytics', 'Design and implement statistical algorithms and predictive analysis', 'Anchor Loans, LP is subject to the California Consumer Privacy Act of 2018 (“CCPA”). A copy of Anchor’s California Privacy Policy can be found at\xa0www.anchorloans.com/privacy.', 'PhD in computer science, Mathematics, Statistics, Physics, Economics, Bio-Engineering/Science field', 'Duties include but are not limited to:', 'At the core of our company is our proprietary technology.\xa0We are seeking a Data Scientist to join the quickly expanding Technology Operations team.\xa0The goal of the\xa0department is to solve business needs through our proprietary technology solutions.', 'PhD in computer science, Mathematics, Statistics, Physics, Economics, Bio-Engineering/Science field6+ years of industry experience in predictive analysis and modeling, data analysis and science4+ years of industry experience in data analyticsProven ability to tackle business problems with data science solutionsExpert level SQL experience; deep experience with statistical packages such as Python and R.Ability to develop analytic plans for data modeling processAbility to accurately determine correlationsExperience with AWS data technologies such as Redshift, S3, Data PipelineExperience with MS PowerBI', 'Anchor Loans\xa0is the nation’s leading provider of quick bridge funding to fix-and-flip investors—originating more than 16,000 loans totaling over $7.25 billion since its founding in 1998. Anchor’s experience, relationships and proprietary Fintech technology platform set it apart from other lenders.']",Mid-Senior level,Full-time,Engineering,Financial Services,2020-11-05 11:32:32
Data Scientist,"InVitro Cell Research, LLC",New York City Metropolitan Area,,N/A,"['', 'p', ""*** If you've already applied to this job, there is no need to reapply.***"", 'estimating', 'Hint', 'state-of-the-art resources', '(Hint: you can merge them as a single document)', ' small-group vibe', 'Want to join us?', 'predicting', 'Please note: Position title and compensation are commensurate with experience.', 'understand the problems', ""InVitro Cell Research (ICR) is dedicated to solving some of the most difficult problems in aging and age-related disease. We're a growing company with a small-group vibe and a highly collaborative work environment. We provide our scientists with the state-of-the-art resources they need to leverage their time and skills most effectively, empowering small teams of scientists to accomplish what would otherwise require much larger teams."", 'A can-do attitude and a friendly, easy going personality', 'Do you understand the problems associated with NHST (null-hypothesis significance testing) and p-values?', 'observables', 'at least 8 years experience in machine learning/predicitve statistics is required.', 'a highly collaborative work environment', 'The ability to work in the United States without sponsorship', 'Can you predict the future with machine learning? Do you ""think in bets""?', 'Excellent English-language communication skills', ""You'll need a solid foundation in all aspects of machine learning and predictive statistics (analysis, modeling, etc) as well as Bayesian statistics and a demonstrated record of accomplishment in these areas. You should be fluent in R and/or Python. Experience with biological/medical data would also come in quite handy."", ' at least 8 years experience in machine learning/predicitve statistics is required.', 'SENIOR data scientists with expertise in machine learning and predictive statistics (analytics and modeling)', 'think in bets', 'Do you understand the value of predicting observables as opposed to estimating parameters?', ""If so, we'd like to hear from you!"", 'parameters', 'Excellent English-language communication skillsThe ability to work in the United States without sponsorshipA can-do attitude and a friendly, easy going personality', 'Also, this is a senior-level scientist position, so at least 8 years experience in machine learning/predicitve statistics is required.', 'Who are we?', ""We're hiring SENIOR data scientists with expertise in machine learning and predictive statistics (analytics and modeling). Also, you'll need some experience working with medical or biological datasets (some background in biology would be very helpful). Experience with Bayesian statistics and a breadth of machine learning techniques is required."", ""Also, you'll need some experience working with medical or biological datasets (some background in biology would be very helpful)."", 'machine learning', '... then please apply with your CV and cover letter!', ""If you grasp what we're looking for with this job description AND you have...""]",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Lead Data Scientist - Clinical Trials,CVS Health,"Woonsocket, RI",12 hours ago,Be among the first 25 applicants,"['', ' Translate complex business problems into analytical and modeling problems, design and implement machine learning and optimization model and quality check results and link them to business insights Write scalable, production level code Communicate well with business partners and data engineering team and create buy-in for new ideas and models Understand the impact and value of machine learning and optimization model in the Clinical Recruitment Platform and product offering and come up with innovative ways to expand current functionality Operate in a complex, cross-functional organization or company where your teams need to collaborate and integrate with other business and IT teams', 'Skill In', ' Translate complex business problems into analytical and modeling problems, design and implement machine learning and optimization model and quality check results and link them to business insights', ' Communicate well with business partners and data engineering team and create buy-in for new ideas and models', 'Preferred Qualifications', 'Knowledge Of', ' A large scale Snowflake or Spark implementation', ' Data management and model productionalization best practices Modern machine learning and artificial intelligence techniques', 'Education', ' Develop machine learning or optimization models taking into account latest development in research and tech community', 'The Senior Advisor Of Data Scientist Will', ' Healthcare space and clinical trial space', ' Translated business problem into modeling approach taking into account business requirements, data availability, development time / complexity and ability to scale. Oversee all project management activities including communications within project teams, stakeholder management, leadership updates, etc.', ' 5+ years of experience within advanced analytics function of a corporation, tech startup or a consulting firm', ' Identify new areas where machine learning and optimization models can bring valuable insights on an ongoing basis', 'Business Overview', ' Common modeling tools and frameworks, e.g. Python, R, Scala, TensorFlow, etc.', ' Write scalable, production level code', 'Required Qualifications', ' Data management and model productionalization best practices', ' Work with data engineering team to scale and productionalize machine learning model in Clinical Recruitment Platform (CRP)', ' Healthcare space and clinical trial space Specific Clinical Trial Recruitment experience and expertise A large scale Snowflake or Spark implementation Identify new areas where machine learning and optimization models can bring valuable insights on an ongoing basis', 'Job Description', ' Understand the impact and value of machine learning and optimization model in the Clinical Recruitment Platform and product offering and come up with innovative ways to expand current functionality', ' Modern machine learning and artificial intelligence techniques', ' Work with business partners to design implementation and measurement approach', ' Specific Clinical Trial Recruitment experience and expertise', ' Translated business problem into modeling approach taking into account business requirements, data availability, development time / complexity and ability to scale. Oversee all project management activities including communications within project teams, stakeholder management, leadership updates, etc. Prepare data for the analysis, in particular work with data engineering team to create modeling dataset, assess completeness and quality of data and perform feature engineering; Develop machine learning or optimization models taking into account latest development in research and tech community Work with data engineering team to scale and productionalize machine learning model in Clinical Recruitment Platform (CRP) Work with business partners to design implementation and measurement approach', 'Ability To', ' Operate in a complex, cross-functional organization or company where your teams need to collaborate and integrate with other business and IT teams', ' Prepare data for the analysis, in particular work with data engineering team to create modeling dataset, assess completeness and quality of data and perform feature engineering;']",Associate,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Mitchell Martin Inc.,"Jersey City, NJ",21 hours ago,103 applicants,"['', '• Work with business SMEs to understand data requirements and translate them into predictive models and analytical tools.', '• Develop processes and tools to monitor and analyze model performance.', '• Required: Candidate must possess an advanced graduate degree in Engineering, mathematics, statistics, computer science, actuarial science, economics or related technical field. Strong background in machine learning, hypothesis testing, regression analysis, NLP, statistics, or probability at the graduate school level or higher, as well as experience creating predictive analytics with noisy data. Background in text analytics, news aggregation and natural language processing.', '• Strong knowledge of advanced statistical methods, Bayesian learning techniques, pattern recognition and outlier detection algorithms, and predictive modeling methods including decision trees and random forest approaches.', 'Local candidates\xa0are preferred.', 'Data Scientist ', '• Experience with and ability to work with data including rapid prototyping and coding skills using common data scientist tools (e.g., Python/R, Plotly, Shiny, Presto, Tensorflow, Keras, pyTorch)', 'Contract', '• Knowledge of financial engineering to develop, maintain and/or validate models used for forecasting, valuation, instrument and strategy selection, portfolio construction, and risk management covering a wide range of financial instruments, including equities, fixed income, currencies, futures, commodities, and/or derivatives.', '• Assess the effectiveness and accuracy of new data sources and data gathering techniques.', 'Local candidates', '• Proficient communication skills and experience writing model documentation', '• Apply techniques in natural language processing and applied mathematics to develop text classification tools to automate the existing manual review of the documents.', 'Jersey City, NJ', 'Required: ', '• 1-2 years of experience and knowledge in the field of quantitative research and the specialized area of financial engineering, data science, or risk analytics as it relates to the securities industry. Knowledge of predictive model development and oversight.', '• Present information using data visualization techniques and communicate findings and mine useful insights.', '• Develop state-of-the-art software tools to collect, and analyze large volumes of structured and/or unstructured data to streamline business processes.', 'Python/R, Plotly, Shiny, Presto, Tensorflow, Keras, pyTorch)', 'Responsibilities: ', 'Mitchell Martin Inc. is partnered with a company located in Jersey City, NJ. Our client is looking to onboard a new Data Scientist on their team as soon as possible on a Contract\xa0basis.\xa0Local candidates\xa0are preferred.', 'Education/Experience']",Mid-Senior level,Contract,Engineering,Banking,2020-11-05 11:32:32
Research Scientist,"Polyglass U.S.A., Inc. / Mapei","Deerfield Beach, FL",2 hours ago,Be among the first 25 applicants,"['', 'Conduct and design tests, observe and record results to establish quantitative performance benchmarks and assure that products or systems meet external code body and internal performance standards.', 'Let’s show you what we mean when we say “Polyglass is a Family”…\xa0\xa0\xa0https://www.youtube.com/watch?v=rZo5t2kn_SQ', 'Experience developing product formulas from the lab, through scale-up and to the final technology transfer stage in the production process', 'Let’s show you what we mean when we say “Polyglass is a Family”…\xa0\xa0\xa0', 'Promote health, safety and environmental regulations by ensuring that standards, policies, and procedures are adhered to in compliance with corporate, federal, state, and local requirements.', 'Strong track record of technology and product development in the areas of roof coatings and primers, air and moisture barriers, and waterproof coatings as well as roofing membranes.', 'Why Polyglass?\xa0', 'Lead major product development projects and technical initiatives in collaboration with Product Management, Operations, Marketing, Purchasing, and Technical Services.Conduct and design tests, observe and record results to establish quantitative performance benchmarks and assure that products or systems meet external code body and internal performance standards.Generate ideas that will enhance existing products and lead to the development of new products, test procedures and protocols.Execute plant trials by transferring technology from small scale lab models to large scale plant production.Create technical reports and communicate effectively with the Principal Scientist and Director of R&D at regular intervals on key projects as required.Perform independently and in teams towards executing the initiatives of the management team.Collaborate with partner companies and key raw material suppliers to advance the development of formulas, products or processes.Train, mentor and guide R&D technicians as needed.Promote health, safety and environmental regulations by ensuring that standards, policies, and procedures are adhered to in compliance with corporate, federal, state, and local requirements.Perform other duties as required.', 'Execute plant trials by transferring technology from small scale lab models to large scale plant production.', 'Create technical reports and communicate effectively with the Principal Scientist and Director of R&D at regular intervals on key projects as required.', 'Why Polyglass?\xa0In addition to what we share in the wonderful video below, it’s important to know that Polyglass is a family-owned company and a leader in our industry.\xa0\xa0We have experienced tremendous growth in the past decade and that success fuels the need for talent like yourself.\xa0\xa0Our wonderfully talented R&D team has been one of the biggest reasons behind this growth!\xa0\xa0Best-in-class benefits, ability to advance in your career and be part of a family of people that succeed by helping others.\xa0Apply for this role and find out more about why so many choose to continue their career at Polyglass for years – even decades.\xa0\xa0We look forward to hearing more about you!', 'What You Get To Do:', 'Join our dynamic R&D team at Polyglass and finally enjoy a career with excitement, challenge and growth!', 'Effective teamwork and communication (oral and written) skills', '\xa0', 'Do you enjoy using your expertise in research to develop best in class products that are the talk of the market?', 'Effective working knowledge of waterproofing coating systems and membranes codes and standards.\xa0', 'Perform independently and in teams towards executing the initiatives of the management team.', 'Generate ideas that will enhance existing products and lead to the development of new products, test procedures and protocols.', 'Collaborate with partner companies and key raw material suppliers to advance the development of formulas, products or processes.', 'Lead major product development projects and technical initiatives in collaboration with Product Management, Operations, Marketing, Purchasing, and Technical Services.', 'Perform other duties as required.', 'The Skills and Background You’ll Contribute:', 'Track record of high scientific achievement (patents, articles, presentations)', 'Our wonderfully talented R&D team has been one of the biggest reasons behind this growth!', 'Position Summary: This position will be responsible for new product development and product support of liquid applied membranes and coatings used in the residential and commercial roofing and building envelope applications. He/She will be responsible for competitive analysis, value engineering and product improvement initiatives for existing product lines, and formulation development of new products. He/she will interface closely with the Director of Research & Development and directly with scientists and technicians to mentor, design, formulate, and develop processes, products, systems, and applications.\xa0Position reports to the Principal Scientist and Director of Research & Development.\xa0Additionally, provides an interface with Product Management, Marketing, Operations, Technical Services, Supply Chain and Sales Departments.', 'Strong track record of technology and product development in the areas of roof coatings and primers, air and moisture barriers, and waterproof coatings as well as roofing membranes.Effective working knowledge of waterproofing coating systems and membranes codes and standards.\xa0Knowledge of acrylic latex, urethane and silicone chemistries.Experience developing product formulas from the lab, through scale-up and to the final technology transfer stage in the production processLab experience working with analytical and mechanical instruments for polymers and coatings characterization including DMA, DSC, DSR, FTIR, Universal testing machine, etc.Ability to use analytical lab tools and data to generate correlations that predict ultimate material performance and durabilityStrong analytical and problem-solving skillsProject management skills with demonstrated track record of successful new product developmentTrack record of high scientific achievement (patents, articles, presentations)Able to work effectively with external partners at a technical and interpersonal level.Effective teamwork and communication (oral and written) skills', 'Project management skills with demonstrated track record of successful new product development', 'Lab experience working with analytical and mechanical instruments for polymers and coatings characterization including DMA, DSC, DSR, FTIR, Universal testing machine, etc.', 'Strong analytical and problem-solving skills', 'Knowledge of acrylic latex, urethane and silicone chemistries.', 'Position Summary: ', 'Able to work effectively with external partners at a technical and interpersonal level.', 'Train, mentor and guide R&D technicians as needed.', 'Ability to use analytical lab tools and data to generate correlations that predict ultimate material performance and durability']",Mid-Senior level,Full-time,Research,Building Materials,2020-11-05 11:32:32
Senior Data Scientist,Bitly,"New York, NY",12 hours ago,Be among the first 25 applicants,"['', 'Must Haves', 'show us your skills!', 'Experience deploying ML at scale in a cloud-based environment (e.g., AWS, GCP, Azure) strongly preferred', 'Experience with large datasets and techniques to handle data which can’t be processed serially strongly preferred.', ' Case Study Interview ', ""with Bitly's internal Recruiter"", 'Recruiter Screen ', 'Your own unique talents – even if you don’t meet 100% of what we list here, apply and tell why you’d be a great fit. Requirements can never capture everything about a role', 'Responsibilities', ' Engineering Interview', ""Recruiter Screen with Bitly's internal RecruiterHiring Manager Phone Screen with our Head of Data ScienceTechnical Challenge show us your skills!Panel Interview where you meet with the broader team (all video) Case Study Interview  Engineering Interview Analytics + Strategy Interview  Values InterviewValues InterviewFinal Interview with our Chief Data Officer"", 'Hiring Manager Phone Screen with our Head of Data Science', 'Technical Challenge', 'Panel Interview where you meet with the broader team (all video)', 'Panel', 'Willingness to take on big data science problems and own the solutions from ideation through execution', 'THE TEAM', 'Create cutting-edge ML algorithms that surface new and innovative insights to our customersDrive the development of ML products and services end-to-end, in close partnership with EngineeringWork cross-functionally with Engineering, Analytics, and Data to pilot new innovation ideas for leveraging ML of unstructured and semi-structured data to inspire and delight our customersDevelop the data science practice at Bitly, with opportunities to help build and lead Bitly’s data science functionBe a culture leader that helps focus Bitly Data on ways to hockey-stick growth', 'Minimum 3 years’ practical experience applying ML algorithms outside of an academic context; experience in leveraging ML in development of products, services, or features in a commercial context strongly preferred', 'Strong proficiency with Python and/or R (or similar programming languages)', 'with our Chief Data Officer', 'Understanding of the technical underpinning behind unsupervised learning / ML / NLP algorithms used for searching and mining unstructured and semi-structured data', 'Develop the data science practice at Bitly, with opportunities to help build and lead Bitly’s data science function', 'Excellent written and oral communication skills, including strong ability to communicate effectively to both technical and nontechnical audiences', 'Interview Process', 'Work cross-functionally with Engineering, Analytics, and Data to pilot new innovation ideas for leveraging ML of unstructured and semi-structured data to inspire and delight our customers', 'Interview', 'Final Interview ', 'where you meet with the broader team (all video)', 'Bachelor’s degree in Computer Science, Engineering, Physics, Mathematics, Statistics, Operations Research or similar technical field preferred; Master’s or Ph.D. strongly preferred', 'THE LOCATION', 'THE ROLE', ' Analytics + Strategy Interview ', 'Minimum 3 years’ practical experience applying ML algorithms outside of an academic context; experience in leveraging ML in development of products, services, or features in a commercial context strongly preferredUnderstanding of the technical underpinning behind unsupervised learning / ML / NLP algorithms used for searching and mining unstructured and semi-structured dataStrong proficiency with Python and/or R (or similar programming languages)Proficiency writing complex SQL queriesExcellent written and oral communication skills, including strong ability to communicate effectively to both technical and nontechnical audiencesWillingness to take on big data science problems and own the solutions from ideation through executionYour own unique talents – even if you don’t meet 100% of what we list here, apply and tell why you’d be a great fit. Requirements can never capture everything about a role', 'with our Head of Data Science', 'Technical Challenge show us your skills!', 'Be a culture leader that helps focus Bitly Data on ways to hockey-stick growth', 'Drive the development of ML products and services end-to-end, in close partnership with Engineering', 'Proficiency writing complex SQL queries', 'Final Interview with our Chief Data Officer', 'Hiring Manager Phone Screen', 'Experience not only using off-the-shelf open-sourced libraries but also writing your own libraries or contributing to open-sourced libraries is preferred', 'Experience not only building ML algorithms but also driving model testing, validation, and deployment at scale, including how to structure statistically sound validation testing. Experience deploying ML at scale in a cloud-based environment (e.g., AWS, GCP, Azure) strongly preferredExperience with large datasets and techniques to handle data which can’t be processed serially strongly preferred.Experience not only using off-the-shelf open-sourced libraries but also writing your own libraries or contributing to open-sourced libraries is preferredBachelor’s degree in Computer Science, Engineering, Physics, Mathematics, Statistics, Operations Research or similar technical field preferred; Master’s or Ph.D. strongly preferred', 'Experience not only building ML algorithms but also driving model testing, validation, and deployment at scale, including how to structure statistically sound validation testing. ', ' Values InterviewValues Interview', 'Bonus Points', 'Create cutting-edge ML algorithms that surface new and innovative insights to our customers', ""Recruiter Screen with Bitly's internal Recruiter""]",Associate,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Data Scientist - AWESOME COMPANY!,Optello,"San Francisco, CA",6 hours ago,Be among the first 25 applicants,"['', 'Optello is proud to be an Equal Opportunity Employer', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JC17-1603948 -- in the email subject line for your application to be considered.***', 'Email Your Resume In Word To', ""Heres What We're After"", ""It'd Be Amazing If"", 'Your Right to Work', ""Here's What You'll Do""]",Entry level,Full-time,Information Technology,Construction,2020-11-05 11:32:32
Graduate Data Scientist - new college graduates,LexisNexis Risk Solutions,"New Providence, NJ",48 minutes ago,Be among the first 25 applicants,"['Assists with the development and maintenance of      infrastructure systems that connect internal data sets; ', 'New Providence, NJ', 'Statistical, mathematical, predictive modeling and      business analysis skills to manage and manipulate complex high volume data      from a variety of sources ', 'New Providence, NJ ', 'XpertHR is part of RELX Group, a world-leading provider of information and analytics for professional and business customers. RELX Group is one of the 30 biggest listed companies in the UK and one of the 500 biggest companies in the world. The Group serves customers in more than 180 countries and has offices in some 40 countries. It employs around 30,000 people. ', 'Graduate Data Scientist - New college graduates ', 'XpertHR ', 'The role ', ' BS in Computer Science, Mathematics, Statistics or      equivalent experience  ', ' Statistical, mathematical, predictive modeling and      business analysis skills to manage and manipulate complex high volume data      from a variety of sources  Assists with the development and maintenance of      infrastructure systems that connect internal data sets;  Assists with the creation of new data collection      frameworks for structured and unstructured data', 'Graduate Data Scientist - New college graduates', 'XpertHR', ""You will be joining a small data science team, providing critical input to the development of a major new product launch.  \xa0Working within a friendly mixed team of data scientists, product, UX and developers you will use your skills to build, refine and test NLP-led technologies/products to address a critical challenge facing HR teams in organization's across the US and the world. "", 'Qualifications ', ' ', 'Technical Skills: ', 'BS in Computer Science, Mathematics, Statistics or      equivalent experience ', 'Assists with the creation of new data collection      frameworks for structured and unstructured data', '\xa0 ', 'XpertHR is the most comprehensive source of employment law, HR good practice and benchmarking information available, providing solutions and expertise for employers in the UK, USA and the Netherlands. Increasingly the challenges and opportunities facing HR practitioners involve the mastery of data, creating an opportunity for data scientists work with our development teams to build successful data-led products in this exciting area. ']",Associate,Full-time,Product Management,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,MSC Industrial Supply Co.,"Davidson County, NC",22 hours ago,Be among the first 25 applicants,"['', 'Architects, builds and maintains data driven machine learning models, experiments, forecasting algorithms, and optimization models.', 'Equal Opportunity Statement ', 'Communicates final recommendations and drive decision making.', ' Provides technical leadership and guidance in advanced analytics solutions as well as:', 'Experience with data visualization libraries such as D3, Matplotlib, Pyplot, ggplot2 required.', 'Mentors others as needed on best practices for design and implementation of cutting-edge analytics solutions.', ' Drives the MSC Culture in the department and throughout the company to ensure fulfillment of MSC’s vision and unity of purpose.', 'Work Location :', 'Requisition ID : 5549 ', 'Collaborates with cross-functional data and product teams across business applications to access and manipulate data, explain data gathering requirements, make recommendations, display results, and build efficient and scalable analytics solutions.', 'Strong Knowledge about Agile techniques: User Stories, Continuous Integration, Test Driven Development, Continuous Testing, Pairing, Automated Testing, Burn Down Metrics, Velocity etc.', 'Strong knowledge of software development processes and procedures to understand team needs includes fundamentals of iterative and incremental development', 'Familiarity with object-oriented programming languages (such as C++ or Java) and visualization tools from at least one toolset (e.g. Tableau, MicroStrategy,, Looker, SAS, Power BI, etc.) preferred.', 'Strong Knowledge about Agile techniques: User Stories, Continuous Integration, Test Driven Development, Continuous Testing, Pairing, Automated Testing, Burn Down Metrics, Velocity etc.Strong knowledge of software development processes and procedures to understand team needs includes fundamentals of iterative and incremental developmentKnowledge of deep learning research.Familiarity with object-oriented programming languages (such as C++ or Java) and visualization tools from at least one toolset (e.g. Tableau, MicroStrategy,, Looker, SAS, Power BI, etc.) preferred.', ' Participation in special projects and performs additional duties as required', 'Potential Work Location :', 'Experience with DevOps process (exposure to GitHub, Jenkins or other CI/CD tools) required.', 'Experience with scientific computing and analysis packages such as NumPy, SciPy, Pandas, Scikit-learn, dplyr, or ggplot2 required.', 'Experience writing testable code and shipping code into production required.', 'People. Collaboration. Insight. That’s how you build something that works.', 'Brief Position Summary', 'State or Province :', 'Build a better career with MSC. ', 'EDUCATION And EXPERIENCE', 'Bachelor’s degree in a quantitative field such as Data Science, Computer Science, Quantitative Finance, Math, Statistics, Physics or a related Engineering degree required.', 'INDICATES ESSENTIAL DUTIES', 'Minimum three years of experience in managing and analyzing large-scale structured and unstructured data using R or Python required.', 'Analysis of operational data and user behavior to improve overall business performance.', 'Defines, computes, tracks, and continuously validates business metrics with diagnostic, predictive, prescriptive analytics.', 'Minimum two years of experience in SQL in big data environments (i.e. Hadoop) and data modeling required.', 'Skills', 'Minimum three years of experience in building models and developing algorithms for machine learning, statistics, mathematical programming, and simulation in industry and/or academia required.', ' Stays current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Employment Type :', 'JOB TITLE:', 'Bachelor’s degree in a quantitative field such as Data Science, Computer Science, Quantitative Finance, Math, Statistics, Physics or a related Engineering degree required.Minimum three years of experience in building models and developing algorithms for machine learning, statistics, mathematical programming, and simulation in industry and/or academia required.Minimum three years of experience in managing and analyzing large-scale structured and unstructured data using R or Python required.Minimum two years of experience in SQL in big data environments (i.e. Hadoop) and data modeling required.Experience with scientific computing and analysis packages such as NumPy, SciPy, Pandas, Scikit-learn, dplyr, or ggplot2 required.Experience with data visualization libraries such as D3, Matplotlib, Pyplot, ggplot2 required.Experience with Machine Learning, Statistics, or other data analysis tools and techniques required.Experience with statistics methods such as forecasting, time series, hypothesis testing, classification, clustering or regression analysis required.Experience writing testable code and shipping code into production required.Experience with DevOps process (exposure to GitHub, Jenkins or other CI/CD tools) required.Experience with machine learning libraries and packages such as PyTorch, Caffe2, TensorFlow, Keras or Theano preferred.', 'DUTIES And RESPONSIBILITIES', 'Job Category :', 'Experience with Machine Learning, Statistics, or other data analysis tools and techniques required.', 'Experience with statistics methods such as forecasting, time series, hypothesis testing, classification, clustering or regression analysis required.', 'Why MSC ', 'Knowledge of deep learning research.', 'Experience with machine learning libraries and packages such as PyTorch, Caffe2, TensorFlow, Keras or Theano preferred.', 'Partners with internal stakeholders on projects to identify and articulate opportunities, see beyond the data to identify solutions that will raise the bar for decision making.']",Not Applicable,Full-time,Information Technology,Business Supplies and Equipment,2020-11-05 11:32:32
Quantitative Researcher,Capital,"New York, NY",2 hours ago,39 applicants,"['', 'You can see cash flows and slice them into structures that give you precise exposure to the risks you want to take. You can articulate these structures mathematically and you can comfortably translate that math into bullet points which the lawyers you collaborate with can transform into legal documents.', ""As a Quantitative Researcher at Capital, you will work on mission-critical problems related to exploring transaction-level private company data which is uniquely accessible at scale via our Capital Machine. You will also explore public, top-down data sets combining both forms of data to generate novel investment theses. You will work with Capital's proprietary financial theory to test your investment ideas across the entire universe of private companies. Like Warren Buffett's concept of\xa0"", 'A fluent data scientist or mathematician who can draw from a wide breadth of theory to solve financial problems', ""As a Quantitative Researcher at Capital, you will work on mission-critical problems related to exploring transaction-level private company data which is uniquely accessible at scale via our Capital Machine. You will also explore public, top-down data sets combining both forms of data to generate novel investment theses. You will work with Capital's proprietary financial theory to test your investment ideas across the entire universe of private companies. Like Warren Buffett's concept of\xa0Owner Earnings, Capital's financial theory supports a generalizable and benchmark-able view of companies. Unlike Owner Earnings, this view leverages granular system-of-record data available only to investors in private companies building investment systems from the ground up in the 2020s. Applying this theory requires the correct blend of financial sophistication and elegance. "", 'You write code fluently and quickly prototype your ideas. You see your power alley as research - you do not need to be a production-quality engineer and you will be supported by a large engineering team that puts the most important research into wide scale production.', 'You know that great investors predict company behavior and investor behavior. You are not dogmatic about a particular type of investing (momentum vs. value or short horizon vs. long horizon) and know that the best bets come from having unique predictive power and thus value unique data sources.', 'To do this well, you must be:', 'An expert investor who has formed your views through first-hand experience in multiple asset classes (ex: credit vs. equity, public vs. private, growing vs. declining assets, etc.).', 'You have strong foundations in finance, math, and economics. You likely self-study history, philosophy and any other field that lets you expand and test your theories on how the world works.You write code fluently and quickly prototype your ideas. You see your power alley as research - you do not need to be a production-quality engineer and you will be supported by a large engineering team that puts the most important research into wide scale production.You have a good eye for data visualization and a strong opinion about the most efficient way to consume informationYou have a strong view on how micro-economic data can be combined with macro-economic data to make actionable investment decisions. You have a good feel for the right level of detail you need to make financial decisions and know that errors compound so avoid boiling the ocean.You know that great investors predict company behavior and investor behavior. You are not dogmatic about a particular type of investing (momentum vs. value or short horizon vs. long horizon) and know that the best bets come from having unique predictive power and thus value unique data sources.You are not an accountant but you are comfortable diving into GAAP and IFRS, taking their best ideas to hone your taxonomy and leaving out unnecessary detail.You can see cash flows and slice them into structures that give you precise exposure to the risks you want to take. You can articulate these structures mathematically and you can comfortably translate that math into bullet points which the lawyers you collaborate with can transform into legal documents.', 'Capital is recruiting quantitative researchers. You will work on a cross-functional team of economists, mathematicians and data scientists to create novel private market investment theses which are then executed by our investment team using The Capital Machine.', 'WHAT SKILLS HAVE YOU MASTERED PROFESSIONALLY TO PREPARE YOU TO BE A QUANTITATIVE RESEARCHER?', 'Maintaining these three qualities in one mind makes you a rare blend of skills and it is likely that you often get bored because you are unable to use all of these skills at once professionally. If you are a fit for this role, you know exactly what we are talking about as you read these words!', 'ABOUT CAPITAL:\xa0Capital (www.captec.io)\xa0is a New York-based fintech company and the creator of The Capital Machine. The Capital Machine is a powerful technology that helps leading global investors find, understand and finance companies\xa0bringing modern, Silicon Valley technology to the world’s $5T private capital markets. Like all category-reinventing businesses (ex:\xa0the FAANG companies) Capital has two sides to its marketplace: capital allocators and companies which demand capital. Sophisticated capital allocators, such as multi billion dollar family offices, banks and sovereign wealth funds come to Capital because they believe that The Capital Machine can level up their businesses - helping them to better originate, underwrite and service whether in their core business or in new investment strategies. Innovative companies come to The Capital Machine because it is the most efficient place in the world to plan and close an institutional fundraising process.\xa0The company was founded by alumni from Stanford, Draper Fisher Jurvetson (DFJ), OakTree, Foursquare, NASA, Class Dojo, and more. The team has over 75 years of experience on Wall Street and Silicon Valley, has raised over $250M to date from top-tier investment firms and has been featured in\xa0TechCrunch\xa0and\xa0Business Insider.\xa0', 'CAPITAL is seeking candidates for a\xa0Quantitative Researcher position\xa0who are available to start immediately.\xa0\xa0', 'ABOUT CAPITAL', 'An expert investor who has formed your views through first-hand experience in multiple asset classes (ex: credit vs. equity, public vs. private, growing vs. declining assets, etc.).A fluent software builder who can bring your ideas to life through working codeA fluent data scientist or mathematician who can draw from a wide breadth of theory to solve financial problems', 'You are not an accountant but you are comfortable diving into GAAP and IFRS, taking their best ideas to hone your taxonomy and leaving out unnecessary detail.', 'WHAT DOES A QUANTITATIVE RESEARCHER DO AT CAPITAL?', 'You have a strong view on how micro-economic data can be combined with macro-economic data to make actionable investment decisions. You have a good feel for the right level of detail you need to make financial decisions and know that errors compound so avoid boiling the ocean.', 'A fluent software builder who can bring your ideas to life through working code', 'You have a good eye for data visualization and a strong opinion about the most efficient way to consume information', 'You have strong foundations in finance, math, and economics. You likely self-study history, philosophy and any other field that lets you expand and test your theories on how the world works.', 'Quantitative Researcher position']",Mid-Senior level,Full-time,Finance,Financial Services,2020-11-05 11:32:32
"Data Scientist, Consultant",Guidehouse,"Atlanta, GA",5 hours ago,Be among the first 25 applicants,"['', ' Visualization skills with tools such Tableau, Power BI, or R Shiny ', ' Collaborating and working in a team environment, as well as the ability to work independently ', ' Knowledge of defense, national security, financial, healthcare, international development, or state and local government environment ', ' Proficiency in an analytics programming language, such as R, Python, or SAS ', ' The successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described. ', 'About Guidehouse', ' Identifying and addressing client needs, building relationships with clients, demonstrating flexibility in prioritizing and completing tasks, communicating potential conflicts to a supervisor ', 'Benefits Include', 'Disclaimer', ' Communicating effectively to various audiences, including various levels of management and external clients, in a professional environment ', 'Responsibilities', 'Desired Experience', ' Analyzing large and complex data sets, with strong aptitude for conducting quantitative and qualitative analysis ', ' Disclaimer ', 'Skills And/or Proven Success In The Following', ' Selecting and applying the appropriate analytical techniques ', 'Qualifications', ' Analytics for business, operations, human capital, or financial management ', 'Additional Requirements', ' Business development including RFP/RFQ responses, developing white papers/concept papers, and building and demonstrating prototype solutions to customers ', ' Statistical analysis, predictive modelling, simulation, machine learning, and artificial intelligence ', ' Contributing as a team member: understanding personal and team roles, contributing to a positive working environment by building strong, collaborative relationships with team members ', 'Overview', ' Statistical analysis, predictive modelling, simulation, machine learning, and artificial intelligence  Selecting and applying the appropriate analytical techniques  Analytics for business, operations, human capital, or financial management  Analyzing large and complex data sets, with strong aptitude for conducting quantitative and qualitative analysis  Proficiency in an analytics programming language, such as R, Python, or SAS  Visualization skills with tools such Tableau, Power BI, or R Shiny ', ' Contributing as a team member: understanding personal and team roles, contributing to a positive working environment by building strong, collaborative relationships with team members  Collaborating and working in a team environment, as well as the ability to work independently  Communicating effectively to various audiences, including various levels of management and external clients, in a professional environment  Identifying and addressing client needs, building relationships with clients, demonstrating flexibility in prioritizing and completing tasks, communicating potential conflicts to a supervisor  Business development including RFP/RFQ responses, developing white papers/concept papers, and building and demonstrating prototype solutions to customers  Knowledge of defense, national security, financial, healthcare, international development, or state and local government environment ']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Quantitative Researcher,CaaS Capital Management,"New York, NY",20 hours ago,Over 200 applicants,"['', 'About CaaS Capital', 'Work closely with PMs, develop and continuously improve statistical models for trading decisions. Help translate algorithms into codeConduct research and statistical analyses to back test trading strategies and evaluate trading ideasBuild system for identifying trading opportunities, generating trading signal and monitoring trading activities in a real-time trading environment', 'CaaS believes in transparent communication and a commitment to our partners. We strive to create long-term partnerships with our partners who share our vision.', 'Experience in analytical software (e.g. numpy, pandas, R)', 'Strong knowledge in probability and statistics', 'Build system for identifying trading opportunities, generating trading signal and monitoring trading activities in a real-time trading environment', 'Bachelor, Master or Ph.D. in Statistics, Computer Science, Mathematics or another highly quantitative field', 'Conduct research and statistical analyses to back test trading strategies and evaluate trading ideas', 'Requirements', 'CaaS Capital Management invests across all regions, industries and capital structures. CaaS feels strongly in providing liquidity — Capital as a Service — to our partners and pursue this objective with great vigor and energy. CaaS has a unique combination of fundamental and quantitative inputs when making investment decisions.', 'Exceptional programming skills in at least one programming language, e.g. Python, C/C++, Java etc.', 'Work closely with PMs, develop and continuously improve statistical models for trading decisions. Help translate algorithms into code', 'Responsibilities', 'At CaaS Capital, quantitative researchers are responsible for developing financial models and testing trading ideas using sophisticated statistical techniques. We are seeking a quantitative researcher to work within the equity and derivatives investment team.', 'Bachelor, Master or Ph.D. in Statistics, Computer Science, Mathematics or another highly quantitative fieldStrong knowledge in probability and statisticsExperience in analytical software (e.g. numpy, pandas, R)Exceptional programming skills in at least one programming language, e.g. Python, C/C++, Java etc.Proficiency with data structures and algorithms', 'Proficiency with data structures and algorithms']",Not Applicable,Full-time,Finance,Investment Management,2020-11-05 11:32:32
Oil and Gas Data Scientist ,Primary Services,"Houston, TX",19 hours ago,75 applicants,"['', 'REQUIREMENTS ', 'JOB DESCRIPTION ', '• Natural language processing, documents processing experience is a plus ', '• Image Processing skills is preferred: uniformity/structure in 1D data and 2D data ', '• Proficiency in Python, and experience in using frameworks like Tensorflow, and Keras is must. ', '• Good analytical and programming skills with strong math or, statistics, engineering, physics background is preferred ', '• Skilled in high standards of code quality and making use of version control tools. ', '• Awareness of developing solutions on cloud platforms like AWS, Azure, Databricks is beneficial\xa0', '• Hands-on experience in developing machine learning/AI based applications, preferably, in O&G industry ', '• Proficient in Python and Plotly programming ', 'Alongside your technical expertise, you’ll also call on your excellent people skills, nurturing mutual trust with a diverse range of stakeholders. Whilst your strong oral and written communication skills will see you effectively translating analysis and modelling findings into language that can be easily understood by both a technical and non-technical audience. Where you fit in You’ll be a part of Our Data Science Centre of Excellence, which supports all businesses in Shell with data science solutions. With a focus on developing Shell’s customer centric digital strategy. We expect you’ll thrive working independently or part of a team, fitting into a highly-collaborative, friendly Agile environment, with the opportunity to learn new practices and technologies. ', 'As Data Scientist, you’ll be providing solutions to customer centric business challenges, driving insights that will have an impact on our business performance. An exciting chance to employ your date science expertise and creative problem-solving skills to real-world customer problems. Your challenge will be to translate a business question into a data science solution, using your experience in customer analytics to help us understand customer behavior, where customers are both businesses as well as consumers. In practice that means you’ll be writing production-level code, working with Python, GIT, Azure, and SQL and regularly integrating models into production. ', '• Experience in developing robust deep learning algorithms (RNN, LSTM, VAEs, CNNs, GANs etc) and methods for time-series, image classification, image analysis, image classification, and semantic segmentation problems is strongly preferred. ']",Associate,Contract,Engineering,Staffing and Recruiting,2020-11-05 11:32:32
"Data Scientist, Machine Learning",GoHealth,"Chicago, IL",20 hours ago,77 applicants,"['', 'current and future', '2+ years of experience demonstrating trajectory of professional growth in software engineering, data science, or data engineering', 'Frequently cited statistics show that women and members of underrepresented groups apply to jobs only if they meet 100% of the qualifications. GoHealth encourages you to break that statistic and to apply. No one ever meets 100% of the qualifications. We look forward to your application. ', 'Medical, dental, vision, and life insurance benefits', ' Open vacation policy because work life balance is important 401k program with company match Employee Stock Purchase Program Medical, dental, vision, and life insurance benefits Paid maternity and paternity leave Professional growth opportunities Generous employee referral bonuses Employee Resource Groups Work from Home Stipend GoHealth is an Equal Opportunity Employer ', 'Benefits And Perks', 'Expertise in applying common machine learning algorithms such as Linear Regression, Random Forests, XGBoost.', 'Lead quantitative analyses with product management, your team, and data engineers in solving problems', 'Present information in front of large groups of users', 'Proficient in Python and related libraries, such as Pandas, Numpy, Scikit-Learn, TensorFlow, Pytorch', 'Responsibilities', 'Stay current with leading edge systems, methods, and best practices for data science and analytics; and introduce technology and process changes across the organization', 'Work from Home Stipend', ""Find ways to improve how the team operates and aligns with GoHealth's goals."", 'Employee Resource Groups', '401k program with company match', 'Generous employee referral bonuses', 'Experience working with Scrum and other Agile methodologies, and Version control systems such as Git or Bitbucket', "" Lead quantitative analyses with product management, your team, and data engineers in solving problems Present information in front of large groups of users Find new ways to combine data that do not naturally mesh together Stay current with leading edge systems, methods, and best practices for data science and analytics; and introduce technology and process changes across the organization Improve the collaboration around actual performance and forecasts to directly help our decisions and actions Find ways to improve how the team operates and aligns with GoHealth's goals. "", 'Find new ways to combine data that do not naturally mesh together', 'Skills And Experience', 'Paid maternity and paternity leave', ""Master's in Statistics, Mathematics, Computer Science, or related quantitative field"", 'Experience deploying real-time prediction models.', 'Employee Stock Purchase Program', ' the unprecedented situation of COVID-19, GoHealth has decided to protect our ', 'Open vacation policy because work life balance is important', "" Master's in Statistics, Mathematics, Computer Science, or related quantitative field 2+ years of experience demonstrating trajectory of professional growth in software engineering, data science, or data engineering Proficient in Python and related libraries, such as Pandas, Numpy, Scikit-Learn, TensorFlow, Pytorch Expertise in applying common machine learning algorithms such as Linear Regression, Random Forests, XGBoost. Experience deploying real-time prediction models. Experience working with Scrum and other Agile methodologies, and Version control systems such as Git or Bitbucket "", 'Improve the collaboration around actual performance and forecasts to directly help our decisions and actions', 'Due to', "" employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities’ and the CDC."", 'GoHealth is an Equal Opportunity Employer', 'Professional growth opportunities']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Saks Fifth Avenue,"New York, NY",6 hours ago,Over 200 applicants,"['', 'As The Data Scientist, You Will', 'What This Position Is All About', 'Perform data engineering tasks required for machine learning use case using PySpark/SQL to aggregate, transform, and check multiple data sources into a centralized repository on AWS', 'Build and maintain clear record of data hierarchy / lineage, to support best-in-class database management and model building', 'HBC welcomes all applicants for this position. Should you be individually selected to participate in an assessment or selection process, accommodations are available upon request in relation to the materials or processes to be used.', 'Develop new features and augment tools based on business requirements', 'You Also Have', 'Build, maintain and improve machine learning models to perform at scale in a production ready environment', ""Bachelor's degree required; preferably in Business, Marketing or a quantitative field like Economics, Mathematics or Statistics"", 'Work collaboratively with the Data Architects, Data Scientists, and other members of the Analytics team to design and build all necessary data pipelines and support other efforts required for the personalization vision', ""3+ years structuring databases and manipulating large data sets 2+ years writing code in relevant languages (e.g. Python, Hive, SQL, Java or Scala) 1 to 3 years of experience in marketing analytics and database marketing.1 to 2 years of experience in supporting personalization strategies for an e-commerce industry. Retail experience preferred.Bachelor's degree required; preferably in Business, Marketing or a quantitative field like Economics, Mathematics or StatisticsMaster's preferredStrong Microsoft Excel skills. Ability to code macros in VBA a plus.Proven ability to apply findings to business problems to lift revenue and profits.Knowledge of web analytics packages (e.g. Omniture, Coremetrics or Google Analytics)."", ' Demonstrated critical thinking and problem-solving skills, leveraging data and working side-by-side with business owners to answer business questions Prior experience building complex machine learning models Knowledge of relevant languages/toolse.g. advanced Python(pandas, numpy, sklearn, scipy, statsmodels), SQL (analytic functions, subqueries, etc), Spark (inclMLlib)-using pySpark & Spark SQL, Git & Github, AWS EMR, Airflow, AWS SageMaker, Dataiku or similar platformsAbility to apply the following modeling approaches / classes of algorithms to business problems e.g. regressions, K Nearest Neighbors, Random Forest, GBM, Neural Networks, boosted trees, LDA, collaborative filtering, BayesianAdvanced knowledge of model evaluation, tuning, and performance; familiarity with machine learning, mathematical, and statistical packages Experience with A/B statistical inference testing, design of experiments, and standardization techniques Experience working side-by-side with business owners, and translating business needs across disciplines into advanced analytics projects with measurable business impact', 'Proven ability to apply findings to business problems to lift revenue and profits.', '2+ years writing code in relevant languages (e.g. Python, Hive, SQL, Java or Scala) ', 'Knowledge of web analytics packages (e.g. Omniture, Coremetrics or Google Analytics).', 'Prior experience building complex machine learning models ', 'Experience working side-by-side with business owners, and translating business needs across disciplines into advanced analytics projects with measurable business impact', 'HBC provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, HBC complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.', 'Advanced knowledge of model evaluation, tuning, and performance; familiarity with machine learning, mathematical, and statistical packages ', 'Understand business problems and identify analytic needs including machine learning algorithms suitable for solving said problem', 'Strong Microsoft Excel skills. Ability to code macros in VBA a plus.', 'Work collaboratively with other team members to define the advanced analytical modeling capabilities, enhancements and outcomes required to enable marketing & personalization use cases ', 'Experience with A/B statistical inference testing, design of experiments, and standardization techniques ', 'Design the test and learn / measurement approaches and techniques for newly deployed use cases', 'Be a SME of all data sources such as browse, all channel transactions, product, market research, credit, loyalty and 3rd party data to drive efficiencies, maximize profitability, drive customer loyalty, and optimize promotional strategies.', 'Knowledge of relevant languages/toolse.g. advanced Python(pandas, numpy, sklearn, scipy, statsmodels), SQL (analytic functions, subqueries, etc), Spark (inclMLlib)-using pySpark & Spark SQL, Git & Github, AWS EMR, Airflow, AWS SageMaker, Dataiku or similar platforms', '3+ years structuring databases and manipulating large data sets ', ""Master's preferred"", 'Who You Are', '1 to 3 years of experience in marketing analytics and database marketing.', '1 to 2 years of experience in supporting personalization strategies for an e-commerce industry. Retail experience preferred.', 'Work with other members of the Personalization Data, Analytics, and Tech teams to peer review code, write unit tests, and provide feedback on data structuring and modeling approaches', 'Ability to apply the following modeling approaches / classes of algorithms to business problems e.g. regressions, K Nearest Neighbors, Random Forest, GBM, Neural Networks, boosted trees, LDA, collaborative filtering, Bayesian', 'Demonstrated critical thinking and problem-solving skills, leveraging data and working side-by-side with business owners to answer business questions ', 'Understand business problems and identify analytic needs including machine learning algorithms suitable for solving said problemWork collaboratively with other team members to define the advanced analytical modeling capabilities, enhancements and outcomes required to enable marketing & personalization use cases Perform data engineering tasks required for machine learning use case using PySpark/SQL to aggregate, transform, and check multiple data sources into a centralized repository on AWSBuild, maintain and improve machine learning models to perform at scale in a production ready environmentDevelop new features and augment tools based on business requirementsBuild and maintain clear record of data hierarchy / lineage, to support best-in-class database management and model buildingWork collaboratively with the Data Architects, Data Scientists, and other members of the Analytics team to design and build all necessary data pipelines and support other efforts required for the personalization visionWork with other members of the Personalization Data, Analytics, and Tech teams to peer review code, write unit tests, and provide feedback on data structuring and modeling approachesDesign the test and learn / measurement approaches and techniques for newly deployed use casesBe a SME of all data sources such as browse, all channel transactions, product, market research, credit, loyalty and 3rd party data to drive efficiencies, maximize profitability, drive customer loyalty, and optimize promotional strategies.Participate in the strategic development of system capabilities within advanced analytics and modeling, data mining and database marketing', 'Participate in the strategic development of system capabilities within advanced analytics and modeling, data mining and database marketing']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Machine Learning Engineer,Tapjoy,"San Francisco, CA",11 hours ago,Be among the first 25 applicants,"['', 'Position Title: ', ' Experiment and improve machine learning models for the recommendation/ad optimization system.  Inform bidding strategy and data engineering architecture.  Understand various ad-optimization algorithms (CTR prediction, eCPM optimization, user targeting and segmentation, RTB optimization, Exploration/Exploitation Algos)  ', 'Deep expertise in recommendation systems, classification models, class imbalance, and model calibration. ', 'Inform bidding strategy and data engineering architecture. ', 'Scaling GPU clusters to train deep neural networks. ', 'Domain and/or marketplace knowledge ', 'Packages: scikit-learn, TensorFlow. ', 'Experience with BigQuery or PySpark or another modern method to access data. ', 'Experimental Design and statistical inference. ', 'Experience with deploying and monitoring real-time model endpoint in AWS SageMaker is a plus ', 'Experiment and improve machine learning models for the recommendation/ad optimization system. ', 'Understand various ad-optimization algorithms (CTR prediction, eCPM optimization, user targeting and segmentation, RTB optimization, Exploration/Exploitation Algos) ', 'Solid coding skills in SQL and in a scripting language like Python. ', 'Competencies', 'Responsibilities', ' Solid coding skills in SQL and in a scripting language like Python.  Packages: scikit-learn, TensorFlow.  Scaling GPU clusters to train deep neural networks.  Deep expertise in recommendation systems, classification models, class imbalance, and model calibration.  Experience with BigQuery or PySpark or another modern method to access data.  Experience with deploying and monitoring real-time model endpoint in AWS SageMaker is a plus  Experimental Design and statistical inference.  ', 'Bonus']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Data Engineer,Olive,"Denver, CO",16 hours ago,44 applicants,"['', 'Communicate effectively and efficiently across all divisions including with the business, technical teams, and leaders', ' Collaborate with Engineers, Analysts, and Product Managers to design and implement features Ability to meet deadlines and satisfy requirements from stakeholders Peer review and code review participation to provide valuable feedback during every step of the development process Quickly produce well-organized, optimized, and documented code Communicate effectively and efficiently across all divisions including with the business, technical teams, and leaders Take technical ownership of tasks and successfully work independently Demonstrate the ability to become a domain expert in projects Mentor and lead junior engineers on multiple tasks or projects ', 'Responsibilities (to Include But Not Limited To)', 'Quickly produce well-organized, optimized, and documented code', 'Experience with the Telegraf, Grafana, InfluxDB, and Flink or other time series analysis stack', 'Description', 'Ability to meet deadlines and satisfy requirements from stakeholders', 'Peer review and code review participation to provide valuable feedback during every step of the development process', 'Knowledge of software and application design and architecture', '4+ years of SQL experience', 'Bachelor’s in Computer Science, Computer Engineering, or relevant equivalent experience', 'AWS experience preferred (Kinesis, S3, IAM)', 'History of designing and delivering software solutions to real world problems across a variety of technology stacks and programming languages with deep experience in several modern programming languages (e.g. JavaScript, Python, Go, JVM based languages)', 'Requirements', 'Mentor and lead junior engineers on multiple tasks or projects', '1-2+ years of Streaming Data and Analytics experience', 'Strong communication, critical thinking, and problem solving skills ', 'Some experience with data modeling', 'Demonstrated understanding of fundamentals engineering concepts', 'Take technical ownership of tasks and successfully work independently', 'Experience with data visualization through tools such as Tableau', 'Collaborate with Engineers, Analysts, and Product Managers to design and implement features', '5+ years of relevant programming experience', ' Bachelor’s in Computer Science, Computer Engineering, or relevant equivalent experience 5+ years of relevant programming experience 4+ years of SQL experience 1-2+ years of Streaming Data and Analytics experience Experience with data visualization through tools such as Tableau Some experience with data modeling Experience with the Telegraf, Grafana, InfluxDB, and Flink or other time series analysis stack AWS experience preferred (Kinesis, S3, IAM) History of designing and delivering software solutions to real world problems across a variety of technology stacks and programming languages with deep experience in several modern programming languages (e.g. JavaScript, Python, Go, JVM based languages) Strong communication, critical thinking, and problem solving skills  Demonstrated understanding of fundamentals engineering concepts Knowledge of software and application design and architecture ', 'Demonstrate the ability to become a domain expert in projects']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Multimedia Solutions,"Edgewater, NJ",23 hours ago,84 applicants,"['', 'Multimedia Solutions is seeking a curious and skilled Data Scientist to lead the development of a data warehousing and data mining solution in order to provide marketing executives with rich insights into the overall client journey. By collecting data on user behavior, channel effectiveness, content preferences, and other behavioral attributes, the overriding goal will be to leverage data-driven insights to provide a tailored and personalized client experience, both online and offline.', 'Formulate a roadmap of project activity that leads to measurable improvement in business performance metrics/ key performance indicators over time. ', 'Research and develop methods for measuring and analyzing the effectiveness of digital marketing performance (spend, impressions, click-thru’s, conversions)', 'Identify and propose new ways for modeling user behavior ', 'Strong technical background and experience with current business intelligence and reporting technologies ', 'Are you interested in helping to drive digital transformation through harnessing the power of data?', '4+ years of relevant experience', 'MS or PhD in Statistics or Mathematics a plus', 'Responsibilities', 'Effective written and verbal communication skills', 'Oversee and develop a deep, analytical understanding of customer behavior and business performance, with a focus on Return On Investment (ROI)', 'Experience in statistical software (R, SAS, SPSS, Alteryx, MATLAB, STATA), databases (Terradata or similar) and scripting languages (such as Python). ', 'Convey through storytelling data-driven insights and communicate opportunities with clients and internal teams', 'Deep interest and aptitude in data, metrics, analysis and trends', 'If you possess an entrepreneurial spirit, embrace a close-knit small business environment, and want to have a big impact on the firm and your career, please read on.', 'Oversee and develop a deep, analytical understanding of customer behavior and business performance, with a focus on Return On Investment (ROI)Formulate data warehouse infrastructure to integrate with multiple data streams, this includes, but is not limited to, captured event data, customer data, third-party data, surveys and marketing channel dataConvey through storytelling data-driven insights and communicate opportunities with clients and internal teamsIdentify and propose new ways for modeling user behavior Research and develop methods for measuring and analyzing the effectiveness of digital marketing performance (spend, impressions, click-thru’s, conversions)Formulate a roadmap of project activity that leads to measurable improvement in business performance metrics/ key performance indicators over time. Work with management team to architect, develop and automate analytics solutions Help formulate business recommendations for clients (cost-benefit, forecasting, impact analysis) with effective presentations of findings at multiple levels of stakeholders through displays of quantitative information Creatively explore how to use data to continually add value and translate ad hoc questions into flexible methodologies that scale to answer broad problems across client organizations', 'Formulate data warehouse infrastructure to integrate with multiple data streams, this includes, but is not limited to, captured event data, customer data, third-party data, surveys and marketing channel data', 'Proven ability to process large data sets from multiple sources, and perform data preparation, consolidation, transformation and mining', 'Experience linking multiple data platforms (social media, open, etc.) with data visualization tools (e.g., Tableau, Google Data Studio) ', 'Proficiency in Microsoft Excel and Microsoft PowerPoint', '4+ years of relevant experienceStrong technical background and experience with current business intelligence and reporting technologies Proficiency with relational databases and data architectureProven ability to process large data sets from multiple sources, and perform data preparation, consolidation, transformation and miningStrong SQL development skills- writing complex queries and stored procedures- SQL, PL/SQL, T-SQL Experience linking multiple data platforms (social media, open, etc.) with data visualization tools (e.g., Tableau, Google Data Studio) Experience in statistical software (R, SAS, SPSS, Alteryx, MATLAB, STATA), databases (Terradata or similar) and scripting languages (such as Python). Ability to articulate business questions, pulling from datasets and using statistics to arrive at a meaningful conclusion that translates into business recommendationsDeep interest and aptitude in data, metrics, analysis and trendsProficiency in Microsoft Excel and Microsoft PowerPointFamiliarity with common KPIs, metrics, and growth experimentsMS or PhD in Statistics or Mathematics a plusEffective written and verbal communication skills', 'As our Data Scientist, you will be responsible for charting our course in developing and implementing an enterprise level platform that will aggregate data from varied silos, perform meaningful analysis that enables digital marketing optimizations, and delivers valuable insights through a robust data visualization layer. ', 'Familiarity with common KPIs, metrics, and growth experiments', 'Creatively explore how to use data to continually add value and translate ad hoc questions into flexible methodologies that scale to answer broad problems across client organizations', 'Desired Skills and Experience', 'Work with management team to architect, develop and automate analytics solutions ', 'Help formulate business recommendations for clients (cost-benefit, forecasting, impact analysis) with effective presentations of findings at multiple levels of stakeholders through displays of quantitative information ', 'Strong SQL development skills- writing complex queries and stored procedures- SQL, PL/SQL, T-SQL ', 'Ability to articulate business questions, pulling from datasets and using statistics to arrive at a meaningful conclusion that translates into business recommendations', 'Proficiency with relational databases and data architecture']",Mid-Senior level,Full-time,Analyst,Marketing and Advertising,2020-11-05 11:32:32
Applied Scientist,Amazon,"New York, NY",6 hours ago,Be among the first 25 applicants,"['', ' Supporting decision making by providing requirements to develop analytic capabilities, platforms, pipelines and metrics then using them to analyze trends and find root causes of forecast inaccuracy', ' Natural curiosity and desire to learn.', ' 2+ years of relevant working experience in an analytical role involving data extraction, analysis, statistical modeling, and communication.', 'Preferred Qualifications', ' Fluency in a scripting or computing language (e.g. Python, Scala, C++, Java, etc.)', 'Company', ' Improving upon existing Demand Forecasting statistical or machine learning methodologies by developing new data sources, testing model enhancements, running computational experiments, and fine-tuning model parameters for new forecasting models', 'Basic Qualifications', 'Description', 'Major Responsibilities Include', ' Translating Demand Forecasting business questions and concerns into specific analytical questions that can be answered with available data using statistical and machine learning methods; working with engineers to produce the required data when it is not available Providing feedback to our science and engineering teams on the applicability of technical solutions from the business perspective Presenting critical data in a format that is immediately useful to answer questions about the inputs and outputs of Demand Forecasting systems and improving their performance Communicating verbally and in writing to business customers with various levels of technical knowledge, educating them about our systems, as well as sharing insights and recommendations Improving upon existing Demand Forecasting statistical or machine learning methodologies by developing new data sources, testing model enhancements, running computational experiments, and fine-tuning model parameters for new forecasting models Supporting decision making by providing requirements to develop analytic capabilities, platforms, pipelines and metrics then using them to analyze trends and find root causes of forecast inaccuracy Formalizing assumptions about how demand forecasts are expected to behave, creating definitions of outliers, developing methods to systematically identify these outliers, and explaining why they are reasonable or identifying fixes for them Utilizing code (Python, R, Scala, SQL etc.) for analyzing data and building statistical and machine learning models and algorithms', ' Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data. Superior verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering teams and business audiences. Proven ability to convey rigorous technical concepts and considerations to non-experts. Natural curiosity and desire to learn. Depth and breadth in quantitative knowledge. Excellent quantitative modeling, statistical analysis skills and problem-solving skills. Sophisticated user of statistical tools. Combination of deep technical skills and business savvy to interface with all levels and disciplines within our and our customer’s organizations. Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.', ' Communicating verbally and in writing to business customers with various levels of technical knowledge, educating them about our systems, as well as sharing insights and recommendations', ' Superior verbal and written communication skills with the ability to effectively advocate technical solutions to scientists, engineering teams and business audiences.', ' 2+ years of experience with data querying languages (e.g. SQL, Hadoop/Hive, Scala) and statistical/mathematical software (e.g. R, Matlab, Stata)', ' Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.', ' Translating Demand Forecasting business questions and concerns into specific analytical questions that can be answered with available data using statistical and machine learning methods; working with engineers to produce the required data when it is not available', ' Combination of deep technical skills and business savvy to interface with all levels and disciplines within our and our customer’s organizations.', ' Utilizing code (Python, R, Scala, SQL etc.) for analyzing data and building statistical and machine learning models and algorithms', ' Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data.', ' Depth and breadth in quantitative knowledge. Excellent quantitative modeling, statistical analysis skills and problem-solving skills. Sophisticated user of statistical tools.', ' Bachelor’s, Master’s, or PhD degree in a quantitative field such as Statistics, Computer Science, Applied Mathematics, Economics, or Engineering.', ' Presenting critical data in a format that is immediately useful to answer questions about the inputs and outputs of Demand Forecasting systems and improving their performance', ' Formalizing assumptions about how demand forecasts are expected to behave, creating definitions of outliers, developing methods to systematically identify these outliers, and explaining why they are reasonable or identifying fixes for them', ' Proven ability to convey rigorous technical concepts and considerations to non-experts.', ' Bachelor’s, Master’s, or PhD degree in a quantitative field such as Statistics, Computer Science, Applied Mathematics, Economics, or Engineering. 2+ years of relevant working experience in an analytical role involving data extraction, analysis, statistical modeling, and communication. Fluency in a scripting or computing language (e.g. Python, Scala, C++, Java, etc.) 2+ years of experience with data querying languages (e.g. SQL, Hadoop/Hive, Scala) and statistical/mathematical software (e.g. R, Matlab, Stata)', ' Providing feedback to our science and engineering teams on the applicability of technical solutions from the business perspective']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
Data Science Consultant,The Select Group,"Charlotte, NC",2 hours ago,Be among the first 25 applicants,"['', 'This position is responsible for business consulting activities for the Analytics Competency Center ', '3-5 years of Data Science experience in addition to degree Experience with Python Experience with SQL Strong knowledge of basic and advanced predictive modeling Data Mining knowledge Mastery of statistics, machine learning, algorithms and advanced mathematics. Excellent verbal and written communication skills as well as the ability to bridge the gap between data science and business management Exceptional organizational skills and is detail oriented ', 'DATA SCIENTIST - REMOTE THEN ONSITE IN CHARLOTTE, NC', 'DATA SCIENTIST - REMOTE THEN ONSITE IN CHARLOTTE, NC ', 'Experience with SQL ', 'Strong knowledge of basic and advanced predictive modeling ', '3-5 years of Data Science experience in addition to degree ', 'RESPONSIBILITIES:', 'Excellent verbal and written communication skills as well as the ability to bridge the gap between data science and business management ', 'DATA SCIENTIST ', ' DATA SCIENTIST ', 'Perform data exploration and data mining ', 'Data Mining knowledge ', 'Exceptional organizational skills and is detail oriented ', 'Create and run models ', ""The Select Group is looking for a Data Scientist to support our client's Analytics Center. You will be responsible for serving as an expert in translating complex data into key strategy insights and valuable actions. If this sounds like the opportunity for you, apply now!DATA SCIENTIST REQUIREMENTS: "", ' ', 'REQUIREMENTS:', 'Create business intelligence, dashboards, visualizations, and/or other advanced analytics reports to adequately tell the business narrative ', 'Discover business narratives told by the data and present them to other scientists, business stakeholders, and managers at various levels ', 'Offer recommendations that are practiced, actionable, and have material impact, in addition to being well-supported by analytical models and data', 'Mastery of statistics, machine learning, algorithms and advanced mathematics. ', 'This position is responsible for business consulting activities for the Analytics Competency Center Discover business narratives told by the data and present them to other scientists, business stakeholders, and managers at various levels Develop and test heuristics Create and run models Perform data exploration and data mining Create business intelligence, dashboards, visualizations, and/or other advanced analytics reports to adequately tell the business narrative Offer recommendations that are practiced, actionable, and have material impact, in addition to being well-supported by analytical models and data', 'Experience with Python ', 'Develop and test heuristics ']",Mid-Senior level,Contract,Information Technology,Oil & Energy,2020-11-05 11:32:32
Data Scientist,Via,"New York, NY",6 hours ago,Over 200 applicants,"['', '  A natural relationship builder that values camaraderie, comes with a sense of humor, and doesn’t take themselves too seriously   Obtained a Master’s degree in statistics, math, computer science, operations research, or other highly quantitative fields with 2+ years of industry experience in a Data Scientist or equivalent role, or a PhD degree with 3+ years of highly quantitative graduate-level research experience.   Mastery in some or all of the following: SQL, Python, R, and Tableau   Obsessed with data; analytical and rigorous, with a thorough understanding of statistics and machine learning   Extraordinary communicator with demonstrated writing and editing skills.   Passionate about elegant visualization; you understand the importance of graphic techniques in communicating a quantitative idea effectively   Deep understanding of business concepts within strategy, operations, and marketing  ', ' Deep understanding of business concepts within strategy, operations, and marketing ', ' Extraordinary communicator with demonstrated writing and editing skills. ', 'What You’ll Do', 'What Catches Our Eye', '  Experience with the transportation industry is a plus   Prior role at a startup or similar high-growth environment  ', ' Adeptly interpret and utilize mass quantities of data to generate innovative hypotheses & insights, and present these insights to the different stakeholders ', ' Obsessed with data; analytical and rigorous, with a thorough understanding of statistics and machine learning ', ' Mastery in some or all of the following: SQL, Python, R, and Tableau ', ' A natural relationship builder that values camaraderie, comes with a sense of humor, and doesn’t take themselves too seriously ', ' Quantitatively test hypotheses about customer and driver behavior using large sets of proprietary data; leverage results to increase conversion and retention at every touch point ', ' Prior role at a startup or similar high-growth environment ', 'Data Scientist', ' Obtained a Master’s degree in statistics, math, computer science, operations research, or other highly quantitative fields with 2+ years of industry experience in a Data Scientist or equivalent role, or a PhD degree with 3+ years of highly quantitative graduate-level research experience. ', 'Who You Are', ' Passionate about elegant visualization; you understand the importance of graphic techniques in communicating a quantitative idea effectively ', ' Design and implement novel experiments to better understand current operation as well as expansion to new markets ', ' Use sophisticated statistical methods to solve problems, leveraging up-to-date academic research and tools ', ' Experience with the transportation industry is a plus ', '  Adeptly interpret and utilize mass quantities of data to generate innovative hypotheses & insights, and present these insights to the different stakeholders   Use sophisticated statistical methods to solve problems, leveraging up-to-date academic research and tools   Quantitatively test hypotheses about customer and driver behavior using large sets of proprietary data; leverage results to increase conversion and retention at every touch point   Design and implement novel experiments to better understand current operation as well as expansion to new markets  ']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Senior AI/ML/NLP Data Scientist,BURNCO Rock Products Ltd,"Dallas, TX",10 hours ago,Be among the first 25 applicants,"['', 'Parallel and distributed processing experience is a plus', 'At least 3 years of Machine Learning', 'Ayata', 'Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments.', 'Job Responsibilities And Duties', 'Build and integrate models into a full-functioning AI business software', 'Lead model development, providing methodology, strategy, ideas, architect, and solutions for real-word, industrial-scale and mission-critical business operations', 'Responsibilities', 'PhD degree in Mathematics, Statistics, Computer Science, or related disciplines', 'The candidate must be able to work out of the Houston Texas office but remote work will be considered for extremly strong candidate', 'Industry (tech/software industry) standard benefits package - medical, dental, vision, 401(k) plan, work-from-home (if applicable), flexible holidays, and more.', 'At least 3 years of Artificial Intelligence', 'Benefits', 'Interact with business clients, understand business requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients', 'Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition', 'Communicate effectively with team members, management, and clients', 'Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models', 'Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing', 'Relocation reimbursement is available for the right candidate', ' Parallel and distributed processing experience is a plus Expertise in data Extraction Transformation and Loading (ETL) is a strong plus (Spark, Hadoop, SQL) in big data environments. Domain knowledge in financial and insurance industries is a big plus ', 'Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering', 'Domain knowledge in financial and insurance industries is a big plus', 'Requirements', '5-8 years of the latest machine learning/AI technology', 'Excellent hands-on code development skills in Python', 'You must have a PHD to be considered for this position. ', 'Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.)', 'Background in Property and Casulity Insurance a big plus!', 'Additional Qualifications', 'Compensation package (base salary + performance bonus + stock options) commensurate with experience.', ' Compensation package (base salary + performance bonus + stock options) commensurate with experience. Industry (tech/software industry) standard benefits package - medical, dental, vision, 401(k) plan, work-from-home (if applicable), flexible holidays, and more.', 'You must be able to work out of our Houston office', 'Develop AI/ML models for business applications', ' 5-8 years of the latest machine learning/AI technology Proven ability to work with large structured and unstructured datasets Demonstrable, hands-on experience in developing advanced analytics algorithms/models, including time series forecasting, machine learning and deep learning, image processing, natural language processing, and speech recognition Excellent hands-on code development skills in Python Good Knowledge of Machine Learning frameworks and packages, including Keras, TensorFlow, MXnet, Scikit-Learn and cloud technology (Amazon, Azure, etc.) Experiences in Machine Learning, Deep Learning, Computer Vision, and Natural Language Processing PhD degree in Mathematics, Statistics, Computer Science, or related disciplines At least 3 years of Artificial Intelligence At least 3 years of Machine Learning Background in Property and Casulity Insurance a big plus! You must be able to work out of our Houston office ', ' Lead model development, providing methodology, strategy, ideas, architect, and solutions for real-word, industrial-scale and mission-critical business operations Develop AI/ML models for business applications Build and integrate models into a full-functioning AI business software Interact with business clients, understand business requirements, propose AI software solutions to meet the business requirements, deliver and present AI software to clients Understand the data set used for the modeling, prepare and preprocess data sets, train and test models and perform model feature engineering Document data dictionary, data understanding, modeling strategy and approaches, and build company’s knowledge base of data and models Communicate effectively with team members, management, and clients ', 'Senior Machine Learning Research Scientist ', 'Proven ability to work with large structured and unstructured datasets']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist - 100% Remote Available,USAA,"San Antonio, TX",6 hours ago,89 applicants,"['', 'Preferred Requirements', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree."", 'Relocation', 'Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions.', 'Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.', 'Works with IT to research architecture for new products, services, and features.', ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization."", 'Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.', 'Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.', 'Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.', 'Develops algorithms and supporting code such that research efforts are based on the highest quality data.', 'Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required.', 'Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree.4 or more years of related experience and accountability for complex tasks and/or projects required.Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required."", 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.', '4 or more years of related experience and accountability for complex tasks and/or projects required.', ""Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation."", ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization.Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation.Works with IT to research architecture for new products, services, and features.Develops algorithms and supporting code such that research efforts are based on the highest quality data.Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions."", 'available', 'Minimum Requirements', 'Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).', 'PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).', 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).', 'Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.', 'Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).']",Not Applicable,Full-time,Engineering,Financial Services,2020-11-05 11:32:32
"Data Scientist, Decisions",Lyft,"San Francisco, CA",5 hours ago,Over 200 applicants,"['', 'Mental health benefits', 'Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience', '5+ years of industry experience in a data science or analytics role', 'Experience in programming, especially with data science and visualization libraries in Python or R', 'Responsibilities', 'Benefits', 'Leverage data and analytic frameworks to identify opportunities for growth and efficiency ', 'Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners ', '18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible', 'Design and analyze experiments; communicate results and act on launch decisions', 'Pre-tax commuter benefits', 'Lyft is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. Lyft does not make hiring or employment decisions on the basis of race, color, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender-identity, sexual orientation, disability, age, military or veteran status, or any other basis protected by applicable local, state, or federal laws or prohibited by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Pursuant to the San Francisco Fair Chance Ordinance and other similar state laws and local ordinances, and its internal policy, Lyft will also consider for employment qualified applicants with arrest and conviction records.', 'In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off', 'Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action', ' Leverage data and analytic frameworks to identify opportunities for growth and efficiency  Partner with product managers, engineers, marketers, designers, and operators to translate data insights into decisions and action Design and analyze experiments; communicate results and act on launch decisions Develop analytical frameworks to monitor business and product performance Establish metrics that measure the health of our products, as well as rider and driver experience ', 'Develop analytical frameworks to monitor business and product performance', 'Experience', 'Great medical, dental, and vision insurance options', 'Proficiency in SQL - able to write structured and efficient queries on large data sets', '401(k) plan to help save for your future', ' Degree in a quantitative field such as statistics, economics, applied math, operations research or engineering (advanced degrees preferred), or relevant work experience 5+ years of industry experience in a data science or analytics role Proficiency in SQL - able to write structured and efficient queries on large data sets Experience in programming, especially with data science and visualization libraries in Python or R Strong oral and written communication skills, and ability to collaborate with and influence cross-functional partners  ', 'Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program', ' Great medical, dental, and vision insurance options Mental health benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program ', 'Establish metrics that measure the health of our products, as well as rider and driver experience']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
SENIOR DATA SCIENTIST,JBS USA,"Richardson, TX",8 hours ago,Be among the first 25 applicants,"['', 'Master’s degree in Applied Mathematics, Computer Science, Software Engineering, Statistics, Business Analytics, Agribusiness, Accounting, Finance, Economics, etc. or equivalent experience', 'Position at JBS USA Food Company', 'Passion for innovation and “can do” attitude', 'Passion for learning, improving process and attentions to the form of how the information it is presented', 'Knowledge in Keras, TensorFlow, H2O, data virtualization, RPA (Automation Anywhere) and cloud computing infrastructures (AWS, Azure, GCP)', 'Master’s degree in Applied Mathematics, Computer Science, Software Engineering, Statistics, Business Analytics, Agribusiness, Accounting, Finance, Economics, etc. or equivalent experienceExperience in data science with a desired knowledge of SAP, QlikView or Qlik SenseHighly proficient in Python and SQLSolid technical hands-on skills in machine learning (regression, classification, clustering, dimensionality reduction), deep learning (CNN, RNN/LSTM, GAN), time series data, anomaly detection, statistical algorithms, data mining, and data engineeringKnowledge in Keras, TensorFlow, H2O, data virtualization, RPA (Automation Anywhere) and cloud computing infrastructures (AWS, Azure, GCP)Strong ability to use logic and excellent problem-solving skillsAbility to work independently and be flexibleAbility to thrive in a fast paced, highly dynamic environmentDemonstrated experience with agile or other rapid development methodsPassion for innovation and “can do” attitudeExperience in agricultural industry data science is a plus.', 'Successful Candidate: ', 'Working with different business organizations across the company to understand their needs and help identify new opportunities.', 'Responsibilities', 'Ability to work independently and be flexible', 'Leveraging and sharing the latest machine and deep learning techniques to challenge the current practices across the business unitsStandardizing the platforms architecture, maintenance and administrationDeveloping the Citizen Data Science program content to train & mentor our subject matter expertsDeveloping a data lake and/or data catalog for each business unitManaging the code and artifacts, including models, algorithms, templates, tools, policies, guidelines, etc.Working with different business organizations across the company to understand their needs and help identify new opportunities.', 'EOE/M/F/VET/DISABLED', 'Description', 'Know how to prioritize the deliverable', 'Managing the code and artifacts, including models, algorithms, templates, tools, policies, guidelines, etc.', 'Demonstrated experience with agile or other rapid development methods', 'Have a strong analytical mindset so that they can drive decisions in a fact-based environment', 'Qualifications', 'Strong ability to use logic and excellent problem-solving skills', 'Ability to thrive in a fast paced, highly dynamic environment', 'Leveraging and sharing the latest machine and deep learning techniques to challenge the current practices across the business units', 'Solid technical hands-on skills in machine learning (regression, classification, clustering, dimensionality reduction), deep learning (CNN, RNN/LSTM, GAN), time series data, anomaly detection, statistical algorithms, data mining, and data engineering', 'Relate with multiple teams to understand the problems of the business', 'Developing a data lake and/or data catalog for each business unit', 'Developing the Citizen Data Science program content to train & mentor our subject matter experts', 'Highly proficient in Python and SQL', 'Take the initiative, easily understand the business dynamics, see the big picture, assess current practices and identify new areas where inefficiencies affect the bottom line of the companyUnderstand the uses of business and market information to better drive decisionsRelate with multiple teams to understand the problems of the businessHave a strong analytical mindset so that they can drive decisions in a fact-based environmentKnow how to prioritize the deliverablePassion for learning, improving process and attentions to the form of how the information it is presented', 'Standardizing the platforms architecture, maintenance and administration', 'Take the initiative, easily understand the business dynamics, see the big picture, assess current practices and identify new areas where inefficiencies affect the bottom line of the company', 'Understand the uses of business and market information to better drive decisions', 'Experience in data science with a desired knowledge of SAP, QlikView or Qlik Sense', 'Experience in agricultural industry data science is a plus.']",Associate,Full-time,Other,Food & Beverages,2020-11-05 11:32:32
Data Scientist,Diverse Lynx,"Cary, NC",45 minutes ago,Be among the first 25 applicants,"['', ' Experience working with large data sets, experience working with AWS cloud', 'Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.', ' Hands on SQL / PySpark queries', ' Strong knowledge on Python, R & other statistical tools']",Entry level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cleared Data Scientist,Huxley,Washington DC-Baltimore Area,3 hours ago,Be among the first 25 applicants,"[""A government contractor in DC is looking for a Senior Data Scientist to join their innovative team. The ideal candidate will have a Master's degree and 2 years’ experience with an active security clearance. "", '· \xa0 \xa0 \xa0 Ability to solve problems in innovative ways ', '· \xa0 \xa0 \xa0 A Bachelors’ or Masters’ in related field (physics, computer science, etc.) ', '· \xa0 \xa0 \xa0 3 or more years’ experience in neural networks, knowledge graphs, and geospatial data ', '· \xa0 \xa0 \xa0 Expert in Python ', 'Responsibilities will include: deploying and managing models for customer needs, managing data science projects, collaborating with R&D, Sales, etc to provide the best solutions, and being a trusted advocate for the client’s data science vision.', '· \xa0 \xa0 \xa0 Must hold active security clearance (TS or above preferred) ', '· \xa0 \xa0 \xa0 Excellent communication skills and experience interacting with clients and stakeholders ', ' ', 'The ideal candidate will have: ']",Mid-Senior level,Full-time,Information Technology,Defense & Space,2020-11-05 11:32:32
Machine Learning Engineer - Data Science,Systems & Technology Research,"Woburn, MA",19 hours ago,Be among the first 25 applicants,"['', 'A U.S. citizen and have ability to obtain and maintain a security clearance', 'Motivated collaborator who’s comfortable communicating to both technical and non-technical audiences', 'Track record of developing, implementing, and evaluating statistical algorithms against real datasets', 'Previous experience (internships and academic work included) working with complex datasets and building statistical, machine learning, or deep learning models', 'Experience working with large datasets and familiarity with big data infrastructure, such as AWS, Hadoop, Spark, Dask, or MapReduce', 'Understanding of and experience with statistical and machine learning techniques', 'About the Team', 'Description', 'Degree in a scientific field such as Computer Science, Math, Statistics, Data Science, or Physics', ' MS or PhD in a scientific field such as Computer Science, Statistics, Mathematics, or Physics Track record of developing, implementing, and evaluating statistical algorithms against real datasets Specialized expertise in a data-rich field such as time-series analysis, graph analytics, geospatial analysis, image processing, or Bayesian programming Experience with one or more deep learning frameworks such as PyTorch or Tensorflow Experience working with large datasets and familiarity with big data infrastructure, such as AWS, Hadoop, Spark, Dask, or MapReduce Active TS or TS/SCI security clearance ', 'Active TS or TS/SCI security clearance', 'Experience with one or more deep learning frameworks such as PyTorch or Tensorflow', 'The Role', 'Machine Learning Engineer – Data Science', ' Degree in a scientific field such as Computer Science, Math, Statistics, Data Science, or Physics Understanding of and experience with statistical and machine learning techniques Proficiency with a one or more programming language such as Python, MATLAB, Java, or C++ Previous experience (internships and academic work included) working with complex datasets and building statistical, machine learning, or deep learning models Motivated collaborator who’s comfortable communicating to both technical and non-technical audiences A U.S. citizen and have ability to obtain and maintain a security clearance ', 'Specialized expertise in a data-rich field such as time-series analysis, graph analytics, geospatial analysis, image processing, or Bayesian programming', 'Requirements', 'Even Better', 'Who You Are', 'MS or PhD in a scientific field such as Computer Science, Statistics, Mathematics, or Physics', 'Proficiency with a one or more programming language such as Python, MATLAB, Java, or C++']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist,Insight,"Columbus, OH",13 hours ago,Be among the first 25 applicants,"['', 'APPLY', 'Insight Named Microsoft Worldwide Customer Experience Partner of the Year', '5+ years of professional advanced analytics development and delivery experience', 'Fortune Top 100 Best Companies for Diversity', '30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizesMicrosoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOpsFortune Top 100 Best Companies for DiversityFortune Top 50 Best Workplaces in TechnologyWinner of several “Best Places to Work” awards30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Experience in traditional database development and analysis (SQL, PowerBI, SSRS, etc.) ', 'Experience building statistical models and leveraging AI frameworks and accelerators: Cortana, Databricks, Azure Machine Learning, Caffe, YOLO, etc.', 'Drive discovery, design, and execution of advanced analytics solutions for external clientsWork closely with client business and technical stakeholders to shape the success of projectsProvide leadership at all stages of the delivery pipeline: estimations, design, management, coding, deployment, and more Create and deploy predictive models and utilizes analytical, statistical, and machine learning tools to uncover insightsCollaborate with other Insight Digital Innovation team members to ensure successful delivery and high business impact for our clientsPresent to client, industry, and internal peer groupsAggressively grow your skillset and expertise to meet the emerging of the market', 'Skilled at crystalizing vision into clear priorities, estimates, tasks, and deliverables', 'Insight Recognized at #14 on CRN’s 2019 Solution Provider 500 List', 'Proven skills delivering with core advanced analytics tools (Python, R, etc.)', 'Deep knowledge of AI cases and patterns: time series, classification, natural language processing, simulation, image recognition and more', 'Drive to make others great though collaboration, example and mentoring', 'Fortune Top 50 Best Workplaces in Technology', 'Strong communication skills with both technical and non-technical stakeholders ', 'What Our Data Scientists Do', 'About Insight', 'Insight in the News!', '5+ years of professional advanced analytics development and delivery experienceDeep knowledge of AI cases and patterns: time series, classification, natural language processing, simulation, image recognition and moreProven skills delivering with core advanced analytics tools (Python, R, etc.)Experience building statistical models and leveraging AI frameworks and accelerators: Cortana, Databricks, Azure Machine Learning, Caffe, YOLO, etc.Capability across the full advanced analytics lifecycle, including business discover, model operationalization, an model monitoring and maintenanceSkilled at crystalizing vision into clear priorities, estimates, tasks, and deliverablesDrive to make others great though collaboration, example and mentoringExperience in traditional database development and analysis (SQL, PowerBI, SSRS, etc.) Eagerness to learn new tools and technologies and passion to deliver quality solutions both individually and as part of a teamStrong communication skills with both technical and non-technical stakeholders ', 'Present to client, industry, and internal peer groups', 'Winner of several “Best Places to Work” awards', 'Capability across the full advanced analytics lifecycle, including business discover, model operationalization, an model monitoring and maintenance', 'Insight Earns 2020 Microsoft U.S. Partner of the Year Award', 'Insight Earns 2020 Microsoft U.S. Partner of the Year AwardInsight Named Microsoft Worldwide Customer Experience Partner of the YearInsight Recognized at #14 on CRN’s 2019 Solution Provider 500 List', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizes', 'Requisition Number: 78961 ', 'Create and deploy predictive models and utilizes analytical, statistical, and machine learning tools to uncover insights', 'What We Look For', 'Drive discovery, design, and execution of advanced analytics solutions for external clients', 'Aggressively grow your skillset and expertise to meet the emerging of the market', 'Collaborate with other Insight Digital Innovation team members to ensure successful delivery and high business impact for our clients', 'Ready to join?', 'Provide leadership at all stages of the delivery pipeline: estimations, design, management, coding, deployment, and more ', 'Work closely with client business and technical stakeholders to shape the success of projects', 'Eagerness to learn new tools and technologies and passion to deliver quality solutions both individually and as part of a team', 'What can Insight offer?', 'Microsoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOps']",Mid-Senior level,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Fellow Data Scientist,Ally,"Charlotte, NC",20 hours ago,Be among the first 25 applicants,"['', ""But Ally's Total Compensation -- Or Total Rewards -- Extends Beyond Your Paycheck And Is Designed To Support And Enrich Your Personal And Professional Life, Including"", ' Prepare and analyze account-level consumer data from internal and external sources to identify stronger predictors of defaults over the life course of loans', 'Business Unit/Enterprise Function ', ' Excellent written and verbal communication skills, including the ability to effectively present model development documentations to internal and external stakeholders', 'Ally is an Equal Opportunity Employer', 'Building a Family:', ' 7+ years of experience in supporting advanced modeling initiatives in the financial services industry with direct experiences in credit risk modeling', ' Ability to work effectively in fast paced environment and to provide support to multiple concurrent projects across LOBs', ' A PhD degree in a quantitative field (Economics, Statistics or a related discipline) is optimal, a master degree in a quantitative field (Economics, Statistics or a related discipline) is required', 'Time Away: competitive holiday and flexible paid-time-off, including time off for volunteering and voting.', '  A PhD degree in a quantitative field (Economics, Statistics or a related discipline) is optimal, a master degree in a quantitative field (Economics, Statistics or a related discipline) is required  7+ years of experience in supporting advanced modeling initiatives in the financial services industry with direct experiences in credit risk modeling  Strong background in probabilistic models and mathematical optimization with application in VaR and CECL analysis  Strong programming skills in Python and/or C++  Excellent written and verbal communication skills, including the ability to effectively present model development documentations to internal and external stakeholders  Ability to work effectively in fast paced environment and to provide support to multiple concurrent projects across LOBs ', 'Supporting your Health & Well-being:', ' Complete model documentation post development according to regulatory and compliance rules', 'Position Description', ' Determine, develop and document data requirements, modeling assumptions and model results for best practice methodologies deployed and alternatives approaches considered', ' Time Away: competitive holiday and flexible paid-time-off, including time off for volunteering and voting. Planning for the Future: benefits to help you plan for the near and long term including an industry-leading 401K retirement savings plan with matching and company contributions, student loan and 529 educational assistance programs, tuition reimbursement and other financial well-being programs. Supporting your Health & Well-being: flexible health and insurance options including dental and vision, pre-tax Health Savings Account with employer contributions and a total well-being program that helps you and family stay on track physically, socially, emotionally and financially. Building a Family: adoption, surrogacy and fertility support as well as benefits that help you take care of your family -- parental and caregiver leave, back-up child and adult/elder day care program and child-care discounts. Work-Life Integration: other benefits including LifeMatters® Employee Assistance Program, subsidized and discounted Weight Watchers® program and other employee discount programs. ', 'Planning for the Future:', 'Qualifications', "" Investigate new approaches, modeling techniques and uses of both batch and streaming data on Ally's big data platfom"", 'Time Away', 'Building a Family: adoption, surrogacy and fertility support as well as benefits that help you take care of your family -- parental and caregiver leave, back-up child and adult/elder day care program and child-care discounts.', ' Strong programming skills in Python and/or C++', 'Ally Overview', 'Job Responsibilities', 'Planning for the Future: benefits to help you plan for the near and long term including an industry-leading 401K retirement savings plan with matching and company contributions, student loan and 529 educational assistance programs, tuition reimbursement and other financial well-being programs.', ' Strong background in probabilistic models and mathematical optimization with application in VaR and CECL analysis', ' Convert models to be executed in a high-performance computing environment; deploy models in this environment and monitor and update as required. ', 'Total Rewards Information', 'Work-Life Integration: ', ' Support model implementation and monitor production activities post development', 'Work-Life Integration: other benefits including LifeMatters® Employee Assistance Program, subsidized and discounted Weight Watchers® program and other employee discount programs.', ""  Convert models to be executed in a high-performance computing environment; deploy models in this environment and monitor and update as required.   Prepare and analyze account-level consumer data from internal and external sources to identify stronger predictors of defaults over the life course of loans  Complete model documentation post development according to regulatory and compliance rules  Support model implementation and monitor production activities post development  Investigate new approaches, modeling techniques and uses of both batch and streaming data on Ally's big data platfom  Determine, develop and document data requirements, modeling assumptions and model results for best practice methodologies deployed and alternatives approaches considered "", 'Supporting your Health & Well-being: flexible health and insurance options including dental and vision, pre-tax Health Savings Account with employer contributions and a total well-being program that helps you and family stay on track physically, socially, emotionally and financially.']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Intelligence Product Analyst/ Data Scientist - Strategy & Growth,Salesforce,"Chicago, IL",10 hours ago,Be among the first 25 applicants,"['', 'Posting Statement', 'Curious, creative, opinionated thinker with a talent for detecting patterns and elevating through strategy.', 'Advanced expert in SQL. Experience with Splunk, Python/R, and BI tools is a plus.', 'Contribute to expanding the Salesforce data culture by growing new relationships, hosting learning sessions, integrating or designing new tools, improving team processes, and other lateral activities.', 'What You Will Do', 'Salesforce.com', 'Produce insights (e.g. performance drivers, retention analysis, behavioral personas) to help grow Salesforce Cloud businesses. This requires acquiring, cleaning, structuring data from multiple sources (e.g. Hadoop, Splunk), and analyzing the data using SQL / Python / R.', 'Accommodations ', 'To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.', 'Job Details', 'Lover of math with solid understanding of statistical methods.', 'Thought leader in analytics (4-9 years of experience in product analytics, sales analytics, marketing analytics or similar, as IC or people manager).', 'Laser focused on impact, balancing effort to value, and getting things done.', 'Partner with Senior Leadership (VP+) to understand their business and advise on strategic objectives, product direction, roadmaps, growth goals, retention strategies, etc. Develop and own the relationships with senior stakeholders across the companyProduce insights (e.g. performance drivers, retention analysis, behavioral personas) to help grow Salesforce Cloud businesses. This requires acquiring, cleaning, structuring data from multiple sources (e.g. Hadoop, Splunk), and analyzing the data using SQL / Python / R.When analyses are ready to be productized, own the delivery by working with engineers and data scientists to turn insights into self-service dashboards or data products.Evangelize the insights through storytelling. Create easy-to-consume media that inspires into action anyone from senior execs to fellow analysts.Contribute to expanding the Salesforce data culture by growing new relationships, hosting learning sessions, integrating or designing new tools, improving team processes, and other lateral activities.', 'Who You Are', 'Partner with Senior Leadership (VP+) to understand their business and advise on strategic objectives, product direction, roadmaps, growth goals, retention strategies, etc. Develop and own the relationships with senior stakeholders across the company', 'Accommodations  - ', 'Salesforce.org', 'Charismatic storyteller ready to lead growth conversations with senior leadership.', 'Expert in building relationships and collaborating in matrixed environments.', 'Job Category', 'Department Overview - Data Intelligence', 'Salesfore.com', 'Evangelize the insights through storytelling. Create easy-to-consume media that inspires into action anyone from senior execs to fellow analysts.', 'When analyses are ready to be productized, own the delivery by working with engineers and data scientists to turn insights into self-service dashboards or data products.', 'Thought leader in analytics (4-9 years of experience in product analytics, sales analytics, marketing analytics or similar, as IC or people manager).Laser focused on impact, balancing effort to value, and getting things done.Curious, creative, opinionated thinker with a talent for detecting patterns and elevating through strategy.Charismatic storyteller ready to lead growth conversations with senior leadership.Expert in building relationships and collaborating in matrixed environments.Advanced expert in SQL. Experience with Splunk, Python/R, and BI tools is a plus.Lover of math with solid understanding of statistical methods.Enterprise software geek. Passion for Salesforce product is a plus!', 'Enterprise software geek. Passion for Salesforce product is a plus!']",Not Applicable,Full-time,Business Development,Computer Software,2020-11-05 11:32:32
Data Scientist,Alight Solutions,"Chicago, IL",4 hours ago,174 applicants,"['', 'Uncover strategic insights in our data to drive value. Manage data, build models and visualizations to identify patterns Develop algorithms and programs needed to support analytics activities Research and develop statistical learning models for data analysis Collaborate with teams of experienced analysts, developers and business experts to implement opportunities as they are discovered Keep up-to-date with latest technology trends Communicate results and ideas to key decision makers Implement new statistical or other mathematical methodologies as needed for specific models or analysis Optimize joint development efforts through appropriate database use and project design Other responsibilities as identified ', 'Manage data, build models and visualizations to identify patterns ', 'Excellent communication and presentation skills ', 'Able to understand various data structures and common methods in data transformation ', 'Intellectually curious with an ability to focus on what matters to the business ', 'Develop algorithms and programs needed to support analytics activities ', 'Disclaimer', 'Uncover strategic insights in our data to drive value. ', 'Excellent pattern recognition and predictive modeling skills ', 'Track-record of independent learning and technical problem-solving ', 'Able to identify and solve problems on your own ', 'Passionate about quality ', ""Master's degree or relevant experience in Statistics, Physical Sciences, Operations Research, Engineering, Mathematics or related quantitative fields. 5 plus years' practical experience with ETL, data processing, database programming and data analytics "", ""Master's degree or relevant experience in Statistics, Physical Sciences, Operations Research, Engineering, Mathematics or related quantitative fields. "", ""5 plus years' practical experience with ETL, data processing, database programming and data analytics "", 'Detail-oriented ', 'Demonstrated ability to work collaboratively in a team ', 'Self-driven and comfortable working without detailed direction ', 'Knowledge/Skills', 'Role model for global and cross-cultural team support ', 'Communicate results and ideas to key decision makers ', 'Strong understanding of software technology, computational techniques, and data models ', 'Collaborate with teams of experienced analysts, developers and business experts to implement opportunities as they are discovered ', 'Coaches broader team on data science methodology ', 'Keep up-to-date with latest technology trends ', 'Extensive background in data mining and statistical analysis Able to understand various data structures and common methods in data transformation Excellent pattern recognition and predictive modeling skills Strong statistics and mathematics background Track-record of independent learning and technical problem-solving Experience managing projects and multiple priorities Demonstrated ability to work collaboratively in a team Excellent communication and presentation skills Ability to develop and communicate creative solutions to technical problems Strong understanding of software technology, computational techniques, and data models Experience deploying predictive models into production Expertise using Tableau, Power BI (or similar visualization tool) and SQL. We expect you are an Excel superuser. Expertise with Python/R and other leading programming and statistical applications Experience working with and manipulating large data sets, including Big Data tools and platforms (e.g. Hadoop) Role model for global and cross-cultural team support Coaches and provides feedback to other colleagues Coaches broader team on data science methodology ', 'Experience working with and manipulating large data sets, including Big Data tools and platforms (e.g. Hadoop) ', 'Key Characteristics', 'Experience deploying predictive models into production ', 'Coaches and provides feedback to other colleagues ', 'Expertise using Tableau, Power BI (or similar visualization tool) and SQL. We expect you are an Excel superuser. ', 'Responsibilities Include', 'Expertise with Python/R and other leading programming and statistical applications ', 'Optimize joint development efforts through appropriate database use and project design ', 'Other responsibilities as identified ', 'Extensive background in data mining and statistical analysis ', 'Strong statistics and mathematics background ', 'Experience managing projects and multiple priorities ', 'Ability to develop and communicate creative solutions to technical problems ', 'Self-Starter ', 'Research and develop statistical learning models for data analysis ', 'Self-driven and comfortable working without detailed direction Able to identify and solve problems on your own Strong presentation and communication skills Intellectually curious with an ability to focus on what matters to the business Detail-oriented Self-Starter Passionate about quality ', 'Strong presentation and communication skills ', 'Implement new statistical or other mathematical methodologies as needed for specific models or analysis ']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Research Scientist,KLA,"Ann Arbor, MI",11 hours ago,Be among the first 25 applicants,"['', 'With The Following Experiences/Skills', ' Group/Division ', ' Ability to invent, develop and implement new algorithms and ideas', ' Ability to work both independently and in a team environment.', ' Designing, developing, modifying and diagnosing complex algorithms', 'Qualifications', ' Excellent written and verbal communication skills.', ' Designing, developing, modifying and diagnosing complex algorithms Ability to invent, develop and implement new algorithms and ideas Hands-on experience in object-oriented and functional programming Hands-on experience with products such as Matlab, Python/TensorFlow is a plus Excellent written and verbal communication skills. Ability to work both independently and in a team environment.', 'We offer a competitive, family friendly total rewards package. We design our programs to reflect our commitment to an inclusive environment, while ensuring we provide benefits that meet the diverse needs of our employees. ', 'KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com to request accommodation.', 'Minimum Qualifications', ' Hands-on experience in object-oriented and functional programming', ' Hands-on experience with products such as Matlab, Python/TensorFlow is a plus', 'Company Overview']",Associate,Full-time,Other,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Data Engineer,Inventables,United States,47 minutes ago,Be among the first 25 applicants,"['', 'Curious, creative, and collaborative working style', 'A complimentary Inventables 3D Carving Machine', 'Collaborate with internal stakeholders to understand data storage, processing, and reporting requirements for the businessDevelop, test, and maintain data architectures including databases, and business intelligence platforms that meet stakeholder requirementsDesign and implement automated processes to collect and transform data from various internal systems into a centralized reporting platformRecommend ways to improve data reliability and qualityEmploy a variety of languages & tools to join data across multiple systems into a unified modelAssist stakeholders in building, using, and interpreting business intelligence dashboards that track their key performance indicators', 'Values the exchange of constructive feedback with a desire to improve', 'Our internal data platform is built with python, Amazon RDS, and Amazon Quicksight. We use agile development techniques to craft software and tools that help team members make data-driven decisions. We work collaboratively and iterate constantly. We choose the right technology for the job. We use automated testing to ensure our software is operating correctly and to allow us to make changes with confidence.', 'Recommend ways to improve data reliability and quality', 'Assist stakeholders in building, using, and interpreting business intelligence dashboards that track their key performance indicators', 'Always assumes positive intent', 'Collaborate with internal stakeholders to understand data storage, processing, and reporting requirements for the business', 'The Data Engineer will:\xa0', 'Bachelor’s degree in science, math, or engineering', '*No staffing firms please', 'Experience implementing automated data pipelines', 'Preferred:', 'Design and implement automated processes to collect and transform data from various internal systems into a centralized reporting platform', 'Annual “exploration budget” to feed your curiosity', 'ABOUT INVENTABLES', 'Bachelor’s degree3+ years programming experience with a modern computing language that supports data engineering work (Python, R, C#, JVM-languages like Java)Strong SQL skillsExperience using BI reporting tools such as Looker or AWS QuicksightExperience implementing automated data pipelinesGeneralist with a strong interest in using data to answer big questionsComfortable working individually (will be first member of the data team)Experience with agile processesCurious, creative, and collaborative working styleAlways assumes positive intentAbility to take initiative and persevere in the company’s success\xa0\xa0Values the exchange of constructive feedback with a desire to improve', 'BENEFITS & PERKS', 'Generalist with a strong interest in using data to answer big questions', 'Experience constructing and maintaining Postgres databases', 'ABOUT THE POSITION', 'Experience using BI reporting tools such as Looker or AWS Quicksight', 'Employ a variety of languages & tools to join data across multiple systems into a unified model', 'Bachelor’s degree', 'Strong SQL skills', 'Ability to take initiative and persevere in the company’s success\xa0\xa0', 'Develop, test, and maintain data architectures including databases, and business intelligence platforms that meet stakeholder requirements', 'Experience with Python', 'Comfortable working individually (will be first member of the data team)', 'Annual “creative project budget” to help you stay creative', 'Excellent Parental Leave Policy', 'Our vision is to ignite a new product revolution by bringing manufacturing capability into the hands of millions of people.\xa0To do this we are building accessible tools to help makers generate income from their work.\xa0The tools we build are software and hardware products designed to help businesses do their own manufacturing cost effectively. Our revolutionary, web-based Easel software is easy to use, whether you are new to designing products or familiar with CNC software. When you’re ready to carve, our X-Carve machine empowers users to create products out of a variety of materials ranging from beautiful hardwoods to colorful acrylics.\xa0', 'QUALIFICATIONS', 'Flexible Accrued Vacation ""Take what you need"" policy', 'BCBS Health Insurance', 'While our downtown Chicago office and workshop is a space where employees can meet, work, and use our products, we are a remote-first company and welcome talent located across the country.', 'Experience with linux shell scripting', 'Experience with source control systems such as git', 'Required:', 'Experience with agile processes', '401(k) program\xa0', 'The Data Engineer will be the first member of our new data team, reporting to the CTO. This team’s mission is to develop data systems, flows, and tools to help our team make data-driven decisions. You will collaborate with stakeholders throughout the company to ensure that the information they need is accessible, accurate, and always up to date.', 'How We Work', '3+ years programming experience with a modern computing language that supports data engineering work (Python, R, C#, JVM-languages like Java)', 'BCBS Health InsuranceOptions Program401(k) program\xa0Flexible Accrued Vacation ""Take what you need"" policyAnnual “exploration budget” to feed your curiosityAnnual “creative project budget” to help you stay creativeAnnual Conference BudgetExcellent Parental Leave PolicyA complimentary Inventables 3D Carving Machine', 'Annual Conference Budget', 'Options Program', 'Experience working with a cloud service such AWS', 'Bachelor’s degree in science, math, or engineeringExperience constructing and maintaining Postgres databasesExperience working with a cloud service such AWSExperience with PythonExperience with linux shell scriptingExperience with source control systems such as git', ""We believe in making time for exploration and innovation. You'll have your own creative project budget, along with access to our workshop. In addition, we set aside every Friday for each engineer to direct their own R&D–whether exploring new technologies, or working on problems they think are important.""]",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Data Scientist,"Aveshka, Inc","Washington, DC",4 hours ago,49 applicants,"['', 'Experienced in working with and exploiting big data; distributed computing; predictive modelling; mathematics; statistics; machine learning; story-telling; and visualization.', 'Aveshka is an Equal Opportunity Employer (EOE)', ' Extensive training programs  Gym membership reimbursement  Education reimbursement  Technology benefits  Commuter benefits  Generous paid time off and much more! ', ' Education reimbursement ', ' Extensive training programs ', 'Demonstrates ability to extract meaning from and interpret data using a variety of tools and methods from statistics and machine learning.', 'Required Education', ' Experiece with using the Microsoft Office suite, including Access, Excel, PowerPoint, Project, Visio, and Word. ', ' Experience with programming languages such as, but not limited to: R, SAS, Python, MatLab, SQL, Hive, Pig, and Spark.', 'Possesses strong working knowledge of the Microsoft Office suite, including Access, Excel, PowerPoint, Project, Visio, and Word.', 'Handles raw data (e.g. structured, unstructured, and mixed datasets), and analyzes data through the application of various statistical techniques or tools.', 'Familiar with programming languages such as, but not limited to: R, SAS, Python, MatLab, SQL, Hive, Pig, and Spark.', ' Commuter benefits ', 'Required Experience', ' Experience with programming languages such as, but not limited to: R, SAS, Python, MatLab, SQL, Hive, Pig, and Spark. Experiece with using the Microsoft Office suite, including Access, Excel, PowerPoint, Project, Visio, and Word. ', ' Gym membership reimbursement ', 'About Aveshka', 'Ability to collect, clean, and mung data in a timely manner as part of a cross-functional team in an intelligence, or related, environment.', 'Handles raw data (e.g. structured, unstructured, and mixed datasets), and analyzes data through the application of various statistical techniques or tools.Familiar with programming languages such as, but not limited to: R, SAS, Python, MatLab, SQL, Hive, Pig, and Spark.Experienced in working with and exploiting big data; distributed computing; predictive modelling; mathematics; statistics; machine learning; story-telling; and visualization.Demonstrates ability to extract meaning from and interpret data using a variety of tools and methods from statistics and machine learning.Ability to collect, clean, and mung data in a timely manner as part of a cross-functional team in an intelligence, or related, environment.Possesses strong working knowledge of the Microsoft Office suite, including Access, Excel, PowerPoint, Project, Visio, and Word.', ' Technology benefits ', ' Generous paid time off and much more! ']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"AI/ML - Data Science Manager, Siri Data",Apple,"Boulder, CO",12 hours ago,Be among the first 25 applicants,"['', 'Description', 'Key Qualifications', 'Summary', 'Additional Requirements']",Not Applicable,Full-time,Other,Consumer Electronics,2020-11-05 11:32:32
Lead Data Scientist,Medix™,"Washington, DC",,N/A,"['', 'Expertise with Python & Python tools (Scikit-learn, Pandas, Numpy, Scipy, PySpark, NLTK)', 'Position Type: Direct Hire / Full Time', 'Guiding, and participating in the building of data sets\xa0--working extensively with R and Python / Python libraries to extract and manipulate data from a variety of internal and external sources (Scikit-learn, Pandas, Numpy, Scipy, PySpark, NLTK)', 'Running predictive analytics to gain insights into consumer behaviors\xa0', '5+ years experience as a Data Scientist', 'REQUIRED PROFESSIONAL EXPERIENCE & QUALIFICATIONS', 'Please note that the work location for this role is 100% remote due to COVID; however work will transition on-site in Bethesda, MD in 2021.\xa0Relocation assistance is also offered.', 'Experience with data manipulation & analysis using R\xa0', 'Position Location: Bethesda, MD (Note: Currently 100% Remote due to COVID)', 'Benefits: Our client offers an exceptional full-time benefits package, including a fantastic medical benefits package for employee + family members, generous paid time off, a 401K retirement savings plan with company contributions, profit sharing, continuing training and tuition reimbursement, college savings plans, Employee Assistance programs and much more!', 'Lead Data Scientist', '****************', 'Preferred PhD in a Computer Science or Data Science field', 'Data visualization tools - Tableau or RShiny, or similar', 'Required Master of Science in a Computer Science or Engineering field', 'Experience working with cloud data tools -\xa0Spark/ MapR', 'Conducting deep analysis on business topics related to\xa0customer sentiment analysis, customer segmentation analysis, risk & fraud, etc.', 'Data collaboration tools such as Dataiku, Datarobot or\xa0RapidMiner', 'Position Type:', 'Required Master of Science in a Computer Science or Engineering fieldPreferred PhD in a Computer Science or Data Science field5+ years experience as a Data ScientistExpertise with Python & Python tools (Scikit-learn, Pandas, Numpy, Scipy, PySpark, NLTK)Experience with data manipulation & analysis using R\xa0Experience working with cloud data tools -\xa0Spark/ MapRData visualization tools - Tableau or RShiny, or similarData collaboration tools such as Dataiku, Datarobot or\xa0RapidMiner', 'ADDITIONAL INFORMATION', 'Leveraging cloud data collaboration tools like Databricks, to explore, prototype and build models in collaboration with the team (other Data Analysts and Data Engineers)', 'Compensation Range: $140,000 - $150,000 / year + profit sharing bonus', 'Medix is currently seeking a Lead Data Scientist for an exciting DIRECT HIRE job opportunity with one of our top clients, headquartered in the Bethesda, MD area.', 'ABOUT OUR CLIENT / ABOUT THIS ROLE', 'Working with big data in the cloud, using analytics engines and cluster computing frameworks like Spark, MapR, Tez and Yarn', 'Working as Lead Data Scientist in a highly collaborative environment\xa0', 'Working as Lead Data Scientist in a highly collaborative environment\xa0Leveraging cloud data collaboration tools like Databricks, to explore, prototype and build models in collaboration with the team (other Data Analysts and Data Engineers)Working with big data in the cloud, using analytics engines and cluster computing frameworks like Spark, MapR, Tez and YarnProviding technical guidance and mentorship for less experienced team members\xa0Guiding, and participating in the building of data sets\xa0--working extensively with R and Python / Python libraries to extract and manipulate data from a variety of internal and external sources (Scikit-learn, Pandas, Numpy, Scipy, PySpark, NLTK)Creating and deploying various machine learning algorithms, and tuning models to achieve desired outcomes.Conducting deep analysis on business topics related to\xa0customer sentiment analysis, customer segmentation analysis, risk & fraud, etc.Running predictive analytics to gain insights into consumer behaviors\xa0Using data visualization software to effectively redact and communicate data outcomes, and recommendations to senior leadership (using Tableau, RShiny, or similar tools)\xa0Presenting outcomes and targeted recommendations to Directors and C-Suite executives\xa0', 'Candidates must be authorized to work as a full-time employee of our client, without the need for visa sponsorship now or in the future.\xa0Sponsorship is not offered for this position.\xa0', 'Creating and deploying various machine learning algorithms, and tuning models to achieve desired outcomes.', 'Compensation Range: ', 'Providing technical guidance and mentorship for less experienced team members\xa0', 'Using data visualization software to effectively redact and communicate data outcomes, and recommendations to senior leadership (using Tableau, RShiny, or similar tools)\xa0', 'Presenting outcomes and targeted recommendations to Directors and C-Suite executives\xa0', 'Benefits: ', 'Our client is a national leader within the risk management & insurance space!\xa0They are seeking to hire a Lead Data Scientist to help drive predictive analytics across several key areas within the organization - primarily on customer experience, risk & fraud, and operations.\xa0This role will be serving as a technical lead, and will be assisting in developing more junior data scientists on the team.\xa0This role will include the full lifecycle of analytics - data engineering as well as predictive modeling and presentations to the business.', 'Position Location:', 'DAY TO DAY RESPONSIBILITIES WILL INCLUDE:']",Director,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist,Ampersand,"New York, NY",16 hours ago,Be among the first 25 applicants,"['', 'Modern statistical methods', 'Ability to communicate and collaborate with stakeholders across Ampersand and to present clear oral and written arguments', 'Modern statistical methodsMachine learningBayesian methods (preferable)', 'Design experiments to test hypotheses, measure the results, and find ways to improve outcomes', 'Define + Find\xa0a strategic audience or select from traditional Nielsen demos\xa0', 'EDUCATION, SKILLS AND EXPERIENCE:', 'Measure + Report\xa0both reach\xa0and\xa0frequency\xa0and\xa0business outcomes\xa0', 'Advanced knowledge of one or more of these:', 'Advanced degree or equivalent experience preferred', 'Data visualization libraries, e.g. Jupyter, matplotlib, ggplot2, bokeh', 'Must have expert knowledge in one or both programming languages: Python or RAdvanced knowledge of one or more of these:Modern statistical methodsMachine learningBayesian methods (preferable)Experience using version control (git)Data visualization libraries, e.g. Jupyter, matplotlib, ggplot2, bokehDegree in quantitative field like math, statistics, operations research, economics, or physicsAdvanced degree or equivalent experience preferred4+ years of experience as a data scientistSolid SQL abilitiesAbility to communicate and collaborate with stakeholders across Ampersand and to present clear oral and written arguments', 'Create and improve various optimization schemes (proposals, cross screen planning, etc.)', 'Collaborate with teams throughout Ampersand to help rationalize and optimize the business and identify opportunities for further growth', 'Define + Find\xa0a strategic audience or select from traditional Nielsen demos\xa0Plan + Execute\xa0against an optimized schedule across multi-screen TV\xa0\xa0 \xa0\xa0Measure + Report\xa0both reach\xa0and\xa0frequency\xa0and\xa0business outcomes\xa0', 'Plan + Execute\xa0against an optimized schedule across multi-screen TV\xa0\xa0 \xa0\xa0', 'Experience using version control (git)', 'ESSENTIAL FUNCTIONS:\xa0', 'Bayesian methods (preferable)', 'Create and improve various forecasting models (audience, reach & frequency, inventory, demand, etc.)Create and improve various optimization schemes (proposals, cross screen planning, etc.)Collaborate with teams throughout Ampersand to help rationalize and optimize the business and identify opportunities for further growthEvaluate internal and external data sets for model and process improvementDesign experiments to test hypotheses, measure the results, and find ways to improve outcomes', 'Solid SQL abilities', 'Degree in quantitative field like math, statistics, operations research, economics, or physics', 'Machine learning', 'Create and improve various forecasting models (audience, reach & frequency, inventory, demand, etc.)', 'Evaluate internal and external data sets for model and process improvement', 'JOB AT A GLANCE:\xa0', '4+ years of experience as a data scientist', 'Must have expert knowledge in one or both programming languages: Python or R']",Mid-Senior level,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Researcher,DISYS,"Columbus, OH",3 hours ago,Be among the first 25 applicants,"['', 'Coursework in statistics or probability (at least one formal class).Coursework in engineering (e.g., transport phenomenon, reaction kinetics).Significant programming experience in an object-oriented programming language (e.g., C++, C#, Java, or python. Matlab, LabVIEW, Mathcad, Mathematica would not be considered relevant experience).Experience with JavaScript/HTML/CSS.', 'MAJOR RESPONSIBILITIES:', ""0 to 2 years of experience in software development, mathematical modeling, statistical analysis, data science, or related field.Education reflecting on the following:Bachelor's or master's degree in Computer Science or Computer Science Engineering with a minor, certificate, or relevant work experience in a scientific or mathematical field (e.g., statistics, data analysis, biology, engineering).Bachelor's or Masters's degree in Physics, Physics engineering, Actuarial science, Mathematics, Biology, or Engineering with a minor or certificate in computer science or relevant work experience requiring computer programming.Must have a GPA of 3.0 or above.Completed coursework in higher-level mathematics (e.g., calculus, differential equations, linear algebra).Completed coursework in computer science and/or mathematical modeling.Experience using object-oriented programming in C++, C#, Java, or python for significant classroom assignments, undergraduate research, or other work experience.Ability to learn and understand new programming languages and mathematical concepts.Must be a U.S. Citizen with the ability to obtain and maintain a Secret DoD clearance."", 'Perform rigorous mathematical and statistical analysis on large data sets.', 'Completed coursework in computer science and/or mathematical modeling.', 'Must have a GPA of 3.0 or above.', 'Support model development activities concerning inhalation, ingestion, dermal, and radiation exposure hazards, response to CBRNE events, and decision support.', 'Completed coursework in higher-level mathematics (e.g., calculus, differential equations, linear algebra).', 'Coursework in engineering (e.g., transport phenomenon, reaction kinetics).', 'Test model code for accuracy and performance.', 'THE FOLLOWING IS DESIRED:', 'Collect, reduce, process, and present model input and output data.', 'We are currently seeking persons with software development expertise, mathematical and statistical skills, and knowledge of physical phenomena. The Hazard Modeling Team within CBRNE Defense provides its customers with software-based products that perform technical analyses and predictive modeling to inform their preparedness and response planning efforts to mitigate risk to the United States or their company. ', 'Support model development activities concerning inhalation, ingestion, dermal, and radiation exposure hazards, response to CBRNE events, and decision support.Perform rigorous mathematical and statistical analysis on large data sets.Design and develop graphical user interfaces for mathematical models.Develop code to support database and back-end server interface.Test model code for accuracy and performance.Collect, reduce, process, and present model input and output data.Write reports of methods used and results obtained.', 'Ability to learn and understand new programming languages and mathematical concepts.', 'Develop code to support database and back-end server interface.', 'Must be a U.S. Citizen with the ability to obtain and maintain a Secret DoD clearance.', ""Bachelor's or master's degree in Computer Science or Computer Science Engineering with a minor, certificate, or relevant work experience in a scientific or mathematical field (e.g., statistics, data analysis, biology, engineering)."", '\xa0We are currently hiring a Research Associate in Columbus, OH!', 'Coursework in statistics or probability (at least one formal class).', 'Education reflecting on the following:', '0 to 2 years of experience in software development, mathematical modeling, statistical analysis, data science, or related field.', 'Experience using object-oriented programming in C++, C#, Java, or python for significant classroom assignments, undergraduate research, or other work experience.', 'THE FOLLOWING REQUIREMENTS MUST BE MET TO BE CONSIDERED FOR THIS POSITION:', ""Bachelor's or Masters's degree in Physics, Physics engineering, Actuarial science, Mathematics, Biology, or Engineering with a minor or certificate in computer science or relevant work experience requiring computer programming."", 'Write reports of methods used and results obtained.', 'Experience with JavaScript/HTML/CSS.', 'Design and develop graphical user interfaces for mathematical models.', 'Significant programming experience in an object-oriented programming language (e.g., C++, C#, Java, or python. Matlab, LabVIEW, Mathcad, Mathematica would not be considered relevant experience).']",Entry level,Full-time,Analyst,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist,Crossix Solutions,"New York, NY",10 hours ago,Be among the first 25 applicants,"['', 'Advanced and in-depth knowledge and professional experience in machine learning and statistics', 'Have a curiosity to figure out new problems', 'Enjoy having clear ownership of a goal even if the path to get there is not entirely clear', 'Strong organizational, management and leadership skills', ""What You've Done"", 'Apply machine learning, data mining, and statistical analysis techniques to large health data sets to build new products and methodologies', 'Flexible PTOAllocations for continuous learning & developmentHealth & wellness programs', '7+ years of hands-on data science experience, demonstrating increasing responsibility and impact over time, including experience leading projectsAdvanced and in-depth knowledge and professional experience in machine learning and statisticsHighly proficient in Python and SQL; experience working with AWS preferredStrong organizational, management and leadership skillsStrong communication skills and agility to work across internal teams', 'Master core parts of the Crossix technology platform. Technologies include Spark, SQL, Python, R, AWS, and proprietary data mining software', '7+ years of hands-on data science experience, demonstrating increasing responsibility and impact over time, including experience leading projects', 'Flexible PTO', 'Allocations for continuous learning & development', 'Own responsibilities related to project and people leadership, including leading data scientists and analysts', 'Have a desire and preference for working in a fast-paced, entrepreneurial environment', 'Health & wellness programs', 'Explore and find meaning in high volumes of data to evaluate data quality and extract actionable insights that will help drive business decisions; execute data querying, data cleansing, and experiment design', 'Are humble and truly think about the success of the group before your own contribution', ""What You'll Do"", 'Highly proficient in Python and SQL; experience working with AWS preferred', 'Apply machine learning, data mining, and statistical analysis techniques to large health data sets to build new products and methodologiesOwn responsibilities related to project and people leadership, including leading data scientists and analystsCollaborate closely with a team of data scientists, product managers, and executives to discover and deliver product offerings from prototype to massive scaleExplore and find meaning in high volumes of data to evaluate data quality and extract actionable insights that will help drive business decisions; execute data querying, data cleansing, and experiment designRapidly build prototype product solutions, communicate findings, and iterateDraw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solvedWork with product and engineering teams to improve and implement methods and featuresMaster core parts of the Crossix technology platform. Technologies include Spark, SQL, Python, R, AWS, and proprietary data mining software', 'Are comfortable challenging existing norms, thinking and teammates, always doing so respectfully', 'Who You Are', 'Perks & Benefits', 'Collaborate closely with a team of data scientists, product managers, and executives to discover and deliver product offerings from prototype to massive scale', 'Rapidly build prototype product solutions, communicate findings, and iterate', 'Draw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solved', 'Work with product and engineering teams to improve and implement methods and features', 'Strong communication skills and agility to work across internal teams', 'Have a desire and preference for working in a fast-paced, entrepreneurial environmentEnjoy having clear ownership of a goal even if the path to get there is not entirely clearHave a curiosity to figure out new problemsAre humble and truly think about the success of the group before your own contributionAre comfortable challenging existing norms, thinking and teammates, always doing so respectfully']",Not Applicable,Full-time,Management,Computer Software,2020-11-05 11:32:32
Senior Data Scientist,N/A,United States,14 hours ago,Be among the first 25 applicants,"['', 'Lead custom analyses and connect them to actionable Business and Product insights', 'Analytical, framework thinker', 'Highly collaborative', 'Research, implement and modify modern Data Science techniques. More specifically:', 'Analytical, framework thinkerComfortable in a fast-paced environmentHighly collaborativeStrong at translating Data Science concepts to non-technical audiencesBusiness focused; measures work in its contributions to business outcomes and prioritizes effort against deliverables accordingly', 'Preferred Qualifications', 'Build Statistical and Machine Learning models that describe the impact of prices and promotions on shopper behavior, including behavioral pricing effects. You’ll need to find middle ground between using flexible modern AI methods and proven classical methods.', 'Minimum Qualifications', 'About the Company', 'Agile experienceExperience with NumPy and Pandas (or equivalent experience in R)', '5+ years of relevant experience in Data Science and/or Machine Learning with direct impact on business valueB.S., M.S., or PhD in Statistics, Mathematics, Operations Research, Machine Learning, Engineering, Economics, Computer Science or relevant quantitative fieldStrong understanding of Generalized Linear ModelsAbility to write efficient code in PythonExperience with Hypothesis Testing and Maximum Likelihood Estimation', 'Responsibilities', 'Ability to write efficient code in Python', 'Develop Optimization and Experiment Design systems, which determine the best prices to set for each product in each store each week. Finding a good balance on the exploration-exploitation tradeoff will be important.', 'Be a go-to resource for science-related questions about the product', 'Create model validation methods to make sure that our models are accurate and to quantify the impact of our solutions on the clients’ bottom line', 'Experience with Hypothesis Testing and Maximum Likelihood Estimation', 'Behavioral Profile', 'Reporting directly to the Head of Data Science, you will be at the center of what determines Eversight’s success as a company. You will analyze the data and develop production code using the newest Data Science and Machine Learning techniques to determine the optimal prices and promotions for major product manufacturers and retailers that sell these products.', 'Location', '5+ years of relevant experience in Data Science and/or Machine Learning with direct impact on business value', 'Serve as Data Science expert both within Eversight and for our clients', 'Team leadership experience strongly preferredStartup experience strongly preferredExperience in A/B testing and Design of Experiments Agile experienceExperience with NumPy and Pandas (or equivalent experience in R)Strong in math and statistics: Linear Algebra, Bayesian Methods, Regressions, Calculus Experience in Machine Learning methods: Neural Networks (Deep Learning, Embeddings, Sequence Modeling, CNN), Tree-based methods (GBDT, Random Forest), Regularization Methods (L1/L2 penalties, Feature Selection, Dimensionality Reduction)Demand Modeling, Pricing, and Causal Inference experience ', 'Work with Product Management to generate ideas and quickly turn them into efficient, well-tested, functioning code (we mostly use Python)', 'Startup experience strongly preferred', 'Eversight is the recognized leader in AI-powered price and promotions. Eversight’s proprietary cloud-based SaaS solution brings AI and continuous experimentation to consumer brands and retailers. Our software acts as a coach, enabling market leaders to transform pricing and promotion strategy for the $3.4 trillion spent in consumer goods retail using intelligent, real-time data and insights.', 'Strong at translating Data Science concepts to non-technical audiences', 'Comfortable in a fast-paced environment', 'Partner with the Engineering team to create highly scalable solutions', 'Strong understanding of Generalized Linear Models', 'Experience in A/B testing and Design of Experiments ', 'Team leadership experience strongly preferred', 'Strong in math and statistics: Linear Algebra, Bayesian Methods, Regressions, Calculus ', 'The Opportunity', 'Demand Modeling, Pricing, and Causal Inference experience ', '\xa0Minimum Qualifications', 'Business focused; measures work in its contributions to business outcomes and prioritizes effort against deliverables accordingly', 'Design and run pricing experiments across hundreds of stores and tens of thousands of products', 'Help prioritize new feature development by assessing potential impact', '\xa0Behavioral Profile', 'Research, implement and modify modern Data Science techniques. More specifically:Build Statistical and Machine Learning models that describe the impact of prices and promotions on shopper behavior, including behavioral pricing effects. You’ll need to find middle ground between using flexible modern AI methods and proven classical methods.Develop Optimization and Experiment Design systems, which determine the best prices to set for each product in each store each week. Finding a good balance on the exploration-exploitation tradeoff will be important.Design and run pricing experiments across hundreds of stores and tens of thousands of productsCreate model validation methods to make sure that our models are accurate and to quantify the impact of our solutions on the clients’ bottom lineWork with Product Management to generate ideas and quickly turn them into efficient, well-tested, functioning code (we mostly use Python)Partner with the Engineering team to create highly scalable solutionsServe as Data Science expert both within Eversight and for our clientsLead custom analyses and connect them to actionable Business and Product insightsHelp prioritize new feature development by assessing potential impactBe a go-to resource for science-related questions about the product', 'Palo Alto, CA', 'Experience in Machine Learning methods: Neural Networks (Deep Learning, Embeddings, Sequence Modeling, CNN), Tree-based methods (GBDT, Random Forest), Regularization Methods (L1/L2 penalties, Feature Selection, Dimensionality Reduction)', 'Eversight is the recognized leader in AI-powered pricing and promotions. Global brands and retailers rely on the Eversight platform to optimize pricing in response to market conditions and to deliver higher ROI on promotional spend. Eversight’s Pricing Suite and Offer Innovation Suite solutions are driving strong margin and sales volume improvements for leading companies such as Coca-Cola, General Mills, Raley’s, and Rite Aid. Founded in 2013, Eversight is headquartered in Palo Alto, California, with offices in Chicago and New York.', 'B.S., M.S., or PhD in Statistics, Mathematics, Operations Research, Machine Learning, Engineering, Economics, Computer Science or relevant quantitative field']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Data Scientist,Six Flags,"Garland, TX",17 hours ago,Over 200 applicants,"['', 'MINIMUM QUALIFICATIONS: ', 'JOB SUMMARY:', 'Identify required data structures and apply strong expertise in advanced analytics techniques (e.g. optimization and machine-learning) to design, prototype, and build solutions to business problems', 'Experience in forecasting and linear optimization (e.g., constraint and mixed-integer programming) strongly preferred', 'Creative', 'Collaborate with business units to provide technical guidance related to AI/ML based models', 'Must possess strong analytical, strategic, project management, decision-making and problem-solving skills', 'Deep knowledge of predictive analytic techniques and statistical diagnostics of models', 'JOB DUTIES: ', 'COMPANY BACKGROUND:\xa0', 'JOB SUMMARY:\xa0\xa0\xa0\xa0\xa0\xa0\xa0', 'Experience with data visualization Effective communications skills that instill confidence with internal and external audiences and translate complex concepts to non-technical stakeholders to help drive informed business decisions', 'Data Intuition', 'We are looking for an individual who can assess applicability of different artificial intelligence and machine learning methods for different use cases with a focus on forecasting and workforce optimization. The role will require the use of advanced analytic tools and methodologies to build solutions in a production environment and draw on insights from large or complex data sets to solve business problems addressed by use cases. The role will help drive advanced analytical thinking and methodologies by investigating various topics and sharing insights with broader planning and analysis team as well as business stakeholders to provide the best consumer centric experience for our guests.', 'Statistical Thinking and Problem Solving', 'Exchanges ideas and conveys complex information clearly and concisely, verbally, visually (presentations and exhibits), and in writing, consistent with the audiences and stakeholders', 'Proven ability to lead and drive projects and assignments to completion', 'Collaborate with data engineers to support data modelling and testing during projects, and incorporating advanced analytics into ongoing business processes', 'Expertise in advanced analytical techniques (e.g., descriptive statistics, time series, machine learning)', 'Help manage use case development and ensure frequent communication with other stakeholders to drive use case development and manage expectations on model limitations and lead times', 'Intellectual curiosity, a passion for data and a results orientation', ""Bachelor's in data science, statistics, CS, or related field; Master's preferred"", 'PROFILE: ', ""Bachelor's in data science, statistics, CS, or related field; Master's preferred3+ years of experience in a statistical and/or data science roleExpertise in advanced analytical techniques (e.g., descriptive statistics, time series, machine learning)Experience in forecasting and linear optimization (e.g., constraint and mixed-integer programming) strongly preferredExperience using analytical in common programming languages, (e.g., Python, R)Experience with data visualization Effective communications skills that instill confidence with internal and external audiences and translate complex concepts to non-technical stakeholders to help drive informed business decisionsEasily establish yourself as a trusted partner and the ability to build effective partnerships across all areas of the organization and with colleagues at all levelsIntellectual curiosity, a passion for data and a results orientation"", 'Data IntuitionStatistical Thinking and Problem SolvingCreative', 'Gather business requirements and translate them into information solutions with a focus on improving guest experience through continuous improvement of workforce optimization by providing ongoing data analyticsIdentify required data structures and apply strong expertise in advanced analytics techniques (e.g. optimization and machine-learning) to design, prototype, and build solutions to business problemsCollaborate with data engineers to support data modelling and testing during projects, and incorporating advanced analytics into ongoing business processesEnsure analytics tools and methods used in projects are robust and of the highest qualityHelp manage use case development and ensure frequent communication with other stakeholders to drive use case development and manage expectations on model limitations and lead timesCollaborate with business units to provide technical guidance related to AI/ML based modelsDevelop internal analytics capabilities and best practices (models, standards, tools), and share learnings with peersEnsures data analysts understand the business process and performance to be measured, while partnering with park level operations leaders to identify process gaps and improvements to be supported by measurement/reportingMust possess strong analytical, strategic, project management, decision-making and problem-solving skillsDeep knowledge of predictive analytic techniques and statistical diagnostics of modelsProven ability to lead and drive projects and assignments to completionExchanges ideas and conveys complex information clearly and concisely, verbally, visually (presentations and exhibits), and in writing, consistent with the audiences and stakeholders', 'Gather business requirements and translate them into information solutions with a focus on improving guest experience through continuous improvement of workforce optimization by providing ongoing data analytics', 'Develop internal analytics capabilities and best practices (models, standards, tools), and share learnings with peers', 'Easily establish yourself as a trusted partner and the ability to build effective partnerships across all areas of the organization and with colleagues at all levels', '3+ years of experience in a statistical and/or data science role', 'Experience using analytical in common programming languages, (e.g., Python, R)', 'Six Flags Entertainment Corporation is the world’s largest regional theme park company with $1.5 billion in revenue and 26 parks across North America.\xa0For more than 57 years, Six Flags has entertained millions of families with world-class coasters, themed rides, thrilling water parks and unique attractions.', 'Ensure analytics tools and methods used in projects are robust and of the highest quality', 'Ensures data analysts understand the business process and performance to be measured, while partnering with park level operations leaders to identify process gaps and improvements to be supported by measurement/reporting']",Entry level,Full-time,Engineering,Entertainment,2020-11-05 11:32:32
Data Scientist,Upstart,"San Mateo, CA",5 hours ago,Over 200 applicants,"['', 'Determination to pursue a question until reaching a satisfactory conclusion', 'Ability to use data to detect bugs, surprises, and other important business issues', 'Strong sense of intellectual curiosity balanced with humility, drive and teamwork', ""2+ years' in data science, data analytics or related experience in a business setting"", "" 2+ years' in data science, data analytics or related experience in a business setting Knowledgeable in applied statistics (e.g., hypothesis testing, linear and logistic regression) Experience with SQL and R or Python Enthusiasm for and alignment with Upstart’s mission and values Strong sense of intellectual curiosity balanced with humility, drive and teamwork Numerically-savvy and smart with ability to operate at a speedy pace Ability to quickly piece together disparate pieces of information to form a broader picture Ability to use data to detect bugs, surprises, and other important business issues Determination to pursue a question until reaching a satisfactory conclusion Experience with consumer (especially consumer finance) data a plus Data visualization skills preferred MS or PhD preferred "", 'The Team', 'Enthusiasm for and alignment with Upstart’s mission and values', ' Competitive compensation (base + bonus & equity) Comprehensive medical, dental, and vision coverage Personal development and technology & ergonomic budgets  Life insurance and disability benefits  Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams)  Generous vacation policy 401(k) retirement plan Catered lunches + snacks & drinks ', 'Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams) ', 'The Role', 'MS or PhD preferred', '401(k) retirement plan', 'Experience with SQL and R or Python', 'Knowledgeable in applied statistics (e.g., hypothesis testing, linear and logistic regression)', 'Competitive compensation (base + bonus & equity)', 'Experience with consumer (especially consumer finance) data a plus', 'What We’re Looking For', 'Numerically-savvy and smart with ability to operate at a speedy pace', 'Comprehensive medical, dental, and vision coverage', 'Ability to quickly piece together disparate pieces of information to form a broader picture', 'Life insurance and disability benefits ', 'Generous vacation policy', 'Data visualization skills preferred', 'Personal development and technology & ergonomic budgets ', 'Catered lunches + snacks & drinks', 'What You’ll Love']",Entry level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Data Scientist,Bravado,"Austin, Texas Metropolitan Area",17 hours ago,179 applicants,"['', 'About the Company', 'Find the well, then carry the water. ', 'Don’t freak out about failing. ', 'As an employee of Bravado, we don’t look at you as a member of our team, but rather as a part of our Family. Families take care of one another, and here’s another way we’re looking to do that! ', 'Curious\xa0- Share your non-stop desire to continue learning. ', '2+ years of professional experience at a direct-to-consumer, community or marketplace startup. ', 'Subsidized modern tech lifestyle, including monthly subscriptions/credits towards: On-demand video (e.g. Netflix, Hulu, HBO, or Disney+) Streaming music (e.g. Spotify, or Apple Music) Mindfulness (Calm App membership) Shopping/grocery service (e.g. Postmates, Instacart, or Amazon Prime) Monthly credit towards Lyft, Uber or Clipper Card Gym membership (monthly ClassPass subscription) Quarterly stipend for books A flexible vacation policy allows you to truly relax and reboot. Comprehensive health, vision, dental, and life insurance as well as disability benefits. 100% of health, vision, and dental premiums paid by Bravado for employees. 401(k) plan with employer matching. Generous paid maternity and paternity leave. ', 'Strong SQL skills. ', 'Descriptive and predictive modeling ', 'Purpose before action. Find the well, then carry the water. Be uniquely great at what you do. Don’t freak out about failing. Be excellent to one another. View our differences as strengths. Put on your Sales Hat™. ', 'Drive data mining, data analysis, experimentation, and research to influence new initiatives and the success of ongoing projects. ', 'On-demand video (e.g. Netflix, Hulu, HBO, or Disney+) Streaming music (e.g. Spotify, or Apple Music) Mindfulness (Calm App membership) Shopping/grocery service (e.g. Postmates, Instacart, or Amazon Prime) Monthly credit towards Lyft, Uber or Clipper Card Gym membership (monthly ClassPass subscription) Quarterly stipend for books ', 'Be uniquely great at what you do. ', 'Fast-Paced\xa0- Work comfortably in a high growth environment with the capability to switch from strategy to execution without losing ground. ', 'Be excellent to one another. ', 'Passionate\xa0- Transform complex data into creative solutions. ', 'Demonstrated advanced knowledge of ', '\xa0 ', 'Implementing visualizations, dashboards, and reports ', 'Major Responsibilities', 'The ability to work and influence cross-functionally. ', 'Shopping/grocery service (e.g. Postmates, Instacart, or Amazon Prime) ', '100% of health, vision, and dental premiums paid by Bravado for employees. ', ' \xa0', '2+ years of professional experience at a direct-to-consumer, community or marketplace startup. Demonstrated advanced knowledge of R/Python data-driven programming skills Strong SQL skills. Descriptive and predictive modeling Implementing visualizations, dashboards, and reports Breadth of knowledge around statistical methods and experiment design, including A/B testing, sequential testing, synthetic control, cluster-randomized testing Work independently, with minimal supervision. The ability to work and influence cross-functionally. You are proactive, always with an insight into future outcomes. Great at communicating with different audiences and can bring different stakeholders on board. A “business owner” mindset, with a keen interest in strategy and operations A strong academic background in statistics or similar programs ', 'Streaming music (e.g. Spotify, or Apple Music) ', 'Team Player\xa0- Jump in wherever needed and collaborate with all teams. ', 'Purpose before action. ', 'A “business owner” mindset, with a keen interest in strategy and operations ', 'Best-in-Class', 'Take the lead in switching our data analytics platform, ensuring our desired goals and needs are met. ', ' ', 'Best-in-Class\xa0- Grow with us and elevate our data management. ', 'While our HQ is in Downtown San Francisco, our team is global. We value every employee’s voice and believe that the most effective team is a diverse one. We live by the following core values, and weave them into everything that we do as an organization: ', '401(k) plan with employer matching. ', 'Put on your Sales Hat™. ', 'Mindfulness (Calm App membership) ', 'Perks', 'Curious', 'R/Python data-driven programming skills ', 'Team Player', 'Data Scientist ', 'This role is both strategic and technical.  You will work cross-functionally with Engineering, Product, and Leadership to build and structure data, mine insights, and be proactive with solutions and strategic direction. You will take the lead on visibility into all company data and share valuable insights with all teams and stakeholders. You will have 100% trust in data accuracy and data cleanliness. You will hold 100% visibility from top to bottom of the business funnel. That means all of our analytic integrations are implemented properly across the site. ', 'Over 1,000 organizations are represented on the Bravado platform. Our members hail from sales teams at Google, Salesforce, Facebook, and Amazon, and many more. Our members have the opportunity to give back to the sales community and mentor students interested in sales, and junior sales professionals. ', 'Become the subject matter expert and actively work with all departments to drive metrics and meet desired goals. ', 'Major Responsibilities ', 'Breadth of knowledge around statistical methods and experiment design, including A/B testing, sequential testing, synthetic control, cluster-randomized testing ', 'Must Haves ', 'Define and validate novel metrics to evaluate business performance. ', 'Subsidized modern tech lifestyle, including monthly subscriptions/credits towards: ', 'Gym membership (monthly ClassPass subscription) ', 'Full Time || Start Immediately || Remote in North America', 'On-demand video (e.g. Netflix, Hulu, HBO, or Disney+) ', 'This is a fantastic opportunity for a Data Scientist to implement state-of-the-art Analytics and Machine Learning methods, solve complex problems and build the next generation of the product in a dynamic and growing startup. ', 'Great at communicating with different audiences and can bring different stakeholders on board. ', 'Monthly credit towards Lyft, Uber or Clipper Card ', 'A strong academic background in statistics or similar programs ', 'Quarterly stipend for books ', 'You are', 'Proactive', 'Data Scientist', 'Full Time || Start Immediately || Remote in North America ', 'Bravado is the first professional network and community for sales professionals. Our team is on a mission to change the perception of sales and usher in a bright future for the most popular career path in North America. We provide online tools and in-person events which empower our members to build their personal brands, connect with other sales professionals, and be the best they can be in their jobs. ', 'If this sounds like a company you would like to join and a role you would thrive in, please don’t hold back from applying! Whatever skills you bring to the table or background you’re coming from, we welcome you to start a conversation with us. We need your unique perspective for our continued innovation and success. We’re looking forward to learning more about you!', 'You are proactive, always with an insight into future outcomes. ', 'Must Haves', 'R/Python data-driven programming skills Strong SQL skills. Descriptive and predictive modeling Implementing visualizations, dashboards, and reports ', 'We are looking for a Data Scientist with experience in extracting insights and telling stories from raw data. The ideal candidate is someone with 2+ years of full-time experience in a startup environment. ', 'Comprehensive health, vision, dental, and life insurance as well as disability benefits. ', 'Generous paid maternity and paternity leave. ', '\xa0', 'Perks ', 'All qualified applicants will receive consideration without regard to race, creed, religion, ability, sex, age, national origin, marital status, sexual orientation, gender identity or presentation, veteran status, or any other status protected by state or federal law. ', 'Build tools to automatically transform data into reports with insights and action steps. ', 'We can’t wait to talk to you and build the future of sales together. ', 'About the Company ', 'Apply operations research, statistical and Machine Learning methods to solve challenges to scale Bravado product and operations. ', 'Provide ad-hoc analytical support for new initiatives. ', 'View our differences as strengths. ', 'Proactive\xa0- Prevent problems and surface solutions before they impact the business. Passionate\xa0- Transform complex data into creative solutions. Team Player\xa0- Jump in wherever needed and collaborate with all teams. Fast-Paced\xa0- Work comfortably in a high growth environment with the capability to switch from strategy to execution without losing ground. Curious\xa0- Share your non-stop desire to continue learning. Best-in-Class\xa0- Grow with us and elevate our data management. ', 'Drive data mining, data analysis, experimentation, and research to influence new initiatives and the success of ongoing projects. Apply operations research, statistical and Machine Learning methods to solve challenges to scale Bravado product and operations. Become the subject matter expert and actively work with all departments to drive metrics and meet desired goals. Define and validate novel metrics to evaluate business performance. Build tools to automatically transform data into reports with insights and action steps. Provide ad-hoc analytical support for new initiatives. Take the lead in switching our data analytics platform, ensuring our desired goals and needs are met. ', 'A flexible vacation policy allows you to truly relax and reboot. ', 'Work independently, with minimal supervision. ', 'Passionate', 'Proactive\xa0- Prevent problems and surface solutions before they impact the business. ', 'Fast-Paced']",Mid-Senior level,Full-time,Information Technology,Internet,2020-11-05 11:32:32
Data Scientist,"United Solutions, LLC","Rockville, MD",17 hours ago,Over 200 applicants,"['', 'Excellent written and verbal communication skills for coordinating across teams.', 'Qualified candidates must live in the United States, with the ability to commute to the Rockville, MD office.', 'Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.', 'Experience working with MongoDB, Oracle Database etc.', 'WHAT YOU’LL BRING TO THE TABLE', 'A drive to learn and master new technologies and techniques.', 'Strong experience in manipulating data and drawing insights from large data sets. Experience working with and creating data architectures.', 'Hands on experience on language modeling tasks, sequence to sequence learning using Natural Language Processing.', 'We’re looking for someone with a minimum of 1 year of experience in data science and building machine learning models and is familiar with the software/tools listed below.Strong problem-solving skills with an emphasis on product development. Strong experience of a variety of machine learning techniques (clustering, decision tree learning, neural networks, deep learning etc.) and their real-world advantages/drawbacks.Strong experience using computer languages such as Python, Javascript and SQL is a must. Having some R and C++ knowledge is a plus.Strong experience in manipulating data and drawing insights from large data sets. Experience working with and creating data architectures.Experience working with MongoDB, Oracle Database etc.Hands on experience on language modeling tasks, sequence to sequence learning using Natural Language Processing.Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, Cassandra etc. is a plus.Experience visualizing/presenting data for stakeholders using: D3, ggplot, Tableau, PowerBI etc.Excellent written and verbal communication skills for coordinating across teams.A drive to learn and master new technologies and techniques.', 'Strong problem-solving skills with an emphasis on product development. Strong experience of a variety of machine learning techniques (clustering, decision tree learning, neural networks, deep learning etc.) and their real-world advantages/drawbacks.', 'Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.', 'Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, Cassandra etc. is a plus.', 'We’re looking for someone with a minimum of 1 year of experience in data science and building machine learning models and is familiar with the software/tools listed below.', 'Experience visualizing/presenting data for stakeholders using: D3, ggplot, Tableau, PowerBI etc.', 'Strong experience using computer languages such as Python, Javascript and SQL is a must. Having some R and C++ knowledge is a plus.']",Not Applicable,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"(USA) Data Scientist eCommerce, Partner Payments – Marketplace",Walmart,"Sunnyvale, CA",2 hours ago,Be among the first 25 applicants,"['', ' Master’s degree with two years of relevant experience or a Bachelor’s degree with 5 years relevant experience, in a highly quantitative field (i.e. Applied Math, Engineering, Statistics, Data Mining, Machine Learning, Analytics, Operations Research, or related field preferred) ', ' Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.  ', 'Minimum Qualifications...', 'Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. ', ""What You'll Do"", 'The Ideal Candidate Will Have', 'Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.', 'Preferred Qualifications...']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist - Top Secret,Stanley Reid & Company,"Springfield, VA",21 hours ago,Be among the first 25 applicants,[''],Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist,Experis,"Normandy, MO",9 minutes ago,Be among the first 25 applicants,"['', 'Keep current in the latest statistical methods and lead statistical method development and programming to address study requirements.', 'Good sense of business/technical interrelationships', 'Travel as necessary', 'Keep current in field and maintain a high level of expertise', 'Provide training to staff as needed in experimental design, statistical data analysis and statistical process control', 'Ability to understand client needs and to communicate technical concepts clearly, concisely, and understandably to non-statistical colleagues.', 'Perform exploratory analyses of data as requested to explore for patterns and trends from past studies.', 'Masters degree in Statistics or related mathematical sciencesMinimum of 5 years of related experience in the food or related industry or equitable experience.Well-versed in statistical software for analysis of research data (SAS is a plus).Experience with design and analysis of research experiments for product and process development.Experience with analysis of variance, regression analysis, mixed models analysis, generalized linear models, categorical data analysis, non-parametric methods, multivariate method, sampling, and process control.Excellent analytical skills with the ability to analyze data from any source.Ability to understand client needs and to communicate technical concepts clearly, concisely, and understandably to non-statistical colleagues.Pro-active/Self-Starter with the ability to work independentlyAbility to work collaboratively with cross-functional teamsMotivated and willingness to learn; attention to detailLeadership, organizational and time management skills, with the ability to effectively manage multiple priorities and projects.Excellent communication skills through oral, written and presentation interpersonal skillsGood sense of business/technical interrelationshipsComputer literacy', 'Consult with scientists from different areas in the design and analysis of experiments.Keep current in the latest statistical methods and lead statistical method development and programming to address study requirements.Interact proactively with individuals and groups on statistical issues and promote the correct use of statistical methods.Perform appropriate statistical modeling and/or analysis of project data, interpreting statistical results and preparing summaries and reports.Work with and manipulate large datasets.Perform exploratory analyses of data as requested to explore for patterns and trends from past studies.Prepare presentations on statistical methods to be presented to project leaders and groups.Travel as necessaryPractice safety in the work area', 'Work with and manipulate large datasets.', 'Consult with scientists from different areas in the design and analysis of experiments.', 'Ability to work collaboratively with cross-functional teams', 'Computer literacy', 'Practice safety in the work area', 'Leadership, organizational and time management skills, with the ability to effectively manage multiple priorities and projects.', 'Essential Functions: ', 'Proven ability and willingness to mentor and guide the less experienced technical staff', 'Keep current in field and maintain a high level of expertiseProvide training to staff as needed in experimental design, statistical data analysis and statistical process controlActively acts as a consulting expert within area of technical expertiseProven ability and willingness to mentor and guide the less experienced technical staff', 'Experience with design and analysis of research experiments for product and process development.', 'This position is responsible for providing broad statistical expertise, including experimental design, data analysis, sample size justification, and exploratory and final data analyses using mainstream statistical analysis software in support of product and process development for the R&D groups.', 'Prepare presentations on statistical methods to be presented to project leaders and groups.', 'Excellent analytical skills with the ability to analyze data from any source.', 'Additional Responsibilities: ', 'Qualifications: ', 'Description:', 'Minimum of 5 years of related experience in the food or related industry or equitable experience.', 'Perform appropriate statistical modeling and/or analysis of project data, interpreting statistical results and preparing summaries and reports.', ' ', 'Actively acts as a consulting expert within area of technical expertise', 'ManpowerGroup is an Equal Opportunity Employer (EOE/AA)', 'Well-versed in statistical software for analysis of research data (SAS is a plus).', 'Interact proactively with individuals and groups on statistical issues and promote the correct use of statistical methods.', 'Motivated and willingness to learn; attention to detail', 'Pro-active/Self-Starter with the ability to work independently', 'Experience with analysis of variance, regression analysis, mixed models analysis, generalized linear models, categorical data analysis, non-parametric methods, multivariate method, sampling, and process control.', 'Masters degree in Statistics or related mathematical sciences', 'Excellent communication skills through oral, written and presentation interpersonal skills']",Associate,Full-time,Science,Food Production,2020-11-05 11:32:32
Staff Data Scientist I,Valassis,"Morrisville, NC",7 hours ago,Be among the first 25 applicants,"['', ""WHAT'S IN IT FOR YOU?"", 'Using geo location data to track foot traffic, commercial visitation and next most likely visit to understand consumer physical behavior.', 'Our ideal candidate will likely have…', 'Ability to grow and ultimately mentor team members of varying experience levels and competencies through data science, product and software development life cycles', 'An advanced degree in a relevant, quantitative field or equivalent experience working with Big Data and Spark in a professional setting', 'Finding the handful of outliers in billions of transactions.', 'Using online behavior data to determine the primary interest categories of consumers and the web properties they visit.', 'Participating in planning, roadmap, and architecture discussions to help evolve our AI processes to improve revenue-generating products.', 'On any given day you’ll be…', ' Using geo location data to track foot traffic, commercial visitation and next most likely visit to understand consumer physical behavior. Using online behavior data to determine the primary interest categories of consumers and the web properties they visit. Implementing a predictive model to determine whether a person is likely to visit a car dealership based on the advertising signals they’ve received. Monitoring & improving a system that deploys and refits 10’s of thousands of models daily. Developing algorithms to optimize the setting of every lever in a high throughput real-time decision system. Analyzing data to better understand how a neighborhood’s consumption of web pages correlates with visits to a local big box store. Finding the handful of outliers in billions of transactions. Deriving a set of new features that will help better understand the interplay between geography and audience features to improve model performance. Building new products with applied AI and bring them to market. Participating in planning, roadmap, and architecture discussions to help evolve our AI processes to improve revenue-generating products. ', ' The professional experience and desire to perform responsibilities similar to those listed above An advanced degree in a relevant, quantitative field or equivalent experience working with Big Data and Spark in a professional setting Ability to grow and ultimately mentor team members of varying experience levels and competencies through data science, product and software development life cycles ', 'Implementing a predictive model to determine whether a person is likely to visit a car dealership based on the advertising signals they’ve received.', 'Developing algorithms to optimize the setting of every lever in a high throughput real-time decision system.', 'Who We Are', 'Analyzing data to better understand how a neighborhood’s consumption of web pages correlates with visits to a local big box store.', 'Monitoring & improving a system that deploys and refits 10’s of thousands of models daily.', 'The professional experience and desire to perform responsibilities similar to those listed above', 'Data Scientist – Machine Learning & Real-Time Decision Processing (Remote, US)', 'Deriving a set of new features that will help better understand the interplay between geography and audience features to improve model performance.', 'Building new products with applied AI and bring them to market.']",Entry level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Data Researcher,S&P Global Ratings,"Centennial, CO",9 hours ago,Be among the first 25 applicants,"['', 'S&P Global Ratings', ""Bachelor's degree required preferably Business, Economics or Business AnalyticsExperience working with fixed income data (coursework is acceptable)Excellent time management skills, ability to meet strict deadlinesStrong communication skillsIntermediate MS Excel skillsUnderstanding of basic SQL a plusInterested in learning programs used in Data Analysis and/or Business Intelligence; Python, R, Qlikview and MicroStrategy"", 'Understanding of basic SQL a plus', 'Collaborate with data, technical and analytic professionals across the organization on new content requests in addition to project work', 'Strong communication skills', 'Role:', ""Bachelor's degree required preferably Business, Economics or Business Analytics"", 'Responsibilities', 'Apply your data analyst skills and time management skills to meet daily workflow responsibilities', 'Basic Qualifications', 'The Team', 'Learn and apply data management business rules and quality standards related to the Corporate Issuer and Issue default data', 'Complete data management activities utilizing internal data management workflow tools and databases to meet strict monthly deadlinesLearn and apply data management business rules and quality standards related to the Corporate Issuer and Issue default dataQuality test data using internal tools and data sources, resolve data defectsUnderstand ratings data definitions and understand the ratings and reference data related to the ratings release processAssist in ad-hoc research activities', 'Experience working with fixed income data (coursework is acceptable)', 'Complete data management activities utilizing internal data management workflow tools and databases to meet strict monthly deadlines', 'What We’re Looking For: ', 'Apply your data analyst skills and time management skills to meet daily workflow responsibilitiesDevelop your data management skills, critical thinking skills, technical skills, communication skills and business acumenCollaborate with data, technical and analytic professionals across the organization on new content requests in addition to project work', 'Intermediate MS Excel skills', 'What’s In It For You', 'The Impact', 'Excellent time management skills, ability to meet strict deadlines', 'Interested in learning programs used in Data Analysis and/or Business Intelligence; Python, R, Qlikview and MicroStrategy', 'EEO StatementNorth America', 'The', 'Understand ratings data definitions and understand the ratings and reference data related to the ratings release process', 'Quality test data using internal tools and data sources, resolve data defects', 'Assist in ad-hoc research activities', 'Develop your data management skills, critical thinking skills, technical skills, communication skills and business acumen', 'The Location:']",Associate,Full-time,Information Technology,Financial Services,2020-11-05 11:32:32
Data Scientist,ClearedJobs.Net,"Springfield, VA",3 hours ago,Be among the first 25 applicants,"['', 'Ability to lead work unit, proactively addressing and responding to the most difficult data science-related challenges in a timely manner while effectively balancing competing priorities.', 'Required Security Clearance', 'Demonstrated strong writing and briefing skills to educate managers, senior internal officers, and the IC.', '10 to 20 years of experience (bachelor’s degree in a field related to the support services may count for up to four years of this experience. A master’s degree in a field related to the support services may count for up to two additional years of this experience.)', 'Benefits', 'Required Education And Experience', 'Background Screening/Check/Investigation', 'Functional Responsibility: ', 'Ability to identify, retrieve, manipulate, relate, and/or exploit multiple structured and unstructured data sets from various sources, including building or generating new data sets as appropriate.Ability to interpret and evaluate the results of data science community’s methods, models, and/or algorithms, understanding the meaning, limitations, and scope of the results, and translate them into insightful output for data science and/or mission, and identifying other applications for use.Ability to initiate the efficient implementation of methods, tools, and algorithms using a comprehensive range of technologies.Ability to lead work unit, proactively addressing and responding to the most difficult data science-related challenges in a timely manner while effectively balancing competing priorities.Demonstrated strong writing and briefing skills to educate managers, senior internal officers, and the IC.', 'Qualifications', 'Ability to identify, retrieve, manipulate, relate, and/or exploit multiple structured and unstructured data sets from various sources, including building or generating new data sets as appropriate.', 'Working Conditions', 'Employment Type', 'Preferences: ', 'Other', 'Ability to interpret and evaluate the results of data science community’s methods, models, and/or algorithms, understanding the meaning, limitations, and scope of the results, and translate them into insightful output for data science and/or mission, and identifying other applications for use.', 'Ability to initiate the efficient implementation of methods, tools, and algorithms using a comprehensive range of technologies.', 'Physical Requirements']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Machine Learning Engineer,Healthgrades,United States,23 hours ago,102 applicants,"['', ""Review other team members' code for correctness and quality"", 'If you are a technologist and your idea of fun is to play with the latest technology, while delivering a world-class product designed from scratch, you will fit right in.', '5+ years of experience in Python or Scala', 'Recommend and drive development best practices and continuous integration and delivery as part of a forward-thinking, agile organization', 'Familiarity with Docker.', 'At Healthgrades, we recognize that our people drive our greatest achievements. We are passionate about maintaining a fulfilling, rewarding and high-energy work environment while setting the stage for your continued success.', 'Healthgrades is focused on providing trusted information that helps consumers and providers make meaningful connections. As a Machine Learning Engineer, you will be building the future of Healthgrades’ data science solutions, enabling health systems, hospitals and providers to better reach the right consumers.', 'Develop data pipeline features to process incoming healthcare information quickly and reliably', 'Develop models in cutting-edge machine learning frameworks', 'Strong knowledge of Git', 'Able to build base-line models with Tensorflow, Pytorch, or other machine learning frameworks.', 'Meaningful Work – empowering consumers with data to make the right decisions for themselves and their familiesChanging the Game - evolving, dynamic culture with career advancement opportunitiesCommunity Builders- participating in local charity organizations and wellness initiativesRobust Perks – generous PTO, 401k contributions, tuition assistance, entertainment discounts & more!', 'Remove roadblocks to development through collaboration, communication, and creative solution recommendations', 'Familiarity with MLFlow or similar tool.', 'Write automated scripts that power a continuous delivery pipeline', 'Experience developing data pipelines or ETLs', 'Robust Perks – generous PTO, 401k contributions, tuition assistance, entertainment discounts & more!', 'Changing the Game - evolving, dynamic culture with career advancement opportunities', 'What You Will Bring:', ""Work with a team of Data Scientists and Engineers to create products that will directly affect the mission of HealthgradesDevelop models in cutting-edge machine learning frameworksDevelop data pipeline features to process incoming healthcare information quickly and reliablyReview other team members' code for correctness and qualityWrite automated scripts that power a continuous delivery pipelineRemove roadblocks to development through collaboration, communication, and creative solution recommendationsRecommend and drive development best practices and continuous integration and delivery as part of a forward-thinking, agile organization"", 'Meaningful Work – empowering consumers with data to make the right decisions for themselves and their families', 'What You Will Do:', 'The Healthgrades enterprise data platform will enable health systems to create a holistic patient view, eliminate data silos, and improve patient experience. This enterprise platform will bring together once disparate data into a single platform, breaking down data silos and making data more useful across an entire organization. The Healthgrades data platform will also serve as the underlying data management solution for powering Healthgrades CRM and other customer experience execution systems while enabling health systems to reach beyond traditional efforts to improve and manage patient experience and patient engagement.', 'A bias towards self-education of new technologies, techniques and methods', 'Work with a team of Data Scientists and Engineers to create products that will directly affect the mission of Healthgrades', 'Test-and-learn mentality – you pivot quickly when an approach is not successful', 'Proficiency with Apache Spark or Databricks', 'Why Healthgrades?', 'Machine Learning Engineer', 'Community Builders- participating in local charity organizations and wellness initiatives', 'Ability to instrument basic automation and CI/CD', '5+ years of experience in Python or ScalaProficiency with Apache Spark or DatabricksExperience developing data pipelines or ETLsStrong understanding of SQL, relational databases, columnar data warehouses, and data modelingStrong knowledge of GitFamiliarity with MLFlow or similar tool.Familiarity with Docker.Ability to instrument basic automation and CI/CDAble to build base-line models with Tensorflow, Pytorch, or other machine learning frameworks.A bias towards self-education of new technologies, techniques and methodsTest-and-learn mentality – you pivot quickly when an approach is not successful', 'Strong understanding of SQL, relational databases, columnar data warehouses, and data modeling']",Mid-Senior level,Full-time,Engineering,Hospital & Health Care,2020-11-05 11:32:32
Marketing Data Scientist – Customer Analytics,Adobe,"San Francisco, CA",5 hours ago,Over 200 applicants,"['', 'Define and own the next-generation analytics stacks focused on identifying deeper customer insights and opportunities in acquisition, engagement and retention', '3+ years of hands-on experience with applied data science, conducting quantitative analysis on datasets to address business questions', 'Leveraging machine learning and visualization to design tools that can explain customer composition changes or differences to enable actionable and timely insights', 'Understanding of statistics, machine-learning and/or econometric modeling', 'Collaborate with the partners to establish analytics roadmap and ensure alignment with future need of the business', 'Nguyen', 'Translate business problems into a data and analytics plan and execute, through exploratory descriptive analysis, feature engineering and/or machine learning techniquesDefine and own the next-generation analytics stacks focused on identifying deeper customer insights and opportunities in acquisition, engagement and retentionDevelop new data features and work with engineering team to scale capabilities to broader use cases and regular refresh cadenceLeveraging machine learning and visualization to design tools that can explain customer composition changes or differences to enable actionable and timely insightsActing as a thought partner to Campaign, Media, Adobe.com, Product, Go-To-Market and other teamsCollaborate with the partners to establish analytics roadmap and ensure alignment with future need of the business', 'Ability to synthesize large scale data sets to generate a clear story and impactful insights', 'Develop new data features and work with engineering team to scale capabilities to broader use cases and regular refresh cadence', 'Experience programming in SQL, and R or Python', 'Advanced degree in Statistics, Economics, Business, or related quantitative field3+ years of hands-on experience with applied data science, conducting quantitative analysis on datasets to address business questionsExperience programming in SQL, and R or PythonUnderstanding of statistics, machine-learning and/or econometric modelingExcellent oral and written communication skillsAbility to synthesize large scale data sets to generate a clear story and impactful insightsA curious mind, passion, and motivation to learn new skills, tools, and analytics techniques critical to tackle business challengesStrong ability to build collaborative, productive relationships with colleagues and teams across the company', 'Acting as a thought partner to Campaign, Media, Adobe.com, Product, Go-To-Market and other teams', 'Excellent oral and written communication skills', 'Our Company', 'Strong ability to build collaborative, productive relationships with colleagues and teams across the company', 'Translate business problems into a data and analytics plan and execute, through exploratory descriptive analysis, feature engineering and/or machine learning techniques', 'Advanced degree in Statistics, Economics, Business, or related quantitative field', 'A curious mind, passion, and motivation to learn new skills, tools, and analytics techniques critical to tackle business challenges']",Mid-Senior level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Data Engineer - Insights & Analytics,FutureSoftIT,"Farmington Hills, MI",18 hours ago,Be among the first 25 applicants,"['', 'Experience working independently and with minimal supervision', 'YOU ', 'Experience with a global team', 'FutureSoftIT ', 'Experience with Test Driven Development and Software Craftsmanship', 'Work with technical and business leads to transfer global business requirements into sound solutions and implementation', 'Experience with Hadoop, Spark, Kafka', 'Ability to illustrate and convey ideas and prototypes effectively with team and partners', 'Share support responsibilities for implemented components', 'Nice to Have', '3+ years of Hive, Spark, JavaScript, SQL, HTML', 'Master data engineer; teaches others; works closely with IT architects to set strategy and design projects', '3+ years of experience with R, Python, SAS, MATLAB, Java, etc.', 'Strong Communications skills', 'Ability to deliver work within deadline', 'DATA ENGINEER - INSIGHTS & ANALYTICS', 'Work with data scientists and software engineers to support data acquisition activities, data solution ideation, and implementation', 'Experience with agile/lean methodologies', 'Technical Skills Required', 'Keys For Success', ' Work with data scientists and software engineers to support data acquisition activities, data solution ideation, and implementation Work with technical and business leads to transfer global business requirements into sound solutions and implementation Share support responsibilities for implemented components ', 'Lead a team of Associate Data Engineers and Data Engineers', 'Provide extensive technical, strategic advice and guidance to key stakeholders around the data transformation efforts', 'Presence demonstrating confidence, ability to learn quickly, influence, and shape ideas', 'Ability to work as a global team member, as well as independently, in a changing environment and managing multiple priorities', ' 3+ years of experience with R, Python, SAS, MATLAB, Java, etc. 3+ years of Hive, Spark, JavaScript, SQL, HTML 3+ years of experience with PCF cloud services Experience with Hadoop, Spark, Kafka Familiar with big data and machine learning tools and platforms Experience with BI tools, such as Informatica, Data Stage, QlikView, Tableau, etc. Design data pipelines and data robots, take a vision and bring it to life Master data engineer; teaches others; works closely with IT architects to set strategy and design projects Lead a team of Associate Data Engineers and Data Engineers Provide extensive technical, strategic advice and guidance to key stakeholders around the data transformation efforts Redesign data flows to prevent recurring data issues Strong analytical and problem-solving skills Possess excellent oral and written communication skills, as well as facilitation and presentation skills, and engaging presentation style Ability to work as a global team member, as well as independently, in a changing environment and managing multiple priorities Ability to establish and maintain cooperative and effective working relationships with application implementation teams, IT project teams, business customers, and end users Ability to deliver work within deadline ', 'Familiar with big data and machine learning tools and platforms', ' BI-Visualization Engineer ', 'Design data pipelines and data robots, take a vision and bring it to life', 'OWN YOUR POTENTIAL BY EMBARKING ON AN EXCITING CAREER-CHANGING JOURNEY!', 'Experience with BI tools, such as Informatica, Data Stage, QlikView, Tableau, etc.', ' 3+ years of experience with R, Python, SAS, MATLAB, Java, etc. 3+ years of Hive, Spark, JavaScript, SQL, HTML Experience with BI tools, such as Informatica, Data Stage, QlikView, Tableau, etc. Experience with Test Driven Development and Software Craftsmanship ', '3+ years of experience with PCF cloud services', ""DON'T DELAY...APPLY TODAY"", 'Redesign data flows to prevent recurring data issues', 'ESSENTIAL FUNCTIONS & REQUIREMENTS OF THE POSITION:', 'Background On The Position', 'Ability to establish and maintain cooperative and effective working relationships with application implementation teams, IT project teams, business customers, and end users', 'Strong analytical and problem-solving skills', ' Experience with agile/lean methodologies Experience working independently and with minimal supervision Experience with a global team Experience with Test Driven Development and Software Craftsmanship ', 'Other', 'Possess excellent oral and written communication skills, as well as facilitation and presentation skills, and engaging presentation style', ' Strong Communications skills Ability to illustrate and convey ideas and prototypes effectively with team and partners Presence demonstrating confidence, ability to learn quickly, influence, and shape ideas ']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist- Growth,Robinhood,"Menlo Park, CA",6 hours ago,Be among the first 25 applicants,"['', '4+ years of experience as a data scientist focusing on building data solutions and/or machine learning products.', 'About The Company', 'Great communication skills and ability to democratize data through actionable insights and solutions.', 'Build production grade models on large-scale dataset to measure effectiveness across growth levers by leveraging statistical modeling, machine learning and data mining techniques.', 'Feeling ready to give 100% to democratizing our financial system? We’d love to have you apply, even if you feel unsure about whether you meet every single requirement in this posting. At Robinhood, we’re looking for people invigorated by our mission, not just those who simply check off all the boxes.', 'Your Day-to-day Will Involve', 'Experience with machine learning techniques and advanced analytics (e.g. regression, classification, time series, econometrics, causal inference, mathematical optimization).', ' Build production grade models on large-scale dataset to measure effectiveness across growth levers by leveraging statistical modeling, machine learning and data mining techniques. Leverage models and experimentations to scientifically quantify incrementality from marketing, referral and content efforts and answer key growth challenges such as spend optimization, user segmentation and targeting, creative optimization and content recommendation. Collaborate with the rest of the data team and partner marketing, product, content, design teams to build data solutions and products to drive user and revenue growth.  Work with cross-functional teams to implement insights and analytical solutions to empower data-driven decision making. ', 'Leverage models and experimentations to scientifically quantify incrementality from marketing, referral and content efforts and answer key growth challenges such as spend optimization, user segmentation and targeting, creative optimization and content recommendation.', 'Masters or PhD in a quantitative field such as mathematics, statistics and engineering.', ' Masters or PhD in a quantitative field such as mathematics, statistics and engineering. 4+ years of experience as a data scientist focusing on building data solutions and/or machine learning products. Experience with machine learning techniques and advanced analytics (e.g. regression, classification, time series, econometrics, causal inference, mathematical optimization). Advanced SQL skills - comfortable working with very large data sets. Proficiency in Python or R. Great communication skills and ability to democratize data through actionable insights and solutions. ', 'Passion for working and learning in a fast-growing company', ' Passion for working and learning in a fast-growing company ', 'Work with cross-functional teams to implement insights and analytical solutions to empower data-driven decision making.', 'About The Role', 'Collaborate with the rest of the data team and partner marketing, product, content, design teams to build data solutions and products to drive user and revenue growth. ', 'Proficiency in Python or R.', 'Advanced SQL skills - comfortable working with very large data sets.', 'Some Things We Consider Critical For This Role', 'Bonus Points']",Associate,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Data Scientist - Operations,Stitch Fix,"San Francisco, CA",18 hours ago,151 applicants,"['', 'Perform analyses and build frameworks / solutions to deliver insights for operational decisions', 'We believe in autonomy & taking initiative', 'We have a smart, experienced leadership team that wants to do it right & is open to new ideas', 'We are a group of people who are bright, kind and motivated by challenges. You can be your authentic self here, and are empowered to encourage others to do the same! ', 'An inquisitive nature, and you scrutinize functional efforts through the lens of constantly improving the client experience and the business', "" We are a group of people who are bright, kind and motivated by challenges. You can be your authentic self here, and are empowered to encourage others to do the same!  We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation We are a technologically and data-driven business We are committed to our clients and connected through our vision of “Transforming the way people find what they love” We love solving problems, thinking creatively and trying new things We believe in autonomy & taking initiative We are challenged, developed and have meaningful impact We take what we do seriously. We don't take ourselves seriously We have a smart, experienced leadership team that wants to do it right & is open to new ideas We offer competitive compensation packages and comprehensive health benefits You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day "", 'About The Team', ""Why You'll Love Working at Stitch Fix"", 'Identify and estimate trade-offs between business objectives, such as efficiency, cost, and customer satisfaction. Design, implement, and analyze A/B tests', 'Experience writing code (Python preferred) in production environments where you have learned industry practices such as unit testing and code reviews.', ""We're Excited About You Because You Have…"", 'We are committed to our clients and connected through our vision of “Transforming the way people find what they love”', 'Maintain and improve algorithmic capabilities in areas such as capacity planning, allocation and warehouse operations', 'We offer competitive compensation packages and comprehensive health benefits', 'Define, build, and deploy algorithmic capabilities that span multiple functions within the business', 'A Ph.D. or Masters degree in Statistics, Biostatistics, Marketing, Econometrics, Mathematics, or other quantitative fields', 'About Stitch Fix', ' Perform analyses and build frameworks / solutions to deliver insights for operational decisions Co-lead the design of cross-functional business processes that leverages what humans and algorithms respectively do best Maintain and improve algorithmic capabilities in areas such as capacity planning, allocation and warehouse operations Define, build, and deploy algorithmic capabilities that span multiple functions within the business Identify and estimate trade-offs between business objectives, such as efficiency, cost, and customer satisfaction. Design, implement, and analyze A/B tests ', 'The ability to explain complex concepts well and move decisions forward in collaboration with your business partners', ""You're Excited About This Opportunity Because You Will…"", ""Please Review Stitch Fix's Recruiting Privacy Policy Here"", 'We love solving problems, thinking creatively and trying new things', 'You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day', 'We are challenged, developed and have meaningful impact', 'Co-lead the design of cross-functional business processes that leverages what humans and algorithms respectively do best', ""We take what we do seriously. We don't take ourselves seriously"", 'We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation', 'The ability to quickly and iteratively prototype analyses and algorithms', ' 2+ years of experience supporting operational roles (demand planning, supply planning, capacity management, operations) A Ph.D. or Masters degree in Statistics, Biostatistics, Marketing, Econometrics, Mathematics, or other quantitative fields Experience writing code (Python preferred) in production environments where you have learned industry practices such as unit testing and code reviews. The ability to quickly and iteratively prototype analyses and algorithms A deep understanding business processes, and have experience working with people with different backgrounds, priorities, and responsibilities The ability to explain complex concepts well and move decisions forward in collaboration with your business partners An inquisitive nature, and you scrutinize functional efforts through the lens of constantly improving the client experience and the business ', '2+ years of experience supporting operational roles (demand planning, supply planning, capacity management, operations)', 'We are a technologically and data-driven business', 'A deep understanding business processes, and have experience working with people with different backgrounds, priorities, and responsibilities']",Mid-Senior level,Full-time,Research,Apparel & Fashion,2020-11-05 11:32:32
BI Data Scientist,TEK Connexion,"Pittsburgh, PA",20 hours ago,Be among the first 25 applicants,[],Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Junior Data Engineer,Dell,"Hopkinton, MA",5 hours ago,39 applicants,"['', 'Willingness to participate in root cause analysis', 'Knowledge of optimization techniques for data workflows', 'Essential Requirements', 'Bachelors (or Certification) in Computer Science/Engineering or related field', 'Deep dive into business problems relating to our quota planning and sales compensation efforts', 'Junior Data Engineer', 'Benefits', 'Decision Sciences ', 'Deign and maintain optimal data architecture for our data science products; partner with your peer data engineers to build reliable systems that scale', 'Knowledge of Python, Java, or a similar object-oriented language', 'Knowledge of PostgreSQL (this is a strict requirement for the role)', '1+ year(s) of experience (preferred) in a data engineering capacity, preferably on a data science or advanced analytics team; will consider recent graduates if other requirements are met', 'Self-learner who is driven to learn new methods and techniques to fulfill business needsDetail-oriented with the ability to effectively prioritize tasksKnowledge of PostgreSQL (this is a strict requirement for the role)Knowledge of Python, Java, or a similar object-oriented languageKnowledge of optimization techniques for data workflowsKnowledge of data pipeline architecturesWillingness to participate in root cause analysisWillingness to learn!Good project management and organizational skills1+ year(s) of experience (preferred) in a data engineering capacity, preferably on a data science or advanced analytics team; will consider recent graduates if other requirements are metBachelors (or Certification) in Computer Science/Engineering or related field', 'Detail-oriented with the ability to effectively prioritize tasks', ' Junior Data Engineer ', 'Remote Role in Massachusetts USA', 'Build, clean, and maintain data sets that feed our machine learning algorithms and discovery processes (based in PostgreSQL database)', 'Identify opportunities for process improvements (may results in automating, optimizing, or fully rebuilding workflows)', 'Deep dive into business problems relating to our quota planning and sales compensation effortsDeign and maintain optimal data architecture for our data science products; partner with your peer data engineers to build reliable systems that scaleBuild, clean, and maintain data sets that feed our machine learning algorithms and discovery processes (based in PostgreSQL database)Identify opportunities for process improvements (may results in automating, optimizing, or fully rebuilding workflows)Work with the greater Decision Sciences team to help with data related issues and analysis needs', 'Key Responsibilities', 'Knowledge of data pipeline architectures', 'Work with the greater Decision Sciences team to help with data related issues and analysis needs', 'Willingness to learn!', 'Self-learner who is driven to learn new methods and techniques to fulfill business needs', 'Good project management and organizational skills']",Not Applicable,Full-time,Information Technology,Computer Hardware,2020-11-05 11:32:32
Sr Data Scientist (machine learning scientist),Aptonet Inc,"Atlanta, GA",29 minutes ago,Be among the first 25 applicants,"['', '· Stream 350+ sensor information in real-time. We create predictive models to predict various component failures hours, days, and sometimes months in advance.', 'What will be your duties:', '· Hands-on and theoretical knowledge of various Machine Learning algorithms and tools, e.g. xgboost/LightGBM, Random Forests, SVMs, PCA, t-sne, kmeans, DBSCAN, etc.', '· Evaluate accuracy and quality of data sources, as well as the designed models', '· Bachelor’s, Master’s or Ph.D. in Computer Science, Electrical Engineering, Machine Learning, Statistics or related field', '· Expertise with Time Series problems is a plus', '· Communicate results to colleagues and business partners.', '· Collaborate with various departments to identify opportunities for process improvement and developing analytics use-cases.', 'What are our requirements:', '· We are very collaborative, you will likely get lots of ideas from the team.', '· There are high-frame cameras beside our tracks, capturing images of trains and rail cars as they pass. We design various Deep Learning and Computer Vision algorithms to detect certain objects of interest or issues and defects. We then optimize their performance and deploy them at the edge for real-time scoring and notification of our mechanical personnel upon detections.', '· We use Python, R, and Spark (PySpark, SparkR) for modeling and EDA.', '\ufeffDisclaimer', '· Most of our models make it to production, they never sit in a research lab. But we also do quite a bit of research to stay up-to-date with the latest technologies/algorithms.', '· This position will focus on Statistics and Machine Learning models (regression, classification, clustering, etc.) and it will not have a Computer Vision or Deep Learning focus.', 'What kind of problems do we solve:', '· You will also have terabytes of memory in our Spark cluster that is not shared by anyone.', 'o You will have a local machine with 512GB of memory, so feel free to load the data in memory if it makes sense or if it fits (!)', '· We use Jupyter notebook, Emacs, PyCharm, Rstudio as IDEs.', 'Who we are and what we do:', '· The AI and Data Science team is centralized across the entire organization.', '· Minimum of 1 year of relevant industry experience (as a Data Scientist, Research Scientist, Machine Learning Engineer, etc.), 2+ preferred; or proven qualifications.', '· Effectively utilize appropriate statistical, Machine Learning, and Deep Learning models and techniques to solve various business problems', 'Job Description', 'Data Scientist\xa0(Machine Learning Scientist)', '· We use Tensorflow, Keras, PyTorch, and MXNet for Deep Learning, and OpenCV for traditional Computer Vision.', '· Excellent knowledge of Python and/or R', '· We work with various product teams across various business units to define high-impact business problems, solve them using novel techniques, and execute and monitor them throughout their lifecycle.', 'What tools do we use:', '· knowledge of Spark (PySpark and SparkR) is a plus', '· Stays up to date with the latest models and changes in the technology', '· Want to learn more? Apply today!', '· We always have the latest versions of our tools/packages/libraries available.']",Mid-Senior level,Contract,Information Technology,Logistics and Supply Chain,2020-11-05 11:32:32
Principal Data Scientist,LivePerson,"Seattle, WA",11 hours ago,56 applicants,"['', 'Production ML evaluation and monitoring performance once completed', 'Ability to efficiently write, test, monitor, and improve production-quality code', 'Masters/PhD in Mathematics, Statistics, Operations Research, Computer Science, Machine Learning or a related field, or BSc + Experience', 'Analysis, problem-solving, communication, and critical-thinking skills', 'Collaborating on writing research articles for external publication where appropriate', 'Experience with frameworks for Statistical Analysis, Machine Learning, Distributed Computing (Pandas, Scikit-Learn, Hadoop, Spark, etc.)', 'Creating durable, flexible scientific deployment and experimentation capabilities', 'You will thrive here if: ', ' In this role you will be:', 'We are an innovative, intent-driven company that believes in building the future and we are looking for growth minded, unconventional thinkers, developers and builders to join the team.', 'LivePerson is a transformational force in how brands and consumers communicate. With over 18,000 brands, including Citi, HSBC, Disney, Verizon, and Home Depot, we are on a mission to make life easier for people and brands everywhere through trusted Conversational AI. We believe in a future where conversations are the norm for getting your intentions fulfilled - whatever they are.', 'Bringing research-driven models to life within production systems', 'LivePerson was named to FastCompany’s World’s most innovative companies of 2020 list for the Artificial Intelligence category. We offer top tier tech & data science colleagues, along with opportunities to push your own limits. We embrace invention and experimentation. You’ll have great benefits, flexible time off, plus snacks and drinks to keep your mind fresh and stomach full. Most importantly, you’ll have an ability to make an impact at work and at brands across the globe as we build the future with trusted Conversational AI together.', 'You relate to our core principles (link) and want to work with Conversational AI experts', '\xa0', 'Analyzing and drawing insights from large scale conversational datasetsChoosing between many available state-of-the-art methods and tools, and consistently finding the most effective, efficient, stable, explainable, and where possible, simple approachesDesigning and building modern, flexible pipelines and services for delivering and navigating insightsBringing research-driven models to life within production systemsCreating durable, flexible scientific deployment and experimentation capabilitiesWork on challenging unsupervised and semi-supervised problems related to intent and dialog management, and create pipelines to accelerate and scale this effortUsing and presenting research findings in ways that inform and sometimes guide business and product strategyCollaborating on writing research articles for external publication where appropriate', 'You believe data-driven decision making is the norm', 'Designing and building modern, flexible pipelines and services for delivering and navigating insights', 'All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.', 'Work on challenging unsupervised and semi-supervised problems related to intent and dialog management, and create pipelines to accelerate and scale this effort', 'Analyzing and drawing insights from large scale conversational datasets', 'You can build partnerships that move our business forward', 'You can operate in a fast paced, dynamic environment', 'Masters/PhD in Mathematics, Statistics, Operations Research, Computer Science, Machine Learning or a related field, or BSc + ExperienceAnalysis, problem-solving, communication, and critical-thinking skillsCore strength in Statistical models, e.g., for significance testing, forecasting, regression, hypothesis testing,\xa0 record-linkageUnderstanding of ML fundamentals, ideally including Deep LearningStrong hands-on programming skills, e.g., Python, R, SQL, any major OO languagesExperience with frameworks for Statistical Analysis, Machine Learning, Distributed Computing (Pandas, Scikit-Learn, Hadoop, Spark, etc.)Ability to efficiently write, test, monitor, and improve production-quality codeCuriosity and interest in learning new applications and toolingAbility to work closely with teammates in a highly collaborative environment, as well as providing strong individual contributionsProduction ML evaluation and monitoring performance once completed', 'Using and presenting research findings in ways that inform and sometimes guide business and product strategy', 'Core strength in Statistical models, e.g., for significance testing, forecasting, regression, hypothesis testing,\xa0 record-linkage', 'Strong hands-on programming skills, e.g., Python, R, SQL, any major OO languages', 'Your qualifications are:', 'Understanding of ML fundamentals, ideally including Deep Learning', 'You build code that is simple, understandable, and clean\xa0', 'Why you’ll love working here:', 'In this role you will be:', 'You see feedback or failure as motivation to learn and to grow', 'Ability to work closely with teammates in a highly collaborative environment, as well as providing strong individual contributions', ' ', 'At LivePerson, people from diverse backgrounds come together to do their best work and be their authentic selves. We are proud to be an equal opportunity employer. ', 'Curiosity and interest in learning new applications and tooling', 'Choosing between many available state-of-the-art methods and tools, and consistently finding the most effective, efficient, stable, explainable, and where possible, simple approaches']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Research Scientist,Massachusetts General Hospital,"Boston, MA",13 hours ago,Be among the first 25 applicants,"['', ' Maintains laboratory notebook', '  Ensure proper supplies are always stocked  Ensures all necessary solutions are properly prepared and stocked  Ensures all lab reagents, chemicals, instruments and equipment are stocked and maintained ', ' Laboratory Training and Leadership ', ' Supervise multiple technicians and ensure quality of their work', ' Sound interpersonal skills and the ability to supervise and train staff effectively. ', ' Conducts analysis of results, and may begin interpretation of results', '  Ability to work independently and as a team member   Experience in molecular genomic techniques (i.e. PCR, qPCR, RNAseq, gel electrophoresis)   Experience in mammalian cell culture required (iPSC culture highly preferred)   Interest in learning and troubleshooting new molecular biology techniques   Excellent organizational and communication skills   Sound interpersonal skills and the ability to supervise and train staff effectively.   Ability to prioritize tasks, set deadlines, and adapt to shifting priorities in response to changing deadlines and needs of the lab.   Ability to function with speed, precision and an understanding of theory behind protocols and experiments.  ', ' Perform appropriate iPSC culture maintenance and differentiation', ' Experience in molecular genomic techniques (i.e. PCR, qPCR, RNAseq, gel electrophoresis) ', ' Ensures all necessary solutions are properly prepared and stocked', ' Participation in Publication ', ' Work independently to determine most suitable methodology and protocols for experiments are being performed', ' Calculates, transcribes and analyzes data', 'Skills/Abilities/Competencies Required', ' Data Management ', ' Design standardized protocols that can be performed routinely with reproducible results', '  Orients and trains new technicians, students and fellows  Train technicians, students and fellows on newly developed protocols and techniques  Supervise multiple technicians and ensure quality of their work  Coordinate with project drivers and analysts to ensure proper integration of data and workflow ', 'General Summary/Overview Statement', '  Perform independent literature searches  Prepares written and/or verbal status reports  Organizing materials and analyze data for publication or presentation  Drafts material for the preparation of research presentations, manuscripts and grants ', 'Organization', ' Conducting Experimental Protocols ', 'Standard Hours', ' Responsible for troubleshooting problems and instructing others in highly specialized techniques', ' Prepares and presents reports', ' Ensures all lab reagents, chemicals, instruments and equipment are stocked and maintained', '  Must be comfortable working with biological specimens (e.g., tissue, blood, cells) from a variety of specimens (e.g., human, mouse, invertebrates)  Work independently to determine most suitable methodology and protocols for experiments are being performed  Work independently to research and develop modifications of existing assay techniques, experimental protocols, or new procedures  Performs advanced design and modification of protocols  Perform appropriate molecular genomics procedures (e.g., DNA/RNA extraction, library production, sample archiving, tissue culture, etc)  Perform appropriate iPSC culture maintenance and differentiation  Ensures proper execution of standard and developmental protocols  Responsible for troubleshooting problems and instructing others in highly specialized techniques  Work independently to develop new methods based on state-of-the art techniques  Design standardized protocols that can be performed routinely with reproducible results ', 'required', ' Work independently to research and develop modifications of existing assay techniques, experimental protocols, or new procedures', ' EDUCATION ', 'Recruiting Department', ' Ability to work independently and as a team member ', ' Ability to function with speed, precision and an understanding of theory behind protocols and experiments. ', '  Maintains laboratory notebook  Conducts analysis of results, and may begin interpretation of results  Calculates, transcribes and analyzes data  Prepares and presents reports  Organizes and summarizes acquired data, using scientific and statistical techniques ', 'Schedule', 'Shift', ' Orients and trains new technicians, students and fellows', 'Work Locations', 'Experience', ' Perform appropriate molecular genomics procedures (e.g., DNA/RNA extraction, library production, sample archiving, tissue culture, etc)', ' Ensure proper supplies are always stocked', ' Ensures proper execution of standard and developmental protocols', ' Must be comfortable working with biological specimens (e.g., tissue, blood, cells) from a variety of specimens (e.g., human, mouse, invertebrates)', 'SUPERVISORY RESPONSIBILITY ', ' Perform independent literature searches', ' Coordinate with project drivers and analysts to ensure proper integration of data and workflow', 'Primary Location', ' Train technicians, students and fellows on newly developed protocols and techniques', ' Excellent organizational and communication skills ', ' Organizing materials and analyze data for publication or presentation', 'Job', ' Drafts material for the preparation of research presentations, manuscripts and grants', ' WORKING CONDITIONS ', ' Prepares written and/or verbal status reports', 'Job Posting', ' Laboratory Maintenance ', ' Performs advanced design and modification of protocols', 'Principal Duties And Responsibilities', ' Work independently to develop new methods based on state-of-the art techniques', ' Interest in learning and troubleshooting new molecular biology techniques ', ' Ability to prioritize tasks, set deadlines, and adapt to shifting priorities in response to changing deadlines and needs of the lab. ', 'Employee Status', ' Organizes and summarizes acquired data, using scientific and statistical techniques', ' Experience in mammalian cell culture required (iPSC culture highly preferred) ']",Associate,Full-time,Other,Nonprofit Organization Management,2020-11-05 11:32:32
Staff Data Scientist,ServiceNow,"Waltham, MA",9 hours ago,Be among the first 25 applicants,"['', 'Unstructured data (utterances, descriptions, documents, …)', 'Company', 'Collaborate day-to-day with an energetic team of like-minded data scientists, developers, product managers and quality engineers.Master new functional areas and take ownership of customer-critical features', 'Mentor and help grow the data science team', 'Bring intelligence to customer workflows by leveraging their individual data -', 'Strong background in statistics, probability, and machine learning', 'Solid software development skills and understanding of computer science fundamentalsStrong proficiency with Python scientific stack (scikit-learn, pandas, numpy, …)Experience with neural network-based NLP technologies (Transformers, BERT, etc.) desiredProficient in Java, SQL, source code control systems (git), and basic UNIX utilitiesStrong educational background (M.S.) in a quantitative discipline (Ph.D. preferred)', 'Structured data (workflow state evolution, database tables)Unstructured data (utterances, descriptions, documents, …)Adapting to their unique and complex workflowsAt Scale: 7000+ customers with a wide range of data volumes', 'Strong educational background (M.S.) in a quantitative discipline (Ph.D. preferred)', 'Experience with neural network-based NLP technologies (Transformers, BERT, etc.) desired', 'Co-pilot the expansion of machine learning into new products with our product management, internal operations teams and development teams', 'Providing technical leadership to data science teams', 'In order to be successful in this role, we need someone who has:', 'Experience evaluating and developing new machine learning algorithms', 'Solid software development skills and understanding of computer science fundamentals', 'Master new functional areas and take ownership of customer-critical features', 'Team ', 'At Scale: 7000+ customers with a wide range of data volumes', 'Staff Data ScientistKirkland, WA, Boston, Ma, Chicago, IL, Bay Area, Ca', 'Demonstrated ability to deploy machine learning solutionsProven track record solving industrial problems with dataExperience evaluating and developing new machine learning algorithmsProviding technical leadership to data science teams', 'Excellent written and oral communication skills', 'Role ', 'Ability to explain models in simple terms to a broader audience', 'Structured data (workflow state evolution, database tables)', 'Adapting to their unique and complex workflows', 'Collaborate day-to-day with an energetic team of like-minded data scientists, developers, product managers and quality engineers.', 'Strong proficiency with Python scientific stack (scikit-learn, pandas, numpy, …)', 'Demonstrated ability to deploy machine learning solutions', 'Proficient in Java, SQL, source code control systems (git), and basic UNIX utilities', 'In This Role, You Will', '6+ years’ experience in a commercial setting:', 'Proven track record solving industrial problems with data']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Workforce Logiq,"Fort Lauderdale, FL",2 hours ago,29 applicants,"['', 'Google Cloud Certified - Professional Data Engineer certification would be a plus', 'monitoring of workflows', 'Experience in design, build and operationalization of\xa0big data pipelines on Cloud Technologies.', 'interpersonal skills', 'Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud', 'Responsibilities', 'Strong communication &\xa0interpersonal skills\xa0', 'remotely', 'Advanced SQL programming skills', 'Be part of the on-call rotation supporting our SLA’s', 'big data pipelines', ""WorkforceLogiq is currently hiring for two\xa0Data Engineer's for our\xa0Ft Lauderdale\xa0location.\xa0This position can workremotely\xa0from anywhere in the US but will need to work EST hours.\xa0\xa0The\xa0Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting.\xa0This engineer’s duty is to monitor the existing metrics, analyze data, and lead partnerships with other Data and Analytics teams in an effort to identify and implement systems and process improvements. This engineer also designs, architects, implements, and supports key datasets."", '\xa0', 'Preferred Qualifications:', 'Familiar with Atlassian products Jira and Confluence', 'ingestion of data from external APIs ', 'Google Cloud Certified - Professional Data Engineer certification would be a plusKnowledge of Git, Jinja2, Docker, Bitbucket, and Bambooamiliar with a NoSQL database such as MongoDBFamiliar with version control systems (Git and Bitbucket)Familiar with Atlassian products Jira and ConfluenceHands-on experience with Apache Airflow or Google Composer', 'Computer Science', ""Bachelor's degree in\xa0Computer Science or equivalent experience in a related field or hands-on experience working in data warehousing or data engineering environmentAdvanced SQL programming skillsExperience developing data solutions on GCP or AWSExperience in\xa0ingestion of data from external APIs and data storesExperience in design, build and operationalization of\xa0big data pipelines on Cloud Technologies.Problem-solving, quality and ability to executeStrong experience in authoring, scheduling, and\xa0monitoring of workflows (Apache Airflow related technologies)Strong communication &\xa0interpersonal skills\xa0"", 'Experience developing data solutions on GCP or AWS', 'amiliar with a NoSQL database such as MongoDB', 'Experience in\xa0ingestion of data from external APIs and data stores', 'Knowledge of Git, Jinja2, Docker, Bitbucket, and Bamboo', 'Data Engineer', 'Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery', 'Develop and promote best practices in data engineering', 'Problem-solving, quality and ability to execute', 'Qualifications', 'Advanced SQL', 'Familiar with version control systems (Git and Bitbucket)', 'Ft Lauderdale', 'Strong experience in authoring, scheduling, and\xa0monitoring of workflows (Apache Airflow related technologies)', 'Hands-on experience with Apache Airflow or Google Composer', 'Participate in design and code reviews\xa0', 'Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloudIdentify, design and implement internal process improvements by automating manual processes and optimizing data deliveryDevelop and promote best practices in data engineeringDevelop real-time data processing applications using Google CloudBe part of the on-call rotation supporting our SLA’sParticipate in design and code reviews\xa0', ""Bachelor's degree in\xa0Computer Science or equivalent experience in a related field or hands-on experience working in data warehousing or data engineering environment"", 'Develop real-time data processing applications using Google Cloud']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Scientist - Clinical Supply Chain,GSK,"Collegeville, PA",59 minutes ago,Be among the first 25 applicants,"['', 'Develop strong relationships with key functional stakeholders', 'Experience with Machine Learning and/or Artificial Intelligence', ""Bachelor's degree from an accredited institution in Data Science, Mathematics, Computer Science, Computational Biology, Computational Chemistry, or Engineering."", 'Experience with developing solutions following a defined Software Development Life Cycle', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.', 'As GSK Focuses On Our Values And Expectations And a Culture Of Innovation, Performance, And Trust, The Successful Candidate Will Demonstrate The Following Capabilities', 'Why GSK?', 'Develop project plans with flexibility to account for variable business resource availability', 'Site Name:', 'Preferred Qualifications', 'Basic Qualifications', 'Continuously looking for opportunities to learn, build skills and share learning.', 'Experience and comprehensive understanding of data collection, transformation and presentation processes.', 'Analyze disparate data sources, producing insights to uncover opportunities', 'Building strong relationships and collaboration, honest and open conversations.', 'Clearly document technical and business requirements from stakeholders using Agile methods', 'Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.', 'Experience using data visualization tools (eg Spotfire, Tableau, Microsoft Power BI, etc)', 'Experience with pharmaceutical clinical supply chain', 'Develop value-based proposals suitable for senior stakeholders', 'Experience with Machine Learning and/or Artificial IntelligenceExperience with pharmaceutical clinical supply chainExperience with GxP regulationsExperience with developing solutions following a defined Software Development Life Cycle', 'Analyze disparate data sources, producing insights to uncover opportunitiesQuickly create tactical solutions for pilots/POC’s to verify value and develop strong business casesAssist clinical supply chain teams with process mapping, data extraction/modeling/visualization for quality investigation and robustness improvement initiativesDevelop value-based proposals suitable for senior stakeholdersDevelop project plans with flexibility to account for variable business resource availabilityDevelop strong relationships with key functional stakeholdersClearly document technical and business requirements from stakeholders using Agile methodsDevelop solution designs and manage technical change control projectsManage automated data extractions and intermediate transformation platformsEffectively work with IT professionals to deliver industrialized analytic solutions', 'Experience with GxP regulations', 'Posted Date:', 'Develop solution designs and manage technical change control projects', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.Continuously looking for opportunities to learn, build skills and share learning.Sustaining energy and well-beingBuilding strong relationships and collaboration, honest and open conversations.Budgeting and cost-consciousness', 'Manage automated data extractions and intermediate transformation platforms', 'Assist clinical supply chain teams with process mapping, data extraction/modeling/visualization for quality investigation and robustness improvement initiatives', '>3 years experience with data visualization tools.', 'Effectively work with IT professionals to deliver industrialized analytic solutions', 'Five (5) years of experience in a relevant business environment, including three (3) years of experience developing complex data models & visualizations.', 'Budgeting and cost-consciousness', 'Why you?', 'Quickly create tactical solutions for pilots/POC’s to verify value and develop strong business cases', 'Experience using statistical computer languages (R, Python, Java, SQL, MATLAB, etc.) to manipulate data and draw insights from large data sets.', 'Sustaining energy and well-being', ""Bachelor's degree from an accredited institution in Data Science, Mathematics, Computer Science, Computational Biology, Computational Chemistry, or Engineering.Five (5) years of experience in a relevant business environment, including three (3) years of experience developing complex data models & visualizations.Experience and comprehensive understanding of data collection, transformation and presentation processes.>3 years experience with data transformation tools.>3 years experience with data visualization tools.Experience with application design, testing and deploymentExperience using statistical computer languages (R, Python, Java, SQL, MATLAB, etc.) to manipulate data and draw insights from large data sets.Experience using data visualization tools (eg Spotfire, Tableau, Microsoft Power BI, etc)"", '>3 years experience with data transformation tools.', 'These Responsibilities Include Some Of The Following', 'Experience with application design, testing and deployment']",Not Applicable,Full-time,Research,Pharmaceuticals,2020-11-05 11:32:32
Senior Data Scientist,Cox Automotive Inc.,"Atlanta, GA",11 hours ago,Be among the first 25 applicants,"['', 'Assist with problem formulation and the selection of an appropriate methodology.', 'Primary Responsibilities And Essential Functions', 'Work independently on all phases of an analytics project, including formulation, research, development, implementation, testing, and maintenance.Assist with problem formulation and the selection of an appropriate methodology.Present findings and recommendations to stakeholders.Maintain an awareness of trends in the field; research and suggest new methodologies.', 'Present findings and recommendations to stakeholders.', 'What We Look For (preferred)', ""BS/BA with 5 years’ experience; MS with 2 years’ experience; PhD with up to 2 years' experience."", 'Required Experience (minimum): ', 'Experience creating compelling data visualizations strongly preferred.', 'Strong problem-solving skills with an emphasis on product development.', 'Proven experience applying descriptive, predictive, and prescriptive statistics to real-world problems. ', 'Technology We Use', 'Primary Location: ', 'The ability and inclination to coach junior staff.', 'About Cox', 'Machine Learning: Selecting, tuning, and implementing a variety of common supervised and unsupervised models, including decision trees, nearest neighbor models, and neural nets; and several standard ML libraries, such as scikit-learn, TensorFlow, or similar.', 'Maintain an awareness of trends in the field; research and suggest new methodologies.', ""Degree in Statistics, Operations Research, Applied Mathematics, Computer Science, Economics, or related quantitative field.BS/BA with 5 years’ experience; MS with 2 years’ experience; PhD with up to 2 years' experience.Strong problem-solving skills with an emphasis on product development.A drive to learn and master new technologies and techniques.Proven experience applying descriptive, predictive, and prescriptive statistics to real-world problems. Experience querying relational databases using SQL.Ability to develop and maintain production-ready code.Experience working with Amazon Web Services (AWS) strongly preferred.The ability to present findings clearly and concisely to team members and data science leadership.The ability and inclination to coach junior staff."", 'The ability to present findings clearly and concisely to team members and data science leadership.', 'Linear and mixed integer optimization, discrete event simulation, heuristic methods, and network flow analysis.', 'Qualifications', 'Work independently on all phases of an analytics project, including formulation, research, development, implementation, testing, and maintenance.', 'Generalized linear models, time series models, forecasting techniques, cluster analysis, and principle component analysis.Linear and mixed integer optimization, discrete event simulation, heuristic methods, and network flow analysis.Machine Learning: Selecting, tuning, and implementing a variety of common supervised and unsupervised models, including decision trees, nearest neighbor models, and neural nets; and several standard ML libraries, such as scikit-learn, TensorFlow, or similar.', 'Shift: ', 'Schedule: ', 'Expertise in one or more of the following strongly preferred:', 'Generalized linear models, time series models, forecasting techniques, cluster analysis, and principle component analysis.', 'About Cox Automotive', 'Experience querying relational databases using SQL.', 'Ability to develop and maintain production-ready code.', 'Experience working with Amazon Web Services (AWS) strongly preferred.', 'A drive to learn and master new technologies and techniques.', 'Requisition Number: ', 'Travel: ', 'Job Level: ', 'Degree in Statistics, Operations Research, Applied Mathematics, Computer Science, Economics, or related quantitative field.', 'Division: ']",Associate,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Data Scientist,Frequency Therapeutics,"Woburn, MA",3 hours ago,82 applicants,"['', 'Set-up and maintain the high performance computing environment on AWSBuild pipelines and perform processing, quality control check, and statistically analysis of -omics data sets, such as RNA-Seq, single cell RNA-Seq, ATAC-Seq, ChIP-Seq and nCounter NanoStringCreate data visualization from those analysis and translate data into biological insights, present and discuss results in project team meetingsDevelop novel computational algorithms and build mathmatical models to solve various problems during the drug development process', 'Create data visualization from those analysis and translate data into biological insights, present and discuss results in project team meetings', 'Familiarity with R and relevant statistical packages and experience with at least one scripting language (Shell script, Python, MATLAB etc.) is required', 'Extensive experience with linux operating system, specially in the AWS cloud environment', 'Exceptional organizational skills and attention to detail, with demonstrated leadership among peers and teammates to meet critical deadlines', 'Develop novel computational algorithms and build mathmatical models to solve various problems during the drug development process', 'Set-up and maintain the high performance computing environment on AWS', 'A proactive communicator with professional written and verbal communications skills and the ability to operate successfully both independently and within a dynamic, multi-disciplinary environment', 'Reporting to the Director, Bioinformatics, the Data Scientist, will work closely with the computational biology team, and cross functionally with our scientific teams, to help decipher drug activity on progenitor cells and to characterize cellular development and maturation.\xa0\xa0These findings will contribute to our programs in hearing, multiple sclerosis, and diabetes. We seek candidates with experience analyzing genomics, epigenetics, and transcriptomic datasets such as nCounter NanoString, RNA-Seq, single cell RNA-Seq, ATAC-Seq, and ChIP-Seq.', 'We offer a competitive compensation and benefit package. For consideration, please submit CV and cover letter', 'Expertise in scientific data analysis complemented by visualization and presentation skills', 'Please visit\xa0www.frequencytx.com\xa0for more\xa0information.', 'At Frequency Therapeutics, we believe that we have the best chance to achieve our mission by creating an environment where our collective problem-solving and leadership skills are put to work, so collaboratively, we can solve some of the most complex challenges in medicine. We are focused on developing new treatments to potentially help millions of patients with novel therapeutics. This requires both a willingness to be audacious in our pursuits and relentless in our focus and commitment to research and patients. We look for individuals who are both highly skilled and self-aware, who are willing to challenge leadership and their colleagues, are entrepreneurial by nature and who are undeterred by uncertainty.\xa0', 'Working at Frequency', 'Master’s Degree in Bioinformatics, Computational Biology, Computer Science, Life Sciences or Mathematics\xa0and bioinformatics related work experience of 3 years, or, a PhD with 1 year of experienceExtensive experience with linux operating system, specially in the AWS cloud environmentFamiliarity with R and relevant statistical packages and experience with at least one scripting language (Shell script, Python, MATLAB etc.) is requiredExperience with standard bulk RNA-seq and single cell RNA-seq toolsWorking knowledge of statisticsBroad knowledge of molecular biology or developmental biologyExpertise in scientific data analysis complemented by visualization and presentation skillsExceptional organizational skills and attention to detail, with demonstrated leadership among peers and teammates to meet critical deadlinesA proactive communicator with professional written and verbal communications skills and the ability to operate successfully both independently and within a dynamic, multi-disciplinary environment', 'Qualifications:', 'Broad knowledge of molecular biology or developmental biology', 'Experience with standard bulk RNA-seq and single cell RNA-seq tools', 'Frequency Therapeutics (Nasdaq: FREQ) is a leader in the development of medicines designed to activate progenitor cells within the body to treat degenerative diseases. The company’s lead product candidate, FX-322, is a potential disease modifying therapy designed to regenerate damaged auditory hair cells to improve hearing function. In initial clinical studies of FX-322, the company observed meaningful improvements in key measures of hearing function in patients with sensorineural hearing loss, the most common form of hearing loss which impacts more than 90 percent of all people with hearing loss. The company recently completed enrollment of a Phase 2a study, with results to be shared in Q2 2021.\xa0\xa0Frequency’s progenitor cell activation (PCA) approach stimulates progenitor cells to create functional tissue and the Company is researching an array of additional degenerative diseases where PCA may be applied, including a pre-clinical program for remyelination in multiple sclerosis.', 'Master’s Degree in Bioinformatics, Computational Biology, Computer Science, Life Sciences or Mathematics\xa0and bioinformatics related work experience of 3 years, or, a PhD with 1 year of experience', 'Key Responsibilities Include:', 'Build pipelines and perform processing, quality control check, and statistically analysis of -omics data sets, such as RNA-Seq, single cell RNA-Seq, ATAC-Seq, ChIP-Seq and nCounter NanoString', 'Working knowledge of statistics']",Associate,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Machine Learning Engineer,PulsePoint,"New York, NY",1 day ago,91 applicants,"['', 'Support and enhance the existing work on health user profiling, prediction, and targeting tools;', 'different Neural Network models (CNN, RNN, auto-encoders, transformers);', 'Support existing codebase for data integration and production support for our core models.', 'The goals of the PulsePoint Data Science team:', 'Improve and optimize our buying platform to ensure cost efficiency and to deliver ad campaigns within budget, target and time constraints;', 'And there’s a lot more!', 'Improve page contextualizer technology: work with healthcare topics detection algorithms, keywords/phrases extraction, general and aspect-based sentiment analysis;', 'PulsePoint™, a global programmatic advertising platform with specialized healthcare expertise, fuses the science of programmatic targeting, distribution, and optimization with the art of brand engagement. The PulsePoint platform is powered by terabytes of impression-level data, allowing brands to efficiently engage the right audiences at scale while helping publishers increase yield through actionable insights.', 'Physics; or BS with several years of applied machine learning experience', 'MS/PhD in Applied Mathematics, Statistics, Machine Learning, Computer Science,', ""What you'll be working on:"", 'Advanced knowledge of Python using the numpy/scipy/pandas/sklearn stack;', 'Contribute on projects relating to patient/physician identity for cross-device tracking, profiling and targeting;', 'Description', 'Optimize and validate targeting mechanisms for specific health conditions;Improve and optimize our proprietary contextualization and recommendation engines that handle millions of transactions per second, trillions each month;Improve and optimize our buying platform to ensure cost efficiency and to deliver ad campaigns within budget, target and time constraints;Collaborate with internal Health experts to design and support rapid assessment, analysis, and prototyping of ideas for achievable commercialization.', 'Improve and optimize our proprietary contextualization and recommendation engines that handle millions of transactions per second, trillions each month;', 'Annual company retreat', 'Comprehensive healthcare with 100%-paid medical, vision, life & disability insurance', 'Engineer/ Data Scientist;', 'Spark;', 'Vacation reimbursement (we give you $500 each year to take vacation), sabbatical, pawternity leave, marriage leave, honeymoon bonus', 'Complimentary annual memberships to One Medical (for you and your family), NY Citi Bike and SF Ford GoBike', 'What we offer:', 'Improve existing or develop new traffic segmentation algorithms and estimations of bid landscapes within each segment;Optimize real-time bidding strategies to efficiently spend ad budgets delivering campaign targets given various constraints;Support and enhance the existing work on health user profiling, prediction, and targeting tools;Improve page contextualizer technology: work with healthcare topics detection algorithms, keywords/phrases extraction, general and aspect-based sentiment analysis;Contribute on projects relating to patient/physician identity for cross-device tracking, profiling and targeting;Support existing codebase for data integration and production support for our core models.', 'Being confident user of Unix-like systems, Dockers, git, bash;', 'Our organization has a strong history of utilizing machine learning, contextualization, and targeting to distribute advertising to the right consumers at the right time and create real connections across the internet. We are now taking that knowledge and expertise to solve challenges within healthcare in order to create better health outcomes through Radical Health Personalization™.', '3+ years of full-time experience working as a Statistician/ Machine LearningEngineer/ Data Scientist;Advanced knowledge of Big Data technologies such as Hadoop, Hive/Impala andSpark;Advanced knowledge of Python using the numpy/scipy/pandas/sklearn stack;Advanced knowledge of classical ML models (logistic regression, decision trees,boosting, bagging, SVM, Bayesian methods, etc) and at least basic knowledge indifferent Neural Network models (CNN, RNN, auto-encoders, transformers);Being confident user of Unix-like systems, Dockers, git, bash;MS/PhD in Applied Mathematics, Statistics, Machine Learning, Computer Science,Physics; or BS with several years of applied machine learning experience', 'Improve existing or develop new traffic segmentation algorithms and estimations of bid landscapes within each segment;', 'Requirements', 'Gym reimbursement, local gym membership discounts', 'Optimize real-time bidding strategies to efficiently spend ad budgets delivering campaign targets given various constraints;', 'boosting, bagging, SVM, Bayesian methods, etc) and at least basic knowledge in', '$2,000 annual training and development budget', 'Game Nights, meditation/mindfulness sessions, fitness and stretch classes, book club, health and wellness seminars and workshops, weekly virtual happy hours with DJ', 'Paid parental leave and a lot of new parent perks', 'Collaborate with internal Health experts to design and support rapid assessment, analysis, and prototyping of ideas for achievable commercialization.', '3+ years of full-time experience working as a Statistician/ Machine Learning', 'Advanced knowledge of classical ML models (logistic regression, decision trees,', 'Generous paid vacation and company holidays', '$100 work-from-home productivity stipend', 'Volunteer Time Off and Donation Matching, ongoing group volunteer opportunities', 'Advanced knowledge of Big Data technologies such as Hadoop, Hive/Impala and', '401(k) Match and free access to a financial advisor', 'Optimize and validate targeting mechanisms for specific health conditions;', 'Up to $100 emergency childcare credit per year', 'Comprehensive healthcare with 100%-paid medical, vision, life & disability insurance401(k) Match and free access to a financial advisorGenerous paid vacation and company holidaysVacation reimbursement (we give you $500 each year to take vacation), sabbatical, pawternity leave, marriage leave, honeymoon bonus$2,000 annual training and development budgetComplimentary annual memberships to One Medical (for you and your family), NY Citi Bike and SF Ford GoBikePaid parental leave and a lot of new parent perksGym reimbursement, local gym membership discounts$100 work-from-home productivity stipendAnnual company retreatUp to $100 emergency childcare credit per yearVolunteer Time Off and Donation Matching, ongoing group volunteer opportunitiesGame Nights, meditation/mindfulness sessions, fitness and stretch classes, book club, health and wellness seminars and workshops, weekly virtual happy hours with DJ']",Mid-Senior level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Forward Deployed Data Scientist,Cresta,"Remote, OR",12 hours ago,Be among the first 25 applicants,"['', 'Proficiency in SQL and data visualization tools (e.g. Tableau, Looker, etc.) as well as standard NLP analysis tooling (e.g. Numpy, Pandas, Jupyter, etc.)Experience with statistical concepts such as statistical significance, selection bias, determining outliers, etc.Strong written and verbal skills willing and able to present results and back up findings to internal and external executives[Bonus] Familiarity with standard chatbot or dialogue frameworks (e.g. Dialog Flow, Rasa, Amazon Lex, etc.)', 'Strong written and verbal skills willing and able to present results and back up findings to internal and external executives', 'Forward Deployed Data Scientist', 'Experience with statistical concepts such as statistical significance, selection bias, determining outliers, etc.', 'Own the end-to-end creation of chatbots starting from the initial key intent discovery to configuration of chatbots using standard 3p and internal tools', '[Bonus] Familiarity with standard chatbot or dialogue frameworks (e.g. Dialog Flow, Rasa, Amazon Lex, etc.)', ""What You'll Do"", 'Build and share static and dynamic data visualizations that can be used both internally and externally based on requirements and feedback from customers', 'Proficiency in SQL and data visualization tools (e.g. Tableau, Looker, etc.) as well as standard NLP analysis tooling (e.g. Numpy, Pandas, Jupyter, etc.)', 'Create tooling and support for statistical analyses: for example designing an experiment to have an even distribution across control and test users, supporting ongoing analysis of the experiment, and ultimately delivering insights and a recommendation based on the results of the test', 'We Are Looking For Someone Who', 'Analyze large corpuses of text data using standard NLP practices: an example analysis might be ""what are the key phrases that sales agents use before making a sale?"" and making that analysis repeatable to be used across different teams and customersCreate tooling and support for statistical analyses: for example designing an experiment to have an even distribution across control and test users, supporting ongoing analysis of the experiment, and ultimately delivering insights and a recommendation based on the results of the testBuild and share static and dynamic data visualizations that can be used both internally and externally based on requirements and feedback from customersOwn the end-to-end creation of chatbots starting from the initial key intent discovery to configuration of chatbots using standard 3p and internal tools', 'Analyze large corpuses of text data using standard NLP practices: an example analysis might be ""what are the key phrases that sales agents use before making a sale?"" and making that analysis repeatable to be used across different teams and customers']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist – 3045,HIRECLOUT,"Los Angeles, CA",23 hours ago,Be among the first 25 applicants,"['', 'Benefits And Perks', ' Utilize data driven insights to enhance member experience ', ' Ability to present and convey rigorous concepts to non-experts ', ' Strong NoSQL ', ' Strong communication skills with both technical and business teams ', ' 2+ years of experience in data science ', ' Free parking valet ', ' Vacation travel budget ', '  Track record of promotion and growth at multiple startups   Consumer B2C experience   Practical consumer ML problem solving skills  ', ' Stocked kitchen ', '  2+ years of experience in data science   2+ years of experience working on data science support teams   Excellent ability working with data and developing software application   Proficiency in Python   Strong communication skills with both technical and business teams   Strong SQL   Strong NoSQL   Excellent verbal and written communication   Ability to present and convey rigorous concepts to non-experts   3+ years of experience in at least one company demonstrating both loyalty and leadership  ', ' Health insurance ', ' Daily budget for food orders ', ' Proficiency in Python ', ' Consumer B2C experience ', ' Tech setup ', ' Strong SQL ', ' Excellent ability working with data and developing software application ', '  Competitive Salary Remote   Health insurance   Free parking valet   Relocation bonus   Tech setup   Company retreats   Unlimited vacation days   Vacation travel budget   Daily budget for food orders   Stocked kitchen  ', ' 2+ years of experience working on data science support teams ', ' Excellent verbal and written communication ', ' Company retreats ', ' Competitive Salary Remote ', ' Function as a lead level data scientist ', ' Relocation bonus ', ' Track record of promotion and growth at multiple startups ', ' Unlimited vacation days ', ' Practical consumer ML problem solving skills ', ' 3+ years of experience in at least one company demonstrating both loyalty and leadership ', '  Function as a lead level data scientist   Utilize data driven insights to enhance member experience  ']",Not Applicable,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Python Data Engineer,Eliassen Group,Miami-Fort Lauderdale Area,19 hours ago,54 applicants,"['Knowledgeable in cloud platforms (preferable AWS: both traditional EC2 and serverless Lambda), micro-services architecture, CI/CD solutions (including Docker), DevOps principles, message queue systems, and background task management. ', '5+ years of Python server development using Django, Flask, Bottle or other python frameworks Ability to write unit-tested and maintainable code Expertise working with and building RESTful APIs Knowledgeable in cloud platforms (preferable AWS: both traditional EC2 and serverless Lambda), micro-services architecture, CI/CD solutions (including Docker), DevOps principles, message queue systems, and background task management. Experience with API security frameworks, token management and user access control including OAuth, JWT, etc. Solid foundation and understanding of relational and NoSQL database principles. Ability to work in an Agile /SCRUM environment. ', 'For immediate consideration, email your updated resume to Dan Malta at dmalta@eliassen.com', 'Experience with API security frameworks, token management and user access control including OAuth, JWT, etc. ', 'Python Data Engineer', 'Ability to work in an Agile /SCRUM environment. ', 'Responsiblities:', 'Solid foundation and understanding of relational and NoSQL database principles. ', 'Python Data Engineer ', 'Ability to write unit-tested and maintainable code ', 'Expertise working with and building RESTful APIs ', 'Responsiblities: ', 'Dan Malta', '5+ years of Python server development using Django, Flask, Bottle or other python frameworks ', '\xa0 ', 'dmalta@eliassen.com', ' ']",Mid-Senior level,Contract,Information Technology,Information Services,2020-11-05 11:32:32
"Data Scientist – Remote, Full-time",Toptal,"Thousand Oaks, CA",5 hours ago,Be among the first 25 applicants,"['', ' A keen attention to detail', ' Full-time availability is a strong advantage', ' Project management skills', ' At least 3 years of professional experience in Data Science']",Mid-Senior level,Contract,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Machine Learning Engineer: up to $250,000 base+equity",Apptronic Labs,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', 'Responsibilities:', 'Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher level abstractions for various common AI/ML techniques.', 'Candidates will need to have a BS or MS from top notch CS programs with industry experience. We are looking for machine learning software engineers who have experience building at least one of the following: ML/AI models which are in production New neural network algorithms based on research papers Low level performance optimization of deep learning systems Machine learning platforms', 'Company Description:', 'Job Description:', 'General Requirements:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. They have also previously been founders and early employees at startups. We raised $18 million in Series A from Decibel Ventures and Eric Schmidt. We are looking for talented machine learning software engineers, systems software engineers and research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Machine Learning Engineer,Xoriant US Staffing,"Redmond, WA",23 hours ago,31 applicants,"['', '•\tGood full stack\xa0Web App building experience\xa0', '•\tKnowledge of azure machine learning pipelines or open source ML pipelines like Ml Flow or Kubeflow is a big plus\xa0', '***************No OPT, No CPT*****************', 'We focus on bring in Machine learning to Azure Stack. Our vision is to create a best in class Machine Learning services for Azure Stack and Databox Edge devices that can work in tandem with Azure cloud. Here you will create production level ML models with data preparation , machine learning and then deployment with CI/CD on Azure Stack hub.', '\xa0- Bachelor’s degree or higher in computer science or related technical field', '- 3+ years of software development, preferably developing and running distributed system', 'Job description', 'Machine Learning Engineer with Azure Stack\xa0(Contract)', 'Amardeep Paul', '•\tKnowledge of various Machine Learning frameworks such as TensorFlow, Caffe, Pytorch, etc.', 'Responsibilities', 'Client: Microsoft', 'Cell: 408-713-4388', '•\tExcellent python software development skills', '•\tExpertise with the development tool chain related to Linux/Yocto', 'Desk: 408-550-1286', '\xa0', 'Location: Redmond, WA', 'We are a team to join if you like to work on cutting edge hybrid offering that is industry leading and help make them a reality on the Azure Stack cloud.\xa0', 'amardeep.paul@xoriant.com', 'The world is undergoing a transformation to Cloud Computing and Microsoft is leading the way with Azure Stack. Azure Stack is a unique hybrid cloud that runs on a variety of hardware configurations while maintaining the fidelity of the Azure development experience, thereby bringing the power of Azure to your datacenter.', 'Interview Process/Mode - Zoom or WebEx\xa0', 'Qualifications', 'Duration: 6+ months', '- Knowledge of Azure, Google Compute Platform or Amazon Web Services is a big plus', 'Thanks', '- 3+ years of experience with C# or Python', '•\tSignificant experience writing production quality code', '•\tKnowledge of AI-on-chip and AI Hardware Accelerators(Nvidia TensorRT, ONNXRT, OpenVino, SNPE)', '- 3+ years of experience with C++', '•\tExpertise in creating and deploying containers on Kubernetes\xa0', '- Webservice creation and deployment expertise on clusters']",Mid-Senior level,Contract,Engineering,Staffing and Recruiting,2020-11-05 11:32:32
Data Engineer,TalentPartners,United States,,N/A,"['Nice to have:', 'Experience with version control systems (Git and Bitbucket)', ' Bachelor’s Degree in Computer Science or a related discipline', 'Required Qualifications:', ' Detail-oriented and document all the work', ' Experience with Apache Airflow or Google Composer', ' Nice to have:', ' knowledge of Application Programming Interfaces', ' Experience with Docker containerization', ' Strong proficiency in Python\xa0with an emphasis in building data pipelines', ' 5+ years of applicable engineering experience', ' Experience with Atlassian products Jira and Confluence', ' Ability to work with others from diverse skill-sets and backgrounds', ' Ability to write complex SQL to perform common types of analysis and aggregations\xa0', ' ']",Mid-Senior level,Full-time,Information Technology,Entertainment,2020-11-05 11:32:32
Data Scientist,JM&A Group,"Deerfield Beach, FL",4 hours ago,197 applicants,"['', 'Job Requirements', ' Autonomous, to own projects end-to-end; ability to work on the entire stack without being dependent on other team members ', ' Contribute to the adoption and better understanding across the company of data science best practices and tools and stay up to date regarding new knowledge and developments in this domain ', ' Ingestion and processing (outlier and missing data handling) ', 'Intellectual Curiosity and Critical Thinking', ' Expertise in Python and R ', ' PhD or Masters in Computer Science, Statistics, Computer Science, Math or a related discipline or equivalent skill set', 'Attention to Detail', ' Intellectual Curiosity and Critical Thinking, necessary to analyze a problem from multiple perspectives and examine the interrelationships between data that may appear superficially unrelated ', ' Excellent presentation skills to non-technical Associates communicating complex concepts in terms the audience can understand through understandable language, tables and visualizations ', 'Clear and concise written and oral communication', 'Responsibilities', 'Creativity', ' Experiment tracking for A/B testing and reproducibility, model evaluation, model interpretability, results communication and deployment ', ' Create a collaborative and effective working relationship with functional leaders to understand business problems, identify opportunities / use cases to improve the performance of our businesses ', ' Sampling of the data and conducting experiments ', ' Exploratory data analysis ', ' Feature engineering (weight of evidence, label encoding, label count encoding, target encoding, time-series, polynomial interactions, binning, outlier handling) ', ' Expertise with open source data mining/machine learning/big data programming libraries, models and frameworks (e.g. Pandas, Scikit-Learn, H2O, TSFresh, FeatureTools, MLflow, Shap, Microsoft Interpret, Tensorflow, Statsmodels, Pandas-Profiling, Seaborn, Plotly, Spark, Koalas) ', ' Focus, to design and test a technique over days and weeks, find it doesn’t work, learn from the failure, and try again ', ' Creativity, to invent and try new approaches to solving a problem ', ' Clear and concise written and oral communication, in order to communicate complex quantitative analysis in a clear and precise manner ', ' Data extraction ', ' Deep working experience applying statistics and machine learning techniques to real-world problems and data and deploying models to production ', ' Core skills in Computer Science: Data Structures, Algorithms, Programming Paradigms and Relational Databases ', ' Hands-on experience with SQL and tools to access databases ', 'Focus', ' Sampling of the data and conducting experiments  Data extraction  Ingestion and processing (outlier and missing data handling)  Exploratory data analysis  Feature engineering (weight of evidence, label encoding, label count encoding, target encoding, time-series, polynomial interactions, binning, outlier handling)  Feature selection (forward, backwards, information value)  Hyperparameter optimization of machine learning models  Experiment tracking for A/B testing and reproducibility, model evaluation, model interpretability, results communication and deployment ', 'JM&A Group', ' Working experience with cloud computing services such as AWS, Microsoft Azure or Google Cloud Platform ', ' Intellectual Curiosity and Critical Thinking, necessary to analyze a problem from multiple perspectives and examine the interrelationships between data that may appear superficially unrelated  Autonomous, to own projects end-to-end; ability to work on the entire stack without being dependent on other team members  Focus, to design and test a technique over days and weeks, find it doesn’t work, learn from the failure, and try again  Creativity, to invent and try new approaches to solving a problem  Attention to Detail, in order to maintain rigor and to detect and avoid over-reliance on intuition when examining data  Clear and concise written and oral communication, in order to communicate complex quantitative analysis in a clear and precise manner  Interpersonal skills, necessary to build good working relationships and work as part of a team ', ' Feature selection (forward, backwards, information value) ', ' Hyperparameter optimization of machine learning models ', 'Data Scientist', ' When evaluating the candidate, special attention will be paid to the following competencies: ', ' Core skills in Computer Science: Data Structures, Algorithms, Programming Paradigms and Relational Databases  Deep working experience applying statistics and machine learning techniques to real-world problems and data and deploying models to production  Hands-on experience with SQL and tools to access databases  Expertise in Python and R  Expertise with open source data mining/machine learning/big data programming libraries, models and frameworks (e.g. Pandas, Scikit-Learn, H2O, TSFresh, FeatureTools, MLflow, Shap, Microsoft Interpret, Tensorflow, Statsmodels, Pandas-Profiling, Seaborn, Plotly, Spark, Koalas)  Working experience with cloud computing services such as AWS, Microsoft Azure or Google Cloud Platform  Excellent presentation skills to non-technical Associates communicating complex concepts in terms the audience can understand through understandable language, tables and visualizations  When evaluating the candidate, special attention will be paid to the following competencies: ', 'Job Description', ' Lead / Contribute to the development of actionable solutions. This includes all aspects of the solution development including problem and goal definition, defining a plan for: ', ' Attention to Detail, in order to maintain rigor and to detect and avoid over-reliance on intuition when examining data ', ' Interpersonal skills, necessary to build good working relationships and work as part of a team ', 'Autonomous', ' Create a collaborative and effective working relationship with functional leaders to understand business problems, identify opportunities / use cases to improve the performance of our businesses  Lead / Contribute to the development of actionable solutions. This includes all aspects of the solution development including problem and goal definition, defining a plan for: ', 'Interpersonal skills']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Senior Data Scientist, Machine Learning (Multiple Teams)",DoorDash,"San Francisco, CA",2 hours ago,Be among the first 25 applicants,"['', ' We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies. We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day.  We are learning - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute. We are customer obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility. We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights.  We offer great compensation packages and comprehensive health benefits. ', 'Adaptable, resilient, and able to thrive in ambiguity — things change quickly in our fast-paced startup and you’ll need to be able to keep up!', 'Improve operations research models used in real time vehicle routing in major metropolitan areas', 'Build econometric models for next generation pricing and pay algorithms', 'We are leaders', 'Our Commitment to Diversity and Inclusion', 'We are all DoorDash - The magic of DoorDash is our people, together making our inspiring goals attainable and driving us to greater heights. ', ' 5+ years of industry experience developing inference and optimization models with business impact — more experience preferred Masters or PhD in Statistics, Economics, Mathematics, Physics, Economics, Operations Research, or other quantitative field Deep understanding of at least one of probability, statistics, machine learning, causal inference, prediction, forecasting, optimization Demonstrated coding and programming abilities (Python preferred) ', 'Improve our recommendation, personalization and ranking algorithms (read more about it here)', 'About DoorDash', 'Masters or PhD in Statistics, Economics, Mathematics, Physics, Economics, Operations Research, or other quantitative field', 'Demonstrated coding and programming abilities (Python preferred)', 'We are customer obsessed - Our mission is to grow and empower local economies. We are committed to our customers, merchants, and dashers and believe in connecting people with possibility.', ' High-energy and confident — you’ll do whatever it takes to win You’re an owner — driven, focused, and quick to take ownership of your work Humble — you’re willing to jump in and you’re open to feedback Adaptable, resilient, and able to thrive in ambiguity — things change quickly in our fast-paced startup and you’ll need to be able to keep up! Growth-minded — you’re eager to expand your skill set and excited to carve out your career path in a hyper-growth setting Desire for impact — ready to take on a lot of responsibility and work collaboratively with your team ', 'Growth-minded — you’re eager to expand your skill set and excited to carve out your career path in a hyper-growth setting', 'High-energy and confident — you’ll do whatever it takes to win', 'Qualifications', '5+ years of industry experience developing inference and optimization models with business impact — more experience preferred', 'We are learning - We’re not afraid to dig in and uncover the truth, even if it’s scary or inconvenient. Everyone here is continually learning on the job, no matter if we’ve been in a role for one year or one minute.', 'doers', 'We are customer obsessed', 'We are doers - We believe the only way to predict the future is to build it. Creating solutions that will lead our company and our industry is what we do -- on every project, every day. ', 'We offer great compensation packages and comprehensive health benefits.', 'Humble — you’re willing to jump in and you’re open to feedback', 'We are all DoorDash', 'Why You’ll Love Working at DoorDash', 'Desire for impact — ready to take on a lot of responsibility and work collaboratively with your team', 'We are leaders - Leadership is not limited to our management team. It’s something everyone at DoorDash embraces and embodies.', 'We are ', 'Predict food preparation time for over 50,000 merchant partners', 'About You', 'We are learning', ' Use casual inference to forecast the supply of available dashers as well as incoming delivery demand Improve our recommendation, personalization and ranking algorithms (read more about it here) Build econometric models for next generation pricing and pay algorithms Improve operations research models used in real time vehicle routing in major metropolitan areas Predict food preparation time for over 50,000 merchant partners ', 'Example Projects', 'Deep understanding of at least one of probability, statistics, machine learning, causal inference, prediction, forecasting, optimization', 'Use casual inference to forecast the supply of available dashers as well as incoming delivery demand', 'You’re an owner — driven, focused, and quick to take ownership of your work']",Not Applicable,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Zuora,"Redwood City, CA",9 hours ago,32 applicants,"['', 'OUR TECH STACK: ', 'What You’ll Achieve', 'Curating a shared corporate data model that helps all teams to foster collaboration and communication about customers, products and end-to-end processes', 'Working with the team and with end users to design effective reports and visualizations for a wide variety of use cases', 'THE OPPORTUNITY', ' Complex SQL for data transformation and for analytics Time series analysis for understanding trends Basic statistical analysis, particularly for monitoring data quality ', 'management consulting', ' Computing metrics and KPIs related to corporate finances, internal processes and product usage, to help executives track the state of the business is real time Curating a shared corporate data model that helps all teams to foster collaboration and communication about customers, products and end-to-end processes Working with engineers to implement continuous monitoring and validation of data quality Working with the team and with end users to design effective reports and visualizations for a wide variety of use cases ', 'Complex SQL for data transformation and for analytics', 'About Zuora & Our “zeo” Culture', 'THE TEAM', 'building data products (such as the analytics features of a business application) for external customers', 'Zuora is proud to be an Equal Employment Opportunity employer.', 'Writing design and implementation documentation', 'supporting internal customers as part of a BI or data team', 'OUR VISION: THE WORLD. SUBSCRIBED.', 'performing the role of technical business analyst on a finance, sales, marketing or ""growth"" team', 'Running a transparent, predictable product delivery lifecycle, including planning, testing and release management', ""As a Data And Product Analyst On The Zuora Corporate Data Team, You'll Have The Opportunity To Support Data-driven Decision Making Across The Entire Company, Including"", 'Desirable Previous Experience Includes', 'Time series analysis for understanding trends', 'Basic statistical analysis, particularly for monitoring data quality', ' Working directly with end users in a variety of different roles to understand business requirements and identify appropriate technical solutions Writing design and implementation documentation Running a transparent, predictable product delivery lifecycle, including planning, testing and release management ', 'Computing metrics and KPIs related to corporate finances, internal processes and product usage, to help executives track the state of the business is real time', ' management consulting building data products (such as the analytics features of a business application) for external customers supporting internal customers as part of a BI or data team performing the role of technical business analyst on a finance, sales, marketing or ""growth"" team ', 'What You’ll Need To Be Successful', 'Working with engineers to implement continuous monitoring and validation of data quality', 'Working directly with end users in a variety of different roles to understand business requirements and identify appropriate technical solutions', 'YOUR MISSION: ']",Entry level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"Senior Machine Learning Engineer, Reinforcement Learning, AI@Unity",Unity Technologies,"Orlando, FL",6 hours ago,Be among the first 25 applicants,"['', 'Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.', 'Collaborate with Product Managers and senior engineering leadership to conceptualize, strategize, and develop new products', 'Contribute to planning, design, implementation, testing, operations, and process improvement as a member of a Scrum team', 'Ph.D. in Computer Science, Math or Statistics, Physics, or related equivalent experience', 'Experience with distributed machine learning and model deployment', 'Responsibilities', 'About Unity Technologies', 'Set and achieve goals that stretch what’s possible for reinforcement training via the Simulations', 'Experience as a developer with solid skills in Python', 'Collaborate with other engineers in the team to work on some of the most complex challenges in simulations', ' Collaborate with Product Managers and senior engineering leadership to conceptualize, strategize, and develop new products Set and achieve goals that stretch what’s possible for reinforcement training via the Simulations Collaborate with other engineers in the team to work on some of the most complex challenges in simulations Contribute to planning, design, implementation, testing, operations, and process improvement as a member of a Scrum team Educate enterprise customers on the value proposition of Unity, it’s AI platform and participate in discussions to ensure solutions are designed for success ', ' Knowledge of the cloud-native ecosystem Experience with Docker and Kubernetes Experience with distributed machine learning and model deployment Significant contributions to open-source software Experience with Unity Engine, 3D simulators, game development and graphics Excellent communication skills with the ability to build relationships across the company ', ' Ph.D. in Computer Science, Math or Statistics, Physics, or related equivalent experience Experience as a developer with solid skills in Python Experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch) Published research in Deep Learning or Reinforcement Learning at major conference or journal Eligible for Federal security clearance ', 'Knowledge of the cloud-native ecosystem', 'Requirements', 'Educate enterprise customers on the value proposition of Unity, it’s AI platform and participate in discussions to ensure solutions are designed for success', '#LI#-MH1 #SEN', 'Eligible for Federal security clearance', 'Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.', 'Significant contributions to open-source software', 'Experience with Deep Learning Frameworks (e.g. TensorFlow, PyTorch)', 'Published research in Deep Learning or Reinforcement Learning at major conference or journal', 'Excellent communication skills with the ability to build relationships across the company', 'Experience with Unity Engine, 3D simulators, game development and graphics', 'Experience with Docker and Kubernetes', 'Bonus Points']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist, Growth",Pinterest,"San Francisco, CA",7 hours ago,Be among the first 25 applicants,"['', 'Perform deep dive analyses to understand and optimize the key levers of our growth ecosystems', 'What You’ll Do', 'Design core metrics that serve as the North Stars for team efforts and model tradeoffs across product areas', 'Work with product managers and engineers to design data products and debug A/B experiments', 'Proven ability to apply scientific methods to solve real-world problems', '4+ years of industry experience with proven ability to apply scientific methods to solve real-world problems on web scale data', 'Proficient in SQL/Hive', 'Knowledgeable about the machine learning trade-offs and model evaluation', ' 4+ years of industry experience with proven ability to apply scientific methods to solve real-world problems on web scale data Expert in at least one scripting language(Python/R) Proficient in SQL/Hive Proven ability to apply scientific methods to solve real-world problems Knowledgeable about the machine learning trade-offs and model evaluation Ability to lead initiatives across multiple product areas and communicate findings with leadership and product teams', 'Expert in at least one scripting language(Python/R)', ' Perform deep dive analyses to understand and optimize the key levers of our growth ecosystems Design core metrics that serve as the North Stars for team efforts and model tradeoffs across product areas Apply statistics, modeling and ML to improve the efficiency of systems and relevance algorithms across Growth Initiatives  Work with product managers and engineers to design data products and debug A/B experiments ', 'What We’re Looking For', 'Apply statistics, modeling and ML to improve the efficiency of systems and relevance algorithms across Growth Initiatives ', 'Ability to lead initiatives across multiple product areas and communicate findings with leadership and product teams', 'About Pinterest']",Mid-Senior level,Full-time,Information Technology,Internet,2020-11-05 11:32:32
"Senior Data Scientist, Machine Learning and Research",Crisis Text Line,"New York, NY",7 hours ago,Be among the first 25 applicants,"['', 'Algorithmic Development. Develop, test, deploy, and maintain multilingual automated product features that streamline workflows and help to improve quality and consistency of service using algorithms like supervised machine learning (regression and classification), unsupervised machine learning, and recommender systems. ', 'Communicate. Identify insights which may positively impact the broader mental health space and write white papers to help inform and influence mental health policy on both a national and international scale.', 'Bereavement leave', 'Evaluation. Frequently analyze the results of new platform product features (eg, a recommender system). Clarify what conclusions the team can draw from what may be imperfect data, and maximize team learnings. ', 'Overview:', 'Who you are:', 'What you will be doing:', '12 weeks paid parental leave (available after 6 months of employment)', "" Either (1) a PhD in a quantitative field (e.g. computer science, applied mathematics, statistics, physics) and 1-2 years of professional experience in data science and machine learning or (2) a master's degree in a quantitative field and 3-4 years professional experience in data science and machine learning, or (3) a bachelor's degree in a quantitative field and a minimum of 5 years professional experience in data science and machine learning.  Proficiency in SQL and in at least one of python, R, or scala. Proficiency in cloud computing on AWS and/or GCP with GPUs.  Professional experience developing machine learning models with text data. Deep Learning (e.g. BERT, GPT-2), Regression, Classification, Recommender Systems, and Unsupervised Learning.  Professional experience working with text data using natural language processing and/or computational linguistics.  Experience with statistical modeling techniques like Regression, Time Series, Markov Chains, and Monte Carlo Methods. Academic experience with research and publication processes and/or technical writing skills a plus. "", 'Computational Linguistics and/or Natural Language Processing. Using an extensive corpus of over 150 million text messages with rich and structured metadata, identify strategies that best support texters in crisis in terms of listening, coping mechanisms, de-escalation, and safety planning. Help build validated insights into our volunteer training. ', 'Deliberate, mindful, team-player. You involve stakeholders early, emphasize consistent rigor and a high standard of ethics in your analyses, and document your work so it is both transparent and replicable. ', 'Algorithms', ' Algorithms Algorithmic Development. Develop, test, deploy, and maintain multilingual automated product features that streamline workflows and help to improve quality and consistency of service using algorithms like supervised machine learning (regression and classification), unsupervised machine learning, and recommender systems.  Computational Linguistics and/or Natural Language Processing. Using an extensive corpus of over 150 million text messages with rich and structured metadata, identify strategies that best support texters in crisis in terms of listening, coping mechanisms, de-escalation, and safety planning. Help build validated insights into our volunteer training.  Evaluation. Frequently analyze the results of new platform product features (eg, a recommender system). Clarify what conclusions the team can draw from what may be imperfect data, and maximize team learnings.   Research (here are some publications that have used our data) Statistical Analysis. With your expertise in statistical modeling, work to build research support for training, policy, and product improvements to improve quality of service using techniques like Machine Learning, Regression, Time Series, Markov Chains, Monte Carlo Methods, and A/B testing.  Communicate. Identify insights which may positively impact the broader mental health space and write white papers to help inform and influence mental health policy on both a national and international scale.  Stakeholder engagement: Be a strategic partner and work with stakeholders to connect insights to key decisions that affect the organization and the mental health space in general.  ', 'Impact-oriented. You want to work on meaningful projects that lead to positive impact. You develop analysis and tools with people in mind. ', 'Proficiency in cloud computing on AWS and/or GCP with GPUs. ', 'Stakeholder engagement: Be a strategic partner and work with stakeholders to connect insights to key decisions that affect the organization and the mental health space in general. ', ' 3 weeks paid time off per calendar year, plus the week between Christmas and New Years, federal holidays, your birthday, and others Paid sick and personal leave Medical, dental, and vision benefits for the staff member and family 403B retirement plan (the nonprofit equivalent of a 401K) that matches 3% of your salary 12 weeks paid parental leave (available after 6 months of employment) Professional development stipend Bereavement leave ', 'Independent, self-motivated, and curious. You have a knack for taking vague questions and crystallizing them into impactful projects. You love identifying and solving problems.', ""Either (1) a PhD in a quantitative field (e.g. computer science, applied mathematics, statistics, physics) and 1-2 years of professional experience in data science and machine learning or (2) a master's degree in a quantitative field and 3-4 years professional experience in data science and machine learning, or (3) a bachelor's degree in a quantitative field and a minimum of 5 years professional experience in data science and machine learning. "", 'Proficiency in SQL and in at least one of python, R, or scala.', ' Impact-oriented. You want to work on meaningful projects that lead to positive impact. You develop analysis and tools with people in mind.  Independent, self-motivated, and curious. You have a knack for taking vague questions and crystallizing them into impactful projects. You love identifying and solving problems. Deliberate, mindful, team-player. You involve stakeholders early, emphasize consistent rigor and a high standard of ethics in your analyses, and document your work so it is both transparent and replicable.  ', '403B retirement plan (the nonprofit equivalent of a 401K) that matches 3% of your salary', 'Benefits:', '3 weeks paid time off per calendar year, plus the week between Christmas and New Years, federal holidays, your birthday, and others', 'You have:', 'Professional experience developing machine learning models with text data. Deep Learning (e.g. BERT, GPT-2), Regression, Classification, Recommender Systems, and Unsupervised Learning. ', 'Research (here are some publications that have used our data)', ' Statistical Analysis. With your expertise in statistical modeling, work to build research support for training, policy, and product improvements to improve quality of service using techniques like Machine Learning, Regression, Time Series, Markov Chains, Monte Carlo Methods, and A/B testing.  Communicate. Identify insights which may positively impact the broader mental health space and write white papers to help inform and influence mental health policy on both a national and international scale. ', ' Algorithmic Development. Develop, test, deploy, and maintain multilingual automated product features that streamline workflows and help to improve quality and consistency of service using algorithms like supervised machine learning (regression and classification), unsupervised machine learning, and recommender systems.  Computational Linguistics and/or Natural Language Processing. Using an extensive corpus of over 150 million text messages with rich and structured metadata, identify strategies that best support texters in crisis in terms of listening, coping mechanisms, de-escalation, and safety planning. Help build validated insights into our volunteer training.  Evaluation. Frequently analyze the results of new platform product features (eg, a recommender system). Clarify what conclusions the team can draw from what may be imperfect data, and maximize team learnings.  ', 'Experience with statistical modeling techniques like Regression, Time Series, Markov Chains, and Monte Carlo Methods.', 'Paid sick and personal leave', 'Professional development stipend', 'Medical, dental, and vision benefits for the staff member and family', 'Statistical Analysis. With your expertise in statistical modeling, work to build research support for training, policy, and product improvements to improve quality of service using techniques like Machine Learning, Regression, Time Series, Markov Chains, Monte Carlo Methods, and A/B testing. ', 'Professional experience working with text data using natural language processing and/or computational linguistics. ', 'Academic experience with research and publication processes and/or technical writing skills a plus.']",Associate,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Data Engineer,Lazarus Naturals,"Portland, OR",10 hours ago,Be among the first 25 applicants,"['', 'Amazon Web Services (AWS) Certified Data Analytics – Specialty', 'Experience in a modern scripting language (e.g., Python) for automation of build tasks', 'Build and maintain tools to automate data modeling (relational and dimensional) and data quality checks.', '3+ years of experience with progressive data modeling, data architecture, data engineering, and/or database administration', 'Design and develop ETL processes for data integration.', ' 3+ years of experience with progressive data modeling, data architecture, data engineering, and/or database administration Experience with data management concepts and activities, including industry best practices for data sourcing, key data elements, data quality (DQ) analysis and management, metadata, and/or Enterprise Data Management (EDM) policy, process, and procedures Experience with participating in all phases of two (or more) ERP implementations Experience with container orchestration technologies (e.g., Docker) Experience working with version control systems (e.g., Bitbucket), build management and CI/CD tools (e.g., Jenkins), and monitoring tools (e.g., App Dynamics) Experience in a modern scripting language (e.g., Python) for automation of build tasks Experience with relational databases and unstructured databases Knowledge of developing standardized data vocabularies across large organizations and multiple business units, data issue identification, analysis, and remediation Experience designing and developing integrations that use common data exchange formats (XML, JSON, CSV) Experience implementing, managing, and/or integrating with Dynamics 365 (NAV and/or Business Central Essentials) Experience with SQL Server Integration Services (SSIS) Experience with SAP Concur SSIS Components Experience with AWS (RDS, Aurora, and S3 specifically) Excellent problem-solving skills Excellent communication skills and interpersonal skills ', 'Experience with relational databases and unstructured databases', 'Experience working with version control systems (e.g., Bitbucket), build management and CI/CD tools (e.g., Jenkins), and monitoring tools (e.g., App Dynamics)', 'Preferred Qualifications', 'Put in place tooling and frameworks to facilitate data governance and shared analysis between internal organizations.', 'Company events', 'Experience implementing, managing, and/or integrating with Salesforce (Sales Cloud, Service Cloud, and/or CPQ modules)', '401K plan', 'Excellent communication skills and interpersonal skills', 'Fully-stocked kitchen', 'Experience with participating in all phases of two (or more) ERP implementations', ' Build and maintain tools to automate data modeling (relational and dimensional) and data quality checks. Lead activities related to data lake and data warehouse development. Put in place tooling and frameworks to facilitate data governance and shared analysis between internal organizations. Design and develop ETL processes for data integration. Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.) Design, create and manage data structures designed for flexibility, scalability and resiliency to support future business needs. Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues. Collaborate on system implementations. Participate in task and project scoping to ensure accurate Sprint planning. Take direction and meeting deadlines in an efficient and timely manner. Communicate progress and blockers effectively with all team members. ', 'Lazarus Naturals is proud to be an equal opportunity employer and is committed to creating a diverse environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.', 'Benefits', 'Experience with networking principles and protocols such as IP subnetting, routing, firewall rules, Virtual Private Cloud, LoadBalancer, Cloud DNS, Cloud CDN, etc.', 'Employee development opportunities', 'Focus on data quality-detect data/analytics quality issues all the way down to root cause, and implement fixes and data audits to prevent/capture such issues.', 'Experience with AWS (RDS, Aurora, and S3 specifically)', 'Experience with ERP implementations and/or integrations (e.g., Infor CloudSuite)', 'Experience with container orchestration technologies (e.g., Docker)', ""A Bachelor's Degree in Data Science, Computer Science, Business Information Systems, or a related field"", 'Comprehensive benefits (medical, vision, and dental insurance)', 'Participate in task and project scoping to ensure accurate Sprint planning.', 'Design, create and manage data structures designed for flexibility, scalability and resiliency to support future business needs.', 'Experience implementing, managing, and/or integrating with Dynamics 365 (NAV and/or Business Central Essentials)', 'Requirements', 'FSA & commuter benefits', 'Excellent problem-solving skills', 'Jitterbit Foundations Certification', 'Experience with SAP Concur SSIS Components', 'Experience designing and developing integrations that use common data exchange formats (XML, JSON, CSV)', 'Experience implementing, managing, and/or integrating with other core financial systems (e.g., QuickBooks)', 'Experience with data management concepts and activities, including industry best practices for data sourcing, key data elements, data quality (DQ) analysis and management, metadata, and/or Enterprise Data Management (EDM) policy, process, and procedures', 'Experience working with eCommerce platforms (e.g., Magento Commerce)', ' Comprehensive benefits (medical, vision, and dental insurance) Employee discount program Fully-stocked kitchen 401K plan FSA & commuter benefits Employee development opportunities Company events ', 'Design, build, and maintain processes and components of a streaming data/ETL pipeline to support real-time analytics (from requirements to data transformation, data modeling, metric definition, reporting, etc.)', 'Employee discount program', "" A Bachelor's Degree in Data Science, Computer Science, Business Information Systems, or a related field Amazon Web Services (AWS) Certified Data Analytics – Specialty Jitterbit Foundations Certification Experience with networking principles and protocols such as IP subnetting, routing, firewall rules, Virtual Private Cloud, LoadBalancer, Cloud DNS, Cloud CDN, etc. Experience with ERP implementations and/or integrations (e.g., Infor CloudSuite) Experience working with eCommerce platforms (e.g., Magento Commerce) Experience implementing, managing, and/or integrating with other core financial systems (e.g., QuickBooks) Experience implementing, managing, and/or integrating with Salesforce (Sales Cloud, Service Cloud, and/or CPQ modules) "", 'Experience with SQL Server Integration Services (SSIS)', 'Take direction and meeting deadlines in an efficient and timely manner.', 'Knowledge of developing standardized data vocabularies across large organizations and multiple business units, data issue identification, analysis, and remediation', 'Collaborate on system implementations.', 'Lead activities related to data lake and data warehouse development.', 'Communicate progress and blockers effectively with all team members.']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Data Engineer,Bradford & Galt,"St Louis, MO",7 hours ago,Be among the first 25 applicants,"['', '• Experience extracting data from machine generated undocumented file formats', '• In-depth knowledge of Python 3.0 programming (5+ years), including pandas, django, and xmletree', '• Experience designing and developing ETL data pipeline', 'Main Purpose:', 'Key Tasks & Responsibilities:', '• Experience designing & developing ETL data pipelines', 'Preferred skills/Experience:', 'Please note that we cannot consider C2C arrangements on this role.  ', '• Experience extracting data from machine generate data', 'Must have skills:', '• Experience with Linux and shell scripting', 'Main Purpose', '• Knowledge of git, Agile and DevOps development techniques', 'This individual will be responsible for data capture, integration, and operationalization of data pipelines for high-throughput, high-value assays which feed our product pipeline. We’re a distributed, diverse team which uses Agile and DevOps development techniques to enable our data pipeline both in cloud and on-premise.', '• Experience with PostgreSQL, Oracle SQL, and/or other relational database technology', '• AWS Cloud experience (AWS is preferred; but will take any cloud experience)', '• Use DevOps and Agile software development techniques to deliver on our mission to provide high-quality, complete, cloud-based datasets', '• Knows DevOps and Agile processes. ', '• 5 years (minimum) Python, version 3 or above', '• Experience building secure REST APIs', 'Bradford & Galt\xa0is an equal opportunity employer. We will not discriminate, and will take affirmative action measures to ensure against discrimination in employment, recruitment, advertisements for employment, compensation, termination, and other conditions of employment, against any employee or job applicant on the basis of race, color, gender, national origin, age, religion, creed, disability, veteran’s status, or sexual orientation.', '• Bachelor’s degree or equivalent ', 'Qualification & Competencies:', ""• Ability to create Rest API's in Python"", '• Work as a member of the Data Engineering team to incorporate data into a centralized asset using cloud and local infrastructure and REST APIs', '• Experience working with AWS serverless architecture', '• Collaborate with stakeholders in the IT group and other teams to achieve broader project goals', '• Experience working in a cloud environment', '• Provides technical contributions in a fast-paced team environment to accelerate our efforts to build an analytics-driven product pipeline', '• Excellent understanding of application development life-cycle']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,The Topps Company,"Orlando, FL",4 hours ago,Be among the first 25 applicants,"['', ' Independence and lack of bureaucracy that clears the way for you to do your best work ', ' Cataloging all data sources ', ' BS/BA in either Computer Science, Statistics, Mathematics or related field required ', ' Integrating Data Warehouse with BI tools such as Looker ', ' Be a resource and advocate for data within the division by teaching and empowering others to use data ', ' At least 1-4 years of experience in a Data/Software Engineering role ', ' Team player ', ' Assisting the data science and analytics teams to produce key data insights and visualizations. ', ' Masters in Computer Science, Statistics, Mathematics, Data Science or related field a plus ', 'Responsibilities', ' Familiarity with Looker (or other similar visualization tools) is highly valued ', ' Interest in building machine learning systems ', ' Collecting data from various sources such as Postgres DBs, Kinesis Firehoses, Internal and External APIs, etc. ', ' Work with the world’s top sports and entertainment properties ', ' Work with a passionate, confident and humble team ', ' Competitive compensation & benefits. We build great teams and take care of them ', 'Options', ' High interest in Big Data processing ', ' Analytical/mathematical mindset ', 'Qualifications', ' Working with engineering groups, as well as product and strategy groups to create and gather data requirements ', ' Topps is looking for a Data Engineer to work in an agile DataOps environment. ', ' BS/BA in either Computer Science, Statistics, Mathematics or related field required  Masters in Computer Science, Statistics, Mathematics, Data Science or related field a plus  At least 1-4 years of experience in a Data/Software Engineering role  Code proficiency in at least one of the following languages: Scala, Python ', ' High interest in Big Data processing  Experience on AWS is a preferred  Experience with Test Driven Development is a plus ', ' Building, maintaining and optimizing data pipelines written in Python and Scala using Spark ', ' Work with the world’s top sports and entertainment properties  Work with a passionate, confident and humble team  Fun office atmosphere ', ' Familiarity with Spark/Databricks is highly valued ', ' Recognize and adopt best practices in reporting and analysis this includes data integrity, testing, maintainability, validation and documentation ', ' Good communication skills ', 'Overview', ' Code proficiency in at least one of the following languages: Scala, Python ', ' Familiarity with Mongo/Postgres is a plus ', ' Experience with Test Driven Development is a plus ', ' Experience on AWS is a preferred ', ' Familiarity with Spark/Databricks is highly valued  Familiarity with Looker (or other similar visualization tools) is highly valued  Familiarity with Mongo/Postgres is a plus  Interest in building machine learning systems  Analytical/mathematical mindset  Good communication skills  Intellectual curiosity. Passion for learning and exploring  Team player ', ' Independence and lack of bureaucracy that clears the way for you to do your best work  Competitive compensation & benefits. We build great teams and take care of them ', ' Intellectual curiosity. Passion for learning and exploring ', ' Building, maintaining and optimizing data pipelines written in Python and Scala using Spark  Working with engineering groups, as well as product and strategy groups to create and gather data requirements  Integrating Data Warehouse with BI tools such as Looker  Recognize and adopt best practices in reporting and analysis this includes data integrity, testing, maintainability, validation and documentation  Be a resource and advocate for data within the division by teaching and empowering others to use data  Cataloging all data sources  Collecting data from various sources such as Postgres DBs, Kinesis Firehoses, Internal and External APIs, etc.  Assisting the data science and analytics teams to produce key data insights and visualizations. ', ' Fun office atmosphere ', 'Why You Will Love It Here']",Entry level,Full-time,Information Technology,Sports,2020-11-05 11:32:32
"Scientist I, Data Management",Foundation Medicine,"Cambridge, MA",6 hours ago,54 applicants,"['', ' Strong programming and computing skills; fluency in one or several scripting languages (Python, Perl), SQL and/or programming language (R, SAS)', ' Perform query on database using SQL or other tools. Mitigate potential data management issues by reviewing protocols for cross-project consistency. Integrate data from multiple data sources for a given project, which may involve merging, reformatting of datasets and deriving new variables. Ensure the quality of data by identifying data errors or inconsistencies and work with appropriate personnel to resolve them. Perform data integration and transformation and deliver data tables based on data specifications. Manage current and historical data/results to build a knowledge base and ensure completeness and searchability. Ensure that all datasets, programs, and documentation are stored in appropriate locations under appropriate names for easy reference. Maintain high-level oversight on data quality metrics and DM deliverables. Perform ad-hoc data management and data analysis tasks. Collaborate with laboratory scientists, biostatisticians, technologists and regulatory affairs team on study design, planning, data preparation, programming, analysis and presentation of results. Other duties as assigned.', ' Technical proficiency and creativity', ' Demonstrated ability of meeting project deadlines', ' 2+ years of relevant working experience (academic or industry)', ' Knowledge and experience with Next-Generation Sequencing (NGS)', 'Preferred Qualifications', ' Fluency in one or several computing software for data programming', 'Basic Qualifications', ' Ensure the quality of data by identifying data errors or inconsistencies and work with appropriate personnel to resolve them.', ' Other duties as assigned.', ' Scientific understanding of cancer genetics and genomics', ' Perform data integration and transformation and deliver data tables based on data specifications.', ' Maintain high-level oversight on data quality metrics and DM deliverables.', ' Experience with Linux operating system', ' Master’s degree in bioinformatics, computer science, biostatistics, information systems or equivalent Fluency in one or several computing software for data programming', ' Integrate data from multiple data sources for a given project, which may involve merging, reformatting of datasets and deriving new variables.', 'Qualifications', 'About The Job', ' Mitigate potential data management issues by reviewing protocols for cross-project consistency.', ' Master’s degree in bioinformatics, computer science, biostatistics, information systems or equivalent', ' Demonstrated record of successful independent work and contributions to team projects', ' Collaborate with laboratory scientists, biostatisticians, technologists and regulatory affairs team on study design, planning, data preparation, programming, analysis and presentation of results.', ' Perform query on database using SQL or other tools.', ' Strong interpersonal skills that include excellent skills in written communication, oral communication, collaboration, and problem solving with other departments and colleagues', ' Commitment to FMI values: patients, innovation, collaboration, and passion', ' Ensure that all datasets, programs, and documentation are stored in appropriate locations under appropriate names for easy reference.', ' Manage current and historical data/results to build a knowledge base and ensure completeness and searchability.', 'Key Responsibilities', ' Experience in a programming role supporting clinical trial studies, biomarker studies in the biopharmaceutical/diagnostics/CRO industry', ' High level of detail orientation with a focus on quality', ' 2+ years of relevant working experience (academic or industry) Experience in a programming role supporting clinical trial studies, biomarker studies in the biopharmaceutical/diagnostics/CRO industry Experience with Linux operating system Strong programming and computing skills; fluency in one or several scripting languages (Python, Perl), SQL and/or programming language (R, SAS) Knowledge and experience with Next-Generation Sequencing (NGS) Demonstrated ability of meeting project deadlines Demonstrated record of successful independent work and contributions to team projects Excellent communication, presentations and writing skills, and the ability to explain complex technical details in clear language Scientific understanding of cancer genetics and genomics Technical proficiency and creativity Strong interpersonal skills that include excellent skills in written communication, oral communication, collaboration, and problem solving with other departments and colleagues High level of detail orientation with a focus on quality Understanding of HIPAA and importance of privacy of patient data Commitment to FMI values: patients, innovation, collaboration, and passion', ' Understanding of HIPAA and importance of privacy of patient data', ' Perform ad-hoc data management and data analysis tasks.', ' Excellent communication, presentations and writing skills, and the ability to explain complex technical details in clear language']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,CGI,"Cleveland, OH",10 hours ago,Be among the first 25 applicants,"['', ' 5+ years of professional experience in: software development and/or data engineering; and in working with relational databases including Oracle, Teradata, MySQL.', ' In-depth knowledge of streaming technologies like Kafka and Spark Streaming', ' 4+ years of experience working with Big Data tools and frameworks like Hadoop, Spark, Map Reduce, Avro, Hive and Impala', 'Desired Qualifications/Non-essential Skills Required', ' Experience with the BI/DW lifecycle components including Source Data Analysis, ETL, ODS, Data Marts, Data Mining.', 'Required Qualifications To Be Successful In This Role', ' Expert in Requirement documentation and articulating them with design, development and testing team', ' Agile experience is required with Version One tool expertise', ' Strong experience in reporting tools like Tableau, COGNOS etc.', ' Oracle ', ' Programming experience in Scala, Python, shell scripting and automation', ' Strong analytical abilities.', ' Expert in writing, BRD, FSD, Use Cases and modelling techniques', ' Oracle  SQL', 'Build your career with us.', 'Job Description', ' Experience with modern workflow/orchestration tools (e.g. Apache Airflow, Oozie, etc.)', 'Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned', 'Skills', ' Excellent communication and thought leadership skills', ' Proficiency in multiple modern programming languages SQL, Linux, Java.', ' SQL', ' Excellent interpersonal skills including the ability to work with diverse personality types and understand technical issues.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Analyst I,Resiliency LLC,"Chicago, IL",22 hours ago,29 applicants,"['Works under limited supervision once the project is outlined.', 'Must be proficient in Microsoft Word and Excel and general office applications.', 'Role focuses on data entry and labeling.', 'Makes decisions but may not have final authority for all aspects of resource commitment.', 'Receives objectives and determines approach to achieving objectives.', ""Must be proficient in Microsoft Word and Excel and general office applications. Role focuses on data entry and labeling. Be able to solve problems where analysis of data requires a review and analysis. May lead the implementation of tactical plans in support of strategic initiatives. Receives objectives and determines approach to achieving objectives. Makes decisions but may not have final authority for all aspects of resource commitment. Works under limited supervision once the project is outlined. Accountable for the achievement of operational goals in at least one department or work area. Integrates customer/client needs and concerns with business issues. Serves as a liaison on specific projects with other work areas. Bachelor's degree or equivalent education and relevant experience. 1-2 years of experience"", 'Integrates customer/client needs and concerns with business issues.', 'Accountable for the achievement of operational goals in at least one department or work area.', 'Be able to solve problems where analysis of data requires a review and analysis.', '1-2 years of experience', ""Bachelor's degree or equivalent education and relevant experience."", 'May lead the implementation of tactical plans in support of strategic initiatives.', 'Serves as a liaison on specific projects with other work areas.']",Mid-Senior level,Contract,Analyst,Computer Software,2020-11-05 11:32:32
Data Scientist,ADVANTIS Global Inc.,"Menlo Park, CA",5 hours ago,Over 200 applicants,"['', 'KEY SUCCESS FACTORS', 'Experience with SQL', 'Experience with distributed computing (Hive/Hadoop)', 'Experience manipulating data sets through statistical software (e.g. R, SAS) or other methods', ' Product Leadership: influencing product teams through presentation of data-based recommendations, communicating state of business, experiment results, etc. to product teams, spreading best practices to analytics and product teams.', ' 4+ professional years doing quantitative analysis within a large-scale company or fast paced environment. Development experience in any scripting language (Python, Perl etc)  Experience with SQL Experience communicating the results of analyses with product and leadership teams to influence the strategy of the product Experience manipulating data sets through statistical software (e.g. R, SAS) or other methods ', '4+ professional years', '(Hive/Hadoop)', 'Bonus Skills', 'Experience working within the tech sector preferred', ' Exploratory Analysis: proposing what to build in the next roadmap, understanding ecosystems, user behaviors, and long-term trends, identifying new levers to help move key metrics, building models of user behaviors for analysis or to power production systems.', 'SQL', 'THE OPPORTUNITY FOR YOU', 'Python', 'About This Opportunity', '4+ professional years doing quantitative analysis within a large-scale company or fast paced environment.', 'Experience communicating the results of analyses with product and leadership teams to influence the strategy of the product', 'Development experience in any scripting language (Python, Perl etc) ', ' Data Infrastructure: working in Hadoop and Hive primarily, sometimes MySQL, Oracle, and Vertica, automating analyses and authoring pipelines via SQL and Python based ETL framework', ' Experience with distributed computing (Hive/Hadoop) ', ' Product Operation: forecasting and setting product team goals, designing and evaluating experiments, monitoring key product metrics, understanding root causes of changes in metrics, building and analyzing dashboards and reports, building key data sets to empower operational and exploratory analysis, evaluating and defining metrics.', ' Experience working within the tech sector preferred']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Confluent Health,"Evansville, IN",11 hours ago,Be among the first 25 applicants,"['', 'Big Data Application Development & Support. Big Data Visualization & Reporting. Big Data Systems Planning & Management. Cloud PaaS , iPaaS and Integrating Systems. R language, Python. SSIS, Informatica experience.', ' Technical Strategy: Works with IT & Corporate Analytics to construct & refine custom / special purpose analytic datasets in a “big data” or other specialized data storage environments. Participate in big data quality assurance functions throughout the lifecycle to ensure customer satisfaction and requirements are met. Understand the infrastructure and architecture of the big data environment to troubleshoot issues and problems. Gather requirements for new data pipeline requests from the business and translate these requests into technical data requirements. Extract, clean, and manage large data sets. Advanced Analytics: Employs specialized advanced analytic tools & techniques to uncover valuable & quantifiable business insights. Communicates & interprets results, provides implications and recommendations at all levels of the organization (C-level to field staff) as appropriate. Assists in determining whether & how insights should be deployed / operationalized beyond the “data science” initial research & analysis.  Operational Execution: Supports IT & Corporate Analytics as subject matter expert to design, architect, develop, and deploy analytics solutions into operational environments or ad-hoc applications as appropriate. Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation. Value Analysis: Works closely with Manager of Corporate Analytics (and others as appropriate) to support business case development and post-project benefits realization analysis.  Domain Expertise: Attends training, conference, and data science networking events to continually develop self and keep current on advanced analytics use cases, technologies, and methods. Keeps Corporate Analytics and IT departments abreast of related innovations and recommends appropriate resources & investments accordingly.  ', 'General understanding and knowledge of the following: Azure Environment knowledge, SQL Skills, Python Programming, REST/SOAP API, and BI experience.', 'Essential Functions', 'Domain Expertise: Attends training, conference, and data science networking events to continually develop self and keep current on advanced analytics use cases, technologies, and methods. Keeps Corporate Analytics and IT departments abreast of related innovations and recommends appropriate resources & investments accordingly. ', 'Bachelor’s Degree or equivalent experience required', 'Master’s Degree in Information Technology preferred', ' Must possess the ability to communicate effectively with all levels of management, employees and outside contacts. Possess the ability to make independent decisions when circumstances warrant such action. Possess the ability to seek out new methods and principles and be willing to incorporate them into existing practices. Sound problem solving, decision making and policy interpretation skills. Must be able to come up with creative solutions keeping in mind legal and financial constraints Ability to remain calm in stressful situations ', 'Possess the ability to seek out new methods and principles and be willing to incorporate them into existing practices.', 'Ability to remain calm in stressful situations', 'Benefits', 'Operational Execution: Supports IT & Corporate Analytics as subject matter expert to design, architect, develop, and deploy analytics solutions into operational environments or ad-hoc applications as appropriate. Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.', '4+ years of experience in software development life cycle concepts and demonstrated execution.', 'Sound problem solving, decision making and policy interpretation skills. Must be able to come up with creative solutions keeping in mind legal and financial constraints', ' Big Data Application Development & Support. Big Data Visualization & Reporting. Big Data Systems Planning & Management. Cloud PaaS , iPaaS and Integrating Systems. R language, Python. SSIS, Informatica experience. Bachelor’s Degree or equivalent experience required Master’s Degree in Information Technology preferred 4+ years of experience in business, industrial, or energy/utilities setting. 4+ years of experience in software development life cycle concepts and demonstrated execution. Experience working with teams on large technical implementations. Experience in utility strategy and industry research a plus. Demonstrated ability to accept assignments, escalate issues and achieve on-time delivery of assigned work. Programming language certifications. General understanding and knowledge of the following: Azure Environment knowledge, SQL Skills, Python Programming, REST/SOAP API, and BI experience. ', 'Qualifications/Skills', ' of related innovations and recommends appropriate resources & investments accordingly. ', 'Experience working with teams on large technical implementations. Experience in utility strategy and industry research a plus. Demonstrated ability to accept assignments, escalate issues and achieve on-time delivery of assigned work. Programming language certifications.', 'Value Analysis: Works closely with Manager of Corporate Analytics (and others as appropriate) to support business case development and post-project benefits realization analysis. ', 'Technical Strategy: Works with IT & Corporate Analytics to construct & refine custom / special purpose analytic datasets in a “big data” or other specialized data storage environments. Participate in big data quality assurance functions throughout the lifecycle to ensure customer satisfaction and requirements are met. Understand the infrastructure and architecture of the big data environment to troubleshoot issues and problems. Gather requirements for new data pipeline requests from the business and translate these requests into technical data requirements. Extract, clean, and manage large data sets.', 'Advanced Analytics: Employs specialized advanced analytic tools & techniques to uncover valuable & quantifiable business insights. Communicates & interprets results, provides implications and recommendations at all levels of the organization (C-level to field staff) as appropriate. Assists in determining whether & how insights should be deployed / operationalized beyond the “data science” initial research & analysis. ', 'Possess the ability to make independent decisions when circumstances warrant such action.', 'Non-Essential Functions', '4+ years of experience in business, industrial, or energy/utilities setting.', 'Must possess the ability to communicate effectively with all levels of management, employees and outside contacts.']",Entry level,Full-time,Information Technology,Hospital & Health Care,2020-11-05 11:32:32
"Senior Data Scientist / Biostatistician, Real-world Data and Cancer Risk Modeling",Freenome,"South San Francisco, CA",12 hours ago,Be among the first 25 applicants,"['', 'Cancer-specific knowledge: biology, therapeutic approaches, and/or epidemiology.', ""Lead the development of statistical risk models for cancer, based on clinical covariates and other data included in EMRs, claims databases, and other real-world sources by leveraging a comprehensive understanding of clinical risk factors for colorectal and other cancers.\xa0Be the in-house expert in this field. Demonstrate strong command of relevant biostatistical, epidemiology, and ML literature. Select and apply best-in-class methodologies, making well-supported modifications or additions to improve performance.Pursue research on methods and applications while also prioritizing the transition to production use.Partner with R&D, Medical Affairs, and Commercial teams to align model performance characteristics with those most likely to be impactful for patient health care.Partner with computational biology and ML scientists in developing algorithms for multi-omics data, to maximize performance for both clinical-only and integrated clinical/molecular classifiers.Partner with data teams from external payer and provider organizations to develop and implement unique approaches to leveraging real-world data for risk assessment and improved patient screening and early cancer detection.Present novel scientific results at conferences and in peer-reviewed scientific journals (when consistent with Freenome’s or external partners' trade secret, intellectual property, and product development strategies).Guide strategy and champion the execution of our intellectual property portfolio, publications, external partnerships, and product development plans.Provide scientific and technical guidance to team members and collaborators, while also empowering and inspiring them to do their best work.\xa0Take a mindful, transparent, and humane approach to your work."", 'Guide strategy and champion the execution of our intellectual property portfolio, publications, external partnerships, and product development plans.', 'Lead the development of statistical risk models for cancer, based on clinical covariates and other data included in EMRs, claims databases, and other real-world sources by leveraging a comprehensive understanding of clinical risk factors for colorectal and other cancers.\xa0', ""Present novel scientific results at conferences and in peer-reviewed scientific journals (when consistent with Freenome’s or external partners' trade secret, intellectual property, and product development strategies)."", 'Outstanding proficiency in the implementation of complex statistical or ML models in a general-purpose programming language.', 'Be the in-house expert in this field. Demonstrate strong command of relevant biostatistical, epidemiology, and ML literature. Select and apply best-in-class methodologies, making well-supported modifications or additions to improve performance.', 'Familiarity working in a Linux environment and with cloud computing infrastructure.', 'Senior Data Scientist / Biostatistician, Real-world Data and Cancer Risk Modeling', '\xa0', 'Take a mindful, transparent, and humane approach to your work.', 'In this role, you will work closely with Freenome’s biostatistics, machine learning (ML), computational biology, and data science teams, as well as with our product management, clinical informatics, and medical affairs teams. You will also work with partners in the major health care provider and payer organizations with which Freenome collaborates, to access unique and comprehensive cohorts of real-world data. You will use these data, complemented by the extensive collections from Freenome’s prospective clinical studies, to develop robust risk models.', 'Partner with data teams from external payer and provider organizations to develop and implement unique approaches to leveraging real-world data for risk assessment and improved patient screening and early cancer detection.', 'PhD or equivalent research experience in a relevant quantitative field such as statistics, biostatistics, epidemiology, bioinformatics, or computer science (with an applied ML emphasis and a record of demonstrated achievement in a relevant application domain).', 'Provide scientific and technical guidance to team members and collaborators, while also empowering and inspiring them to do their best work.\xa0', 'Excellent ability to communicate to technical peers and also across disciplines, and to work collaboratively on interdisciplinary teams.', 'This Senior Scientist will lead work on one of Freenome’s early cancer detection strategic pillars: the use of real-world data to identify patients at high risk of developing cancer. In this role, you will be responsible for leading the development of statistical risk models for cancer, based on data included in electronic medical records (EMRs), claims databases, and other real-world data sources. At Freenome, we are taking a holistic approach to detect cancer at the earliest stages by integrating EMR-based risk modeling, our blood-based multi-omic test, and early intervention strategies. This role is essential to this strategy. Impact for patients is maximized by detecting cancer early when curative intervention is most achievable, and Freenome’s holistic strategy brings the potential for early detection to a wider and more diverse set of patients.\xa0', 'How you’ll contribute:', '\ufeff', 'Nice to Haves', 'Solid knowledge in one or more areas of biological or medical research, demonstrating an ability to match technical expertise with relevant domain knowledge.', 'Experience in scientific parallel computing and/or in distributed computing environments like Kubernetes.', 'PhD or equivalent research experience in a relevant quantitative field such as statistics, biostatistics, epidemiology, bioinformatics, or computer science (with an applied ML emphasis and a record of demonstrated achievement in a relevant application domain).4+ years of post-PhD experience in academia or industry, working on problems relevant to this subject matter.Expertise in the successful application of biostatistical, epidemiological, or ML techniques to practical problems in biology or human health, demonstrated by research publications or industry achievements.Solid knowledge in one or more areas of biological or medical research, demonstrating an ability to match technical expertise with relevant domain knowledge.Outstanding proficiency in the implementation of complex statistical or ML models in a general-purpose programming language.Experience working with EMR and/or claims data, with an understanding of the unique nuances of real-world datasets.Excellent ability to communicate to technical peers and also across disciplines, and to work collaboratively on interdisciplinary teams.An entrepreneurial mindset, a passion for innovation, demonstrated initiative in tackling new areas of research, and an ability to carry great ideas forward to practical and impactful implementation.', 'An entrepreneurial mindset, a passion for innovation, demonstrated initiative in tackling new areas of research, and an ability to carry great ideas forward to practical and impactful implementation.', 'Expertise in the successful application of biostatistical, epidemiological, or ML techniques to practical problems in biology or human health, demonstrated by research publications or industry achievements.', 'Experience working with human germline genetics data and genetic correlates of disease or other phenotypes.', 'Partner with R&D, Medical Affairs, and Commercial teams to align model performance characteristics with those most likely to be impactful for patient health care.', 'Partner with computational biology and ML scientists in developing algorithms for multi-omics data, to maximize performance for both clinical-only and integrated clinical/molecular classifiers.', 'Familiarity working in a Linux environment and with cloud computing infrastructure.Cancer-specific knowledge: biology, therapeutic approaches, and/or epidemiology.Experience working with human germline genetics data and genetic correlates of disease or other phenotypes.Experience in scientific parallel computing and/or in distributed computing environments like Kubernetes.', '4+ years of post-PhD experience in academia or industry, working on problems relevant to this subject matter.', 'Pursue research on methods and applications while also prioritizing the transition to production use.', 'What you’ll bring:\xa0', 'Experience working with EMR and/or claims data, with an understanding of the unique nuances of real-world datasets.']",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Sr. Data Scientist,Ntelicor,"Bentonville, AR",23 hours ago,Be among the first 25 applicants,"['', 'Analytical Modeling: Selects the analytical modeling technique most suitable for the structured, complex data and develops custom analytical models. Conducts exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data. Defines and finalizes features based on model responses and introduces new or revised features to enhance the analysis and outcomes. Identifies the dimensions of the experiment, finalizes the design, tests hypotheses, and conducts the experiment. Perform trend and cluster analysis on data to answer practical business problems and provide recommendations and key insights to the business. Mentors and guides junior associates on basic modeling and analytics techniques to solve complex problems.', 'Data Source Identification: Understand the appropriate data set required to develop simple models by developing initial drafts. Supports the', '4 years’ experience using open source frameworks (for example, scikit learn, tensorflow, torch).', 'An individual must be able to successfully perform the essential functions of this position with or without a reasonable accommodation.', 'Model Deployment & Scaling: Supports efforts to ensure that analytical models and techniques used can be deployed into production. Supports evaluation of the analytical model. Supports the scalability and sustainability of analytical models.', 'Successful completion of one or more assessments in Python, Spark, Scala, or R.', 'Essential Functions', 'Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function.', ""6 years' experience in data science, machine learning, optimization models, or related field.Successful completion of one or more assessments in Python, Spark, Scala, or R.4 years’ experience using open source frameworks (for example, scikit learn, tensorflow, torch)."", 'Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues.', 'Code Development & Testing: Writes code to develop the required solution and application features by using the recommended program', 'identification of the most suitable source for data. Maintains awareness of data quality.', ""6 years' experience in data science, machine learning, optimization models, or related field."", 'An individual must be able to successfully perform the essential functions of this position with or without a reasonable accommodation.Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues.Data Source Identification: Understand the appropriate data set required to develop simple models by developing initial drafts. Supports theidentification of the most suitable source for data. Maintains awareness of data quality.Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function.Analytical Modeling: Selects the analytical modeling technique most suitable for the structured, complex data and develops custom analytical models. Conducts exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data. Defines and finalizes features based on model responses and introduces new or revised features to enhance the analysis and outcomes. Identifies the dimensions of the experiment, finalizes the design, tests hypotheses, and conducts the experiment. Perform trend and cluster analysis on data to answer practical business problems and provide recommendations and key insights to the business. Mentors and guides junior associates on basic modeling and analytics techniques to solve complex problems.Model Deployment & Scaling: Supports efforts to ensure that analytical models and techniques used can be deployed into production. Supports evaluation of the analytical model. Supports the scalability and sustainability of analytical models.Code Development & Testing: Writes code to develop the required solution and application features by using the recommended program', 'Required Skills']",Mid-Senior level,Full-time,Information Technology,Airlines/Aviation,2020-11-05 11:32:32
Data Scientist,"DynPro, Inc.","Palo Alto, CA",32 minutes ago,Over 200 applicants,"['', 'Build and train production grade ML models on large-scale datasets to solve various business use cases for Commercial Banking.', 'Duration: 6 Months This is a 6-month contract with excellent potential for long term extension or contract to hire', 'Advanced Degree in field of Computer Science, Data Science or equivalent discipline.', 'You will collaborate to develop large-scale data modeling experiments, evaluating against strong baselines, and extracting key statistical insights and/or cause and effect relations.', 'Build both batch and real-time model prediction pipelines with existing application and front-end integrations.', 'Ability to build ML models across Public and Private clouds including container-based Kubernetes environments.', 'Use Deep Learning models like CNN, RNN and NLP (BERT) for solving various business use cases like name entity resolution, forecasting and anomaly detection.', 'Data Scientist/Machine Learning Engineer - Role Responsibilities:', '\xa0', 'Build and train production grade ML models on large-scale datasets to solve various business use cases for Commercial Banking.Use large scale data processing frameworks such as Spark, AWS EMR for feature engineering and be proficient across various data both structured and un-structured.Use Deep Learning models like CNN, RNN and NLP (BERT) for solving various business use cases like name entity resolution, forecasting and anomaly detection.Ability to build ML models across Public and Private clouds including container-based Kubernetes environments.Develop end-to-end ML pipelines necessary to transform existing applications and business processes into true AI systems.Build both batch and real-time model prediction pipelines with existing application and front-end integrations.You will collaborate to develop large-scale data modeling experiments, evaluating against strong baselines, and extracting key statistical insights and/or cause and effect relations.', 'Data Scientist/Machine Learning Engineer - Required Skills/Experience:', 'Use large scale data processing frameworks such as Spark, AWS EMR for feature engineering and be proficient across various data both structured and un-structured.', 'The ideal candidate will have a strong knowledge of ML, NLP, Deep Learning, Knowledge Graphs and have experience working with massive amounts of data. They should also have strong software engineering skills and the ability to build systems that reach enterprise-level scale.', 'Data Scientist/Machine Learning Engineer ', 'Minimum 2-3 years of working experience as a data scientist', 'Experience with machine learning techniques and advanced analytics (e.g. regression, classification, clustering, time series, econometrics, causal inference, mathematical optimization)', 'Advanced Degree in field of Computer Science, Data Science or equivalent discipline.Minimum 2-3 years of working experience as a data scientistExpertise with Python, PySpark, DL frameworks like TensorFlow and MLOps.Experience in designing and building highly scalable distributed ML models in production (Scala, applied machine learning, proficient in statistical methods, algorithms)Experience with analytics (ex: SQL, Presto, Spark, Python, AWS suite)Experience with machine learning techniques and advanced analytics (e.g. regression, classification, clustering, time series, econometrics, causal inference, mathematical optimization)Experience working with end-to-end pipelines using frameworks like KubeFlow, TensorFlow and/or crowd-sourced data labeling a plus.', 'Experience working with end-to-end pipelines using frameworks like KubeFlow, TensorFlow and/or crowd-sourced data labeling a plus.', 'Develop end-to-end ML pipelines necessary to transform existing applications and business processes into true AI systems.', 'Experience in designing and building highly scalable distributed ML models in production (Scala, applied machine learning, proficient in statistical methods, algorithms)', 'Expertise with Python, PySpark, DL frameworks like TensorFlow and MLOps.', 'Location: Palo Alto, CA', 'Experience with analytics (ex: SQL, Presto, Spark, Python, AWS suite)']",Entry level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Principal Machine Learning Engineer (ML) - Financial Services,LEAPROS™ Workforce Solutions,United States,9 hours ago,Be among the first 25 applicants,"['', 'his opportunity\xa0is\xa0a fixed-term consulting engagement with an estimated 12-months in duration and is benefit eligible.\xa0', 'A successful candidate will apply applicable experience to innovate and enhance current client product offerings', 'AREAS OF CONTRIBUTION:', 'CLIENT PARTNER PROFILE AND VALUE PROPOSITION', 'Design, develop, document, test, and debugs applications software and systems', 'his opportunity\xa0is\xa0a fixed-term consulting engagement with an estimated 12-months in duration and is benefit eligible.\xa0(Eligible for REMOTE work in select\xa0states)\xa0', 'Work with proprietary\xa0tools to enhance core platform functionality\xa0', 'Have an interest in increased areas of responsibility\xa0', 'A successful candidate will apply applicable experience to innovate and enhance current client product offeringsApply a highly consultative approach from the perspective of thought leadership, hands-on technical development, and develop\xa0actionable technical specifications\xa0\xa0Work with proprietary\xa0tools to enhance core platform functionality\xa0Maintain high visibility with leadership and cross-functional teamsMaintain high accountability for machine learning engineering/developemnt\xa0Have an interest in increased areas of responsibility\xa0', 'At LEAPROS™, we are committed to our core values and guiding ethical principles, to conducting business in a non-discriminatory manner, and to operating in strict compliance with applicable federal and state laws pertaining to Equal Employment Opportunity. This commitment enhances our ability to conduct business with the highest level of integrity, solidifying our position as the most trusted workforce solutions partner. \xa0', '\xa0', 'Implement ML approaches to business problems for the Backstop platform utilizing techniques such as prediction, optimization, and classification', 'Experience with data preparation, OCR, data classification, and information extraction', 'POSITION SUMMARY:\xa0', 'Demonstrated experience in Microsoft technology stack in complex engineering and solution\xa0development\xa0\xa0', 'Apply a highly consultative approach from the perspective of thought leadership, hands-on technical development, and develop\xa0actionable technical specifications\xa0\xa0', 'ROLE AND RESPONSIBILITIES:', 'Work hands-on and provide overall guidance to a team of SW engineers to implement AI/ML software', 'Willingness to collaborate with offshore development teams during off-hours', 'Deep commitment to solving advanced data problems using Machine Learning\xa0', 'POSITION SUMMARY:\xa0Our client is seeking a fixed-term consultant with a possible extension to make a strong contribution in the role of Principal Machine Learning (ML) Engineer.\xa0for an experienced Machine Learning ""ML"" engineer that has a passion for solving complex automation, classification, and prediction problems. The ideal candidate has previous experience working with data classification, tagging, and information extraction. This role will report to the CTO and start out as a Principal focused on blazing a trail with new technologies and approaches and can grow into a leadership role.\xa0', 'Design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better accuracy and end-user automationImplement ML approaches to business problems for the Backstop platform utilizing techniques such as prediction, optimization, and classificationWork hands-on and provide overall guidance to a team of SW engineers to implement AI/ML softwareDesign, develop, document, test, and debugs applications software and systemsCollaborates with members of the Product team to understand business needs and translate those into technologies and usOther duties as required to meet the needs of the business\xa0', 'Join a growing team of passionate, self-motivated, talented, and creative people with big ideas about the future of data for the investment industry. Over the last few years, our client has\xa0grown considerably, won several awards, and built a lot of great software.\xa0This opportunity\xa0is\xa0a fixed-term consulting engagement with an estimated 12-months in duration and is benefit eligible.\xa0(Eligible for REMOTE work in select\xa0states)\xa0', 'Expertise in Artificial Intelligence and Machine Learning to perform algorithm development and data analysisExperience with data preparation, OCR, data classification, and information extractionExperience with scalable architecture designsExperience with CI/CD on AWSDemonstrated experience in Machine Learning classification, automation, and extractions\xa0Demonstrated experience in Microsoft technology stack in complex engineering and solution\xa0development\xa0\xa0Progressive professional development and increase responsibility in engineering and software development\xa0Deep commitment to solving advanced data problems using Machine Learning\xa0Willingness to collaborate with offshore development teams during off-hours', 'Expertise in Artificial Intelligence and Machine Learning to perform algorithm development and data analysis', 'Maintain high accountability for machine learning engineering/developemnt\xa0', 'Demonstrated experience in Machine Learning classification, automation, and extractions\xa0', 'Other duties as required to meet the needs of the business\xa0', 'Experience with CI/CD on AWS', 'REQUIREMENTS:', 'Design software-systems, applications, and data architectures that directly implement AI techniques to support achieving better accuracy and end-user automation', 'Progressive professional development and increase responsibility in engineering and software development\xa0', 'Experience with scalable architecture designs', 'POSITION TITLE:\xa0\xa0\xa0Principal Machine Learning (ML) Engineer', 'Collaborates with members of the Product team to understand business needs and translate those into technologies and us', 'Maintain high visibility with leadership and cross-functional teams', 'POSITION TITLE:\xa0\xa0']",Executive,Full-time,Information Technology,Financial Services,2020-11-05 11:32:32
Senior Data Scientist,Procter & Gamble,"Cincinnati, OH",9 hours ago,Be among the first 25 applicants,"['', 'High-Performance Parallel and Distributing Computing', 'Unix/Linux', 'Description', 'Strong written and verbal communication skills to influence others to take action', 'Data Management Systems', 'Shown leadership in applying and scaling Analytic techniques to deliver actionable insights from data (in academics or in industry)', 'Data Visualization', 'Shown leadership in applying and scaling Analytic techniques to deliver actionable insights from data (in academics or in industry)Strong written and verbal communication skills to influence others to take actionDemonstrated ability to handle multiple prioritiesGood social skills, self-motivated, dynamic and can-do attitudeStrong enthusiasm and curiosity about the intersection of business and technology(Preferred) Experience in disrupting current business practices in CPG or related industries to help crafting a new go-to-market models.Preferred Experience with Analytical Tools/Applications including:Unix/LinuxScientific Computing: R, Python, C++, Java, Scala,High-Performance Parallel and Distributing ComputingDeep Learning frameworks: Keras, TensorflowData VisualizationData Management SystemsDeep Learning frameworks: TensorFlow, PyTorch Keras', 'Preferred Experience with Analytical Tools/Applications including:', 'Qualifications', 'Good social skills, self-motivated, dynamic and can-do attitude', 'Scientific Computing: R, Python, C++, Java, Scala,', '(Preferred) Experience in disrupting current business practices in CPG or related industries to help crafting a new go-to-market models.', 'Deep Learning frameworks: Keras, Tensorflow', 'Strong enthusiasm and curiosity about the intersection of business and technology', 'Requirements (skills / experiences) for the role:', 'Demonstrated ability to handle multiple priorities', 'Just So You Know', 'Deep Learning frameworks: TensorFlow, PyTorch Keras']",Not Applicable,Full-time,Research,Consumer Goods,2020-11-05 11:32:32
Data Scientist,The Phoenix Group,"Boston, MA",,N/A,"['', 'Troubleshooting quality control anomalies generated by automated pipelines.', 'Ability to work independently and as a member of a team of software developers, technical project manager, project manager, and post docs.', 'Create and maintain documentation and examples showing researchers how to use the client libraries in R and Python and other tools to assist in scientific analysis.', 'Create and maintain R and Python examples', 'Meet and discuss with researchers to identify analytical challenges and goals.', 'Experience developing scientific use cases using phenotypic and genomic data.', 'Excellent verbal and written communication skills.', 'Self-motivated and highly detail-oriented.', 'Basic Qualifications', 'Create and maintain R and Python examplesCreate and maintain documentation and examples showing researchers how to use the client libraries in R and Python and other tools to assist in scientific analysis.Develop scientific use cases using phenotypic and genomic data types accessed through the  API client libraries in R and PythonCreate useful high level statistics operations that can be implemented by developersCurate data concept paths and hierarchies to be more user friendlyPerforms preliminary analysis of genomic and phenotype data and format for use by other analysts.Troubleshooting quality control anomalies generated by automated pipelines.Propose solutions to optimize the platform to better serve end users.Collaborate with software developers to provide new feature requirements.Contribute to scientific writing and creation of data figures to be included in research publications.Meet and discuss with researchers to identify analytical challenges and goals.', 'Proficiency with R and Python is compulsory.', 'Typical Core Duties', 'Curate data concept paths and hierarchies to be more user friendly', 'Experience using Linux command line utilities to manipulate data.Self-motivated and highly detail-oriented.Excellent verbal and written communication skills.A solution-focused attitude and ability to apply their skills to multiple projects at a time.Ability to work independently and as a member of a team of software developers, technical project manager, project manager, and post docs.', 'Experience using Linux command line utilities to manipulate data.', 'Contribute to scientific writing and creation of data figures to be included in research publications.', 'Minimum Masters Degree in\xa0Bioinformatics, Biomedical Informatics, Genomics, Biostatistics or a related field\xa0and 1 years relevant work experience in a Bioinformatics Analyst or\xa0specific statistical analysis experience using R and Python for\xa0Biomedical research.Proficiency with R and Python is compulsory.Experience developing scientific use cases using phenotypic and genomic data.', 'Additional\xa0Qualifications', 'A solution-focused attitude and ability to apply their skills to multiple projects at a time.', 'Propose solutions to optimize the platform to better serve end users.', 'Create useful high level statistics operations that can be implemented by developers', 'Minimum Masters Degree in\xa0Bioinformatics, Biomedical Informatics, Genomics, Biostatistics or a related field\xa0and 1 years relevant work experience in a Bioinformatics Analyst or\xa0specific statistical analysis experience using R and Python for\xa0Biomedical research.', 'Develop scientific use cases using phenotypic and genomic data types accessed through the  API client libraries in R and Python', 'Collaborate with software developers to provide new feature requirements.', 'Performs preliminary analysis of genomic and phenotype data and format for use by other analysts.']",Mid-Senior level,Full-time,Engineering,Higher Education,2020-11-05 11:32:32
Data Engineer,Rooster Teeth,"Austin, TX",10 hours ago,Be among the first 25 applicants,"['', 'Catered meal on Mondays', 'Kitchen stocked with snacks', 'Assist in QA of data lake/warehouse data', '2+ years experience in a Data Engineer role', ""2+ years experience in a Data Engineer roleProduction experience with AirFlow, Spark, AWS cloud services (EMR, S3, Red Shift)High proficiency in Python and SQLExperience building and optimizing 'big data' pipelines, architectures, and data setsExperience building and optimizing ETL processesB.S. Computer Science, related field, or equivalent professional experience"", 'Create and maintain ETL processes to be used by reporting', 'Production experience with AirFlow, Spark, AWS cloud services (EMR, S3, Red Shift)', 'Create and maintain data pipelines- ', 'Experience building and optimizing ETL processes', ""Experience building and optimizing 'big data' pipelines, architectures, and data sets"", ' About Rooster Teeth ', 'Opportunity for career growth', 'Facilitate external data API integrations', ' Qualifications ', 'Medical, dental, vision, and life insurance', 'Flexible dress code', 'Use What You Need paid time off', 'Coordinate with other engineers to standardize event collection across platforms', 'Medical, dental, vision, and life insuranceUse What You Need paid time off401(k) with a company matchCatered meal on MondaysOpportunity for career growthFlexible dress codeKitchen stocked with snacksPet Friendly', 'B.S. Computer Science, related field, or equivalent professional experience', '401(k) with a company match', 'Pet Friendly', 'High proficiency in Python and SQL', ' Responsibilities ', 'Create and maintain data pipelines- Create and maintain ETL processes to be used by reportingFacilitate external data API integrationsCoordinate with other engineers to standardize event collection across platformsAssist in QA of data lake/warehouse data']",Entry level,Full-time,Information Technology,Online Media,2020-11-05 11:32:32
Senior Data Engineer,Custom Ink,"Fairfax, VA",12 hours ago,Be among the first 25 applicants,"['', 'How You’ll Make a Difference', 'Familiarity with BI tools (Tableau, Crystal Reports, Looker, etc.)', 'Collaborative leader that can assume a high level of ownership for the teams work', 'Ensure end users/business partners have trust in the data and actively promote stakeholder adoption of self-service tools', 'Improvements to the design and implementation of our Data Warehouse that impact performance, reliability, and efficiency', 'Improvements to the design and implementation of our Data Warehouse that impact performance, reliability, and efficiencyMeet project deadlines and requirementsEnsure end users/business partners have trust in the data and actively promote stakeholder adoption of self-service toolsEstablish strong working relationships with Project Managers, Software Engineers, and other key stakeholders', 'Strong skill set in ETL and data modeling', 'Description', 'What You’ll Do', 'Meet project deadlines and requirements', 'Strong written and verbal communication skills', 'Identify gaps and weaknesses in our data stack and continues to drive learning advancements for the team', 'Work with business partners and software engineers to gather, understand, and bridge definitions and requirements', 'Ability to extract and transform data via scripting languages and other tools (e.g. Python, R, Java, etc.)', 'Ability to coach and mentor team members and support team growth and development', 'How You’ll Be Measured', 'Familiarity with AWS Cloud solutions', 'Drive efficiency gains through improved reliability and stakeholder adoption of self-serve tools', 'Drive innovation within Data Engineering by playing a lead role in technology decisions for the future of our data science, analysis, and reporting needsWork with business partners and software engineers to gather, understand, and bridge definitions and requirementsLead the design and development for highly complex and critical data projects with strict timelinesDrive efficiency gains through improved reliability and stakeholder adoption of self-serve toolsLeverage research and previous experience to ensure we’re up to date and continuously exploring Identify gaps and weaknesses in our data stack and continues to drive learning advancements for the teamProvide technical expertise and leadership to Data Engineering team in all phases of work including analysis, design, and development of architecture', 'Minimum of 5+ years data engineering experience with a proven track record for success in a fast paced environmentAbility to extract and transform data via scripting languages and other tools (e.g. Python, R, Java, etc.)Strong skill set in ETL and data modelingExperience working with Apache Airflow and real-time processing frameworksAbility to write, analyze and debug SQL queries in any relational database (MySQL, Oracle, Redshift, etc.)Experience working with API’s to collect and ingest dataAble to negotiate and influence changes outside of the team that continuously shape and drive the Data vision of the companyFamiliarity with AWS Cloud solutionsMachine learning or Predictive Modeling experience is a plusFamiliarity with BI tools (Tableau, Crystal Reports, Looker, etc.)Able to negotiate and influence changes outside of the team that continuously shape and drive the Data vision of the companyCollaborative leader that can assume a high level of ownership for the teams workAbility to coach and mentor team members and support team growth and developmentStrong written and verbal communication skillsExceptional problem solving and analytical skills', 'Machine learning or Predictive Modeling experience is a plus', 'What We’re Looking For', 'Drive innovation within Data Engineering by playing a lead role in technology decisions for the future of our data science, analysis, and reporting needs', 'Exceptional problem solving and analytical skills', 'Able to negotiate and influence changes outside of the team that continuously shape and drive the Data vision of the company', 'Experience working with Apache Airflow and real-time processing frameworks', 'Ability to write, analyze and debug SQL queries in any relational database (MySQL, Oracle, Redshift, etc.)', 'Lead the design and development for highly complex and critical data projects with strict timelines', 'Experience working with API’s to collect and ingest data', 'Establish strong working relationships with Project Managers, Software Engineers, and other key stakeholders', 'Minimum of 5+ years data engineering experience with a proven track record for success in a fast paced environment', 'Leverage research and previous experience to ensure we’re up to date and continuously exploring ', 'Provide technical expertise and leadership to Data Engineering team in all phases of work including analysis, design, and development of architecture']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Sr/Principal Data Scientist ,Softworld,"Boston, MA",3 hours ago,Be among the first 25 applicants,"['Senior/Principal Data Scientist', 'Develop and support best data handling and data provenance practices utilizing reproducible, interpretable research approaches', 'Strongly prefer a working knowledge of UNIX operating systems, ideally with experience in high-performance computing environments.', ' THIRD PARTY AGENCIES, SUBCONTRACTORS, AND RECRUITERS NEED NOT APPLY. Applicants received from firms will not be considered. Subcontracting is not available for this position.', 'Ability to work independently on complicated datasets, including all aspects of data analysis (data cleaning, algorithm development, statistical analysis, and documentation).', 'Applying data science methodologies as needed for various projects and data types. Projects will require advanced analytical and statistical methods, such as statistical inference and modern methods for machine learning and AI.', 'EDUCATION, EXPERIENCE AND SKILLS: ', 'Work closely with statisticians to ensure statistical issues in data analysis are addressed as needed.', 'Understanding and effectively working with a wide variety of data sources, such as wearable device data (for example accelerometry and ECG), voice recordings, imaging data, electronic health records or social media postings.', 'Independently represent data science function on global project teams in support of pre-clincial and clinical studies and compound level programs.Play a leadership role in the development and review of the study synopsis, protocol, statistical analysis plan, clinical study report, ensuring accurate and statistically valid deliverables.Perform end-to-end data analyses, from hypotheses formulation, experimental design, writing analysis plans, data cleaning, executing analysis, and preparing reports and documentation.Develop and support best data handling and data provenance practices utilizing reproducible, interpretable research approachesWork closely with statisticians to ensure statistical issues in data analysis are addressed as needed.', 'Identifying and applying state-of-the-art data manipulation and analysis tools, in various programming languages, to develop bespoke analysis pipelines.', 'Expert-level knowledge of data science programming languages (Python and R, or similar) and experience with recommended practices for software development.', 'Significant depth of expertise in at least one field relevant to the job (for example, machine learning, signal processing, etc.) and strong background in both supervised and unsupervised machine learning.', 'Independently represent data science function on global project teams in support of pre-clincial and clinical studies and compound level programs.', ""Education in a relevant field, for example a) PhD in a field such as Biostatistics, Physics, Electrical Engineering, Biomedical Engineering, Computer Science, Applied Mathematics with at least 6 years of experience and a clear interest in data science methods, or b) Master's degree with at least 9 years of relevant experience"", ""Education in a relevant field, for example a) PhD in a field such as Biostatistics, Physics, Electrical Engineering, Biomedical Engineering, Computer Science, Applied Mathematics with at least 6 years of experience and a clear interest in data science methods, or b) Master's degree with at least 9 years of relevant experienceExpert-level knowledge of data science programming languages (Python and R, or similar) and experience with recommended practices for software development.Significant depth of expertise in at least one field relevant to the job (for example, machine learning, signal processing, etc.) and strong background in both supervised and unsupervised machine learning.Ability to work independently on complicated datasets, including all aspects of data analysis (data cleaning, algorithm development, statistical analysis, and documentation).Strongly prefer a working knowledge of UNIX operating systems, ideally with experience in high-performance computing environments."", ' ', 'Independently designing studies, ranging from simple to more complex, and supporting all aspects of projects from data wrangling through to machine learning and statistical analysis', 'Understanding and effectively working with a wide variety of data sources, such as wearable device data (for example accelerometry and ECG), voice recordings, imaging data, electronic health records or social media postings.Applying data science methodologies as needed for various projects and data types. Projects will require advanced analytical and statistical methods, such as statistical inference and modern methods for machine learning and AI.Identifying and applying state-of-the-art data manipulation and analysis tools, in various programming languages, to develop bespoke analysis pipelines.Independently designing studies, ranging from simple to more complex, and supporting all aspects of projects from data wrangling through to machine learning and statistical analysis', 'RESPOINSIBILITIES', 'Play a leadership role in the development and review of the study synopsis, protocol, statistical analysis plan, clinical study report, ensuring accurate and statistically valid deliverables.', 'Perform end-to-end data analyses, from hypotheses formulation, experimental design, writing analysis plans, data cleaning, executing analysis, and preparing reports and documentation.', 'Remote']",Associate,Contract,Consulting,Biotechnology,2020-11-05 11:32:32
Autonomous Driving Data Engineer - AI/ML,CareerAddict,"Roswell, GA",11 hours ago,Be among the first 25 applicants,"['', 'Contribute to the implementation of a secure distributed data access solution for data on-premise and via cloud providers to connect data with service providers and partners', 'Strong communication skills', 'Previous experience with big data applications or Back End software development', 'Work with machine learning experts, testing engineers and software developers to solve challenging development problems', 'Contribute to the architecture and implementation of data ingestion process for transferring and storing large-scale vehicle sensor data', ' Work with a data pipeline for the development and test of ADAS/AD features Enable efficient data (pre-)processing (cloud infrastructure) Contribute to the architecture and implementation of data ingestion process for transferring and storing large-scale vehicle sensor data Help to optimize data storage, search and data processing Contribute to the implementation of a secure distributed data access solution for data on-premise and via cloud providers to connect data with service providers and partners Work with machine learning experts, testing engineers and software developers to solve challenging development problems ', '4+ years of work experience or a PhD in a related field', ' experience building efficient large-scale data collection, storage and processing pipelines Understanding of cyber-security issues and best practices Advanced degrees ', ' BS minimum in the areas of Computer Science/Engineering, Data Engineering or other related fields 4+ years of work experience or a PhD in a related field Knowledge of database systems, big data concepts and cluster computing frameworks (eg Spark, Hadoop, or other tools) Highly skilled in C++, Python, Java or other related programming languages Previous experience with big data applications or Back End software development Experience with machine learning, data engineering, deep learning frameworks and related open-loop testing techniques Strong communication skills ', 'Understanding of cyber-security issues and best practices', 'Advanced degrees', 'Highly skilled in C++, Python, Java or other related programming languages', 'Knowledge of database systems, big data concepts and cluster computing frameworks (eg Spark, Hadoop, or other tools)', 'Experience with machine learning, data engineering, deep learning frameworks and related open-loop testing techniques', 'Work with a data pipeline for the development and test of ADAS/AD features', 'Plus Skills', 'Help to optimize data storage, search and data processing', 'Enable efficient data (pre-)processing (cloud infrastructure)', 'experience building efficient large-scale data collection, storage and processing pipelines', 'BS minimum in the areas of Computer Science/Engineering, Data Engineering or other related fields', 'About Esg Consulting', 'Required Skills.']",Entry level,Full-time,Other,Computer & Network Security,2020-11-05 11:32:32
Data Engineer,Nutanix,"San Jose, CA",5 hours ago,Be among the first 25 applicants,"['', 'Non-Technical/Behavioral Competencies Required', 'Good understanding of computer science concepts such as database systems, graph algorithms, and software performance', 'About Us', 'Should be able to monitor complex system for issues and areas of improvement and be able to troubleshoot and fix issues in a timely manner', 'Possess expert analytical skills, ability to transform business requirements into highly reliable software processes', 'Should have experience of working under stringent deadlines in a Matrix organization structure ', 'Should have proven analytical and problem-solving skills', 'We’re an equal opportunity employer', 'Possess system administration skills with Linux based servers and tools: MySQL or Puppet (or other system configuration system)', 'Should be a quick learner, self-starter, go-getter and a team player', 'Should have very good verbal and written communication, technical articulation, listening and presentation skills', 'Required Experience', 'Be proficient in software development tools: Git, Bezel (or other build system), and Protocol Buffers', 'Fortune 100 Best Companies to Work For® 2020', 'Be proficient in programming languages: Python, Go, SQL, and Bash scripting.', 'Bloomberg’s Top 50 Companies to Watch in 2020', 'Must have the ability to assess accuracy and reliability of incoming data and be meticulous in ensuring accuracy and integrity of data provided to customers', 'Should have ability to work with diverse groups of systems to complete tasks.', '8+ years of experience in implementing and maintaining data transformation pipelines involving multiple data sources', 'Job Description', 'Should have demonstrated effective task prioritization, time management and internal/external stakeholder management skills', 'Should have ability to work with diverse groups of systems to complete tasks.Should have very good verbal and written communication, technical articulation, listening and presentation skillsShould have proven analytical and problem-solving skillsShould have demonstrated effective task prioritization, time management and internal/external stakeholder management skillsShould be a quick learner, self-starter, go-getter and a team playerShould have experience of working under stringent deadlines in a Matrix organization structure ', '#LifeAtNutanix', 'Should be familiar with Data privacy and Cyber security principles', 'About Our Business', 'Should have experience with machine learning concepts and systems', '8+ years of experience in implementing and maintaining data transformation pipelines involving multiple data sourcesPossess expert analytical skills, ability to transform business requirements into highly reliable software processesMust have the ability to assess accuracy and reliability of incoming data and be meticulous in ensuring accuracy and integrity of data provided to customersShould have experience with machine learning concepts and systemsGood understanding of computer science concepts such as database systems, graph algorithms, and software performanceShould be able to monitor complex system for issues and areas of improvement and be able to troubleshoot and fix issues in a timely mannerBe proficient in programming languages: Python, Go, SQL, and Bash scripting.Be proficient in software development tools: Git, Bezel (or other build system), and Protocol BuffersPossess system administration skills with Linux based servers and tools: MySQL or Puppet (or other system configuration system)Should be familiar with Data privacy and Cyber security principles']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Nutanix,"San Jose, CA",5 hours ago,Be among the first 25 applicants,"['', 'Non-Technical/Behavioral Competencies Required', 'Good understanding of computer science concepts such as database systems, graph algorithms, and software performance', 'About Us', 'Should be able to monitor complex system for issues and areas of improvement and be able to troubleshoot and fix issues in a timely manner', 'Possess expert analytical skills, ability to transform business requirements into highly reliable software processes', 'Should have experience of working under stringent deadlines in a Matrix organization structure ', 'Should have proven analytical and problem-solving skills', 'We’re an equal opportunity employer', 'Possess system administration skills with Linux based servers and tools: MySQL or Puppet (or other system configuration system)', 'Should be a quick learner, self-starter, go-getter and a team player', 'Should have very good verbal and written communication, technical articulation, listening and presentation skills', 'Required Experience', 'Be proficient in software development tools: Git, Bezel (or other build system), and Protocol Buffers', 'Fortune 100 Best Companies to Work For® 2020', 'Be proficient in programming languages: Python, Go, SQL, and Bash scripting.', 'Bloomberg’s Top 50 Companies to Watch in 2020', 'Must have the ability to assess accuracy and reliability of incoming data and be meticulous in ensuring accuracy and integrity of data provided to customers', 'Should have ability to work with diverse groups of systems to complete tasks.', '8+ years of experience in implementing and maintaining data transformation pipelines involving multiple data sources', 'Job Description', 'Should have demonstrated effective task prioritization, time management and internal/external stakeholder management skills', 'Should have ability to work with diverse groups of systems to complete tasks.Should have very good verbal and written communication, technical articulation, listening and presentation skillsShould have proven analytical and problem-solving skillsShould have demonstrated effective task prioritization, time management and internal/external stakeholder management skillsShould be a quick learner, self-starter, go-getter and a team playerShould have experience of working under stringent deadlines in a Matrix organization structure ', '#LifeAtNutanix', 'Should be familiar with Data privacy and Cyber security principles', 'About Our Business', 'Should have experience with machine learning concepts and systems', '8+ years of experience in implementing and maintaining data transformation pipelines involving multiple data sourcesPossess expert analytical skills, ability to transform business requirements into highly reliable software processesMust have the ability to assess accuracy and reliability of incoming data and be meticulous in ensuring accuracy and integrity of data provided to customersShould have experience with machine learning concepts and systemsGood understanding of computer science concepts such as database systems, graph algorithms, and software performanceShould be able to monitor complex system for issues and areas of improvement and be able to troubleshoot and fix issues in a timely mannerBe proficient in programming languages: Python, Go, SQL, and Bash scripting.Be proficient in software development tools: Git, Bezel (or other build system), and Protocol BuffersPossess system administration skills with Linux based servers and tools: MySQL or Puppet (or other system configuration system)Should be familiar with Data privacy and Cyber security principles']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,General Dynamics Advanced Information Systems,"Chantilly, VA",4 hours ago,Be among the first 25 applicants,"['', 'Develop technical documentation and standard operating procedures', 'Design, develop, implement and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory)', 'Knowledge Skills And Abilities', 'Working knowledge of entity resolution systemsExperience with messages systems like KafkaExperience with NoSQL and/or graph databases like MongoDB or ArangoDBAny of the following databases: SQL, MongoDB, Oracle, PostgresWorking experience with ETL processingWorking experience with data workflow products like StreamSets or NiFiWorking experience with Python RESTful API services, JDBCExperience with Hadoop and Hive/ImpalaExperience with Cloudera Data Science Workbench is a plusUnderstanding of pySpark Leadership experienceCreative thinkerAbility to multi-taskExcellent use and understanding of data engineering concepts, principles, and theories', 'Develop processes to identify data drift and malformed records', 'Support data science team by designing, developing and implementing scalable ETL process for disparate datasets into a Hadoop infrastructureDesign, develop, implement and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory)Develop processes to identify data drift and malformed recordsDevelop technical documentation and standard operating proceduresLeads technical tasks for small teams or projects', 'Ability to multi-task', 'Leads technical tasks for small teams or projects', 'Experience with messages systems like Kafka', 'Experience with NoSQL and/or graph databases like MongoDB or ArangoDB', 'Excellent use and understanding of data engineering concepts, principles, and theories', 'Creative thinker', 'Support data science team by designing, developing and implementing scalable ETL process for disparate datasets into a Hadoop infrastructure', 'Clearance Requirements', 'Representative Duties And Tasks', 'General Dynamics Mission Systems (GDMS)', 'Working experience with ETL processing', 'Experience with Hadoop and Hive/Impala', 'Understanding of pySpark Leadership experience', 'Working knowledge of entity resolution systems', 'Working experience with Python RESTful API services, JDBC', 'Any of the following databases: SQL, MongoDB, Oracle, Postgres', 'Working experience with data workflow products like StreamSets or NiFi', 'Experience with Cloudera Data Science Workbench is a plus']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Science Specialist,The Bachrach Group,New York City Metropolitan Area,2 hours ago,170 applicants,"['WHAT WE ARE LOOKING FOR:', 'Ability to quickly prototype new ideas and use creative approaches to solve complex problems ', 'The ability to think “out of the box” to combine multiple possibly unrelated solutions to solve a single complex problem. ', 'Demonstrated expertise in working hands-on in analyzing and modeling large data sets. ', 'WHAT WE ARE LOOKING FOR: ', 'Ph.D./MS/BS in Computer Science, Statistics, Math, Finance, or another quantitative field ', '\xa0', 'Experience using SQL on large datasets (or related environments like SAS, Spark, Hadoop, Python, etc.) ', 'You will consult with clients, internal teams, and engineering teams to define, design, and support the implementation of machine learning models into critical business processes, forecast industry trends, and build data pipelines and data solutions to solve those business problems. ', 'You should have a passion for solving complex data-related problems, deriving actionable insight from complex data, working directly with stakeholders to define business problems, and developing informative and interactive data visualizations as well as can speak to data science concepts in approachable ways. ', 'Possess knowledge and experience with metric design, NLP, and categorical and numeric prediction models', 'Possess knowledge and experience with metric design, NLP, and categorical and numeric prediction models ', 'Experience in machine learning for temporal and hierarchical domains (e.g. recurrent neural networks, deep learning). ', 'As a Data Scientist, you will have the opportunity to work on a variety of challenges to uncover trends in content intelligence and discover and surface valuable insights lurking within a massive store of data. ', 'Deep understanding of the mathematical foundations of Machine Learning algorithms. ', '5+ years of hands-on data science experience in building and delivering data models ', 'Ph.D./MS/BS in Computer Science, Statistics, Math, Finance, or another quantitative field 5+ years of hands-on data science experience in building and delivering data models Deep understanding of the mathematical foundations of Machine Learning algorithms. Possess knowledge and experience with metric design, NLP, and categorical and numeric prediction models Experience in machine learning for temporal and hierarchical domains (e.g. recurrent neural networks, deep learning). Experience using SQL on large datasets (or related environments like SAS, Spark, Hadoop, Python, etc.) Demonstrated expertise in working hands-on in analyzing and modeling large data sets. Ability to quickly prototype new ideas and use creative approaches to solve complex problems The ability to think “out of the box” to combine multiple possibly unrelated solutions to solve a single complex problem. ', '5+ years of hands-on data science experience in building and delivering data models', '\xa0 ']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
DATA ENGINEER,The Judge Group,"Irving, TX",5 hours ago,Be among the first 25 applicants,"['', 'Understanding of modern software development and engineering practices', 'This job and many more are available through The Judge Group. Find us on the web at www.judge.com', 'Experience modeling data to be consumed in a BI technology (such as Power BI, Tableau, Excel, Looker, ThoughtSpot, SAP Business Objects)', 'Location: ', 'Contact:', ' Solid knowledge of data modeling, SQL, and optimization techniques', ' Understands and can explain different data storage technologies at a high level, with in depth knowledge and experience in at least one technology (such as Hadoop, SQL Server, Cassandra, Snowflake, Azure Data Lake Gen2)', ' Proactively identify areas for operational improvement in the data delivery space and collaborate with the rest of the data engineering team to achieve those goals', ' 3+ years professional experience in data & analytics/software engineering or 1+ year professional experience and a graduate degree in relevant field', 'Understand modern data warehouse practices', ' During the normal course of work, contribute tests that improve data quality in our Enterprise Data Warehouse', 'Understands different levels of technical ability in business users (data analysts, data scientists, management) and can speak at those levels', ' Collaborate with business data partners to rapidly iterate on new metrics / datasets and promote the results into a governed Enterprise Data Warehouse', 'Description: ', 'Deployed production code in at least 1 programming or scripting language (such as Python, R, Java, C#, PowerShell, bash)']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Quantitative Researcher/Developer,Millennium,"New York, NY",6 hours ago,Over 200 applicants,"['', 'Experience working with exchange tick data', ""2+ years of experience with C++, R, or PythonExperience with low latency trading systems and C++Experience working with exchange tick dataExperience with at least one market: Equities, Futures, FXProven creative solutions and curiosityFamiliarity with kdb+Familiarity with Transaction Cost Analysis methods (TCA)Knowledge of equity microstructureBachelor's or higher degree, ideally on a STEM topic"", 'Produce accurate, performant and maintainable code', 'Familiarity with kdb+', ""Bachelor's or higher degree, ideally on a STEM topic"", 'Knowledge of equity microstructure', 'Show a principled approach towards trading performance optimization', 'Show a principled approach towards trading performance optimizationCritically evaluate existing solutions and apply ideas for improvementBuild research tools with reuse in mindProduce accurate, performant and maintainable code', 'Critically evaluate existing solutions and apply ideas for improvement', 'Familiarity with Transaction Cost Analysis methods (TCA)', 'Qualifications:', '2+ years of experience with C++, R, or Python', 'Proven creative solutions and curiosity', 'Experience with low latency trading systems and C++', 'Experience with at least one market: Equities, Futures, FX', 'Responsibilities', 'Build research tools with reuse in mind']",Not Applicable,Full-time,Finance,Investment Management,2020-11-05 11:32:32
Data Scientist - Digital Manufacturing Services,Rexroth,"Chicago, IL",17 hours ago,Be among the first 25 applicants,"['', 'FIRST Robotics (For Inspiration and Recognition of Science and Technology)', 'Contribute to an appropriate & seamless architecture design from edge to cloud for secure & robust data collection', 'Bachelor or Master of Science Degree in a related technical field such as Computer Science, Mechatronics, Electrical Engineering, or Mechanical Engineering', 'Execute complex data science & data engineering tasks within projects that have a significant impact on Bosch global business', 'Collaborate with research & development teams', 'Preferred Qualifications', 'Good understanding of relational databases, document based databases, and time-series database experience (such as InfluxDB)', 'Execute complex data science & data engineering tasks within projects that have a significant impact on Bosch global businessCollaborate with product development & engineering teams across many Bosch business unitsContribute to the development of efficient big-data pipelines for large scale analyticsCollaborate with research & development teamsSelect & apply appropriate methods such as machine learning & deep learning techniques to large amounts of dataPrepare & present results in front of different teamsContribute to an appropriate cloud architecture design for efficient data analytics implementations from edge to cloudContribute to an appropriate & seamless architecture design from edge to cloud for secure & robust data collection', 'Primary Responsibilities Will Be', 'Basic Qualifications', 'AWIM (A World In Motion)', 'FIRST Robotics (For Inspiration and Recognition of Science and Technology)AWIM (A World In Motion)', 'AWIM', 'FIRST Robotics', 'Prepare & present results in front of different teams', 'Good coding practices', 'Experience with most common ML Frameworks such as Tensorflow and Keras', 'Collaborate with product development & engineering teams across many Bosch business units', 'BOSCH is a proud supporter of STEM (Science, Technology, Engineering & Mathematics) Initiatives', 'Experience with creation and refinement with AI techniques and practices', 'Hands-on experience with Azure and/or AWS Cloud back-end architectures and data management', 'Experience with manufacturing process and equipment a plus', 'Good communication skills', 'Select & apply appropriate methods such as machine learning & deep learning techniques to large amounts of data', 'Experience with rapid prototyping tools such as Node-RED and Grafana a plus', 'Contribute to the development of efficient big-data pipelines for large scale analytics', 'Company Description', 'Contribute to an appropriate cloud architecture design for efficient data analytics implementations from edge to cloud', 'Job Description', '2 years Programming experience with Python and C-like languages. JavaScript experience a plus', 'Bachelor or Master of Science Degree in a related technical field such as Computer Science, Mechatronics, Electrical Engineering, or Mechanical EngineeringExperience with creation and refinement with AI techniques and practices2 years Programming experience with Python and C-like languages. JavaScript experience a plusExperience with most common ML Frameworks such as Tensorflow and Keras', 'Hands-on experience with Azure and/or AWS Cloud back-end architectures and data managementGood understanding of relational databases, document based databases, and time-series database experience (such as InfluxDB)Good communication skillsGood coding practicesExperience with manufacturing process and equipment a plusExperience with rapid prototyping tools such as Node-RED and Grafana a plus']",Associate,Full-time,Engineering,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Data Engineer,Canyon Associates,"Somerset, NJ",,N/A,"['', 'Experience with relational SQL and NoSQL databases: MongoDB, Neo4j, etc', 'Experience with visualization tools: Google Data Studio, Tableau, Qlikview, etc.', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Required:', 'This role will involve planning, design, development and maintenance of our data repositories, pipeline, and analytical solutions. Build and maintain optimal data pipeline architecture', 'Data Engineer - Full time', 'Experience with cloud services: GCP, AWS, etc', 'Experience with relational SQL and NoSQL databases: MongoDB, Neo4j, etcExperience with cloud services: GCP, AWS, etcExperience with object-oriented/object function scripting languages: Python, Java, etc.Experience with big data tools: Hadoop, Spark, Kafka, etc.Experience with Data Flow, Data Pipeline and workflow management tools: Cloud Composer, Airflow, Luigi, etc.Experience with visualization tools: Google Data Studio, Tableau, Qlikview, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, etc.', ' Assemble large, sophisticated data sets that meet functional / non-functional business requirements.', 'Experience with Data Flow, Data Pipeline and workflow management tools: Cloud Composer, Airflow, Luigi, etc.', 'Sponsorship is unavailable']",Not Applicable,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer Co-op,Bose Corporation,"Boston, MA",13 hours ago,Be among the first 25 applicants,"['', 'Strong interpersonal skills, accountability, written and verbal communication skills, time management', 'Data governance domain knowledge and tools (e.g. Collibra)', 'Application integration experience (e.g. RESTful API)', 'To love good music and good sound!', 'Make applications “handshaking”', 'Manage individual data delivery projects (project plan, requirements, technology selection, development, presentation etc)Design and develop ETL workflows to integrate data management processesData Quality root cause analysis, assessment and improvementMake applications “handshaking”Evaluating new technologies', 'Data Quality root cause analysis, assessment and improvement', 'Manage individual data delivery projects (project plan, requirements, technology selection, development, presentation etc)', 'AWS background, information security, middleware and networking understanding', 'Java, JavaScript, Python, Json, Groovy is a big plusTalend, Snowflake, Databricks, PowerBIDatabase development, solid SQL knowledge, Data ModelingAWS background, information security, middleware and networking understandingApplication integration experience (e.g. RESTful API)Ability to analyze complex structured and unstructured dataStrong in gaining knowledge of new technologies across data management disciplinesStrong interpersonal skills, accountability, written and verbal communication skills, time management', 'Strong in gaining knowledge of new technologies across data management disciplines', 'Talend, Snowflake, Databricks, PowerBI', 'Understanding of machine learning, statistics, natural language processing, sentiment analysis', 'Sense of Humor!', 'Good To Have', 'Java, JavaScript, Python, Json, Groovy is a big plus', 'Preferable Skills And Experiences', 'Database development, solid SQL knowledge, Data Modeling', 'Job Description', 'Responsibilities Include', 'Data Catalog Development experience (e.g. Talend)', 'Understanding of machine learning, statistics, natural language processing, sentiment analysisData governance domain knowledge and tools (e.g. Collibra)Data Catalog Development experience (e.g. Talend)Sense of Humor!To love good music and good sound!', 'Design and develop ETL workflows to integrate data management processes', 'Evaluating new technologies', 'Ability to analyze complex structured and unstructured data']",Associate,Full-time,Information Technology,Consumer Electronics,2020-11-05 11:32:32
Data Engineer,Bluehawk Consulting,"Redmond, WA",13 hours ago,Be among the first 25 applicants,"['', ' Storage: SQL, Azure SQL, structured/unstructured data streams (COSMOS), COSMOS DB Azure environments: Azure Data Lakes (ADLs) Gen 1 & 2, ALDs file formats - parquet, blobs, table store Development: SSIS, Scope script, Azure Data Factory, Azure Databricks, JSON, C# ', ' Our diverse team, they make us great! Consultative, client-focused and interactive approaches Innovation, actualizing potential, and “can-do-ness”  Learning, listening and communicating openly with respect Passion, energy, zeal - we have lots of it Humor, lightness, flexibility ', 'Passion, energy, zeal - we have lots of it', 'Consultative, client-focused and interactive approaches', 'Azure environments: Azure Data Lakes (ADLs) Gen 1 & 2, ALDs file formats - parquet, blobs, table store', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'we have lots of it', 'Our Culture', 'can-do-ness” ', 'Storage: SQL, Azure SQL, structured/unstructured data streams (COSMOS), COSMOS DB', 'Understand business requirements and translate into engineering solutions', 'This resource must be a data engineer, not BI or application engineers. We’re', 'Development: SSIS, Scope script, Azure Data Factory, Azure Databricks, JSON, C#', 'Must be able to transform the data to deliver the consumption data models to meet the business requirements', 'Experience with GitHub, VSO, Agile framework, DevOps', 'Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.', 'Innovation, actualizing potential, and “can-do-ness” ', 'Responsibilities', 'BI experience is a plus but not required', 'Proficient in the analysis of data: schemas, processing, correlation; and storage architecture listed in the requirements', 'Education', 'Build the infrastructure required for ETL processing of data based on defined schema using tools and technologies listed in the requirements', 'Knowledge and understanding of compliance best practices - Software Development Lifecycle (SDL) & Data Privacy (GDPR, EGRC)', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'Bellevue, WA', 'Able to build efficient data pipeline architecture and ETLs to ingest the data', 'Required Skills & Experience', ""If this sounds like a place you'd like to learn more about, visit us at "", ' Able to build efficient data pipeline architecture and ETLs to ingest the data Understand business requirements and translate into engineering solutions Transform the data to deliver the consumption data models to meet the business requirements Proficient in the analysis of data: schemas, processing, correlation; and storage architecture listed in the requirements Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for ETL processing of data based on defined schema using tools and technologies listed in the requirements Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs Keep data properly secure, including encryption, managing permission level, handling PII information, etc. Work with data and analytics experts to strive for greater functionality in the data systems ', 'Our diverse team, they make us great!', 'Data Engineer', 'We Value', 'Proficient in the analysis of data: schemas, processing, correlation; and storage architecture Storage: SQL, Azure SQL, structured/unstructured data streams (COSMOS), COSMOS DB Azure environments: Azure Data Lakes (ADLs) Gen 1 & 2, ALDs file formats - parquet, blobs, table store Development: SSIS, Scope script, Azure Data Factory, Azure Databricks, JSON, C#  ', 'Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs', 'Learning, listening and communicating openly with respect', 'Bachelor’s degree required', 'Humor, lightness, flexibility', ' Bachelor’s degree required ', 'they make us great!', 'not looking for a reporting or dashboard person who is a BI engineer', 'Transform the data to deliver the consumption data models to meet the business requirements', 'Work with data and analytics experts to strive for greater functionality in the data systems', 'Must be proficient in data architecture - able to build efficient data pipelines and ETLs to ingest the data', 'Strong analytic skills related to working with structured and unstructured datasets.', ' Must be proficient in data architecture - able to build efficient data pipelines and ETLs to ingest the data Must be able to transform the data to deliver the consumption data models to meet the business requirements Understand business requirements and translate into engineering solutions Proficient in the analysis of data: schemas, processing, correlation; and storage architecture Storage: SQL, Azure SQL, structured/unstructured data streams (COSMOS), COSMOS DB Azure environments: Azure Data Lakes (ADLs) Gen 1 & 2, ALDs file formats - parquet, blobs, table store Development: SSIS, Scope script, Azure Data Factory, Azure Databricks, JSON, C#   Big data, data optimization and presentation Experience with GitHub, VSO, Agile framework, DevOps Knowledge and understanding of compliance best practices - Software Development Lifecycle (SDL) & Data Privacy (GDPR, EGRC) Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with structured and unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management BI experience is a plus but not required ', 'Keep data properly secure, including encryption, managing permission level, handling PII information, etc.', 'Big data, data optimization and presentation', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Morgan Stanley Research - AlphaWise Data Analytics Analyst / Associate,Morgan Stanley,"New York, NY",3 hours ago,Be among the first 25 applicants,"['', 'Posting Date', ' Work with off-shore team members on product development efforts', ' AlphaWise Primary Research team', ' Comfortable working in a large organization with a broad set of stakeholders across various functions (i.e., Business, IT, Operations)', ' Partner with Research teams, quants/data scientists, and technology to create and enhance data sets that provide insights into key investment debates', ' 2-4 years of experience as a data analyst, data scientist, or related quantitative role; experience in banking/financial services preferred', ' Bachelor’s Degree from an accredited higher learning institution (required area of study: Computer Science Mathematics, Statistics, Physics or related engineering degrees)', ' Identify signal in alternative data sets to help forecast key company KPI’s', ' General awareness of data management practices, emerging trends, and issues', 'Technical Qualifications', ' Experience in data quality management', 'Job Level', ' Be aware of common pitfalls with basic ML algorithms (Linear/Logistic Regression) and how to combat these issues', ' Experience in Python and/or R (other modern programming languages such as Perl, JavaScript are a bonus) and statistical packages', ' Experience configuring technical architecture to support data analysis activities', ' Create efficient and reusable code meant for the improvement, manipulation, and analysis of data', ' Analyze proprietary and/or third party data, develop transformation scripts, and remediate quality issues', ' Communicate and collaborate with Morgan Stanley Research teams around idea generation, proof of concept and data analysis / deliverables related to alternative data projects', ' Excellent verbal and written communication skills presenting complex analytical results to technical and non-technical audiences', ' Experience with using data profiling tools to query the data, identify anomalies, gaps and issues', 'Primary Location', ' Create and maintain standards and documentation (mapping, rulebooks, etc.)', ' Ability and desire to work in a start-up paced environment and culture', 'Job', 'Employment Type', ' Experience with using data profiling tools to query the data, identify anomalies, gaps and issues Experience in Python and/or R (other modern programming languages such as Perl, JavaScript are a bonus) and statistical packages Experience configuring technical architecture to support data analysis activities Experience in data quality management Experience in working with data in various forms (data warehouses/SQL, unstructured data environments/PIG,HIVE, Impala) General awareness of data management practices, emerging trends, and issues', ' Strong analytical and reasoning skills; able to decompose complex problems and projects into manageable pieces; comfortable suggesting and presenting solutions', 'Key Responsibilities', ' Partner with Research teams, quants/data scientists, and technology to create and enhance data sets that provide insights into key investment debates Identify signal in alternative data sets to help forecast key company KPI’s Analyze proprietary and/or third party data, develop transformation scripts, and remediate quality issues Communicate and collaborate with Morgan Stanley Research teams around idea generation, proof of concept and data analysis / deliverables related to alternative data projects Create efficient and reusable code meant for the improvement, manipulation, and analysis of data Be aware of common pitfalls with basic ML algorithms (Linear/Logistic Regression) and how to combat these issues Create and maintain standards and documentation (mapping, rulebooks, etc.) Work with off-shore team members on product development efforts Bachelor’s Degree from an accredited higher learning institution (required area of study: Computer Science Mathematics, Statistics, Physics or related engineering degrees) 2-4 years of experience as a data analyst, data scientist, or related quantitative role; experience in banking/financial services preferred Strong analytical and reasoning skills; able to decompose complex problems and projects into manageable pieces; comfortable suggesting and presenting solutions Comfortable working in a large organization with a broad set of stakeholders across various functions (i.e., Business, IT, Operations) Excellent verbal and written communication skills presenting complex analytical results to technical and non-technical audiences Ability and desire to work in a start-up paced environment and culture', ' Experience in working with data in various forms (data warehouses/SQL, unstructured data environments/PIG,HIVE, Impala)']",Not Applicable,Full-time,Research,Financial Services,2020-11-05 11:32:32
Machine Learning Engineer / AD,JD.COM,"Mountain View, CA",8 hours ago,Be among the first 25 applicants,"['', ' MS/Ph.D in computer science or software engineering or equivalent Relevant professional experience (1+ years) in tuning deep learning model, with understanding in deep cross network, and click-through rate prediction preferred Experience with various ads ranking strategies in different scenarios Experience/familiarity with large data and distributed systems Experience/familiarity with one or more of the following languages: pig Latin, Scala, Spark, Python, C++ Experience/familiarity with ML packages such as TensorFlow, Scikit-learn, Caffe, Theano, and PyTorch Experience/familiarity with recommendation system is a big plus Experience with ACM/OI competition is also a big plus ', 'Experience/familiarity with large data and distributed systems', 'Responsibilities:', 'Experience/familiarity with one or more of the following languages: pig Latin, Scala, Spark, Python, C++', 'Experience with ACM/OI competition is also a big plus', 'Work with state-of-the-art deep-learning frameworks such as TensorFlow, Caffe and PyTorch', ' Develop and tuning machine learning algorithms for ads ranking to boost organic business growth Design and develop ads ranking strategies to boost organic business growth Design and develop features for better click-through rate prediction Work closely with application teams to ensure online delivery Work with state-of-the-art deep-learning frameworks such as TensorFlow, Caffe and PyTorch ', 'Design and develop ads ranking strategies to boost organic business growth', 'JD.com is an Equal Opportunity Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.', 'Experience/familiarity with recommendation system is a big plus', 'Design and develop features for better click-through rate prediction', 'Work closely with application teams to ensure online delivery', 'About JD-Business Growth', 'Basic Qualifications：', 'Develop and tuning machine learning algorithms for ads ranking to boost organic business growth', 'Experience/familiarity with ML packages such as TensorFlow, Scikit-learn, Caffe, Theano, and PyTorch', 'MS/Ph.D in computer science or software engineering or equivalent', 'Relevant professional experience (1+ years) in tuning deep learning model, with understanding in deep cross network, and click-through rate prediction preferred', 'Experience with various ads ranking strategies in different scenarios']",Entry level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Lead Data Scientist - AI / Machine Learning,Cedrus Digital,"New York, United States",22 hours ago,Be among the first 25 applicants,"['', 'Researches relevant emerging empirical methods and quantitative tools', 'Leads innovative packaging and presentation of insights to business and broader analytics community', 'As a Lead, Data Scientist, you will…', 'We’d love to hear from people with:', 'Expertise in several Modeling & Machine Learning Techniques (regression, tree models, survival analysis, cluster analysis, forecasting, anomaly detection, association rules, etc.)', 'Expertise in several Modeling & Machine Learning Techniques (regression, tree models, survival analysis, cluster analysis, forecasting, anomaly detection, association rules, etc.)Expertise in several Data ETL (Teradata, Oracle, SQL, Python, Java, Ruby, Pig)Expertise in several Analytic Languages (R, SAS, SPSS, Stata)3 + years of experience in this discipline', 'Expertise in several Data ETL (Teradata, Oracle, SQL, Python, Java, Ruby, Pig)', 'Extracts data from various data sources and performs exploratory data analysis, cleanses, wrangles, and transforms dataEmploys scaling & automation to data preparation techniquesIntroduces incremental improvements to data analysis, visualization, and presentation techniques to communicate discoveriesResearches relevant emerging empirical methods and quantitative toolsLeads innovative packaging and presentation of insights to business and broader analytics communityDevelops processes to automate and scale insights operationalization', 'Introduces incremental improvements to data analysis, visualization, and presentation techniques to communicate discoveries', 'Develops processes to automate and scale insights operationalization', '3 + years of experience in this discipline', 'Employs scaling & automation to data preparation techniques', 'Extracts data from various data sources and performs exploratory data analysis, cleanses, wrangles, and transforms data', 'Expertise in several Analytic Languages (R, SAS, SPSS, Stata)']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Head of Data Science and Innovation,Moody's Corporation,"Charlotte, NC",6 hours ago,69 applicants,"['', ' Strong leadership skills to thrive, lead and influence in an entrepreneurial environment. ', ' Supporting the reporting to MIS’ Senior Leadership Team on the progress of our innovation efforts, appropriate business and technology KPIs, and monitor them on a regular basis. ', 'Experience Level', 'Securities Trading Policy (STP)', ' Must be results-oriented and have a proven ability to get things done through people, including those not under direct management. ', 'Line of Business', ""Working at Moody's"", ' Demonstrated aptitude for collaborating with other functional areas at all levels of the organization ', 'Job Sub Category', ' Minimum bachelor’s degree or equivalent military/work experience; Master’s degree and/or relevant certifications a plus  15+ years building high-performing innovative teams directly or in a matrix environment  15+ years of experience from senior R&D or Product Management positions from leading technology-oriented companies  15+ years of driving innovation in several technology areas throughout career  15+ years working in lean and agile development processes to develop and manage products and people through the product lifecycle starting with innovative concept  Demonstrated experience translating strategy into meaningful deliverables using KPIs to measure and refine outputs  Demonstrated strong knowledge of innovative technical concepts including Machine Learning, AI, Block Chain, etc  Demonstrated experience leading change within an organization and continual challenging of the status quo.  Track record of successful project management, preferably within a financial services or capital markets environment  Ability to build and develop durable relationships across product teams, engineers, marketing, etc. to support research and strategy execution needs.  Demonstrated aptitude for collaborating with other functional areas at all levels of the organization  Excellent written and oral communication skills with an ability to communicate complex concepts to a senior audience.  Strong leadership skills to thrive, lead and influence in an entrepreneurial environment.  Ability to frame choices in a way that is forward looking, to integrate and assimilate complex information and situations and drive decision making  Strong analytical and quantitative skills.  Must be results-oriented and have a proven ability to get things done through people, including those not under direct management. ', ' Demonstrated strong knowledge of innovative technical concepts including Machine Learning, AI, Block Chain, etc ', 'Role/Responsibilities', ' Leading by influence and example, periodically directing the work of others who are part of different lines of business during cross-functional projects. ', ' 15+ years building high-performing innovative teams directly or in a matrix environment ', 'Entity', ' Strong analytical and quantitative skills. ', ' Excellent written and oral communication skills with an ability to communicate complex concepts to a senior audience. ', 'MIS Culture of Excellence', ' Managing innovation best practice processes that enable MIS to fund new ideas within existing LOB’s and ideas in the whitespace. ', 'City', ' Ability to frame choices in a way that is forward looking, to integrate and assimilate complex information and situations and drive decision making ', 'LOB/Department', ' Minimum bachelor’s degree or equivalent military/work experience; Master’s degree and/or relevant certifications a plus ', ' Demonstrated experience translating strategy into meaningful deliverables using KPIs to measure and refine outputs ', ' 15+ years working in lean and agile development processes to develop and manage products and people through the product lifecycle starting with innovative concept ', ' Contributing to the development of ATS’ multi-year strategy and goals. ', 'Qualifications', ' Taking the initiative, work independently, lead cross-functional project teams and produce high-quality work. ', ' Partnering with internal subject matter experts and business owners to discuss potential opportunities, investments, and/or acquisitions. ', ' Leading t he teams supporting our innovation efforts, and MIS’ Data Science Team and coordinating with other data science teams across MCO to create synergies, leverage existing talent, and increase capacity contributing to innovative ideas.  Supporting the reporting to MIS’ Senior Leadership Team on the progress of our innovation efforts, appropriate business and technology KPIs, and monitor them on a regular basis.  Taking the initiative, work independently, lead cross-functional project teams and produce high-quality work.  Leading by influence and example, periodically directing the work of others who are part of different lines of business during cross-functional projects. ', 'EEO Policy', ' Leading t he teams supporting our innovation efforts, and MIS’ Data Science Team and coordinating with other data science teams across MCO to create synergies, leverage existing talent, and increase capacity contributing to innovative ideas. ', 'Regular/Temporary', 'Responsibilities Include', ' Scanning the market, leading external engagements to understand opportunities and potential disruption risk, and meeting with external partners, such as start-ups, accelerators, tech companies, and VC funds to bring new ideas to MIS. ', ' Demonstrated experience leading change within an organization and continual challenging of the status quo. ', ' 15+ years of experience from senior R&D or Product Management positions from leading technology-oriented companies ', ' Implementing Governance process and KPIs for monitoring the new solutions that ATS is sponsoring on a regular basis and providing status updates to all stakeholders. ', ' Presenting clearly, concisely and with confidence while working with a broad cross-section of the organization, including senior executives (President of MIS, MIS SLT and Managing Directors).  Contributing to the development of ATS’ multi-year strategy and goals.  Scanning the market, leading external engagements to understand opportunities and potential disruption risk, and meeting with external partners, such as start-ups, accelerators, tech companies, and VC funds to bring new ideas to MIS.  Partnering with internal subject matter experts and business owners to discuss potential opportunities, investments, and/or acquisitions.  Managing innovation best practice processes that enable MIS to fund new ideas within existing LOB’s and ideas in the whitespace.  Implementing Governance process and KPIs for monitoring the new solutions that ATS is sponsoring on a regular basis and providing status updates to all stakeholders. ', ' Track record of successful project management, preferably within a financial services or capital markets environment ', 'Job Category', 'Job Req ID', ' 15+ years of driving innovation in several technology areas throughout career ', ' Ability to build and develop durable relationships across product teams, engineers, marketing, etc. to support research and strategy execution needs. ', ' Presenting clearly, concisely and with confidence while working with a broad cross-section of the organization, including senior executives (President of MIS, MIS SLT and Managing Directors). ']",Not Applicable,Full-time,Other,Financial Services,2020-11-05 11:32:32
Data Scientist -- Senior,Amobee,"Baltimore, MD",5 hours ago,58 applicants,"['', 'Extreme attention to detail', 'Strong analytical, statistical, and math abilities; Exceptional problem-solving skills', '3+ years of relevant experience', 'Knowledge in at least one deep learning framework ', 'Degree in Operations Research, Computer Science, Mathematics, Statistics, Industrial Engineering, Mechanical Engineering, Physics, or related field; MS/PhD preferred', 'Responsibilities', 'Researching existing state-of-the-art solutions for data driven problems that are similar to the ones Amobee faces and convert them to fit our business needsIdentifying relevant data sources that will help create new data driven products Executing analytical experiments to measure the quality of our products and monitor it over timeCreating detailed reports and analytics for the performance of our data driven solutions Implementing improvements to our existing data driven products ', 'Ability to work as part of a team in a fast-paced environment', 'Executing analytical experiments to measure the quality of our products and monitor it over time', 'Creating detailed reports and analytics for the performance of our data driven solutions ', 'Researching existing state-of-the-art solutions for data driven problems that are similar to the ones Amobee faces and convert them to fit our business needs', 'Qualifications', 'Identifying relevant data sources that will help create new data driven products ', 'Implementing improvements to our existing data driven products ', 'Excellent communication skills', 'Degree in Operations Research, Computer Science, Mathematics, Statistics, Industrial Engineering, Mechanical Engineering, Physics, or related field; MS/PhD preferred3+ years of relevant experienceStrong analytical, statistical, and math abilities; Exceptional problem-solving skillsKnowledge in Python/Java/ClojureKnowledge in at least one deep learning framework Excellent communication skillsExtreme attention to detailAbility to work as part of a team in a fast-paced environment', 'About Amobee', 'Knowledge in Python/Java/Clojure']",Associate,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Machine Learning Engineer Lead,Levi Strauss & Co.,"San Francisco, CA",11 hours ago,Be among the first 25 applicants,"['', 'FULL TIME/PART TIME', ' Utilize your entrepreneurial spirit to identify new opportunities to optimize business processes and improve consumer experiences, and prototype solutions to demonstrate value with a crawl, walk, run mindset.', 'Current LS&Co Employees, apply via your Workday account.', 'Personalized in-session product recommendation engineCustomer SegmentationAutomated text summarization and clusteringNext-Best offer prediction Designing Microassortments for Next-Gen storesAnomaly detection and Root Cause AnalysisUnified consumer profile with probabilistic record linkageVisual search for similar and complementary products', 'University or advanced degree in engineering, computer science, mathematics, or a related field 5+ years experience developing and deploying machine learning systems into production Experince working with a variety of relational SQL and NoSQL databasesExperience working with big data tools: Hadoop, Spark, Kafka , etc. Experience with at least one cloud provider solution (AWS, GCP, Azure)Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala , etc.  Ability to work in a Linux environmentIndustry experience building and productionizing creative end-to-end Machine Learning systemsExperience working with distributed systems, service oriented architectures and designing APIsKnowledge of data pipeline and workflow management toolsExpertise in standard software engineering methodology, e.g. unit testing, test automation, continuous integration, code reviews, design documentationRelevant working experience with Docker and Kubernetes is a big plus', 'Automated text summarization and clustering', 'Architect, build, maintain, and improve new and existing suite of algorithms and their underlying systems.', 'Contribute to and promote good software engineering practices across the team', 'Architect, build, maintain, and improve new and existing suite of algorithms and their underlying systems.Implement end-to-end solutions for batch and real-time algorithms along with requisite tooling around monitoring, logging, automated testing, performance testing and A/B testing Utilize your entrepreneurial spirit to identify new opportunities to optimize business processes and improve consumer experiences, and prototype solutions to demonstrate value with a crawl, walk, run mindset.Work closely with data scientists and analysts to create and deploy new product features on the ecommerce website, in-store portals and the Levi’s mobile appEstablish scalable, efficient, automated processes for data analyses, model development, validation and implementationWrite efficient and well-organized software to ship products in an iterative, continual -release environmentContribute to and promote good software engineering practices across the teamMentor and educate team members to adopt best practices in writing and maintaining production machine learning code Communicate clearly and effectively to technical and non-technical audiences equally well Actively contribute to and re-use community best practicesEmbody the values and passions that characterize Levi Strauss & Co., with empathy to engage with colleagues from a wide range of backgrounds', ' Experince working with a variety of relational SQL and NoSQL databases', ' Ability to work in a Linux environment', 'Industry experience building and productionizing creative end-to-end Machine Learning systems', 'Mentor and educate team members to adopt best practices in writing and maintaining production machine learning code', 'Anomaly detection and Root Cause Analysis', ' Current LS&Co Employees, apply via your Workday account.', ' EOE M/F/Disability/Vets ', 'Visual search for similar and complementary products', 'Experience with at least one cloud provider solution (AWS, GCP, Azure)', ' Actively contribute to and re-use community best practices', 'Knowledge of data pipeline and workflow management tools', ' 401K match : $1.25 for every $1.00 you contribute up to the first 6% of pay you save.', 'Expertise in standard software engineering methodology, e.g. unit testing, test automation, continuous integration, code reviews, design documentation', 'Five hours of paid volunteer time per month with nonprofit organizations', 'Product discount of 50% off regular-price merchandise', 'About The Job', 'University or advanced degree in engineering, computer science, mathematics, or a related field', 'Establish scalable, efficient, automated processes for data analyses, model development, validation and implementation', ' Communicate clearly and effectively to technical and non-technical audiences equally well', 'LOCATION', 'Next-Best offer prediction', 'Personalized in-session product recommendation engine', 'Work closely with data scientists and analysts to create and deploy new product features on the ecommerce website, in-store portals and the Levi’s mobile app', ""Here's a Small Snapshot"", 'About You', 'Experience working with big data tools: Hadoop, Spark, Kafka , etc. ', 'Unified consumer profile with probabilistic record linkage', 'Job Description', ' Designing Microassortments for Next-Gen stores', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala , etc. ', 'Relevant working experience with Docker and Kubernetes is a big plus', 'Embody the values and passions that characterize Levi Strauss & Co., with empathy to engage with colleagues from a wide range of backgrounds', 'Example Projects', 'Write efficient and well-organized software to ship products in an iterative, continual -release environment', 'Implement end-to-end solutions for batch and real-time algorithms along with requisite tooling around monitoring, logging, automated testing, performance testing and A/B testing', 'Customer Segmentation', ' 401K match : $1.25 for every $1.00 you contribute up to the first 6% of pay you save.Five hours of paid volunteer time per month with nonprofit organizationsProduct discount of 50% off regular-price merchandise', 'Experience working with distributed systems, service oriented architectures and designing APIs', ' 5+ years experience developing and deploying machine learning systems into production']",Not Applicable,Full-time,Engineering,Apparel & Fashion,2020-11-05 11:32:32
UX Researcher,Foot Locker,"Chicago, IL",3 hours ago,Be among the first 25 applicants,"['', ' Knowledge of conducting primary research using online user testing tools.', 'Design and field primary research - including moderation (UX testing, site intercept surveys, panel surveys, etc.).', ' Experience in analyzing site metrics and using key insights to inform UX testing objectives a plus.', 'Stay abreast of key trends in the fields of human factors and user experience research.', 'Work closely with product managers, UX designers, UI designers, data analysts and other team members to prioritize research opportunities in a fast-paced, rapidly changing environment.', ' Minimum of 1yr of experience in usability research or user research.', 'Responsibilities', 'Analyze data (quantitative and qualitative) and prepare multi-media (picture in picture video clips) key findings reports.', 'Promote and evangelize design thinking approach throughout the Footlocker organization.', 'Deliver key data driven insights and recommended actions in an easy to digest and persuasive manner that influence stakeholders decisions.', "" Bachelor's Degree (a degree with a HCI, Cognitive Science, Psychology or Social Science concentration a plus)"", 'Plan and execute user experience research efforts to support iterative design and development for complex applications and websites.Write reports including findings and recommendations that drive user discovery and future design improvements.Work closely with product managers, UX designers, UI designers, data analysts and other team members to prioritize research opportunities in a fast-paced, rapidly changing environment.Deliver key data driven insights and recommended actions in an easy to digest and persuasive manner that influence stakeholders decisions.Craft and socialize research planning documents (research plans, screeners, moderator’s guides).Design and field primary research - including moderation (UX testing, site intercept surveys, panel surveys, etc.).Analyze data (quantitative and qualitative) and prepare multi-media (picture in picture video clips) key findings reports.Promote and evangelize design thinking approach throughout the Footlocker organization.Generates actionable insights that serve as a catalyst for product innovation.Stay abreast of key trends in the fields of human factors and user experience research.Facilitate the publishing of papers/articles on industry techniques. ', 'Please attach portfolio or writing samples to application', 'Write reports including findings and recommendations that drive user discovery and future design improvements.', 'Qualifications', ' Do you love participating in the creative process from brainstorm to launch, actively seeking out opportunities to contribute during all phases?', ' Are you receptive to constructive feedback and understand that revision is an essential part of the creative process?', 'Generates actionable insights that serve as a catalyst for product innovation.', "" Master's Degree a plus."", ' Strong communication and collaboration skills.', ' Do you love all things digital and have an uncontrollable need to stay current on new creative technologies?', ' Understanding and familiarity with Service Design concepts and methods, especially as it relates to internal services within the B2C retail space a plus.', ' Knowledge of web-based analytic tools (Adobe Analytics, Google Analytics, etc) a plus.', 'Overview', 'Strong portfolio or writing samples to demonstrate the skillset of a passionate/driven UX researcher required with application.', 'Click Here! ', 'Plan and execute user experience research efforts to support iterative design and development for complex applications and websites.', ' Experience with using site metrics to inform site/application/mobile design refreshes and redesigns a plus.', 'Craft and socialize research planning documents (research plans, screeners, moderator’s guides).', ' Experience in lo-fi wire-framing to demonstrate UX solutions.', ' Do you want to help drive the growth and culture of a growing user experience team?', 'Facilitate the publishing of papers/articles on industry techniques. ', ' Retail/eCommerce experience preferred.', ' Experience analyzing and presenting findings from secondary research.']",Associate,Full-time,Public Relations,Information Technology and Services,2020-11-05 11:32:32
Big Data Engineer,Landmark Health,"Baltimore, MD",7 hours ago,Be among the first 25 applicants,"['', ' Bachelor’s degree in Computer Science, Information Systems, Information Technology, Management Information Systems, or equivalent experience is preferred 3+ years designing, developing and implementing solutions in Hadoop environments 3+ years supporting technologies in the Hadoop ecosystem Expertise with HDFS, YARN, MapReduce, Hive, Pig, Spark Proficiency with Hadoop technologies such as Nifi, HDFS, HBase, Flume and Sqoop Ability to write reliable, manageable and highly efficient code using Hadoop tools Proficiency with SQL scripting Experience in backend programming, particularly Java, JavaScript, Python, R, Scala Working knowledge of Linux/Unix, distributed computing, networks and network security Strong problem solving and analytical skills Effective oral and written communication skills for both technical and non-technical audiences Excellent systems and data analysis skills Ability to prioritize and manage competing projects', ' 3+ years supporting technologies in the Hadoop ecosystem', ' Develop tools for automated build test deployment and management of the platform', ' Setting up new Hadoop users.', ' Architect, design, develop, implement, configure and document current and future Hadoop infrastructure Perform software installation and configuration, database backup and recovery, storage management, performance tuning, database connectivity and security Implement and support various components of the Hadoop ecosystem Monitor Hadoop cluster connectivity and performance. HDFS support and maintenance. Setting up new Hadoop users. Responsible for the new and existing administration of Hadoop infrastructure. Support data modelling, design and implementation, Work closely with infrastructure, network, database, business intelligence and application teams to ensure business applications are readily available and performing within agreed upon service levels Develop tools for automated build test deployment and management of the platform Continuously improve integration and delivery systems', ' Big Data Engineers', ' Expertise with HDFS, YARN, MapReduce, Hive, Pig, Spark', 'Responsibilities', ' Continuously improve integration and delivery systems', ' Effective oral and written communication skills for both technical and non-technical audiences', ' Need help finding the right job? ', ' Perform software installation and configuration, database backup and recovery, storage management, performance tuning, database connectivity and security', ' Working knowledge of Linux/Unix, distributed computing, networks and network security', 'Options', ' Architect, design, develop, implement, configure and document current and future Hadoop infrastructure', ' Responsible for the new and existing administration of Hadoop infrastructure.', 'Big Data Engineers', ' Work closely with infrastructure, network, database, business intelligence and application teams to ensure business applications are readily available and performing within agreed upon service levels', ' Bachelor’s degree in Computer Science, Information Systems, Information Technology, Management Information Systems, or equivalent experience is preferred', 'Qualifications', ' Proficiency with SQL scripting', ' Monitor Hadoop cluster connectivity and performance.', ' 3+ years designing, developing and implementing solutions in Hadoop environments', ' Implement and support various components of the Hadoop ecosystem', ' Experience in backend programming, particularly Java, JavaScript, Python, R, Scala', ' Strong problem solving and analytical skills', ' Ability to prioritize and manage competing projects', ' Excellent systems and data analysis skills', 'Overview', ' Unfortunately, VISA SPONSORSHIP is NOT offered for these roles ', ' HDFS support and maintenance.', ' Proficiency with Hadoop technologies such as Nifi, HDFS, HBase, Flume and Sqoop', ' Support data modelling, design and implementation,', ' Ability to write reliable, manageable and highly efficient code using Hadoop tools']",Entry level,Full-time,Engineering,Nonprofit Organization Management,2020-11-05 11:32:32
Senior Data Scientist,Pluralsight,"Draper, UT",6 hours ago,139 applicants,"['', ' You will create, iterate, and innovate on models and algorithms and collaborate with team members to implement them on the Pluralsight platform. ', ' M.S. or Ph.D in Computer Science, Statistics, Mathematics, Data Science, or related quantitative discipline  Minimum 5 years in a non-academic data science role, conducting analysis, developing algorithms and building prototypes  Experience working with product development teams and/or with developers', ' You have mastery of either Python or R. Regardless of your favorite scientific computing environment, you can flex between the two languages. ', ' You will propose and design experiments to test new product features and analyze their results. ', ' You can describe and speak in an approachable way about complex analyses and concepts within a cross-functional team. You are a great “analytic translator”. ', ' You will evaluate and introduce new technology by developing proof-of-concepts and prototypes and effectively communicating highly complex information to Experience team partners and leaders ', 'What You’ll Do', ' M.S. or Ph.D in Computer Science, Statistics, Mathematics, Data Science, or related quantitative discipline ', ' You can guide complex projects from ideation and planning to model design to deployment and independently make decisions about the technical approach ', ' You are able to perform rapid prototyping of experimental solutions, writing readable, scalable, and reproducible code. ', ' You will also serve as a data science expert and consultant to Pluralsight’s product teams, leveraging your statistical and analytical skills to answer ad hoc questions. ', 'Job Description:', ' You are intellectually curious, collaborative, and highly driven with an entrepreneurial mindset. You have excellent critical thinking, problem solving, and analytical skills.  You can guide complex projects from ideation and planning to model design to deployment and independently make decisions about the technical approach  You have a solid data science toolkit that you can leverage, with knowledge of and understanding of how and when to apply different algorithms and technical approaches.  You have a strong foundation in Machine Learning, Computer Science, and Statistics.  You have mastery of either Python or R. Regardless of your favorite scientific computing environment, you can flex between the two languages.  You know your way around SQL-like databases (e.g. PostGres, Impala, Hive) and even better if you have experience with Spark and other big data platforms.  You are able to perform rapid prototyping of experimental solutions, writing readable, scalable, and reproducible code.  You can describe and speak in an approachable way about complex analyses and concepts within a cross-functional team. You are a great “analytic translator”. ', ' Minimum 5 years in a non-academic data science role, conducting analysis, developing algorithms and building prototypes ', ' You have a solid data science toolkit that you can leverage, with knowledge of and understanding of how and when to apply different algorithms and technical approaches. ', ' You will collaborate with product teams to understand and solve complex problems; envisioning and creating data science solutions needed to drive our user experience outcomes. ', 'The Opportunity', 'Experience You’ll Need', ' You will create, iterate, and innovate on models and algorithms and collaborate with team members to implement them on the Pluralsight platform.  You will evaluate and introduce new technology by developing proof-of-concepts and prototypes and effectively communicating highly complex information to Experience team partners and leaders  You will propose and design experiments to test new product features and analyze their results.  You will also serve as a data science expert and consultant to Pluralsight’s product teams, leveraging your statistical and analytical skills to answer ad hoc questions. ', 'This position is available for remote employment in these areas:', 'Who You Are', ' You are intellectually curious, collaborative, and highly driven with an entrepreneurial mindset. You have excellent critical thinking, problem solving, and analytical skills. ', ' You have a strong foundation in Machine Learning, Computer Science, and Statistics. ', ' Experience working with product development teams and/or with developers', ' You know your way around SQL-like databases (e.g. PostGres, Impala, Hive) and even better if you have experience with Spark and other big data platforms. ']",Associate,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Sr. Machine Learning Engineer,Zoom,"Phoenix, AZ",5 hours ago,Be among the first 25 applicants,"[' Clear understanding of text pre-processing and normalization techniques, such as tokenization, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level.', ' Research latest technology in NLP, machine learning, create and improve machine learning models and algorithms. Design and develop AI / machine learning solutions to enhance Zoom meeting experience; Develop machine learning systems for Zoom applications. Train deep learning models with large datasets and accelerating the training process with GPU and CUDA. Research for open sourced labeled dataset and build data pipeline to perform data extraction, transformation and loading. Develop requirement guideline and evaluation criteria for text based data labeling. Integrate machine learning program with Zoom’s core product. Work closely with the Product team to understand current challenges when it comes to use, understand and present the results of text analytics. Work closely with offshore team, providing requirements, technical leadership, and evaluating results.', ' Train deep learning models with large datasets and accelerating the training process with GPU and CUDA.', ' Integrate machine learning program with Zoom’s core product.', 'Responsibilities', ' At least 3 years industry working experience or research experience in the field of machine learning.', ' Develop requirement guideline and evaluation criteria for text based data labeling.', '  M.S., prefer Ph.D in NLP, Machine Learning, Computational Linguistics, Computer Science, Electrical Engineering, Statistics, Mathematics or a related technical field. Familiar with latest development in neural network and the application in machine learning. Experience with developing machine learning systems and familiar with machine learning pipeline components and process. At least 3 years industry working experience or research experience in the field of machine learning. Clear understanding of text pre-processing and normalization techniques, such as tokenization, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level. Strong fundamentals on Machine Learning (ML) / Deep Learning (DL) and NLP algorithms (Word embedding, CNN, LSTM, BERT, etc), techniques (transfer learning, transformers, etc.). Hands-on experience on developing and training models with large- scale text data. Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, SpaCy, AllenNLP, NLTK, gensim, etc. Familiar with software development. Strong analytical skills and attention to detail. Strong mastery of python and general software development skills (source code management, debugging, testing, deployment, etc.)', ' Experience with developing machine learning systems and familiar with machine learning pipeline components and process.', ' OUR IDEAL CANDIDATE: This role requires experience with machine learning in research and application development, creative problem solving and strong communication skills to work with different teams and stakeholders. This person should be highly organized, with the ability to manage requests efficiently and accurately. ', ' Develop machine learning systems for Zoom applications.', ' Strong fundamentals on Machine Learning (ML) / Deep Learning (DL) and NLP algorithms (Word embedding, CNN, LSTM, BERT, etc), techniques (transfer learning, transformers, etc.). Hands-on experience on developing and training models with large- scale text data.', ' Work closely with the Product team to understand current challenges when it comes to use, understand and present the results of text analytics.', ' Research latest technology in NLP, machine learning, create and improve machine learning models and algorithms.', '   M.S., prefer Ph.D in NLP, Machine Learning, Computational Linguistics, Computer Science, Electrical Engineering, Statistics, Mathematics or a related technical field. Familiar with latest development in neural network and the application in machine learning. Experience with developing machine learning systems and familiar with machine learning pipeline components and process. At least 3 years industry working experience or research experience in the field of machine learning. Clear understanding of text pre-processing and normalization techniques, such as tokenization, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level. Strong fundamentals on Machine Learning (ML) / Deep Learning (DL) and NLP algorithms (Word embedding, CNN, LSTM, BERT, etc), techniques (transfer learning, transformers, etc.). Hands-on experience on developing and training models with large- scale text data. Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, SpaCy, AllenNLP, NLTK, gensim, etc. Familiar with software development. Strong analytical skills and attention to detail. Strong mastery of python and general software development skills (source code management, debugging, testing, deployment, etc.)', ' Work closely with offshore team, providing requirements, technical leadership, and evaluating results.', 'Requirements', ' Research for open sourced labeled dataset and build data pipeline to perform data extraction, transformation and loading.', ' Design and develop AI / machine learning solutions to enhance Zoom meeting experience;', ' Familiar with latest development in neural network and the application in machine learning. Experience with developing machine learning systems and familiar with machine learning pipeline components and process. At least 3 years industry working experience or research experience in the field of machine learning. Clear understanding of text pre-processing and normalization techniques, such as tokenization, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level. Strong fundamentals on Machine Learning (ML) / Deep Learning (DL) and NLP algorithms (Word embedding, CNN, LSTM, BERT, etc), techniques (transfer learning, transformers, etc.). Hands-on experience on developing and training models with large- scale text data. Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, SpaCy, AllenNLP, NLTK, gensim, etc. Familiar with software development. Strong analytical skills and attention to detail. Strong mastery of python and general software development skills (source code management, debugging, testing, deployment, etc.)', ' Familiar with latest development in neural network and the application in machine learning.', 'Zoom is an award-winning workplace. We have been recognized by Comparably as #1 CEO, Company Happiness, Benefits, Compensation, Diversity, and more! Not to mention we’ve been awarded by Glassdoor as the 2nd Best US workplace & Best Large Company US CEO in 2018, Wealthfront, and Business Insider. Our culture focuses on delivering happiness, our commitment to transparency, and the tangible benefits we provide our employees and our customers. ', ' Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, SpaCy, AllenNLP, NLTK, gensim, etc.', ' Familiar with software development. Strong analytical skills and attention to detail. Strong mastery of python and general software development skills (source code management, debugging, testing, deployment, etc.)']",Not Applicable,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Machine Learning Engineer,Forefront Solutions & Consultancies Ltd,"Seattle, WA",5 hours ago,Over 200 applicants,"['', 'Machine learning platforms', 'ML/AI models which are in production', 'ML/AI models which are in productionNew neural network algorithms based on research papersLow level performance optimization of deep learning systemsMachine learning platformsNLP', 'NLP', 'Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher level abstractions for various common AI/ML techniques.', 'Low level performance optimization of deep learning systems', 'New neural network algorithms based on research papers', 'Candidates will need to have a BS or MS from top notch CS programs with industry experience. We are looking for machine learning software engineers who have experience building at least one of the following:']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Data Engineer,"Capstone Technology Resources, Inc. (Capstone)","San Francisco, CA",17 hours ago,34 applicants,"['', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Preference given to those with advanced data modeling experience.', 'Responsibilities:', ""Our client, Autodesk, is the global leader in 3D AutoCAD software. Headquartered in the SF Bay Area, they're established, award-winning, and financially solid (zero layoffs due to covid). This is a 3-month engagement to start, with expected extensions."", 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Candidate will be coordinating work with other teams.', 'Minimum Qualifications:', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Hands-on/Player-Coach style candidate.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa05+ years of experience.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Create and update data models for decision support of digital help programs and initiatives.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Self-starter and a driver, ability to communicate/own a project to completion while working with various teams (not directly managing the teams).', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL (primarily MS SQL) and AWS technologies.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Drive the re-architecting of ADSK data sources feeding our automation workflows (re-align source file acquisitions within AWS).', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experienced data solution architecting.', 'Remote role:\xa0SF Preferred area; however, open to candidate in other areas as long as he/she can work PST time zone.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Maintain/ develop a scalable database/ data warehouse through connecting. disparate data tables housed across numerous organizational systems and different business lines.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Drive SQL server conversion onto AWS platform.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Optimize and maintain scripts on present data warehouses and present ETL.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Expertise in gathering data through multiple sources through API calls and scripting languages.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa070-Technical/30-Functional.', '***Sorry, no third parties please***', 'Job Title:\xa0Data Engineer w/MS SQL Server Automation experience', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Excellent written and verbal communication skills.', '\xa0\xa0\xa0\xa0\xa0\xa0\xa0C++ etc.', 'o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with object-oriented/object function scripting languages: Python, Java,', 'Nice to Have but not required:', ""o\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Bachelor's degree computer science, information systems, or a related discipline."", '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Code review all current SSIS jobs for effectiveness.']",Mid-Senior level,Contract,Information Technology,Staffing and Recruiting,2020-11-05 11:32:32
Data Engineer - SaaS/SQL,Visionaire Partners,"Atlanta, GA",3 hours ago,Be among the first 25 applicants,"['', '\ufeffRESPONSIBILITIES:\xa0', 'SAAS (Experience working with SAAS products and data)', 'Create and maintain ETL solutions capable of extreme growth\xa0', 'Data Modeling', 'Create data strategy and architectural\xa0roadmaps for all things surrounding dataOwn the ingestion of all data into the enterpriseCreate and maintain ETL solutions capable of extreme growth\xa0Create a self serve data / reporting environment for usersManage a cloud based DW (data warehouse)Create requirements for Engineering teamsBuild Data Visualizations for BI', 'Create data strategy and architectural\xa0roadmaps for all things surrounding data', 'ETL', 'Enjoy a long term contract opportunity with option to convert to direct hire. We will work remote until it is safe to return to the office which is near Perimeter Mall. Enjoy working in a digital Internet environment using modern tech.\xa0This is NOT your traditional old school environment. If you truly enjoy working with Cloud technology and SaaS technology and are passionate about implementing this tech in new and innovative ways, this is the opportunity for you!\xa0', 'Build Data Visualizations for BI', '\ufeffREQUIRED SKILLS:', 'Create requirements for Engineering teams', 'SQL\xa0ETLSAAS (Experience working with SAAS products and data)AWS or Google Cloud or Azure (we use AWS)Data Modeling', 'We seek a Data Engineer who is comfortable working in a heavy SaaS environment!\xa0We use multiple best of breed SaaS applications and tools and are building out our digital internet based environment. We seek a candidate who is passionate about using cloud technology. If you are ""into"" using new technology and passionate about putting new tech into production, this is the job for you!\xa0\xa0', 'Data Engineer - SaaS Technical Environment', 'Manage a cloud based DW (data warehouse)', '\ufeffRESPONSIBILITIES:', 'You will develop data strategies and create digital roadmaps for the organization and put them in production! You will also play a critical role in the ingestion of all data. You will own the ETL process and work with the team when data anomalies occur. You will assist with transforming data into usable insights for the business.\xa0', 'AWS or Google Cloud or Azure (we use AWS)', 'SQL\xa0', 'NOT', 'Own the ingestion of all data into the enterprise', 'Create a self serve data / reporting environment for users']",Mid-Senior level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,HireHappi,Greater Seattle Area,14 hours ago,Be among the first 25 applicants,"['Exposure to cloud technologies is required (GCP is a plus)', 'Very good experience in PL/SQL', '4-6 years of experience as a Data or BI Engineer dealing with large complex data scenarios', '4-6 years of experience as a Data or BI Engineer dealing with large complex data scenarios4+ years of experience in ETLVery good experience in PL/SQLExposure to cloud technologies is required (GCP is a plus)', '4+ years of experience in ETL']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,3M,"Maplewood, MN",22 hours ago,29 applicants,"['', 'Please note: your application may not be considered if you do not provide your education and work history, either by: 1) uploading a resume, or 2) entering the information into the application fields directly.', ' 3M Global Terms of Use and Privacy Statement ']",Entry level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Data Engineer,Henlow Group US,"New York, NY",2 hours ago,Be among the first 25 applicants,"['', 'Interest in applying technology to real situations, comfortable working in a fast-paced environment, detail-oriented and capable of performing tasks under pressure', 'Design and implement software to facilitate data integration with trading and simulating systemsImprove existing frameworks of data flow and monitoringImplement software that interface with external vendors to bring in new data setsCollect and analyze statistics on market data applications and devise approaches to improve the relevant processes', 'The Role', 'Degree in a quantitative or technical discipline from a top university and strong academic scoresInterest in applying technology to real situations, comfortable working in a fast-paced environment, detail-oriented and capable of performing tasks under pressureDemonstrated experience with C++ or other object oriented languagesExperience with scripting languages such as Perl, Python, and shell scripting; Interface with database (such as MySQL)', 'Collect and analyze statistics on market data applications and devise approaches to improve the relevant processes', 'Improve existing frameworks of data flow and monitoring', 'Demonstrated experience with C++ or other object oriented languages', 'Experience', 'Implement software that interface with external vendors to bring in new data sets', 'Design and implement software to facilitate data integration with trading and simulating systems', 'Experience with scripting languages such as Perl, Python, and shell scripting; Interface with database (such as MySQL)', ""What You'll Bring"", 'Degree in a quantitative or technical discipline from a top university and strong academic scores']",Entry level,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
"Data Engineer, People Analytics",WeWork,"New York, NY",7 hours ago,200 applicants,"['', 'Maintain and support business critical applications ', 'Basic understanding of some Object Oriented programming concepts (Inheritance, Polymorphism, Encapsulation, Abstraction)', 'Comfortable working with various APIs such as Rest, Curl to retrieve data', 'Bachelor’s degree in Computer Science, Computer Engineering or related field and 2+ years of experienceSolid knowledge of PythonBasic understanding of some Object Oriented programming concepts (Inheritance, Polymorphism, Encapsulation, Abstraction)Good understanding of data structures, such as lists, tuples, dictionaries and arraysComfortable working with various APIs such as Rest, Curl to retrieve dataComfortable with query writing using any of the SQL variants (ie. PostGre, MySQL) and good understanding of aggregate functions, joins and subqueriesAbility to think abstractly before codingWillingness to learn Hadoop, Hive, Airflow, Github and SnowflakeComfortable programming as an individual contributor and in a teamAbility to complete a project from start to finish with some supervision from the Senior Engineer or Manager', 'Debug processes that may fail during the day to day', 'Assist the Senior Engineer or Manager with data engineering projects as requestedTake part in ensuring data integrity of main data source in PostGre and HiveDebug processes that may fail during the day to dayHelp rebuild or restructure old processes as requestedManage our ELT and ETL processesMaintain and support business critical applications ', 'Bachelor’s degree in Computer Science, Computer Engineering or related field and 2+ years of experience', 'About Us', 'Ability to think abstractly before coding', 'Good understanding of data structures, such as lists, tuples, dictionaries and arrays', 'here.', 'Willingness to learn Hadoop, Hive, Airflow, Github and Snowflake', 'Comfortable programming as an individual contributor and in a team', 'Ability to complete a project from start to finish with some supervision from the Senior Engineer or Manager', 'Assist the Senior Engineer or Manager with data engineering projects as requested', 'Take part in ensuring data integrity of main data source in PostGre and Hive', 'About The Role', 'Life at WeWork', 'Comfortable with query writing using any of the SQL variants (ie. PostGre, MySQL) and good understanding of aggregate functions, joins and subqueries', 'About You', 'Key Responsibilities', 'Help rebuild or restructure old processes as requested', 'Solid knowledge of Python', 'Manage our ELT and ETL processes']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"Machine Learning Engineer: up to $250,000 base+equity",Scovios,"Seattle, WA",9 hours ago,Be among the first 25 applicants,"['', 'Responsibilities:', 'Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher level abstractions for various common AI/ML techniques.', 'Candidates will need to have a BS or MS from top notch CS programs with industry experience. We are looking for machine learning software engineers who have experience building at least one of the following: ML/AI models which are in production New neural network algorithms based on research papers Low level performance optimization of deep learning systems Machine learning platforms', 'Company Description:', 'Job Description:', 'General Requirements:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. They have also previously been founders and early employees at startups. We raised $18 million in Series A from Decibel Ventures and Eric Schmidt. We are looking for talented machine learning software engineers, systems software engineers and research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Data Engineer,StockX,"Detroit, MI",8 hours ago,Be among the first 25 applicants,"['', 'Automation of end to end data pipeline with metadata, data quality checks and audit ', 'Experience with data visualization tools such as Tableau, Looker, PowerBI', 'Support mission critical applications and near real time data needs from the data platform', ' Masters in Computer Science, Physics, Mathematics, Statistics or other Engineering disciplines Experience with data visualization tools such as Tableau, Looker, PowerBI Experience with Hadoop implementation ', 'Ability to work independently with business partners and management to understand their needs and exceed expectations in delivering tools/solutions', 'Optimize the data pipeline to support ML workloads and use cases', 'Nice To Have', 'Minimum 3 years of Big Data and Big Data tools in one or more of the following: Kafka, MapReduce, Spark or Python, Hadoop', 'Strong familiarity with batch processing and workflow tools such as AirFlow, NiFi', 'Strong interpersonal, verbal and written communication skills and ability to present complex technical/analytical concepts to executive audience', 'Experience providing technical leadership and mentoring other engineers for best practices on data engineering', 'Build and support reusable framework to ingest, integration and provision data', 'Responsibilities', 'Build and support a big data platform on the cloud', ""3+ years' experience with AWS or engineering in other cloud environments"", 'Experience with Database Architecture/Schema design', 'Work collaboratively with business analysts, product managers, data scientists as well as business partners and actively participate in design thinking session', "" 7+ years’ experience in data warehouse / data lake technical architecture Minimum 3 years of Big Data and Big Data tools in one or more of the following: Kafka, MapReduce, Spark or Python, Hadoop 3+ years' experience with AWS or engineering in other cloud environments Experience with Database Architecture/Schema design Strong familiarity with batch processing and workflow tools such as AirFlow, NiFi Ability to work independently with business partners and management to understand their needs and exceed expectations in delivering tools/solutions Strong interpersonal, verbal and written communication skills and ability to present complex technical/analytical concepts to executive audience Strong business mindset with customer obsession; ability to collaborate with business partners to identify needs and opportunities for improved data management and delivery Experience providing technical leadership and mentoring other engineers for best practices on data engineering BS/BA degree in Computer Science, Physics, Mathematics, Statistics or other Engineering disciplines "", 'Participate in design and code reviews', 'Experience with Hadoop implementation', 'Qualifications', 'Strong business mindset with customer obsession; ability to collaborate with business partners to identify needs and opportunities for improved data management and delivery', 'Define and implement automation of jobs and testing', 'Design and build mission critical data pipelines with a highly scalable distributed architecture - including data ingestion (streaming, events and batch), data integration, data curation', 'BS/BA degree in Computer Science, Physics, Mathematics, Statistics or other Engineering disciplines', 'We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. This job description is intended to convey information essential to understanding the scope of the job and the general nature and level of work performed by job holders within this job. However, this job description is not intended to be an exhaustive list of qualifications, skills, efforts, duties, responsibilities or working conditions associated with the position. StockX reserves the right to amend this job description at any time.', ' Design and build mission critical data pipelines with a highly scalable distributed architecture - including data ingestion (streaming, events and batch), data integration, data curation Help continually improve ongoing reporting and analysis processes, simplifying self-service support for business stakeholders Build and support reusable framework to ingest, integration and provision data Automation of end to end data pipeline with metadata, data quality checks and audit  Build and support a big data platform on the cloud Define and implement automation of jobs and testing Optimize the data pipeline to support ML workloads and use cases Support mission critical applications and near real time data needs from the data platform Capture and publish metadata and new data to subscribed users Work collaboratively with business analysts, product managers, data scientists as well as business partners and actively participate in design thinking session Participate in design and code reviews Motivate, coach, and serve as a role model and mentor for other development team associates/members that leverage the platform  ', 'Masters in Computer Science, Physics, Mathematics, Statistics or other Engineering disciplines', 'Motivate, coach, and serve as a role model and mentor for other development team associates/members that leverage the platform ', 'Help continually improve ongoing reporting and analysis processes, simplifying self-service support for business stakeholders', 'Capture and publish metadata and new data to subscribed users', '7+ years’ experience in data warehouse / data lake technical architecture']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist,WHOOP,"Boston, MA",5 hours ago,63 applicants,"['', 'Develop advanced mathematical models and algorithms to solve problems', '5+ years of full-time professional experience in a related area', 'Degree in Mathematics, Statistics, Computer Science, or a related field5+ years of full-time professional experience in a related area5+ years experience applying advanced mathematical and statistical techniquesKnowledge of Machine learning and statistical/mathematical modelingProficient in the scientific Python stack (numpy, scipy, scikit-learn, matplotlib, pandas, etc)Ability to formulate hypotheses, draw conclusions and deliver resultsExcellent verbal and written communication skillsAbility to present findings to stakeholders and communicate results to all colleaguesUnderstanding of exercise physiology or athletic experience a plus', 'Qualifications', 'Work closely with the product manager and engineers to translate prototypes into production-ready code', 'Identify and build new datasets that would enhance models and decision making', 'Proficient in the scientific Python stack (numpy, scipy, scikit-learn, matplotlib, pandas, etc)', 'Understanding of exercise physiology or athletic experience a plus', 'Develop software tools and libraries for analytics applications', 'Knowledge of Machine learning and statistical/mathematical modeling', 'Develop advanced mathematical models and algorithms to solve problemsDevelop software tools and libraries for analytics applicationsIdentify and build new datasets that would enhance models and decision makingWork closely with the product manager and engineers to translate prototypes into production-ready code', 'Ability to formulate hypotheses, draw conclusions and deliver results', 'Degree in Mathematics, Statistics, Computer Science, or a related field', '5+ years experience applying advanced mathematical and statistical techniques', 'Responsibilities', 'Ability to present findings to stakeholders and communicate results to all colleagues', 'Excellent verbal and written communication skills']",Associate,Full-time,Other,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Data Engineer,Agile Tech Labs,"Sunnyvale, CA",6 minutes ago,Be among the first 25 applicants,"['', '> Resolves technical issues through debugging, research, and investigation.\xa0', 'Best Regards,', 'Minimum Qualifications', 'Innovation & Technology Focused on your success', '> Designs, develops, and implements Hadoop eco-system based applications to support business requirements.\xa0', 'This position is more of a UI Developer. The manager is looking for experience with React Framework, NodeJS, HTML, CSS, and JavaScript as the main skillset', 'www.agile-techlabs.com', 'I hope you and your family are doing well, We are living in unprecedented times.\xa0Still we are here to help you get placed.', 'Senior Talent Acquisition Specialist | Agile Tech Labs, Inc.', ""1. Bachelor's degree in Computer Science, Information Technology, or related field and 5 years experience in computer programming, software development or related"", '4. Strong communication and problem-solving skills', 'Roles & Responsibilities', 'Greetings,', '2. 3+ years of solid Java and 2+ years experience in design, implementation, and support of solutions big data solution in Hadoop using Hive, Spark, Drill, Impala, HBase', 'https://www.linkedin.com/in/jay-nahariya/', 'Jay Nahariya', 'Required Skills', '3. Hands on experience with Unix, Teradata and other relational databases. Experience with @Scale a plus.', 'Spark-Hive-HBase-Hadoop-Impala-Java-Drill', 'Summary', '> Follows approved life cycle methodologies, creates design documents, and performs program coding and testing.', '+1.248.834.2413 | Jay.Nahariya@agile-techlabs.com']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Senior Data Scientist, Growth",Spotify,"New York, NY",7 hours ago,39 applicants,"['', 'You have a PhD / MS degree in Econometrics, Statistics or similar field (focus on causal inference / experimentation / scaled measurement) ', 'You have 5+ years experience with mixed data skill sets and approaches (analytics, analytic tools, and data science); experience with rapid product development for a consumer facing tech company preferred', 'Lead experimentation for initiatives both on and off-platform (e.g. SEO, product launches, marketing initiatives, etc): design test plans, obtain cross-functional alignment, execute robust analysis, and deliver actionable insights', 'Drive product strategy by leading foundational research & experimentation initiatives to develop a deeper understanding of our user funnel', 'Maintain a culture of rigor and data curiosity to drive tangible business impact', 'You are a highly motivated and flexible individual with the ability to lead cross-functional teams and drive projects to successful and timely delivery.', 'You have strong SQL skills and advanced programmatic expertise, like R or Python', 'You have deep understanding of a breadth of modeling techniques (e.g. regression models, causal inference in marketing and product launches, advanced Bayesian techniques)', 'Establish learning agendas, measurement plans and success metrics in close coordination with contributing teams and stakeholders', 'You thrive in a dynamic environment and are able to execute with autonomy. ', 'Work as part of a cross-functional team of product, data science, tech, design and user research that aims to propel Spotify’s user growth by fostering a culture of impact and performanceLead experimentation for initiatives both on and off-platform (e.g. SEO, product launches, marketing initiatives, etc): design test plans, obtain cross-functional alignment, execute robust analysis, and deliver actionable insightsEstablish learning agendas, measurement plans and success metrics in close coordination with contributing teams and stakeholdersSet a strategic framework to identify and prioritize new projects by evaluating and forecasting their potential for growth impactDrive product strategy by leading foundational research & experimentation initiatives to develop a deeper understanding of our user funnelMaintain a culture of rigor and data curiosity to drive tangible business impact', 'You have strong analytical skills, including analysis and modeling of big data, statistics, A/B testing, and experimental design required ', ""What You'll Do"", 'Work as part of a cross-functional team of product, data science, tech, design and user research that aims to propel Spotify’s user growth by fostering a culture of impact and performance', 'Who You Are', 'You have the capacity and passion to translate business objectives into actionable analyses and results into business and product recommendations', 'Set a strategic framework to identify and prioritize new projects by evaluating and forecasting their potential for growth impact', 'You have a PhD / MS degree in Econometrics, Statistics or similar field (focus on causal inference / experimentation / scaled measurement) You have 5+ years experience with mixed data skill sets and approaches (analytics, analytic tools, and data science); experience with rapid product development for a consumer facing tech company preferredYou have strong analytical skills, including analysis and modeling of big data, statistics, A/B testing, and experimental design required You have deep understanding of a breadth of modeling techniques (e.g. regression models, causal inference in marketing and product launches, advanced Bayesian techniques)You have strong SQL skills and advanced programmatic expertise, like R or PythonYou have the capacity and passion to translate business objectives into actionable analyses and results into business and product recommendationsYou have experience with international markets, growth marketing, web platformsYou are a highly motivated and flexible individual with the ability to lead cross-functional teams and drive projects to successful and timely delivery.You thrive in a dynamic environment and are able to execute with autonomy. ', 'You have experience with international markets, growth marketing, web platforms']",Not Applicable,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Research Scientist,Visiting Nurse Service of New York,"Manhattan, NY",13 hours ago,Be among the first 25 applicants,"['', 'Education', 'Education: Ph.D. with content expertise in Nursing, Public Health, Medicine, Gerontology, Social Work, Sociology, Health Economics, Informatics or other relevant discipline required.Required Experience: Successful track record in obtaining NIH/AHRQ funding to support research activities. Must have strong skills in outcomes-focused research, including data analysis, modelling, and interpretation. Proven publication and professional presentation record. Senior Scientist: Minimum of five years of experience conducting large scale R01-level independent research conducted in an academic, clinical or health policy research setting.Knowledge of and prior work experience in home health care setting preferred. Prior experience working with large data sets, decision support, geriatrics, chronic disease management, palliative care, and/or practice behavior change also preferred. A joint appointment with an academic medical center or university will be considered.', 'Overview', 'Qualifications', 'Mentors others in research design and conduct. Provides general direction/guidance/training to new/less experienced staff.', 'Prepares scientific and other articles and technical reports for publication; Presents at professional meetings.', 'Designs and implements projects of varied size/scope/impact on the utilization, costs and quality of home and community-based services and long-term care.', 'Knowledge of and prior work experience in home health care setting preferred. Prior experience working with large data sets, decision support, geriatrics, chronic disease management, palliative care, and/or practice behavior change also preferred. A joint appointment with an academic medical center or university will be considered.', 'Education: Ph.D. with content expertise in Nursing, Public Health, Medicine, Gerontology, Social Work, Sociology, Health Economics, Informatics or other relevant discipline required.', 'Designs and implements projects of varied size/scope/impact on the utilization, costs and quality of home and community-based services and long-term care.Develops proposals to external funders (e.g., AHRQ, NIH, RWJF, The Commonwealth Fund) in response to Requests for Proposals/Applications, for investigator-initiated grants, and in response to other grant and contract opportunities.Oversees the development and implementation of detailed data analytic plans using advanced statistical methods.Works with Director and other investigators and project staff to develop and implement research studies.Mentors others in research design and conduct. Provides general direction/guidance/training to new/less experienced staff.Prepares scientific and other articles and technical reports for publication; Presents at professional meetings.', 'Develops proposals to external funders (e.g., AHRQ, NIH, RWJF, The Commonwealth Fund) in response to Requests for Proposals/Applications, for investigator-initiated grants, and in response to other grant and contract opportunities.', 'Oversees the development and implementation of detailed data analytic plans using advanced statistical methods.', 'Works with Director and other investigators and project staff to develop and implement research studies.', 'Required Experience: Successful track record in obtaining NIH/AHRQ funding to support research activities. Must have strong skills in outcomes-focused research, including data analysis, modelling, and interpretation. Proven publication and professional presentation record. Senior Scientist: Minimum of five years of experience conducting large scale R01-level independent research conducted in an academic, clinical or health policy research setting.', 'Responsibilities', 'Required Experience']",Associate,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Data Engineer (Data Integration),IT People Corporation,"Piscataway, NJ",1 hour ago,Be among the first 25 applicants,"['Required skills (maximum of 6): ETL design using Microsoft SSIS,SQL Server ,SQL Query Language,MS Visual Studio ', 'Work remotely: Yes ']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Genzeon,"New York, NY",1 hour ago,Be among the first 25 applicants,"['Responsibilities', 'Experience with Hadoop, Spark, and Docker is a plus', 'Investigate vendor data thoroughly to become a subject matter expert on its characteristics and irregularities', 'Strong programming skills, preference for Python, Java is a plus', 'Proficient with SQL, experience with Postgres is a plus', 'Job Title: Data Engineer', ' Communicate with quantitative researchers and other end-users to understand their requirements and potential future requests Investigate vendor data thoroughly to become a subject matter expert on its characteristics and irregularities Develop ETL processing components using cutting edge technologies, and write robust tests for on-going quality control Support developed transformations and ETL frameworks in production trading as well as backtest research Build flexible data API components in iterations with research peers to ensure their needs are met Optimize data IO and load balancing for distributed, grid computation ', 'Ability to find practical solutions and successfully make trade-offs between long-term goals and short-term deliverables', 'Experience with the scientific Python stack, Numpy, Scipy, Pandas, Matplotlib', 'Optimize data IO and load balancing for distributed, grid computation', '2-5 years of professional experience, ideally exposure to work with complex data sets and all stages of cleaning, preparing data to be used in specific format', 'Requirements', 'Ability to troubleshoot difficult problems, both numerically and technically', 'Duration: Contract/ Permanent Full Time', 'Support developed transformations and ETL frameworks in production trading as well as backtest research', 'Computer Science/Math or similar degree', 'Develop ETL processing components using cutting edge technologies, and write robust tests for on-going quality control', ' Strong programming skills, preference for Python, Java is a plus Experience with the scientific Python stack, Numpy, Scipy, Pandas, Matplotlib Ability to find practical solutions and successfully make trade-offs between long-term goals and short-term deliverables Ability to troubleshoot difficult problems, both numerically and technically Proficient with SQL, experience with Postgres is a plus Experience with Hadoop, Spark, and Docker is a plus Analyze a variety of large data sets to develop and implement alpha signals Computer Science/Math or similar degree 2-5 years of professional experience, ideally exposure to work with complex data sets and all stages of cleaning, preparing data to be used in specific format', 'Communicate with quantitative researchers and other end-users to understand their requirements and potential future requests', 'Analyze a variety of large data sets to develop and implement alpha signals', 'Location: New York, NY / Austin, TX', 'Build flexible data API components in iterations with research peers to ensure their needs are met']",Entry level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer / Architect,Analysts,"St Louis, MO",2 hours ago,Be among the first 25 applicants,"['AIC is seeking a Data Engineer/Architect with a continuously improving mindset excited about building a modern and transparent data platform in a Data/Ops and SRE culture!  ', 'Idempotent Pipelines with fitness functions validating production purpose ', 'Kubernetes, App Engine, Cloud Functions', 'Data Engineer / Architect ', '\xa0 ', 'Google Cloud Platform, Amazon Web Services ', 'Python, Java, Go Lang ', 'BigQuery, Solr, Airflow, Dataflow/Beam, Pub/Sub Technologies, MySQL(legacy) ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
BI Data Engineer,Brooksource,"Carmel, IN",19 hours ago,Be among the first 25 applicants,"['Preferred Skills', 'OOP or functional Object-oriented scripting languageprogramming experience (ex. Python, Java, C++, Scala, R, etc.). ', 'Advanced ability to visualize data (Tableau experience preferred). ', 'Identify and implement internal process improvements (ex. automation and optimization). ', 'Working knowledge of message queuing and stream processing.', 'Be a champion for data quality, integrity, and security within the organization. ', 'Experience with cloud warehousing and analytics (ex. Snowflake, Redshift, BigQuery) and analytics. Experience with semi-structured and unstructured data (JSON). OOP or functional Object-oriented scripting languageprogramming experience (ex. Python, Java, C++, Scala, R, etc.). Working knowledge of message queuing and stream processing.', 'Responsibilities', 'Experience with semi-structured and unstructured data (JSON). ', 'Collaborate with business partners to understand processes and identify opportunities for our team to make meaningful improvements. ', 'Advanced SQL and RDBMS experience (ex. Oracle, SQL Server, MySQL, etc.) including complex SQL, Procedures, functions, views, outer joins, aggregations, unions, and partitioning. ', 'Lead BI modernization efforts, design solutions with a focus on cloud, PaaS, SaaS, and serverless services. ', 'Experience engineering data ingestion and transformation solutions (ex. Informatica, Azure Data Factory, SSIS, Talend, Pentaho, Python, Databricks, stored procedures, etc.). ', '\xa0', 'Data Warehouse and Business Intelligence experience. Strong problem-solving skills, with the ability to analyze and break down problems. Advanced SQL and RDBMS experience (ex. Oracle, SQL Server, MySQL, etc.) including complex SQL, Procedures, functions, views, outer joins, aggregations, unions, and partitioning. Experience engineering data ingestion and transformation solutions (ex. Informatica, Azure Data Factory, SSIS, Talend, Pentaho, Python, Databricks, stored procedures, etc.). Advanced ability to visualize data (Tableau experience preferred). Understanding and practice of Agile and DevOps principles (Azure DevOps experience Preferred). ', 'Responsibilities ', 'Required Skills ', 'Understanding and practice of Agile and DevOps principles (Azure DevOps experience Preferred). ', 'Collaborate with business partners to understand processes and identify opportunities for our team to make meaningful improvements. Implement simple, intuitive data engineering and visual solutions. Mentor users and piers to improve analytical skillsets across the organization. Identify and implement internal process improvements (ex. automation and optimization). Lead BI modernization efforts, design solutions with a focus on cloud, PaaS, SaaS, and serverless services. Be a champion for data quality, integrity, and security within the organization. ', 'Preferred Skills ', 'Implement simple, intuitive data engineering and visual solutions. ', 'Strong problem-solving skills, with the ability to analyze and break down problems. ', ' ', 'Mentor users and piers to improve analytical skillsets across the organization. ', 'BI Data Engineer', 'Required Skills', 'Experience with cloud warehousing and analytics (ex. Snowflake, Redshift, BigQuery) and analytics. ', 'BI Data Engineer ', 'Data Warehouse and Business Intelligence experience. ', '\xa0 ']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
FCC Data Scientist,BankUnited,"Miami, FL",6 hours ago,99 applicants,"['', ' Advanced experience with data mining/analytical tools such as R and Python', ' Assist with the identification, evaluation, and development of controls to mitigate FCC risk and operational impacts.', ' Conduct assessments of models and provide reports detailing the current state of data feeds, rule output at current settings, and alert outputs at alternative settings.', ' Communicate effectively to different audiences, including both business and technical parties.', ' Create documentation and provide technical training to business users as needed (this includes training post model tuning deployments and on new enhancements).', ' Perform any other assignments as directed by manager.', ' Possess a general understanding of banking with respect to BSA/AML and Fraud risks.', ' Research, develop, prototype and test new models and their related inputs.', ' Strong knowledge of Structured Query Language (SQL), Oracle programming language, data mining techniques, and Business Intelligence Tools', ' Prepare reports in a manner that is clear and comprehensible to FCC supervisors/managers, internal auditors and regulatory examiners.', ' Maintain business definitions in the form of a data dictionary for all department managed models.', ' Communicate production issues with key stakeholders such as business lines, FCC management team, and the IT Department.', ""  Bachelor's degree in Computer Science, Management Information Systems or related field.  At least 3 years working with data modeling, software implementation, enhanced reporting analytics or related experience preferably with a financial institution.  Advanced experience with data mining/analytical tools such as R and Python  Strong knowledge of Structured Query Language (SQL), Oracle programming language, data mining techniques, and Business Intelligence Tools  Strong database skills, including working with advanced data sets, pivot tables, advanced database and statistical functions and methods  Experience visualizing data using tools such as Tableau  Experience with developing and implementing Fraud and BSA/AML risk strategies in decision engines, detection tools and onboarding platforms."", ' Perform model management reviews for the ongoing assessment of model suitability against emerging risk.', ' At least 3 years working with data modeling, software implementation, enhanced reporting analytics or related experience preferably with a financial institution.', ' Experience with developing and implementing Fraud and BSA/AML risk strategies in decision engines, detection tools and onboarding platforms.', "" Bachelor's degree in Computer Science, Management Information Systems or related field."", ' If necessary, effectively communicate with the business lines in order to obtain the necessary information and documentation to complete model improvements.', ' Utilize Oracle SQL to the extent of simulating model output.', "" Assist with data integrity and validation testing on FCC projects including software implementations, operational enhancements related to efficiency gains, and other special projects as needed including the coordination of software updates in collaboration with the Bank's IT Department and or Project Management Office."", ' Strong database skills, including working with advanced data sets, pivot tables, advanced database and statistical functions and methods', ' Identify potential logic deficiencies in model outputs through cross validation of external analyses ', ' Assist with annual FCC model tuning and optimization efforts in line with regulatory expectations to meet false-positive and detection rate criteria; performs quantitative analysis on the alert output of each tuning cycle (able to prepare reports detailing forecast results).', ' Support manager with resolving of open issues and/or defects involving applications used by the FCC Department including the identification of issues, tracking, escalation, testing, and resolution.', 'EDUCATION And/or EXPERIENCE', ' Experience visualizing data using tools such as Tableau', ""  Conduct assessments of models and provide reports detailing the current state of data feeds, rule output at current settings, and alert outputs at alternative settings.  Utilize Oracle SQL to the extent of simulating model output.  Identify potential logic deficiencies in model outputs through cross validation of external analyses   Assist with the identification, evaluation, and development of controls to mitigate FCC risk and operational impacts.  Research, develop, prototype and test new models and their related inputs.  Assist with annual FCC model tuning and optimization efforts in line with regulatory expectations to meet false-positive and detection rate criteria; performs quantitative analysis on the alert output of each tuning cycle (able to prepare reports detailing forecast results).  Perform model management reviews for the ongoing assessment of model suitability against emerging risk.  Assist with data integrity and validation testing on FCC projects including software implementations, operational enhancements related to efficiency gains, and other special projects as needed including the coordination of software updates in collaboration with the Bank's IT Department and or Project Management Office.  Support manager with resolving of open issues and/or defects involving applications used by the FCC Department including the identification of issues, tracking, escalation, testing, and resolution.  Maintain business definitions in the form of a data dictionary for all department managed models.  Prepare reports in a manner that is clear and comprehensible to FCC supervisors/managers, internal auditors and regulatory examiners.  Communicate production issues with key stakeholders such as business lines, FCC management team, and the IT Department.  Create documentation and provide technical training to business users as needed (this includes training post model tuning deployments and on new enhancements).  If necessary, effectively communicate with the business lines in order to obtain the necessary information and documentation to complete model improvements.  Handle a large workload with the ability to complete the tasks correctly and efficiently within the designated timeframes exercising discretion in setting priorities.  Communicate effectively to different audiences, including both business and technical parties.  Possess a general understanding of banking with respect to BSA/AML and Fraud risks.  Perform any other assignments as directed by manager. "", ' Handle a large workload with the ability to complete the tasks correctly and efficiently within the designated timeframes exercising discretion in setting priorities.']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Baker Tilly US,"Milwaukee, WI",11 hours ago,Be among the first 25 applicants,"['', 'You Will Enjoy This Role If You', ' You will be responsible for working within an agile environment to aid in the delivery of a managed service defined by the Architect of Project Manager. ', ' You are constantly looking to grow your education in technology and staying up to date with the latest trends. ', ' Ability to travel potentially up to 50% of the time. ', ' You have and are interested in maintaining different technical certifications. ', ' Outstanding customer service skills following proper business requirements and human resources expectations. ', ' Baker Tilly Annual Report 2018 ', ' Have at least 4 years of experience working within these technologies as well as other backend tech. ', 'Responsibilities', ' Disciplined to be able to work in a variety of business environments. ', ' Need help finding the right job? ', ' Utilize your scoping talents to help identify more areas within the business that our team can successfully impact for future projects. ', 'Successful Candidates Will Have', ' Have strong experience building out data warehouses. ', ' Apply different data modeling techniques and functional knowledge to both your internal team and external partners. ', 'What you will do:', ' Lead or support the day to day sprint activities provided to you by your pod leader. ', ' You are very well versed in BI and data analytics, SQL, the MS Stack, Azure and other cloud services. ', ' Work to understand business processes and possible improvements across an array of industries. ', ' You will be responsible for working within an agile environment to aid in the delivery of a managed service defined by the Architect of Project Manager.  Have strong experience building out data warehouses.  Lead or support the day to day sprint activities provided to you by your pod leader.  Work to understand business processes and possible improvements across an array of industries.  Utilize your scoping talents to help identify more areas within the business that our team can successfully impact for future projects. ', ' You enjoy being face to face with clients, understand who the key stakeholders on projects are, and positively influence the business need behind the use of data. ', ' Maintained a Bachelor’s degree in Computer Science, Engineering, Math, Information Technology, or other related discipline or 10 + years of commensurate experience. ', ' You enjoy sharing what you learned with the team and are willing to be a mentor to others. ', 'Qualifications', ' Enjoy building relationships with your colleagues through social activities and team outings supporting work-life balance. ', ' Have hands on experience in Microsoft business intelligence technologies that may include:  Have at least 4 years of experience working within these technologies as well as other backend tech.  Apply different data modeling techniques and functional knowledge to both your internal team and external partners.  Exhibit responsibility and accountability towards quality completion of projects and consistently hitting project timelines.  Strong verbal and written communication skills and are not ashamed to ask questions or raise concern on projects.  Outstanding customer service skills following proper business requirements and human resources expectations.  Disciplined to be able to work in a variety of business environments.  Ability to travel potentially up to 50% of the time.  Maintained a Bachelor’s degree in Computer Science, Engineering, Math, Information Technology, or other related discipline or 10 + years of commensurate experience. ', ' Exhibit responsibility and accountability towards quality completion of projects and consistently hitting project timelines. ', ' You are a team player that encourages collaboration and has an intrapreneurial mind. ', ' You are very well versed in BI and data analytics, SQL, the MS Stack, Azure and other cloud services.  You enjoy supporting a variety of industries and embedding yourself with client teams to work together to find a solution.  You enjoy being face to face with clients, understand who the key stakeholders on projects are, and positively influence the business need behind the use of data.  You are constantly looking to grow your education in technology and staying up to date with the latest trends.  You are a team player that encourages collaboration and has an intrapreneurial mind.  You enjoy sharing what you learned with the team and are willing to be a mentor to others.  You love to learn and enjoy putting yourself out of your comfort zone and have done or at least entertained the idea of speaking at tech events.  Enjoy building relationships with your colleagues through social activities and team outings supporting work-life balance.  You have and are interested in maintaining different technical certifications. ', ' You enjoy supporting a variety of industries and embedding yourself with client teams to work together to find a solution. ', 'Overview', ' You love to learn and enjoy putting yourself out of your comfort zone and have done or at least entertained the idea of speaking at tech events. ', ' Strong verbal and written communication skills and are not ashamed to ask questions or raise concern on projects. ', ' Have hands on experience in Microsoft business intelligence technologies that may include: ', 'It’s an exciting time to join Baker Tilly!']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Maxar Technologies,"Arlington, VA",17 hours ago,Be among the first 25 applicants,"['', 'Recent Experience With Some Of The Following Technologies', 'Day-to-day With Your Colleagues', 'Minimum Requirements', 'Preferred Qualifications']",Not Applicable,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
User Researcher ,Scopely,Los Angeles Metropolitan Area,10 hours ago,Be among the first 25 applicants,"['', 'Scrabble® GO, MARVEL Strike Force, Star Trek™ Fleet Command, Looney Tunes™ World of Mayhem, WWE Champions, The Walking Dead: Road To Survival™, YAHTZEE® With Buddies ', 'Scopely is a leading mobile games company home to many top-grossing, award-winning franchises including Scrabble® GO, MARVEL Strike Force, Star Trek™ Fleet Command, Looney Tunes™ World of Mayhem, WWE Champions, The Walking Dead: Road To Survival™, YAHTZEE® With Buddies and Wheel of Fortune®: Free Play, among others. Scopely creates rewarding, immersive games that empower a directed-by-consumer experience. Founded in 2011, Scopely is fueled by a world-class team and a proprietary technology platform that personalizes gameplay at scale across one of the most diversified portfolios in the west. Recognized in Fast Company’s ‘World’s Most Innovative Companies’ and #2 on Deloitte’s ‘Technology Fast 500’ as one of the fastest-growing companies in North America, Scopely has achieved more than $1 billion in lifetime revenue by creating game experiences that are an important part of people’s lives. Scopely has global operations in Los Angeles, Barcelona, Boulder, Dublin (DIGIT game studio), London and Tokyo, with additional studios in seven countries across four continents.\xa0For more information, visit scopely.com.', 'Attention to detail, intellectual curiosity, and a drive to answer complex questions', 'Partner with designers to generate solutions to identified issues', 'Oversee research on mobile games across their lifespan to drive greater understanding of our players and their experiences', 'Manage in-house usability research, including screener design, recruiting, script development, moderating, analysis, and presenting findings to stakeholders', 'Candidate information will be treated in accordance with our candidate privacy notice which can be found here: https://scopely.com/scopely-candidate-privacy-notice/', 'Familiarity with online survey software tools (e.g. Survey Gizmo, Qualtrics) and/or remote user testing platforms (e.g. Playtest Cloud, UserZoom, Usertesting.com) a plus', 'Wheel of Fortune®: Free Play', 'Scopely is looking for a user experience researcher to join our Research & Insights team. The User Researcher will be responsible for developing & conducting impactful research and delivering player and market insights that will help improve the quality and consumer relevance of our games.', 'Ability to translate research findings into actionable product improvements\xa0', 'Do you love mobile games? Are you curious about what motivates players in mobile games and do you have the drive to find the answers? Do you enjoy guiding teams with in-depth insights? Can you express the value of good UX and convince others of its importance? This is the research position you’ve been looking for!', 'Bachelor’s degree required; MBA/Masters/Ph.D. preferred', '\xa0', 'Oversee research on mobile games across their lifespan to drive greater understanding of our players and their experiencesDesign, implement and lead high-impact quantitative and qualitative research to support a number of cross-functional teams, including game design, UX design, product management, production, and marketingManage in-house usability research, including screener design, recruiting, script development, moderating, analysis, and presenting findings to stakeholdersManage quantitative research studies (e.g. consumer satisfaction surveys, research on game features and events, etc.), including survey development, data analysis, report creation, and presenting findings to stakeholdersGuide game development teams’ efforts based on player feedbackPartner with designers to generate solutions to identified issuesCollaborate with fellow researchers about new research techniques and methodologies', 'Experience designing and conducting survey research & usability research/playtests', 'Collaborate with fellow researchers about new research techniques and methodologies', 'Design, implement and lead high-impact quantitative and qualitative research to support a number of cross-functional teams, including game design, UX design, product management, production, and marketing', 'About Scopely:', 'Scopely is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, family or parental status, gender identity, veteran, or disability status, or other protected status.\xa0', 'Manage quantitative research studies (e.g. consumer satisfaction surveys, research on game features and events, etc.), including survey development, data analysis, report creation, and presenting findings to stakeholders', 'Experience with qualitative and quantitative research & analysis', 'Excellent interpersonal, analytical, and project management skills', 'Bachelor’s degree required; MBA/Masters/Ph.D. preferred2+ years of industry experience conducting research in mobile gaming space or a related field\xa0Experience with qualitative and quantitative research & analysisExperience designing and conducting survey research & usability research/playtestsAbility to translate research findings into actionable product improvements\xa0Excellent interpersonal, analytical, and project management skillsAbility to build relationships that allow you to influence cross-functional teams\xa0Attention to detail, intellectual curiosity, and a drive to answer complex questionsA passion for games (familiarity with mobile games required)Competency with SPSS, Tableau, or other analytics software packages a plusFamiliarity with online survey software tools (e.g. Survey Gizmo, Qualtrics) and/or remote user testing platforms (e.g. Playtest Cloud, UserZoom, Usertesting.com) a plus', 'Guide game development teams’ efforts based on player feedback', 'What will you do?', 'A passion for games (familiarity with mobile games required)', 'What do you need?', 'Competency with SPSS, Tableau, or other analytics software packages a plus', '2+ years of industry experience conducting research in mobile gaming space or a related field\xa0', 'Ability to build relationships that allow you to influence cross-functional teams\xa0']",Associate,Full-time,Information Technology,Entertainment,2020-11-05 11:32:32
"People Research Scientist, Performance Management (Contract)",Twitter,"San Francisco, CA",10 hours ago,Be among the first 25 applicants,"['', 'Job Description', 'Competency Modeling - Ability to lead stakeholders through competency model development and validation. ', 'Applied Research Design - Ability to craft well-designed and useful analyses including study design, sampling, hypothesis generation, data collection methods, and implications.', 'Presentation and Communication - Ability to present data and results, explain theory, strategy and findings in an easy to understand way to technical and non-technical audiences. ', 'Measurement - Knowledge of psychometric best practices for assessment development, validation, reliability assessment.', 'Knowledge, Skills, And Abilities', 'Applied Research Design - Ability to craft well-designed and useful analyses including study design, sampling, hypothesis generation, data collection methods, and implications.Statistical Ability - Ability to analyze and interpret research results. Identify relationships and trends in data, as well as any factors that could affect the results of research. Measurement - Knowledge of psychometric best practices for assessment development, validation, reliability assessment.Competency Modeling - Ability to lead stakeholders through competency model development and validation. Appraisal System Design - Knowledge of best practices for designing and implementing appraisal systems, including promotion and performance. Data Visualization - Ability to display data and results visually, for interpretation ease.Presentation and Communication - Ability to present data and results, explain theory, strategy and findings in an easy to understand way to technical and non-technical audiences. Qualitative Analysis - Experience with qualitative methods a plus.', 'Qualitative Analysis - Experience with qualitative methods a plus.', 'Appraisal System Design - Knowledge of best practices for designing and implementing appraisal systems, including promotion and performance. ', 'Statistical Ability - Ability to analyze and interpret research results. Identify relationships and trends in data, as well as any factors that could affect the results of research. ', 'Data Visualization - Ability to display data and results visually, for interpretation ease.', 'Company Description']",Not Applicable,Contract,Other,Internet,2020-11-05 11:32:32
Scientist - Sensory & Perception,Impossible Foods,"Redwood City, CA",12 hours ago,Be among the first 25 applicants,"['', 'MS/Ph.D. in Food Science, Biochemistry, Material Science, Chemical Engineering, Chemistry or similar field.', 'Ability to continuously challenge assumptions to seek innovative solutions.', 'Proactively collaborate cross-functionally and manage multiple projects that adhere to fast timelines.', 'Be the lead perceptual scientist on research and product development projects that result in the creation of new delicious and nutritious plant-based meat products.Research and develop new testing methodologies.Design, conduct, analyze and interpret perceptual experiments.Proactively collaborate cross-functionally and manage multiple projects that adhere to fast timelines.Align day to day tasks with big picture goals.Provide mentorship and managerial guidance, as needed.', 'Align day to day tasks with big picture goals.', 'You Have', 'Self starter with the ability to thrive and adapt in a dynamic and fast-paced environment.', 'Excellent communication skills.', 'Design, conduct, analyze and interpret perceptual experiments.', '3-5+ years of experience.', 'Strong, creative and collaborative problem solving.', 'You Will', 'Research and develop new testing methodologies.', 'Provide mentorship and managerial guidance, as needed.', 'Experience in statistical analyses, including data programming.', 'Passion for creating new products that meet consumers needs.', 'Be the lead perceptual scientist on research and product development projects that result in the creation of new delicious and nutritious plant-based meat products.', 'MS/Ph.D. in Food Science, Biochemistry, Material Science, Chemical Engineering, Chemistry or similar field.3-5+ years of experience.Experience in statistical analyses, including data programming.Passion for creating new products that meet consumers needs.Strong, creative and collaborative problem solving.Self starter with the ability to thrive and adapt in a dynamic and fast-paced environment.Excellent communication skills.Ability to continuously challenge assumptions to seek innovative solutions.']",Not Applicable,Full-time,Research,Food & Beverages,2020-11-05 11:32:32
Data Engineer,Guardian Life,Buffalo-Niagara Falls Area,21 hours ago,26 applicants,"['', 'Develop and maintain data pipelines and build out new API integrations to support continuing increases in data volume and complexity. ', 'Review and understand data requirements for operational and analytic projects, with a special emphasis on developing scalable data solutions involving data integration, reporting, analytics and data warehousing. ', 'Experience with big data tools Athena, Redshift, HIVE, Presto, Spark, Kafka, etc. Experience with AWS Glue, Redshift, Athena, Parquet file formats, Snowflake, or data lake architecture is a plus. ', '  Review data sources and assess data quality; determine the appropriate data inputs, outputs and integration rules and strategy. Create functional design specifications to be used by the developers. Advanced problem solving, data analytics and troubleshooting skills with the ability to identify and solve complex business needs. Exposure to Data Integration tools like SSIS, Syncsort and Informatica.   ', 'Your Responsibilities', 'Position Objective', 'Data Analysis & Design:\xa0\xa0', 'Collaborate with business and IT partners to refine data requirements and perform data analysis activities including data profiling, creation of data dictionaries, data transformation rules and integration requirements. ', 'Interface with business units, internal IT, customers and management in the performance of duties. Experience with or knowledge of Agile Software Development methodologies. ', 'Interface with business units, internal IT, customers and management in the performance of duties. Experience with or knowledge of Agile Software Development methodologies.  ', '\xa0', '  Experience with BI Solutions like Tableau, Business Objectives, and SSRS for distribution of data through interactive dashboards and reports for projects, management and other interested parties throughout the organization.   ', 'Review data sources and assess data quality; determine the appropriate data inputs, outputs and integration rules and strategy. Create functional design specifications to be used by the developers. Advanced problem solving, data analytics and troubleshooting skills with the ability to identify and solve complex business needs. Exposure to Data Integration tools like SSIS, Syncsort and Informatica. ', 'Review data sources and assess data quality; determine the appropriate data inputs, outputs and integration rules and strategy. Create functional design specifications to be used by the developers. Advanced problem solving, data analytics and troubleshooting skills with the ability to identify and solve complex business needs. Exposure to Data Integration tools like SSIS, Syncsort and Informatica.  ', 'Integrate data from a variety of systems into refined data products available to the rest of the enterprise to support both real-time and batch processing. ', '  Review and understand data requirements for operational and analytic projects, with a special emphasis on developing scalable data solutions involving data integration, reporting, analytics and data warehousing.  Collaborate with business and IT partners to refine data requirements and perform data analysis activities including data profiling, creation of data dictionaries, data transformation rules and integration requirements.  Develop and maintain data pipelines and build out new API integrations to support continuing increases in data volume and complexity.  Integrate data from a variety of systems into refined data products available to the rest of the enterprise to support both real-time and batch processing.  Implement processes and systems to monitor data quality, ensuring production data accuracy and assist in data analysis to troubleshoot and resolve data issues   ', 'Experience with BI Solutions like Tableau, Business Objectives, and SSRS for distribution of data through interactive dashboards and reports for projects, management and other interested parties throughout the organization.  ', '  Data engineering abilities and expertise in using SQL, DDL/DML, performance tuning, data modelling and data warehousing techniques. Knowledge of Python/Java with an ability to code in other web languages.  Experience working with relational/non-relational databases and understanding of storage technologies like MySQL, Aurora PostgreSQL, SQL Server, Oracle, DB2. Work with DBA and other staff as necessary, to instantiate physical databases based on the models.   ', 'Cloud Data Technologies:\xa0', 'Implement processes and systems to monitor data quality, ensuring production data accuracy and assist in data analysis to troubleshoot and resolve data issues ', 'Experience working with cloud services and cloud data warehouses. ', 'Experience with BI Solutions like Tableau, Business Objectives, and SSRS for distribution of data through interactive dashboards and reports for projects, management and other interested parties throughout the organization. ', 'Experience working with cloud services and cloud data warehouses.  Experience with big data tools Athena, Redshift, HIVE, Presto, Spark, Kafka, etc. Experience with AWS Glue, Redshift, Athena, Parquet file formats, Snowflake, or data lake architecture is a plus.  ', 'Review and understand data requirements for operational and analytic projects, with a special emphasis on developing scalable data solutions involving data integration, reporting, analytics and data warehousing.  Collaborate with business and IT partners to refine data requirements and perform data analysis activities including data profiling, creation of data dictionaries, data transformation rules and integration requirements.  Develop and maintain data pipelines and build out new API integrations to support continuing increases in data volume and complexity.  Integrate data from a variety of systems into refined data products available to the rest of the enterprise to support both real-time and batch processing.  Implement processes and systems to monitor data quality, ensuring production data accuracy and assist in data analysis to troubleshoot and resolve data issues  ', 'Experience working with relational/non-relational databases and understanding of storage technologies like MySQL, Aurora PostgreSQL, SQL Server, Oracle, DB2. Work with DBA and other staff as necessary, to instantiate physical databases based on the models. ', 'Data Engineering: ', 'Data engineering abilities and expertise in using SQL, DDL/DML, performance tuning, data modelling and data warehousing techniques. Knowledge of Python/Java with an ability to code in other web languages.  Experience working with relational/non-relational databases and understanding of storage technologies like MySQL, Aurora PostgreSQL, SQL Server, Oracle, DB2. Work with DBA and other staff as necessary, to instantiate physical databases based on the models.  ', 'Information Dissemination:\xa0', 'Cross-Organizational Coordination:', 'Data engineering abilities and expertise in using SQL, DDL/DML, performance tuning, data modelling and data warehousing techniques. Knowledge of Python/Java with an ability to code in other web languages. ', 'Do you want to be part of a collaborative Enterprise Data team? ', '  Experience working with cloud services and cloud data warehouses.  Experience with big data tools Athena, Redshift, HIVE, Presto, Spark, Kafka, etc. Experience with AWS Glue, Redshift, Athena, Parquet file formats, Snowflake, or data lake architecture is a plus.   ', 'Reporting Relationships', '  Interface with business units, internal IT, customers and management in the performance of duties. Experience with or knowledge of Agile Software Development methodologies.   ']",Entry level,Full-time,Information Technology,Financial Services,2020-11-05 11:32:32
Senior Data Scientist,Lawrence Harvey,New York City Metropolitan Area,19 hours ago,55 applicants,"['Healthcare Investment Firm ', '', 'BS or MS in a highly quantitative field (Computer Sciences, Electrical Engineering, Math or Engineering)', 'BS or MS in a highly quantitative field (Computer Sciences, Electrical Engineering, Math or Engineering)Experience with large scale structured and unstructured healthcare data4+ years of experience in a similar role building world class modelsExtensive experience in python and related libraries.Have worked in a cloud extensive environment', 'This role is highly competitive and is already conducting interviews. Please apply directly through LinkedIn.', 'Healthcare Investment Firm', 'Have worked in a cloud extensive environment', 'Requirements', 'This Hedge Fund that operates exclusively in the Healthcare & Analytics space is looking to bring on an experienced Data Scientist to their growing Analytics team.\xa0This firm is truly unique as they work not only across public companies but also act as an investment partner to both private companies and specific research initiatives with the goal of advancing healthcare for all. Ideal candidates will have experienced within on healthcare vertical (Claims data, life sciences or epidemiology) Candidates will not only have to posses top-tier technical abilities but an attitude and work ethic that thrives in a horizontal highly-collaborative environment.', 'Extensive experience in python and related libraries.', '4+ years of experience in a similar role building world class models', 'Senior Data Scientist | NYC', 'You will across the analytics business along with the portfolio teams to build reports in addition to the validation and communication of the business-critical information contained in the reports. As stated previously this is a horizontal organization so you will work directly with firm leadership and other end-users to ensure the information process is transparent and crystal clear.', 'Experience with large scale structured and unstructured healthcare data']",Mid-Senior level,Full-time,Health Care Provider,Staffing and Recruiting,2020-11-05 11:32:32
Data Engineer ,Johnson & Johnson,"Titusville, NJ",4 hours ago,Be among the first 25 applicants,"['', 'Job Description', ' Working experience in data science projects using predictive technologies, data mining and/or text mining of datasets in the clinical or healthcare domain is preferred.', ' Bachelors Degree in Bioinformatics, Statistics, Computer Science, Information Technology, Operation Research or a related discipline is required. Familiarity with machine learning techniques is required. Proficient with one or more programming language such as SQL, Python, R, or Java is required. Working knowledge of a cloud platform such as AWS is desirable. Experience in the use of a data science workbench is desirable. Working experience in data science projects using predictive technologies, data mining and/or text mining of datasets in the clinical or healthcare domain is preferred. Excellent communication, interpersonal, and written skills are required.', ' Bachelors Degree in Bioinformatics, Statistics, Computer Science, Information Technology, Operation Research or a related discipline is required.', ' Working knowledge of a cloud platform such as AWS is desirable.', 'Qualifications', ' Excellent communication, interpersonal, and written skills are required.', ' Implement data & analytics engineering strategy for R&D Data Science community. Partner closely with Janssen R&D IT and external partners for implementation and execution Work closely with R&D data scientists to design, build and implement data solutions to support R&D Data Science initiative with a focus on research and translational data Introduce/Lead/Participate in evaluations of algorithms, tools and technologies that enable R&D data science initiative', ' Experience in the use of a data science workbench is desirable.', ' Work closely with R&D data scientists to design, build and implement data solutions to support R&D Data Science initiative with a focus on research and translational data', ' Familiarity with machine learning techniques is required.', ' Implement data & analytics engineering strategy for R&D Data Science community. Partner closely with Janssen R&D IT and external partners for implementation and execution', ' Introduce/Lead/Participate in evaluations of algorithms, tools and technologies that enable R&D data science initiative', ' Proficient with one or more programming language such as SQL, Python, R, or Java is required.', 'The Data Engineer Will']",Not Applicable,Full-time,Information Technology,Hospital & Health Care,2020-11-05 11:32:32
Data Engineer,CRST International,"Cedar Rapids, IA",11 hours ago,Be among the first 25 applicants,"['', ' Build and maintain data pipelines to extract, transform, and load data from various data systems into enterprise data systems ', ' Project management and organizational skills ', 'Apache Airflow', ' Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency , and other key business performance metrics ', 'Apache Ranger', ' Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs ', ' Kubernetes ', 'Job Overview', ' 3+ years working as a Data Engineer ', ' Experience with data profiling and data governance ', 'Minimum Qualifications For Data Engineer', ' Experience supporting and working with cross-functional teams in a dynamic environment ', '  Bachelor’s degree from a quantitative field (Computer Science, Informatics, Engineering, etc.)   2+ years working as a Data Engineer or Software Engineer   Experienced with one or more of the following programming languages: Python, Java, C, C++   Experienced with automated testing - unit tests, integration tests, etc.   Analytically driven   Self-motivated and a willingness to learn   Project management and organizational skills   Experienced in collecting and manipulating both relational and non-relational data in various systems including databases and web APIs   A successful history of manipulating, processing and extracting value from large disconnected datasets   Experience supporting and working with cross-functional teams in a dynamic environment  ', ' Assemble large, complex data sets that meet functional / non-functional business requirements ', ' Analytically driven ', ' Self-motivated and a willingness to learn ', 'Data Engineer Job Description', '  Build and maintain data pipelines to extract, transform, and load data from various data systems into enterprise data systems   Architect, implement, and maintain infrastructure for the enterprise data lake and warehouse   Assemble large, complex data sets that meet functional / non-functional business requirements   Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency , and other key business performance metrics   Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs   Work with data and analytics experts to strive for greater functionality in our data systems  ', 'Apache Atlas', ' Experienced with one or more of the following programming languages: Python, Java, C, C++ ', ' Experienced with automated testing - unit tests, integration tests, etc. ', '  3+ years working as a Data Engineer   Experience building and optimizing data pipelines, architectures, and data sets   Experience establishing and maintaining big data infrastructure within a cloud environment (AWS, Azure, etc.)   Continuous deployment and continuous integration   Experience with processing near real time data   Experience with data profiling and data governance   Experience with the following Python Apache Airflow Apache Spark (PySpark) Apache Presto Apache Hive Apache Ranger Apache Atlas Apache Hue  Kubernetes    ', 'Apache Presto', ' 2+ years working as a Data Engineer or Software Engineer ', ' Work with data and analytics experts to strive for greater functionality in our data systems ', ' Continuous deployment and continuous integration ', 'Preferred Qualifications For Data Engineer', ' Experienced in collecting and manipulating both relational and non-relational data in various systems including databases and web APIs ', ' Experience building and optimizing data pipelines, architectures, and data sets ', 'Python', 'Apache Spark (PySpark)', ' Python Apache Airflow Apache Spark (PySpark) Apache Presto Apache Hive Apache Ranger Apache Atlas Apache Hue  Kubernetes  ', ' Architect, implement, and maintain infrastructure for the enterprise data lake and warehouse ', ' Bachelor’s degree from a quantitative field (Computer Science, Informatics, Engineering, etc.) ', ' Experience establishing and maintaining big data infrastructure within a cloud environment (AWS, Azure, etc.) ', 'Apache Hive', 'Apache Hue', ' Experience with the following Python Apache Airflow Apache Spark (PySpark) Apache Presto Apache Hive Apache Ranger Apache Atlas Apache Hue  Kubernetes   ', ' Experience with processing near real time data ', ' A successful history of manipulating, processing and extracting value from large disconnected datasets ']",Entry level,Full-time,Information Technology,Transportation/Trucking/Railroad,2020-11-05 11:32:32
Research Scientist,Patel Consultants Corporation,"Ridgefield, CT",20 hours ago,Be among the first 25 applicants,"['', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0IMMUNOASSAYS', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0CELL CULTURE', 'Degree Required:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0MICROSCOPE', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0PROTEIN ASSAYS', 'Experience Required: ', 'Scientist II', 'Duties: Responsible for culture, maintenance and storage of mammalian cells and\xa0developing in vitro models for inflammatory diseases.\xa0Experience with induced pluripotent stem cells and adult stem cells is a plus but not required. In addition to cell culture, you will be responsible for performing standard cell and molecular biology techniques.\xa0These include experiments such as cell viability, RNA extraction, qPCR,\xa0immunoblotting, immunostaining, ELISA and microscopy.', 'Familiar with a variety of cell and molecular biology techniques. Minimum 1 year industry or academic work experience is required.\xa0Excellent organizational skills, data analysis/interpretation and a keen sense of sterile technique in the laboratory are required.', ""Degree Required: Master's Degree"", 'Required Skills:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0QPCR']",Associate,Contract,Research,Staffing and Recruiting,2020-11-05 11:32:32
Senior Game Data Scientist,Zynga,"Austin, TX",12 hours ago,Be among the first 25 applicants,"['', 'Position at Zynga', 'Work closely with game teams to design, test, verify and implement machine learning models with Zynga’s games that impact the daily life of millions of users', 'Specifically, you may encounter projects focused on: modeling the Poker economy through simulation, personalizing our in-game store using recommendation algorithms, or combating fraud and abusive behavior through near-real time interventions.', 'Fluent in SQL, Python, and other programming languages; Experience in applying machine learning on large datasets, preferably using Spark on Databricks', 'Generous Paid Maternity/Paternity leave', 'Open vacation policy for all full time employees', 'Flexible working hours on many teams', 'Design and evaluate novel scalable approaches to experiments for gameplay, using our in-house experimentation platform', 'Full medical, dental, vision benefits as well as life insurance', 'Responsibilities', 'Description', 'Demonstrated experience with some or all of the following: machine learning, data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualization', 'BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred', 'Zynga Stock RSUs and Bonus Plan', 'Leverage our modern tech stack, AWS (Redshift & Kinesis), DataBricks and PySpark, Airflow, and Tableau to identify opportunities to improve the experience that Zynga provides to its playersApply predictive modeling and Data Mining techniques for a variety of user modeling tasks within Zynga’s Game NetworkWork closely with game teams to design, test, verify and implement machine learning models with Zynga’s games that impact the daily life of millions of usersDesign and evaluate novel scalable approaches to experiments for gameplay, using our in-house experimentation platformSpecifically, you may encounter projects focused on: modeling the Poker economy through simulation, personalizing our in-game store using recommendation algorithms, or combating fraud and abusive behavior through near-real time interventions.', 'Apply predictive modeling and Data Mining techniques for a variety of user modeling tasks within Zynga’s Game Network', '3+ years of work experience in data science, machine learning or analytics roles', 'BS in Computer Science, Math, Statistics, Economics, or other quantitative field; Masters or PhD strongly preferred3+ years of work experience in data science, machine learning or analytics rolesDemonstrated experience with some or all of the following: machine learning, data mining, predictive modeling, statistics, experimental design, computational analytics, econometric modeling, data visualizationFluent in SQL, Python, and other programming languages; Experience in applying machine learning on large datasets, preferably using Spark on DatabricksStrong written and oral communication skills', 'Work alongside driven individuals towards a common goal', 'Leverage our modern tech stack, AWS (Redshift & Kinesis), DataBricks and PySpark, Airflow, and Tableau to identify opportunities to improve the experience that Zynga provides to its players', 'Zynga Stock RSUs and Bonus PlanFull medical, dental, vision benefits as well as life insuranceGenerous Paid Maternity/Paternity leaveOpen vacation policy for all full time employeesFlexible working hours on many teamsWork alongside driven individuals towards a common goal', 'Required Skills And Experience', 'What We Offer You', 'Strong written and oral communication skills']",Associate,Full-time,Other,Computer Games,2020-11-05 11:32:32
"Atmospheric Data Scientist (Python) - Python, Signal Processing",CyberCoders,"Denver, CO",22 hours ago,Be among the first 25 applicants,"['', ' Remote sensing development and applications', 'Advanced Tier Skill Set', ' FIR and IIR filter design and implementation in software', ' Relocation reimbursement', ' Developing a state-of-the-art, global, atmospheric/geophysical remote sensing system using a constellation of smallsats focused on weather, space weather and', ' 4+ years of scientific Python using numpy, Pandas, SciPy, Matplotlib OR similar applications', ' US Citizen / permanent resident', ' Masters in Engineering (Atmospheric/Geo Science, Computer Science, Physics, or Mathematics) 4+ years of experience in scientific data processing OR PhD with 2+ years experience Focus on signal processing: Experience w/ software-defined radio or similar complex signal processing applications Least squares problem solving and linear algebra 4+ years of scientific Python using numpy, Pandas, SciPy, Matplotlib OR similar applications US Citizen / permanent resident', ' Experience w/ software-defined radio', ' Vacation/PTO', ' Apply directly to this link w/ an updated resume & answer all skills questions', ' Coherent electromagnetic signal propagation', ' Focus on signal processing:', ' Experience in an cloud-hosted software environment', ' Design / code / test / debug new & existing features in a cloud-hosted data processing pipeline', ' Highly-technical scientific software scientist/engineer that will be building game changing technology from the ground up Using scientific data processing skill set to develop the next generation of atmospheric radio-occultation processing software Design / code / test / debug new & existing features in a cloud-hosted data processing pipeline Collaborate w/ software-defined radio team to design, build, and refactor APIs according to feature requirements Participate in agile planning & code reviews', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Polynomial interpolation, extrapolation, and time-series resampling', ' Publications in a related field', ' Experience with GNSS or radar applications Coherent electromagnetic signal propagation Experience w/ software-defined radio RDBMS experience, especially SQLite and PostgreSQL C++ 11 or newer, including PyBind11, FFTW, Eigen or related scientific data processing libraries Experience in an cloud-hosted software environment Publications in a related field', 'Minimum Skill Set', ' Equity in venture-backed startup', ' C++ 11 or newer, including PyBind11, FFTW, Eigen or related scientific data processing libraries', ' Highly-technical scientific software scientist/engineer that will be building game changing technology from the ground up', 'Experience working with GNSS radio occultation data', ' Email me an updated resume, salary requirements and interview availability to josh.reifman@cybercoders.com', ' Experience with GNSS or radar applications', ' Experience w/ software-defined radio or similar complex signal processing applications', ' Polynomial interpolation, extrapolation, and time-series resampling Remote sensing development and applications FIR and IIR filter design and implementation in software Linux operating environment, both locally and in the cloudExperience working with GNSS radio occultation data', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JR12-1606641 -- in the email subject line for your application to be considered.***', ' Masters in Engineering (Atmospheric/Geo Science, Computer Science, Physics, or Mathematics)', ' Least squares problem solving and linear algebra', ' Medical/Dental/Vision', ' 4+ years of experience in scientific data processing OR PhD with 2+ years experience', ' Participate in agile planning & code reviews', ' Equity in venture-backed startup Bonus Vacation/PTO Medical/Dental/Vision Relocation reimbursement', ' Linux operating environment, both locally and in the cloud', 'Bonus Skill Set', 'Email Your Resume In Word To', ' Bonus', ' Collaborate w/ software-defined radio team to design, build, and refactor APIs according to feature requirements', ' RDBMS experience, especially SQLite and PostgreSQL', 'Your Right to Work', ' Using scientific data processing skill set to develop the next generation of atmospheric radio-occultation processing software']",Mid-Senior level,Full-time,Engineering,Airlines/Aviation,2020-11-05 11:32:32
"Software Engineer, New Grad",Materialize,"New York, NY",22 hours ago,Over 200 applicants,"['', ' Bonuses ', ' You Should Have ', 'Strong written and verbal communications skills. ', 'Significant internship experience or open-source development experience.', 'Work on technical challenges ranging from parsing and evaluating SQL statement to solving challenging distributed systems problems. ', 'B.S., M.S., or Ph.D in Computer Science. Timely and Differential Dataflow are built upon years of academic and industrial research, and you’ll need to become familiar with the research areas.', 'B.S., M.S., or Ph.D in Computer Science. Timely and Differential Dataflow are built upon years of academic and industrial research, and you’ll need to become familiar with the research areas.Significant internship experience or open-source development experience.Coursework in databases, compilers, distributed systems, and operating systems.Ability to work both autonomously and collaboratively, as needed.Strong written and verbal communications skills. ', 'Knowledge of SQL databases.', 'Iterate on Materialize to discover and adapt to customer needs. ', ""Collaborate with other engineers and product management, as well as Materialize's founders."", ""Design, implement, ship, and maintain substantial parts of Materialize in Rust.Work on technical challenges ranging from parsing and evaluating SQL statement to solving challenging distributed systems problems. Iterate on Materialize to discover and adapt to customer needs. Collaborate with other engineers and product management, as well as Materialize's founders."", ' 401k', 'Industry or research experience in compilers.', 'Knowledge of streaming processing.', ' You Will ', 'Experience implementing data infrastructure.', 'Design, implement, ship, and maintain substantial parts of Materialize in Rust.', 'Ability to work both autonomously and collaboratively, as needed.', ' 4 weeks of vacation', 'Coursework in databases, compilers, distributed systems, and operating systems.', 'Experience with Rust.', 'Knowledge of streaming processing.Knowledge of SQL databases.Experience implementing data infrastructure.Experience with Rust.', ' Flexible working hours', ' 100% covered health insurance for you and all your dependents', ' Competitive equity package']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Robert Half,"Columbia, MD",,N/A,"['', 'Description', 'Requirements']",Entry level,Temporary,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Client Company,"San Francisco, CA",8 hours ago,Be among the first 25 applicants,"['', 'Follows automate-first/automate-everything philosophy.', 'Perform tasks efficiently and work together with team to ensure project success.', 'Good knowledge of secure coding practices is a plus.', '5+ years IT-Software/ Software products.', 'Duties And Responsibilities', 'Applied knowledge of Object Orientated programming concept (OOPS), Operating System (OS) concept.', 'Bachelors in Science - Computer Science or equivalent.', 'Hands on in multiple programming paradigms, not limited to Object Oriented.', 'AWS Technologies - S3, AWS Glue, RDS, lambda, cloud watch, etc.', 'Participate in integrated test sessions of components and subsystems on test and production servers.', 'Experienced across programming languages, patterns and data structures.', 'Experienced across programming languages, patterns and data structures.Adequate hands on experience with data modeling, locks, database concurrency.Applied knowledge of Object Orientated programming concept (OOPS), Operating System (OS) concept.Proficient with software Architecture, design patterns and strong demonstrated experience in building frameworks.Strong computer science background including distributed computing.Good knowledge of software development tools and methodologies.Good knowledge of secure coding practices is a plus.Thorough understanding and hands-on experience in the development of all layers of enterprise applications to analyze system scalability, integration, and performance issues as well as internationalization utilizing either Unicode and/or multi-byte databases.Good exposure of software development life cycle, development process flow and their tools usage.Must be aware of Agile, Incremental or spiral development methodology.Excellent diagnostic and troubleshooting skills, problem solving, and an ability to learn quickly.Domain Knowledge in Financial Service is a plus.', 'Work independently to implement solutions on multiple platform (DEV, QA, UAT, PROD).', 'Adequate hands on experience with data modeling, locks, database concurrency.', '5+ years IT-Software/ Software products.Bachelors in Science - Computer Science or equivalent.Experience with following Data Engineering languages and technologies - AWS Glue, Python, PySpark, Spark, Informatica, Git, JenkinsCI.SQL Server, ORACLE, PostgreSQL, Stored Procedure.AWS Technologies - S3, AWS Glue, RDS, lambda, cloud watch, etc.Datawarehouse concepts.Kafka and Spark Streaming is nice to have.', 'Support management of the team’s technical infrastructure (e.g., repository, build system, testing system) under guidance from the systems engineer or another project leader.', 'Develops code and test artifacts that reuse subroutines or objects, is well structured, backed by automated tests, includes sufficient comments and is easy to maintain.', 'Datawarehouse concepts.', 'Good exposure of software development life cycle, development process flow and their tools usage.', 'Good knowledge of software development tools and methodologies.', 'Thorough understanding and hands-on experience in the development of all layers of enterprise applications to analyze system scalability, integration, and performance issues as well as internationalization utilizing either Unicode and/or multi-byte databases.', 'Excellent diagnostic and troubleshooting skills, problem solving, and an ability to learn quickly.', 'Must be aware of Agile, Incremental or spiral development methodology.', 'Implement and debug subsystems/micro service and components.', 'Work with the business and IT team to understand business problems, and to design, implement, and deliver an appropriate solution using Agile methodology across the larger program.', 'Proficient with software Architecture, design patterns and strong demonstrated experience in building frameworks.', 'Strong computer science background including distributed computing.', 'Required Skills/Experience', 'Determine and communicate the implications of system-level decisions on subsystems and Components, and help determine how best to mitigate or take advantage of these implications.', 'Kafka and Spark Streaming is nice to have.', 'Job Description', 'Provide technical direction, leadership, and reviews to other engineers working on the same project.', 'Preferred Skills/Experience', 'Domain Knowledge in Financial Service is a plus.', 'SQL Server, ORACLE, PostgreSQL, Stored Procedure.', 'Experience with following Data Engineering languages and technologies - AWS Glue, Python, PySpark, Spark, Informatica, Git, JenkinsCI.', 'Work with the business and IT team to understand business problems, and to design, implement, and deliver an appropriate solution using Agile methodology across the larger program.Develops code and test artifacts that reuse subroutines or objects, is well structured, backed by automated tests, includes sufficient comments and is easy to maintain.Work independently to implement solutions on multiple platform (DEV, QA, UAT, PROD).Provide technical direction, leadership, and reviews to other engineers working on the same project.Implement and debug subsystems/micro service and components.Participate in integrated test sessions of components and subsystems on test and production servers.Follows automate-first/automate-everything philosophy.Determine and communicate the implications of system-level decisions on subsystems and Components, and help determine how best to mitigate or take advantage of these implications.Perform tasks efficiently and work together with team to ensure project success.Support management of the team’s technical infrastructure (e.g., repository, build system, testing system) under guidance from the systems engineer or another project leader.Hands on in multiple programming paradigms, not limited to Object Oriented.']",Entry level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Research Scientist, ASIC & VLSI",NVIDIA,"Santa Clara, CA",8 hours ago,Be among the first 25 applicants,"['', 'Ph.D. in EE or related with a strong research record, well referenced publications and / or patents is required.', 'Collaborate on the development of research prototype testchips.', 'Collaborate with circuits and architecture team members in research and product teams.', 'Contribute to novel research advancing the state-of-the-art in machine learning accelerator design.', 'Experience with C, C++, Python, and scripting languages required; experience with machine learning frameworks such as PyTorch or Tensorflow preferred.', 'Ph.D. in EE or related with a strong research record, well referenced publications and / or patents is required.Recent PhD graduates (Research Scientist) or candidates with more years of relevant work or research experience (Senior Research Scientists) will be considered for the open position.You should display a strong background in VLSI, circuits, IC design, computer micro-architecture fundamentals, machine learning, EDA algorithms and software development.Experience with C, C++, Python, and scripting languages required; experience with machine learning frameworks such as PyTorch or Tensorflow preferred.Strong interpersonal skills needed. Being a creative and dynamic presenter is a huge advantage.', 'Publish and present your original research, speak at conferences and events', 'What You’ll Be Doing', 'You should display a strong background in VLSI, circuits, IC design, computer micro-architecture fundamentals, machine learning, EDA algorithms and software development.', 'We are now looking for a Research Scientist - ASIC & VLSI', 'Develop and apply machine learning and GPU acceleration to EDA software and ASIC and VLSI design tool flows.', 'Strong interpersonal skills needed. Being a creative and dynamic presenter is a huge advantage.', 'What We Need To See', 'Research and develop creative and innovative EDA software and algorithms, ASIC and VLSI design techniques, machine learning accelerator approaches, and/or novel digital VLSI circuits.', 'Recent PhD graduates (Research Scientist) or candidates with more years of relevant work or research experience (Senior Research Scientists) will be considered for the open position.', 'Collaborate with external researchers and a diverse set of internal product teams.', 'Research and develop creative and innovative EDA software and algorithms, ASIC and VLSI design techniques, machine learning accelerator approaches, and/or novel digital VLSI circuits.Contribute to novel research advancing the state-of-the-art in machine learning accelerator design.Collaborate on the development of research prototype testchips.Develop and apply machine learning and GPU acceleration to EDA software and ASIC and VLSI design tool flows.Collaborate with circuits and architecture team members in research and product teams.Publish and present your original research, speak at conferences and eventsCollaborate with external researchers and a diverse set of internal product teams.']",Not Applicable,Full-time,Other,Computer Hardware,2020-11-05 11:32:32
Principal Data Scientist | Healthcare ,Intelletec,San Francisco Bay Area,17 hours ago,27 applicants,"['', ""Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Economics, Physics, Engineering, or related discipline. Masters degree or Ph.D. preferred.Experience building machine learning pipelines (e.g. Airflow or Prefect) and deploying them to the cloud (e.g. AWS, GCP, or Azure).Thorough understanding of machine learning engineering principles such as distributed/parallel computing paradigms and advanced data structures.Substantive experience working with tera-scale data in a distributed computing environment.\xa0Highly proficient in Python, Hive, and Git. Scala is a plus.Familiarity with modern libraries such as Spark, Dask, Arrow, and Rapids.Track record of technical innovation and implementing novel machine learning techniques.Superior ability to communicate technical ideas and results to non-technical clients in written and verbal form."", 'Highly proficient in Python, Hive, and Git. Scala is a plus.', 'Experience building machine learning pipelines (e.g. Airflow or Prefect) and deploying them to the cloud (e.g. AWS, GCP, or Azure).', 'Superior ability to communicate technical ideas and results to non-technical clients in written and verbal form.', '\xa0', 'Lead development and execution of software solutions involving domain-specific analytics frameworks and scalable machine learning systems.', 'Provide strategic leadership for the identification of opportunities and the development of solutions related to the data science lifecycle.', 'You will be a full-stack data scientist or ML engineer with 6-10 years or hands-on experience in applied predictive modeling and software engineering.\xa0', 'Use data to inform strategic and design decision making in addition to measuring performance and outcomes to demonstrate efficacy.\xa0', 'Substantive experience working with tera-scale data in a distributed computing environment.\xa0', 'Provide mentoring to junior data scientists throughout the organization.', 'Familiarity with modern libraries such as Spark, Dask, Arrow, and Rapids.', 'Provide strategic leadership for the identification of opportunities and the development of solutions related to the data science lifecycle.Lead development and execution of software solutions involving domain-specific analytics frameworks and scalable machine learning systems.Use statistics and machine learning to analyze petabytes of health care data in our data lake.Work cross-functionally with data scientists, data engineers, and senior leadership.Use data to inform strategic and design decision making in addition to measuring performance and outcomes to demonstrate efficacy.\xa0Provide mentoring to junior data scientists throughout the organization.', 'Track record of technical innovation and implementing novel machine learning techniques.', ""Intelletec has teamed up with one of the US's Leading Healthcare firms. They are going through a massive transformation and are looking for a Principal Data Scientist to join the leadership team. Join an unparalleled platform to make a difference in healthcare in the US and beyond!"", 'Very competitive pay, bonus, full medical, dental & vision benefits, and more', 'Work cross-functionally with data scientists, data engineers, and senior leadership.', 'RESPONSIBILITIES: ', ""Bachelor's degree or equivalent work experience in Mathematics, Statistics, Computer Science, Economics, Physics, Engineering, or related discipline. "", 'A tight-knit team of passionate people and a tech-first business', 'Use statistics and machine learning to analyze petabytes of health care data in our data lake.', 'ON OFFER:', 'Opportunity for fast growth & promotion', 'This position lies within the Data Science Optimization team.\xa0This team focuses on special projects aimed at improving the productivity of hundreds of data scientists and engineers throughout the organization.', 'PRINCIPAL DATA SCIENTIST', 'Masters degree or Ph.D. preferred.', 'Thorough understanding of machine learning engineering principles such as distributed/parallel computing paradigms and advanced data structures.', 'Very competitive pay, bonus, full medical, dental & vision benefits, and moreA tight-knit team of passionate people and a tech-first businessAutonomy and end-to-end ownershipOpportunity for fast growth & promotion', 'Autonomy and end-to-end ownership', 'SKILLS NEEDED:']",Mid-Senior level,Full-time,Engineering,Hospital & Health Care,2020-11-05 11:32:32
Data Engineer - Azure,OmniData,"Portland, OR",7 hours ago,Be among the first 25 applicants,"['SSISSQL ServerSQL Server Analysis Services (Tabular & Multi-Dimensional)', 'What does our recruitment process look like?', 'Microsoft SQL base Data SkillsSSISSQL ServerSQL Server Analysis Services (Tabular & Multi-Dimensional)', 'OmniData is offering you the opportunity to work with the entire lifecycle of large Data Projects, focused on next generation data warehousing, with surface points to Analytics, Machine Learning and AI. We offer a collaborative work culture, that enables you to produce client results with a safety net from your team.  You will get to work closely with very experienced consultants who will be able to provide mentorship and career guidance.  At the same time, you will be rewarded for learning fast and executing within our teams to provide solutions for OmniData clients.', ""You will work on various Big Data, Data Warehouse Automation, and Data Analytics projects for our world class clients.  In addressing complex client needs, you will be integrated into appropriately sized and skilled teams. You'll be asked to analyze requirements, develop data and analytical solutions and execute as part of the project team, all while working with the latest tools, such as Azure Synapse Analytics and related Microsoft technologies. "", 'Azure Synapse Analytics', 'Power BI, DAX', 'Qualifications and Skills', 'You need to be a Microsoft Certified Azure Data Engineer or demonstrate experience in the same skill set.  You need to be proficient in Power BI.  You need to have solid experience working with data and analytics, a strong technical aptitude, and be a quick learner.  In return, we offer an exciting position at a young startup experiencing rapid growth, deep mentorship and the opportunity to be part of creating a consulting firm that makes a difference for our clients every day we are with them.  ', 'Azure Data Factory', 'Work independently toward client success, at the same time knowing your own limitations and when to call on your OmniData team for help.', 'OmniData is a US-based Data and Analytics focused consulting firm leveraging the Microsoft technology stack to help organizations build their Modern Data Estates, designed to serve their digital innovation needs for many years to come.  To do this, we apply deep experience in Solution Architecture, Data, Analytics, and technology to simplify the complex.   ', 'Execution of team-leading Solution Architect and Data Architect vision for client success, with Azure based data warehouse and business intelligence tools.Contribute collaboratively to team meetings using your experience base to further the cause of innovating for OmniData clients.Instill confidence in the client, your team, and your team membersWork independently toward client success, at the same time knowing your own limitations and when to call on your OmniData team for help.', 'Benefits and Perks', 'Must be decisive and show ability to work with clients and assist their business and technical decision-making.', 'High growth potential for those with an entrepreneurial spirit.', 'Great communication skills tying technologies and architectures to business results will advance your position.', 'Data Warehouse Automation experience ', 'Job Summary', 'Execution of team-leading Solution Architect and Data Architect vision for client success, with Azure based data warehouse and business intelligence tools.', 'Azure Analysis Services', 'Azure Data FactoryAzure Data LakeAzure Synapse AnalyticsAzure Analysis Services', 'Azure based Data Services Azure Data FactoryAzure Data LakeAzure Synapse AnalyticsAzure Analysis Services', 'SQL Server Analysis Services (Tabular & Multi-Dimensional)', ""Willingness to travel (post-COVID) and work with a consultant's diligence."", 'Salary and benefits commensurate with experience.  ', 'SQL Server', 'SSIS', 'Experience and a proven track-record with designing and building solutions in Azure is required.', 'OmniData is small and growing.  You will be exposed to senior leaders and you will be given the opportunity to learn and grow quickly in your career.', ""Analytical approach to problem-solving; ability to use technology to solve business problemsAzure based Data Services Azure Data FactoryAzure Data LakeAzure Synapse AnalyticsAzure Analysis ServicesMicrosoft SQL base Data SkillsSSISSQL ServerSQL Server Analysis Services (Tabular & Multi-Dimensional)Power BI, DAXRequirements Analysis and Project Delivery methodologyYou must be humble, hungry and a fast learner.  OmniData and our clients place a high value on inventiveness.Great communication skills tying technologies and architectures to business results will advance your position.Experience and a proven track-record with designing and building solutions in Azure is required.Must be decisive and show ability to work with clients and assist their business and technical decision-making.Willingness to travel (post-COVID) and work with a consultant's diligence.OmniData is small and growing.  You will be exposed to senior leaders and you will be given the opportunity to learn and grow quickly in your career."", 'About You', 'OmniData Is An Equal Opportunity Employer And All Qualified Applicants Will Receive Consideration For Employment Without Regard To Race, Color, Religion, Sex, National Origin, Disability Status, Protected Veteran Status, Or Any Other Characteristic Protected By Law.', 'You must be humble, hungry and a fast learner.  OmniData and our clients place a high value on inventiveness.', '2+ years of experience in Analytics and Data Warehousing, with Azure knowledge a plus.  ', 'About OmniData', 'Our process is highly personalized. Some candidates complete their process in one week, while others can take several weeks or even months. Deciding to take a new job is a big decision, so regardless of how long or short the process may be for you, the most important thing is that you find your dream job.', 'Responsibilities and Duties', 'Contribute collaboratively to team meetings using your experience base to further the cause of innovating for OmniData clients.', 'Azure Data Lake', 'Analytical approach to problem-solving; ability to use technology to solve business problems', '2+ years of experience in Analytics and Data Warehousing, with Azure knowledge a plus.  Data Warehouse Automation experience ', 'Instill confidence in the client, your team, and your team members', 'Requirements Analysis and Project Delivery methodology', 'Salary and benefits commensurate with experience.  High growth potential for those with an entrepreneurial spirit.']",Entry level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
BHJOB15656_15057 - Data Engineer,Myticas Consulting ULC,Greater Chicago Area,4 hours ago,Be among the first 25 applicants,"['', '2+ years of experience with Spark using Python/Scala. Experience with Spark streaming, building real time data pipelines is preferred', 'Prior experience with traditional ETL tools like Talend Open Studio, Pentaho or something similar is a plus', 'Experience with automating and orchestrating jobs on a big data platform using Oozie, Airflow, Jenkins or something similar', 'Prior experience with working in a SQL server based environment and using SSIS, SSRS, TSQL is a plus.', 'The recruitment team at Myticas Consulting is looking for an experienced Data Engineer who would be interested in a contract to hire opportunity offered within the Elmhurst, IL region.·', '5+ years of experience working with enterprise data platforms, building and managing data lakes and using big data technologies', '2+ years of experience working with AWS platform. Experience with solutioning on AWS infrastructure using services like AWS S3, Lambda, EMR, Redshift (or Snowflake)', 'Requirements:', 'Good understanding and experience working with various products in the Big data ecosystem like Hive, HDFS, Presto, NoSQL databases like Cassandra, DynamoDB', '5+ years of experience working with enterprise data platforms, building and managing data lakes and using big data technologies2+ years of experience with Spark using Python/Scala. Experience with Spark streaming, building real time data pipelines is preferred2+ years of experience working with AWS platform. Experience with solutioning on AWS infrastructure using services like AWS S3, Lambda, EMR, Redshift (or Snowflake)Experience with automating and orchestrating jobs on a big data platform using Oozie, Airflow, Jenkins or something similarGood understanding and experience working with various products in the Big data ecosystem like Hive, HDFS, Presto, NoSQL databases like Cassandra, DynamoDBExperience with setting up and using Kafka for real time streaming is a big plusHas to be a team player and open to working with newer technologies as well as supporting legacy systemsPrior experience with working in a SQL server based environment and using SSIS, SSRS, TSQL is a plus.Prior experience with traditional ETL tools like Talend Open Studio, Pentaho or something similar is a plus', 'Experience with setting up and using Kafka for real time streaming is a big plus', 'Has to be a team player and open to working with newer technologies as well as supporting legacy systems']",Mid-Senior level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist,Norfolk Southern Corporation,"Atlanta, GA",6 hours ago,80 applicants,"['', '•\xa0\xa0\xa0Hands-on and theoretical knowledge of various Machine Learning algorithms and tools, e.g. xgboost/LightGBM, Random Forests, SVMs, PCA, t-sne, kmeans, DBSCAN, etc. or hands-on and theoretical knowledge of various Deep Learning algorithms and frameworks for Localization, Segmentation, Object Detection, etc.', 'What will be your duties:', '•\xa0\xa0\xa0We use Tensorflow, Keras, PyTorch, and MXNet for Deep Learning, and OpenCV for traditional Computer Vision.', 'http://bit.ly/NS_New_HQ', 'Norfolk Southern is in the process of constructing a vibrant & modern corporate HQ in Midtown Atlanta, GA. Our HQ is scheduled for completion in the summer of 2021. To check out a sneak peek, we’ve linked a playlist below.', 'Equal employment opportunities are available to all applicants regardless of race, color, religion, age, sex, national origin, disability status, genetic information, veteran status, sexual orientation and, gender identity. Together, we power progress.', '•\xa0\xa0\xa0Minimum of 2-3 years of relevant industry experience (as a Data Scientist, Research Scientist, Machine Learning Engineer, Computer Vision Scientist, etc.), 3+ preferred; or proven qualifications.', '•\xa0\xa0\xa0Excellent knowledge of Python and/or R, knowledge of Spark is a plus', 'Norfolk Southern Corporation (NYSE: NSC) is a Fortune 300 organization and one of the nation’s premier transportation companies. Its Norfolk Southern Railway Company subsidiary operates approximately 19,500 route miles in 22 states and the District of Columbia, serves every major container port in the eastern United States, and provides efficient connections to other rail carriers.', 'Norfolk Southern Corporation (NYSE: NSC)', '•\xa0\xa0\xa0Want to learn more? Apply today!', 'What are our requirements:', 'We are a team of more than 20,000 employees working together to maintain our reputation as ""The Thoroughbred of Transportation."" As an industry leader, Norfolk Southern offers a competitive salary and an excellent benefits package.', '•\xa0\xa0\xa0Expertise with Time Series problems is a plus', '\xa0', '•\xa0\xa0\xa0We always have the latest versions of our tools/packages/libraries available.', 'o\xa0\xa0\xa0You will have a local machine with 512GB of memory, so feel free to load the data in memory if it makes sense or if it fits (!)', '•\xa0\xa0\xa0We use Jupyter notebook, Emacs, PyCharm, Rstudio as IDEs.', '•\xa0\xa0\xa0Effectively utilize appropriate statistical, Machine Learning, Deep Learning, and Computer Vision models and techniques to solve various business problems', '•\xa0\xa0\xa0Design and develop (almost) production ready code.', '•\xa0\xa0\xa0Coordinate with application development teams to integrate developed models with existing applications.', 'o\xa0\xa0\xa0You will have your own dedicated GPU (!) in addition to a GPU cluster to run parallel training and inference jobs.', '•\xa0\xa0\xa0Collaborate with various departments to identify opportunities for process improvement and developing analytics use-cases.', '•\xa0\xa0\xa0Our locomotives stream 350+ sensor information in real-time. We create predictive models to predict various component failures hours, days, and sometimes months in advance.', '•\xa0\xa0\xa0Communicate results to colleagues and business partners.', 'At Norfolk Southern, we believe in celebrating our individuality. By leveraging the unique backgrounds and viewpoints of our employees, we can create a culture of innovation, respect, and inclusion. We know that employees thrive in a workplace where differing viewpoints, ideas, and experiences are freely shared and valued. As such, we encourage all employees to contribute their distinctive skills and capabilities to our organization.', '•\xa0\xa0\xa0Stays up to date with the latest models and changes in the technology', '•\xa0\xa0\xa0We are very collaborative, you will likely get lots of ideas from the team.', '•\xa0\xa0\xa0Evaluate accuracy and quality of data sources, as well as the designed models', 'What kind of problems do we solve:', '•\xa0\xa0\xa0Provide guidance, support and mentoring to junior team members.', '•\xa0\xa0\xa0Master’s or Ph.D. in Computer Science, Electrical Engineering, Machine Learning, Statistics or related field, or Bachelor’s degree with 5+ years of industry experience', 'Who we are and what we do:', 'Don’t just work here, Thrive here.', '(Machine Learning or Computer Vision)', '•\xa0\xa0\xa0You will also have terabytes of memory in our Spark cluster that is not shared by anyone.', '•\xa0\xa0\xa0The AI and Data Science team is centralized across the entire organization.', 'Senior Data Scientist\xa0', 'Job Description', 'New Headquarters – Atlanta, GA', 'What tools do we use:', '•\xa0\xa0\xa0We work with various product teams across various business units to define high-impact business problems, solve them using novel techniques, and execute and monitor them throughout their lifecycle.', '•\xa0\xa0\xa0We use Python, R, and Spark (PySpark, SparkR, Scala) for modeling and EDA.', '•\xa0\xa0\xa0Most of our models make it to production, they never sit in a research lab. But we also do quite a bit of research to stay up-to-date with the latest technologies/algorithms.', '•\xa0\xa0\xa0There are high-frame cameras beside our tracks, capturing images of trains and rail cars as they pass. We design various Deep Learning and Computer Vision algorithms to detect certain objects of interest or issues and defects. We then optimize their performance and deploy them at the edge for real-time scoring and notification of our mechanical personnel upon detections.', 'Company Overview', 'Education and Experience']",Mid-Senior level,Full-time,Other,Transportation/Trucking/Railroad,2020-11-05 11:32:32
Data Engineer,General Dynamics Mission Systems,"Chantilly, VA",20 hours ago,Be among the first 25 applicants,"['Develop technical documentation and standard operating procedures', 'Design, develop, implement and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory)', 'Working knowledge of entity resolution systemsExperience with messages systems like KafkaExperience with NoSQL and/or graph databases like MongoDB or ArangoDBAny of the following databases: SQL, MongoDB, Oracle, PostgresWorking experience with ETL processingWorking experience with data workflow products like StreamSets or NiFiWorking experience with Python RESTful API services, JDBCExperience with Hadoop and Hive/ImpalaExperience with Cloudera Data Science Workbench is a plusUnderstanding of pySpark Leadership experienceCreative thinkerAbility to multi-taskExcellent use and understanding of data engineering concepts, principles, and theories', 'KNOWLEDGE SKILLS AND ABILITIES:', ""Bachelor's degree in Engineering, Computer Science, Statistics, Applied Math is required plus a\xa0minimum of 2 years relevant experience or Master’s degree in a related technical discipline"", 'Develop processes to identify data drift and malformed records', '\xa0', 'Support data science team by designing, developing and implementing scalable ETL process for disparate datasets into a Hadoop infrastructureDesign, develop, implement and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory)Develop processes to identify data drift and malformed recordsDevelop technical documentation and standard operating proceduresLeads technical tasks for small teams or projects', 'Ability to multi-task', 'Developing mission-critical systems that help keep people safe is what we do. At General Dynamics Mission Systems, you’ll be part of the team that helps heroes make a true impact. The work we do is important. The challenges we face are career-defining. The opportunity we can offer is one-of-a-kind. We apply advanced technologies such as Artificial Intelligence, Blockchain, AR/VR, Cloud Native and Quantum Physics to solve our customers’ missions in cyber, RF, undersea, interstellar space and everything in between.As a Data Engineer, you’ll lead model and simulation activities as you participate in requirements analysis and management, functional analysis, performance analysis, system design, trade studies, systems integration and test (verification). It’s your chance to step up to the challenge and prove you’re ready to lead the world.', 'Leads technical tasks for small teams or projects', 'Experience with messages systems like Kafka', 'REPRESENTATIVE DUTIES AND TASKS:', 'Experience with NoSQL and/or graph databases like MongoDB or ArangoDB', 'Excellent use and understanding of data engineering concepts, principles, and theories', 'We are seeking a Data Engineer to support the Insider Threat mission. Data Engineers work with various security system data owners to automate data integration and collection strategies. Work closely with the data science team to ensure data cleanliness and accuracy.', 'Creative thinker', 'General Dynamics Mission Systems (GDMS) engineers a diverse portfolio of high technology solutions, products and services that enable customers to successfully execute missions across all domains of operation.\xa0With a global team of 13,000+ top professionals, we partner with the best in industry to expand the bounds of innovation in the defense and scientific arenas.\xa0Given the nature of our work and who we are, we value trust, honesty, alignment and transparency.\xa0We offer highly competitive benefits and pride ourselves in being a great place to work with a shared sense of purpose.\xa0You will also enjoy a flexible work environment where contributions are recognized and rewarded.\xa0If who we are and what we do resonates with you, we invite you to join our high performance team!General Dynamics is an Equal Opportunity/Affirmative Action Employer that is committed to hiring a diverse and talented workforce.\xa0EOE/Disability/Veteran', 'Support data science team by designing, developing and implementing scalable ETL process for disparate datasets into a Hadoop infrastructure', '#CB', 'General Dynamics Mission Systems (GDMS)', '#CJ3', 'Working experience with ETL processing', 'Experience with Hadoop and Hive/Impala', 'Understanding of pySpark Leadership experience', 'Working knowledge of entity resolution systems', 'Working experience with Python RESTful API services, JDBC', 'Any of the following databases: SQL, MongoDB, Oracle, Postgres', 'A TS/SCI security clearance with the ability to obtain a Polygraph is required\xa0at time of hire.\xa0 Candidates must be able to obtain the Polygraph within a reasonable amount of time from date of hire. Applicants selected will be subject to a U.S. Government security investigation and must meet eligibility requirements for access to classified information. Due to the nature of work performed within our facilities, U.S. citizenship is required.', 'CLEARANCE REQUIREMENTS: ', 'Experience with Cloudera Data Science Workbench is a plus', 'Working experience with data workflow products like StreamSets or NiFi']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Scientist - Experimentation,McAfee,"San Jose, CA",20 hours ago,Be among the first 25 applicants,"['', 'Advance self service A/B testing and automation', 'Additional Locations:', 'Pension and Retirement Plans', '7+ years of demonstrated experience at senior level analyzing product and content user behavior for online consumer software product, e.g. online shopping, social site, streaming services, gaming and etc.', 'Implement continuous improvements to all aspects of our experimentation program to increase the quality, reliability, volume and velocity of experimentation in the organization.', 'You will use statistical models to forecast, size and prioritize ideas for A/B testing.', 'Location: ', ' Masters/PhD in Statistics, Operation Research, Applied Mathematics, Economics, Computer Science, or a quantitative discipline preferred.', 'You will create dashboards, reports, and analyses that present A/B testing results, explaining what happened and why', 'Paid Time Off', '5+ years of experience in leading experimentation (A/B testing) program in a high test volume environment', 'Experience with one or more testing tools like optimizely or adobe test and target', 'Use segmentation, cohort analysis , clustering and statistical techniques on A/B testing data to uncover new insights and opportunities.', 'Job Title', 'You will participate in vendor selection related to new experimentation tools', 'Design and execute experiments to help us validate hypothesis and relationships in the data', 'Role Overview', 'You will analyze consumer behavior, product usage and marketing data to identify opportunities and create hypothesis for product improvements, consumer experience enhancements and business optimization.', 'Support for Community Involvement', 'Develop, deploy and own tools, best practice methodologies, processes and standards for A/B testing across the organization', 'About The Role', '7+ years of demonstrated experience at senior level analyzing product and content user behavior for online consumer software product, e.g. online shopping, social site, streaming services, gaming and etc.5+ years of experience in leading experimentation (A/B testing) program in a high test volume environmentExperience with one or more testing tools like optimizely or adobe test and targetAnalyzing very large datasets with SQL (Redshift, Teradata, Oracle, or MySQL) and R, SAS or other statistical package.Thorough knowledge of statistical methods for common parametric and non-parametric testsExpert knowledge of SQL required Masters/PhD in Statistics, Operation Research, Applied Mathematics, Economics, Computer Science, or a quantitative discipline preferred.', 'Analyzing very large datasets with SQL (Redshift, Teradata, Oracle, or MySQL) and R, SAS or other statistical package.', 'Expert knowledge of SQL required', 'About You', 'Implement and analyze A/B or Multi-Variate Tests to help us measure the impact of product decisions and changes', 'You will analyze consumer behavior, product usage and marketing data to identify opportunities and create hypothesis for product improvements, consumer experience enhancements and business optimization.You will use statistical models to forecast, size and prioritize ideas for A/B testing.Design and execute experiments to help us validate hypothesis and relationships in the dataDevelop, deploy and own tools, best practice methodologies, processes and standards for A/B testing across the organizationImplement and analyze A/B or Multi-Variate Tests to help us measure the impact of product decisions and changesUse segmentation, cohort analysis , clustering and statistical techniques on A/B testing data to uncover new insights and opportunities.Implement continuous improvements to all aspects of our experimentation program to increase the quality, reliability, volume and velocity of experimentation in the organization.You will participate in vendor selection related to new experimentation toolsAdvance self service A/B testing and automationYou will create dashboards, reports, and analyses that present A/B testing results, explaining what happened and whyIdentify and understand several data sources; build tools and services to improve analysis and experimentation throughput, and work with Data Warehouse team to make online and offline data cross platforms available.', 'Medical, Dental and Vision Coverage', 'Job Type', 'Identify and understand several data sources; build tools and services to improve analysis and experimentation throughput, and work with Data Warehouse team to make online and offline data cross platforms available.', 'Company Benefits And Perks', 'Primary Location:', 'Pension and Retirement PlansMedical, Dental and Vision CoveragePaid Time OffPaid Parental LeaveSupport for Community Involvement', 'Thorough knowledge of statistical methods for common parametric and non-parametric tests', 'Company Overview', 'Paid Parental Leave']",Mid-Senior level,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist,Agoda,"Washington, DC",4 hours ago,51 applicants,"['', 'Design, code, experiment and implement models and algorithms to maximize customer experience, supply side value, business outcomes, and infrastructure readiness.', ' 3+ years hands-on data science experience. Excellent understanding of AI/ML/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks. Significant proficiency in SQL and languages like Python, PySpark and/or Scala. Can lead, work independently as well as play a key role in a team. Good communication and interpersonal skills for working in a multicultural work environment. ', 'Work with developers and a variety of business owners to deliver daily results with the best quality.', 'Experience in data science for e-commerce and/or OTA', 'Mine a big data of hundreds of millions of customers and more than 600M daily user generated events, supplier and pricing data, and discover actionable insights to drive improvements and innovation.', 'Can lead, work independently as well as play a key role in a team.', 'Get to Know Our Team', 'About Agoda', 'Research discover and harness new ideas that can make a difference', 'Significant proficiency in SQL and languages like Python, PySpark and/or Scala.', ' PhD or MSc in Computer Science / Operations Research / Statistics or other quantitative fields Experience in NLP, image processing and/or recommendation systems Hands on experience in data engineering, working with big data framework like Spark/Hadoop Experience in data science for e-commerce and/or OTA ', 'Excellent understanding of AI/ML/DL and Statistics, as well as coding proficiency using related open source libraries and frameworks.', '3+ years hands-on data science experience.', 'The Opportunity', 'In This Role, You’ll Get to', 'Equal Opportunity Employer', 'What You’ll Need To Succeed', ' Design, code, experiment and implement models and algorithms to maximize customer experience, supply side value, business outcomes, and infrastructure readiness. Mine a big data of hundreds of millions of customers and more than 600M daily user generated events, supplier and pricing data, and discover actionable insights to drive improvements and innovation. Work with developers and a variety of business owners to deliver daily results with the best quality. Research discover and harness new ideas that can make a difference ', 'We welcome both local and international applications for this role. Full visa sponsorship and relocation assistance available for eligible candidates.', 'Experience in NLP, image processing and/or recommendation systems', 'Hands on experience in data engineering, working with big data framework like Spark/Hadoop', 'Good communication and interpersonal skills for working in a multicultural work environment.', 'PhD or MSc in Computer Science / Operations Research / Statistics or other quantitative fields', 'It’s Great if You Have', 'Working Location: Bangkok, Thailand']",Mid-Senior level,Full-time,Information Technology,Internet,2020-11-05 11:32:32
Researcher II,Genesis10,"Mountain View, CA",56 minutes ago,Be among the first 25 applicants,"['Experience working with other researchers on qualitative data collection, analysis, and reporting. Organized and detail-oriented.Desired Ideally minimum 1 year experience conducting research on consumer-facing experiences. Experience with one or more of the following methods: consumer surveys, usability studies, concept tests, benchmarks, diary studies, interviewing consumers, field research.  ', 'Experienced at survey design and analysis (descriptive statistics only).', 'About Genesis10', 'Support ongoing UX research work. Survey design, analysis, writing detailed reports.', 'BA/BS in Computer Science, Human-Computer Interaction, Cognitive Science, Experimental Psychology, Anthropology, Information Science with 2 years of equivalent practical experience. OR Masters degree with internship.', 'Responsibilities', 'Description', 'Ideally minimum 1 year experience conducting research on consumer-facing experiences.', ' Support ongoing UX research work. Survey design, analysis, writing detailed reports. Work with other researchers, designers, product managers, engineers in a fast-paced, rapidly changing environment. ', 'Understand and incorporate complex technical and business requirements into research.', 'Work with other researchers, designers, product managers, engineers in a fast-paced, rapidly changing environment.', ' Ideally minimum 1 year experience conducting research on consumer-facing experiences. Experience with one or more of the following methods: consumer surveys, usability studies, concept tests, benchmarks, diary studies, interviewing consumers, field research. ', 'Advocate research findings to diverse audiences through written reports and oral presentations. Be willing to jump in where needed.', "" BA/BS in Computer Science, Human-Computer Interaction, Cognitive Science, Experimental Psychology, Anthropology, Information Science with 2 years of equivalent practical experience. OR Masters degree with internship. Experienced at survey design and analysis (descriptive statistics only). Great working knowledge of our client's Forms and/or Microsoft Excel. Must be flexible and willing to work in a fast-paced environment. Excellent interpersonal, communication, negotiation and collaboration skills. Experience working with other researchers on qualitative data collection, analysis, and reporting. Organized and detail-oriented.Desired Ideally minimum 1 year experience conducting research on consumer-facing experiences. Experience with one or more of the following methods: consumer surveys, usability studies, concept tests, benchmarks, diary studies, interviewing consumers, field research.   "", 'Survey support: Create surveys and report data; code open-ended comments, create graphs and report findings.', 'Experience with one or more of the following methods: consumer surveys, usability studies, concept tests, benchmarks, diary studies, interviewing consumers, field research.', ' Survey support: Create surveys and report data; code open-ended comments, create graphs and report findings. Advocate research findings to diverse audiences through written reports and oral presentations. Be willing to jump in where needed. Understand and incorporate complex technical and business requirements into research. ', 'If you have the described qualifications and are interested in this exciting opportunity, please apply!About Genesis10Genesis10 is a leading U.S. business and technology consulting firm with hundreds of clients needing proven talent and solutions to power their strategic initiatives. If you are a high performing business or IT professional with solid, referenced experience, we want to meet you. Genesis10 recruiters and delivery professionals are highly accomplished career advocates, who get to know you beyond your resume to position you with the opportunities that fit your skills, experience and aspirations. We have benefit options to fit your needs and a support staff that works with you from placement throughout your engagement project after project. To learn more about Genesis10 and to view all our available career opportunities, please visit us at www.genesis10.com. ""Genesis10 is an Equal Opportunity Employer, M/F/D/V', 'Genesis10 is currently seeking a Researcher II with our client in the SEO industry in their Mountain View, CA location. This is a 12 month + contract position.DescriptionSeeking a Researcher II Support ongoing UX research work. Survey design, analysis, writing detailed reports. Work with other researchers, designers, product managers, engineers in a fast-paced, rapidly changing environment. Responsibilities Survey support: Create surveys and report data; code open-ended comments, create graphs and report findings. Advocate research findings to diverse audiences through written reports and oral presentations. Be willing to jump in where needed. Understand and incorporate complex technical and business requirements into research. RequirementsAble to work as a W2 employee of Genesis10 (no Corp-to-Corp) BA/BS in Computer Science, Human-Computer Interaction, Cognitive Science, Experimental Psychology, Anthropology, Information Science with 2 years of equivalent practical experience. OR Masters degree with internship. Experienced at survey design and analysis (descriptive statistics only). Great working knowledge of our client\'s Forms and/or Microsoft Excel. Must be flexible and willing to work in a fast-paced environment. Excellent interpersonal, communication, negotiation and collaboration skills. Experience working with other researchers on qualitative data collection, analysis, and reporting. Organized and detail-oriented.Desired Ideally minimum 1 year experience conducting research on consumer-facing experiences. Experience with one or more of the following methods: consumer surveys, usability studies, concept tests, benchmarks, diary studies, interviewing consumers, field research.   If you have the described qualifications and are interested in this exciting opportunity, please apply!About Genesis10Genesis10 is a leading U.S. business and technology consulting firm with hundreds of clients needing proven talent and solutions to power their strategic initiatives. If you are a high performing business or IT professional with solid, referenced experience, we want to meet you. Genesis10 recruiters and delivery professionals are highly accomplished career advocates, who get to know you beyond your resume to position you with the opportunities that fit your skills, experience and aspirations. We have benefit options to fit your needs and a support staff that works with you from placement throughout your engagement project after project. To learn more about Genesis10 and to view all our available career opportunities, please visit us at www.genesis10.com. ""Genesis10 is an Equal Opportunity Employer, M/F/D/V', 'Requirements', ""Great working knowledge of our client's Forms and/or Microsoft Excel. Must be flexible and willing to work in a fast-paced environment."", 'Excellent interpersonal, communication, negotiation and collaboration skills.']",Entry level,Contract,Research,Internet,2020-11-05 11:32:32
Qualitative Researcher,Elizabeth Norman International,"New York, United States",4 hours ago,Over 200 applicants,"['', 'They have a team based in London and are now hiring in the US. They are looking to bring on a mid-level (3-8 years experience) qualitative researcher who has qualitative research experience, brand strategy and/or planning experience from a market research or advertising agency.', 'They are looking to bring on a mid-level (3-8 years experience) qualitative researcher who has qualitative research experience, brand strategy and/or planning experience from a market research or advertising agency.', '\xa0', 'They are a creative agency looking for qualitative researchers who relish the challenge of getting to the heart of research by pioneering approaches.', 'Please note that all applicants must have Right to Work status for the US.', 'Are you looking to join a fast-growing cultural insights agency?', 'The office is based in New York. They are currently remote working so this person can be based anywhere in the US. Future travel to NY and elsewhere in the US will be expected in 2021.', 'They do a lot of ethnography projects so experience with this is a big bonus.', 'An incredible opportunity for a seasoned qualitative researcher who is keen to join the early journey of the NY office and help grow their offering further globally. (Plus an opportunity to work with the nicest and most talented researchers we know)!', 'They offer competitive salaries and benefits including healthcare and holiday allowance (between 20-25 days), a wellness budget and more.', ""They partner with the World's best-known brands in entertainment, eCommerce, FMCG, social media, finance and travel. They have influenced the strategic vision of the World’s most popular social media platform to the narrative of the world’s most sought-after computer game."", 'They have been nominated for an MRS Culture Award and are having their best ever year, winning contracts with the likes of Amazon, TikTok, Spotify, PlayStation and other big names.', ""We're still looking for candidates for this role - advert reposted 5th November. "", 'Their approaches range from 360 immersion programmes, brand strategy and digital research. They are a creative agency looking for qualitative researchers who relish the challenge of getting to the heart of research by pioneering approaches.', 'Apply below.']",Mid-Senior level,Full-time,Research,Market Research,2020-11-05 11:32:32
"Data Engineer - SQL, T-SQL, Azure",KORE1,Greater Boston,1 day ago,38 applicants,"['', '·\xa0\xa0\xa0\xa0\xa0\xa0Ability to spot problematic areas, analyze solutions and propose, direct and execute their resolution.', '·\xa0\xa0\xa0\xa0\xa0\xa0Experience with backup/recovery tasks, user administration, data system installation and configuration', '·\xa0\xa0\xa0\xa0\xa0\xa0T-SQL programming, performance, and optimization', '·\xa0\xa0\xa0\xa0\xa0\xa0Scripting or software development experience (PowerShell, python, C#, etc.)', '·\xa0\xa0\xa0\xa0\xa0\xa0Hands-on experience with data architecture and design.', '·\xa0\xa0\xa0\xa0\xa0\xa0A solution and delivery oriented mindset with a ‘roll-up your sleeves’ attitude', 'This is a full-time, direct hire role. Will start out 100% remote, but client will expect someone to relocate to Boston in 2021 or when it is safe to do so. Client CAN do h-1b transfers.', '·\xa0\xa0\xa0\xa0\xa0\xa05+ years of closely related experience with one or more of the following: Microsoft SQL Server, AWS Aurora, PostgreSQL, MySQL, Snowflake, MongoDB, Redis, DynamoDB', '·\xa0\xa0\xa0\xa0\xa0\xa0Data replication technologies, configuration and performance in a clustered environment']",Mid-Senior level,Full-time,Information Technology,Staffing and Recruiting,2020-11-05 11:32:32
Operations Research Scientist,Koch Industries,"Chicago, IL",6 hours ago,53 applicants,"['', 'Experience developing in Python, Java, or C++ within a collaborative production environment', 'Work with product managers and clients to better understand the business problem', 'Experience developing proof of concepts and testing new ideas, as well as scaling these ideas into production ready models that can be deployed', 'Experience putting emerging ideas into practice through rapid experimentation and prototyping', 'Education', 'Collaborate with other scientists and analysts', 'Description', 'Work with data engineers and/or data analysts to procure data and test it for problems', 'Collaborate with product managers to find the best way to present the results', 'Work with developers on productionizing models', 'A minimum of 3 years of post-academic experience developing and deploying advanced optimization models', 'An advanced Degree (Masters or PhD) in Operations Research, Industrial Engineering, Mathematics, Physics, Statistics, or ChemistryA minimum of 3 years of post-academic experience developing and deploying advanced optimization modelsExperience putting emerging ideas into practice through rapid experimentation and prototypingExpert in mathematical optimization and decomposition of complex problems for custom solutionsExperience with commercial (Gurobi, Cplex, Xpress) or free/open source (GLPK, lp_solve, MIPCL) solversExperience in scheduling and routing optimization problemsExperience developing in Python, Java, or C++ within a collaborative production environmentHigh quality understanding of stochastic processes and uncertainty modeling, experience formulating and solving mixed integer linear, non-linear, and quadratic programming modelsExperience developing proof of concepts and testing new ideas, as well as scaling these ideas into production ready models that can be deployed ', 'Work with product managers and clients to better understand the business problemCreate a list of potentially relevant supporting data elementsWork with data engineers and/or data analysts to procure data and test it for problemsCollaborate with other scientists and analystsPropose modeling approachesMine the data to check completeness, value distributions, etc.Test models for quality and scalabilityCollaborate with product managers to find the best way to present the resultsWork with developers on productionizing models ', 'Experience in scheduling and routing optimization problems', 'The Experience You Will Bring.', 'Experience with commercial (Gurobi, Cplex, Xpress) or free/open source (GLPK, lp_solve, MIPCL) solvers', 'An advanced Degree (Masters or PhD) in Operations Research, Industrial Engineering, Mathematics, Physics, Statistics, or Chemistry', 'Mine the data to check completeness, value distributions, etc.', 'Propose modeling approaches', 'Expert in mathematical optimization and decomposition of complex problems for custom solutions', 'Salary And Benefits Commensurate With Experience.', 'High quality understanding of stochastic processes and uncertainty modeling, experience formulating and solving mixed integer linear, non-linear, and quadratic programming models', 'What You Will Do In Your Role.', 'Create a list of potentially relevant supporting data elements', 'Test models for quality and scalability']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Engineer,Modis,"Minneapolis, MN",3 hours ago,Be among the first 25 applicants,"['', 'Skills:', 'Title: Sr. Data Engineer ', 'Location: Minneapolis, MN', 'Responsibilities:', '• Work collaboratively with business teams including data scientists and business intelligence analysts to understand their needs for data and create an extract that satisfy Business requirements', '• 4+ years of experience in Software Development Life Cycle (SDLC) - system development projects', '• 2+ years of hands on experience programming on Hadoop', '• Understanding and related experience with Hadoop database tools (HBase, Spark, Cassandra, etc.)', '• Design, code, test, document, and maintain high-quality and scalable Big Data solutions', '• Analytical and problem solving experience applied to a Big Data environment', '• Previous experience with Relational Databases (RDBMS) & Non- Relational Databases', 'Job Description:', '• Design, build, and deploy processes to load data (sets and sources) into Hadoop', '• Write code, and leverage tools, to transform data to incorporate business logic as defined in conjunction with various business stakeholders', '• Previous experience in implementation of ETL processes, Data warehousing principles, architecture and robust development of data pipelines in complex environments', '• Write technical documentation', '• Hands-on experience with related/complementary open source software platforms and languages (e.g. Java, Scala, Python, Unix)', 'Duration: 12 Months', '• Experience with agile/scrum methodologies', '• Implement process improvement initiatives and automation for efficiency where appropriate', '• Analyze raw data sources and data transformation requirements', '• Perform data modeling against large data sets for peak efficiency']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr Data Scientist - Quality Testing & Statistics,HERE Technologies,"Chicago, IL",40 minutes ago,Be among the first 25 applicants,"['', ' Experience with understanding, specifying and explaining measurement and analytic systems with other teams of data scientists and engineers to execute projects delivering those solutions. ', ' MS or PhD Degree in statistics, mathematics, physical sciences, econometrics, or related fields. ', ' Make HERE your destination, we are just getting started. Come join us! ', ' Who are we? ', ' Designing and developing data and computing tools to enable processing of quality testing data and results ', ' Engaging with map and location experts, engineering teams, and other teams across the company ', ' Interpreting project objectives and requirements, and creating enabling data science solutions and outcomes ', ' Who are you? ', 'The Team', ' Developing sampling plans for data collection, quality evaluation, and the production of training data, along with technical estimators for the evaluation of map quality, and A/B experiments to validate optimization and solution approaches ', ' Variety in the types of projects ', ' MS or PhD Degree in statistics, mathematics, physical sciences, econometrics, or related fields.  5+ years of related work experience, preferably within a quality testing organization.  Proficiency of sampling methods, and data mining and analytic methods such as regression, classifiers, clustering, association rules, decision trees, etc.  Proficiency with analysis and programming in R, or any similar package (Python, Matlab, SAS, etc).  Knowledge and experience with using GIS tools for spatial data analysis.  Knowledge of tools such as Pig, Hive, etc. for working with big data in Hadoop or Spark for data extraction/prep for analysis.  Experience with understanding, specifying and explaining measurement and analytic systems with other teams of data scientists and engineers to execute projects delivering those solutions. ', "" Challenging problems to solve  Opportunities to learn cool new things  Work that makes a difference in the world  Freedom to decide how to perform your work  Variety in the types of projects  Feedback so you will know how well you are doing  Collaborative, Supportive Colleagues in a workplace where you're free to be yourself"", ' Knowledge of tools such as Pig, Hive, etc. for working with big data in Hadoop or Spark for data extraction/prep for analysis. ', 'The Role', 'Role', ' Work that makes a difference in the world ', ""What's the role? "", ' Interpreting project objectives and requirements, and creating enabling data science solutions and outcomes  Developing sampling plans for data collection, quality evaluation, and the production of training data, along with technical estimators for the evaluation of map quality, and A/B experiments to validate optimization and solution approaches  Building and testing statistical and machine learning models to support improvement of a wide variety of data-driven processes for map- and location-making data evaluation and decisions  Designing and developing data and computing tools to enable processing of quality testing data and results  Engaging with map and location experts, engineering teams, and other teams across the company ', ' Proficiency with analysis and programming in R, or any similar package (Python, Matlab, SAS, etc). ', ' Feedback so you will know how well you are doing ', ' Proficiency of sampling methods, and data mining and analytic methods such as regression, classifiers, clustering, association rules, decision trees, etc. ', ' Opportunities to learn cool new things ', "" Collaborative, Supportive Colleagues in a workplace where you're free to be yourself"", ' You will be a Subject Matter Expert (SME) on data science methods for Map and Location quality testing processes and involved in the following: ', ' 5+ years of related work experience, preferably within a quality testing organization. ', ' Knowledge and experience with using GIS tools for spatial data analysis. ', ' Building and testing statistical and machine learning models to support improvement of a wide variety of data-driven processes for map- and location-making data evaluation and decisions ', 'What You’ll Get', ' Challenging problems to solve ', ' Freedom to decide how to perform your work ']",Associate,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Research Scientist,Emory University,"Atlanta, GA",19 hours ago,Be among the first 25 applicants,"['', 'Job Description', ' Assists with training students and supervises technical staff. ', ' Responsible for lab organization and compliance. ', ' Proficient in western blot analysis, immunoprecipitation, cell culture, quantitative real-time PCR and FACS analysis. ', ' Assists with data analysis and manuscript preparation. ', ' Connect With Us! ', 'Options', ' Description ', 'Discover Your Career at Emory University ', ' Performs related responsibilities as required. ', ' Emory Supports a Diverse and Inclusive Culture ', ' Develops and executes cell-based assays for permeability, migration and proliferation.  Proficient in western blot analysis, immunoprecipitation, cell culture, quantitative real-time PCR and FACS analysis.  Assists with training students and supervises technical staff.  Responsible for lab organization and compliance.  Assists with data analysis and manuscript preparation.  Performs related responsibilities as required. ', 'Minimum Qualifications', "" Bachelor's degree and 7 years of related experience or equivalent combination of experience, education and training. Strong technical background. "", ' Develops and executes cell-based assays for permeability, migration and proliferation. ']",Associate,Full-time,Other,Higher Education,2020-11-05 11:32:32
"Quantum Algorithms Researcher (Approximation, Software, Python)",Understanding Recruitment,San Francisco Bay Area,3 hours ago,Over 200 applicants,"['', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Intellectual challenges that you would not experience in most companies.', '\xa0', 'Quantum Algorithms Researcher (Approximation, Software, Python)', 'QAOA, Quantum Approximate Optimization Algorithm, Variational Quantum Eigensolver, VQE, Algebraic Algorithms, Number Theoretic Algorithms, Oracular Algorithms, Optimization, Numerics', 'As a VC-funded startup in the Bay Area, we are keen on bringing in exceptional researchers and developers to aid in developing novel algorithms for cutting-edge quantum computing hardware to be made easily accessible by not only quantum computing experts, but any classically-trained developer or data scientist using any process including binary optimization, machine learning, chemistry simulation, and more.', 'We can offer a\xa0Quantum Algorithms Researcher:', ""Key Skills: Quantum Computing, Quantum Algorithms, Machine Learning, Research, Shor's Algorithm, Grover's Algorithm, Quantum Computation, Quantum Information, Quantum Entanglement, Quantum Superposition,"", 'We are currently seeking a Quantum Algorithms Researcher (Approximation, Software, Python) to join a Bay Area startup ($15 million Series A) whose vision is to break through the global market with their unique, patented quantum computing software. As a Quantum Algorithms Researcher in our company, you will work alongside our world-renowned team of Quantum Algorithms experts hailing from top universities (MIT, Stanford, University of Oxford) helping develop and optimize novel, resource-efficient quantum algorithms to help realize the potential of quantum computing.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A chance to develop novel quantum algorithms alongside world-renowned quantum algorithms experts', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Competitive salaries, equity and benefits packages', ""Key Skills: Quantum Computing, Quantum Algorithms, Machine Learning, Research, Shor's Algorithm, Grover's Algorithm, Quantum Computation, Quantum Information, Quantum Entanglement, Quantum Superposition, QAOA, Quantum Approximate Optimization Algorithm, Variational Quantum Eigensolver, VQE, Algebraic Algorithms, Number Theoretic Algorithms, Oracular Algorithms, Optimization, Numerics"", 'An ideal Quantum Algorithm Researcher will have experience developing and publishing work on quantum algorithms, as well as strong software programming skills.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A collaborative team and culture that truly looks after talent and cultivates success']",Associate,Full-time,Research,Computer Software,2020-11-05 11:32:32
Machine Learning Engineer,"Plume Design, Inc","Palo Alto, CA",6 hours ago,Over 200 applicants,"['', 'Deliver clean, well-tested code.', 'Strong software engineering skills in complex multi-language systems, particularly fluency in Python', 'Responsibilities', 'Design software architecture and data flows for scalable machine learning development work', 'Exposure to machine learning methodology and top practices', 'Significant hands on experience training machine learning models and taking them to production', 'Experience building systems with scalable data processing technologies (Spark, YugaByte, SQL, Mongo, Presto, etc.)', 'Desired Experience', 'Lead technical projects to completion and communicate with peers to build requirements and track progress.', 'Significant full-time experience building end to end data systems as a ML Engineer', 'Job Summary', ' Significant full-time experience building end to end data systems as a ML Engineer Significant hands on experience training machine learning models and taking them to production Exposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, etc.) Strong software engineering skills in complex multi-language systems, particularly fluency in Python Experience working with cloud computing and database systems Familiarity with data bricks, Spark Airflow, MLFlow, Kafka, etc. Experience building systems with scalable data processing technologies (Spark, YugaByte, SQL, Mongo, Presto, etc.) Exposure to machine learning methodology and top practices ', 'Exposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, etc.)', 'Develop scalable tools and services for handling machine learning workflows', 'Prior work with networking related data, particularly wireless networking', 'Build and integrate end to end life cycles of large-scale, distributed machine learning systems using the latest open source technologies', ' Experience or background with data coming from Health/Fitness wearables Prior work with networking related data, particularly wireless networking Familiarity with AWS', 'Implement cloud distributed training approaches for deep learning models', 'Familiarity with AWS', 'Qualifications (Required)', ' Build and integrate end to end life cycles of large-scale, distributed machine learning systems using the latest open source technologies Develop scalable tools and services for handling machine learning workflows Implement cloud distributed training approaches for deep learning models Collaborate with engineers across functions to solve complex data problems at scale Identify and evaluate new technologies to improve performance, maintainability and elegance of our machine learning systems Design software architecture and data flows for scalable machine learning development work Lead technical projects to completion and communicate with peers to build requirements and track progress. Deliver clean, well-tested code. ', 'Collaborate with engineers across functions to solve complex data problems at scale', 'Familiarity with data bricks, Spark Airflow, MLFlow, Kafka, etc.', 'Experience or background with data coming from Health/Fitness wearables', 'Identify and evaluate new technologies to improve performance, maintainability and elegance of our machine learning systems', 'Experience working with cloud computing and database systems']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Senior/Lead Data Scientist,Sentient Science,United States,21 hours ago,52 applicants,"['', 'Proficiency working with a modern programming language focused on data analysis and machine learning (e.g. Python, R, Julia, Matlab)', 'Familiar with some form of physics-based modeling, such as FEM, CFD, MD, MC, DFT, etc.', 'Unlimited paid time-off', 'Demonstrable knowledge of theory and application of (one or more) techniques across supervised/unsupervised learning, natural language processing, computer vision and statistical inference', 'Flexible working hours and fully remote option available', 'Demonstrated experience working with large (TB+) repositories of structured and unstructured data spanning forms such as numeric, text, images/rasters', 'Understanding/familiarity with deploying, monitoring and retraining machine learning models in cloud-facing production setting (AWS preferred)', '\xa0Lead and mentor junior team members in design, optimization and production-deployment of machine learning and statistical forecasting models while adhering to timelines governed by the product development roadmap', 'Employer-sponsored health insurance', 'Qualifications', 'Building and Implementing the machine learning based statistical models to predict certain damage modes in major components in wind turbines such as Gearbox.', 'Unlimited paid time-offFlexible working hours and fully remote option availableEmployer-sponsored health insuranceOur commitment to\xa0inclusion\xa0across race, gender, age, religion, identity, and experience drives us forward every day', 'Resonsibilities', 'The Senior/Lead Data Scientist leads\xa0efforts to expand the data science capabilities of Sentient’s cloud-based predictive analytics platform. Individual in this position will have a solid background in production-level machine learning systems with broad exposure to a wide variety of algorithmic techniques (demonstrable proof of impactful work in areas such as damage-anomaly detection, natural language processing, explainability-driven deep learning and time-series forecasting is valuable). Our team particularly values experience in building inferential algorithms for high-stake decisions while dealing with noisy, diverse, distributed datasets. Being able to communicate complex concepts in simple language to diverse stakeholders with an unwavering commitment to empathy and customer obsession is highly desired. The title and associated responsibility for the position can be modified for the right candidate – if our mission inspires you, please apply.', 'inclusion', 'Benifits', 'Knowledgeable in programmatically consuming data from APIs and other micro-services', 'Possess a curious mind, insatiable drive to learn proactively and profound humility and empathy for your colleagues as well the customer', 'Proficiency with relevant tools and libraries for a collaborative machine learning workflow: scikit-learn, git etc.', ""Here is an opportunity to join Sentient Science, a company whose solutions lie at the convergence of many exponentially accelerating innovative technologies: Cloud, edge computing and the Industrial Internet of Things (IoT); AI, machine learning and deep learning; Big Data and analytics; and 3D printing (additive manufacturing). Sentient Science helps customers lower the costs of designing, operating, and sustaining their high value mechanical assets by providing digital twin technology that predicts the life of mechanical systems. Sentient's DigitalClone® SaaS solutions use proprietary algorithms derived from physics-based modeling and machine learning. Help us achieve our vision of a world where rotorcraft manufacturers, wind energy operators and railroads rely on Sentient DigitalClone for a digital implementation of their O&M cost reduction strategy. And a high concentration of PhDs will keep you intellectually stimulated and challenged."", 'Reviews large data sets (SCADA) of sensor-derived observations and alarm logs from operating wind turbines and utilizes subject matter expertise to ascertain veracity of these data', 'Interface with customer-facing executives to stay abreast with voice of the customer and update technical roadmap accordingly.', 'US citizenship required', 'Our commitment to\xa0inclusion\xa0across race, gender, age, religion, identity, and experience drives us forward every day', 'Building and Implementing the machine learning based statistical models to predict certain damage modes in major components in wind turbines such as Gearbox.Reviews large data sets (SCADA) of sensor-derived observations and alarm logs from operating wind turbines and utilizes subject matter expertise to ascertain veracity of these dataDevelops, implements and tests statistical algorithms for anomaly detection in large datasets from fleets of field-operating large machines e.g. wind turbines and rotorcraft\xa0Lead and mentor junior team members in design, optimization and production-deployment of machine learning and statistical forecasting models while adhering to timelines governed by the product development roadmapInterface with customer-facing executives to stay abreast with voice of the customer and update technical roadmap accordingly.', 'Develops, implements and tests statistical algorithms for anomaly detection in large datasets from fleets of field-operating large machines e.g. wind turbines and rotorcraft', 'Masters or Ph.D. in mechanical engineering, industrial engineering, wind energy systems, aerospace engineering, statistics, data science, computer science, or related disciplineDemonstrable knowledge of theory and application of (one or more) techniques across supervised/unsupervised learning, natural language processing, computer vision and statistical inferenceDemonstrated experience working with large (TB+) repositories of structured and unstructured data spanning forms such as numeric, text, images/rastersFamiliar with some form of physics-based modeling, such as FEM, CFD, MD, MC, DFT, etc.Proficiency working with a modern programming language focused on data analysis and machine learning (e.g. Python, R, Julia, Matlab)Understanding/familiarity with deploying, monitoring and retraining machine learning models in cloud-facing production setting (AWS preferred)Proficiency with relevant tools and libraries for a collaborative machine learning workflow: scikit-learn, git etc.Knowledgeable in programmatically consuming data from APIs and other micro-servicesPossess a curious mind, insatiable drive to learn proactively and profound humility and empathy for your colleagues as well the customerUS citizenship required', 'Masters or Ph.D. in mechanical engineering, industrial engineering, wind energy systems, aerospace engineering, statistics, data science, computer science, or related discipline']",Not Applicable,Full-time,Computer Software,N/A,2020-11-05 11:32:32
Cloud Data Engineer,Zencon Group,"Austin, TX",13 hours ago,Be among the first 25 applicants,"['Title: Cloud Data EngineerLocation: Austin, TX (Remote until COVID restrictions are lifted)Duration: Until 8/31/2021Job Type: ContractJob Description:', 'Minimum Requirements:', 'As the State of Texas rushes to address the many impacts of the COVID-19 pandemic, it has become critical to rely on the Department of State Health Services (DSHS) to provide reliable, up to the minute data regarding the current state of infection in the state.  As DSHS works to provide this critical data to inform decision makers, health care administrators and citizens, the agency is experiencing serious limitations in the ability to efficiently and reliably provide the data due to a legacy of disparate systems and data that currently resides in numerous locations and databases across the agency. Sharing this vital data across all of these systems is inherently difficult, time-consuming, and requires resource intensive manual and inefficient processes. These cumbersome manual processes have a severe impact on Texas\' ability to respond effectively to the COVID-19 pandemic and prevent the loss of life.The Infectious Disease Data Integration (IDDI) project is intended to improve the efficiency of current processes. An integrated approach to data services will aid in providing the most current data to inform decision makers about the health and readiness statuses of jurisdictions across the state.The Infectious Disease Data Integration project aims to create a data analytics platform plus data governance with Informatica Axon. The IDDI platform will facilitate the sharing, reporting, and analytics of the data collected from the COVID-19 contact tracing in the Texas Health Trace (THT) system, the COVID-19 case management data contained in the National Electronic Disease Surveillance System (NEDSS), and COVID-19 immunization tracking in the ImmTrac system.All work products resulting from the project shall be considered  ""works made for hire” and are the property of the HHSC. HHSC may include pre-selection requirements that potential Vendors (and their Workers) submit to and satisfy criminal background checks as authorized by the Texas law. HHSC will pay no fees for interviews or discussions, which occur during the process of selecting a Worker(s).HHSC IT is currently implementing a Analytics Platform with Informatica PowerCenter, Snowflake and AWS technologies as well as Informatica Axon Data Governance with a goal to accomplish improved COVID-19 reporting.·  Assist DSHS program area use of the IDDI Platform to its fullest potential·  Assist with analytics use with off the shelf reporting tools like SAS, SPSS, Tableau, ARCgis·  Assist with publishing as needed to Tableau and/or ARCgis servers or other web platforms·  Data modeling, data profiling, data quality, data validation, data curation and data transformation·  Resolve any data source ingestion issues·  Operationalize ingestion of new data sources as needed·  Other work includes, but is not limited to:·  Validation of performance metric requirements·  Creation of EPICS/User Stories·  Creation and validation of dashboard and report mock-ups·  Automation of data acquisition from a variety of data sources·  Dashboard and report development·  Testing – integration, load and stress, and user·  Deployment / publication internally and externally·  Operations support and enhancement of the IDDI platform·  All other duties as assignedMinimum Requirements:Candidates that do not meet or exceed the minimum stated requirements (skills/experience) will be displayed to customers but may not be chosen for this opportunity.Years    Required/Preferred    Experience8    Required    Experience as a data engineer implementing data pipelines for a data mart or a data warehouse.6    Required    Excellent oral and written communication skills.6    Required    Effectively manage multiple responsibilities, prioritize conflicting assignments, and switch quickly between assignments, as required.4    Required    Experience in interfacing with tools such as Informatica PowerCenter and Informatica Data Quality jobs.4    Required    Design highly scalable ETL processes with complex data transformations, data formats including error handling and monitoring.3    Required    Experience in implementing data pipelines using cloud native services on any one of the major cloud platforms.2    Required    Hands-on experience implementing solutions using Snowflake utilities, SnowSQL, and SnowPipe.3    Preferred    Prior experience in the Healthcare Industry2    Preferred    Experience working in an agile sprint team.2    Preferred    Prior experience with an HHS agency']",Entry level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
R&D Scientist - Data Science/Wafer Yield,SBT,"Hillsboro, OR",23 hours ago,Be among the first 25 applicants,"['', 'Maintain baseline process data and analyze for yield and quality trends.Identify root cause of process excursions or opportunities for improvement via process parametersPerform statistical split analyses to support research to improve SiC crystal quality and yieldImprove crystal quality, improve yield and develop next generation product linesIP Management: Develop and understand the IP landscape across the industryPartner with external customers, consultants, vendors, and other entities to efficiently execute programs, as needed', 'Ph.D. in Materials, Chemical, Ceramics, Electrical Engineering, or Physical Science', 'Qualifications', 'Significant experience with statistical analyses, Or a PhD in statistics with a substantial track record of applied industrial research', 'Perform statistical split analyses to support research to improve SiC crystal quality and yield', 'Exceptional statistical analysis skills and understanding', 'This is a “game-changing” role. Our client is a leading global wafer manufacturer for the semiconductor industry.\xa0With their technology platform and wafer manufacturing history, they are positioned to be the leading wafer supplier for the high power and Electric Vehicle market in the coming years.\xa0They are in the early stages of a growth initiative which has already seen a 25% increase in their plant size so far in 2020.\xa0', 'Ph.D. in Materials, Chemical, Ceramics, Electrical Engineering, or Physical ScienceSignificant experience with statistical analyses, Or a PhD in statistics with a substantial track record of applied industrial researchExperience working within the semiconductor industry in silicon wafer manufacturingExceptional statistical analysis skills and understanding', 'Identify root cause of process excursions or opportunities for improvement via process parameters', 'IP Management: Develop and understand the IP landscape across the industry', 'Partner with external customers, consultants, vendors, and other entities to efficiently execute programs, as needed', 'Experience working within the semiconductor industry in silicon wafer manufacturing', 'Improve crystal quality, improve yield and develop next generation product lines', 'They are currently seeking to add an experienced Scientist to their bulk crystal growth R&D organization. This person can be the SME when it comes to implementing a statistical analysis infrastructure to the current R&D organization.\xa0', 'Core Responsibilities', 'Maintain baseline process data and analyze for yield and quality trends.']",Mid-Senior level,Full-time,Engineering,Semiconductors,2020-11-05 11:32:32
"Researcher, Health Communication and Behavior Change Research",Fors Marsh Group,"Arlington, VA",4 hours ago,Be among the first 25 applicants,"['', 'Supporting the design, execution, and management of projects employing quantitative and qualitative data analysisAssisting in the development of surveys and supporting materials including study protocols, data analysis plans, and quality control plansIndependently applying a variety of analysis types from fields such as statistics, survey methodology, and/or other social science disciplines (e.g., univariate analyses, ANOVA, regression)Interpreting study results to identify patterns and solutions; converting complex data and findings into understandable tables, charts, and written reportsPreparing research reports, briefs, presentation decks, and other external communications summarizing research methods, findings, and implications for marketing strategies and advertising messaging. Tailoring these materials for non-technical audiencesSupporting projects employing qualitative design, data collection, and analysis methods. Lead or contribute to the creation of study protocols, developing interview and moderator guides, protocol testing, and quality control plansOverseeing project tasks and collaborating with project team on a day-to-day basis to work under tight deadlines to fulfill client requestsBalancing roles and responsibilities across multiple concurrent studies and/or tasksAnticipating potential barriers to project completion, proposing solutions to team leadership', 'We Offer:', 'Preparing research reports, briefs, presentation decks, and other external communications summarizing research methods, findings, and implications for marketing strategies and advertising messaging. Tailoring these materials for non-technical audiences', 'Experience conducting message or concept testing', 'Experience with data visualization tools and techniques to present data in different forms', 'Applicants may be subject to a low-level government security investigation and must meet eligibility criteria for access to sensitive information', 'Independently applying a variety of analysis types from fields such as statistics, survey methodology, and/or other social science disciplines (e.g., univariate analyses, ANOVA, regression)', 'Preferred qualifications:', 'Interpreting study results to identify patterns and solutions; converting complex data and findings into understandable tables, charts, and written reports', 'Strong proficiency and experience working with and interpreting data in at least one quantitative statistical analysis software package (e.g., SPSS, STATA, SAS) and Microsoft Excel', 'Advanced degree (MA, MS, PhD)', 'Strong knowledge of syntax/code in statistical software packages', 'Responsibilities include:', 'Supporting projects employing qualitative design, data collection, and analysis methods. Lead or contribute to the creation of study protocols, developing interview and moderator guides, protocol testing, and quality control plans', 'A highly collegial and intellectually stimulating work environment.A company culture promoting work/life balance.Highly competitive benefit/compensation package.', 'Experience presenting statistical analysis results to groups with non-data backgrounds', 'Experience working with government agencies such as FDA, CDC, CPSC, HHS, or similar preferred', 'Balancing roles and responsibilities across multiple concurrent studies and/or tasks', 'Experience in applied research as part of a government contract', 'Minimum of three years of professional research experience required', 'Assisting in the development of surveys and supporting materials including study protocols, data analysis plans, and quality control plans', 'Qualifications:', 'Anticipating potential barriers to project completion, proposing solutions to team leadership', 'A company culture promoting work/life balance.', 'Experience with qualitative and quantitative data collection and analysis.', 'Fors Marsh Group LLC is an Equal Opportunity Employer.\xa0M/F/Disability/Vet', 'BA/BS degree in communication, social science, public health, or related field, Advanced degree preferredMinimum of three years of professional research experience requiredExperience conducting message or concept testingExperience with qualitative and quantitative data collection and analysis.Strong proficiency and experience working with and interpreting data in at least one quantitative statistical analysis software package (e.g., SPSS, STATA, SAS) and Microsoft ExcelExperience presenting statistical analysis results to groups with non-data backgroundsExperience with data visualization tools and techniques to present data in different formsAbility to work well with others, as well as independently under minimal supervisionStrong verbal and written communications skillsApplicants may be subject to a low-level government security investigation and must meet eligibility criteria for access to sensitive information', 'Supporting the design, execution, and management of projects employing quantitative and qualitative data analysis', 'Native-level Spanish fluency', 'At Fors Marsh Group (FMG), we combine the power of science and strategy to improve people’s lives. Each day, we work with institutions and organizations that seek to disrupt markets, understand and influence behavior, drive action on a national scale, and create positive impact. Our approach extends far beyond our client portfolio—as a certified B Corporation and a 2020 Greenbook Top 50 Market Research Company, we make a difference in our community through corporate-sponsored employee volunteer programs and pro bono partnerships with values-aligned nonprofits. Most importantly, as a 2019 Washington Post Top Workplace, we are committed to putting people first and foster a culture that reflects that commitment. We are proud to be an equal opportunity employer, and we celebrate diversity and inclusivity as the foundation of a healthy, successful, and innovative work environment. Join us, and together we can work to ensure a better tomorrow.\xa0', 'Advanced degree (MA, MS, PhD)Native-level Spanish fluencyStrong knowledge of syntax/code in statistical software packagesProficiency with NVIVO or other qualitative analysis programsExperience in applied research as part of a government contractExperience working with government agencies such as FDA, CDC, CPSC, HHS, or similar preferred', 'Overseeing project tasks and collaborating with project team on a day-to-day basis to work under tight deadlines to fulfill client requests', 'A highly collegial and intellectually stimulating work environment.', 'Ability to work well with others, as well as independently under minimal supervision', 'BA/BS degree in communication, social science, public health, or related field, Advanced degree preferred', 'Proficiency with NVIVO or other qualitative analysis programs', 'FMG is seeking a highly organized, experienced, intelligent and motivated researcher in the area(s) of health communication, social marketing, persuasion, and/or social psychology, to support message testing activities for a large public service and advertising campaign for COVID-19. You will contribute to the design, execution, interpretation, and reporting of several ongoing message testing studies, employing quantitative and qualitative methodologies.', 'Strong verbal and written communications skills', 'Highly competitive benefit/compensation package.']",Mid-Senior level,Full-time,Research,Research,2020-11-05 11:32:32
Data Engineer,DDI | Development Dimensions International,United States,18 hours ago,48 applicants,"['', 'Experience with Microsoft SQL Server.', 'Work with a team to design, implement, and document best practices for data in the cloud.', 'Experience with modern data platforms, such as Databricks, Synapse, Snowflake, etc.', 'Preferred Qualifications', 'The Data Engineer will help design, build, and support our data and insights enablement solutions in the cloud. As part of an Agile solutions team, they will work to implement purpose-built data solutions for our internal and external stakeholders.', 'Interest in designing and implementing data management, querying, and storage systems.', 'Responsibilities', 'Experience with JavaScript frameworks - Angular, React.', 'Experience working in Azure.', 'Collaborate on the strategy of new cloud data stores and migration of existing data.', 'Strong Written and verbal communication skills.', 'Work with a team to design, implement, and document best practices for data in the cloud.Collaborate on the strategy of new cloud data stores and migration of existing data.Be an advocate for quality and security through data quality and accuracy validation and while using security best practices.Work collaboratively our product owners to understand requirements and business problems; to propose and develop solutions that enable effective decision-making through analytics and support insights that will drive our business growth.Support our cloud data platforms as part of an agile team.', 'Work collaboratively our product owners to understand requirements and business problems; to propose and develop solutions that enable effective decision-making through analytics and support insights that will drive our business growth.', 'Scripting languages: Python, PowerShell.', 'Support our cloud data platforms as part of an agile team.', 'Be an advocate for quality and security through data quality and accuracy validation and while using security best practices.', 'Experience with Git and Azure DevOps, JSON.', '1+ years’ experience working with Azure DatalakeExperience with modern data platforms, such as Databricks, Synapse, Snowflake, etc.Experience with Git and Azure DevOps, JSON.Scripting languages: Python, PowerShell.Experience working with data visualization tool – Power BI, Tableau, etc.Interest in designing and implementing data management, querying, and storage systems.Ability to build data sets and data pipelines.Experience in software engineering with full stack .NET development experience.Experience with JavaScript frameworks - Angular, React.Experience with Microsoft SQL Server.Experience working in Azure.Strong Written and verbal communication skills.', '1+ years’ experience working with Azure Datalake', 'Experience working with data visualization tool – Power BI, Tableau, etc.', 'Ability to build data sets and data pipelines.', 'Experience in software engineering with full stack .NET development experience.']",Mid-Senior level,Full-time,Information Technology,Human Resources,2020-11-05 11:32:32
Tableau Consultant,Accenture,"San Francisco, CA",10 hours ago,Be among the first 25 applicants,"['', 'You know your way around other data visualization toolsets such as Qlikview or Spotfire ', 'Here’s What You Need: ', 'Minimum of 2 year’s experience designing or developing with Tableau, including dashboards, reports, and/or front-end visualizations ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', 'You’re familiar with Business Intelligence tools including Cognos, Business Objects, OBIEE, methodologies, and/or responsibilities ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'You’re no newbie to Data Platforms such as Teradata, IBM, TM1, Netezza, DataMirror, Oracle, Essbase, GoldenGate, EMS, Greenplum', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Experience with database development including Custom SQL design, PLSQL, and/or Data Modeling ', 'Accenture Overview', 'Bonus Points If:', 'Equal Employment Opportunity:', 'Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'You’ve had experience with, or exposure to custom data visualization frameworks such as d3.js ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Accenture is committed to providing veteran employment opportunities to our service men and women. ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'You’ve got experience of full life-cycle development in a BI or Analytics environment ', 'The Work:', 'You Are:', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Business Development,Information Technology and Services,2020-11-05 11:32:32
Applied Scientist - AWS AI,Amazon Web Services (AWS),"East Palo Alto, CA",6 hours ago,Be among the first 25 applicants,"['', 'Description', "" Master's Degree in computer science, statistics, engineering, mathematics, or related field."", "" Master's Degree in computer science, statistics, engineering, mathematics, or related field. Specialization in machine learning, NLP, ASR, deep learning, computer vision, or related fields. 2 years of professional experience. Experience with machine learning/deep learning frameworks and libraries (TensorFlow, PyTorch, MXNet, Chainer, Caffe, Scikit, etc.) Knowledge of programming languages such as C/C++, Java, or Python (SciPy, RPy2, etc)."", ' Excellent written and verbal communication skills.', ' Specialization in machine learning, NLP, ASR, deep learning, computer vision, or related fields.', ' PhD degree with specialization in machine learning/deep learning and related fields. 3 years of proffesional experience in the field. Experience with data mining, Experience in High Performance Computing. Excellent written and verbal communication skills.', ' 2 years of professional experience.', ' Knowledge of programming languages such as C/C++, Java, or Python (SciPy, RPy2, etc).', 'Preferred Qualifications', ' PhD degree with specialization in machine learning/deep learning and related fields.', 'Company', ' Experience with data mining,', ' Experience with machine learning/deep learning frameworks and libraries (TensorFlow, PyTorch, MXNet, Chainer, Caffe, Scikit, etc.)', ' Experience in High Performance Computing.', ' 3 years of proffesional experience in the field.', 'Basic Qualifications']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
"Search Information Retrieval, Machine Learning Engineer (Staff/Senior)",Instacart,"San Francisco, CA",12 hours ago,Be among the first 25 applicants,"['', ' An expert with 5+ years of industry experience in information retrieval, machine learning, and natural language processing Have strong engineering skills with expertise in Python and fluency in data manipulation (SQL, Spark, Pandas) and machine learning (scikit-learn, XGBoost, Keras/Tensorflow) tools Demonstrated ability to work as part of a small, focused team and complete critical milestones under pressure Are a strong communicator who can collaborate with diverse stakeholders across all levels B.Sc. (required), M.S./PhD (preferred) in Computer Science, Mathematics, Statistics or related field', 'You will build new machine learning models to improve ranking and query understanding techniques based on the latest research in the field. You will work on state-of-art information retrieval techniques to recall results for product search queries in an efficient way. ', 'This is a senior individual contributor role leading projects with significant impact both within the machine learning team and on the product team(s) you will collaborate with.', 'You will evaluate relevance and quality of search results using state of the art methods.', ' This is a senior individual contributor role leading projects with significant impact both within the machine learning team and on the product team(s) you will collaborate with. You will build new machine learning models to improve ranking and query understanding techniques based on the latest research in the field. You will work on state-of-art information retrieval techniques to recall results for product search queries in an efficient way.  You will evaluate relevance and quality of search results using state of the art methods. You will design and code highly scalable, machine learning applications processing large volumes of data You will participate in the entire development lifecycle of Search projects, from concept to production release You will collaborate with other Machine Learning Engineers, Data Scientists and Product managers in crafting and implementing your technical vision You will evaluate relevance quality using state of the art methods You will coach and mentor the next generation of strong engineers on the team ', 'You will collaborate with other Machine Learning Engineers, Data Scientists and Product managers in crafting and implementing your technical vision', 'You will participate in the entire development lifecycle of Search projects, from concept to production release', 'Demonstrated ability to work as part of a small, focused team and complete critical milestones under pressure', 'B.Sc. (required), M.S./PhD (preferred) in Computer Science, Mathematics, Statistics or related field', 'About The Job', 'You will coach and mentor the next generation of strong engineers on the team', 'You will evaluate relevance quality using state of the art methods', 'About You', 'Overview', 'You will design and code highly scalable, machine learning applications processing large volumes of data', 'An expert with 5+ years of industry experience in information retrieval, machine learning, and natural language processing', 'Have strong engineering skills with expertise in Python and fluency in data manipulation (SQL, Spark, Pandas) and machine learning (scikit-learn, XGBoost, Keras/Tensorflow) tools', 'Are a strong communicator who can collaborate with diverse stakeholders across all levels']",Associate,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Multi View Machine Learning Researcher,"Fyusion, Inc","San Francisco, CA",16 hours ago,46 applicants,"['', 'Participating in the engineering life-cycle at Fyusion, including designing systems, writing production code, conducting code reviews and working alongside our design, engineering, and QA teams.', 'Create and maintain datasets for machine learning tasks. Manage data pipelines for training ML models on data uploaded by Fyusion customers.', 'BS/MS in Computer Science, or a related field.Proficient in Python (Pytorch or Tensorflow).Experience with machine learning using visual data is required.Experience with 3D geometry and/or multi-view data is a plus.Experience in C++ is a plus.', ""Here's what we are looking for:"", ""Demonstrate engineering skills. This is a hybrid research/engineering role. You'll be responsible for productionizing your pipelines/models and integrating them against our back-end services."", 'Define evaluation procedures for the developed algorithms.', 'Experience in C++ is a plus.', 'Work as part of a team and contribute to a common code base.', 'Implement and advance models from the research community, including literature surveys and implementing novel techniques from research papers.', 'Experience with 3D geometry and/or multi-view data is a plus.', 'Proficient in Python (Pytorch or Tensorflow).Experience with machine learning using visual data is required.', 'Fyusion is a machine learning & computer vision company that enables anyone to capture and display interactive 3D 360 images using their smartphone. Our unique 3D format allows for significant additional functionality that 2D images can’t offer, including: background image effects & automatic damage detection for cars, and an understanding of the human skeleton for tagging products & features in fashion E-commerce. Our investors and customers include large international conglomerates and industry leaders, which puts us in a unique and advantageous position. We have ambitious goals and are looking for new energetic team members to help us reach them together.\xa0', 'The research team at Fyusion develops and applies state of the art algorithms in visualization, 3D reconstruction, SLAM, bundle adjustment, state estimation, and sensor fusion. We are looking for candidates who are excited about solving complex problems at the intersection of classical 3D geometry and Deep Learning. You will have the resources and opportunities to publish your work at major conferences.', ""Here's the day-to-day:"", 'BS/MS in Computer Science, or a related field.', 'Robust exploratory/experimental skills. We have the largest multi-view dataset in the industry and are using both single- and multi-view visual data within our algorithms.', 'Maintain insight into trends and advances in machine learning.', 'Develop, test, and deploy ML models for various computer vision tasks.', ""Develop, test, and deploy ML models for various computer vision tasks.Robust exploratory/experimental skills. We have the largest multi-view dataset in the industry and are using both single- and multi-view visual data within our algorithms.Maintain insight into trends and advances in machine learning.Implement and advance models from the research community, including literature surveys and implementing novel techniques from research papers.Work as part of a team and contribute to a common code base.Create and maintain datasets for machine learning tasks. Manage data pipelines for training ML models on data uploaded by Fyusion customers.Define evaluation procedures for the developed algorithms.Demonstrate engineering skills. This is a hybrid research/engineering role. You'll be responsible for productionizing your pipelines/models and integrating them against our back-end services.Participating in the engineering life-cycle at Fyusion, including designing systems, writing production code, conducting code reviews and working alongside our design, engineering, and QA teams.""]",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Researcher (Downstream Development),TechObserver,"Exton, PA",24 hours ago,Be among the first 25 applicants,"['', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Ability to identify, investigate, and trouble-shoot basic process and equipment problems.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Strong written and oral communication skills and good interpersonal skills.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with process scale systems and chromatography columns a plus.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with analytical techniques such as HPLC, electrophoresis and ELISA desirable.', 'The Researcher of Downstream Development will be responsible for executing laboratory scale experiments for all aspects of protein purification including chromatography, filtration and membrane separations (TFF, UFDF, microfiltration, viral filtration, and depth filtration), investigating and evaluating novel technologies to improve current purification processes, participating in internal/external technology transfers, performing standard analytical methods to characterize biologics and reagents including UV/Vis spectroscopy, HPLC, electrophoresis and ELISA, participate in design and execution of viral clearance studies and participate in process validation experiments in support of late stage products. The individual will also be responsible for maintaining PD equipment and laboratories to ensure efficient, safe and effective operations of the laboratory. The individual might also participate in project subteams and provide cross-functional support for other departments at the discretion of management.', '\xa0', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Physical requirements: handling of laboratory equipment, chemicals and biological materials.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Team player who can excel in fast-paced entrepreneurial environment.', 'Job Summary', 'Education:\xa0BS or MS in biological sciences, chemistry, biochemistry or equivalent job experience/degree is strongly preferred.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Basic skills in designing and executing studies and interpreting data of technology transfer, scale-up, equipment validation studies.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Knowledge or experience with scale-up, technology transfer, process validation, viral clearance studies, and GMP manufacturing desirable.', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Hands-on experience with AKTA (Explorer, Avant, Pure) chromatography and filtration (TFF, NFF) systems is preferred.', 'Under general supervision, the Researcher of Downstream Development will be responsible for the development, optimization and scale-up of GMP compliant purification processes for monoclonal antibodies, antibody drug conjugates and recombinant proteins. The individual will provide expertise in purification process development and will be responsible for contributing to the planning, execution, analysis and reporting of experiments related to the development, optimization and scale-up of purification processes for the manufacture of early (Preclinical to Phase 2 ) and late stage (Phase 3 to commercial) biologic drug products.', 'Knowledge/Skills/Abilities Required', '•\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Minimum of 0-2 years practical scientific experience.', 'Education:', 'Experience:']",Mid-Senior level,Contract,Science,Publishing,2020-11-05 11:32:32
Data Engineer II,Apex Systems,"Redmond, WA",2 hours ago,Be among the first 25 applicants,[''],Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Applied Researcher 2 - Search Content,eBay,"San Jose, CA",17 hours ago,Be among the first 25 applicants,"['', '- Seek scientifically valid solutions that deliver real value to eBay customers', 'We are looking for stellar applied researchers to join us and build the next generation of content understanding technologies in eBay search. If you enjoy the scale and technical complexity of NLP problems and want to be at the frontier of applied research in information retrieval in e-commerce, join now.', 'Basic Qualifications', '- Experience with Python or R, and Java or Scala', 'eBay Inc. is an equal opportunity employer.\xa0 All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status.\xa0 If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com.\xa0 We will make every effort to respond to your request for disability assistance as soon as possible.', 'View our accessibility info', 'accessibility info', '- Experience in big data processing, e.g. Hadoop, SQL, Spark', '- Industrial experience with one or more of the following: classification, regression, recommendation systems, targeting systems, ranking systems, fraud detection, online advertising, or related', 'For more information see:', 'This website uses cookies to enhance your experience. By continuing to browse the site, you agree to our\xa0use of cookies', '- Present key technical and novel research work in public forums and conferences', '- 2 or more related publications in quality conferences or journals', 'Looking to make an impact on the future of global commerce? Do you want to shape how millions of people buy, sell, and engage around the world?', '- Work with multiple teams to help promote standard scientific methodologies and processes in your field', 'EEO is the Law Poster', 'Job Responsibilities', 'View our privacy policy', 'The Search Content, Item and Inventory Understanding team is part of the biggest organization that drives eBay’s world-wide impact. We innovate at the heart of ecommerce search, with the ambitious goal of redefining ecommerce search. We craft optimized experiences for buyers and sellers on eBay. We innovate rapidly in this space and there is no shortage of new challenges for motivated individuals.', '- 1-3 years (with PhD) or 3-5 years (with MS) of industrial experience in a related field', 'EEO is the Law Poster Supplement', '- Build machine learning models and data pipelines to deliver insightful yet practical solutions', '- MS or PhD in Computer Science, Statistics, Mathematics, or equivalent']",Mid-Senior level,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
"Senior Data Scientist, Game Analytics",Rockstar Games,"Carlsbad, CA",6 hours ago,56 applicants,"['', ' 7+ years in data science or similar role in the marketing, finance, forensics or technology fields required. Extensive knowledge of machine learning techniques such as k-NN, Naive Bayes, SVM, Decision Forests, Data Mining, Clustering, and Classification. Experience in pushing models to production and iterating on models in production. Proficiency in statistics such as distributions, predictive modeling, data validation, statistical testing, and regression. 5+ years of experience in machine learning / statistical languages and systems such as Python, Matlab, R. Bachelor’s degree in Computer Science or related field, with a strong quantitative background. Ability to develop and maintain good relations and communicate with people at all hierarchical levels. Strong problem-solving skills. Ability to reconcile technical and business perspectives. Autonomy and entrepreneurship. Strong team spirit. Passion for Rockstar Games and our titles. ', 'We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses, and machine learning applications.', 'Design, develop, and deliver machine learning enabled solutions to address critical business or game questions.', 'Required', 'Strong team spirit.', 'Bachelor’s degree in Computer Science or related field, with a strong quantitative background.', '5+ years of experience in machine learning / statistical languages and systems such as Python, Matlab, R.', 'Game industry experience strongly desired.', 'Responsibilities', 'Ability to reconcile technical and business perspectives.', '7+ years in data science or similar role in the marketing, finance, forensics or technology fields required.', 'The Rockstar Analytics team provide insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making.', 'We partner with multiple departments across the company to design and implement data and pipelines.', ' Assure Rockstar’s ongoing competitive advantage through best-in-class Machine Learning initiatives that have a high potential of applicability in industry. Identify and lead analytic experiments aligned with long-term strategic initiatives. Design, develop, and deliver machine learning enabled solutions to address critical business or game questions. Design and build validation tests to assess the efficiency of the model (or algorithm) in place and provide strategic insights to stakeholders. Conduct proactive in-depth analysis and predictive modeling to uncover hidden opportunities. Partner with data analysts, data engineers, data scientists, and stakeholders to better understand requirements, find bottlenecks, and implement resolutions. Collaborate with the Analytics Tech lead to establish best practices for repeated application. Help mentor and develop the skillsets of the junior team members within your team or department. Work within a team of data analysts and engineers. ', 'Identify and lead analytic experiments aligned with long-term strategic initiatives.', 'Autonomy and entrepreneurship.', 'PLUSES', 'Graduate degree (MBA, MSc or Master’s, PHD), an asset.', 'Conduct proactive in-depth analysis and predictive modeling to uncover hidden opportunities.', 'Collaborate with the Analytics Tech lead to establish best practices for repeated application.', 'Proficiency in statistics such as distributions, predictive modeling, data validation, statistical testing, and regression.', 'Work within a team of data analysts and engineers.', 'Strong problem-solving skills.', 'Experience in pushing models to production and iterating on models in production.', 'How To Apply', '4+ years using SQL (or a SQL-like language) required, other programming experience highly preferred.', 'Help mentor and develop the skillsets of the junior team members within your team or department.', 'Experience with Hadoop and pySpark an asset.', 'What We Do', 'Extensive knowledge of machine learning techniques such as k-NN, Naive Bayes, SVM, Decision Forests, Data Mining, Clustering, and Classification.', 'Passion for Rockstar Games and our titles.', ' 4+ years using SQL (or a SQL-like language) required, other programming experience highly preferred. Experience with Hadoop and pySpark an asset. Graduate degree (MBA, MSc or Master’s, PHD), an asset. Game industry experience strongly desired. ', 'Partner with data analysts, data engineers, data scientists, and stakeholders to better understand requirements, find bottlenecks, and implement resolutions.', 'Design and build validation tests to assess the efficiency of the model (or algorithm) in place and provide strategic insights to stakeholders.', ' The Rockstar Analytics team provide insights and actionable results to a wide variety of stakeholders across the organization in support of their decision making. We partner with multiple departments across the company to design and implement data and pipelines. We collaborate as a global team to develop cutting-edge data pipelines, data products, data models, reports, analyses, and machine learning applications. ', 'Assure Rockstar’s ongoing competitive advantage through best-in-class Machine Learning initiatives that have a high potential of applicability in industry.', 'Ability to develop and maintain good relations and communicate with people at all hierarchical levels.']",Associate,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Senior Big Data Engineer,"Techaxis, Inc",New York City Metropolitan Area,49 minutes ago,Be among the first 25 applicants,"['', 'You will help our clients navigate the complex world of modern data analytics.\xa0We’ll look to you to provide our clients with a unique business perspective on how Big Data analytics can transform and improve their entire organization – starting with key business issues they face.\xa0This is a high growth, high visibility area with plenty of opportunities to enhance your skill set and build your career.', '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0', 'IaC & Config Management: Tools like Chef, puppet, CloudFormation ,terraform, ansible, boto3 and/or Azure/GCP equivalent', 'Hands-on experience of core Operating systems like Linux RHEL, Ubuntu, System administration tasks including shell scripting\xa0', 'Demonstrating a deep understanding of big data technology, concepts, tools, features, functions, and benefits of different approaches', '\xa0', 'CI/CD pipeline management like git/bitbucket, and code deployment tools like Jenkins, sonar cube', 'Security tools/concepts like At Rest and in transit Encryption, IAM, key and certificate management, etc.', 'Ideally, you’ll also have', 'Seeking out information to learn about emerging methodologies and technologies', 'Network Engineering/Admin (vpc, subnet, security groups, VPC-Endpoints, nat/route tables, etc)', 'Skills and attributes for success', 'At least\xa0three years of hands-on\xa0experience with various\xa0Cloud and Big Data technologies\xa0', 'Clearly communicating findings, recommendations, and opportunities to improve data systems and solutions', ""A bachelor's degree and approximately\xa0three years of\xa0related\xa0work experience; or a master's degree and approximately two years of related work experience"", 'You’ll spend most of your time working with a wide variety of clients to deliver the latest big data technologies and practices to design, build and maintain scalable and robust solutions that unify, enrich and analyze data from multiple sources.\xa0\xa0', 'Solving problems by incorporating data into decision making\xa0\xa0', 'To qualify for the role you must have', 'Designing, Architecting, and Developing solutions leveraging cloud big data technology to ingest, process, and analyze large, disparate data sets to exceed business requirementsUnifying, enriching, and analyzing customer data to derive insights and opportunitiesLeveraging in-house data platforms as needed and recommending and building new data platforms/solutions as required to exceed business requirementsClearly communicating findings, recommendations, and opportunities to improve data systems and solutionsDemonstrating a deep understanding of big data technology, concepts, tools, features, functions, and benefits of different approachesSeeking out information to learn about emerging methodologies and technologiesClarifying problems by driving to understand the true issueLooking for opportunities for improving methods and outcomesApplying a data-driven approach (KPIs) in tying technology solutions to specific business outcomesCollaborating, influencing, and building consensus through constructive relationships and effective listeningSolving problems by incorporating data into decision making\xa0\xa0', 'Collaborating, influencing, and building consensus through constructive relationships and effective listening', 'At least\xa0two years of experience\xa0in\xa0implementing,\xa0automating,\xa0and\xa0integrating\xa0Big Data infrastructure resources like S3, Redshift, Aurora, Kinesis, Kafka, EMR, Lambda, SNS, Azure Blob Storage Account, SQL Data Warehouse, Microsoft Event Hubs, HDInsights, Azure Databricks, Azure Functions, Event Grid, Data Lake Analytics in an ephemeral/transient and in an elastic manner', 'Designing, Architecting, and Developing solutions leveraging cloud big data technology to ingest, process, and analyze large, disparate data sets to exceed business requirements', 'Unifying, enriching, and analyzing customer data to derive insights and opportunities', 'Looking for opportunities for improving methods and outcomes', 'related', 'Your key responsibilities', 'A valid driver’s license in the US; willingness and ability to travel to meet client needs.', 'Bachelor’s Degree or above in mathematics, information systems, statistics, computer science, or related disciplines', 'Independent and able to manage and prioritize workload.', ""A bachelor's degree and approximately\xa0three years of\xa0related\xa0work experience; or a master's degree and approximately two years of related work experienceAt least\xa0three years of hands-on\xa0experience with various\xa0Cloud and Big Data technologies\xa0At least\xa0two years of experience\xa0in\xa0implementing,\xa0automating,\xa0and\xa0integrating\xa0Big Data infrastructure resources like S3, Redshift, Aurora, Kinesis, Kafka, EMR, Lambda, SNS, Azure Blob Storage Account, SQL Data Warehouse, Microsoft Event Hubs, HDInsights, Azure Databricks, Azure Functions, Event Grid, Data Lake Analytics in an ephemeral/transient and in an elastic mannerIaC & Config Management: Tools like Chef, puppet, CloudFormation ,terraform, ansible, boto3 and/or Azure/GCP equivalentHands-on experience of core Operating systems like Linux RHEL, Ubuntu, System administration tasks including shell scripting\xa0Network Engineering/Admin (vpc, subnet, security groups, VPC-Endpoints, nat/route tables, etc)Experience with container technology like Docker, Kubernetes, etc.Security tools/concepts like At Rest and in transit Encryption, IAM, key and certificate management, etc.CI/CD pipeline management like git/bitbucket, and code deployment tools like Jenkins, sonar cubeCommunication is essential, must be able to listen and understand the question and develop and deliver clear insights.Outstanding team player.Independent and able to manage and prioritize workload.Ability to quickly and positively adapt to change.A valid driver’s license in the US; willingness and ability to travel to meet client needs."", 'The opportunity', 'Leveraging in-house data platforms as needed and recommending and building new data platforms/solutions as required to exceed business requirements', 'Clarifying problems by driving to understand the true issue', 'Experience with container technology like Docker, Kubernetes, etc.', 'Communication is essential, must be able to listen and understand the question and develop and deliver clear insights.', 'Outstanding team player.', 'Ability to quickly and positively adapt to change.', 'Applying a data-driven approach (KPIs) in tying technology solutions to specific business outcomes']",Mid-Senior level,Full-time,Engineering,Management Consulting,2020-11-05 11:32:32
"Machine Learning Engineer, TikTok Creator Marketplace",TikTok,"Mountain View, CA",15 hours ago,41 applicants,"['', '4. Good team player, communication skills and project management experience is preferred.', '2. Understand product objectives,  help developing a scalable and reliable system aligned with product target and requirements. ', 'Qualifications', '2. Demonstrated knowledge of machine learning technology (RecSys/NLP/CV).', ""1. Bachelor's degree or above, majoring in Computer Science or related fields."", '3. Closely follow state-of-the-art technologies, improve multimodal understanding of both advertisers and creators.', ""What You'll Do"", '5. Strong perseverance and courage to help the business to a higher level.', '1. Responsible for the development of machine learning solutions on online recommendation and matching.', 'TikTok is the leading destination for short-form mobile video and aims to inspire creativity and bring joy. Launched in over 150 markets and in 75 languages, TikTok has global offices including Mountain View, Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo. ', 'We are looking for Machine Learning Engineers to join our TikTok Creator Marketplace, which belongs to TikTok Creative Center. Creator Marketplace is dedicated to building a world-wide platform for all kinds of transactions between advertisers and creators, providing precise and efficient matching service and developing algorithm-based comprehensive solutions. The team has already achieved some milestones in this field and is a rising star facing the blue ocean of TikTok monetization.', '3. Passion for new technologies and proven capability in analysis and problem-solving.']",Associate,Full-time,Engineering,Internet,2020-11-05 11:32:32
"Sr. Data Scientist, Consumer Behavior",Wish,"Seattle, WA",5 hours ago,196 applicants,"['', 'Advanced degree in a quantitative field.A minimum of 3 years of Data Science experience in technology or research industry.Proficient in Python or RDeep statistical skills utilized in A/B testing, analyzing observational data, and modelingAn advanced ability to translate business questions into analysis and experiments that yield business insights and shape the company strategy', 'here', 'Research, identify and implement new frameworks to better measure success of our products and shape our strategy', 'Demonstrated track record of successful projects in applying quantitative techniques to improve a product or business.', 'Preferred Qualifications', 'A minimum of 3 years of Data Science experience in technology or research industry.', 'Mentor junior data scientists on how to use more advanced methods and solve business problems', 'Propose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process. ', 'Deep statistical skills utilized in A/B testing, analyzing observational data, and modeling', 'Proactively develop insights and models to help us understand user behavior, identify opportunities and make better product decisions.Lead the design, analysis, and interpretation of experiments that shape decision-making across the companyPropose, test and implement new experimentation methodologies, causal-inference approaches that can sharpen our product decision-making process. Research, identify and implement new frameworks to better measure success of our products and shape our strategyMentor junior data scientists on how to use more advanced methods and solve business problems', 'Demonstrated track record of successful projects in applying quantitative techniques to improve a product or business.7+ years work experience in technology or research industry.Domain expert in one of the fields: statistics, machine learning, optimization, and economics.', 'Additional Information', 'Advanced degree in a quantitative field.', 'Lead the design, analysis, and interpretation of experiments that shape decision-making across the company', 'Domain expert in one of the fields: statistics, machine learning, optimization, and economics.', 'Proactively develop insights and models to help us understand user behavior, identify opportunities and make better product decisions.', 'Qualifications', '7+ years work experience in technology or research industry.', 'Proficient in Python or R', 'Company Description', 'Job Description', 'An advanced ability to translate business questions into analysis and experiments that yield business insights and shape the company strategy', ""What you'll be doing:""]",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Senior Data Engineer,Symbotic,"Wilmington, MA",57 minutes ago,Be among the first 25 applicants,"['Our Research and Development team is currently in need of a Senior Data Engineer to join our fast-growing team. The ideal candidate will be intricately involved in creating ETL pipelines to generate data sets, run analytical experiments in a methodical manner, and evaluate alternate models via theoretical approaches. This is the perfect opportunity for the successful candidate to become a part of an innovative and energetic team that develops analysis tools which will influence both our products and clients.', 'Communicate results and ideas to key decision makers', 'Implement new statistical or other mathematical methodologies as needed for specific models or analysis', 'Research and develop statistical learning models for data analysisCollaborate with product management and engineering departments to understand company needs and devise possible solutionsKeep up-to-date with latest technology trendsCommunicate results and ideas to key decision makersImplement new statistical or other mathematical methodologies as needed for specific models or analysisOptimize joint development efforts through appropriate database use and project designImplement ETL pipelines to aggregate and enrich data to create meaningful data sets.', 'Optimize joint development efforts through appropriate database use and project design', 'Implement ETL pipelines to aggregate and enrich data to create meaningful data sets.', 'Keep up-to-date with latest technology trends', 'Collaborate with product management and engineering departments to understand company needs and devise possible solutions', 'Responsibilities', 'Research and develop statistical learning models for data analysis']",Associate,Full-time,Engineering,Industrial Automation,2020-11-05 11:32:32
"Staff Data Scientist - League Data Central, Gameplay",Riot Games,"Los Angeles, CA",39 minutes ago,26 applicants,"['', 'Our Perks', 'Experience working in an Agile environment', 'Identify opportunities for data-driven approaches that deliver value to teams across the organization, and champion data solutions to product leads and engineers', ' Ph.D. in Machine Learning, AI, Statistics, Math, Physics, or related Computer Science/Quantitative field with 3+ years of industry experience, or equivalent experience Deep knowledge of League of Legends gameplay and metagame systems (e.g. how progression through ranked ladder works) OR experience with a similar PVP competitive game Hands-on programming experience in Python and SQL Deep knowledge of data science methodologies, including machine learning, statistics, deep learning, optimization Experience in data science use cases and data engineering concepts (e.g., modeling, pipelines, distributed processing) Stakeholder management skills. Ability to build alignment, define scope, deliver, and maintain data science products Strong written and verbal communication skills. Ability to effectively present and share information across a wide array of technical expertise and seniority within the organization ', 'Improve our data science practice by identifying novel techniques and technical approaches', 'Responsibilities', '.', 'Experience with elo rating or similar ranking and match-making systems', 'Deep knowledge of data science methodologies, including machine learning, statistics, deep learning, optimization', 'Collaborate with team leadership, leading the execution and delivery of data science products that directly impact League of Legends systems and player experience ', '===', ' Collaborate with team leadership, leading the execution and delivery of data science products that directly impact League of Legends systems and player experience  Develop relationships with product and engineering teams to understand their data science needs Identify opportunities for data-driven approaches that deliver value to teams across the organization, and champion data solutions to product leads and engineers Work with stakeholders across the organization and on initiatives, gathering requirements, designing project plans, determining approaches, and defining success criteria Improve our data science practice by identifying novel techniques and technical approaches Act as a mentor to advise and level up data scientists in both data science and technical best practices ', ""It’s our policy to provide equal employment opportunity for all applicants and members of Riot Games, Inc. Riot Games makes reasonable accommodations for handicapped and disabled Rioters and does not unlawfully discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, handicap, veteran status, marital status, criminal history, or any other category protected by applicable federal and state law, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance relating to an applicant's criminal history (LAMC 189.00)."", 'Work with stakeholders across the organization and on initiatives, gathering requirements, designing project plans, determining approaches, and defining success criteria', 'Desired Qualifications', 'Stakeholder management skills. Ability to build alignment, define scope, deliver, and maintain data science products', ' Experience with elo rating or similar ranking and match-making systems Experience with Scala, Spark, big data tech (e.g., Hadoop) Experience with cloud data tools (AWS, GCP) Experience working in an Agile environment ', 'Required Qualifications', 'Staff Data Scientist on the League Data Central team', 'Deep knowledge of League of Legends gameplay and metagame systems (e.g. how progression through ranked ladder works) OR experience with a similar PVP competitive game', 'Experience with cloud data tools (AWS, GCP)', 'Experience with Scala, Spark, big data tech (e.g., Hadoop)', 'Hands-on programming experience in Python and SQL', 'Act as a mentor to advise and level up data scientists in both data science and technical best practices', 'Strong written and verbal communication skills. Ability to effectively present and share information across a wide array of technical expertise and seniority within the organization', 'Ph.D. in Machine Learning, AI, Statistics, Math, Physics, or related Computer Science/Quantitative field with 3+ years of industry experience, or equivalent experience', 'Develop relationships with product and engineering teams to understand their data science needs', 'Experience in data science use cases and data engineering concepts (e.g., modeling, pipelines, distributed processing)']",Not Applicable,Full-time,Engineering,Computer Games,2020-11-05 11:32:32
"Research Scientist, Sr",University of Massachusetts Medical School,"Worcester, MA",10 hours ago,Be among the first 25 applicants,"['', 'Bachelor’s degree in a Biological Science, or equivalent degree', 'Major Responsibilities', '7 years of research experience.', 'Responsible for data acquisition, data analysis, and presentation of research results. ', ' Direct Instillation of compounds into the gastrointestinal tract of rodents ', 'Current knowledge of pertinent literature.', ' In vitro studies with parasitic nematodes, including adult and larval stages ', 'Expertise in specific procedures and instrumentation necessary to complete specific research programs.', 'Bachelor’s degree in a Biological Science, or equivalent degree7 years of research experience.Familiarity with general laboratory procedures.Expertise in specific procedures and instrumentation necessary to complete specific research programs.Current knowledge of pertinent literature.Oral and written communication and presentation skillsAbility to travel to off-site locations', 'Preferred Qualifications', 'Organize and analyze data acquired in the course of research projects.', 'Participate regularly in laboratory meetings.', 'Write manuscripts and grant applications', 'Design and implement experiments designed to further ongoing research projects, in consultation with the principal investigator.', 'Supervision Received', ' Maintenance of the life cycle of parasitic nematodes, including hookworms (Ancylostoma, Necator), whipworms (Trichuris muris), and Heligmosomoides. ', ' Therapeutic studies with anthelmintic compounds in infection models ', 'Provide assistance in the general operation of the laboratory.', 'Perform other duties as required.', 'Design and implement research projects in the laboratory', 'Required Qualifications', 'Environmental Working Conditions', 'Design and implement experiments designed to further ongoing research projects, in consultation with the principal investigator.Organize and analyze data acquired in the course of research projects.Write manuscripts and grant applicationsDesign and implement research projects in the laboratoryResponsible for data acquisition, data analysis, and presentation of research results. Train and supervise junior lab personnel, ensuring staff is trained in current methodology and safety procedures in the laboratory.Prepare and present data for publication in public forums.Assist in the preparation of grant applications and other research proposals.Provide assistance in the general operation of the laboratory.Participate regularly in laboratory meetings.Stay current with the literature and regularly leads discussions of new reports pertinent to ongoing and proposed projectsPerform other duties as required.', 'Supervision Exercised', 'Ability to travel to off-site locations', 'Prepare and present data for publication in public forums.', 'General Summary Of Position', 'Train and supervise junior lab personnel, ensuring staff is trained in current methodology and safety procedures in the laboratory.', 'Assist in the preparation of grant applications and other research proposals.', 'Familiarity with general laboratory procedures.', ' Maintenance of the life cycle of parasitic nematodes, including hookworms (Ancylostoma, Necator), whipworms (Trichuris muris), and Heligmosomoides.  Therapeutic studies with anthelmintic compounds in infection models  Vaccine studies with hookworm antigens in infection models  Direct Instillation of compounds into the gastrointestinal tract of rodents  In vitro studies with parasitic nematodes, including adult and larval stages  Western blotting, SDS PAGE  RNA and DNA isolation from parasitic nematodes ', 'Oral and written communication and presentation skills', ' Vaccine studies with hookworm antigens in infection models ', ' RNA and DNA isolation from parasitic nematodes ', ' Western blotting, SDS PAGE ', 'Stay current with the literature and regularly leads discussions of new reports pertinent to ongoing and proposed projects']",Not Applicable,Full-time,Other,Research,2020-11-05 11:32:32
Data Engineer,HTC Global Services,"Washington, DC",19 hours ago,Be among the first 25 applicants,"['', 'Will be remote while Covid - maybe onsite starting Jan 2021...', 'Creating and managing postgres schemas, tables, functions in PGAdmin.', 'Creating Azure Data Factory (ADF) Pipeline', 'Creating Azure Data Factory (ADF) Pipelines which can read data from Azure Datalake(EDL)\xa0and MongoDB, copy filtered data to EDL, read functions from Postgres and finally get the cleaned data in EDL for tagging and training.', 'Create and manage inference pipelines in ADF which read from Databricks notebooks\xa0and import processed data to PostgresDB', 'Experience with NLP and Data Science experience', 'Creating Azure Data Factory (ADF) Pipelines which can read data from Azure Datalake(EDL)\xa0and MongoDB, copy filtered data to EDL, read functions from Postgres and finally get the cleaned data in EDL for tagging and training.Create and manage inference pipelines in ADF which read from Databricks notebooks\xa0and import processed data to PostgresDBExtract new data source from MongoDB using ADF and querying out required data at sourceCreating and managing postgres schemas, tables, functions in PGAdmin.Experience with NLP and Data Science experience', 'Extract new data source from MongoDB using ADF and querying out required data at source', 'Data Engineer']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
UX Researcher ,Insight Global,"Charlotte, NC",24 hours ago,65 applicants,"['Insight Global is looking for a UX Researcher to join a financial company in Charlotte, NC. You will: plan, execute and analyze user research studies with ability to flexibly scale them across desktop and mobile devices. Collaborate with stakeholders to define & refine research objectives and ensure alignment with strategic, business and user goals. Work closely with UX strategists, designers and fellow researchers to provide research expertise and support during workshops and ongoing UX activities. Collaborate with design team to conduct design research to enhance UI Standards & Design Pattern library. Interpret qualitative and quantitative data from web analytics, user research data, trends and patterns to create actionable recommendations at project and portfolio level. Elicit user needs and usability concerns through various research methods, such as interviews, surveys, usability testing, task analysis, contextual inquires, ethnographic studies, & card sorting. Evaluate and evolve user models (personas, scenarios, profiles). Perform heuristic evaluation, accessibility reviews and testing of applications and make concrete recommendations for improving their usability. Provide rapid prototyping support to communicate concepts/designs recommendations based on research conducted. Synthesize research data, summarize findings & present results to management and project teams for both strategic and project level insight.\xa0']",Mid-Senior level,Full-time,Research,Financial Services,2020-11-05 11:32:32
Senior Data Engineer,ReCharge Payments,"Los Angeles, CA",9 hours ago,Be among the first 25 applicants,"['', ' Hands-on leadership, influence, and development of all things data services. ', ' Expert proficiency in SQL ', ' Distill technical requirements into the product development and operational process via continuous collaboration with product, engineering, and analytics team members. ', ' Use analytics to influence product development, surfacing data around product usage and customer behavior. ', '  Typically, 6+ years experience in a data engineering related role (Data Warehouse Developer, ETL Developer, Business Intelligence Analytics, Software Engineer) with a track record of manipulating, processing and extracting value from datasets   Experience working with a variety of ETL platforms (Matillion {preferred}, CloverETL, FiveTran, Stitch, DBT, Spark, AWS Glue, DataFlow)   3+ years of hands-on experience designing and building ETL pipelines for ingesting, transforming and delivery of large amounts of data, from multiple sources into a Data Warehouse/Data Lake.   Experience with a variety of data storage platforms (Snowflake {preferred}, Redshift, MySQL, Postgres, Oracle, RDS)   Expert proficiency in SQL   Deep understanding and application of modern data processing technology and real-time/low-latency data pipeline and ETL architectures   Strong stakeholder interaction and influence experience at executive, business stakeholder, and engineering team levels   Bachelor degree or equivalent experience  ', ' Complete current evaluation of new ETL software options, propose recommendations, and implement the solution. ', ' Facilitate data transformation, normalization, cleansing, aggregation, workflow management, and business rule application. ', ""What You'll Bring"", ' Experience with a variety of data storage platforms (Snowflake {preferred}, Redshift, MySQL, Postgres, Oracle, RDS) ', ' Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues. ', ' Develop modern data architectural approaches for business intelligence reporting and analytics, including that for machine learning models and data science, ensuring effectiveness, scalability, and reliability. ', ' Design, develop, implement, and optimize existing ETL processes that merge data from disparate sources for consumption by data analysts and scientists, business owners, and decisions makers. ', ' Deep understanding and application of modern data processing technology and real-time/low-latency data pipeline and ETL architectures ', ' Influence and communicate with all levels of stakeholders including analysts, developers, business users, and executives. ', ' Bachelor degree or equivalent experience ', ' Live by and champion our values: #day-one, #ownership, #empathy, #humility. ', ' ETL tool evaluation and implementation to prepare for scaling and efficiency. ', ' Experience working with a variety of ETL platforms (Matillion {preferred}, CloverETL, FiveTran, Stitch, DBT, Spark, AWS Glue, DataFlow) ', ' Typically, 6+ years experience in a data engineering related role (Data Warehouse Developer, ETL Developer, Business Intelligence Analytics, Software Engineer) with a track record of manipulating, processing and extracting value from datasets ', ' Strong stakeholder interaction and influence experience at executive, business stakeholder, and engineering team levels ', ""What You'll Do"", 'Who We Are', 'Overview', ' 3+ years of hands-on experience designing and building ETL pipelines for ingesting, transforming and delivery of large amounts of data, from multiple sources into a Data Warehouse/Data Lake. ', '  Live by and champion our values: #day-one, #ownership, #empathy, #humility.   Hands-on leadership, influence, and development of all things data services.   Develop modern data architectural approaches for business intelligence reporting and analytics, including that for machine learning models and data science, ensuring effectiveness, scalability, and reliability.   Design, develop, implement, and optimize existing ETL processes that merge data from disparate sources for consumption by data analysts and scientists, business owners, and decisions makers.   Complete current evaluation of new ETL software options, propose recommendations, and implement the solution.   Facilitate data transformation, normalization, cleansing, aggregation, workflow management, and business rule application.   Detect data quality issues, identify their root causes, implement fixes, and design data audits to capture issues.   Distill technical requirements into the product development and operational process via continuous collaboration with product, engineering, and analytics team members.   Influence and communicate with all levels of stakeholders including analysts, developers, business users, and executives.   Use analytics to influence product development, surfacing data around product usage and customer behavior.   ETL tool evaluation and implementation to prepare for scaling and efficiency.  ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Data Engineer, Warehouse ",Bookbyte,"Salem, OR",19 hours ago,31 applicants,"['', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with public cloud solutions (i.e., AWS (preferred), Azure, GCP)', 'Preferred Qualifications', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa03+ years of data warehousing experience', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Ingest and transform structured and semi-structured data into data models', 'Working at Bookbyte also means full benefits, a competitive salary, and a friendly work environment. While Bookbyte is based out of Oregon, we are a remote-first company.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience in delivering solutions based on Agile principles', 'Bookbyte is looking for a Warehouse Data Engineer to help architect and develop our evolving data platform. The Warehouse Data Engineer role will be part of our growing data team, interfacing closely with software engineering. If you are a highly independent worker and have excellent organizational and problem-solving skills, this is the job for you.', '\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Develop automated data audit, testing, and validation processes', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Expert SQL skills and database ETL/ELT', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Conduct testing on large scale data platforms', 'Bookbyte is the largest 3rd party provider of product rentals on Amazon. Our remote-first organization is focused on real-time analysis of available market data to perform tens of thousands of pricing operations each minute.', 'Duties and Responsibilities', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Translate business requirements into technical specifications', 'Minimum Job Requirements', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with DBT', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0In-depth knowledge of relational databases (e.g. PostgreSQL, MSSQL)', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Create or update technical documentation for transition to support teams, including data flows and transformations', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Development, construction, and maintenance of data models within Data Warehouse(s) (Dimensional modeling/Kimball)', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Handle error logs and build robust data pipelines', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Stay up to date on ever-evolving technologies', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Participate in all design reviews and requirement sessions, as required', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Manage data lake(s)', 'This is a fully remote position.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Communicate ideas to both technical and non-technical people in all levels of the organization', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0BS in Computer Science, Engineering, or related field, or equivalent job experience\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with Snowflake', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Proficient with GIT', 'As a member of a small but growing data team, you will be working closely with business partners, and software engineering teams playing a vital role in the design, build, and maintenance of OLTP data stores; providing timely, accurate, and reliable information to all aspects of the business. As we incrementally improve and expand our company, you will be building new systems from the ground up or replacing legacy systems outright, free from supporting legacy code bases.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Understand database design, programming concepts, cloud architecture patterns, and data modeling', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Administration of Data Warehouse(s)', 'Summary']",Mid-Senior level,Full-time,Information Technology,Internet,2020-11-05 11:32:32
Scientists - Experimental Science & Plasma Control,General Atomics,"San Diego, CA",24 hours ago,Be among the first 25 applicants,"['', ' Radiofrequency physics experts for heating and current drive in tokamaks to understand detailed physical mechanisms and develop innovative RF approaches through engagement with hardware development, measurement, analysis, simulation, and experiments, including application and optimization of high performance plasma scenarios. ', 'Experience Level', ' Must possess the ability to independently (1) understand new concepts quickly; (2) apply them accurately throughout an evolving environment; (3) organize, schedule, and coordinate work phases; and, (4) determine the appropriate approach at the task level or, with assistance, at the project level to provide solutions to a range of complex problems. ', 'US Citizenship Required?', 'Full-Time/Part-Time', ' Publishing in recognized scientific journals and presenting work at national and international levels. ', ' Divertor optimization scientist, focusing on understanding the interplay between drift effects and divertor closure, and integrated data analysis of detached plasmas. The jobholder will also engage in development of state-of-the-art diagnostics for advanced divertor studies and associated analysis to support model validation. Experience in spectroscopy is desirable. ', ' Integrated modeling expert to analyze behavior in tokamak plasmas, using state of the art simulations to interpret phenomena and test physics concepts, and design new approaches or facility upgrades. Contribute to simulation tool development and provision to the wider team. ', ' Divertor optimization scientist, focusing on understanding the interplay between drift effects and divertor closure, and integrated data analysis of detached plasmas. The jobholder will also engage in development of state-of-the-art diagnostics for advanced divertor studies and associated analysis to support model validation. Experience in spectroscopy is desirable.  Plasma control science to develop advanced control solutions for tokamak plasmas on DIII-D, with opportunities to engage in international tokamaks. Activities include software development, control simulation, participating in and leading experiments, presenting and publishing results.  Senior plasma physics operator, experienced in leading complex tokamak experiment programs, organizing a team, and understanding the technical challenges and systems of a working tokamak.  Plasma scenario development expert, with knowledge of underlying and interconnected challenges faced in reaching high performance tokamak operation, and particularly issues of plasma stability. Activities include proposing and leading experiments, analysis, simulations, presenting and publishing results.  Integrated modeling expert to analyze behavior in tokamak plasmas, using state of the art simulations to interpret phenomena and test physics concepts, and design new approaches or facility upgrades. Contribute to simulation tool development and provision to the wider team.  Radiofrequency physics experts for heating and current drive in tokamaks to understand detailed physical mechanisms and develop innovative RF approaches through engagement with hardware development, measurement, analysis, simulation, and experiments, including application and optimization of high performance plasma scenarios.  Plasma stability and 3D response scientist to focus on control of edge localized modes and related measurement and physics of 3D magnetic perturbation techniques. Work will involve an appropriate mix of leading experiments, analyzing data, simulation and magnetic diagnostic support. There are also opportunities to work with the DIII-D disruption mitigation team and international collaborators to test and understand the physics of plasma quench techniques and associated plasma evolution.  Energetic particle scientist, to understand the physics of fusion self-heating and associated driven instabilities through experiments, analysis and development of innovative diagnostics. The jobholder will also connect the confinement of fast ions in DIII-D to performance improvement and control of advanced scenarios.  Programmer and analyst for diagnostic systems including charge exchange recombination measurements. This is a non-scientific role (minimum requirement Bachelor’s degree in relevant field), with focus on software and analysis support, and provision of excellent diagnostic capability. ', ' Plasma stability and 3D response scientist to focus on control of edge localized modes and related measurement and physics of 3D magnetic perturbation techniques. Work will involve an appropriate mix of leading experiments, analyzing data, simulation and magnetic diagnostic support. There are also opportunities to work with the DIII-D disruption mitigation team and international collaborators to test and understand the physics of plasma quench techniques and associated plasma evolution. ', ' Energetic particle scientist, to understand the physics of fusion self-heating and associated driven instabilities through experiments, analysis and development of innovative diagnostics. The jobholder will also connect the confinement of fast ions in DIII-D to performance improvement and control of advanced scenarios. ', ' Willingness to adjust working hours in accordance with the schedules and needs of the Fusion Division. ', 'Job Summary', ' Must have strong communication, computer, documentation, presentation, and interpersonal skills, ability to work independently and as part of a team; able to perform complex tasks in one scientific area; and, lead a team of less experienced professional employees on semi-routine tasks. ', 'Job Qualifications', ' Programmer and analyst for diagnostic systems including charge exchange recombination measurements. This is a non-scientific role (minimum requirement Bachelor’s degree in relevant field), with focus on software and analysis support, and provision of excellent diagnostic capability. ', ' Typically requires a Bachelors degree, Masters degree or PhD in a scientific or related technical field and progressively complex scientific experience as follows; six or more years experience with a Bachelors degree, four or more years experience with a Masters degree, and two or more with a PhD. ', ' Scientific leadership opportunities.  Work in the multidisciplinary team environment of the DIII-D tokamak.  Opportunities to work on various other national or international facilities.  Participation in experimental operation and support of DIII-D.  Publishing in recognized scientific journals and presenting work at national and international levels.  Perform other duties as assigned or required. ', 'Clearance Required?', ' Senior plasma physics operator, experienced in leading complex tokamak experiment programs, organizing a team, and understanding the technical challenges and systems of a working tokamak. ', ' Plasma scenario development expert, with knowledge of underlying and interconnected challenges faced in reaching high performance tokamak operation, and particularly issues of plasma stability. Activities include proposing and leading experiments, analysis, simulations, presenting and publishing results. ', ' Participation in experimental operation and support of DIII-D. ', ' Ability to communicate effectively with the scientific and engineering communities of DIII-D and collaborators, including written and oral technical presentations. ', ' Typically requires a Bachelors degree, Masters degree or PhD in a scientific or related technical field and progressively complex scientific experience as follows; six or more years experience with a Bachelors degree, four or more years experience with a Masters degree, and two or more with a PhD.  Must possess the ability to independently (1) understand new concepts quickly; (2) apply them accurately throughout an evolving environment; (3) organize, schedule, and coordinate work phases; and, (4) determine the appropriate approach at the task level or, with assistance, at the project level to provide solutions to a range of complex problems.  Must have strong communication, computer, documentation, presentation, and interpersonal skills, ability to work independently and as part of a team; able to perform complex tasks in one scientific area; and, lead a team of less experienced professional employees on semi-routine tasks.  Facility in moving rapidly from one task area to another, and ability to work extended hours and travel as required.  Ability to communicate effectively with the scientific and engineering communities of DIII-D and collaborators, including written and oral technical presentations.  Willingness to adjust working hours in accordance with the schedules and needs of the Fusion Division. ', ' Facility in moving rapidly from one task area to another, and ability to work extended hours and travel as required. ', 'Key Roles, Duties & Responsibilities', 'All positions will also involve:', ' Opportunities to work on various other national or international facilities. ', 'Travel Percentage Required', ' Work in the multidisciplinary team environment of the DIII-D tokamak. ', 'Job Category', ' Scientific leadership opportunities. ', ' Plasma control science to develop advanced control solutions for tokamak plasmas on DIII-D, with opportunities to engage in international tokamaks. Activities include software development, control simulation, participating in and leading experiments, presenting and publishing results. ', ' Perform other duties as assigned or required. ']",Not Applicable,Full-time,Science,Oil & Energy,2020-11-05 11:32:32
Principal Scientist,Bristol Myers Squibb,"Princeton, NJ",11 hours ago,Be among the first 25 applicants,"['', 'Manager Maryellen Cvijic', 'Position Overview/Key Responsibilities', 'Superior assay design and screening skills in both biochemical and cell-based assay formats as well as experience in the application of modern technology and automation are important assets for this position.', 'Advanced skills in data and computational analysis as well as ability to deploy tools for big data integration, data mining and predictive analytics for knowledge generation are compulsory.', 'TITLE Principal Scientist', 'Ph.D. in Biochemistry, Pharmacology or Cell Biology is required with a minimum of 10 years pharmaceutical industry experience.The successful candidate will be able to clearly demonstrate a consistent track record of impact on drug discovery programs through the judicious use of science and technology.Superior assay design and screening skills in both biochemical and cell-based assay formats as well as experience in the application of modern technology and automation are important assets for this position.Extensive knowledge of biochemistry, cell biology and pharmacology are required in addition to understanding physiologically relevant models and translational approaches.Advanced skills in data and computational analysis as well as ability to deploy tools for big data integration, data mining and predictive analytics for knowledge generation are compulsory.A “cutting edge” awareness of new technology advances and scientific knowledge in the high throughput screening field to apply for program support is essential.He or she must have a track record in building strategy and expanding functional capability in today’s dynamic and competitive environment.Ability to create and maintain an effective scientific network through teamwork, excellent problem solving skills and open collaborative style are of critical importance to the success of this role.Supervisory experience is essential to lead a group of scientists providing management and scientific support to lab members and promote their career developmentA communication style that will impart scientific credibility and create a strong positive image for LDO and BMS. Will be responsible for developing compelling scientific presentations and reports for internal review meetings and scientific journals.He or she must have a track record in building strategy and expanding functional capability in today’s dynamic and competitive environment. Ability to create and maintain an effective scientific network through teamwork, excellent problem solving skills and open collaborative style are of critical importance to the success of this role.Supervisory experience is essential to lead a group of scientists providing management and scientific support to lab members and promote their career developmentA communication style that will impart scientific credibility and create a strong positive image for LDO and BMS. Will be responsible for developing compelling scientific presentations and reports for internal review meetings and scientific journals.Around the world, we are passionate about making an impact on the lives of patients with serious diseases. Empowered to apply our individual talents and diverse perspectives in an inclusive culture, our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives.', 'Ph.D. in Biochemistry, Pharmacology or Cell Biology is required with a minimum of 10 years pharmaceutical industry experience.', 'Ability to create and maintain an effective scientific network through teamwork, excellent problem solving skills and open collaborative style are of critical importance to the success of this role.', 'Extensive knowledge of biochemistry, cell biology and pharmacology are required in addition to understanding physiologically relevant models and translational approaches.', 'A communication style that will impart scientific credibility and create a strong positive image for LDO and BMS. ', 'Will be responsible for developing compelling scientific presentations and reports for internal review meetings and scientific journals.', 'He or she must have a track record in building strategy and expanding functional capability in today’s dynamic and competitive environment. ', 'A “cutting edge” awareness of new technology advances and scientific knowledge in the high throughput screening field to apply for program support is essential.', 'He or she must have a track record in building strategy and expanding functional capability in today’s dynamic and competitive environment.', 'Supervisory experience is essential to lead a group of scientists providing management and scientific support to lab members and promote their career development', 'Location Lawrenceville', 'The successful candidate will be able to clearly demonstrate a consistent track record of impact on drug discovery programs through the judicious use of science and technology.']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
"Senior Product Data Scientist, Cash App",Cash App,"San Francisco, CA",11 hours ago,Be among the first 25 applicants,"['', 'Approach problems from first principles, using a variety of statistical and mathematical modeling techniques to research and understand customer behavior', 'Python (Pandas, Numpy)', 'For All Of The Above Roles, You Have', 'Build and share data visualizations and self-serve dashboards for your product team', 'A PhD or other relevant graduate degree in the physics, economics, statistics, or a similar STEM field', 'Analyze large datasets using SQL and scripting languages to surface meaningful/actionable insights and opportunities to the product team and other key stakeholders', 'Experience in a high-growth tech environment', 'Technologies We Use And Teach', 'Build, forecast, and report on metrics that drive strategy and facilitate decision making for key business initiatives', 'For all of the above roles, you will:', 'Work with engineers to log new, useful data sources as we build new product features', 'Support', 'Experience with cohort and funnel analyses, a deep understanding statistical concepts such as selection bias, probability distributions, and conditional probabilities', 'Banking', '1-2 years of data science and analytics experience in industry', 'Intellectual curiosity and a passion for what Cash App is building', 'Design and analyze A/B experiments to evaluate the impact of changes we make to the product', 'Partner directly with a Cash App product team, working closely with product managers, engineers, and designers', 'Write code to effectively process, cleanse, and combine data sources in unique and useful ways, often resulting in curated ETL datasets that are easily used by the broader team', 'Qualifications', 'SQL (MySQL, Snowflake, BigQuery, etc.)', 'SQL (MySQL, Snowflake, BigQuery, etc.)Python (Pandas, Numpy)Tableau, Airflow, Looker', 'Tableau, Airflow, Looker', '1-2 years of data science and analytics experience in industryA PhD or other relevant graduate degree in the physics, economics, statistics, or a similar STEM fieldExperience with scripting and data analysis programming languages, such as Python or RAdvanced proficiency with SQL and data visualization tools (e.g. Tableau, Looker, etc)Experience with cohort and funnel analyses, a deep understanding statistical concepts such as selection bias, probability distributions, and conditional probabilitiesExperience in a high-growth tech environmentAn appreciation for the connection between your work and the experience it delivers to customersIntellectual curiosity and a passion for what Cash App is building', 'Company Description', 'Job Description', 'Advanced proficiency with SQL and data visualization tools (e.g. Tableau, Looker, etc)', 'Effectively communicate your work with team leads and cross-functional stakeholders on a regular basis', 'Experience with scripting and data analysis programming languages, such as Python or R', 'Partner directly with a Cash App product team, working closely with product managers, engineers, and designersAnalyze large datasets using SQL and scripting languages to surface meaningful/actionable insights and opportunities to the product team and other key stakeholdersApproach problems from first principles, using a variety of statistical and mathematical modeling techniques to research and understand customer behaviorDesign and analyze A/B experiments to evaluate the impact of changes we make to the productWork with engineers to log new, useful data sources as we build new product featuresBuild, forecast, and report on metrics that drive strategy and facilitate decision making for key business initiativesWrite code to effectively process, cleanse, and combine data sources in unique and useful ways, often resulting in curated ETL datasets that are easily used by the broader teamBuild and share data visualizations and self-serve dashboards for your product teamEffectively communicate your work with team leads and cross-functional stakeholders on a regular basis', 'An appreciation for the connection between your work and the experience it delivers to customers']",Associate,Full-time,Other,Computer Software,2020-11-05 11:32:32
Senior Data Scientist,Virgin Pulse,"Minneapolis, MN",7 hours ago,26 applicants,"['', ' Leverage existing studies, literature, and analyses into current research and analysis projects ', ' Conduct ad-hoc analysis using varied analytical tools and techniques, including advanced statistics ', ' A Master’s degree in statistics, computer science, economics, or related field; further Advanced degree is a plus ', ' Troubleshoot and perform  data  audits to ensure and improve  data  integrity; investigate and resolve  data  discrepancies ', ' Comfort working in a global environment with remote teams ', ' Employee health management/health engagement industry preferred ', 'We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to any protected class status.', ' Experience with clinical/medical data and work in employee health management/health engagement industry preferred ', 'Responsibilities', ' Creative energy, self-starter, works equally well independently and collaboratively ', ' Work with Insights departmental processes, projects and programs using Smartsheet, MS and Atlassian toolsets to keep projects and milestones on schedule, our collaborative and internal work organized as well as externally facing documentation comprehensive, updated, and accessible ', 'Minneapolis, MN', ' Strong analytical ability, with an emphasis on quantitative analysis, descriptive and inferential statistics ', ' Aptitude to learn new technologies and troubleshoot complex problems independently ', ' Consult to and collaborate with Product, Reporting, Analytics and Client Success team members to ensure appropriate data is analyzed and that results are provided in a format consistent with standard and customized client reporting services ', ' Write Python, R and SQL programs to access, clean, and transform required data prior to analysis and reporting ', 'Options', ' Design, conduct and manage new analytical research projects and experiments, starting with project planning, hypothesis development and data gathering, then to analysis and modeling, and through to communications and recommendations ', ' Experience in managing medium and large-scale analytics projects from end to end ', 'To Represent The Best Of What We Have To Offer, You Come To Us With a Multitude Of Positive Attributes, Including', ' Excellent communication and organization skills with the ability to manage competing priorities, meet deadlines, and process ad-hoc requests ', ' Design, conduct and manage new analytical research projects and experiments, starting with project planning, hypothesis development and data gathering, then to analysis and modeling, and through to communications and recommendations  Leverage existing studies, literature, and analyses into current research and analysis projects  Write Python, R and SQL programs to access, clean, and transform required data prior to analysis and reporting  Troubleshoot and perform  data  audits to ensure and improve  data  integrity; investigate and resolve  data  discrepancies  Develop and deliver analysis results using various visualization and presentation software/tools, such as R/Toolkit, Tableau, MS Powerpoint, MS Word, etc.  Consult to and collaborate with Product, Reporting, Analytics and Client Success team members to ensure appropriate data is analyzed and that results are provided in a format consistent with standard and customized client reporting services  Conduct ad-hoc analysis using varied analytical tools and techniques, including advanced statistics  Support Sales, Marketing, and Client Success staff with Virgin Pulse clients and prospects by directly communicating on data and analytics processes and projects, as well as the results of analyses  Work with Insights departmental processes, projects and programs using Smartsheet, MS and Atlassian toolsets to keep projects and milestones on schedule, our collaborative and internal work organized as well as externally facing documentation comprehensive, updated, and accessible  Achieve annual Key Performance Indicator objectives, which can include report volumes and scope, internal and external client satisfaction, introducing new areas of data and analysis, and influencing company product and process decisions ', ' Experience with producing and delivering results using varied media (i.e. multiple MS office formats, dashboards/visualization tools) ', ' Develop and deliver analysis results using various visualization and presentation software/tools, such as R/Toolkit, Tableau, MS Powerpoint, MS Word, etc. ', 'Qualifications', ' Strong organizing and coordination of work products, documents, and content for publication and distribution ', ' Experience in providing consultative guidance and contributing to the growth and development of others ', ' Flexibility and ability to adapt to changes in priority quickly and seamlessly ', 'Overview', 'Skills', ' Experience working with large-scale datasets and multiple projects simultaneously ', ' Knowledge of data visualization tools preferred (i.e. Tableau, R: Shiny, ggplot2) ', ' A Master’s degree in statistics, computer science, economics, or related field; further Advanced degree is a plus  A minimum of seven years of work experience in a similar path, history of increasing responsibilities a plus ;  Employee health management/health engagement industry preferred  Advanced knowledge and recent hands-on experiences in SQL databases, Redshift preferred  Extensive experience coding in at least one scripting language, such as R or Python  Knowledge of data visualization tools preferred (i.e. Tableau, R: Shiny, ggplot2)  Experience with producing and delivering results using varied media (i.e. multiple MS office formats, dashboards/visualization tools)  Experience in managing medium and large-scale analytics projects from end to end  Experience with clinical/medical data and work in employee health management/health engagement industry preferred  Comfort working in a global environment with remote teams ', ' Strong collaboration, process and project management skills  Strong analytical ability, with an emphasis on quantitative analysis, descriptive and inferential statistics  Experience working with large-scale datasets and multiple projects simultaneously  Aptitude to learn new technologies and troubleshoot complex problems independently  Creative energy, self-starter, works equally well independently and collaboratively  Flexibility and ability to adapt to changes in priority quickly and seamlessly  Strong organizing and coordination of work products, documents, and content for publication and distribution  Excellent communication and organization skills with the ability to manage competing priorities, meet deadlines, and process ad-hoc requests  Experience in providing consultative guidance and contributing to the growth and development of others ', ' Strong collaboration, process and project management skills ', ' Who you are ', ' A minimum of seven years of work experience in a similar path, history of increasing responsibilities a plus ; ', ' Advanced knowledge and recent hands-on experiences in SQL databases, Redshift preferred ', ' data ', 'Providence, RI', ' Achieve annual Key Performance Indicator objectives, which can include report volumes and scope, internal and external client satisfaction, introducing new areas of data and analysis, and influencing company product and process decisions ', 'Remote', ' In addition, you possess the following additional competencies and characteristics: ', ' Extensive experience coding in at least one scripting language, such as R or Python ', ' Support Sales, Marketing, and Client Success staff with Virgin Pulse clients and prospects by directly communicating on data and analytics processes and projects, as well as the results of analyses ']",Associate,Full-time,Other,Computer Software,2020-11-05 11:32:32
Senior Data Engineer,"Management Science Associates, Inc.","Pittsburgh, PA",3 hours ago,Be among the first 25 applicants,"['', 'Ability to refine existing analytical processes to maximize run-time efficiencies.', 'Microsoft office skills including MS Word, MS Excel, MS PowerPoint, MS Outlook and MS Access.', 'Proficient with file access methods and experience with various database technologies such as Oracle, SQL, Access, Hadoop.', 'Organized with effective time management skills and the ability to multi-task and meet deadlines.', 'High degree of flexibility; accepting of change and uncertainty.', 'Experience working with transactional POS / scan data is a plus.', ""Bachelor's degree in Quantitative Analytics, Business Analytics, Math, Statistics, Economics, Computer Science or related discipline, or equivalent experience. Relevant Master's degree may substitute for up to one year of related experience. PhD may substitute for up to five years of experience depending on discipline."", 'Develop ongoing data quality checks.', 'Mentor, train and guide division personnel.', 'Conduct research and experiments to become an expert with the most cutting edge technologies and methodologies, data mining techniques, machine learning and data visualization. Provide technical guidance to internal and/or external clients.', 'Responsibilities', 'Strong analytical, problem solving, critical thinking, data management, and organizational skills. Desire to analyze large data sets, find the truth in data, and develop efficient processes for data analysis.', 'Overview: ', 'Perform testing and debugging. Resolve unexpected problems ranging in complexity resulting from unusual data and limitations inherent in software applications and data processing resources.', 'Write and maintain complex SQL queries on large databases.', 'Advanced knowledge of data mining techniques and applications and data pattern recognition, knowledge of database technologies, big data, and information visualization.', ' Conduct extensive data mining and analysis to resolve complex data issues. May interact with clients depending on project needs. Work with cross-functional team members to conduct independent and collaborative analytical work.  Design moderately complex and efficient code to manipulate large datasets and conduct analysis. Perform testing and debugging. Resolve unexpected problems ranging in complexity resulting from unusual data and limitations inherent in software applications and data processing resources. Write and maintain complex SQL queries on large databases. Develop ongoing data quality checks. Conduct research and experiments to become an expert with the most cutting edge technologies and methodologies, data mining techniques, machine learning and data visualization. Provide technical guidance to internal and/or external clients. Mentor, train and guide division personnel. ', 'Design moderately complex and efficient code to manipulate large datasets and conduct analysis.', 'Highly detail-oriented, with an eye for quality standards. Experience with Six Sigma or Statistical Process Control preferred, but not required.', 'Passionate about data integrity, with the desire to solve data mysteries through deep dive root cause analysis.', 'Demonstrated problem solving skills with the ability to maintain an open mind and think creatively about problems and their resolution.', 'Required Skills', "" Bachelor's degree in Quantitative Analytics, Business Analytics, Math, Statistics, Economics, Computer Science or related discipline, or equivalent experience. Relevant Master's degree may substitute for up to one year of related experience. PhD may substitute for up to five years of experience depending on discipline. Minimum five years of related experience performing analytical problem solving within market research, data analytics, computer science, or related field. Advanced knowledge of data mining techniques and applications and data pattern recognition, knowledge of database technologies, big data, and information visualization. Strong analytical, problem solving, critical thinking, data management, and organizational skills. Desire to analyze large data sets, find the truth in data, and develop efficient processes for data analysis. Organized with effective time management skills and the ability to multi-task and meet deadlines. Highly detail-oriented, with an eye for quality standards. Experience with Six Sigma or Statistical Process Control preferred, but not required. Passionate about data integrity, with the desire to solve data mysteries through deep dive root cause analysis. Innovative and proactive in solving technical problems and identifying process improvements and efficiencies. Strong coding skills in languages such as C++, VBA, SQL, Python, Java with the ability to work from general specifications to develop user-friendly interactive tools for leveraging the analytics as well as potentially develop and deliver client-ready software solutions. Ability to refine existing analytical processes to maximize run-time efficiencies. Proficient with file access methods and experience with various database technologies such as Oracle, SQL, Access, Hadoop. Strong and effective communication, both written and oral, coupled with highly developed interpersonal skills to effectively communicate in a professional manner. Ability to communicate technical topics to a non-technical audience in a concise, easy to understand way. Microsoft office skills including MS Word, MS Excel, MS PowerPoint, MS Outlook and MS Access. Demonstrated problem solving skills with the ability to maintain an open mind and think creatively about problems and their resolution. Strong work ethic and commitment to getting the job done. Self-motivated for continued learning and growth. High degree of flexibility; accepting of change and uncertainty. Applies mastery and broad understanding in a specific field such as database systems and machine learning to business projects. Experience working with transactional POS / scan data is a plus."", 'Self-motivated for continued learning and growth.', 'Work with cross-functional team members to conduct independent and collaborative analytical work. ', 'Conduct extensive data mining and analysis to resolve complex data issues. May interact with clients depending on project needs.', 'Strong coding skills in languages such as C++, VBA, SQL, Python, Java with the ability to work from general specifications to develop user-friendly interactive tools for leveraging the analytics as well as potentially develop and deliver client-ready software solutions.', 'Strong and effective communication, both written and oral, coupled with highly developed interpersonal skills to effectively communicate in a professional manner. Ability to communicate technical topics to a non-technical audience in a concise, easy to understand way.', 'Applies mastery and broad understanding in a specific field such as database systems and machine learning to business projects.', 'Minimum five years of related experience performing analytical problem solving within market research, data analytics, computer science, or related field.', 'Innovative and proactive in solving technical problems and identifying process improvements and efficiencies.', 'Strong work ethic and commitment to getting the job done.']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Orangetheory Fitness,"Boca Raton, FL",19 hours ago,Be among the first 25 applicants,"['', 'We offer a competitive salary along with exceptional benefits such as:', 'SUPERIVISORY REQUIREMENTS', 'POSITION TYPE ', 'State-of-the-Art Wellness Center at Corporate Headquarters', 'EEO STATEMENT', 'TRAVEL', '·\xa0\xa0\xa0\xa0\xa0\xa0Experience with both Object Oriented and Functional programming paradigms', '·\xa0\xa0\xa0\xa0\xa0\xa05+ years of experience building large scale data pipelines, designing cloud architectures, working with scientists who work in various reporting and analytics capacities', '·\xa0\xa0\xa0\xa0\xa0\xa0Experience working with Snowflake data warehouses', 'We are looking for a passionate and experienced Sr. Data Engineer to join the ML and Analytics team at\xa0Orangetheory® Fitness. This is a senior position perfect for an experienced data engineer looking for an opportunity to join a leader in the fitness franchise industry. If you are keen on getting in on projects on the ground floor, helping define the architecture and ETL pipelines for the movement of large amounts of data, and enabling the end to end deployment of complex ML pipelines, this is the team for you.\xa0The Sr. Data Engineer will use a breadth of knowledge to deliver highly available, scalable and cost-effective data architectures. You will demonstrate a comfort with ambiguity and play the role of a technical leader, guiding simple yet creative solutions to complex problems. The end-to-end analytics enabled by this role will be critical in drawing insight from large and complex data sets and\xa0using these insights to drive analytical thinking at all levels of the company.', 'This position is expected to provide technical mentorship to all levels of the Analytics organization. Additionally, this role will supervise incoming entry level Data Engineers.', 'PREFERRED SKILLS', '·\xa0\xa0\xa0\xa0\xa0\xa0Experience writing highly optimized and efficient SQL', 'SUMMARY/OBJECTIVE', '·\xa0\xa0\xa0\xa0\xa0\xa0Create an environment that allows for the exploration and exploitation of our rich datasets', 'ACCOUNTABILITIES', '\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0Make data more available', 'Orangetheory Fitness provides equal employment opportunity to all individuals regardless of their race, color, creed, religion, gender, age, sexual orientation, national origin, disability, veteran status, or any other characteristic protected by state, federal, or local law.\xa0Discrimination of any type will not be tolerated.', '·\xa0\xa0\xa0\xa0\xa0\xa0Continuous integration, automation, change control, as well as scalable and performant designs', 'Paid Time Off', '·\xa0\xa0\xa0\xa0\xa0\xa05+ years of experience working in an AWS heavy environment and a breadth of knowledge and familiarity with core AWS storage and data pipelining services. (Redshift, EMR, RDS, Glue, Kinesis, Dynamo DB, Firehose)', '·\xa0\xa0\xa0\xa0\xa0\xa0Experience working in a big data environment, moving large amounts of data through complex pipelines', 'Team Building, Employee Engagement activities and so much more', ' This is a Full-Time position', 'Orangetheory® Fitness is one of the fastest-growing global fitness franchises with studios located throughout the United States as well as internationally.\xa0We are a scientifically designed, one-of-a-kind, group personal training workout broken into intervals of cardiovascular and strength training. Led by highly skilled coaches, each Orangetheory Fitness workout incorporates endurance, strength, and power elements through a variety of equipment including treadmills, rowing machines, TRX® suspension training and free weights.\xa0\xa0We have over 1,200 locations open in the United States and currently operate 150+ International studios in 23 countries with more than 400 new fitness studios under development across the nation and internationally.', '\xa0\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0Interpret requirements from the business analysis and data science teams to deliver optimal solutions', 'Free workouts at corporate studios', 'Parental Leave Pay', 'Healthcare Benefits: Medical, Dental, Vision among many other supplemental benefits', '·\xa0\xa0\xa0\xa0\xa0\xa0Implement and maintain highly available and stable data ingestion pipelines using industry standard ETL/ELT best practices', '·\xa0\xa0\xa0\xa0\xa0\xa0Experience executing spark jobs through YARN on EMR clusters', '·\xa0\xa0\xa0\xa0\xa0\xa0Provide mentorship and thought partnership to data engineers, scientists and analyst across the analytics organization', '401k Plan with Employer Contribution', ' ', '·\xa0\xa0\xa0\xa0\xa0\xa0Guide the constant improvement of the analytics data ingestion and routing mechanism and ensure that the systems stay current and up to date', '·\xa0\xa0\xa0\xa0\xa0\xa0Collaborate closely with ML scientists and BI engineers/analysts to facilitate fast and efficient algorithm development', '\xa0\xa0\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0Bachelor’s degree in a quant/tech field like Computer Science, Computer Engineering or Statistics', '·\xa0\xa0\xa0\xa0\xa0\xa03+ years of experience working in Python', ' This position does not require travel; however, travel may be required for training initiatives and/or visits to collaborate with business partners on rare occasions.', 'Holiday Pay', 'REQUIREMENTS & SKILLS', '·\xa0\xa0\xa0\xa0\xa0\xa0High level understanding and knowledge of core statistical and data science concepts are a plus', 'WHY JOIN ORANGETHEORY CORPORATE?', '·\xa0\xa0\xa0\xa0\xa0\xa02+ years of experience with PySpark including experience interfacing with a wide variety of data sources and targets using PySpark', 'Employer Paid Benefits: Long-Term Disability and Life Insurance', '·\xa0\xa0\xa0\xa0\xa0\xa0Quickly identify weaknesses, data integrity lapses and bugs in our data ingestion pipelines and remedy them', '·\xa0\xa0\xa0\xa0\xa0\xa0Experience with the standard software development lifecycle including code reviews, source control management, CI/CD etc.']",Mid-Senior level,Full-time,Information Technology,"Health, Wellness and Fitness",2020-11-05 11:32:32
Sr. Data Engineer,SmileDirectClub,"Nashville, TN",7 hours ago,Be among the first 25 applicants,"['', ' What are our customers saying? Link here. ', ' What is SmileDirectClub? Link here.  What are our customers saying? Link here.  What is a SmileShop? Link here.  What is our culture like? Link here.  How do we celebrate your team members? Link here. ', ' Possesses strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems, and information retrieval ', ' Medical, Dental and Vision Insurance  401K with match  PTO  Aligner and Whitening Benefit  Collaborative work environment and positive culture ', ' How do we celebrate your team members? Link here. ', 'Job Type ', 'Responsibilities', ' Design, build, and maintain large software systems ', ' What is our culture like? Link here. ', ' Need help finding the right job? ', 'Company Profile', ' Collaborative work environment and positive culture ', ' Work closely with Analytics, Marketing, Finance, and Operations teams to understand data and analysis requirements ', ' Medical, Dental and Vision Insurance ', 'Options', ' Design and build new dimensional data models and schema designs to improve accessibility, efficiency, and quality of internal analytics data  Build, monitor, and maintain analytics data ETL pipelines  Implement systems for tracking data quality and consistency  Work closely with Analytics, Marketing, Finance, and Operations teams to understand data and analysis requirements  Work with teams to continue to evolve data models and data flows to enable analytics for decision making (e.g., improve instrumentation, optimize logging, etc)  Design, build, and maintain large software systems ', ' Has built large-scale data pipelines professionally and can craft clean and beautiful code in Java, Scala, Python and/or SQL ', ' PTO ', ' Work with teams to continue to evolve data models and data flows to enable analytics for decision making (e.g., improve instrumentation, optimize logging, etc) ', ' Has a curiosity about how things work ', ' Is someone that others enjoy working with due to your technical competence and positive attitude ', 'Qualifications', ' What is a SmileShop? Link here. ', ' 401K with match ', ' Aligner and Whitening Benefit ', 'Benefits Of Joining The Club', ' Implement systems for tracking data quality and consistency ', ' Can jump into situations with few guardrails and make things better ', ' Has experience with ETL jobs, metrics, alerting, and/or logging ', ' Has experience with MPP data warehouses (Redshift, Snowflake, or similar) ', 'Overview', ' Has a curiosity about how things work  Has built large-scale data pipelines professionally and can craft clean and beautiful code in Java, Scala, Python and/or SQL  Has built batch data pipelines with Hadoop/Spark as well as with relational database engines, and understands their respective strengths and weaknesses  Has experience with ETL jobs, metrics, alerting, and/or logging  Can jump into situations with few guardrails and make things better  Possesses strong computer science fundamentals: data structures, algorithms, programming languages, distributed systems, and information retrieval  Is a strong communicator. Explaining complex technical concepts to product managers, support, and other engineers is no problem for you  When things break, and they will, is eager and able to help fix them  Has experience with MPP data warehouses (Redshift, Snowflake, or similar)  Is someone that others enjoy working with due to your technical competence and positive attitude ', ' Design and build new dimensional data models and schema designs to improve accessibility, efficiency, and quality of internal analytics data ', ' Is a strong communicator. Explaining complex technical concepts to product managers, support, and other engineers is no problem for you ', ' When things break, and they will, is eager and able to help fix them ', ' Has built batch data pipelines with Hadoop/Spark as well as with relational database engines, and understands their respective strengths and weaknesses ', ' What is SmileDirectClub? Link here. ', ' Build, monitor, and maintain analytics data ETL pipelines ']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Design Researcher,"eXcell, a division of CompuCom Systems","Redmond, WA",1 hour ago,Be among the first 25 applicants,"['', 'Communicate, defend, and build consensus around your research and how it informs design', 'Strong oral and written communication skills', 'Required Qualifications:', 'Work with the supervising Researcher or Manager in addressing critical usability issues', 'Document and present recommendations and point of view based on research and analysis', 'Experience with large-scale survey tools', 'Experience using varied user research techniques at various stages of the development process (e.g. lab usability studies, heuristic evaluations, surveys, field research / ethnographic techniques)', ' Drive design research activities to inform product design, including but not limited to: usability studies, heuristic evaluations, interviews, surveys, etc. Deliver actionable research findings to your counterparts on time and with quality Communicate, defend, and build consensus around your research and how it informs design Document and present recommendations and point of view based on research and analysis Work with the supervising Researcher or Manager in addressing critical usability issues ', 'Desired Qualifications:', 'Responsibilities', 'Experience with UserTesting.com', ' Experience with UserTesting.com Experience with large-scale survey tools Experience analyzing and delivering impactful findings based on telemetry data ', 'Deliver actionable research findings to your counterparts on time and with quality', 'Experience analyzing and delivering impactful findings based on telemetry data', 'e', 'Must be capable of taking feedback and ownership of the end-to-end research process', 'Demonstrated ability to analyze research data, create results presentations, and deliver them to design and product teams', 'Ability to get up to speed with a complex new area quickly', 'cell', 'Ability to work as part of a team', 'Drive design research activities to inform product design, including but not limited to: usability studies, heuristic evaluations, interviews, surveys, etc.', 'Excellent collaboration skills and some experience teaming with designers to help prepare designs for testing', '2-5 years of industry experience conducting user research / design research and effectively partnering with development teams to improve the user experience based on research results', 'Design Researcher', 'Successful history of turning research findings into actionable recommendations', ' 2-5 years of industry experience conducting user research / design research and effectively partnering with development teams to improve the user experience based on research results Experience using varied user research techniques at various stages of the development process (e.g. lab usability studies, heuristic evaluations, surveys, field research / ethnographic techniques) Experience creating usability test plans and running large and small tests Accurate measurement and precise reporting of usability data and other research data Demonstrated ability to analyze research data, create results presentations, and deliver them to design and product teams Must be capable of taking feedback and ownership of the end-to-end research process Excellent collaboration skills and some experience teaming with designers to help prepare designs for testing Successful history of turning research findings into actionable recommendations Strong oral and written communication skills Ability to get up to speed with a complex new area quickly Ability to work as part of a team ', 'X', 'Experience creating usability test plans and running large and small tests', 'Accurate measurement and precise reporting of usability data and other research data']",Entry level,Contract,Engineering,Computer Software,2020-11-05 11:32:32
"Data Scientist, Performance Analytics - McD Tech Labs",McD Tech Labs,"Mountain View, CA",5 hours ago,114 applicants,"['', 'Collaborate with engineering teams to ensure that data infrastructure and systems are performant, scalable, reliable and secure ', 'Job Description</strongMcD Tech Labs is the recently established Silicon Valley based technology development group within McDonald’s Corporation. Our mission is to deliver advanced technology solutions that address real-world, data-driven needs in the McDonald’s Restaurant environment. We are focused on using state-of-the-art Machine Learning, AI, and related technologies along with McDonald’s unparalleled scale to completely transform the customer experience!We are currently looking for talented data scientists to join our performance analytics team at McD Tech Labs. This team design and develop pipelines, reports, dashboards and framework that monitor and analyze performance of the AI Drive Thru Voice Agents.\u202f Providing insights of the product performance in real time in diverse regions and stores worldwide, the team aggregate, curate and distill data from various hubs and feeds actionable data to various data and engineering teams, business, operations and the greater McD ecosystem. Such insight and data contribute and complete a key, necessary part of the AI/ML product development lifecycle.The ideal candidate will have previous experience designing and delivering analytics for large-scale ML products, and enjoys working in an agile, fast-growing environment.ResponsibilitiesDefine and develop data schema, ETL, metrics and reports for production performance analytics Collaborate with stakeholders and partners within Tech Labs and across McD ecosystem to identify, iterate and evolve rigor and maturity of data sources, quality and signals to distill and present consolidated view of product performance across platform and products Employ advanced statistical modeling to analyze large data sets, create dashboards and derive insights to guide key business, product and engineering decisions Collaborate with engineering teams to ensure that data infrastructure and systems are performant, scalable, reliable and secure Enable big data and batch/real-time analytical solutions that leverage state-of-the-art data and ML technologies Qualifications</strongBachelor’s Degree Computer Science, Mathematics, Statistics or a related quantitative discipline 5+ years of experience in data science or analytics 3+ years of Python and SQL experience working with big data Strong understanding of high-performance algorithms and statistics Expert knowledge of data modeling, queries and understanding of different data structures Excellent analytical skills with an engineering, algorithmic mind to design tools, pipelines and systems to handle large-scale, real-time ML analysis, whether in batch or streaming. Demonstrated ability to facilitate and coordinate complex data analysis and development activities across teams in agile sprints with minimal direction Additional Information</strongAll your information will be kept confidential according to EEO guidelines.', 'Excellent analytical skills with an engineering, algorithmic mind to design tools, pipelines and systems to handle large-scale, real-time ML analysis, whether in batch or streaming. ', 'Bachelor’s Degree Computer Science, Mathematics, Statistics or a related quantitative discipline ', 'Strong understanding of high-performance algorithms and statistics ', 'Responsibilities', 'Bachelor’s Degree Computer Science, Mathematics, Statistics or a related quantitative discipline 5+ years of experience in data science or analytics ', '5+ years of experience in data science or analytics ', 'Enable big data and batch/real-time analytical solutions that leverage state-of-the-art data and ML technologies ', 'Expert knowledge of data modeling, queries and understanding of different data structures ', 'Define and develop data schema, ETL, metrics and reports for production performance analytics ', 'Collaborate with engineering teams to ensure that data infrastructure and systems are performant, scalable, reliable and secure Enable big data and batch/real-time analytical solutions that leverage state-of-the-art data and ML technologies ', '3+ years of Python and SQL experience working with big data ', 'Employ advanced statistical modeling to analyze large data sets, create dashboards and derive insights to guide key business, product and engineering decisions ', 'Additional Information</strongAll your information will be kept confidential according to EEO guidelines.', 'Company Description', 'Collaborate with stakeholders and partners within Tech Labs and across McD ecosystem to identify, iterate and evolve rigor and maturity of data sources, quality and signals to distill and present consolidated view of product performance across platform and products ', '3+ years of Python and SQL experience working with big data Strong understanding of high-performance algorithms and statistics Expert knowledge of data modeling, queries and understanding of different data structures Excellent analytical skills with an engineering, algorithmic mind to design tools, pipelines and systems to handle large-scale, real-time ML analysis, whether in batch or streaming. Demonstrated ability to facilitate and coordinate complex data analysis and development activities across teams in agile sprints with minimal direction ', 'Define and develop data schema, ETL, metrics and reports for production performance analytics Collaborate with stakeholders and partners within Tech Labs and across McD ecosystem to identify, iterate and evolve rigor and maturity of data sources, quality and signals to distill and present consolidated view of product performance across platform and products Employ advanced statistical modeling to analyze large data sets, create dashboards and derive insights to guide key business, product and engineering decisions ', 'Demonstrated ability to facilitate and coordinate complex data analysis and development activities across teams in agile sprints with minimal direction ', 'Qualifications</strongBachelor’s Degree Computer Science, Mathematics, Statistics or a related quantitative discipline 5+ years of experience in data science or analytics 3+ years of Python and SQL experience working with big data Strong understanding of high-performance algorithms and statistics Expert knowledge of data modeling, queries and understanding of different data structures Excellent analytical skills with an engineering, algorithmic mind to design tools, pipelines and systems to handle large-scale, real-time ML analysis, whether in batch or streaming. Demonstrated ability to facilitate and coordinate complex data analysis and development activities across teams in agile sprints with minimal direction Additional Information</strongAll your information will be kept confidential according to EEO guidelines.']",Not Applicable,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"PhD New Grad, Machine Learning Engineer, Prediction",Cruise,"San Francisco, CA",6 hours ago,146 applicants,"['', 'We’re Funded', 'Passionate about self driving car technology and its impact on the world', ""We're Vested You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow.   "", ' On the research end, the ML engineer explores, prototypes, validates, and iterates new models and algorithms On the development end, the ML engineer optimizes, productionizes, and monitors / refines on-road performance for their models Invent pragmatic long term and stable software solutions to complex problems Champion engineering excellence, coming up with solutions not just identifying problems ', ' Completing or recently completed PhD in CS/CE/EE, or equivalent industry experience Extensive experience with deep learning frameworks such as Tensorflow, Caffe, and PyTorch  Strong experience with deep learning  Strong programming skills in Python or C++ Excellent mathematical reasoning skills, especially with probability  Passionate about self driving car technology and its impact on the world ', 'Strong experience with deep learning ', 'Strong programming skills in Python or C++', 'On the development end, the ML engineer optimizes, productionizes, and monitors / refines on-road performance for their models', 'We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the bleeding-edge of technology, but also define it.', 'We’re Integrated', ' GM, Honda, SoftBank, and T. Rowe Price have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed. ', 'Healthy meals and snacks provided', 'Commuter benefits', 'Champion engineering excellence, coming up with solutions not just identifying problems', ' We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the bleeding-edge of technology, but also define it. ', 'Completing or recently completed PhD in CS/CE/EE, or equivalent industry experience', 'Competitive salary and benefits ', 'Cruise LLC is an equal opportunity employer. All applicants for employment will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, gender identity or expression, veteran status, genetics or any other legally protected basis. Below, you have the opportunity to share your preferred gender pronouns, gender, ethnicity, and veteran status with Cruise to help us identify areas of improvement in our hiring and recruitment processes. Completion of these questions is entirely voluntary. Any information you choose to provide will be kept confidential, and will not impact the hiring decision in any way.', 'Experience in deploying perception algorithms into real world environments', 'What You’ll Be Doing', 'Medical / dental / vision, AD+D and Life', 'Bonus Points!', 'Invent pragmatic long term and stable software solutions to complex problems', 'Experience with CUDA', 'Why Cruise?', ' Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale. ', ""We're Vested"", 'We’re Integrated Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale.  ', 'Paid parental leave & family expansion stipend', ' Experience with ROS, OpenCV, Gazebo, or PCL Experience with CUDA Experience in deploying perception algorithms into real world environments ', "" Our benefits are here to support the whole you: Competitive salary and benefits  401(k) Cruise matching program  Medical / dental / vision, AD+D and Life Flexible vacation and company paid holidays Healthy meals and snacks provided Paid parental leave & family expansion stipend Monthly wellness stipend Commuter benefits   We’re Integrated Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale.   We’re Funded GM, Honda, SoftBank, and T. Rowe Price have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed.   We’re Independent We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the bleeding-edge of technology, but also define it.   We're Vested You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow.    "", 'We’re Independent We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the bleeding-edge of technology, but also define it.  ', ' Competitive salary and benefits  401(k) Cruise matching program  Medical / dental / vision, AD+D and Life Flexible vacation and company paid holidays Healthy meals and snacks provided Paid parental leave & family expansion stipend Monthly wellness stipend Commuter benefits ', 'We also consider for employment qualified applicants regardless of criminal histories, consistent with applicable laws. And, if you believe that you will need any type of accommodation, please let us know.Note to Recruitment Agencies: Cruise does not accept unsolicited agency resumes. Furthermore, Cruise does not pay placement fees for candidates submitted by any agency other than its approved partners.', 'GM, Honda, SoftBank, and T. Rowe Price have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed.', 'What You Must Have', 'Experience with ROS, OpenCV, Gazebo, or PCL', 'We’re Funded GM, Honda, SoftBank, and T. Rowe Price have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed.  ', 'You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow. ', 'Extensive experience with deep learning frameworks such as Tensorflow, Caffe, and PyTorch ', 'Our benefits are here to support the whole you:', 'Our benefits are here to support the whole you: Competitive salary and benefits  401(k) Cruise matching program  Medical / dental / vision, AD+D and Life Flexible vacation and company paid holidays Healthy meals and snacks provided Paid parental leave & family expansion stipend Monthly wellness stipend Commuter benefits  ', 'Monthly wellness stipend', 'We’re Independent', 'Flexible vacation and company paid holidays', 'On the research end, the ML engineer explores, prototypes, validates, and iterates new models and algorithms', 'Note to Recruitment Agencies:', ' You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow.  ', 'Excellent mathematical reasoning skills, especially with probability ', 'Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale.', '401(k) Cruise matching program ']",Associate,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Researcher II,NTT DATA Services,"Mountain View, CA",23 hours ago,Be among the first 25 applicants,"['', 'Overall Responsibilities: ', 'Experienced at survey design and analysis (descriptive statistics only).', 'Researcher II', 'Support ongoing UX research work. Survey design, analysis, writing detailed reports.Work with other researchers, designers, product managers, engineers in a fast-paced, rapidly changing environment.Understand and incorporate complex technical and business requirements into research.', 'Support ongoing UX research work. Survey design, analysis, writing detailed reports.', '12 months', 'Information Science with 2 years of equivalent practical experience. OR Masters degree with internship.', 'Desired:', 'Education: BA/BS in Computer Science, Human-Computer Interaction, Cognitive Science, Experimental Psychology, Anthropology,Information Science with 2 years of equivalent practical experience. OR Masters degree with internship.Experienced at survey design and analysis (descriptive statistics only).Great working knowledge of\xa0Forms and/or Microsoft Excel.Must be flexible and willing to work in a fast-paced environment.Excellent interpersonal, communication, negotiation and collaboration skills.Experience working with other researchers on qualitative data collection, analysis, and reporting.Organized and detail-oriented.', 'Experience working with other researchers on qualitative data collection, analysis, and reporting.', 'Ideally minimum 1 year experience conducting research on consumer-facing experiences.', 'Understand and incorporate complex technical and business requirements into research.', 'Work with other researchers, designers, product managers, engineers in a fast-paced, rapidly changing environment.', 'Survey support: Create surveys and report data; code open-ended comments, create graphs and report findings.', 'Organized and detail-oriented.', 'Education: BA/BS in Computer Science, Human-Computer Interaction, Cognitive Science, Experimental Psychology, Anthropology,', 'Experience with one or more of the following methods: consumer surveys, usability studies, concept tests, benchmarks, diary studies, interviewing consumers, field research.', 'Ideally minimum 1 year experience conducting research on consumer-facing experiences.Experience with one or more of the following methods: consumer surveys, usability studies, concept tests, benchmarks, diary studies, interviewing consumers, field research.', 'Advocate research findings to diverse audiences through written reports and oral presentations.Be willing to jump in where needed.', 'Must be flexible and willing to work in a fast-paced environment.', 'Survey support: Create surveys and report data; code open-ended comments, create graphs and report findings.Advocate research findings to diverse audiences through written reports and oral presentations.Be willing to jump in where needed.', 'Great working knowledge of\xa0Forms and/or Microsoft Excel.', 'Excellent interpersonal, communication, negotiation and collaboration skills.', 'Top 3 Daily Responsibilities:', 'Mountain View, CA', 'Mandatory:']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
ESG Researcher,Moody's Analytics,"San Francisco, CA",6 hours ago,50 applicants,"['', ' Ph. D. or have completed all coursework required by a Ph.D. program, in economics, finance, accounting. Ideally, candidate would have experience measuring the business impact of ESG related factors. ', 'Experience Level', ' Ph. D. or have completed all coursework required by a Ph.D. program, in economics, finance, accounting. Ideally, candidate would have experience measuring the business impact of ESG related factors.  Research experience in econometric and statistical modeling;  Experience with programming tools such as Python, SAS, R, or Matlab;  Strong written and oral communication skills. ', ' Strong written and oral communication skills. ', 'Securities Trading Policy (STP)', ' Background in Business Ethics ', 'Line of Business', ""Working at Moody's"", 'Job Sub Category', 'Role/Responsibilities', ' Background in Environmental Science ', ' Experience leveraging techniques in machine learning and artificial intelligence as well as climate modeling. ', 'Entity', ' Research experience in econometric and statistical modeling; ', ' Other desirable qualifications: ', 'Specific Responsibilities May Include', ' Collaborate with financial researchers and data analysts on research projects; ', ' Research experience in financial accounting and corporate finance; ', ' Partner with marketing, sales, product management, client service teams, and clients on the education and implementation of risk management technology; ', 'City', ' Partner with engineering teams to deploy completed research through various technology channels’; ', 'LOB/Department', ' Present research findings to technical and non-technical audiences internally and externally. ', 'Qualifications', 'EEO Policy', 'Regular/Temporary', ' Conducting sophisticated theoretical and empirical research measuring the impact of ESG risks on profits, accounting valuations, market valuations and credit risk; ', ' Desired Qualifications: ', ' Conducting sophisticated theoretical and empirical research measuring the impact of ESG risks on profits, accounting valuations, market valuations and credit risk;  Collaborate with financial researchers and data analysts on research projects;  Partner with engineering teams to deploy completed research through various technology channels’;  Partner with marketing, sales, product management, client service teams, and clients on the education and implementation of risk management technology;  Present research findings to technical and non-technical audiences internally and externally. ', 'Job Category', 'Job Req ID', ' Experience with programming tools such as Python, SAS, R, or Matlab; ', ' Research experience in financial accounting and corporate finance;  Background in Environmental Science  Background in Business Ethics  Experience leveraging techniques in machine learning and artificial intelligence as well as climate modeling. ']",Not Applicable,Full-time,Research,Financial Services,2020-11-05 11:32:32
Lead Data Engineer,Fifth Third Bank,"Cincinnati, OH",11 hours ago,Be among the first 25 applicants,"['', ' Is relentlessly customer-focused ', ' At least 1 year of experience working with big data technologies includingSpark, Cassandra, Hadoop, PostgreSQL, Redshift, or MongoDB ', ' Has a sense of intellectual curiosity and a burning desire to learn ', ' Has great communication and reasoning skills, including the ability to make a strong case for technology choices', 'Make banking a Fifth Third better®', 'Values data and truth over ego ', ' At least 2 years of data engineering experience ', ' Is self-driven, actively looks for ways to contribute, and knows how to get things done ', ' At least 1 year of experience in Java, Scala, Python, or SQLLead Data EngineerLOCATION -- Cincinnati, Ohio 45263Fifth Third Bank, National Association is proud to have an engaged and inclusive culture and to promote and ensure equal employment opportunity in all employment decisions regardless of race, color, gender, national origin, religion, age, disability, sexual orientation, gender identity, military status, veteran status or any other legally protected status.', ' Has a strong sense of engineering craftsmanship and takes pride in the code they write ', ' Believes that good software development includes good testing, good documentation, and good collaboration - and that these practices extendto the data environment', ' Bachelor’s degree ']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer (Full Time Permanent Remote Work Opportunity),BDO Canada,"California, United States",9 hours ago,Be among the first 25 applicants,"['', ' Knowledge of Continuous Integration and Source Control systems (e.g. Gradle, Maven, Bamboo, TeamCity, Git) ', ' Experience with DataBricks ', 'Everyone counts:', "" You demonstrate BDO's core values through all aspect of your work: Integrity, Respect and Collaboration "", 'Preferably, you also have:', 'As an experienced Data Engineer, you have:', ' 5+ years of programming experience in Python ', ' Achieve your personal goals outside of the office and make an impact on your community. ', ' Post-secondary education in engineering or computer science or equivalent work experience ', ' Post-secondary education in engineering or computer science or equivalent work experience  A proven track record using the Apache Hadoop ecosystem (Spark, Data Lake, Hive, HDFS, Impala) to tackle ""big data"" problems  A master of all things SQL (and NoSQL)  5+ years of programming experience in Python  Proven experience using RESTful Web Services & JSON  Good experience using Cloud based data solutions (AWS/Azure)  Experience working with production systems  Knowledge of ELT, ELT, Lambda and Kappa data architectures ', 'Total rewards that matter', ' We help you be the best professional you can be in our services, industries and markets. ', ' A master of all things SQL (and NoSQL) ', 'Giving back, it adds up: ', 'Data Engineer', ' You actively participate in the adoption of digital tools and strategies to drive an innovative workplace ', ' You grow your expertise through learning and professional development. ', ' You understand your client’s industry, challenges, and opportunities; client describe you as positive, professional, and delivering high quality work ', ' Experience working with production systems ', 'How do we define success for your role? ', ' Some experience using Docker ', ' You share in an inclusive and engaging work environment that develops, retains & attracts talent ', ' Some Data Visualization experience in Power BI, Tableau, or similar ', ' You identify, recommend, and are focused on effective service delivery to your clients ', ' Knowledge of Continuous Integration and Source Control systems (e.g. Gradle, Maven, Bamboo, TeamCity, Git)  Experience with DataBricks  Some Data Visualization experience in Power BI, Tableau, or similar  Exposure to data science, machine learning or statistics  Some experience using Docker ', ' Proven experience using RESTful Web Services & JSON ', 'Ready to make your mark at BDO?', ' A proven track record using the Apache Hadoop ecosystem (Spark, Data Lake, Hive, HDFS, Impala) to tackle ""big data"" problems ', 'To explore other opportunities at BDO, check out our', ' Knowledge of ELT, ELT, Lambda and Kappa data architectures ', "" We enable you to engage with the firm's strategic plan, and be a key contributor to the success and growth of the firm. "", 'Why BDO?', ' Exposure to data science, machine learning or statistics ', ' Good experience using Cloud based data solutions (AWS/Azure) ', "" We enable you to engage with the firm's strategic plan, and be a key contributor to the success and growth of the firm.  We help you be the best professional you can be in our services, industries and markets.  Achieve your personal goals outside of the office and make an impact on your community. "", "" You demonstrate BDO's core values through all aspect of your work: Integrity, Respect and Collaboration  You understand your client’s industry, challenges, and opportunities; client describe you as positive, professional, and delivering high quality work  You identify, recommend, and are focused on effective service delivery to your clients  You share in an inclusive and engaging work environment that develops, retains & attracts talent  You actively participate in the adoption of digital tools and strategies to drive an innovative workplace  You grow your expertise through learning and professional development. ""]",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,ektello,"Sunnyvale, CA",,N/A,"['', 'Implement container based architecture, infrastructure as code and configuration management for the platform.', 'Tune Hadoop solutions to improve performance and end-user experienceDesigning efficient and robust data workflowsDocumenting requirements as well as resolve conflicts or ambiguitiesWorking in teams and collaborate with others to clarify requirementsStrong co-ordination and project management skills to handle complex projectsOwnership of the platform framework and tools.Enhance, Enable and Implement CICD.Code new operators, functions to automate ETL use cases.Implement container based architecture, infrastructure as code and configuration management for the platform.', 'Extensive experience with ETL design, coding, and testing patterns as well as engineering software platforms and large-scale data infrastructures. ', 'Exceptionally strong coding, optimized algorithm skills in Python.', 'Top Requirements', 'Designing efficient and robust data workflows', 'Documenting requirements as well as resolve conflicts or ambiguities', 'Experience with Apache Airflow Implementation.', 'Strong co-ordination and project management skills to handle complex projects', 'Data Engineering/Data Operations and ETL Development experience.', 'Tune Hadoop solutions to improve performance and end-user experience', 'Enhance, Enable and Implement CICD.', '14 month Contract to potential hire', 'Bachelors in Computer Science', 'Extensive experience with ETL design, coding, and testing patterns as well as engineering software platforms and large-scale data infrastructures. Big Data Engineers have the capability to architect highly scalable end-to-end pipeline using different open source tools, including building and operationalizing high-performance algorithms..', 'Ownership of the platform framework and tools.', 'Code new operators, functions to automate ETL use cases.', 'Role and Responsibilities: (MUST-HAVE SKILLS):', 'Big Data Engineers have the capability to architect highly scalable end-to-end pipeline using different open source tools, including building and operationalizing high-performance algorithms..', 'Bachelors in Computer ScienceExceptionally strong coding, optimized algorithm skills in Python.AWS administration skills with automation, architecture and implementation experience.Experience with Apache Airflow Implementation.Data Engineering/Data Operations and ETL Development experience.Strong communication, troubleshooting and coordination skills. Communication with the stakeholders of the platforms, Data center partners and vendors.', 'Working in teams and collaborate with others to clarify requirements', 'AWS administration skills with automation, architecture and implementation experience.', 'Strong communication, troubleshooting and coordination skills. Communication with the stakeholders of the platforms, Data center partners and vendors.', 'Role and Responsibilities: ', 'We are seeking\xa0an Data Engineer\xa0to become an integral part of our team, ensuring both the reliability and applicability of the teams data products to the entire organization.', '\ufeffSkills and Qualifications:']",Mid-Senior level,Contract,Information Technology,Staffing and Recruiting,2020-11-05 11:32:32
Sr Data Engineer,Noblesoft Technologies,United States,21 hours ago,32 applicants,"['', 'Candidate must have GCP certification – Data Engineer / ACEMust have experience working with GCP ProjectsExperience with data pipelines and data analytics in the cloud (preferably GCP)Experience in GCP Big Query, SnowflakeExperience with migrating implementing and/or maintaining technical solutions in virtualized environments.Experience in design, migration and implementation of Data warehouses, data pipelines and flows.Experience with reading software code in one or more languages such as Java, Python and SQL.Experience designing and deploying large scale distributed data processing systems with few technologies such as Oracle, MS SQL Server, MySQL, PostgreSQL, MongoDB, Cassandra, Redis, Hadoop, Spark, HBase, Vertica, Netezza, Teradata, Tableau, Qlik or MicroStrategy. Also experience in setting up cloud foundationCustomer facing migration experience, including service discovery, assessment, planning, execution, and operations.Excellent communication, presentation, and problem-solving skills.', 'Job Description.', 'Noblesoft is looking to serve one of its premier Client for their immediate need.', 'Please share your resume to prasad@noblesoft.com', 'Experience with data pipelines and data analytics in the cloud (preferably GCP)', 'Experience in GCP Big Query, Snowflake', 'Customer facing migration experience, including service discovery, assessment, planning, execution, and operations.', 'Excellent communication, presentation, and problem-solving skills.', 'Experience with migrating implementing and/or maintaining technical solutions in virtualized environments.', 'Candidate must have GCP certification – Data Engineer / ACE', 'Experience with reading software code in one or more languages such as Java, Python and SQL.', 'Experience designing and deploying large scale distributed data processing systems with few technologies such as Oracle, MS SQL Server, MySQL, PostgreSQL, MongoDB, Cassandra, Redis, Hadoop, Spark, HBase, Vertica, Netezza, Teradata, Tableau, Qlik or MicroStrategy. Also experience in setting up cloud foundation', 'GCP Certifification is Mandatory', 'Experience in design, migration and implementation of Data warehouses, data pipelines and flows.', 'Must have experience working with GCP Projects']",Mid-Senior level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Sr. Data Engineer, Machine Learning",iRobot,"Bedford, MA",,N/A,"['What you will do:\xa0', 'Required Qualifications:', 'If the scope and opportunity of this role interests you, then please click to apply!', 'A\xa0supportive environment to learn and grow with cutting edge technologies\xa0Opportunity to help design and influence production systems\xa0', 'Cloud providers (AWS or GCP or Azure)\xa0', 'Sr. Data Engineer, Machine Learning\xa0', 'Desired Qualifications:', 'In return you can expect:\xa0', 'Work with\xa0state-of-the-art\xa0tools and frameworks to build scalable and efficient solutions for data management, data preprocessing and dataset building.\xa0\xa0', ""The Sr. Data Engineer within the\xa0Machine\xa0Learning team will\xa0help build development and production systems for\xa0storing and\xa0processing data.\xa0If you have a passion for\xa0engineering systems and\xa0working on data at scale, let's talk.\xa0"", '\xa0', 'What you will do:', 'In return you can expect:', 'Work closely with machine learning engineers and\xa0various\xa0teams within iRobot\xa0to enable faster ML based application development.\xa0\xa0Work with\xa0state-of-the-art\xa0tools and frameworks to build scalable and efficient solutions for data management, data preprocessing and dataset building.\xa0\xa0Contribute to the architecture and implementation of an efficient data ingestion,\xa0processing\xa0and storage pipeline.\xa0\xa0', 'Experience writing unit and integration tests\xa0', 'Django or similar frameworks\xa0\xa0', 'Strong attention to detail\xa0', 'Contribute to the architecture and implementation of an efficient data ingestion,\xa0processing\xa0and storage pipeline.\xa0\xa0', '2+ years of software development with\xa0Python\xa0\xa0', 'A\xa0supportive environment to learn and grow with cutting edge technologies\xa0', 'Kubernetes\xa0\xa0', 'Required Qualifications:\xa0', 'Work closely with machine learning engineers and\xa0various\xa0teams within iRobot\xa0to enable faster ML based application development.\xa0\xa0', 'Data engineering\xa0', '5+\xa0years experience\xa0and a bachelor’s degree,\xa0or\xa03+\xa0years\xa0experience\xa0and a Masters in CS, data engineering or other related fields\xa0', 'Desired Qualifications:\xa0', 'Opportunity to help design and influence production systems\xa0', 'Managing\xa0image and video data\xa0', 'Building efficient large-scale data collection,\xa0storage\xa0and processing pipelines\xa0', '5+\xa0years experience\xa0and a bachelor’s degree,\xa0or\xa03+\xa0years\xa0experience\xa0and a Masters in CS, data engineering or other related fields\xa02+ years of software development with\xa0Python\xa0\xa0Strong attention to detail\xa0Strong communication skills\xa0Experience writing unit and integration tests\xa0', 'Experience with any of the following\xa0', 'Building efficient large-scale data collection,\xa0storage\xa0and processing pipelines\xa0Data engineering\xa0Cloud providers (AWS or GCP or Azure)\xa0Managing\xa0image and video data\xa0Django or similar frameworks\xa0\xa0Kubernetes\xa0\xa0', 'Strong communication skills\xa0', 'If the scope and opportunity of this role interests you, then please click to apply!\xa0', 'Do you want to steer the future of one of the largest consumer robot companies in the world? You will have a hand in developing the next generation of products that will live in millions of homes across the world. As a pioneer in the robot industry, our goal is to drive innovation, serve as an industry catalyst and change the world by empowering people to do more.\xa0']",Mid-Senior level,Full-time,Engineering,Consumer Electronics,2020-11-05 11:32:32
Principal Data Scientist,Scipher Medicine,"Waltham, MA",21 hours ago,Be among the first 25 applicants,"['', 'Prepare and deliver scientific presentations for both internal and external use', 'Strong communication skills, both written and verbal', 'Proficiency in coding (R and python are preferable)', 'To all recruitment agencies: Scipher Medicine does not accept agency resumes. Please do not forward resumes to our jobs alias, or Scipher Medicine employees. Scipher Medicine is not responsible for any fees related to unsolicited resumes.', 'Ability to establish and maintain effective working relationships with coworkers, managers and clients', ""Drive to developing companies' platforms and algorithms in collaboration with the research team.Participate and lead components of the PRISM-RA and PRISM-UC data analysis projects.Work closely with Harvard Medical School and Northeastern University on Research Sponsored Agreement collaborations.Summarize and communicate results to project teams, provide intellectual input, and contribute to decision-making.Prepare and deliver scientific presentations for both internal and external usePresent the company’s scientific results at leading industry conferencesMaintain knowledge latest scientific and technology advancements in the fieldContribute to high-quality documents and scientific publicationsProvide regular updates to the technical teamManage each project within agreed upon timelines"", 'Present the company’s scientific results at leading industry conferences', 'Background in working with gene expression data', 'Provide regular updates to the technical team', 'Maintain knowledge latest scientific and technology advancements in the field', 'The Principal Data Scientist will lead the technical team to develop and apply state-of-the-art computational and statistical methods to deliver testable hypotheses and biological insights.', 'The Role', 'Work closely with Harvard Medical School and Northeastern University on Research Sponsored Agreement collaborations.', 'Contribute to high-quality documents and scientific publications', 'PhD in Bioinformatics, Computational Biology, Biological Sciences, or relevant fields', 'Manage each project within agreed upon timelines', 'Summarize and communicate results to project teams, provide intellectual input, and contribute to decision-making.', '5 plus years of experience in bioinformatics, systems biology and statistics', 'Familiar and experienced in network medicine approaches is preferred', 'Ability to laugh at yourself', 'PhD in Bioinformatics, Computational Biology, Biological Sciences, or relevant fields5 plus years of experience in bioinformatics, systems biology and statisticsBackground in working with gene expression dataSkilled in machine learning and statistical analysisProficiency in coding (R and python are preferable)Familiar and experienced in network medicine approaches is preferredAbility to establish and maintain effective working relationships with coworkers, managers and clientsAbility to laugh at yourselfAbility to work within a matrix team environmentStrong communication skills, both written and verbal', 'What will I do? ', 'Minimum Education and Qualifications ', 'Participate and lead components of the PRISM-RA and PRISM-UC data analysis projects.', ""Drive to developing companies' platforms and algorithms in collaboration with the research team."", 'Skilled in machine learning and statistical analysis', 'Ability to work within a matrix team environment']",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Associate Scientist - Robotics and Automation,Pfizer,"Pearl River, NY",17 hours ago,Be among the first 25 applicants,"['', 'Required Qualifications:', 'EEO & Employment Eligibility', 'Where applicable, performs job responsibilities in compliance with cGxP and all other regulatory agency requirements.', 'Responsibilities', 'Eligible for Employee Referral Bonus: YES', 'Completes required documentation for all laboratory work.', 'Performs sample preparation for preclinical and clinical serology assays to support vaccine development and clinical studies.This includes manual and robotic sample preparation, use and maintenance of appropriate equipment, and preparation of relevant reagents. With the guidance of the supervisor, the incumbent performs moderately complex experiments and calculations, and discusses conclusions.Completes required documentation for all laboratory work.This includes the use of laboratory information management systems and/or paper forms.May participate in the qualification of new instruments and robotic methods following established protocols or scripts.Satisfactorily completes all required laboratory, cGxP and safety training, in conformance with departmental requirements.Where applicable, performs job responsibilities in compliance with cGxP and all other regulatory agency requirements.May train other analysts on established, basic technologies that he/she has become proficient.', 'Role Summary', 'May participate in the qualification of new instruments and robotic methods following established protocols or scripts.', 'Performs sample preparation for preclinical and clinical serology assays to support vaccine development and clinical studies.', 'May train other analysts on established, basic technologies that he/she has become proficient.', 'Experience with programming languages such as Python, R and /or JavaScript.', 'Experience using robotic liquid handlers.Experience with programming languages such as Python, R and /or JavaScript.', 'This includes the use of laboratory information management systems and/or paper forms.', 'Strong communication and computer/technical skills.', 'Other Job Details:', 'Experience using robotic liquid handlers.', 'Satisfactorily completes all required laboratory, cGxP and safety training, in conformance with departmental requirements.', 'Sunshine Act', 'BS or MS degree in a relevant field of science.Laboratory experience in a relevant field of science acquired in academic/industrial setting.Strong communication and computer/technical skills.', 'BS or MS degree in a relevant field of science.', 'Preferred Skills:', 'Laboratory experience in a relevant field of science acquired in academic/industrial setting.', 'This includes manual and robotic sample preparation, use and maintenance of appropriate equipment, and preparation of relevant reagents. With the guidance of the supervisor, the incumbent performs moderately complex experiments and calculations, and discusses conclusions.', 'Why Patients Need You']",Associate,Full-time,Research,Pharmaceuticals,2020-11-05 11:32:32
UX Researcher I - 014649 - Rochester,Excellus BCBS,"Rochester, NY",7 hours ago,Be among the first 25 applicants,"['', ' Collaborates with product owners and business teams to evaluate research methods for determining customer needs and the planning and development of solutions.', ' Must be equally as competent and experienced with journey mapping, personas and wireframes as they are with conversion rates, competitive benchmarking and testing and learning across all digital channels including web, mobile, social and email.', ' Serves as a subject matter expert in multiple areas or products within the division.', ' Motivations', ' Conducts research to learn about new technologies, capabilities, and trends in digital marketing and ensures we adhere to best practices.', ' Coaches and counsels members of cross-functional teams to accomplish projects, meet established schedules, or resolve technical/operational issues.', ' Strong communication, writing, presentation, public speaking and interpersonal skills required. Must have the ability to translate and effectively communicate complex information into layman’s terms. Facilitation skills to lead requirements elicitation meetings and projects.', ' Performs other functions as assigned by management.', ' Overall accountability for the successful development and implementation of a comprehensive UX research process.  Directs subordinate staff and fosters positive attitudes among staff on quality and safety to ensure that delivered service meets agreed service levels. Monitors and evaluates quality of performance from all work within scope of responsibility. Briefs staff on their individual and team performance.  Acts as Change Leader implementing changes that benefit Excellus Heath Plan.  Communicates and comprehends business strategy and drives strategic recommendations and facilitates related implementations.', ' At least one years’ experience with Litmus or other email testing tools.', 'Minimum Qualifications', ' Travels within our plan service area to attend and present information at meetings with staff and customers.', ' Considered an expert in the discipline. Understands web technologies, their capabilities, interactions and their effect on the end user experience.', ' A minimum of 7 years’ total experience with UX research and strategy across all channels.', ' Must be proficient in testing, with an eye for detail and a keen attention to process.', ' Qualifications', ' Manages projects of large complex scope with multiple cross functional teams.  Serves as a mentor to less experienced team members.  Serves as a subject matter expert in multiple areas or products within the division.  Coaches and counsels members of cross-functional teams to accomplish projects, meet established schedules, or resolve technical/operational issues.', ' Serves as a mentor to less experienced team members.', ' Acts as Change Leader implementing changes that benefit Excellus Heath Plan.', ' Demonstrated leadership, decision making, and team building skills.', ' Bachelor’s degree in computer science, human computer interaction, business administration, marketing research or related field with a minimum of 3 years’ total experience with digital usability analysis and strategy.  Must be proficient in testing, with an eye for detail and a keen attention to process.  Proficient with web testing tools such as Visual Sciences/Omniture Insight, Omniture Site Catalyst, Omniture Test & Target, Tealeaf, Foresee, OpinionLab, and Loop11.  Proficient with wireframing or mock-up tools like Axure, Balsamiq, or Adobe XD.  At least one years’ experience with Litmus or other email testing tools.  At least one years’ experience with social publishing and monitoring tools like Sprinklr, Radian6 or HootSuite.  Experience with Salesforce Marketing Cloud preferred.  Considered an expert in the discipline. Understands web technologies, their capabilities, interactions and their effect on the end user experience.  Must be equally as competent and experienced with journey mapping, personas and wireframes as they are with conversion rates, competitive benchmarking and testing and learning across all digital channels including web, mobile, social and email.  Self-motivated, able to analyze problems and identify solutions with minimal direction, flexible, able to meet deadlines, able to manage project schedules, and work well in a fast paced, high volume team environment.  Strong communication, writing, presentation, public speaking and interpersonal skills required. Must have the ability to translate and effectively communicate complex information into layman’s terms. Facilitation skills to lead requirements elicitation meetings and projects.', ' Recommends optimized email, SMS and social experiences based on reports from Digital Analytics Manager.', ' Must have experience in leading projects with an emphasis on formulating strategic planning and evaluating current state against long term roadmap/goals.', ' Facilitates stakeholder interviews, user research, contextual inquiry research, in-person and remote usability testing, competitive analysis, to determine gaps in features and channels (web, mobile, email) to aid in prioritization and synthesize strategies.', ' Experience with Salesforce Marketing Cloud preferred.', ' A minimum of 5 years’ total experience with digital usability analysis and strategy, 5 years’ experience in web/mobile usability, and at least 2 years’ experience with email, social and SMS.', ' Overall accountability for the successful development and implementation of a comprehensive UX research process.', ' Proficient with web testing tools such as Visual Sciences/Omniture Insight, Omniture Site Catalyst, Omniture Test & Target, Tealeaf, Foresee, OpinionLab, and Loop11.', ' Prepares formal reports of recommendations and presents to teammates, business stakeholders and management.', 'Job Details', 'Our Company Culture', ' Regular and reliable attendance is expected and required.', ' Education', ' Directs subordinate staff and fosters positive attitudes among staff on quality and safety to ensure that delivered service meets agreed service levels. Monitors and evaluates quality of performance from all work within scope of responsibility. Briefs staff on their individual and team performance.', ' At least one years’ experience with social publishing and monitoring tools like Sprinklr, Radian6 or HootSuite.', ' A minimum of 5 years’ total experience with digital usability analysis and strategy, 5 years’ experience in web/mobile usability, and at least 2 years’ experience with email, social and SMS.  Must have experience in leading projects with an emphasis on formulating strategic planning and evaluating current state against long term roadmap/goals.', ' Self-motivated, able to analyze problems and identify solutions with minimal direction, flexible, able to meet deadlines, able to manage project schedules, and work well in a fast paced, high volume team environment.', 'Experience', ' Bachelor’s degree in computer science, human computer interaction, business administration, marketing research or related field with a minimum of 3 years’ total experience with digital usability analysis and strategy.', ' Proficient with wireframing or mock-up tools like Axure, Balsamiq, or Adobe XD.', ' Maintains high regard for member privacy in accordance with the corporate privacy policies and procedures.', "" Facilitates stakeholder interviews, user research, contextual inquiry research, in-person and remote usability testing, competitive analysis, to determine gaps in features and channels (web, mobile, email) to aid in prioritization and synthesize strategies.  Develops user personas and scenarios; understand target audiences' needs, tasks and goals, and then translates feature/functions into simple wireframes and functional components.  Develops and documents information hierarchies and architectures across all digital channels (web, mobile, email, social) and provides recommendations for improvements to stakeholders.  Conducts and/or coordinates evaluation techniques, including design walkthroughs, user feedback sessions and formal usability testing to validate proposed design solutions with stakeholders and end users against usability goals and heuristics.  Prepares formal reports of recommendations and presents to teammates, business stakeholders and management.  Collaborates with product owners and business teams to evaluate research methods for determining customer needs and the planning and development of solutions.  Recommends optimized email, SMS and social experiences based on reports from Digital Analytics Manager.  Conducts research to learn about new technologies, capabilities, and trends in digital marketing and ensures we adhere to best practices.  Monitors ‘Best in Class’ and competitor websites, mobile apps, emails and social channels to benchmark improvement ideas.  Creates and maintains detailed documentation on findings, recommendations, practices and processes.  Travels within our plan service area to attend and present information at meetings with staff and customers.  Consistently demonstrates high standards of integrity by supporting the Lifetime Healthcare Companies’ mission and values, adhering to the Corporate Code of Conduct and leading to the Lifetime Way values and beliefs.  Maintains high regard for member privacy in accordance with the corporate privacy policies and procedures.  Regular and reliable attendance is expected and required.  Performs other functions as assigned by management."", ' Description', 'Preferred', "" Develops user personas and scenarios; understand target audiences' needs, tasks and goals, and then translates feature/functions into simple wireframes and functional components."", ' Monitors ‘Best in Class’ and competitor websites, mobile apps, emails and social channels to benchmark improvement ideas.', 'Essential Responsibilities/Accountabilities', 'Skills', ' Develops and documents information hierarchies and architectures across all digital channels (web, mobile, email, social) and provides recommendations for improvements to stakeholders.', ' Consistently demonstrates high standards of integrity by supporting the Lifetime Healthcare Companies’ mission and values, adhering to the Corporate Code of Conduct and leading to the Lifetime Way values and beliefs.', ' Behaviors', ' Conducts and/or coordinates evaluation techniques, including design walkthroughs, user feedback sessions and formal usability testing to validate proposed design solutions with stakeholders and end users against usability goals and heuristics.', ' Licenses & Certifications', ' A minimum of 7 years’ total experience with UX research and strategy across all channels.  Demonstrated leadership, decision making, and team building skills.', ' :', ' Creates and maintains detailed documentation on findings, recommendations, practices and processes.', ' Manages projects of large complex scope with multiple cross functional teams.', ' Communicates and comprehends business strategy and drives strategic recommendations and facilitates related implementations.', 'Summary', 'Physical Requirements']",Associate,Full-time,Information Technology,Insurance,2020-11-05 11:32:32
Senior Data Engineer,Credera,"Dallas, TX",13 hours ago,Be among the first 25 applicants,"['', ' Candidate with 5+ years of experience in a Data Engineering role Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field Experience building and optimizing data pipelines and data architecture Experience with wrangling, exploring, and analyzing data to answer specific business questions and identify opportunities for improvement Strong project management and organizational skills Consulting experience is preferred The ideal candidate will have working knowledge of the following: Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.)   Experience with one or more of the following cloud service providers: AWS cloud services Google Cloud Platform Azure cloud services   ', 'Scripting languages (e.g. Python, Java, C++, Scala, etc.)', 'Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.)', 'Stream-processing systems (e.g. Storm, Spark-Streaming, etc.)', ' Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.) ', 'Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.)', ' QUALIFICATIONS: Candidate with 5+ years of experience in a Data Engineering role Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field Experience building and optimizing data pipelines and data architecture Experience with wrangling, exploring, and analyzing data to answer specific business questions and identify opportunities for improvement Strong project management and organizational skills Consulting experience is preferred The ideal candidate will have working knowledge of the following: Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.)   Experience with one or more of the following cloud service providers: AWS cloud services Google Cloud Platform Azure cloud services     ', 'QUALIFICATIONS: Candidate with 5+ years of experience in a Data Engineering role Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field Experience building and optimizing data pipelines and data architecture Experience with wrangling, exploring, and analyzing data to answer specific business questions and identify opportunities for improvement Strong project management and organizational skills Consulting experience is preferred The ideal candidate will have working knowledge of the following: Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.)   Experience with one or more of the following cloud service providers: AWS cloud services Google Cloud Platform Azure cloud services    ', 'Strong project management and organizational skills', 'Candidate with 5+ years of experience in a Data Engineering role', 'The ideal candidate will have working knowledge of the following: Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.)  ', 'AWS cloud services', 'voluntary', 'LEARN MORE:', 'Experience with wrangling, exploring, and analyzing data to answer specific business questions and identify opportunities for improvement', 'Experience with one or more of the following cloud service providers: AWS cloud services Google Cloud Platform Azure cloud services  ', 'U.S. Equal Opportunity Employment Information (Completion is voluntary)', 'Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field', 'We do not currently commence ""sponsor"" immigration cases in order to employ candidates.', 'Container Orchestration (e.g. Kubernetes, Docker, etc.)', 'Big data tools (e.g. Hadoop, Spark, Kafka, etc.)', 'Along with a great company culture, Credera provides an outstanding compensation package including a competitive salary and a comprehensive benefit plan (e.g., medical, dental, disability, matching 401k, PTO, etc.). This position is an exempt position.', 'Google Cloud Platform', 'Consulting experience is preferred', 'Travel: ', 'Experience building and optimizing data pipelines and data architecture', 'Azure cloud services', ' AWS cloud services Google Cloud Platform Azure cloud services ']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Pactera EDGE,"New York, United States",24 hours ago,39 applicants,"['', 'Data Engineer will build big data pipelines with Python/SQL in the cloud to transform\xa0 data for BI purposes\xa0Build processes supporting data transformation, data structures, metadata,\xa0 dependency and workload management.\xa0We need to support agile development process and constant changes throughout\xa0peak.', 'Strong undergraduate degree in Engineering\xa05 to 8 years’ experience\xa0Data Engineer will have: -Strong Azure background -Python & SQL (experience with\xa0PySpark is a plus)Power BI reporting skills a plus.Strong agile project management and organizational background\xa0Experience with big data tools (Spark is a plus)\xa0Experience building and working with APIs (experience with Azure API Management\xa0 is a plus)\xa0Experience with data pipeline and workflow management tools (Apache Airflow\xa0preferred)', 'Experience building and working with APIs (experience with Azure API Management\xa0 is a plus)\xa0', 'Job Responsibility:', 'Data Engineer will have: -Strong Azure background -Python & SQL (experience with\xa0PySpark is a plus)', '\xa0', 'Experience with data pipeline and workflow management tools (Apache Airflow\xa0preferred)', 'About Pactera\xa0EDGE', 'Job Title: Data Engineer', 'URL: https://www.pacteraedge.com', 'Strong agile project management and organizational background\xa0', 'Experience with big data tools (Spark is a plus)\xa0', '5 to 8 years’ experience\xa0', 'Strong undergraduate degree in Engineering\xa0', ' ', 'Location: NYC, NY', 'About Pactera\xa0EDGE\xa0-\xa0Pactera EDGE is a global organization with offices in the US, Europe, India, and Asia-Pacific.\xa0Clients include 100+ of the Global 500 companies, with industry concentration in Software and Technology, CPG, Retail, Logistics, Financial Services, Insurance, Healthcare, Food & Beverage, and Travel & Hospitality.\xa0', 'Data Engineer will build big data pipelines with Python/SQL in the cloud to transform\xa0 data for BI purposes\xa0', 'Build processes supporting data transformation, data structures, metadata,\xa0 dependency and workload management.\xa0', '\xa0Job Requirements:', 'Power BI reporting skills a plus.', 'We need to support agile development process and constant changes throughout\xa0peak.']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Principal Research Scientist, Toxicology",Aligos Therapeutics,San Francisco Bay Area,13 hours ago,Be among the first 25 applicants,"['', 'NOTE: ONLY APPLICANTS CURRENTLY RESIDING IN THE BAY AREA WILL BE CONSIDERED', 'Will be a functional representative on Aligos discovery and development project teams', ""At Aligos, our science is the key to our success with the ultimate goal of improving patients' quality of life. Our pipeline of developing novel compounds and investigative therapies reflects our commitment to bring innovative products to patients with unmet needs in the area of liver diseases. This is an exciting opportunity to become an employee of a high energy, Research and Development company.\xa0We are looking for an enthusiastic scientist who understands and appreciates the entrepreneurial environment and who is willing to do what it takes to contribute to the success of the company."", 'Aligos Therapeutics, Inc. is a biotechnology company located in South San Francisco, California that is developing novel medicines to treat liver diseases in virology, inflammation/fibrosis and oncology. Aligos is pursuing the development of both oligonucleotide-based and small molecule therapeutics, each addressing major commercial market opportunities.', 'Work with external CROs and internally with Operations Manager for study placement and protocol development, serve as a study monitor, review and finalize study reports.', 'PhD or equivalent in toxicology, pharmacology or related discipline.\xa0Post-doctoral training and DABT certification is preferred.Experience in the pharmaceutical industry (5 to 8 years)Must have experience in outsourcing and managing studies to contract research organizations.Must have knowledge of regulatory documents and proven track record as an author and contributor for IND/NDA, study reports and other regulatory documents. Knowledge of GLP, GCP, drug development and regulatory guidelines.Strong scientific background in toxicology and scientific aptitude with excellent critical thinking, strong decision-making based on scientific principles, complex problem solving, critical data analysis and interpretation skills.The ability to work independently and have the ability to work effectively and collaboratively on cross-functional project teams. Excellent interpersonal and organizational skills, excellent oral/written communication, proven track record of teamwork, ability to multitask and prioritize to delivery results within tight timelines is a must.The position does involve 10% traveling.', 'Qualifications and requirements: ', 'PhD or equivalent in toxicology, pharmacology or related discipline.\xa0Post-doctoral training and DABT certification is preferred.', 'Analyze, interpret, and summarize nonclinical safety data.\xa0Communicate and present findings and recommendations to internal project teams.', '\xa0', 'Design and oversee nonclinical toxicology programs for Aligos small molecule and oligonucleotide discovery and development programs, including both in vitro and in vivo studies. Help develop and implement de-risking and screening strategies to support lead optimization.', 'The position does involve 10% traveling.', 'This position will report to the Senior Director of Toxicology.\xa0In this role, the candidate will be responsible for the following key aspects:', 'Must have experience in outsourcing and managing studies to contract research organizations.', 'Strong scientific background in toxicology and scientific aptitude with excellent critical thinking, strong decision-making based on scientific principles, complex problem solving, critical data analysis and interpretation skills.', 'Ensure timely and accurate nonclinical study deliverables of projects to enable compound progression and decision-making.', 'Must have knowledge of regulatory documents and proven track record as an author and contributor for IND/NDA, study reports and other regulatory documents. Knowledge of GLP, GCP, drug development and regulatory guidelines.', 'The ability to work independently and have the ability to work effectively and collaboratively on cross-functional project teams. Excellent interpersonal and organizational skills, excellent oral/written communication, proven track record of teamwork, ability to multitask and prioritize to delivery results within tight timelines is a must.', 'Author regulatory documents that are required for worldwide filings. ', 'Will be a functional representative on Aligos discovery and development project teamsDesign and oversee nonclinical toxicology programs for Aligos small molecule and oligonucleotide discovery and development programs, including both in vitro and in vivo studies. Help develop and implement de-risking and screening strategies to support lead optimization.Work with external CROs and internally with Operations Manager for study placement and protocol development, serve as a study monitor, review and finalize study reports.Analyze, interpret, and summarize nonclinical safety data.\xa0Communicate and present findings and recommendations to internal project teams.Author regulatory documents that are required for worldwide filings. Lead investigative efforts into mechanisms of toxicity as needed. Ensure timely and accurate nonclinical study deliverables of projects to enable compound progression and decision-making.', 'Lead investigative efforts into mechanisms of toxicity as needed. ', 'Experience in the pharmaceutical industry (5 to 8 years)']",Director,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Data Engineer,iHeartMedia,"San Antonio, TX",7 hours ago,79 applicants,"['', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement', 'Strong understanding of ETL processes', 'Working knowledge of CI/CD processes and Git source control', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Hands-on knowledge of SQL and experience with both relational and distributed databases', 'Experience writing automated tests', 'Experience with AWS and/or GCP', 'Experience supporting and working with cross-functional teams in a dynamic environment', 'Minimum Qualifications', 'Preferred Qualifications', 'Responsibilities', 'Utilize and stay current in programming languages and software technology', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Experience building data pipelines using Python', 'Work with cross functional teams to strive for greater functionality in our data systems, and recommend and implement ways to improve data reliability, efficiency, and quality', 'Bachelor’s Degree in Computer Science, Information Technology, Informatics, or Applied Math3-5 years of commercial experience in a data engineering role with a proven record of manipulating, processing and extracting value from large disconnected datasetsStrong understanding of ETL processesHands-on knowledge of SQL and experience with both relational and distributed databasesProven programming skills in Python or similar programming languageWorking knowledge of CI/CD processes and Git source controlExperience writing automated testsExperience working with REST APIsStrong organizational, communication, and presentation skillsExperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementExperience supporting and working with cross-functional teams in a dynamic environment', 'Job Summary', 'Location', 'Experience with AWS and/or GCPExperience with Apache AirflowExperience with AWS tools and services such as Redshift, Athena, Lambda Functions, Step FunctionsExperience building data pipelines using PythonExperience with big data tools: Hadoop, Spark, Kafka, etc.5+ years of experience in data or software engineering', 'Proven programming skills in Python or similar programming language', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Experience working with REST APIs', 'Communicate complex solutions and ideas to a variety of stakeholders (other team members, IT leadership, and business leaders) in easily understandable language', 'Assemble large, complex data sets that meet functional and non-functional business requirements', 'Assemble large, complex data sets that meet functional and non-functional business requirementsBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sourcesDevelop and maintain standards for administration and operation including the scheduling, running, monitoring, logging, error management, failure recovery, and output validationIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Work with cross functional teams to strive for greater functionality in our data systems, and recommend and implement ways to improve data reliability, efficiency, and qualityContribute to the project planning process by estimating tasks and deliverablesCommunicate complex solutions and ideas to a variety of stakeholders (other team members, IT leadership, and business leaders) in easily understandable languageUtilize and stay current in programming languages and software technology', '3-5 years of commercial experience in a data engineering role with a proven record of manipulating, processing and extracting value from large disconnected datasets', 'Develop and maintain standards for administration and operation including the scheduling, running, monitoring, logging, error management, failure recovery, and output validation', 'Current employees and contingent workers click here to apply and search by the Job Posting Title. ', 'Strong organizational, communication, and presentation skills', 'Experience with AWS tools and services such as Redshift, Athena, Lambda Functions, Step Functions', 'Bachelor’s Degree in Computer Science, Information Technology, Informatics, or Applied Math', 'Experience with Apache Airflow', 'Contribute to the project planning process by estimating tasks and deliverables', '5+ years of experience in data or software engineering']",Entry level,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
UX Researcher,Sprinklr,"Portland, OR",7 hours ago,Be among the first 25 applicants,"['', 'Responsibilities:', ""Why you'll love Sprinklr:"", '274B) of the Immigration and Nationality Act (INA), 8 U.S.C. ', 'Analyze and distill user feedback into actionable insights to inform product and design decisions', 'Employment Policy', 'UX Researcher - Portland, Oregon', 'Disclaimer', 'The Sprinklr Way', 'Ability to work in fast-paced, ambiguous environments against software release timelines', ""Host and facilitate research sessions with Sprinklr's rich user base, including all role levels, industries and geographical regions"", 'Develop strong understanding of Sprinklr user personas, workflows and behaviors to represent users throughout design process', 'Candidates need to be located in Portland, Oregon', ""1324b.DisclaimerOur careers site is only for individuals seeking a position with Sprinklr and its holdings companies. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications, or resumes, and any such submissions will be considered unsolicited. Sprinklr does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our job alias, Sprinklr employees, or any other company location. Sprinklr is not responsible for any fees related to unsolicited resumes/applications.Any offer (s) of employment are contingent upon a satisfactory background and criminal records check, which will be conducted in accordance with local legal regulations.Why you'll love Sprinklr: We're committed to creating the kind of culture where you feel like you belong, are happier today than yesterday, and your contributions matter. At Sprinklr, our goal is to treat everyone like family and passionately, genuinely care. We offer flexible paid time off and paid parental leave, medical plans, dental and vision plans, life insurance, 401(k) savings plans, employee stock options, gym and wellness discounts, Plum benefits, Lifemart discounts, and paid time off to invest in learning and career development.We focus on our mission: We founded Sprinklr with one mission: to enable every organization on the planet to make their customers happier.We believe in our product: Sprinklr was built from the ground up to enable a brand's digital transformation. Its platform provides every customer-facing team with the ability to reach, engage and listen to customers around the world. At Sprinklr, we have many of the world's largest brands as our clients, and our employees have the opportunity to work closely alongside them.For the fifth consecutive year, Sprinklr has been named to the Forbes Cloud 100, the definitive ranking of the top 100 private cloud companies in the world. We were also named a 2020 Gartner Peer Insights Customers' Choice for Social Marketing Management. And in 2019, Sprinklr was the only leader in the Forrester Research, Inc. report, The Forrester Wave™: Social Suites.We invest in our people: At Sprinklr, we believe every human has the potential to be amazing. We empower each Sprinklrite in the journey toward achieving their personal and professional best. For wellbeing, this includes daily meditation breaks, virtual fitness, and access to Headspace. We have continuous learning opportunities available with Audible for Business, Linkedin Learning, and more.The Sprinklr WayEEO - Our philosophy on inclusion: Our goal is to ensure every employee feels like they belong and are operating in a judgement-free zone regardless of gender, race, ethnicity, age, and lifestyle preference, among others. We value and celebrate our sense of belonging and fervently believe every employee matters, and should be respected, listened to, and have opportunities to contribute to the magic of Sprinklr!We celebrate differences, and we seek to hear unique perspectives because it helps us all to learn. We seek to understand. We believe we are stronger when we belong because collectively, we're more innovative, creative, and successful. As we continue on our growth journey, we know that bringing together diverse talent leads to better company-wide innovation, improved financial results and better decision making.Sprinklr is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. See also Sprinklr's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know."", 'We invest in our people', ""Why You'll Love Sprinklr:"", "" Collaborate with designers, product owners, engineers and fellow researchers to prioritize research needs and opportunities in a fast-paced environment Host and facilitate research sessions with Sprinklr's rich user base, including all role levels, industries and geographical regions Develop strong understanding of Sprinklr user personas, workflows and behaviors to represent users throughout design process Analyze and distill user feedback into actionable insights to inform product and design decisions Identify, implement and iterate new research methodologies as Sprinklr's UX Research operations continue to evolve "", 'We believe in our product:', 'We invest in our people:', 'We focus on our mission: ', 'We believe in our product', 'Strong problem-solving and critical thinking skills', 'Qualifications:', "" Bachelor's Degree in Psychology, Sociology, Human-Computer Interaction, Information Science, Design or related field :2 years UX Research/Design or relevant industry experience In-depth knowledge of UX Research + Design principles and methodologies Strong written and verbal communication skills, including confidence corresponding with senior stakeholders and high-profile customers Ability to work in fast-paced, ambiguous environments against software release timelines Ability to collaborate and build relationships with fellow team members and stakeholders Curious, empathetic mindset, including intuition to ask effective questions to receive actionable feedback Strong problem-solving and critical thinking skills "", 'Curious, empathetic mindset, including intuition to ask effective questions to receive actionable feedback', 'Collaborate with designers, product owners, engineers and fellow researchers to prioritize research needs and opportunities in a fast-paced environment', 'EEO - Our philosophy on inclusion: ', 'Ability to collaborate and build relationships with fellow team members and stakeholders', ""Bachelor's Degree in Psychology, Sociology, Human-Computer Interaction, Information Science, Design or related field"", 'Strong written and verbal communication skills, including confidence corresponding with senior stakeholders and high-profile customers', 'In-depth knowledge of UX Research + Design principles and methodologies', 'UX Researcher', ':2 years UX Research/Design or relevant industry experience', ""Sprinklr is a Customer Experience Management (CXM) platform for modern enterprises with 1,900 employees helping the world's most valuable enterprises make their customers happier."", 'We focus on our mission:', ""Identify, implement and iterate new research methodologies as Sprinklr's UX Research operations continue to evolve""]",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
"SCIENTIST, BIOINFORMATICS","Vir Biotechnology, Inc.","San Francisco, CA",6 hours ago,75 applicants,"['', 'As a Bioinformatic Scientist, you will: Collaborate with data scientists, software engineers, and with scientists in wet labs.Work with large scale datasets to derive insights to improve our capabilities and our business Develop novel apps, tools and methods for increasing our analytical capabilities Communicate both internally and externally to understand and document requirements.', 'Work with large scale datasets to derive insights to improve our capabilities and our business ', 'Collaborate with data scientists, software engineers, and with scientists in wet labs.', 'Minimum Qualifications', 'Responsibilities', 'Communicate both internally and externally to understand and document requirements.', 'Network and cloud-based Unix/Linux environments to enable the development of production ready remote computational pipelines. Inclusive of but not limited to AWS, Docker and Kubernetes.', '“A World Without Infectious Disease”.', 'Use of NGS tools like bwa, samtools, vcftools, picard, GATK, Freebayes, ANNOVAR, VEP.', 'Demonstrated knowledge of large scale genome analytics (host and pathogen) and data structures.Use of NGS tools like bwa, samtools, vcftools, picard, GATK, Freebayes, ANNOVAR, VEP.Basic knowledge in biostatistics, molecular biology, and/or computer sciences.Knowledge in analyzing next generation sequencing data. Experience with pathogen genomics, single cell genomics data like single cell RNA-seq, single cell ATAC-seq or single cell DNA methylation data is a plus.Demonstrated knowledge in statistics and programming languages such as Python, Perl, and R.Network and cloud-based Unix/Linux environments to enable the development of production ready remote computational pipelines. Inclusive of but not limited to AWS, Docker and Kubernetes.', 'As a Bioinformatic Scientist, you will: ', 'EDUCATION', 'Develop novel apps, tools and methods for increasing our analytical capabilities ', 'Knowledge in analyzing next generation sequencing data. Experience with pathogen genomics, single cell genomics data like single cell RNA-seq, single cell ATAC-seq or single cell DNA methylation data is a plus.', 'Demonstrated knowledge in statistics and programming languages such as Python, Perl, and R.', ""Bachelor's, Master’s Degree or PhD in Bioinformatics, Computational Biology, or related area; and/or equivalent experience/training."", 'Demonstrated knowledge of large scale genome analytics (host and pathogen) and data structures.', 'Basic knowledge in biostatistics, molecular biology, and/or computer sciences.']",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Sr Data Engineer,"Codeworks, Inc.","Milwaukee, WI",23 hours ago,27 applicants,"['', '5-8 years of professional experience in data', 'Accountable for ensuring data within the store meets quality and security requirements\xa0', 'Experience with pipeline/ETL tooling such as\xa0SSIS, Azure Data Factory, AWS Glue, PowerBI Dataflows, Informatica Data Integration, etc.\xa0', 'Execute alone but is a collaborative teammate', 'Embraces continuous learning, curiosity, experimentation and ambiguity', 'Strong SQL background including writing and solving complexity within SQL code and performance tuning', 'Design, build and support data pipelines to facilitate BI and Analytic solutions among the ETL team', 'Bachelor’s Degree in Computer Science, MIS or direct experience\xa0', ' remote to start ', 'Design, build and support data pipelines to facilitate BI and Analytic solutions among the ETL teamSupport establishing a self-service BI data environment including data sourcing, modeling and distribution for consumption by BI Developers\xa0Accountable for ensuring data within the store meets quality and security requirements\xa0Build consensus and trust with partnered organizations on future state patterns\xa0Drive the sharing of standards on our team and the greater community through coaching, mentoring and articles around core methodologies and processesBuild reports/dashboards for consumption within the team using BI tooling; such as\xa0Tableau or Power BICollecting data systematically and consider a broad range of issues or factors to promote sustainability of the dataset', 'Support establishing a self-service BI data environment including data sourcing, modeling and distribution for consumption by BI Developers\xa0', 'Build consensus and trust with partnered organizations on future state patterns\xa0', 'Working with a range of data sources;\xa0Traditional DBMS (MS SQL, IBM DB2, etc.) No SQL DBMS (Mongo), Flat Files (CSV, XLS, etc.), Web (XML, JSON, etc.)', 'Build reports/dashboards for consumption within the team using BI tooling; such as\xa0Tableau or Power BI', 'SSIS, Azure Data Factory, AWS Glue, PowerBI Dataflows, Informatica Data Integration, etc.\xa0', 'Collecting data systematically and consider a broad range of issues or factors to promote sustainability of the dataset', 'Knowledge of pipeline/ETL development standard methodologies for batch and near real-time integrations', 'This is a 12 month W2 contract, remote to start with onsite work required later in 2021 in Milwaukee, Wisconsin.\xa0', 'Solid grasp of summarizing technical solutions into concise and meaningful proposals', 'We are working with a direct client in Milwaukee, Wisconsin looking for a\xa0Sr.\xa0Data Engineer\xa0to join a group providing BI and Analytic solutions for Senior and Executive Leadership within IT. In addition, they provide data solutions and guidance to empower self-service BI Developers and Analysts across all IT functions. ', 'Sr.\xa0Data Engineer\xa0', 'Drive the sharing of standards on our team and the greater community through coaching, mentoring and articles around core methodologies and processes', 'Strong customer/client orientation', 'Bachelor’s Degree in Computer Science, MIS or direct experience\xa05-8 years of professional experience in dataStrong SQL background including writing and solving complexity within SQL code and performance tuningWorking with a range of data sources;\xa0Traditional DBMS (MS SQL, IBM DB2, etc.) No SQL DBMS (Mongo), Flat Files (CSV, XLS, etc.), Web (XML, JSON, etc.)Knowledge of pipeline/ETL development standard methodologies for batch and near real-time integrationsExperience with pipeline/ETL tooling such as\xa0SSIS, Azure Data Factory, AWS Glue, PowerBI Dataflows, Informatica Data Integration, etc.\xa0Grasp of APIs (SOAP and REST)Solid grasp of summarizing technical solutions into concise and meaningful proposalsEmbraces continuous learning, curiosity, experimentation and ambiguityStrong customer/client orientationExecute alone but is a collaborative teammate', 'Responsibilities\xa0', 'Tableau or Power BI', 'Qualifications\xa0', 'Traditional DBMS (MS SQL, IBM DB2, etc.) No SQL DBMS (Mongo), Flat Files (CSV, XLS, etc.), Web (XML, JSON, etc.)', 'This role will help shape and drive the data warehouse/lake for BI and Analytic solutions built by their team as well as the data solution behind the self-service function for their community of BI Developers and Analysts.\xa0', 'Grasp of APIs (SOAP and REST)']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Motion Recruitment,"Irvine, CA",17 hours ago,Be among the first 25 applicants,"['', 'Experience Spark and Scala', ' MS in economics, statistics, physics or another quantitative field Excellent communication skills both verbal and written Experience with ETLs ', 'Experience Data lakes / Data Warehousing', 'Required Skills & Experience', '5+ years as a Data Scientist', '401(k)', 'Experience with Python and Java', ' 5+ years as a Data Scientist Experience Spark and Scala Experience Data lakes / Data Warehousing Experience with Python and Java ', 'You Will Receive The Following Benefits', ' Competitive Pay: Up to $70/hourly, DOE ', 'MS in economics, statistics, physics or another quantitative field', 'Excellent communication skills both verbal and written', 'Pre-tax Commuter Benefit', 'Medical Insurance & Health Savings Account (HSA)', ' Medical Insurance & Health Savings Account (HSA) 401(k) Paid Sick Time Leave Pre-tax Commuter Benefit', 'Job Description', 'Competitive Pay: Up to $70/hourly, DOE', 'Paid Sick Time Leave', 'Although the position is remote, you must be local to the Orange County area. ', 'Experience with ETLs', 'Desired Skills & Experience']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer - EDM,PamTen Inc,"Plano, TX",1 hour ago,Be among the first 25 applicants,"['', 'Contribute to the build out of highly scalable data sets and design of performant access layers', 'Musts', "" 5-7 years of Financial Services/ Trading applications 3+ years of closely related experience with one or more of the following: Microsoft SQL Server, AWS Aurora, PostgreSQL, MySQL, Snowflake, MongoDB, Redis, DynamoDB Strong Python is a MUST T-SQL programming, performance, and optimization Experience with backup/recovery tasks, user administration, data system installation and configuration Data replication technologies, configuration and performance in a clustered environment Scripting or software development experience (PowerShell, python, C#, etc.) Bachelor's degree in computer science or a related technical field"", 'Contribute to project-based work while managing the on-demand workload of pro-active support.', 'Strong Python is a MUST', 'Experience with backup/recovery tasks, user administration, data system installation and configuration', 'Provide guides, examples and coaching to share best practices and increase adoption of tools and techniques', '3+ years of closely related experience with one or more of the following: Microsoft SQL Server, AWS Aurora, PostgreSQL, MySQL, Snowflake, MongoDB, Redis, DynamoDB', 'Pro-actively tune and optimize existing workloads and contribute coded solutions', 'Scripting or software development experience (PowerShell, python, C#, etc.)', '(Enterprise Data Management is the ability of an organization to precisely define, easily integrate and effectively retrieve data for both internal applications and external communication. EDM is focused on the creation of accurate, consistent and transparent content.)', 'Own the expertise in the data platform domain relational and non-relational stores, caches, ETL, streaming', 'Design mechanisms to efficiently migrate data from development to production', ' Own the expertise in the data platform domain relational and non-relational stores, caches, ETL, streaming Collaborate with the Enterprise Data Management function to apply data governance best practices and to integrate data quality and monitoring controls into designs and architecture. (Enterprise Data Management is the ability of an organization to precisely define, easily integrate and effectively retrieve data for both internal applications and external communication. EDM is focused on the creation of accurate, consistent and transparent content.) ', 'Lead efforts to build out next generation systems and harmonize compute capabilities', '5-7 years of Financial Services/ Trading applications', 'Collaborate with the Enterprise Data Management function to apply data governance best practices and to integrate data quality and monitoring controls into designs and architecture.', 'Understand the platforms, data, applications and workflow to ensure that the investment process is best empowered through the lens of highly reliable and performant data systems', ' Lead efforts to build out next generation systems and harmonize compute capabilities Pro-actively tune and optimize existing workloads and contribute coded solutions Contribute to the build out of highly scalable data sets and design of performant access layers Design mechanisms to efficiently migrate data from development to production Understand the platforms, data, applications and workflow to ensure that the investment process is best empowered through the lens of highly reliable and performant data systems Contribute to project-based work while managing the on-demand workload of pro-active support. Provide guides, examples and coaching to share best practices and increase adoption of tools and techniques', 'T-SQL programming, performance, and optimization', ""Bachelor's degree in computer science or a related technical field"", 'Data replication technologies, configuration and performance in a clustered environment']",Entry level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,PeerIQ,"New York, NY",22 hours ago,33 applicants,"['', 'Support existing and develop new data flows as needed by developing processes that verify, standardize, and scale data input, transformation and storage', 'Medical/Dental/Vision', 'Experience with big data (spark, presto, hive) and stream technologies (Kafka, MQ)\xa0Experience providing technical leadership and educating other engineers for best practices on data engineeringFamiliar with *Nix systems, bash, dockerizing applications (You are ultimately responsible for your own infrastructure and you’re cool with that.)Financial Services experience', 'Experience providing technical leadership and educating other engineers for best practices on data engineering', 'Experience developing and building distributed and scalable ETL processes and workflows', 'Work closely with insights/analytics to build and enhance highly configurable, scalable, robust data processing infrastructure and applications to meet rapidly growing data needsImplement and productionize data pipelines and automation to support product and business needs\xa0Support existing and develop new data flows as needed by developing processes that verify, standardize, and scale data input, transformation and storageWork closely with our product, data, research, and capital markets leads on data retrieval and analysis, as well as prototyping and iterative developmentMaintain the privacy of our users and partners by helping ensure best practices in security and data handling continue as we growAct as an advocate for the Data Engineering team by establishing and maintaining a high-level of operational excellence in data engineering', 'B.S. in Computer Science, Engineering, Math, or equivalent experience', 'Work closely with insights/analytics to build and enhance highly configurable, scalable, robust data processing infrastructure and applications to meet rapidly growing data needs', 'Experience tackling complex performance challenges such as runtime optimization of the queries and scalability of the data retrieval', 'The ideal candidate is a self-starting engineer who enjoys working with data (analysis, transformations, analytics) with experience in multiple back end, front end, and visualization technologies. As a Senior Data Engineer, you should be an expert with data warehousing technical components (e.g. Data Modeling, ETL, and Reporting), infrastructure (e.g. hardware and software) and their integration. The candidate is expected to be able to build efficient, flexible, extensible, and scalable ETL and reporting solutions. You should be enthusiastic about learning new technologies and be able to implement solutions using them to provide new functionality to the users or to scale the existing platform.\xa0', 'PERKS & BENEFITS', 'Stock Options/401K', 'BONUS QUALIFICATIONS', 'Generous compensation package', 'PeerIQ is transforming the way lending and securitization markets work.\xa0 Meeting the needs across the credit funding cycle - from loan purchasing to financing to securitization - we work with industry leaders to unlock capital at scale.\xa0 We aim to bridge the gap between originators and the capital markets so that investors can invest with confidence. Our employees come from the technology and financial sectors, combining the best of both to change the game of consumer credit.\xa0\xa0', 'Learn about Finance, Data Science, and latest programming technologies and best practices', 'Maintain the privacy of our users and partners by helping ensure best practices in security and data handling continue as we grow', 'Experience with big data (spark, presto, hive) and stream technologies (Kafka, MQ)\xa0', 'Work closely with our product, data, research, and capital markets leads on data retrieval and analysis, as well as prototyping and iterative development', '4-6 years of experience as a Data Engineer or in a similar role', 'PeerIQ is looking to hire a Senior Data Engineer with a passion for data, data-driven insights, and building products designed to improve financial services and transform capital markets. You will be at the forefront of green field development in delivering our data and analytics platform, working closely with our product, research, and capital markets teams on business-driven development.', 'Strong relational and distributed database experience (Redshift, Oracle etc), familiarity with SQL is critical', 'Experience with automated build and continuous integration testing tools (CircleCI) and continuous deployment tools (Jenkins), container orchestration tools (Kubernetes)', 'QUALIFICATIONS', 'RESPONSIBILITIES', 'Implement and productionize data pipelines and automation to support product and business needs\xa0', 'Act as an advocate for the Data Engineering team by establishing and maintaining a high-level of operational excellence in data engineering', 'Financial Services experience', 'Flexible vacation and sick leave policies', '3+ years experience with AWS services including S3, Redshift, EMR and RDS', 'Generous compensation packageMedical/Dental/VisionStock Options/401KFlexible vacation and sick leave policiesTraining and learning allowance, both money and timeLearn about Finance, Data Science, and latest programming technologies and best practices', 'Proficiency in Python and knowledge of REST API frameworks (Flask, Django a plus), workflow tools (Airflow)', 'Proven critical thinking and analytical problem-solving skills', 'Previous successful candidates for this role, even if lacking experience in financial products, have shown themselves to be passionate developers through projects they have built from scratch.', 'B.S. in Computer Science, Engineering, Math, or equivalent experience4-6 years of experience as a Data Engineer or in a similar role3+ years experience with AWS services including S3, Redshift, EMR and RDSProficiency in Python and knowledge of REST API frameworks (Flask, Django a plus), workflow tools (Airflow)Strong relational and distributed database experience (Redshift, Oracle etc), familiarity with SQL is criticalExperience developing and building distributed and scalable ETL processes and workflowsExperience tackling complex performance challenges such as runtime optimization of the queries and scalability of the data retrievalExperience with automated build and continuous integration testing tools (CircleCI) and continuous deployment tools (Jenkins), container orchestration tools (Kubernetes)Proven critical thinking and analytical problem-solving skillsDesire to learn more about the consumer credit ecosystem and how capital markets affect everyday consumers', 'Familiar with *Nix systems, bash, dockerizing applications (You are ultimately responsible for your own infrastructure and you’re cool with that.)', 'Desire to learn more about the consumer credit ecosystem and how capital markets affect everyday consumers', 'Training and learning allowance, both money and time']",Mid-Senior level,Full-time,Engineering,Financial Services,2020-11-05 11:32:32
Senior Machine Learning Engineer (Multiple Openings),Nike,"Boston, MA",21 hours ago,25 applicants,"['WHAT YOU BRING TO NIKE- Undergraduate degree in Computer Science, or equivalent experience- 5+ years of professional experience in software engineering, data engineering, machine learning, or related field- Strong problem solving and analytical mindset- Proven ability to write robust, maintainable, and extendable code in Python- Experience with cloud architecture and technologies, in particular Amazon Web Services- Experience with technologies like Spark, Kubernetes, Docker, Jenkins, Hive, Terraform is highly desirable- Experience with agile development and test driven development- Proven understanding of data structures, data modeling and software architecture- Effective communication skills (with team members, the business, and in code)', 'WHO ARE WE LOOKING FORWe seek multiple Senior Software Engineers to join our team. As a Senior Software Engineer, you will develop robust advanced analytics and machine learning solutions that have a direct impact on the business. You should have experience in Python; a strong background in algorithms and data structures; hands-on AWS experience; as well as experience in database technology (e.g. Postgres, Redis) and data processing technology (e.g. EMR). You should also have a proven history of team leadership and value delivery, and thrive in working in a product model using Scrum.WHAT WILL YOU WORK ONIf this is you, you’ll be working with the Advanced Analytics and Machine Learning (AAML) team at Nike. With teammates in Portland, Boston, China, and Poland, you will be joining a global organization working to tackle machine learning problems at scale. You’ll be designing and implementing scalable applications that use prediction models and optimization programs to deliver data driven decisions that result in immense business impact. You’ll also contribute to core advanced analytics and machine learning platforms and tools to enable both prediction and optimization model development. You thrive when surrounded by hardworking colleagues and aim to never stop learning. We are looking for candidates who enjoy a collaborative and academic environment where we develop and share new skills, mentor, and drive to deliver knowledge and software back to the analytics and engineering communities both within Nike and at-large.We value and cultivate our culture by seeking to always be collaborative, intellectually curious, fun, open, and diverse.WHO WILL YOU WORK WITHIn this role, you’ll be working closely with the rest of our global team, along with Commercial and Consumer Analytics, Enterprise Architecture, and Solution Architecture. This role reports to a Director of Engineering on the AAML team. ']",Mid-Senior level,Full-time,Information Technology,Sporting Goods,2020-11-05 11:32:32
Equity Factor Researcher - Hedge Fund,Selby Jennings,"New York, NY",24 hours ago,Over 200 applicants,"['They have a reputation for offering some of the most competitive compensation on Wall Street and are happy to wait out non-competes to get the right person.', 'They are looking for candidates with a who have an impressive academic background, with the soft skills to match, as well as being a strong hands-on programmer in Python.\xa0You will need to have an extensive background in equity factor modelling as well as in-depth knowledge investment research. ', 'One of the most reputable Hedge Funds in the world are looking for a Talented Intraday Equity Factor Modeller to join one of their highest profile business units. The Fund operates both quantitative and systematic strategies and is well known for having some of the most cutting-edge infrastructure in the market. ', 'The team’s remit spreads across the Fund’s entire equities business, with their research agenda being set by the Fund’s CEO.\xa0You will be working collaboratively to build complex equity factor models and the research infrastructure to allow these to implemented across Front Office. ', ' ']",Mid-Senior level,Full-time,Research,Financial Services,2020-11-05 11:32:32
Lead Data Scientist,Texas Health Resources,"Arlington, TX",1 hour ago,59 applicants,"['', '\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0', 'Texas Health Resources is one of the largest faith-based, nonprofit health care delivery systems in the United States and the largest in North Texas in terms of patients served.', '·\xa0\xa0\xa0\xa0\xa0\xa0Full Time; 1st\xa0Shift-Flexible Schedule (1-2 days a week you will have the option to work from home).', 'Skills:', '·\xa0\xa0\xa0\xa0\xa0\xa0Proven track record of building intuitive statistical model that provide actionable insight to business users', 'The address is ', 'Texas Health Resources seeks to hire a DATA SCIENTIST LEAD to work Full Time in the Data Integration Department.', 'The ideal candidate will possess the following qualifications', 'At Texas Health, we strive to create an atmosphere of respect, integrity, compassion and excellence for all who come in contact with us, be they patients or our employees. We are committed to diversity in our workforce, and our mission to serve spreads\xa0', '\xa0', 'The address is 612 East Lamar Blvd., Arlington, TX 76011.', '·\xa0\xa0\xa0\xa0\xa0\xa0Excellent skills using Tableau, Power BI, Cognos, or equivalent visualization software.', 'Why Texas Health Resources? ', 'Essential Functions:', '·\xa0\xa0\xa0\xa0\xa0\xa0Excellent skills doing data discovery in an EDW or data lake environment. ', 'Salary range is Min. $53.48/hr to Max. $85.73/hr – based on relevant experience ', ""The Data Scientist Lead role will be a self-motivated individual, who can inspire others by telling stories with data. The individual will lead and manage other analyst on projects. They will help educate the business on data analysis and drive business decisions through their team's analytic work. Regularly exercising independent judgment and decision making in projects across the entire enterprise of Texas Health Resources. This position manages four people."", ""·\xa0\xa0\xa0\xa0\xa0\xa07 Years with a Master's degree: 7 years experience working with inferential statistics and/or machine learning required. Experience working in healthcare or related field preferred."", ""·\xa0\xa0\xa0\xa0\xa0\xa0Master's Degree Statistics, Engineering, Epidemiology, Health Service Research, Operation Research, Economic, Statistics or equivalent area. Required"", 'Job Description:', '·\xa0\xa0\xa0\xa0\xa0\xa0Ability to manage train others, set timelines, and hold accountability.', '·\xa0\xa0\xa0\xa0\xa0\xa0Excellent skills using SQL to query, join tables, and create tables.', '·\xa0\xa0\xa0\xa0\xa0\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0Excellent skills using SPSS, R, SAS or python.', 'Qualifications:', '·\xa0\xa0\xa0\xa0\xa0\xa0Ph.D. Statistics, Engineering, Epidemiology, Health Service Research, Operation Research, Economic, Statistics or equivalent area. Preferred', 'Texas Health has 25 acute-care and short-stay hospitals that are owned, operated, joint-ventured or affiliated with the system. It has more than 3,800 licensed beds, more than 21,100 employees of fully-owned/operated facilities plus 1,400 employees of consolidated joint ventures and counts more than 5,500 physicians with active staff privileges at its hospitals.', '·\xa0\xa0\xa0\xa0\xa0\xa05 Years with a PhD: 5 years experience working with inferential statistics and/or machine learning required. Experience working in healthcare or related field preferred.', 'Leads multiple projects in an analytic role, and overcome roadblock in data to get things done. Works with minimal guidance and can manipulating and join data from multiple sources into population set for comparative analysis. To be accomplished using a SQL, or No-SQL tool approach. Partners with senior leadership across the organization to assess need and define business questions. Leads analytic meetings to translate business questions/problems into analytical questions and deliver analytic insights back to the business. Ability to communicate complex methodologies of analytics to a non-technical user. Works with multi-disciplinary or cross functional teams to plan and build efficient scalable models that can be automated for large scale data analyses, development, validation, and implementation. Ability to communicate this plan Deliver actionable insights with data to propose operational or process changes. Identify key driver of desired outcomes both known and unknown at the start of the analysis. Explaining the analysis to key stakeholders. Program or project analysis using statistical techniques to prove or disprove efficacy of the projects, tying in sources from the EMR, Supply Chain, Finance, Patient Experience, and third-party sources. Presentations to upper leadership on findings through graphical displays, and ability to tell the story through data and examples. Write statistical methodology and results for technical reports and publication. Submit for publication insights discovered at THR. Effectively manage diverse assignment with shifting priorities and tight timeframes. Mentor analytic team members to grow their skills and ability. This might include creating training classes on analytic concepts, or leading a monthly journal article review. ', ""·\xa0\xa0\xa0\xa0\xa0\xa0Bachelor's Degree Statistics, Engineering, Epidemiology, Health Service Research, Operation Research, Economic, Statistics or equivalent area. Required AND"", '·\xa0\xa0\xa0\xa0\xa0\xa0Able to take on multiple projects concurrently and manage changes in scope along the way.', ' Work Schedule\xa0']",Mid-Senior level,Full-time,Health Care Provider,Hospital & Health Care,2020-11-05 11:32:32
Senior Data Engineer,Hamilton Porter,"Chicago, IL",,N/A,"['', 'Collaborate with multiple teams in high visibility roles and own the solution development end-to-end', 'Responsibilities:', 'Hands-on knowledge of Python and Spark', 'BS/MS in Technical Field, Computer Science, Mathematics, or a related field', '401k matching program, health & wellness programs, and much more!', '4+ years’ experience in SQL, developing ETL Processes in the data warehouse spaceHands on experience with Azure Data Platform including but not limited to Azure Data Factory, Synapse Analytics and Azure Data Lake.BS/MS in Technical Field, Computer Science, Mathematics, or a related fieldExperience and knowledge in end-to-end architecture and development of enterprise data solutions using Data Lake, Python, Spark, CI/CD frameworks and MPP systemsHands-on knowledge of Python and SparkExperience with Linux, Cloud/Big Data architecturesExcellent communication, teamwork and consulting skills.Strong analytical and problem-solving skill set.', 'Experience with Linux, Cloud/Big Data architectures', 'This role provides opportunities to shape the future of data infrastructure and work on the latest cloud data technologies to develop analytic systems that scale with company growth. In this new role, you’ll architect cloud data infrastructure used by different teams and see data projects from beginning to end. As a key hire in a new department you will design build and manage scalable data pipelines, data warehouses and work with our Decision / Data Science team to on machine learning models which provide insights to multiple business partners to make data-driven business decisions.', 'Strong analytical and problem-solving skill set.', 'Develop enterprise elastic/cloud data lake, data warehousing platform supporting the needs of business intelligence, data science and advance analytics projects', 'Compensation & Perks', 'Design and develop new framework and automation tools to enable teams to consume and understand data faster', 'Competitive Annual Base Salary', 'Experience and knowledge in end-to-end architecture and development of enterprise data solutions using Data Lake, Python, Spark, CI/CD frameworks and MPP systems', '4+ years’ experience in SQL, developing ETL Processes in the data warehouse space', 'Develop optimal data processing architecture and systems for new data and ETL pipelines based on the newly created Azure Data Platform environment.Develop enterprise elastic/cloud data lake, data warehousing platform supporting the needs of business intelligence, data science and advance analytics projectsDive deep into all aspects of the business, understand the problems, and tie them back to data engineering solutionsAct as a technical leader and mentor for the data analysts and BI business analysts, helping institute best engineering practices and approachesDesign and develop new framework and automation tools to enable teams to consume and understand data fasterBrainstorm and contribute ideas to our technology, algorithms and productsCollaborate with multiple teams in high visibility roles and own the solution development end-to-end', 'Senior Data Engineer ', 'Act as a technical leader and mentor for the data analysts and BI business analysts, helping institute best engineering practices and approaches', 'Hands on experience with Azure Data Platform including but not limited to Azure Data Factory, Synapse Analytics and Azure Data Lake.', 'Employee Stock Purchase Program and Profit Sharing', 'Hamilton Porter ', 'This role can be worked 100% remotely, but we are only considering candidates that live in the Greater Chicago area at this time', 'We are looking to interview and hire for this position ASAP ~ please apply today for consideration!', 'Skills Required:', 'Brainstorm and contribute ideas to our technology, algorithms and products', 'Generous PTO Plan with ability to work 100% remotely', 'Develop optimal data processing architecture and systems for new data and ETL pipelines based on the newly created Azure Data Platform environment.', 'Hamilton Porter is a recruiting firm that works with technology companies from across the United States to find and hire engineering talent on a full-time basis. We are happy to announce that one of our largest clients is actively looking to hire a Senior Data Engineer to their team. Our client is a publicly traded manufacturing and supply chain company that operates at high scale and the movement of data between their systems and teams is at the heart of their continued growth. This role can be worked 100% remotely, but we are only considering candidates that live in the Greater Chicago area at this time. Please read on for more details!', 'Competitive Annual Base SalaryExcellent Healthcare Benefits (Medical, Dental, Vision, etc..)Employee Stock Purchase Program and Profit SharingGenerous PTO Plan with ability to work 100% remotely401k matching program, health & wellness programs, and much more!', 'Excellent communication, teamwork and consulting skills.', 'Dive deep into all aspects of the business, understand the problems, and tie them back to data engineering solutions', 'Excellent Healthcare Benefits (Medical, Dental, Vision, etc..)']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"Research Scientist, Polymer Materials",iHire,"West Chicago, IL",3 hours ago,Be among the first 25 applicants,"['', 'Education', ' Stay abreast of technology development in analytical chemistry and polymer and material science and engineering as applicable ', ' Proven track record of problem solving and innovative solutions. ', ' Analytical research skills in instrument and analytical techniques, including Spectroscopy (FTIR, NIR, UV), Thermal analysis (TGA, DSC), DMA, Gas chromatography, Rheometry, Microscopy (optical, SEM). ', ' Document R&D findings and performance data in the appropriate form for various uses, including R&D reporting, support of third-party certification, patent record of inventions, and customer presentations. ', ' Experience with other inorganic systems, such as mineral ceramics, optional but a plus. ', ' BS or higher in Polymer Science, Material Science, Polymer or Chemical Engineering, Analytical Chemistry, or equivalent field ', 'Experience', ' Provide expertise in analysis of various materials (primarily polymer and wood-based composites, adhesives, and coatings) to enable accelerated product and process development cycles and quality improvement without always engaging costly large-scale experiments and manufacturing trials.  Demonstrate (sub) project leadership, team collaboration, and communication across functional groups, while balancing prioritizations and meeting timelines.  Apply scientific methods (DOE, Root Cause Analysis, Statistical Analysis, structured experimentation, formulation recommendations, scale to commercialization, etc.) to solve complex problems and further Masonites technical competencies.  Provide ongoing support for cost optimization projects, resolving quality issues and addressing complex manufacturing problems in a timely fashion.  Document R&D findings and performance data in the appropriate form for various uses, including R&D reporting, support of third-party certification, patent record of inventions, and customer presentations.  Stay abreast of technology development in analytical chemistry and polymer and material science and engineering as applicable ', ' Demonstrate (sub) project leadership, team collaboration, and communication across functional groups, while balancing prioritizations and meeting timelines. ', ' Provide ongoing support for cost optimization projects, resolving quality issues and addressing complex manufacturing problems in a timely fashion. ', ' Minimum five years experience in R&D setting conducting analytical research and experiments with polymer and wood composite products, coatings, and adhesives. ', ' Minimum five years experience in R&D setting conducting analytical research and experiments with polymer and wood composite products, coatings, and adhesives.  Analytical research skills in instrument and analytical techniques, including Spectroscopy (FTIR, NIR, UV), Thermal analysis (TGA, DSC), DMA, Gas chromatography, Rheometry, Microscopy (optical, SEM).  Proven track record of problem solving and innovative solutions.  Demonstrated ability to work both autonomously and in collaborative settings.  Experience with other inorganic systems, such as mineral ceramics, optional but a plus. ', ' Apply scientific methods (DOE, Root Cause Analysis, Statistical Analysis, structured experimentation, formulation recommendations, scale to commercialization, etc.) to solve complex problems and further Masonites technical competencies. ', 'Responsibilities', ' Provide expertise in analysis of various materials (primarily polymer and wood-based composites, adhesives, and coatings) to enable accelerated product and process development cycles and quality improvement without always engaging costly large-scale experiments and manufacturing trials. ', ' Demonstrated ability to work both autonomously and in collaborative settings. ']",Associate,Full-time,Science,Chemicals,2020-11-05 11:32:32
UX Researcher,Argo AI,"Pittsburgh, PA",8 hours ago,Be among the first 25 applicants,"['', ' Bachelor’s degree in HCI, UX Research or similar preferred 5+ years work experience as a UX Researcher Understanding of human computer interaction and UI/UX principles Experience conducting qualitative studies and field interviews/observations Experience developing protocols to aid in objective heuristic evaluations Experience with Userzoom, UserTesting or similar platforms Ability to synthesize and translate data to make well informed business decisions and recommendations Experience working as a member of a cross-functional team Empathy and the ability to connect with users to gain a deep understanding of their needs Ability to speak with and understand technical details Ability to coordinate with stakeholders and make trade-offs Exposure to common development and software planning practices (Optional) Experience in Sketch, Adobe XD, InVision, or similar ', ' Conduct user testing for a suite of products across the organization Plan and conduct research products as a member of a cross-functional team Develop screening criteria and test protocols Partner with product designers and managers to help deliver best-in-class user experiences and customer journeys Plan for the long-term vision while meeting short-term goals Coordinate with stakeholders and developers to create achievable experiences that meet the needs of the organization ', 'Understanding of human computer interaction and UI/UX principles', 'Coordinate with stakeholders and developers to create achievable experiences that meet the needs of the organization', 'Company and team bonding outlets: employee resource groups, quarterly team activity stipend, and wellness initiatives', 'Experience developing protocols to aid in objective heuristic evaluations', 'in-vehicle displays for our passengers and test specialists', 'Develop screening criteria and test protocols', 'Exposure to common development and software planning practices', 'Employer-matched 401(k) retirement plan with immediate vesting', 'Complimentary daily lunches, beverages, and snacks', 'terminals for remote operations to provide guidance to vehicles', 'Competitive compensation packages', 'Employer-paid group term life insurance and the option to elect voluntary life insurance ', 'Unlimited vacation', 'Discounted programs that include legal services, identity theft protection, pet insurance, and more', 'Conduct user testing for a suite of products across the organization', 'What You’ll Do', ' High-quality individual and family medical, dental, and vision insurance Competitive compensation packages Employer-matched 401(k) retirement plan with immediate vesting Employer-paid group term life insurance and the option to elect voluntary life insurance  Paid parental leave  Paid medical leave Unlimited vacation Complimentary daily lunches, beverages, and snacks Pre-tax commuter benefits Monthly wellness stipend  Professional development reimbursement Employee assistance program Discounted programs that include legal services, identity theft protection, pet insurance, and more Company and team bonding outlets: employee resource groups, quarterly team activity stipend, and wellness initiatives ', 'Monthly wellness stipend ', ' in-vehicle displays for our passengers and test specialists terminals for remote operations to provide guidance to vehicles tools to quickly and accurately label data from our sensors tools to create virtual simulation scenarios to test the cars virtually ', 'tools to create virtual simulation scenarios to test the cars virtually', 'Plan and conduct research products as a member of a cross-functional team', 'Ability to speak with and understand technical details', 'Pre-tax commuter benefits', 'Experience working as a member of a cross-functional team', '(Optional) Experience in Sketch, Adobe XD, InVision, or similar', 'Our Background', 'Meet The Team', 'Partner with product designers and managers to help deliver best-in-class user experiences and customer journeys', '5+ years work experience as a UX Researcher', 'tools to quickly and accurately label data from our sensors', 'Who We Are', 'Ability to synthesize and translate data to make well informed business decisions and recommendations', 'Ability to coordinate with stakeholders and make trade-offs', 'Bachelor’s degree in HCI, UX Research or similar preferred', 'Professional development reimbursement', 'Paid medical leave', 'Experience with Userzoom, UserTesting or similar platforms', 'Employee assistance program', 'Experience conducting qualitative studies and field interviews/observations', 'Empathy and the ability to connect with users to gain a deep understanding of their needs', ""What You'll Need To Succeed"", 'High-quality individual and family medical, dental, and vision insurance', 'Paid parental leave ', 'Plan for the long-term vision while meeting short-term goals', 'What We Offer You']",Associate,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Machine Learning Researcher/Engineer,Cypress HCM,"Boston, MA",21 hours ago,Over 200 applicants,"['5+ years of experience in engineering,      computer science, or statistics ', 'Collaborate with regional      and national research computing peers on the fields landscape and best      practices. ', 'Responsibilities:', ' 5+ years of experience in engineering,      computer science, or statistics  3+ years of experience in      developing statistical data analysis using Python or R  Experience applying      machine learning and deep learning concepts/techniques such as random      forest, support vector machines, RNNs, CNNs, LSTM  Hands-on experience in      installing and programming in common frameworks such as scikit-learn,      TensorFlow, Keras, Theano, Caffe  Demonstrated proficiency      in multiple programming languages (Python, MATLAB, R, and C) and the      ability to quickly learn new programming languages and tools as required  GPU programming experience      with CUDA or OpenCL is highly desired  Experience utilizing and      scripting for Linux HPC clusters   Strong analytical skills      required with an ability to manage multiple projects and deliverables  Excellent communication      skills, and the ability to work well both independently as well as in a      team  ', 'As a remember of a research      focused team, you’ll be engaging researchers as partners to co-create and      co-learn research activities and relevant advanced computing capabilities      to facilitate and transform collaborative and interdisciplinary research ', 'Provide outreach and training      to the university research community. ', 'Hands-on experience in      installing and programming in common frameworks such as scikit-learn,      TensorFlow, Keras, Theano, Caffe ', 'Excellent communication      skills, and the ability to work well both independently as well as in a      team ', 'Work directly with      faculty, staff, and graduate students and related communities on complex      projects that require advanced knowledge of machine/deep Learning      algorithms/frameworks ', 'Important Soft Skills: ', 'Education Requirements: Master’s degree is preferred ', '\xa0 ', 'Important Technical Skills', '\xa0', '3+ years of experience in      developing statistical data analysis using Python or R ', 'Travel: There is no travel for this position ', 'Location: ', 'Employees: ', 'Industry: Higher education ', ' As a remember of a research      focused team, you’ll be engaging researchers as partners to co-create and      co-learn research activities and relevant advanced computing capabilities      to facilitate and transform collaborative and interdisciplinary research  Work directly with      faculty, staff, and graduate students and related communities on complex      projects that require advanced knowledge of machine/deep Learning      algorithms/frameworks  Provide necessary training      and consulting to support efficient utilization high-performance computing      resources.  Install, document, and      validate existing researcher-facing software packages.  Provide outreach and training      to the university research community.  Collaborate with regional      and national research computing peers on the fields landscape and best      practices.  ', 'Important Soft Skills: Experience working with researchers in a university setting is ideal, strong team player, strong communication skills, self-starter ', 'Install, document, and      validate existing researcher-facing software packages. ', 'Experience applying      machine learning and deep learning concepts/techniques such as random      forest, support vector machines, RNNs, CNNs, LSTM ', 'Location: Boston, MA ', 'Benefits: Strong medical, dental, vision plans, 401K match, tuition reimbursement', 'Demonstrated proficiency      in multiple programming languages (Python, MATLAB, R, and C) and the      ability to quickly learn new programming languages and tools as required ', 'Education Requirements: ', 'Industry: ', 'Important Technical Skills ', 'Employees: 12,000 ', 'Machine/Deep Learning Researcher/Engineer ', 'Strong analytical skills      required with an ability to manage multiple projects and deliverables ', 'Experience utilizing and      scripting for Linux HPC clusters  ', 'GPU programming experience      with CUDA or OpenCL is highly desired ', 'Benefits: ', 'Travel: ', 'Responsibilities: ', 'Provide necessary training      and consulting to support efficient utilization high-performance computing      resources. ', 'Machine/Deep Learning Researcher/Engineer']",Mid-Senior level,Full-time,Engineering,Higher Education,2020-11-05 11:32:32
Microfluidics Engineer / Scientist,Quanterix,"Billerica, MA",19 hours ago,Be among the first 25 applicants,"['', 'Proven ability to collaborate in a multi-disciplinary environment', 'Test platform design, system integration and verification pertaining to the miniaturization approaches', 'Skill And Knowledge Requirements', 'Travel Requirements', 'Technology scouting of external miniaturization approaches', 'Industrial experience in assay and instrumentation development preferred', 'Invention of technologies that enable Simoa miniaturization', 'Feasibility research on miniaturization technologies applicable to Simoa', 'Interacting with engineering and assay development groups to transfer new Simoa technologies from feasibility to full development', ' Proven ability to collaborate in a multi-disciplinary environment Strong background in experimental design and communication of scientific results Background in miniaturization technology research and/or development for biomedical and analytical chemistry applications Experience with specific microfluidic technologies, e.g., digital microfluidics, droplets, etc. preferred Experience in working with breadboard and/or engineering prototype systems, system integration and design verification Excellent quantitative analytical skills and trouble-shooting skills Must be a self-starter and motivated to learn new laboratory techniques and relevant engineering software packages Track record of publications on miniaturization technologies preferred ', ' Some travel expected to visit collaboration or development partners, and to attend scientific conferences ', 'Some travel expected to visit collaboration or development partners, and to attend scientific conferences', ' Master’s degree or above in physical sciences or engineering disciplines (physics, chemistry, chemical engineering, mechanical engineering, biomedical engineering) required Industrial experience in assay and instrumentation development preferred Experience with quality management system preferred ', 'Experience in working with breadboard and/or engineering prototype systems, system integration and design verification', 'Background in miniaturization technology research and/or development for biomedical and analytical chemistry applications', 'Track record of publications on miniaturization technologies preferred', 'Collaboration with technology development partners to develop and evaluate miniaturization technologies', 'Experience with specific microfluidic technologies, e.g., digital microfluidics, droplets, etc. preferred', ' Feasibility research on miniaturization technologies applicable to Simoa Test platform design, system integration and verification pertaining to the miniaturization approaches Invention of technologies that enable Simoa miniaturization Collaboration with technology development partners to develop and evaluate miniaturization technologies Technology scouting of external miniaturization approaches Collaboration with assay scientists in the Technology group to demonstrate Simoa assays on miniaturized systems Interacting with engineering and assay development groups to transfer new Simoa technologies from feasibility to full development ', 'Excellent quantitative analytical skills and trouble-shooting skills', 'Experience with quality management system preferred', 'Collaboration with assay scientists in the Technology group to demonstrate Simoa assays on miniaturized systems', 'Must be a self-starter and motivated to learn new laboratory techniques and relevant engineering software packages', 'Microfluidics Engineer/Scientist', 'Key Responsibilities', 'Strong background in experimental design and communication of scientific results', 'Master’s degree or above in physical sciences or engineering disciplines (physics, chemistry, chemical engineering, mechanical engineering, biomedical engineering) required', 'Minimum Experience And Education']",Entry level,Full-time,Engineering,Medical Devices,2020-11-05 11:32:32
UX Researcher,Synergis Creative,"New York, NY",2 hours ago,Be among the first 25 applicants,"['', 'Skill/Experience/Education Mandatory', 'Synergis Creative/Synergis is an Equal Opportunity/Affirmative Action employer.', 'The ability work in a very fast-paced environment.', 'No C2C, Sponsorship not offered', 'Synergis Creative recruiters have been a driving force of the creative and marketing space for over six years. We draw from a wealth of experience with technology staffing, industry best practices and exceptional connections to match candidates with incredible opportunities.', 'Familiarity with planning and conducting a wide range of research design and practical work.\xa0Strong\xa0understanding of strengths and shortcomings of different research methods and tools.\xa0Excellent communication and teamwork skills.The ability work in a very fast-paced environment.Effective communication through written reports and oral presentations.', 'Excellent communication and teamwork skills.', 'Requirements:', ""You will impress the interviewers if you have capabilities consistent with: Large scale data collection and analysis (e.g., collecting data from online communities, scraping social networking sites, crawling websites for landscape analyses, etc). Automated processing of visual data (e.g., experience with automated image classification, OpenCV, etc). Social network analysis (e.g., mapping networks of resource usage).Visualization, especially of information rich sets of data.Research instrument or prototype development skills Experience of research with target users that include Software Developers and User Experience Designers Bachelor's degree preferred (In related field)"", 'You\xa0will work as part of a small cross-functional team including Program Management, Design, Engineers and Research to conduct research collecting and analyzing\xa0user behavior with appropriate methods, qualitative and quantitative. You will\xa0be working in a\xa0fast-paced, rapidly changing environment,\xa0focussed on establishing and evaluating user needs and\xa0expectations.', ""Research instrument or prototype development skills Experience of research with target users that include Software Developers and User Experience Designers Bachelor's degree preferred (In related field)"", 'Effective communication through written reports and oral presentations.', '12+ month contract (benefits offered, potential to extend)', 'A track record of decision-making based on using a variety of practical techniques in a successful software-product development environment. Including responsibility for designing and facilitating goal directed and task directed usability assessments of software interactions on a range of different software platforms (iOS, Android, Web)', 'You will need Critical thinking in human behavioral analysis normally evidenced by Master’s degree level or equivalent on a human centered research course, for example HCI, Psychology, Human Factors, Social Psychology, Anthropology Familiarity with experimental design basics, including setup, understanding and explaining trade-offs of method, understanding populations and sampling, familiarity with issues of validity, bias, and the ability to construct or critique possible experimental setupsA track record of decision-making based on using a variety of practical techniques in a successful software-product development environment. Including responsibility for designing and facilitating goal directed and task directed usability assessments of software interactions on a range of different software platforms (iOS, Android, Web)Excellent communication skills illustrated through participant management, interview planning and management, workshop facilitation using focus group techniques and translation of findings into impactful design stories. Ability to construct, deploy and analyze surveys that have high quality structure, content and question structure.Demonstrable experience analyzing, synthesizing and distilling insights from both quantitative and qualitative data sources. A portfolio that illustrates your communication and research skills.', 'New York, NY (Telecommute)', 'Visualization, especially of information rich sets of data.', 'Desired', 'Master’s degree level ', 'Excellent communication skills illustrated through participant management, interview planning and management, workshop facilitation using focus group techniques and translation of findings into impactful design stories. Ability to construct, deploy and analyze surveys that have high quality structure, content and question structure.', 'Local to NYC area (starts remote, potential onsite in the future)', 'Demonstrable experience analyzing, synthesizing and distilling insights from both quantitative and qualitative data sources. ', '5+ years of professional experience', 'You will impress the interviewers if you have capabilities consistent with: Large scale data collection and analysis (e.g., collecting data from online communities, scraping social networking sites, crawling websites for landscape analyses, etc). Automated processing of visual data (e.g., experience with automated image classification, OpenCV, etc). Social network analysis (e.g., mapping networks of resource usage).', 'Strong\xa0understanding of strengths and shortcomings of different research methods and tools.\xa0', 'Familiarity with planning and conducting a wide range of research design and practical work.\xa0', 'A portfolio that illustrates your communication and research skills.', 'UX Researcher', '\ufeffCreative (creative.synergishr.com/) is a specialized division of Synergis (www.synergishr.com) that serves the needs of leading creative firms, departments and agencies. Synergis Creative carefully matches creative and marketing talent to a full-time, contract or project positions.', 'You will need Critical thinking in human behavioral analysis normally evidenced by Master’s degree level or equivalent on a human centered research course, for example HCI, Psychology, Human Factors, Social Psychology, Anthropology Familiarity with experimental design basics, including setup, understanding and explaining trade-offs of method, understanding populations and sampling, familiarity with issues of validity, bias, and the ability to construct or critique possible experimental setups', 'If interested in learning more or applying please reach out to rebecca@synergiscreative.com ']",Associate,Contract,Design,Staffing and Recruiting,2020-11-05 11:32:32
"Research Associate II/Sr. Research Associate Core Technologies, Analytics",Astellas Pharma US,"Seattle, WA",9 hours ago,Be among the first 25 applicants,"['', ' Collaborates with members of the R&D teams and with other teams within Universal Cells.', ' Maintain accurate records and assist Scientist with recording experimental data', ' Research Associate II: BS degree with 3+ years or MS with 0-2 years of relevant laboratory experience.', ' Developing and routinely executing standard analytical assays including genotyping PCR/qPCR and flow cytometry.', ' Performing standard molecular biology techniques including primer design, molecular cloning, and Sanger sequencing.', 'Required', ' Summarizing and presenting data in both oral and written formats.', ' Strong organizational, time management, and problem-solving skills with scientific attention to detail', '  Experience with aseptic technique and mammalian cell culture  Experience optimizing and running flow cytometry assays (up to 4 colors)  Experience with liquid handlers/lab robotics  Experience managing and data mining databases  Experience with Southern blots ', ' Strong work ethic with a passion for working in a fast-paced, dynamic and diverse work environment', ' Experience with aseptic technique and mammalian cell culture', ' Performs other duties as assigned or special projects as needed.', '  Education/Experience:  Research Associate II: BS degree with 3+ years or MS with 0-2 years of relevant laboratory experience.  Senior Research Associate: BS degree with 5+ years or MS with 2+ years of relevant laboratory experience.  Extensive PCR experience designing Taqman probes and multiplexed assays.  Ability to troubleshoot, problem solve, and apply critical thinking.  Experience with aseptic technique and mammalian cell culture  Strong organizational, time management, and problem-solving skills with scientific attention to detail  Ability to work independently and ability to effectively collaborate with other teams  Excellent communication and interpersonal skills  Excellent work planning, organization and record keeping  Strong work ethic with a passion for working in a fast-paced, dynamic and diverse work environment ', ' Experience managing and data mining databases', ' Compiling and analyzing data in a timely manner.', ' Excellent communication and interpersonal skills', '  Developing and routinely executing standard analytical assays including genotyping PCR/qPCR and flow cytometry.  Performing standard molecular biology techniques including primer design, molecular cloning, and Sanger sequencing.  Compiling and analyzing data in a timely manner.  Summarizing and presenting data in both oral and written formats.  Maintain accurate records and assist Scientist with recording experimental data  Collaborates with members of the R&D teams and with other teams within Universal Cells.  Performs other duties as assigned or special projects as needed. ', 'Purpose', ' Experience with Southern blots', ' Extensive PCR experience designing Taqman probes and multiplexed assays.', 'Preferred', ' Education/Experience:', 'Essential Job Responsibilities', ' Senior Research Associate: BS degree with 5+ years or MS with 2+ years of relevant laboratory experience.', ' Ability to troubleshoot, problem solve, and apply critical thinking.', ' Ability to work independently and ability to effectively collaborate with other teams', ' Experience optimizing and running flow cytometry assays (up to 4 colors)', ' Experience with liquid handlers/lab robotics', ' Excellent work planning, organization and record keeping']",Not Applicable,Full-time,Other,Biotechnology,2020-11-05 11:32:32
User Experience Researcher,Strategic Systems Inc,"Indianapolis, IN",22 hours ago,41 applicants,"['', 'At least 2 years of work experience in statistical analysis, qualitative analysis, quantitative analysis, product usability moderating, experimental design, and test method selection. In addition,', 'Must have had proven successful experience in the integration of consumer research into a business’s product design practice.', 'Candidate must display a genuine passion for product-centric innovation; an ability to work well independently as well as with a team; must have a keen and exceptional attention to detail; and more importantly, an ability to identify root recommendations inspired by the consumers’ needs and behaviors.', 'Experience related requirement, a UX Researcher candidate must display a strong comprehension of the strengths and limitations of the different research methods, inclusive of when and how to apply each in product/market/consumer analyses.', 'Role of the UI/UX researcher is a critical leadership role in the adoption of Human Centered Design (HCD) within company’s environment. The adoption of HCD practices and artifacts is a critical component in the company’s ability to competitively respond to CMS and other agency bids. The UI/UX researcher skill set will support the company’s ability to connect to the provider and beneficiary through interview knowledge, survey building and knowledge of a variety of HCD tools and techniques. The UI/UX Researcher will demonstrate how empathy and connection will help development teams build an experience that delights the customer.', 'Candidate must possess an effective problem solving ability even under short notice. The UX Researcher must be able to come up with creative solutions and consider a variety of alternative solutions for each problem', 'Role Description', 'Candidate possess excellent communication skills to be able to relay these research methodology concepts and findings to product department personnel and to other collaborating personnel in a clear, simple, and relatable manner.', 'At least 2 years of work experience in statistical analysis, qualitative analysis, quantitative analysis, product usability moderating, experimental design, and test method selection. In addition,Must have had proven successful experience in the integration of consumer research into a business’s product design practice.Experience in product usability testing tools, for example Keynote.Experience related requirement, a UX Researcher candidate must display a strong comprehension of the strengths and limitations of the different research methods, inclusive of when and how to apply each in product/market/consumer analyses.Candidate possess excellent communication skills to be able to relay these research methodology concepts and findings to product department personnel and to other collaborating personnel in a clear, simple, and relatable manner.Candidate must possess an effective problem solving ability even under short notice. The UX Researcher must be able to come up with creative solutions and consider a variety of alternative solutions for each problemCandidate must show proficiency in Sketch, InDesign, Illustrator, Keynote and Photoshop computer software(s).Candidate must display a genuine passion for product-centric innovation; an ability to work well independently as well as with a team; must have a keen and exceptional attention to detail; and more importantly, an ability to identify root recommendations inspired by the consumers’ needs and behaviors.', 'Candidate must show proficiency in Sketch, InDesign, Illustrator, Keynote and Photoshop computer software(s).', 'Experience in product usability testing tools, for example Keynote.']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Euclid Innovations,"Chicago, IL",21 hours ago,Be among the first 25 applicants,"['', 'Here is the Requirement:', 'Azure Data Engineer ', 'Location: Chicago IL', 'Duration: 6 months', ' Role Description: ', 'Hope you would find this email in your interest – Please find the below requirement for your review and reply with your interest levels on the same. Appreciate if you could send me your updated copy or resume, availability to move ahead in the process.', 'Hello', ' ', 'Data analysis, data modeling, and data integration using azure technologies like Azure Data Factory (ADF). Hands on experience with Azure Synapse, Databricks, ADLS Gen 2, & Logic Apps', 'W2 Only']",Mid-Senior level,Contract,Engineering,Information Technology and Services,2020-11-05 11:32:32
Sr. Machine Learning Scientist,"Sage Intacct, Inc.","San Francisco, CA",21 hours ago,37 applicants,"['What it’s like to work here: ', 'Experience communicating projects to both technical and non-technical audiences.\xa0', 'Working with product managers and engineers to translate product/business problems into tractable machine learning problems and drive the ideas into production using machine leaning\xa0', 'Writing production-quality/ optimized code.\xa0', 'You may be a fit for this role if you: ', 'Responsibilities:', 'Today, unfortunately, financial management and services are universally manual, tedious, and error prone. At the same time, these processes often follow well-defined rules, abide by industry standardization, and have become increasingly\xa0data-rich. Our team, within the Medium Segment Native Cloud Solutions at Sage, builds cloud-based AI-powered features and products that fundamentally change the way businesses operate.\xa0', 'Preferred Qualifications : ', '5+ years industry experience training and shipping production machine learning models.\xa0', 'You may be a fit for this role if you:', 'Every business on the face of Earth must, in some way, do bookkeeping, accounting, and financial planning to operate. At the outset, these functions may seem like mundane facts-of-life in the process of running a business; however, the skill with which a company does them can have a profound impact not only on their business, but also the world.\xa0A poorly forecasted budget,\xa0could mean the abrupt end to the clinical trial of a potentially life-saving drug. On the other hand, a highly accurate hiring plan can lead to successful team growth that allows a company to design a brand-new material that helps reverse climate change.\xa0', 'You often think about applications of machine learning in your personal life.\xa0', 'Minimum Qualifications:', 'PhD in Computer Science, Electrical Engineering, Statistics, Physics, or similar quantitative fields.\xa0Publications in top conferences (ICML,\xa0NeurIPS, ICLR, ACL, EMNLP, ICCV).\xa0Experience wrangling data, writing complex SQL queries and basic bash scripting.\xa0You have deep experience\xa0with:\xa0logistic regression, gradient descent, regularization, cross-validation, overfitting, bias, variance, convex optimization, eigenvectors, sampling, latency, computational complexity, sparse matrices.\xa0', 'We are looking for a Principal Machine Learning Scientist in San Francisco to help us ship AI-powered products and services.\xa0', 'Publications in top conferences (ICML,\xa0NeurIPS, ICLR, ACL, EMNLP, ICCV).\xa0', 'Strong production level programming skills in Python or C++.\xa0', 'Building, experimenting, training, tuning, and shipping machine learning models in the areas\xa0of:\xa0classification, clustering, time-series modeling and\xa0forecasting.\xa0Writing production-quality/ optimized code.\xa0Working with product managers and engineers to translate product/business problems into tractable machine learning problems and drive the ideas into production using machine leaning\xa0Working with machine learning infrastructure engineers to ship models.\xa0Presenting findings, results, and performance metrics to stakeholders.\xa0', 'What it’s like to work here:', 'You’re comfortable with investigating open-ended problems and coming up with concrete approaches to solve them.\xa0', 'Minimum Qualifications: ', ""You don't only use machine learning models but can implement many machine learning and statistical learning models from scratch and know when/how to apply them to real world noisy data.\xa0"", 'You will have an opportunity to work on a small and growing team based in San Francisco in an environment where engineering is central to what we do. The products we build are breaking new ground, and we have a focus on providing the best environment to allow you to do what you do best - solve problems, collaborate with your team and push first class software. We promote an open diverse environment, encourage contributions to open-source software and invest heavily in our staff. Our team is talented, capable and inclusive. We know that great things can only be done with great teams and look forward to building and working with a great people.\xa0', 'Have a strong intuition into different modeling techniques and their suitability to different problems.\xa0', 'Working with machine learning infrastructure engineers to ship models.\xa0', 'You can consume research ideas and papers and translate them into production models.\xa0', 'Building, experimenting, training, tuning, and shipping machine learning models in the areas\xa0of:\xa0classification, clustering, time-series modeling and\xa0forecasting.\xa0', 'Preferred Qualifications :', '5+ years of hands-on experience in working with several of:\xa0pytorch,\xa0tensorflow,\xa0numpy,\xa0scipy, scikit-learn, pandas.\xa0', 'MS in Computer Science, Electrical Engineering, Statistics, Physics, or similar quantitative field.\xa0Strong theoretical and mathematical foundations in linear algebra, probability theory, multivariate optimization.\xa0Have a strong intuition into different modeling techniques and their suitability to different problems.\xa0Strong production level programming skills in Python or C++.\xa05+ years of hands-on experience in working with several of:\xa0pytorch,\xa0tensorflow,\xa0numpy,\xa0scipy, scikit-learn, pandas.\xa05+ years industry experience training and shipping production machine learning models.\xa0Experience communicating projects to both technical and non-technical audiences.\xa0', 'You’re a deeply curious person and eager to learn and grow.\xa0', 'Presenting findings, results, and performance metrics to stakeholders.\xa0', 'You have deep experience\xa0with:\xa0logistic regression, gradient descent, regularization, cross-validation, overfitting, bias, variance, convex optimization, eigenvectors, sampling, latency, computational complexity, sparse matrices.\xa0', 'Experience wrangling data, writing complex SQL queries and basic bash scripting.\xa0', ""You’re comfortable with investigating open-ended problems and coming up with concrete approaches to solve them.\xa0You can consume research ideas and papers and translate them into production models.\xa0You don't only use machine learning models but can implement many machine learning and statistical learning models from scratch and know when/how to apply them to real world noisy data.\xa0You’re a deeply curious person and eager to learn and grow.\xa0You often think about applications of machine learning in your personal life.\xa0"", 'MS in Computer Science, Electrical Engineering, Statistics, Physics, or similar quantitative field.\xa0', 'Strong theoretical and mathematical foundations in linear algebra, probability theory, multivariate optimization.\xa0', 'Responsibilities: ', 'PhD in Computer Science, Electrical Engineering, Statistics, Physics, or similar quantitative fields.\xa0']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Sr. Researcher,Aditi Consulting,"Bellevue, WA",20 hours ago,Be among the first 25 applicants,"['Build strong relationships with Designers, Product Managers, Marketing, Analytics and Engineers to deliver impact on our global products', ""Conduct multi-screen research to inform the definition and development of Marketplace's products. Research spans from generative research to design, launch and measurement of product performanceDesign, plan and conduct user research, employing methods such as: remote usability, field studies, competitive evaluations, usability studies, RITE studies, surveys, diary studies, and other relevant approachesProvide insight and vision to the team based on understanding user needs and behaviorsLead stakeholders in translation of research findings into actionable results, activating design thinking and concept making through facilitation.Build strong relationships with Designers, Product Managers, Marketing, Analytics and Engineers to deliver impact on our global productsSynthesize research findings from other data sources (including market research, site analytics and secondary research) into meaningful recommendations and actionable results"", 'Primary responsibilities:', 'Design, plan and conduct user research, employing methods such as: remote usability, field studies, competitive evaluations, usability studies, RITE studies, surveys, diary studies, and other relevant approaches', 'Provide insight and vision to the team based on understanding user needs and behaviors', 'Lead stakeholders in translation of research findings into actionable results, activating design thinking and concept making through facilitation.', ""Conduct multi-screen research to inform the definition and development of Marketplace's products. Research spans from generative research to design, launch and measurement of product performance"", 'Synthesize research findings from other data sources (including market research, site analytics and secondary research) into meaningful recommendations and actionable results']",Associate,Contract,Research,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Infigage,"Sterling, VA",3 hours ago,88 applicants,"['', 'Location: Sterling VA', '\xa0', 'Informatica DEI', 'PowerCenter', 'Shell Scripting', 'Scala', 'Spark ', 'AWS', 'Data BricksSpark Scala', 'Position: Data Engineer', 'Position Type: Long Term Contract', 'Python', 'Good to Have:', 'Informatica DEIPowerCenterAWSShell ScriptingPython', 'Required Skills:', 'Data Bricks']",Mid-Senior level,Contract,Engineering,Staffing and Recruiting,2020-11-05 11:32:32
Data Engineer,Cisco,"San Francisco, CA",19 hours ago,59 applicants,"['', '  Work closely with our strategy and business systems teams to design and maintain scalable data models and pipelines   Develop an enterprise reporting and data warehouse solution to drive business decision-making   Administer and maintain our organizational business intelligence and data visualization tool   Manage product instrumentation and tag management application   Have a clear understanding of the reports/analyses/insights to be driven by data and build data solutions to effectively support the analytics needed  Interact with our Engineering and Infrastructure teams to ensure production stability   Understand and lead the effort to expand on existing design, processes, standards and reusable components from various engineering functions to reduce complexity and ensure quality and performance.  ', ' Thorough analytical mind and high attention to detail ', ' Strong CS fundamentals and experience with scripting languages (Python, Ruby, Javascript) ', ' Develop an enterprise reporting and data warehouse solution to drive business decision-making ', ' Work closely with our strategy and business systems teams to design and maintain scalable data models and pipelines ', 'What You Will Do', '  Experienced knowledge of various database platforms (SQL, NoSql, On-Prem)   History of building and maintaining a data warehouse from scratch   Strong CS fundamentals and experience with scripting languages (Python, Ruby, Javascript)   Experience with Cloud Data Warehouses (Experience working with Snowflake is a plus)   Experience with business intelligence tools (Microstrategy is a plus)   Experience with analytics instrumentation technology (Google Tag Manager and Analytics is a plus)   Thorough analytical mind and high attention to detail   Unparalleled drive for speed and early results in an area of immense opportunity   Pragmatic and business-impact driven ', ' Experience with business intelligence tools (Microstrategy is a plus) ', ' Experience with Cloud Data Warehouses (Experience working with Snowflake is a plus) ', ' Manage product instrumentation and tag management application ', ' Interact with our Engineering and Infrastructure teams to ensure production stability ', ' Administer and maintain our organizational business intelligence and data visualization tool ', ' Pragmatic and business-impact driven ', 'Who We Are', 'Who You Are', ' Experience with analytics instrumentation technology (Google Tag Manager and Analytics is a plus) ', ' Have a clear understanding of the reports/analyses/insights to be driven by data and build data solutions to effectively support the analytics needed ', ' History of building and maintaining a data warehouse from scratch ', ' Understand and lead the effort to expand on existing design, processes, standards and reusable components from various engineering functions to reduce complexity and ensure quality and performance. ', ' Unparalleled drive for speed and early results in an area of immense opportunity ', ' Experienced knowledge of various database platforms (SQL, NoSql, On-Prem) ']",Not Applicable,Full-time,Information Technology,Computer Hardware,2020-11-05 11:32:32
"Research Scientist, HFE/HCI",GN Group,"Glenview, IL",5 hours ago,26 applicants,"['', 'Coordinate and manage projects across a multi-disciplinary team of scientists.', 'Experience with VR development and Unity a plus.', 'Be a user advocate within a research team, applying HFE/HCI driven methodologies to assess and define solutions.Conduct systematic literature reviews, and synthesizing evidence to influence design decisions.Drive the creation of conceptual models and usability objectives aligned with user-centered design goals and tasks.Design and develop hardware and software prototypes for proof-of-concept and feasibility studies to formulate evidence-based solutions.Coordinate and manage projects across a multi-disciplinary team of scientists.', 'Experience with bio-sensing and novel input methods. Human participant experimental design and data analysis.Experience with applying machine learning methods, specifically computer vision and signal processing. Familiarity with tools such as TensorFlow, CoreML and ARKit a plus.Experience with VR development and Unity a plus.Experience coordinating input from stakeholders in multiple disciplines.User-Centered Design – skilled in creating solutions from user research and iterative design process.', 'Rapid prototyping using hardware and software tools: Xamarin development, PCB etching, 3D printing, etc.', 'Be a user advocate within a research team, applying HFE/HCI driven methodologies to assess and define solutions.', 'Experience coordinating input from stakeholders in multiple disciplines.', 'Experience with applying machine learning methods, specifically computer vision and signal processing. Familiarity with tools such as TensorFlow, CoreML and ARKit a plus.', 'User-Centered Design – skilled in creating solutions from user research and iterative design process.', 'Design and develop hardware and software prototypes for proof-of-concept and feasibility studies to formulate evidence-based solutions.', 'Conduct systematic literature reviews, and synthesizing evidence to influence design decisions.', 'Why GN Hearing:', 'Areas of responsibility:', 'Qualifications:', 'Human participant experimental design and data analysis.', 'Location:', 'Experience with bio-sensing and novel input methods. ', 'Drive the creation of conceptual models and usability objectives aligned with user-centered design goals and tasks.', 'Research Scientist, HFE/HCI']",Not Applicable,Full-time,Engineering,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Drug Safety Scientist,Planet Pharma,"Boston, MA",3 hours ago,Be among the first 25 applicants,"['', 'Contributes to initiatives for process improvement and consistency regarding aggregate reporting, clinical trial safety oversight, signal management and responding to ad hoc safety questions.', 'Project manage, and author of aggregate safety reports such as PSURs, DSURs, PADERs, local reports in collaboration with the PV scientist LeadFacilitates signal management process for assigned products (i.e., signal tracking, leading review meetings, etc.) and in collaboration with Safety MDs and Sr. PV Scientist / AD, evaluates safety data and signals as part of ongoing pharmacovigilance activities. May include authoring signal evaluation reports, or sections of signal evaluation reports. Conducts literature review for safety information and interacts with other groups to obtain necessary data (i.e., Epidemiology, SAE data).Responsible for the Aggregate reports Master calendar (production, update, stakeholders review)In collaboration with PV Scientist lead coordinates and authors responses to safety questions from regulatory authorities.Contributes to initiatives for process improvement and consistency regarding aggregate reporting, clinical trial safety oversight, signal management and responding to ad hoc safety questions.Understands, interprets, analyzes, and clearly presents scientific and medical data in verbal and written format (including intermediate understanding and application of medical concepts and terminology).Interacts collaboratively and effectively in a team environment (including Safety, Clinical Development, Medical Affairs, Clinical Operations, and Regulatory), as well as with external colleaguesLeads and conducts, independently and/or collaboratively, all aspects of substantive projects such as signaling, authoring of aggregate data reports, and responses to regulatory agency requests.', 'In collaboration with PV Scientist lead coordinates and authors responses to safety questions from regulatory authorities.', 'Interacts collaboratively and effectively in a team environment (including Safety, Clinical Development, Medical Affairs, Clinical Operations, and Regulatory), as well as with external colleagues', 'Facilitates signal management process for assigned products (i.e., signal tracking, leading review meetings, etc.) and in collaboration with Safety MDs and Sr. PV Scientist / AD, evaluates safety data and signals as part of ongoing pharmacovigilance activities. May include authoring signal evaluation reports, or sections of signal evaluation reports. Conducts literature review for safety information and interacts with other groups to obtain necessary data (i.e., Epidemiology, SAE data).', 'Understands, interprets, analyzes, and clearly presents scientific and medical data in verbal and written format (including intermediate understanding and application of medical concepts and terminology).', 'Minimum 5 years industry experience, with a minimum of 3 years of PV experience.', 'Project manage, and author of aggregate safety reports such as PSURs, DSURs, PADERs, local reports in collaboration with the PV scientist Lead', 'Responsibilities:', 'Education Bachelor’s Degree in biologic or natural science; or health care discipline. Advanced degree (PhD, MPH, NP, PharmD, etc.) preferred.', 'Leads and conducts, independently and/or collaboratively, all aspects of substantive projects such as signaling, authoring of aggregate data reports, and responses to regulatory agency requests.', 'Education Bachelor’s Degree in biologic or natural science; or health care discipline. Advanced degree (PhD, MPH, NP, PharmD, etc.) preferred.Minimum 5 years industry experience, with a minimum of 3 years of PV experience.', 'Reporting to a Sr. PV Scientist or above, the PV Scientist will serve as a critical team member with the lead PV Scientist for products or product groups, including project management and authoring of aggregate reports (PSUR, DSUR, PADER), safety evaluations, aggregate report planning, authoring responding to ad hoc regulatory responses, conducting safety literature reviews.', 'Requirements:', 'Responsible for the Aggregate reports Master calendar (production, update, stakeholders review)', 'Description:', 'The PV Scientist will serve as a Subject Matter Expert for the Safety and cross-functional team on relevant global safety regulations and guidelines; data output and analyses; and, product information.']",Mid-Senior level,Contract,Writing/Editing,Pharmaceuticals,2020-11-05 11:32:32
Executive Search Researcher,The Lawrence Advisory,United States,23 hours ago,Be among the first 25 applicants,"['', '•\tPrevious experience recruiting or executive search is a plus', 'Experience/Competencies:', '•\tStrong work ethic, sense of customer service, and responsiveness', 'Responsibilities:', '•\tParticipate in the search strategy development', '•\tA bachelor’s degree\xa0', '•\tHighly developed analytical abilities, critical thinking, and problem-solving skills', '•\tProject management\xa0', '•\tDevelop outreach target lists', '•\tHands-on experience involving market or prospect research', '•\tAssist with document editing\xa0', '•\tFamiliarity with LinkedIn and online databases/tools', '•\tCreate search status reports and other reports for clients', '        candidates', '•\tIdentify search outreach targets (organizations, potential referral sources, and prospective ', '•\tConduct mapping, market, competitive intelligence, internet, and LinkedIn research', '•\tFive plus years of related professional experience']",Associate,Contract,Research,Human Resources,2020-11-05 11:32:32
GCP Data Engineer,"AQUA Information Systems, Inc","Hartford, CT",22 hours ago,Be among the first 25 applicants,"['', 'BigData/GCP ', 'Need Exp candidate with Bigdata and GCP Exp', 'Remote or Contract ', 'W2']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Manager Scientist, Formulation Development",Sanofi,"Meriden, CT",4 hours ago,Be among the first 25 applicants,"['', 'Adhere to company policies and maintain documentation and records of laboratory data and results.', 'Having experience in managing associates is a plus.', 'Excellent verbal and written communication skills.', 'Experience in managing multiple projects and laboratory personnel.', 'Preferred Qualifications:', 'Participate in cross-functional teams to manage the project and transfer the technology.', 'Basic Qualifications:', 'Responsibilities include:', 'Present ideas, concepts, and findings internally and externally and represent the company at national and international scientific conferences.', '5-8 years of experience with MS, 1-2 years of experience with Ph.D.', '2-5+ years of hands on experience in the characterization of vaccines and biologics in a pharmaceutical or biotechnology industry setting preferred.', 'MS or Ph.D. degree in Biochemistry or relevant field including Biophysical Chemistry, Biology, Pharmacy, Biomedical Engineering or combination of experience and training that is equivalent.', 'Experience in developing novel formulations', 'Experience in biophysical and biochemical characterization of proteins and a familiarity with state of the art biophysical and biochemical assays such as DSC, DLS, DSF, Bi-layer Interferometry, CD Spectroscopy, FITR etc.', 'Identify stability and formulation issues and evaluate potential solutions and improvements independently.', 'Function as a lead and subject matter expert in investigations to support vaccine development and manufacturing.', 'Maintain a knowledge of the scientific literature.', '2-5+ years of hands on experience in the characterization of vaccines and biologics in a pharmaceutical or biotechnology industry setting preferred.Experience in biophysical and biochemical characterization of proteins and a familiarity with state of the art biophysical and biochemical assays such as DSC, DLS, DSF, Bi-layer Interferometry, CD Spectroscopy, FITR etc.Experience in developing novel formulationsFamiliarity with cGMPs and/or vaccine manufacturing is a plus.Experience in managing multiple projects and laboratory personnel.Excellent verbal and written communication skills.Having experience in managing associates is a plus.', 'Provide and write status updates, assessments, study protocols, development reports, and written procedures (SOPs), and publish manuscripts in peer reviewed journals where appropriate.', 'Perform batch monitoring of the DS batches produced at different sites across Sanofi network and also by CMO using biophysical and biochemical methods and techniques such as Sodium Dodecyl Sulfate-Polyacrylamide Electrophoresis (SDS-PAGE), Dynamic Light Scattering (DLS), Differential Scanning Fluorimetry (DSF), Bi-layer Interferometry (Octet), Infrared spectroscopy (IR), Flow imaging microscopy, and Circular Dichroism Spectroscopy.Identify stability and formulation issues and evaluate potential solutions and improvements independently.Function as a lead and subject matter expert in investigations to support vaccine development and manufacturing.Participate in cross-functional teams to manage the project and transfer the technology.Manage and train laboratory associate on procedures and studies.Adhere to company policies and maintain documentation and records of laboratory data and results.Provide and write status updates, assessments, study protocols, development reports, and written procedures (SOPs), and publish manuscripts in peer reviewed journals where appropriate.Maintain a knowledge of the scientific literature.Present ideas, concepts, and findings internally and externally and represent the company at national and international scientific conferences.', 'Manage and train laboratory associate on procedures and studies.', 'Perform batch monitoring of the DS batches produced at different sites across Sanofi network and also by CMO using biophysical and biochemical methods and techniques such as Sodium Dodecyl Sulfate-Polyacrylamide Electrophoresis (SDS-PAGE), Dynamic Light Scattering (DLS), Differential Scanning Fluorimetry (DSF), Bi-layer Interferometry (Octet), Infrared spectroscopy (IR), Flow imaging microscopy, and Circular Dichroism Spectroscopy.', 'MS or Ph.D. degree in Biochemistry or relevant field including Biophysical Chemistry, Biology, Pharmacy, Biomedical Engineering or combination of experience and training that is equivalent.5-8 years of experience with MS, 1-2 years of experience with Ph.D.', 'Familiarity with cGMPs and/or vaccine manufacturing is a plus.']",Mid-Senior level,Full-time,Other,Pharmaceuticals,2020-11-05 11:32:32
Research Scientist I - EX,Seattle Children's,"Seattle, WA",5 hours ago,43 applicants,"['', 'Area of Interest: Research & Development;FTE/Hours per pay period: 1.0 FTE (80 hours per bi-weekly pay periods);Work Status: Regular;Department: Immunity & Immunotherapies;Shift: Day Shift;Job ID: 35959;', 'Work Status: Regular;', 'Job ID:', 'The people who work at Seattle Children’s are members of a community that seeks to respect and celebrate all the qualities that make each of us unique. Each of us is empowered to be ourselves within this community, which cultivates and promotes equity, diversity, and inclusion at all levels. ', 'Area of Interest: Research & Development;', 'Work Status:', 'About Us', 'U.S. News & World Report’s', 'Department:', 'FTE/Hours per pay period:', 'Shift:', 'FTE/Hours per pay period: 1.0 FTE (80 hours per bi-weekly pay periods);', 'Seattle Children’s is proud to be an Equal Opportunity Workplace and Affirmative Action Employer.', 'Hope. Care. Cure. These three simple words capture what we do at Seattle Children’s - to help every child live the healthiest and most fulfilling life possible. Are you ready to engage with a mission-driven organization that is life-changing to many, and touches the hearts of all? #HOPECARECURE', ' Bachelor’s Degree in biology, microbiology, immunology, molecular biology or biochemistry.', 'Requirements', ' Prior experience in a laboratory setting.', 'Required Credentials', 'Preferred', 'Area of Interest:', 'Overview', ' N/A', 'Job ID: 35959;', 'Shift: Day Shift;', ' Research experience working with rodents, and/or tissue culture techniques is highly preferred.', 'Our community welcomes diverse experiences, backgrounds, and thoughts as this is what drives our spirit of inquiry and allows us to better connect with our increasingly diverse patients and families. Our organization recruits, employs, trains, compensates, and promotes without regard to race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. ', 'Our Commitment to Diversity', 'Department: Immunity & Immunotherapies;']",Associate,Full-time,Research,Nonprofit Organization Management,2020-11-05 11:32:32
"Senior Data Engineer, Platforms and Databases",Ocrolus,"New York, NY",19 hours ago,Be among the first 25 applicants,"['', 'Build our data platforms and orchestration tools, and help ensure delivery of early use cases for the platform', 'Knowledge of Continuous Delivery principles, automation, and testing practices', 'Partner with our SRE team to ensure the data platform is consistently healthy and that its operational burdens are eliminated or minimized', 'Mentor Data Engineers (and Data Scientists) in learning how to write high quality computer code\xa0', 'Nice To Have', 'Experience thoughtfully implementing security standards such as PCI or SOC\xa0Analytics or Machine Learning experience', 'Experience thoughtfully implementing security standards such as PCI or SOC\xa0', 'Fluent in SQL or database query languages', 'Who We Are:\xa0', 'Partner with Product Engineering and Machine Learning teams to create new features, models, and products', 'Responsibilities ', 'Requirements ', 'Comfortable delivering tech in cloud environments such as AWS', 'Interest in database internals and distributed systems: We will use Postgres, Kafka, Spark, Hudi, Elastic, Terraform, and other open source tools to compose our platform.', '5+ years building software using python, scala, java, c++, etcFluent in SQL or database query languagesKnowledge of Continuous Delivery principles, automation, and testing practicesComfortable delivering tech in cloud environments such as AWSInterest in database internals and distributed systems: We will use Postgres, Kafka, Spark, Hudi, Elastic, Terraform, and other open source tools to compose our platform.', 'Ocrolus is a fast growing company with many emerging data needs. We are establishing new platforms and capabilities for users both inside and outside the company. We are building to support a wide variety of use cases with a high degree of engineering rigor as well as product agility. We value engineering excellence, automation and testing and believe doing these things well will create more long term value than simply shipping new features fast.', 'Partner with Compliance Officers and Security Engineers to ensure the data platform is secure and compliant with a range of security standards', '5+ years building software using python, scala, java, c++, etc', 'Requirements', 'Ocrolus is a fintech infrastructure company that transforms documents into actionable data. Powered by Artificial Intelligence and a unique human-in-the-loop data validation process, Ocrolus plugs directly into customer workflows via API, eliminating the need for manual data work. The solution includes built-in fraud detection and analytics, enabling customers to make smarter and faster business decisions with unprecedented precision.', 'Build our data platforms and orchestration tools, and help ensure delivery of early use cases for the platformPartner with our SRE team to ensure the data platform is consistently healthy and that its operational burdens are eliminated or minimizedPartner with Product Engineering and Machine Learning teams to create new features, models, and productsPartner with Compliance Officers and Security Engineers to ensure the data platform is secure and compliant with a range of security standardsMentor Data Engineers (and Data Scientists) in learning how to write high quality computer code\xa0', 'We are seeking a candidate with proven experience building data intensive systems to join our Data Team as a platform centric engineer and technical leader.', 'Data at Ocrolus:', 'Use-cases include loan underwriting, account openings, invoice processing, and other document-intensive processes. Ocrolus has raised over $30 million in venture capital, backed by Oak HC/FT, FinTech Collective, Bullpen Capital, and QED Investors, among others.', 'Analytics or Machine Learning experience']",Mid-Senior level,Full-time,Engineering,Financial Services,2020-11-05 11:32:32
"Sr. Manager, Data Engineer - Data Warehouse/Analytics",MannKind Corporation,"Westlake Village, CA",14 hours ago,Be among the first 25 applicants,"['', 'Build dashboards and reports using BI tools (Tableau, PowerBI)', '  BS/BA Degree with 5-7 years of related experience in data management or analysis. Ability to decipher and organize large amounts of data. An analytical mindset with superb communication and problem-solving skills. Ability to translate complex problems clearly and in nontechnical terms. In-depth SQL programming knowledge - partitioning, indexing, performance tuning knowledge, stored procedure, views Knowledge in various Azure PAAS offerings e.g. ADLS, Azure BLOB, Batch Service, Key Vaults, etc. Knowledge of computer system validation, 21CFR Part11, and HIPAA regulations. Excellent communications, problem-solving and organizational skills. Must be a self-starter and have the ability to drive results. Resourceful and innovative, willing to think “out of the box” when developing solutions. ', 'Provide functional and technical support to the business and functional areas.', 'Develop and implement procedures for effective data management.', 'Position Summary', 'Ability to decipher and organize large amounts of data.', 'Ability to translate complex problems clearly and in nontechnical terms.', 'Assist with recognizing and upholding digital security systems to protect delicate information.', 'Resourceful and innovative, willing to think “out of the box” when developing solutions.', 'Excellent communications, problem-solving and organizational skills.', 'Regularly monitor and evaluate information and data systems that could affect analytical results.', ' Develop and implement procedures for effective data management. Create rules and procedures for data sharing. Advise the company about tools, data sources, and best practices to facilitate digital marketing, pricing, and web analytics Regularly monitor and evaluate information and data systems that could affect analytical results. Assess system performance and make recommendations for software, hardware, and data storage improvements. Manage all incoming data files. Continually develop data management strategies. Build dashboards and reports using BI tools (Tableau, PowerBI) Assist with recognizing and upholding digital security systems to protect delicate information. Provide functional and technical support to the business and functional areas. Gather requirements from business stakeholders, translate those requirements into technical implementation plans and execute plans to provide technology solutions. Ensure project documentation and protocols follow Computer System Validation Lifecycle Management, when appropriate. Ability to use strong industry knowledge to relate to customer needs and dissolve customer concerns and a high level of focus and attention to detail. As a member of the IT organization at MannKind Corp., the incumbent is also expected to be customer-focused, a problem solver, a communicator, professional, willing to learn, organized, and a team player. Duties and responsibilities are not limited to the work listed above and may include other assignments as necessary. ', 'Duties and responsibilities are not limited to the work listed above and may include other assignments as necessary.', 'An analytical mindset with superb communication and problem-solving skills.', 'Knowledge of computer system validation, 21CFR Part11, and HIPAA regulations.', 'Ability to use strong industry knowledge to relate to customer needs and dissolve customer concerns and a high level of focus and attention to detail.', 'Gather requirements from business stakeholders, translate those requirements into technical implementation plans and execute plans to provide technology solutions.', 'Principal Responsibilities', 'In-depth SQL programming knowledge - partitioning, indexing, performance tuning knowledge, stored procedure, views', 'Ensure project documentation and protocols follow Computer System Validation Lifecycle Management, when appropriate.', 'Continually develop data management strategies.', 'As a member of the IT organization at MannKind Corp., the incumbent is also expected to be customer-focused, a problem solver, a communicator, professional, willing to learn, organized, and a team player.', 'Create rules and procedures for data sharing.', 'Knowledge in various Azure PAAS offerings e.g. ADLS, Azure BLOB, Batch Service, Key Vaults, etc.', 'Must be a self-starter and have the ability to drive results.', 'Assess system performance and make recommendations for software, hardware, and data storage improvements.', 'Advise the company about tools, data sources, and best practices to facilitate digital marketing, pricing, and web analytics', ' BS/BA Degree with 5-7 years of related experience in data management or analysis.', 'Education And Experience Qualifications', 'Manage all incoming data files.']",Associate,Full-time,Business Development,Pharmaceuticals,2020-11-05 11:32:32
Data Engineer (.NET),eTeam,"Peoria, IL",17 hours ago,Be among the first 25 applicants,"['Technical Skills', '', 'Candidate must be comfortable reaching out and collaborate with process partners from around the world. Candidates must have excellent English communication skills and be able to effectively solve complex problems. Attention to detail is critical.', 'Soft Skills:', '\xa0', 'Job Title:\xa0Data Engineer 3  (.NET)', 'Core hours 9 am-3 pm Central time, otherwise flexible work hours. ', 'Duration:\xa012 months', ""Minimum four-year College or University degree in Software or Data Engineering, or Computer Science or equivalent. Master's degree preferred with exposure to Statistics."", 'Job responsibilities include the development of .NET data intake application for corporate capacity planning Oracle databases, development of SQL programs ensuring data integrity and interaction with other corporate databases (Db2, Snowflake). The position will require close collaboration with the capacity planning team as well as active collaboration with data owners and IT staff company-wide.', 'Typical Day', 'Location:\xa0Peoria IL', 'Candidate Responsibilities', '\ufeffRemote work location possible but eventual co-location to Peoria, IL desired.', 'Proven 3 years industry (internship experience will not be accepted) experience with Oracle database systems, SQL proficiency, and working experience with .NET program development. Ability to manipulate, process, and interact with larger data repositories.', 'Education Requirements:']",Entry level,Full-time,Accounting/Auditing,Information Technology and Services,2020-11-05 11:32:32
Ligand Binding Assay Scientist,"LanceSoft, Inc.","Groton, CT",21 hours ago,Be among the first 25 applicants,"['', 'can have some combination of academic and industry      but industry exp. is highly preferred. ', 'Routine use of liquid      handling systems, various immunoanalytical platforms (ELISA, MSD, Erenna,      Licor etc), and Watson LIMS are required. Position requires expertise in      biological sample handling and preparation, and laboratory automation.', 'remote/ onsite', 'team player, team collaboration but be able to work      individually on project assigned. ', '-assays will be onsite in Groton, CT ', '- data analytics will be done remote ', 'BS but must have 2+ years hands on industry exp.', 'Responsibilities include      the quantitative analysis of novel biomarkers utilizing immunoassay      techniques. Successful job performance includes development,      characterization, & implementation of appropriate ligand binding assay      techniques and related sample isolation technology for supporting      quantitation of large molecule biomarker species.', 'assays will be onsite in Groton, CT ', 'Location: Groton – CT - 06340', 'Role includes planning      of laboratory activities with key stakeholders and senior leaders,      understanding and influencing therapeutic area biomarker strategies to use      biomarkers in scientific decision-making. ', 'data analytics will be done remote', 'data analytics will be done remote ', 'will have limited people onsite to keep social      distancing requirements ', '\xa0', '- will have limited people onsite to keep social distancing requirements', 'Responsibilities include      the quantitative analysis of novel biomarkers utilizing immunoassay      techniques. Successful job performance includes development,      characterization, & implementation of appropriate ligand binding assay      techniques and related sample isolation technology for supporting      quantitation of large molecule biomarker species. ', 'Responsible for      providing Ligand Binding based analytical data for biomarker discovery and      development, supporting assay method development, validation and study      execution. ', 'What is the minimum education experience required?: Master or 3 years experience with college degree in biological areas.', 'This position provides      biomarker bioanalytical support for ligand binding assay methods. This      scientist provides laboratory support for assay and method development,      assay validation and study support using ligand binding assay techniques      (ELISA, MSD). ', '2 round interviews', '-Must have Elisa exp. ', 'What is the minimum education experience required?: Master or 3 years experience with college degree in biological areas. ', 'This position provides      biomarker bioanalytical support for ligand binding assay methods. This      scientist provides laboratory support for assay and method development,      assay validation and study support using ligand binding assay techniques      (ELISA, MSD).', 'Role includes planning      of laboratory activities with key stakeholders and senior leaders,      understanding and influencing therapeutic area biomarker strategies to use      biomarkers in scientific decision-making.', ' assays will be onsite in Groton, CT  data analytics will be done remote  will have limited people onsite to keep social      distancing requirements  ', 'BS but must have 2+ years hands on industry exp. ', ' This position provides      biomarker bioanalytical support for ligand binding assay methods. This      scientist provides laboratory support for assay and method development,      assay validation and study support using ligand binding assay techniques      (ELISA, MSD).  Responsible for      providing Ligand Binding based analytical data for biomarker discovery and      development, supporting assay method development, validation and study      execution.  Responsibilities include      the quantitative analysis of novel biomarkers utilizing immunoassay      techniques. Successful job performance includes development,      characterization, & implementation of appropriate ligand binding assay      techniques and related sample isolation technology for supporting      quantitation of large molecule biomarker species.  Routine use of liquid      handling systems, various immunoanalytical platforms (ELISA, MSD, Erenna,      Licor etc), and Watson LIMS are required. Position requires expertise in      biological sample handling and preparation, and laboratory automation.  Role includes planning      of laboratory activities with key stakeholders and senior leaders,      understanding and influencing therapeutic area biomarker strategies to use      biomarkers in scientific decision-making.  ', 'Duration: 18 months ', '-assays will be onsite in Groton, CT', 'Job Title: Ligand Binding Assay Scientist', 'team player, team collaboration but be able to work      individually on project assigned.', '2 round interviews ', 'Position Comments ', 'can have some combination of academic and industry      but industry exp. is highly preferred.', 'Routine use of liquid      handling systems, various immunoanalytical platforms (ELISA, MSD, Erenna,      Licor etc), and Watson LIMS are required. Position requires expertise in      biological sample handling and preparation, and laboratory automation. ', '- will have limited people onsite to keep social distancing requirements ', ' ', 'PhD also accepted', 'Job Title: Ligand Binding Assay Scientist ', 'Responsible for      providing Ligand Binding based analytical data for biomarker discovery and      development, supporting assay method development, validation and study      execution.', '-must have ligand binding assay techniques ', '-must have ligand binding assay techniques', 'OT eligible in the future 6+ months out', '- data analytics will be done remote', 'OT eligible in the future 6+ months out ', 'remote/ onsite ', 'assays will be onsite in Groton, CT', 'will have limited people onsite to keep social      distancing requirements', '\xa0 ', '-Must have Elisa exp.', 'Location: Groton – CT - 06340 ', ' -Must have Elisa exp.  -must have ligand binding assay techniques  can have some combination of academic and industry      but industry exp. is highly preferred.  2 round interviews  OT eligible in the future 6+ months out  team player, team collaboration but be able to work      individually on project assigned.  ']",Associate,Contract,Science,Medical Devices,2020-11-05 11:32:32
AWS Python/Data Engineer,ConsultNet,"Edison, NJ",1 day ago,Over 200 applicants,"['', 'AWS Python/Data Engineer', 'Apache Ranger ', 'Experience using Lake Formation or other third party tools for expediting creations of data pipelines', 'JOB DESCRIPTION:\xa0', 'Hive SQL (HiveQL), SQL Server', '\xa0', 'Significant experience creating Data Pipelines on AWS', 'JOB DESCRIPTION:', 'Python, Spark, PySpark', '3RD PARTY VENDORS/CANDIDATES AND RECENT GRADS DO NOT APPLY!\xa0', 'DURATION: 6 months project with a possible extension', 'UPON APPLYING, PLEASE ATTACH YOUR UPDATED RESUME ', 'C# is a plus', 'Familiarity with Linux Shell Scripting', 'AWS Data Lakes related skills Athena, Redshift, Glue, QuickSight', 'TITLE:\xa0AWS Python/Data Engineer', 'Strong understanding of creating Data Lakes on AWS', 'AWS S3 (Store/Retrieve in S3 buckets), CLI, Lambda', 'LOCATION: Edison, NJ (REMOTE)', ' ', 'Strong understanding of creating Data Lakes on AWSSignificant experience creating Data Pipelines on AWSExperience using Lake Formation or other third party tools for expediting creations of data pipelinesPython, Spark, PySparkHive SQL (HiveQL), SQL ServerAWS S3 (Store/Retrieve in S3 buckets), CLI, LambdaAWS Data Lakes related skills Athena, Redshift, Glue, QuickSightApache Ranger C# is a plusFamiliarity with Linux Shell Scripting', 'ONLY QUALIFIED LOCAL CANDIDATES WITH\xa0AWS, PYTHON, DATA LAKE AND DATA PIPELINES EXPERIENCE NEED APPLY!\xa0', 'TITLE:']",Mid-Senior level,Contract,Information Technology,Banking,2020-11-05 11:32:32
"Cloud Data Engineer (Informatica, Snowflake and AWS)",ALIS Software LLC,"Austin, TX",17 hours ago,Be among the first 25 applicants,"['', 'Preferred', 'II. CANDIDATE SKILLS AND QUALIFICATIONS', 'Experience', 'Required', 'Minimum Requirements', 'Other Work Includes, But Is Not Limited To', 'minimum']",Entry level,Full-time,Consulting,Hospital & Health Care,2020-11-05 11:32:32
Data Scientist with Security Clearance,ClearanceJobs,"Herndon, VA",3 hours ago,Be among the first 25 applicants,"['', 'Familiarity/Experience With IC Data Is Preferred', 'Clearance: Applicants must be US citizens and able to obtain a clearance. Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information. Management retains the discretion to add to or change the duties of the position at any time. BasisPath, Inc. is an Equal Opportunity Employer and an Affirmative Action Employer (M/F/Disabled/Veteran). BasisPath, Inc. prohibits employment discrimination based on race, color, religion, creed, age, sex, sexual orientation, gender identity/expression, national origin or ancestry, marital status, status as a military veteran (including recently separated and other protected veterans), or status as a qualified handicapped or disabled individual, or as Vietnam-Era Veteran, in accordance with applicable law.']",Entry level,Contract,Engineering,Information Technology and Services,2020-11-05 11:32:32
RESEARCH SCIENTIST I (EPIDEMIOLOGY/BIOSTATISTICS),California Department of Public Health,"Sacramento County, CA",9 hours ago,Be among the first 25 applicants,"['', 'Classification', '# of Positions', ' Evaluation Scientist ', 'Position #(s)', 'Department Information', 'Job Description And Duties', 'Job Type', 'Position Details', 'Work Location', ' Are you looking to join an exciting, dedicated team of professionals improving the life course of women, infants, children and adolescents in California? The Maternal, Child and Adolescent Health (MCAH) Division promotes the health and well-being of mothers and their families through cross-cutting programs and innovative solutions. Among the MCAH offerings are the adolescent sexual health programs Personal Responsibility Education Program and Information & Education Program, and programs designed to support pregnant and parenting women, including Black Infant Health Program, Adolescent Family Life Program and California Home Visiting Program. Additional programs under the MCAH umbrella include SIDS and Breastfeeding Programs. To accomplish this mission, MCAH maintains partnerships, contracts, and agreements with State, federal, and local agencies in both public and private sectors.', 'Job Code #', ' Duty Statement ', 'Will Consider', 'Working Title']",Associate,Full-time,Research,Nonprofit Organization Management,2020-11-05 11:32:32
"Research Scientist (BS or MS), Assay Development and Screening",Novartis Institutes for BioMedical Research (NIBR),"Cambridge, MA",6 hours ago,Be among the first 25 applicants,"['', 'Division', ' Perform mechanism-of-action studies using cellular biology, genetics, and molecular biology approaches', ' Synthesize data and communicate results in team settings', 'Work Location', ' Ability to handle large data sets and familiarity with GraphPad Prism/Spotfire.', ' Previous experience with automation, and phenotypic screening will be favorably considered', 'Country', 'Functional Area', 'Company/Legal Entity', 'The Novartis Group of Companies are Equal Opportunity Employers and take pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status.', ' Execute mid to large screens using compounds or genetic reagents for drug/target discovery', ' Excellent team player with strong oral and written communication skills', 'Shift Work', ' Develop disease-relevant biochemical and cellular assays compatible with HTS', ' Assess and implement emerging cutting-edge technologies and novel assays', ' M.S. degree in biological sciences and 2+ years, or B.S. degree 4+ years of hands-on research experience in biochemistry and mammalian cell biology Demonstrated proficiency in assay development, automation, and screening (including but not limited to: HTRF, FI, NanoBit and reporter assays) Strong knowledge of biochemistry, cell and molecular biology techniques that may include: enzymology, protein-protein interaction, cell culture, cloning, viral transduction, stable cell line generation, immunofluorescence, qRT-PCR, Western Blotting, and CRISPR Excellent team player with strong oral and written communication skills Highly self-motivated, curious, flexible, and innovative', ' Engage with multidisciplinary project teams to design, execute, and interpret experiments', 'Business Unit', ' Develop disease-relevant biochemical and cellular assays compatible with HTS Execute mid to large screens using compounds or genetic reagents for drug/target discovery Perform mechanism-of-action studies using cellular biology, genetics, and molecular biology approaches Assess and implement emerging cutting-edge technologies and novel assays Engage with multidisciplinary project teams to design, execute, and interpret experiments Synthesize data and communicate results in team settings Develop productive relationships with collaborators and represent Novartis values of integrity, courage, innovation, performance, quality, and collaboration', ' Previous experience with automation, and phenotypic screening will be favorably considered Ability to handle large data sets and familiarity with GraphPad Prism/Spotfire.', 'Job Description', 'Employment Type', ' Strong knowledge of biochemistry, cell and molecular biology techniques that may include: enzymology, protein-protein interaction, cell culture, cloning, viral transduction, stable cell line generation, immunofluorescence, qRT-PCR, Western Blotting, and CRISPR', 'Job Type', ' M.S. degree in biological sciences and 2+ years, or B.S. degree 4+ years of hands-on research experience in biochemistry and mammalian cell biology', 'Minimum Requirements', ' Demonstrated proficiency in assay development, automation, and screening (including but not limited to: HTRF, FI, NanoBit and reporter assays)', ' Highly self-motivated, curious, flexible, and innovative', 'EEO Statement', ' Develop productive relationships with collaborators and represent Novartis values of integrity, courage, innovation, performance, quality, and collaboration']",Associate,Full-time,Research,Pharmaceuticals,2020-11-05 11:32:32
Senior Machine Learning Engineer,Glocomms,San Francisco Bay Area,19 hours ago,Over 200 applicants,"['', 'End to End production of machine learning products', 'MS (PhD Preferred) in a highly quantitative field', 'Requirements:', 'MS (PhD Preferred) in a highly quantitative field5+ years building production-ready systemsGreat working knowledge of ML algorithms\xa0Top levels skills in Python (Scipy, Pandas etc…)Ability to present clearly to present to C-suiteExperience working with Deep Learning techniques (TensorFlow)', ""What you'll do: "", '5+ years building production-ready systems', 'Great working knowledge of ML algorithms\xa0', 'Consulting with key stakeholders to implement new solutions', 'Senior Machine Learning Engineer', 'Ability to present clearly to present to C-suite', 'End to End production of machine learning productsThought leadership on all Machine Learning problemsConsulting with key stakeholders to implement new solutionsThinking outside the box to make a better customer experienceMentor junior engineers', 'Experience working with Deep Learning techniques (TensorFlow)', 'Leading FinTech Company', 'Thought leadership on all Machine Learning problems', 'One of the fastest-growing and most innovative FinTech organizations is actively looking to add a Sr. ML Engineer to help build their core product. As part of a newly developed Data Science & ML Engineering team, you will work on designing and building ML algorithims as well having a heavy modeling scope. The ideal candidate will be a self-starter with superior communication skills (verbal and written).\u202fA solid understanding of data science, advanced statistics, machine learning, data mining and visualization techniques are a must. In addition to the following qualifications, the desire and ability to learn quickly is vital.', 'SF Bay Area', 'Mentor junior engineers', 'Salary: $200k - $250k + Bonus & Equity', 'Top levels skills in Python (Scipy, Pandas etc…)', 'Thinking outside the box to make a better customer experience']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
UX Researcher,Klarna,"Columbus, OH",7 hours ago,91 applicants,"['', 'Job Summary', 'About Klarna', 'The role', 'Some of the ways you may support the team include:', 'About You']",Not Applicable,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Senior Data Engineer,Fidelity Investments,"Westlake, TX",4 hours ago,Be among the first 25 applicants,"['', 'A mentality of test first development and are experienced in modern test frameworks', 'Experience in Data architecture', 'Performance tuning the database', 'The Skills You Bring', 'The Expertise You Have', 'Strong communication skills and technical expertise to drive and participate in important discussions', 'Experience in Business Intelligence and Analytics tools, Grafana, Tableau', 'Crafting and managing automation jobs necessary for the project and data availability for clients', 'Crafting analytics, metrics and dashboards necessary for giving users informative metrics', 'Owning the database administration and setup including infrastructure, authorization and maintenanceCrafting and data architecture and ETL jobsCrafting and managing automation jobs necessary for the project and data availability for clientsPerformance tuning the databaseCrafting analytics, metrics and dashboards necessary for giving users informative metrics', 'Advanced experience in SQL, PL/SQL', 'Good at gathering requirements and designing solutions for users', 'The Team', 'Proven experience in python/java', 'Bachelor’s degree in computer science or similar courses.Advanced experience in SQL, PL/SQLProven experience in python/javaStrong proven experience with Linux and shell scriptingStrong experience with PostgreSQL/Oracle, database performance tuning and administrationStrong experience with ETLExperience with Business Intelligence and Analytics, MetricsExperience with Cloud Database, AWS databaseExperience in Business Intelligence and Analytics tools, Grafana, TableauExperience in Data architectureExperience in Experience on machine learning, data science is preferredExperience in CI/CD DevOps Environment Experience, Jenkins, Git/Stash, uDeployExperience in Docker', 'Experience in Experience on machine learning, data science is preferred', 'Strong experience with PostgreSQL/Oracle, database performance tuning and administration', 'Experience in Docker', 'Strong proven experience with Linux and shell scripting', 'Good at gathering requirements and designing solutions for usersStrong communication skills and technical expertise to drive and participate in important discussionsSelf-starter, who actively challenges status-quo, is curious and not afraid to ask “Why”A mentality of test first development and are experienced in modern test frameworks', 'Owning the database administration and setup including infrastructure, authorization and maintenance', 'Experience in CI/CD DevOps Environment Experience, Jenkins, Git/Stash, uDeploy', 'Strong experience with ETL', 'Experience with Cloud Database, AWS database', 'Certifications', 'Bachelor’s degree in computer science or similar courses.', 'Job Description', 'The Value You Deliver', 'Crafting and data architecture and ETL jobs', 'Experience with Business Intelligence and Analytics, Metrics', 'Self-starter, who actively challenges status-quo, is curious and not afraid to ask “Why”']",Mid-Senior level,Full-time,Quality Assurance,Financial Services,2020-11-05 11:32:32
Remote User Experience Researcher,Creative Circle,"St Louis, MO",23 hours ago,41 applicants,"['', '- Determines and recommends the most efficient and effective research approaches to solve for business needs and meet agreed-upon objectives', '- Expert in critical thinking, strategic thinking, process improvement, relationship-building and problem-solving abilities.', '- Identifies, influences, supports and partners with multi-disciplinary teams to execute research projects.', '- Expert in both qualitative and quantitative user experience research methodologies.', 'Our finance client has a HOT need for a User Experience Researcher with 5+ years of experience UX / Design research experience for a 12+ month, 40 hour/week, offsite contract role starting in Mid-October.\xa0', 'User Experience Researcher Responsibilities:\xa0', 'User Experience Researcher Requirements:\xa0', ""- Bachelor's degree in Human Factors, Human-Computer Interaction, Psychology or relevant field."", '- Develops, designs and executes user research using qualitative and quantitative methods.', '- Proactively develops self in the field of current and emerging research and technology.', '- Communicates insights and influences business partners to take action by providing thought leadership on how insights impact desired business/project outcomes.', '- Able to expertly research, analyze and consolidate data into trends and share with teams.', 'The User Experience Researcher must have experience using design thinking to discover and deliver human-centered solutions. In this role, the UX Researcher will lead and executes strategic design and execution of user-centered research that provides actionable insights which influence design and development of multiple departments in the firm.\xa0']",Mid-Senior level,Contract,Research,Financial Services,2020-11-05 11:32:32
Field Application Specialist,Intabio,San Francisco Bay Area,13 hours ago,Be among the first 25 applicants,"['', 'Train customers on assay development and data analysis on Intabio’s Blaze instrumentAccompany Sales Representatives on sales calls in customer laboratories to provide technical and applications assistanceWork closely with Marketing and Sales personnel during customer interactions and play a key role in Intabio’s pre-sales process\xa0Support global sales team by analyzing customer samples on the Blaze system integrated to a mass spectrometerHelp to maintain and increase product usage and support sales efforts through technical presentations and product demonstrationsBecome a technical expert on the Blaze as well as necessary mass spectrometer technologyProvide on-going assay development support and troubleshooting for customers in-person, via phone and emailDevelop and maintain positive relationships with customers in assigned territoryAssist in creation and review of technical literatureCreate and maintain customer support information in database (SalesForce)', 'Ability to travel domestically, as needed', 'Ability to work collaboratively and foster professional, constructive relationships as part of a team while also working independently to produce/ analyze data and meet challenging timelines and goals', 'Excellent communication skills for oral presentations, customer discussions and written technical reports required', '5+ years of industry experience required in biopharma analytical work or field application work on analytical systems', 'Train customers on assay development and data analysis on Intabio’s Blaze instrument', 'PhD degree or equivalent experience in Analytical Chemistry, Chemical Engineering, Biochemistry or related field experience required5+ years of industry experience required in biopharma analytical work or field application work on analytical systemsHighly proficient in mass spectrometry operation (multiple brands) and data analysis, especially electrospray, for intact proteins; experience with CE, cIEF and biologic samples would be a plusExcellent analytical and problem-solving skillsExcellent communication skills for oral presentations, customer discussions and written technical reports requiredAbility to work collaboratively and foster professional, constructive relationships as part of a team while also working independently to produce/ analyze data and meet challenging timelines and goalsAbility to travel domestically, as needed', 'Highly proficient in mass spectrometry operation (multiple brands) and data analysis, especially electrospray, for intact proteins; experience with CE, cIEF and biologic samples would be a plus', 'Key Responsibilities include (but not limited to):', 'Qualifications:', 'Help to maintain and increase product usage and support sales efforts through technical presentations and product demonstrations', 'Become a technical expert on the Blaze as well as necessary mass spectrometer technology', 'Excellent analytical and problem-solving skills', 'Assist in creation and review of technical literature', 'PhD degree or equivalent experience in Analytical Chemistry, Chemical Engineering, Biochemistry or related field experience required', 'Create and maintain customer support information in database (SalesForce)', 'Accompany Sales Representatives on sales calls in customer laboratories to provide technical and applications assistance', 'Support global sales team by analyzing customer samples on the Blaze system integrated to a mass spectrometer', 'Provide on-going assay development support and troubleshooting for customers in-person, via phone and email', 'Intabio has an opening for a Field Applications Scientist with a home base in the San Francisco Bay Area. This individual will bring their industry experience to interactions with pharmaceutical and biotechnology customers while presenting data-driven presentations on the Blaze technology when integrated with a mass spectrometer.\xa0\xa0The ideal candidate is both an experienced bench scientist/ applications scientist with a background in drug-discovery sciences and intact mass spectrometry.\xa0\xa0The candidate will be a key member of the Field Applications team and will be responsible for providing both pre- and post-sales applications and technical support to customers.\xa0\xa0The candidate will also work closely with the Sales Team to technically close sales by giving detailed data presentations and by performing on-site and in-house product demonstrations.\xa0\xa0\xa0This position reports to the Director of Sales.', 'Develop and maintain positive relationships with customers in assigned territory', 'Work closely with Marketing and Sales personnel during customer interactions and play a key role in Intabio’s pre-sales process\xa0']",Mid-Senior level,Full-time,Sales,Biotechnology,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Buffalo, NY",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,hear.com,"Miami, FL",8 hours ago,Be among the first 25 applicants,"['', 'Expertise in data engineering, data modelling and virtualisation', 'Develop new solutions and automate work flows', 'Option to work remotely', 'Key contributor to the design, build and migration re: our new Snowflake DWH', 'Ownership of engineering and data modelling process', ' Change lives… see the real world impact of what you do (this is the best part) !! A chance to shape the future of a leading HealthTech A unique content-driven, top-performing and family-type work culture $4k annual educational budget… learn new skills in areas that excite you A high degree of autonomy and responsibility from day one An open-minded and international working environment that fosters creativity Excellent salary and benefits package with entrepreneurial incentives Option to work remotely ', 'You Bring', ' Design and implement complex data models for our Customer Data Platform Design, build and automate new work flows via introduction of ML + cloud based products Key contributor to the design, build and migration re: our new Snowflake DWH Ownership of engineering and data modelling process Drive best practice across the data engineering function Develop new solutions and automate work flows Ownership of the engineering and data modelling process and structure for reporting Implement cadence between reporting and engineering Take ownership of technical solutions and processes on the reporting team ', 'Familiarity with database technologies (PostgreSQL, Snowflake, MySQL) and AWS', 'Why Hear.com', 'Excellent salary and benefits package with entrepreneurial incentives', 'Experience in BI tools (e.g. Domo, Tableau, Power BI)', 'A unique content-driven, top-performing and family-type work culture', 'Miami, FL', 'BSc in Computer Science (or similar) OR equivalent work experience', 'A chance to shape the future of a leading HealthTech', ' Proficiency in at least one programming language (python, java, c#) Expertise in data engineering, data modelling and virtualisation Familiarity with database technologies (PostgreSQL, Snowflake, MySQL) and AWS Experience in BI tools (e.g. Domo, Tableau, Power BI) Experience in at least one workflow management platform (Airflow etc) Excellent communication and problem solving skills Experience in distributed computing is a plus (Hadoop, Spark, Kafka, Pulsar, AWS Kinesis) BSc in Computer Science (or similar) OR equivalent work experience ', 'Excellent communication and problem solving skills', 'Design, build and automate new work flows via introduction of ML + cloud based products', 'A high degree of autonomy and responsibility from day one', 'Take ownership of technical solutions and processes on the reporting team', 'Implement cadence between reporting and engineering', 'Change lives… see the real world impact of what you do (this is the best part) !!', 'The Role', 'Design and implement complex data models for our Customer Data Platform', '$4k annual educational budget… learn new skills in areas that excite you', 'Experience in distributed computing is a plus (Hadoop, Spark, Kafka, Pulsar, AWS Kinesis)', 'Proficiency in at least one programming language (python, java, c#)', 'apply now', 'Drive best practice across the data engineering function', 'Ownership of the engineering and data modelling process and structure for reporting', 'An open-minded and international working environment that fosters creativity', 'Experience in at least one workflow management platform (Airflow etc)', 'hear.com']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Assistant Research Scientist Lockless Lab,Texas A&M University,"College Station, TX",10 hours ago,Be among the first 25 applicants,"['Genetics', 'Doctoral degree Full Job Description Job Title Assistant Research Scientist', 'High-performance liquid chromatography', 'Recruiting', ""Lockless Lab Agency Texas A & M University Department Biology Proposed Minimum Salary Commensurate Job Location College Station, Texas Job Type Staff Job Description Our Commitment Texas A & M University is committed to enriching the learning and working environment for all visitors, students, faculty, and staff by promoting a culture that embraces inclusion, diversity, equity, and accountability. Diverse perspectives, talents, and identities are vital to accomplishing our mission and living our core values . Who we are The Department of Biology at Texas A & M University is responsible for research and teaching within the vast disciplines of the biological sciences, from molecular cell biology to ecology and evolutionary biology. Our faculty perform cutting-edge research in a wide array of biological sciences in the laboratory and in the field. Our graduate research programs prepare scientists for careers in academia, industry and government and enhance our understanding of the central role of biological systems in the global environment. Our undergraduate students gain a firm foundation in modern biological sciences to prepare them for a multitude of careers that depend on a solid understanding of biology. To learn more, please visit us at What we want The selected candidate will subscribe to and support our commitment to Inclusion, Diversity, Equity and Accountability (IDEA) as stated above. If the description sounds interesting to you, we invite you to to be considered for this opportunity. What you need to know COVID-19 information : Texas A & M University monitors and updates our recruiting, hiring and onboarding processes to align with local, state and federally mandated health guidelines to keep employees, prospective employees, and visitors as safe as possible. Each department has established both remote and in-person procedures for conducting these processes, which include sanitizing common spaces, a mask policy, and maintaining safe physical distancing to the extent possible. Departments will provide the procedures to be followed at each step of the recruiting process. Required Education and Experience: Appropriate PhD Relevant professional experience Required Knowledge, Skills and Abilities: Ability to multi-task and work cooperatively with others Preferred Education and Experience: PhD in microbiology Strong background in bacterial genetics and physiology, including mutant isolation and bacterial culturing Experience in DNA/RNA extractions, qPCR and bacterial genetics Preferred Knowledge, Skills, and Abilities: Experience in Soxhlet extraction Experience in HPLC and TLC Responsibilities: Designing and executing research experiments and analyzing results Writing of manuscripts, presenting findings, and contributing to grant proposals General laboratory duties such as equipment maintenance, making common reagents, and maintaining a safe working environment Performs other duties as assigned Instructions to Applicants : Applications received by Texas A & M University and TAMHSC, must either have all job application data entered or a resume attached. Failure to provide all job application data or a complete resume could result in an invalid submission and a rejected application. We encourage all applicants to upload a resume or use a LinkedIn profile to pre-populate the online application. All positions are security-sensitive. Applicants are subject to a criminal history investigation, and employment is contingent upon the institution's verification of credentials and/or other information required by the institution's procedures, including the completion of the criminal history check. Equal Opportunity/Affirmative Action/Veterans/Disability Employer committed to diversity. Show full job description Apply Now""]",Entry level,Part-time,Other,Nonprofit Organization Management,2020-11-05 11:32:32
"Data Engineer, EDM III",Rose International,"San Francisco, CA",15 hours ago,Be among the first 25 applicants,"['', ' Experienced data solution architecting.', ' Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', ' Drive the re-architecting of Client data sources feeding our automation workflows (re-align source file acquisitions within AWS).', 'Minimum Qualifications', ' Expertise in gathering data through multiple sources through API calls and scripting languages.', ' Maintain/ develop a scalable database/ data warehouse through connecting. disparate data tables housed across numerous organizational systems and different business lines.', 'Responsibilities', ' Code review all current SSIS jobs for effectiveness.', ' 70-Technical/30-Functional.', "" Bachelor's degree computer science, information systems, or a related discipline."", 'Description', "" Bachelor's degree computer science, information systems, or a related discipline. 5+ years of experience. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function. Expertise in gathering data through multiple sources through API calls and scripting languages. Preference given to those with advanced data modeling experience. Self-starter and a driver, ability to communicate/own a project to completion while working with various teams (not directly managing the teams). Candidate will be coordinating work with other teams. Hands-on/Player-Coach style candidate. Excellent written and verbal communication skills. 70-Technical/30-Functional."", ' Candidate will be coordinating work with other teams.', ' Self-starter and a driver, ability to communicate/own a project to completion while working with various teams (not directly managing the teams).', ' 5+ years of experience.', ' Optimize and maintain scripts on present data warehouses and present ETL.', ' Preference given to those with advanced data modeling experience.', 'Position Description', ' Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function.', ' Hands-on/Player-Coach style candidate.', ' Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL (primarily MS SQL) and AWS technologies.', ' Create and update data models for decision support of digital help programs and initiatives.', ' Maintain/ develop a scalable database/ data warehouse through connecting. disparate data tables housed across numerous organizational systems and different business lines. Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL (primarily MS SQL) and AWS technologies. Optimize and maintain scripts on present data warehouses and present ETL. Create and update data models for decision support of digital help programs and initiatives. Drive SQL server conversion onto AWS platform. Code review all current SSIS jobs for effectiveness. Drive the re-architecting of Client data sources feeding our automation workflows (re-align source file acquisitions within AWS). Experienced data solution architecting.', ' Excellent written and verbal communication skills.', 'Nice To Have But No Required', ' Drive SQL server conversion onto AWS platform.']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Idexcel,"Richmond, VA",2 hours ago,133 applicants,"['2) Ability to design events in a domain driven design', 'Required Skills', '1) Data modeling and Architecture -15+ years senior', '3) AWS Environment & Spark.']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Flynn Restaurant Group,"Independence, OH",3 hours ago,110 applicants,"['', 'Create visualizations and reports for requested projects', 'Since then the company has grown at over 30% a year, added three additional leading brands in Taco Bell, Panera, and Arby’s, and has become the largest restaurant franchise and one of top 20 largest foodservice companies in the United States.', 'Document and streamline current and future processes', 'Build and support analytical assets for business consumption', 'FUN CULTURE!', 'Company Outings', 'Managing user access and permissions for data access', 'Experience with Azure SQL DB, Azure Data Factory, Azure Data Lake and Azure Blob storage ', 'Whatever it Takes', 'The Flynn Restaurant Group is an Equal Opportunity Employer', ""Bachelor's degree in Computer Science, Computer Engineering, Business Administration, Mathematics or a related field5+ years of industry experience with the full stack of the Microsoft Data Platform (e.g., on-premise SQL Server, Azure SQL DB, )Experience designing and implementing enterprise data & analytics architectures requiredExperience managing delivery of multiple simultaneous complex technology solutionsExperience in modern cloud data architecturesExtensive experience with MS SQL Server and SSIS Strong experience and proficiency with best practices for deploying data integration architectures used for data management (ETL)Trusted to work independently with stakeholders at all levelsExperience with Azure SQL DB, Azure Data Factory, Azure Data Lake and Azure Blob storage Ability to execute projects and tasks with minimal guidance and supervisionExcellent oral and written communication skillsExcellent data gathering, analytical, and problem-solving skillsExperience with both On-Prem Microsoft SQL Server and Azure SQL and Data Services platformsExperience with Power BI, DAX and data modelling best practicesFull stack development experience a plus"", 'Experience managing delivery of multiple simultaneous complex technology solutions', 'Own it', 'Collaborate with teams to integrate systems', 'Develop and update technical documentation', 'Experience with Power BI, DAX and data modelling best practices', 'Specifically, the Data Engineer will:', ""Today, through its four wholly-owned subsidiaries, Apple American Group, Bell American, Pan American, and RB American Group, FRG owns and operates over 460 Applebee's, 280 Taco Bells, 130 Panera cafes, and 360 Arby’s representing $2.3 Billion in Sales and directly employing almost 50,000 people in 35 states."", 'Excellent data gathering, analytical, and problem-solving skills', 'Develop, manage, and test back-up and recovery plans', 'On-Site Cafe', 'Preferred Qualifications', 'Develop and execute database queries and conduct analyses', 'San Francisco Commuter Benefits', 'Data Engineer', 'Experience with both On-Prem Microsoft SQL Server and Azure SQL and Data Services platforms', 'Basic Life Insurance', 'Our mission at the Support Center is clear – we provide ever improving support and systems that enable our operators to be more effective and focus on running premier restaurants.', 'Identify opportunities for improved utilization of existing business applications and processes', 'Contribute to training and roll out of solutions', 'Trusted to work independently with stakeholders at all levels', 'Desired Skills and Experience', 'Excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions', 'Track record of manipulating, processing, and extracting value from large datasets', 'Going forward the company plans to continue its aggressive growth by building and acquiring additional restaurants as well as opportunistically expanding into other brands and businesses.', 'Flynn Restaurant Group (FRG) was started in 1999 as the owner and operator of eight Applebee’s in Washington State.', ""Bachelor's degree in Computer Science, Computer Engineering, Business Administration, Mathematics or a related field"", 'We value our 150+ employees and are committed to setting clear expectations, rewarding and appreciating their contributions and helping our employees reach their full potential.', 'We look for people to join our team who think beyond themselves and consider the overall business, that want to “Own it” and have the “Whatever it Takes” attitude!', 'Dining Discounts', 'Full stack development experience a plus', 'Retirement and Savings Plan', 'Strong experience and proficiency with best practices for deploying data integration architectures used for data management (ETL)', 'Basic Qualifications', 'Human Resources Field Recruiter', 'Strong ability to interact, communicate, present and influence within multiple levels of the organization', 'Experience designing and implementing enterprise data & analytics architectures required', 'Architect and Manage our data lake and govern our data pipelines', 'Paid Time Off', 'Essential Responsibilities', 'Position Description', 'Ensure that storage and archiving procedures are functioning correctly', 'Short and Long Term Disability', 'Medical/ Dental /VisionRetirement and Savings PlanShort and Long Term DisabilityBasic Life InsuranceVoluntary Life InsuranceTuition ReimbursementPaid Time OffFlexible Work SchedulesSan Francisco Commuter BenefitsCompany OutingsDining DiscountsOn-Site Workout FacilityOn-Site DaycareOn-Site CafeFUN CULTURE!', 'This person in this position will be responsible for designing, developing, implementing, testing, documenting, and maintaining the data platform for our internal customers using best practices in data modeling and ETL/ELT processes.', 'Experience leading large-scale data warehousing and analytics projects using Microsoft technologies – Azure AS, Azure DW, Azure Data Factory and other big data technologies', 'Voluntary Life Insurance', 'Coordinate with business, technology and support teams to ensure system solutions meet business requirements', 'On-Site Workout Facility', 'Company Background', 'On-Site Daycare', 'Flynn Restaurant Group offers a variety of benefits and perks to encourage and empower our employees. We are committed to helping each employee work and live to his or her fullest potential. We offer a variety of benefits and perks while working for us:', '5+ years of industry experience with the full stack of the Microsoft Data Platform (e.g., on-premise SQL Server, Azure SQL DB, )', 'Coordinate with business, technology and support teams to ensure system solutions meet business requirementsDocument and streamline current and future processesIdentify opportunities for improved utilization of existing business applications and processesDesign, build and deploy BI solutionsBuild and support analytical assets for business consumptionMaintain and support data analytics platforms (Power BI)Collaborate with teams to integrate systemsContribute to training and roll out of solutionsDevelop and execute database queries and conduct analysesCreate visualizations and reports for requested projectsDevelop and update technical documentationArchitect and Manage our data lake and govern our data pipelinesCollaborate with internal and external stakeholders on database and Datawarehouse conceptual and logical designImplement and maintain database physical designDevelop, manage, and test back-up and recovery plansEnsure that storage and archiving procedures are functioning correctlyCommunicate regularly with technical, applications and operational staff to ensure database integrity and securityManaging user access and permissions for data access', '\xa0Essential Responsibilities', 'Design, build and deploy BI solutions', 'Extensive experience with MS SQL Server and SSIS ', '\xa0', 'Experience in modern cloud data architectures', 'Flynn Restaurant Group Support Center', 'Why Work for Flynn?', 'Tuition Reimbursement', 'Experience leading large-scale data warehousing and analytics projects using Microsoft technologies – Azure AS, Azure DW, Azure Data Factory and other big data technologiesStrong ability to interact, communicate, present and influence within multiple levels of the organizationTrack record of manipulating, processing, and extracting value from large datasetsExcellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions', 'Medical/ Dental /Vision', 'Excellent oral and written communication skills', 'Flexible Work Schedules', 'For a copy of Flynn Restaurant Group’s Workplace Privacy Notice, please visit http://www.flynnrestaurantgroup.com/workplace-privacy-notice/', 'Implement and maintain database physical design', 'Collaborate with internal and external stakeholders on database and Datawarehouse conceptual and logical design', 'Maintain and support data analytics platforms (Power BI)', 'Communicate regularly with technical, applications and operational staff to ensure database integrity and security', 'Ability to execute projects and tasks with minimal guidance and supervision']",Associate,Full-time,Information Technology,Restaurants,2020-11-05 11:32:32
"Senior Data Engineer, Finance Products",Squarespace,"New York, NY",6 hours ago,Be among the first 25 applicants,"['', 'Write, test and review microbatch or streaming ETL pipelines powered by Kafka', 'Commuter benefit in the form of reduced tax (Ireland) and pretax (US)', 'Build and maintain data processing services built with Airflow', 'Be a technical leader, mentor, and encourage the technical growth of your teammates', ' Perks', 'Continuously improve our system, tests, and Data Quality Indicators', 'Work with the team to guide technical and architectural changes.', '5+ years of data engineering experience', 'Up to 20 weeks of paid family leave', 'Experience in data modeling, storage, security, and retrieval', 'Fertility and adoption benefits', 'Education reimbursement', 'Benefits ', 'Responsibilities', 'Experience writing, testing, and reviewing microbatch or streaming ETL pipelines and SQL queries', 'strive for', 'customer base', 'Experience working with dynamic programming languages, relational databases, and distributed systems. We currently work in Python, Java, Postgres, Kubernetes, Spark, Presto, Kafka, and MongoDB', '&', ', but we also ', 'Today, more than a million people around the globe use Squarespace to share different perspectives and experiences with the world. Not only do we embrace and celebrate the diversity of our ', 'Write, test and review complex SQL queries and stored procedures for Postgres', 'Retirement benefits with employer match', 'Equity plan for all employees', 'Dog-friendly workplace in New York office', 'Stay knowledgeable about the ever changing technology landscape.', ' Health insurance with 100% premium covered for you and your dependent children Flexible vacation & paid time off Up to 20 weeks of paid family leave Equity plan for all employees Retirement benefits with employer match Fertility and adoption benefits Free lunch and snacks at all offices Education reimbursement Dog-friendly workplace in New York office Commuter benefit in the form of reduced tax (Ireland) and pretax (US) ', 'Qualifications', ' Experience writing, testing, and reviewing microbatch or streaming ETL pipelines and SQL queries Experience in Python, Airflow, and SQL Experience writing, testing, and reviewing microbatch or streaming ETL pipelines and SQL queries Experience in data modeling, storage, security, and retrieval Experience working with dynamic programming languages, relational databases, and distributed systems. We currently work in Python, Java, Postgres, Kubernetes, Spark, Presto, Kafka, and MongoDB 5+ years of data engineering experience ', 'Experience in Python, Airflow, and SQL', 'Free lunch and snacks at all offices', 'Health insurance with 100% premium covered for you and your dependent children', ' Build and maintain data processing services built with Airflow Write, test and review microbatch or streaming ETL pipelines powered by Kafka Write, test and review complex SQL queries and stored procedures for Postgres Continuously improve our system, tests, and Data Quality Indicators Stay knowledgeable about the ever changing technology landscape. Work with the team to guide technical and architectural changes. Be a technical leader, mentor, and encourage the technical growth of your teammates ', 'About Squarespace', 'Flexible vacation & paid time off', ' the same in our employees. At Squarespace, we are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.']",Mid-Senior level,Full-time,Information Technology,Investment Banking,2020-11-05 11:32:32
Staff Data Engineer,"Checkr, Inc.","San Francisco, CA",5 hours ago,48 applicants,"['', 'What You Bring', 'Checkr is committed to hiring talented and qualified individuals with diverse backgrounds for all of its tech, non-tech, and leadership roles. Checkr believes that the gathering and celebration of unique backgrounds, qualities, and cultures enriches the workplace. ', ' A fast-paced and collaborative environment Competitive compensation and opportunity for advancement 100% medical, dental and vision coverage Unlimited PTO policy Fitness reimbursements ', 'What You Get', 'Responsibilities', '.', '100% medical, dental and vision coverage', 'Competitive compensation and opportunity for advancement', 'Architect systems for scale and security to keep up with a huge influx of data as Checkr continues to grow,', ' Build, maintain and optimize critical data pipelines that serve as the foundation for Checkr’s data platform and products, Build tools that help streamline the management and operation of our data ecosystem, Architect systems for scale and security to keep up with a huge influx of data as Checkr continues to grow, Architect systems that empower repeatable and scalable machine learning workflows, Identify innovative applications of data that can enable new products or insights and enable other teams at Checkr to maximize their own impact ', 'Equal Employment Opportunities at Checkr', 'Architect systems that empower repeatable and scalable machine learning workflows,', 'Identify innovative applications of data that can enable new products or insights and enable other teams at Checkr to maximize their own impact', 'San Francisco’s Fair Chance Ordinance', ' 6+ years of industry-related experience in a backend or data engineering role and a Bachelor’s degree or equivalent experience. Experience architecting, developing and maintaining production data services Familiarity with modern CI/CD practices and tools (e.g., gitlab and kubernetes)  Experience and passion for mentoring other data engineers Deep programming expertise in Python and SQL ', 'Fitness reimbursements', 'Unlimited PTO policy', '6+ years of industry-related experience in a backend or data engineering role and a Bachelor’s degree or equivalent experience.', 'Experience architecting, developing and maintaining production data services', 'Experience and passion for mentoring other data engineers', 'Staff Data Engineer', 'Familiarity with modern CI/CD practices and tools (e.g., gitlab and kubernetes) ', 'Build tools that help streamline the management and operation of our data ecosystem,', 'Checkr also welcomes the opportunity to consider qualified applicants with prior arrest or conviction records. Checkr’s commitment to diversity extends to hiring talented individuals in spite of a prior criminal history in accordance with local, state, and/or federal laws, including the ', 'Build, maintain and optimize critical data pipelines that serve as the foundation for Checkr’s data platform and products,', 'Deep programming expertise in Python and SQL', 'A fast-paced and collaborative environment']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Data Engineer, EDM III #: 20-12266","TalentBurst, an Inc 5000 company","San Francisco, CA",11 hours ago,Be among the first 25 applicants,"['', 'Job #: 20-12266', '5&plus; years of experience.', ' Experienced data solution architecting.', 'Expertise in gathering data through multiple sources through API calls and scripting languages.', 'Minimum Qualifications', 'Location: Remote role ', 'Responsibilities', ' Code review all current SSIS jobs for effectiveness.', 'Create and update data models for decision support of digital help programs and initiatives.', ""Bachelor's degree computer science, information systems, or a related discipline."", ' Drive the re-architecting of ADSK data sources feeding our automation workflows (re-align source file acquisitions within AWS).', 'Preference given to those with advanced data modeling experience.', 'Self-starter and a driver, ability to communicate/own a project to completion while working with various teams (not directly managing the teams).', 'Optimize and maintain scripts on present data warehouses and present ETL.', 'Duration: 3 months&plus; Contract (Possibility of more extension)', 'Hands-on/Player-Coach style candidate.', 'Maintain/ develop a scalable database/ data warehouse through connecting. disparate data tables housed across numerous organizational systems and different business lines.Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL (primarily MS SQL) and AWS technologies.Optimize and maintain scripts on present data warehouses and present ETL.Create and update data models for decision support of digital help programs and initiatives. Drive SQL server conversion onto AWS platform. Code review all current SSIS jobs for effectiveness. Drive the re-architecting of ADSK data sources feeding our automation workflows (re-align source file acquisitions within AWS). Experienced data solution architecting.', 'Job Description', 'Excellent written and verbal communication skills.', ""Bachelor's degree computer science, information systems, or a related discipline.5&plus; years of experience.Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function.Expertise in gathering data through multiple sources through API calls and scripting languages.Preference given to those with advanced data modeling experience.Self-starter and a driver, ability to communicate/own a project to completion while working with various teams (not directly managing the teams).Candidate will be coordinating work with other teams.Hands-on/Player-Coach style candidate.Excellent written and verbal communication skills.70-Technical/30-Functional."", 'Candidate will be coordinating work with other teams.', 'Maintain/ develop a scalable database/ data warehouse through connecting. disparate data tables housed across numerous organizational systems and different business lines.', 'Nice To Have But No Required', 'Experience with transforming, developing data structures, metadata, dependency and data workflows to support an Analytics function.', '70-Technical/30-Functional.', 'Remote role: ', 'Maintain/ develop the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL (primarily MS SQL) and AWS technologies.', ' Drive SQL server conversion onto AWS platform.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Job Title: Data Engineer w/MS SQL Server Automation experience']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Amgen,"Tampa, FL",21 hours ago,Be among the first 25 applicants,"['', 'Travel – Approximately 15% of work time', 'Experience with AWS cloud services: EC2, S3, EMR, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API Gateway', 'Contribute to the exploration and understanding of new tools, and techniques and propose improvements to the data pipeline', 'Experience working with Apache Spark, Apache Airflow', 'Hands on development experience with Informatica MDM product', 'Experience working agile development methodologies such as Sprint and Scrum', 'Collaborate with Data Architects, Business SME’s, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regions', 'Preferred Qualifications', 'Biotech / Pharma experience', 'Build data products and service processes which perform data transformation, extraction, loading; work flow management and data quality checks', 'Responsibilities', 'Basic Qualifications', 'Participate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with product teams', 'Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.', 'Data integration with other Amgen enterprise data lake platform/product', 'Experience with software engineering best-practices, including but not limited to version control (Git, Subversion, etc.), CI/CD (Jenkins, Maven etc.), automated unit testing, and Dev Ops', 'Be a key team member assisting in design and development of the data pipeline for Global Data and Analytics team', 'Full stack development using cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc.)', ' Join Us ', 'As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.', 'Implement standardized, automated operation and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAs', '5+ years of experience with one or more general purpose programming languages, including but not limited to: Java, Python, Scala, C, C++, C#, Swift/Objective C, or JavaScript', 'Adhere to best practices for coding, testing and designing reusable code/component', ""If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen."", 'Be a key team member assisting in design and development of the data pipeline for Global Data and Analytics teamCollaborate with Data Architects, Business SME’s, and Data Scientists to design and develop end-to-end data pipeline to meet fast paced business need across geographic regionsBuild data products and service processes which perform data transformation, extraction, loading; work flow management and data quality checksImplement standardized, automated operation and quality control processes to deliver accurate and timely data and reporting to meet or exceed SLAsAdhere to best practices for coding, testing and designing reusable code/componentContribute to the exploration and understanding of new tools, and techniques and propose improvements to the data pipelineData integration with other Amgen enterprise data lake platform/productParticipate in sprint planning meetings and provide estimations on technical implementation; Collaborate and communicate effectively with product teamsTravel – Approximately 15% of work time', '5+ years of experience with data modeling for both OLAP and OLTP databases, performance tuning for relational database, NoSQL datastore, and columnar database', '5+ years of hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL', 'Career CategoryInformation SystemsJob Description', '5+ years of hands-on experience with SQL, preferred Oracle, PostgreSQL, and Hive SQL5+ years of experience with data modeling for both OLAP and OLTP databases, performance tuning for relational database, NoSQL datastore, and columnar databaseExperience working with Apache Spark, Apache Airflow5+ years of experience with one or more general purpose programming languages, including but not limited to: Java, Python, Scala, C, C++, C#, Swift/Objective C, or JavaScriptExperience with software engineering best-practices, including but not limited to version control (Git, Subversion, etc.), CI/CD (Jenkins, Maven etc.), automated unit testing, and Dev OpsExperience with AWS cloud services: EC2, S3, EMR, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API GatewayFull stack development using cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc.)Hands on development experience with Informatica MDM productExperience working agile development methodologies such as Sprint and ScrumBiotech / Pharma experience']",Associate,Full-time,Information Technology,Biotechnology,2020-11-05 11:32:32
Associate Scientist 1 (790),Amyris,"Emeryville, CA",6 hours ago,54 applicants,"['', 'Analyze and visualize raw data in Excel, Spotfire and JMP', 'visit our website < http://www.amyris.com >', 'Responsibilities', 'Ability to work well in a fast-paced environment, and balance multiple projects', 'Embrace Amyris’ Core Values', '3 months of prior process development experience is required. Prior experience with experimental planning and basic statistical analysis of data is expected. Internship or co-op experience is acceptable, if these skills were clearly demonstrated during that time. ', 'Execute existing separations and purification processes, including filtration, extraction, distillation, chromatography crystallization, chromatography and reactive separations, at bench scale.Document observable data and proceduresPrepare samples for chromatographic analyses, run GC and LC samples, and process the analytical dataPerform non-chromatographic analyses on product and in-process streams, including optimal measurements, LOD, TSS, viscosity and microscopy Work with scientists and engineers in the evaluation and implementation of new laboratory equipment, including separations units, analytical equipment, and automation tools Present experimental plans for Scientist review, prior to execution.Analyze and visualize raw data in Excel, Spotfire and JMPPresent work in written updates and in slides, to be shared with the rest of the Process Development team Be responsible for individual and co-worker safety Embrace Amyris’ Core Values', 'Prepare samples for chromatographic analyses, run GC and LC samples, and process the analytical data', 'Amyris, a leader in industrial synthetic biology, uses its innovative bioscience solutions to achieve renewable products by converting plant sugars into hydrocarbon molecules. Amyris’ molecules are used in wide range of specialty & performance chemicals, flavors & fragrances and in applications ranging from cosmetics to biofuels. Learn more at www.amyris.com .', 'Perform non-chromatographic analyses on product and in-process streams, including optimal measurements, LOD, TSS, viscosity and microscopy ', 'For a full list of our current openings, please visit our website < http://www.amyris.com >.', 'As a VEVRAA Federal Contractor, Amyris is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Amyris complies with applicable state and local laws governing nondiscrimination in employment.', 'Execute existing separations and purification processes, including filtration, extraction, distillation, chromatography crystallization, chromatography and reactive separations, at bench scale.', 'Present work in written updates and in slides, to be shared with the rest of the Process Development team ', 'Some fermentation experience is a plus ', 'Present experimental plans for Scientist review, prior to execution.', 'Be responsible for individual and co-worker safety ', 'Attention to detail, a can-do attitude, and sensitivity to timelines', 'Job Description', 'California Consumer Privacy Act of 2018 (“CCPA”)', 'BS in chemical engineering, chemistry, food science or equivalent3 months of prior process development experience is required. Prior experience with experimental planning and basic statistical analysis of data is expected. Internship or co-op experience is acceptable, if these skills were clearly demonstrated during that time. Experience with any of the following is strongly preferred: centrifugation, filtration, cell disruption, extraction, chromatography, crystallization and distillationSome fermentation experience is a plus Excellent interpersonal and communications skills Attention to detail, a can-do attitude, and sensitivity to timelinesAbility to work well in a fast-paced environment, and balance multiple projectsAmyris, a leader in industrial synthetic biology, uses its innovative bioscience solutions to achieve renewable products by converting plant sugars into hydrocarbon molecules. Amyris’ molecules are used in wide range of specialty & performance chemicals, flavors & fragrances and in applications ranging from cosmetics to biofuels. Learn more at www.amyris.com .As a VEVRAA Federal Contractor, Amyris is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Amyris complies with applicable state and local laws governing nondiscrimination in employment.For a full list of our current openings, please visit our website < http://www.amyris.com >.', 'Skills', 'Document observable data and procedures', 'Experience with any of the following is strongly preferred: centrifugation, filtration, cell disruption, extraction, chromatography, crystallization and distillation', 'The Downstream Process Development team is seeking an energetic, self-motivated individual to contribute to the bench-scale development of various separations processes, designed to recover biomass and products from fermentation broth. This position requires previous experience with laboratory and/or pilot plant equipment, preferably in an industrial biotech setting. The successful candidate will be responsible for running existing processes, modifying equipment and processes under supervision, analyzing product using a variety of analytical methods, and working with scientists and engineers to develop novel separations techniques. We are looking for a strong team player with a growth mindset, who prioritizes safety, and values the opportunity to work on multiple product lines in a fast-paced environment.', 'BS in chemical engineering, chemistry, food science or equivalent', 'Work with scientists and engineers in the evaluation and implementation of new laboratory equipment, including separations units, analytical equipment, and automation tools ', 'Excellent interpersonal and communications skills ']",Associate,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Senior Security Researcher,Palo Alto Networks,"Santa Clara, CA",7 hours ago,Be among the first 25 applicants,"['', 'Your Experience', 'Able to understand and uncover vulnerabilities', 'Excellent English reading comprehension and writing skills', 'Present your research at well-known cybersecurity conferences', 'Innovate new features and protection mechanisms to enrich Prisma Cloud Compute', 'Our Mission', 'Familiar with Go language and security of Go code preferred', 'Understand various types of vulnerabilities e.g. memory issues, logical issues, web', 'Familiar with cloud service providers and security of cloud service providers such as Google Cloud Platform, Amazon Web Services, Azure preferred', 'The Team', 'Prefer Bachelors or Masters in Computer Science or related degree', 'Highly motivated about cloud and container securityAble to understand and uncover vulnerabilitiesUnderstand various types of vulnerabilities e.g. memory issues, logical issues, webExperienced in reverse engineering and malware analysisFamiliar with Go language and security of Go code preferredFamiliar with cloud service providers and security of cloud service providers such as Google Cloud Platform, Amazon Web Services, Azure preferredAble to explain complex problems in a way that is easy to understand, great communication skillsStrong attention to detailExcellent English reading comprehension and writing skillsPrefer Bachelors or Masters in Computer Science or related degree', 'Qualifications', 'Determine Prisma Cloud Compute detection coverage and protection from vulnerabilities and malwaresInnovate new features and protection mechanisms to enrich Prisma Cloud ComputeHunt and analyze malware attacking cloud and container workloadsAnalyze a broad range of one-day vulnerabilities in cloud and container servicesSupport our product and development teams with practical knowledge on mitigating exploitation and post-exploitation malicious activitySupport our efforts to secure Prisma Cloud Compute and actively engage in evaluating our product securityPublish research blogs on Unit 42Present your research at well-known cybersecurity conferences', 'Analyze a broad range of one-day vulnerabilities in cloud and container services', 'Highly motivated about cloud and container security', 'Publish research blogs on Unit 42', 'Company Description', 'Job Description', 'Strong attention to detail', 'Support our efforts to secure Prisma Cloud Compute and actively engage in evaluating our product security', 'Support our product and development teams with practical knowledge on mitigating exploitation and post-exploitation malicious activity', 'Your Impact', 'Determine Prisma Cloud Compute detection coverage and protection from vulnerabilities and malwares', 'Experienced in reverse engineering and malware analysis', 'Able to explain complex problems in a way that is easy to understand, great communication skills', 'Hunt and analyze malware attacking cloud and container workloads', 'Our Commitment']",Not Applicable,Full-time,Information Technology,Computer & Network Security,2020-11-05 11:32:32
Research Professional 2,Ampcus Inc,"Norwood, MA",1 hour ago,Be among the first 25 applicants,"['', 'Description', 'Highly Desired Skills', 'Responsibilities', 'Position Requirements']",Entry level,Full-time,Research,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Business Data Analyst 2,LSC Communications,"Nashville, TN",6 hours ago,39 applicants,"['', ' First shift position.  ', 'Responsible for department reporting needs.', ' Collect and interpret data from multiple data sources. Gather internal and external data and documentation. Identify patterns and trends across data sets. Responsible for data comparison and visualization. Generate fact based data reports from single or multiple systems. Responsible for department reporting needs. Proactively analyze data to answer key questions from stakeholders. Proactively identify what drives business performance, efficiency and productivity. Investigate and communicate areas for improvement. In-depth quantitative and qualitative analysis to support development and execution of new category, sourcing, and supplier relationship management. Analyze market, economic trends and supplier performance. Create and maintain rich interactive visualizations through data interpretation and analysis by integrating various reporting components from multiple data sources. Define and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution. Work alongside teams within the business and/or management team to establish business needs. Report results back to the relevant members of the business. Process confidential data and information according to guidelines. This visible leadership position must be capable of working with all levels within the company, supply base and end customer businesses. Performs other related duties and participates in special projects as assigned. ', 'Generate fact based data reports from single or multiple systems.', 'Create and maintain rich interactive visualizations through data interpretation and analysis by integrating various reporting components from multiple data sources.', ' Bachelor degree in Mathematics, Computer Science, Economics, Statistics, Data Scientist, Engineering, Supply Chain Management or discipline related to functional work or role OR demonstrated ability to meet the job requirements through a comparable number of years of applicable work experience.  Minimum 5 years of data management and reporting experience, preferred. Willing and able to travel 20% of the time (mostly local but could involve domestic and overnight). Technical knowledge of data analysis, data evaluation, data visualization, possible data mining along with the creation of building queries, reports and/or presentations. Experience with cost modeling, cost drivers and/or cost structures. Able to demonstrate problem-solving skills and appropriately apply proven solutions. Consistently deliver prescribed outcomes in a timely and accurate manner with appropriate guidance. Apply existing processes and procedures to solve problems and may receive guidance for problems that are non-routine. Advanced functional computer knowledge in utilizing Microsoft Windows, MAC or other technical tools to complete work assignments. May require knowledge of, or ability to quickly learn specialized software related to the position. Experience working in an ERP environment (SAP preferred) and/or with sourcing RFP tools, preferred. Requires professional communication skills, both verbal and written. Able to communicate effectively with diverse groups of people when completing work assignments.', 'This visible leadership position must be capable of working with all levels within the company, supply base and end customer businesses.', 'Gather internal and external data and documentation.', 'Analyze market, economic trends and supplier performance.', 'Bachelor degree in Mathematics, Computer Science, Economics, Statistics, Data Scientist, Engineering, Supply Chain Management or discipline related to functional work or role OR demonstrated ability to meet the job requirements through a comparable number of years of applicable work experience. ', 'Responsible for data comparison and visualization.', 'Process confidential data and information according to guidelines.', 'Requires professional communication skills, both verbal and written. Able to communicate effectively with diverse groups of people when completing work assignments.', 'First shift position. ', 'Qualifications', 'Performs other related duties and participates in special projects as assigned.', 'In-depth quantitative and qualitative analysis to support development and execution of new category, sourcing, and supplier relationship management.', 'Technical knowledge of data analysis, data evaluation, data visualization, possible data mining along with the creation of building queries, reports and/or presentations. Experience with cost modeling, cost drivers and/or cost structures.', 'Advanced functional computer knowledge in utilizing Microsoft Windows, MAC or other technical tools to complete work assignments. May require knowledge of, or ability to quickly learn specialized software related to the position. Experience working in an ERP environment (SAP preferred) and/or with sourcing RFP tools, preferred.', 'Minimum 5 years of data management and reporting experience, preferred. Willing and able to travel 20% of the time (mostly local but could involve domestic and overnight).', 'Able to demonstrate problem-solving skills and appropriately apply proven solutions. Consistently deliver prescribed outcomes in a timely and accurate manner with appropriate guidance. Apply existing processes and procedures to solve problems and may receive guidance for problems that are non-routine.', 'Job Description', 'Identify patterns and trends across data sets.', 'Proactively analyze data to answer key questions from stakeholders.', 'Work alongside teams within the business and/or management team to establish business needs. Report results back to the relevant members of the business.', 'Proactively identify what drives business performance, efficiency and productivity. Investigate and communicate areas for improvement.', 'Define and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution.', 'Position Specific Details', 'Collect and interpret data from multiple data sources.']",Associate,Full-time,Information Technology,Construction,2020-11-05 11:32:32
Postdoctoral Research Scientist,ASAPP,United States,6 hours ago,74 applicants,"['', 'Familiarity with at least one of the deep learning toolkits, such as Pytorch, Tensorflow and MxNet', 'Ability to independently develop and drive original research initiatives', 'Prototype and productionize your research outcome by collaborating with other functions at ASAPP', 'Strong communication skills', 'Conduct novel and impactful research to advance the field of Machine LearningBe actively involved in the research community by publishing in top-tier conferencesLeverage the massive amounts of data generated by our products, and identify research problems that are directly related to our business and productsPrototype and productionize your research outcome by collaborating with other functions at ASAPP', 'Perks', 'Ability to thrive in an atmosphere of constant change', 'At ASAPP, our mission is to solve complex and challenging problems by building transformative machine learning-powered products. We leverage artificial intelligence to address significant challenges that share three common characteristics: huge economic scale, systemic inefficiencies, and tremendous amounts of data. Our talented teams that drive our product innovation and development are located in New York City, Ithaca, San Francisco, Mountain View, and Buenos Aires.', ""What you'll do"", 'Familiarity with at least one of the deep learning toolkits, such as Pytorch, Tensorflow and MxNetSolid coding skillsAbility to thrive in an atmosphere of constant change', 'Solid record of peer reviewed publications', 'Competitive compensation', ""What you'll need"", 'Excellent teamwork spirit', 'If you thrive in an environment of deep thinking, impactful research, start up-paced execution, and strong collaboration with all parts of an organization, ASAPP is an ideal environment for you.', 'Competitive compensationFitness and wellness perksLearning and development opportunities', 'PhD in any area of Machine Learning, or equivalent experienceAbility to independently develop and drive original research initiativesSolid record of peer reviewed publicationsExcellent teamwork spiritStrong communication skills', 'Fitness and wellness perks', 'Leverage the massive amounts of data generated by our products, and identify research problems that are directly related to our business and products', 'Solid coding skills', 'PhD in any area of Machine Learning, or equivalent experience', 'Be actively involved in the research community by publishing in top-tier conferences', 'ASAPP is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status. If you have a disability and need assistance with our employment application process, please email us at careers@asapp.com to obtain assistance.', 'Learning and development opportunities', 'Conduct novel and impactful research to advance the field of Machine Learning', 'We are seeking a Postdoctoral Researcher in our Ithaca research lab. Successful applicants will work side-by-side with our talented team under the supervision of Professor Kilian Weinberger. They leverage the massive amounts of data generated by our products, and our ability to deploy AI features into real-world use to ask and address fundamental research questions in novel ways.', ""What we'd like to see""]",Entry level,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Postdoctoral Research Scientist,ASAPP,United States,6 hours ago,74 applicants,[],Entry level,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Senior Risk And Decisions Analyst,Preferred Lease,"Plano, TX",22 hours ago,38 applicants,"['Capable of contributing      independent analysis and researching appropriate statistical methods for      assigned projects.', 'Proficient with the use of at      least one of the following programming languages: SAS, R, or Python. ', 'Evaluate models for accuracy,      stability, and bias during the development process and in production. ', 'Create the necessary reporting      and scorecards to track changes and performance. ', ' Master\'s degree in a highly      quantitative field (e.g., Mathematics, Economics, Statistics, etc. ).  Minimum 2 years professional      experience in analytics including the development of predictive models.  Proficient with the use of at      least one of the following programming languages: SAS, R, or Python.  Proficient with SQL.  Experience in Financial      Services, Fraud Detection, or Risk Management preferred.  Highly detail-oriented; works      with the mantra that the quality of his/her work reflects strongly on      his/her personal ""brand.""  Highly organized with proven      ability to multi-task.  ', ""Master's degree in a highly      quantitative field (e.g., Mathematics, Economics, Statistics, etc. ). "", 'Develop predictive models to be      used in key areas of decision making for assigned lines of business. ', 'Highly organized with proven      ability to multi-task. ', 'Remain current on advanced      statistical techniques in order to enable consistent improvements in      business decisions. ', 'Capable of being objective and      giving/taking constructive feedback. ', 'Minimum 2 years professional      experience in analytics including the development of predictive models. ', 'JOB REQUIREMENTS:', 'JOB REQUIREMENTS: ', 'JOB PURPOSE: The Data Scientist will design, develop, and maintain complex customer behavior models and underwriting strategies that enable Preferred Lease and RAC business units to make more effective decisions in the areas of customer acceptance, pricing, and fraud prevention. In this role, he/she will gather data from vendors and multiple internal databases for the purposes of model development and ad-hoc analysis. He/she will also monitor, refresh, and update models for lines of business as assigned. ', 'Develop actionable business      recommendations related to risk management, price optimization, and margin      improvement. ', 'JOB PURPOSE', ' Develop predictive models to be      used in key areas of decision making for assigned lines of business.  Build expert knowledge of the      business rules and underwriting strategies in place for assigned lines of      business, retail partner, and customer segmentation.  Evaluate models for accuracy,      stability, and bias during the development process and in production.  Design champion/challenger      tests and experiments to constantly refine risk models, decision engine      logic and pricing parameters.  Remain current on advanced      statistical techniques in order to enable consistent improvements in      business decisions.  Partner closely with members of      the Data Warehouse team to deliver accurate and timely results.  Create the necessary reporting      and scorecards to track changes and performance.  Develop actionable business      recommendations related to risk management, price optimization, and margin      improvement.  ', 'Partner closely with members of      the Data Warehouse team to deliver accurate and timely results. ', ' ', 'Design champion/challenger      tests and experiments to constantly refine risk models, decision engine      logic and pricing parameters. ', 'Proficient with SQL. ', 'KEY RESPONSIBILITIES: ', 'Experience in Financial      Services, Fraud Detection, or Risk Management preferred. ', 'Highly detail-oriented; works      with the mantra that the quality of his/her work reflects strongly on      his/her personal ""brand."" ', ' Capable of being objective and      giving/taking constructive feedback.  Capable of contributing      independent analysis and researching appropriate statistical methods for      assigned projects.', 'Build expert knowledge of the      business rules and underwriting strategies in place for assigned lines of      business, retail partner, and customer segmentation. ']",Associate,Full-time,Analyst,Financial Services,2020-11-05 11:32:32
Senior Data Engineer,Helen of Troy,"New York, NY",1 day ago,Be among the first 25 applicants,"['', 'Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. ', 'For more information about Helen of Troy, visit www.helenoftroy.com. You can also find us on LinkedIn, Glassdoor, Facebook, Instagram and Twitter. ', ""Explore/Analyze Company's Operational data and find correlation between different business process to improve and/or recommend changes to Business Processes"", 'Develops and implements effective/strategic business solutions through research and analysis of data and business processes', 'Curious, independent mindset and attitude - you explore new technological & methodical options independently', 'Experience working with structured, semi structured (JSON, XML) & unstructured data types (text, files etc.) ', ""Bachelor's degree from an accredited four-year college or university in related field4+ years working on Data Platforms2+ years on a Modern Data Platform. (AWS, Azure, Snowflake etc.)Experience in evaluating, designing and implementing data platforms and data pipelines to scale and automate extraction of data from multiple internal and external sourcesExperience articulating business questions and using quantitative techniques and driving insights for businessSolution-oriented with an ability to identify and assess risk and prioritize competing demands Strong storytelling skills to help decision-makers see the big picture and act on the results of analysisAbility to devise and deliver persuasive presentations, based on data-driven insights and facts, to gain support for business strategies and/or initiativesCurious, independent mindset and attitude - you explore new technological & methodical options independentlyKnowledge of professional software engineering practices and best practices for the full software development life cycle (Waterfall and Agile), including coding standards, code reviews, source control management, build processes, testing, and operationsStrong programming skills in R / Python or equivalent tools for exploratory and predictive analyticsProficiency in data transformations, handling missing data, feature engineering, regression, classification and clustering analysisDeep technical understanding of machine learning (linear models, decision trees, boosting, random forest, k-means, ensemble models etc.)Experience in relational databases such as Oracle and proficiency with SQLExperience working with structured, semi structured (JSON, XML) & unstructured data types (text, files etc.) Familiarity with Git, NoSql databases, Spark, TensorFlowApplicants must be authorized to work in the United States on a full-time basis"", 'Helen of Troy is an Equal Opportunity / Affirmative Action Employer', 'Strong storytelling skills to help decision-makers see the big picture and act on the results of analysis', 'Solution-oriented with an ability to identify and assess risk and prioritize competing demands ', 'Knowledge of professional software engineering practices and best practices for the full software development life cycle (Waterfall and Agile), including coding standards, code reviews, source control management, build processes, testing, and operations', 'Deliver value-add solutions at the speed of business ', 'Evaluate gaps in existing data platform and aid the implementation of a modern data platform', '2+ years on a Modern Data Platform. (AWS, Azure, Snowflake etc.)', 'Ability to devise and deliver persuasive presentations, based on data-driven insights and facts, to gain support for business strategies and/or initiatives', 'Proficiency in data transformations, handling missing data, feature engineering, regression, classification and clustering analysis', 'Create and implement customer centric solutions', 'Experience articulating business questions and using quantitative techniques and driving insights for business', ""What you'll be doing"", 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing data infrastructure for greater scalability', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management', 'Gather business needs and translating into analytical problems', 'Troubleshoot data quality issues - identifying root cause/system & documentation/communication of resolution ', '*This position is temporarily eligible for Work from Home until our offices reopen. Once our offices reopen, this position is not eligible to be Work from Home, and you will be required to report to the office Monday-Friday.', '4+ years working on Data Platforms', 'Develop programs to assist business in improving Marketing strategy, Product Pricing and customer retention', 'Deep technical understanding of machine learning (linear models, decision trees, boosting, random forest, k-means, ensemble models etc.)', 'Create and maintain excellent data documentation that allows the data to be understood (Metadata) and leveraged for additional use.', 'Familiarity with Git, NoSql databases, Spark, TensorFlow', 'Experience in relational databases such as Oracle and proficiency with SQL', 'What are the requirements for consideration?', 'If you, as one of our employees or as an applicant for employment, have any questions about our Affirmative Action Plan, please contact Human Resources during regular business hours. If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact Human Resources at (915) 225-8000.', 'Analyze data to find actionable insights and “tell the story"" of our business as well as help deliver solutions to any business needs using machine learning, text-mining/NLP to extract insights from structured and unstructured data to assist in new product development, improving the quality of the products, improving customer service experience', 'Conduct written and verbal presentations to share insights and recommendations to audiences of varying levels of technical sophistication', 'Design and Develop Data platforms and pipelines', 'Strong programming skills in R / Python or equivalent tools for exploratory and predictive analytics', 'What contribution will I make to Helen of Troy?', 'Ensure the effective collection, organization and distribution of data, from a variety of data sources', ""Bachelor's degree from an accredited four-year college or university in related field"", 'Applicants must be authorized to work in the United States on a full-time basis', 'Design and implement predictive & prescriptive data models', 'Experience in evaluating, designing and implementing data platforms and data pipelines to scale and automate extraction of data from multiple internal and external sources', 'Build strong relationships with the different departments, teams, and support functions to understand the business needs', 'The Senior Data Engineer with create and implement strategies directed at acquiring data from new and existing sources, build a modern data platform and promote the development of insights and data driven decisions using our Operational, Sales and Marketing data to improve Business Process efficiency and Product quality.', 'Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions.', 'Translate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies.', 'Collaborate and knowledge share with internal stakeholders to ensure single source of truth for all data', 'Design and Develop Data platforms and pipelinesEvaluate gaps in existing data platform and aid the implementation of a modern data platformIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing data infrastructure for greater scalabilityEnsure the effective collection, organization and distribution of data, from a variety of data sourcesBuild processes supporting data transformation, data structures, metadata, dependency and workload managementGather business needs and translating into analytical problemsTranslate business questions and concerns into specific quantitative questions that can be answered with available data using sound methodologies.Create and maintain excellent data documentation that allows the data to be understood (Metadata) and leveraged for additional use.Retrieve, synthesize, and present critical data in a format that is immediately useful to answering specific questions.Design and implement predictive & prescriptive data modelsAnalyze data to find actionable insights and “tell the story"" of our business as well as help deliver solutions to any business needs using machine learning, text-mining/NLP to extract insights from structured and unstructured data to assist in new product development, improving the quality of the products, improving customer service experienceExplore/Analyze Company\'s Operational data and find correlation between different business process to improve and/or recommend changes to Business ProcessesDevelop programs to assist business in improving Marketing strategy, Product Pricing and customer retentionCreate and implement customer centric solutionsBuild strong relationships with the different departments, teams, and support functions to understand the business needsCollaborate and knowledge share with internal stakeholders to ensure single source of truth for all dataConduct written and verbal presentations to share insights and recommendations to audiences of varying levels of technical sophisticationDetermines business information needs, identifies system requirements, KPIs, and methods for the data warehouse to assist with operational and strategic planningDevelops and implements effective/strategic business solutions through research and analysis of data and business processesTroubleshoot data quality issues - identifying root cause/system & documentation/communication of resolution Deliver value-add solutions at the speed of business ', 'Determines business information needs, identifies system requirements, KPIs, and methods for the data warehouse to assist with operational and strategic planning', ""Join us as Senior Data Engineer and make an impact supporting world-class brands including our 8 leadership brands: OXO, Hydro Flask, Vicks, Braun, Honeywell, PUR, Hot Tools, Drybar. Our outstanding products elevate people's lives everywhere, every day. This position can be located at our New York, NY, Marlborough, MA, Irvine, CA or El Paso, TX locations.""]",Mid-Senior level,Full-time,Information Technology,Consumer Goods,2020-11-05 11:32:32
Materials Scientist,Headway Technologies,"Milpitas, CA",20 hours ago,Over 200 applicants,"['', 'SUMMARY:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0', 'Trouble shoots issues and coordinates the repair of equipment/tools as needed', 'Able to comply with all safety policies and procedures', 'Knowledge and ability to use Microsoft Office applications to create spreadsheets, Word documents, and presentations', 'Performs the materials and physical characterization of development and product devices', 'Interacts and responds to inquiries from other product groups regarding process-related issues and product or device requirements', 'Performs the materials and physical characterization of development and product devicesDesigns and conducts experiments using Dual Beam and SEM techniquesPrepares precision TEM samples for high resolution TEM applicationsWorks to continuously improve current or future materials or processes by reviewing and monitoring sample data, summarizing findings, and recommending corrective actionProactively responds to issues related to materials quality or the characterization process and initiates resolutionReviews and analyzes data, creates reports, and presents findings to panels, groups, teams, or departments as requiredTrouble shoots issues and coordinates the repair of equipment/tools as neededInteracts and responds to inquiries from other product groups regarding process-related issues and product or device requirementsAdheres to all safety policies and procedures as requiredPerforms other duties of a similar nature or level*', 'Designs and conducts experiments using Dual Beam and SEM techniques', 'Able to create various reports, presentations, and written sample analysis', 'Able to communicate effectively, both verbally and in writing, with all levels of contractors, consultants, employees, and management', 'Knowledge of electron microscopy principles, practices, and techniques', '*Other duties of a similar nature or level are duties that may be required, but may not be specifically listed in the job description or posting.', 'Proficient in the use of Microsoft Office Applications', 'Knowledge of magneto-resistance technology as it relates to fabrication of hard disk drive manufacturing processes', 'REPORTS TO:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0SR. DIRECTOR OF WAFER CHARACTERIZATION', 'The Materials Scientist works primarily in a laboratory environment from Monday thru Friday. The schedule may be altered from time-to-time to meet business or operational needs; may travel from building-to-building as needed.\xa0Adheres to required safety and dress protocols standards. Spends a majority of time in a seated position, but occasionally stands and walks; performs various fine grasping movements, bends, and twists; operates a computer and enters information using a keyboard, operates a telephone, and other office equipment. May occasionally be required to push, pull, or lift up to 10 pounds.', 'Master’s degree in Materials Science, Chemical Engineering, or Physics, and/or equivalent relevant experience; PhD degree preferred', 'MINIMUM QUALIFICATIONS:', 'REQ#:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa020-024', 'Knowledge and ability to prepare TEM samples, conduct experiments, interpret complex data, and recommend correction action', 'Able to work productively and collaboratively with all levels of employees and management', 'FLSA STATUS:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0EXEMPT', 'Prepares precision TEM samples for high resolution TEM applications', 'Performs other duties of a similar nature or level*', 'Three years of hands on experience working in the magnetic recording head or semiconductor industry using Dual Beam, SEM, and EDS', 'Master’s degree in Materials Science, Chemical Engineering, or Physics, and/or equivalent relevant experience; PhD degree preferredThree years of hands on experience working in the magnetic recording head or semiconductor industry using Dual Beam, SEM, and EDSKnowledge and experience with TEM and XRD preferredProficient in the use of Microsoft Office Applications', 'TDK/Headway Technologies, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, gender, national origin, age, disability, or genetics.\xa0Applicants requiring accommodation in order to complete the application process should contact the Headway Human Resources Department.', 'Under the direction of the Sr. Director of Wafer Characterization, the Materials Scientist performs the materials and physical characterization of development and product devices; designs and conducts experiments using Dual Beam and SEM techniques; analyzes results, summarizes findings, and makes recommendations regarding future impact to current processes or materials in development such as recording heads, HDD wafers, MRAM, MEMS, or other devices. This position is located in Milpitas, California.', 'Knowledge and experience with TEM and XRD preferred', 'Adheres to all safety policies and procedures as required', 'ESSENTIAL FUNCTIONS:', 'TITLE:\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0MATERIALS SCIENTIST (DUAL BEAM)', 'Proficient in the knowledge and operation of Dual Beam, SEM, and EDSAble to create various reports, presentations, and written sample analysisAble to communicate effectively, both verbally and in writing, with all levels of contractors, consultants, employees, and managementAble to work productively and collaboratively with all levels of employees and managementAble to comply with all safety policies and proceduresKnowledge of electron microscopy principles, practices, and techniquesKnowledge of semiconductor industry principles, practices, and techniquesKnowledge of magneto-resistance technology as it relates to fabrication of hard disk drive manufacturing processesKnowledge and ability to prepare TEM samples, conduct experiments, interpret complex data, and recommend correction actionKnowledge and ability to use Microsoft Office applications to create spreadsheets, Word documents, and presentationsAble to comply with all safety policies and proceduresDemonstrated organizational and time management skillsDemonstrated problem-solving and trouble shooting skillsFlexible and able to prioritize', 'Proficient in the knowledge and operation of Dual Beam, SEM, and EDS', 'Demonstrated organizational and time management skills', 'Works to continuously improve current or future materials or processes by reviewing and monitoring sample data, summarizing findings, and recommending corrective action', 'Knowledge of semiconductor industry principles, practices, and techniques', 'Demonstrated problem-solving and trouble shooting skills', 'Flexible and able to prioritize', 'WORKING CONDITIONS:', 'Proactively responds to issues related to materials quality or the characterization process and initiates resolution', 'Reviews and analyzes data, creates reports, and presents findings to panels, groups, teams, or departments as required', 'Knowledge, Skills, and Abilities:']",Associate,Full-time,Research,Computer Hardware,2020-11-05 11:32:32
Research Scientist 1- Immunology,Charles River Laboratories,"Morrisville, NC",19 hours ago,Be among the first 25 applicants,"['', 'Research Scientist 1- Immunology', 'Discovery', 'Equal Employment Opportunity', ' Experience: Minimum of 6 to 7 years related experience in the contract research, academic, or pharmaceutical industry. 3-4 years’ experience of conducting immunology studies using flow cytometry, gene expression, protein/cytokine analysis (Luminex) and other related techniques', 'About Charles River', 'Design and execute immune cell-based assays and flow cytometry based analysis of relevant animal tissues for cancer research studies', ' Research Scientist 1- Immunology', 'Job Summary', 'Review, interpret, integrate, and present data on assigned studies, using the assistance of senior scientific staff as appropriate.', 'Develop new assays and troubleshoot issues related to assay performance.', ' Design and execute immune cell-based assays and flow cytometry based analysis of relevant animal tissues for cancer research studies Participate in and coordinate all phases of the experimental planning process with appropriate departments. Generate high-quality protocols, amendments, and reports appropriate for assigned studies. Review, interpret, integrate, and present data on assigned studies, using the assistance of senior scientific staff as appropriate. Provide technical and scientific guidance to more junior research staff. Develop new assays and troubleshoot issues related to assay performance. Attend scientific meetings, conferences and training courses to enhance job and professional skills. Perform all other related duties as assigned. ', 'Perform all other related duties as assigned.', 'Generate high-quality protocols, amendments, and reports appropriate for assigned studies.', "" Education: Bachelor's degree (B.S./B.A.) or equivalent in a scientific related discipline. Related Master's degree (M.S./M.A.) or PhD/DVM preferred."", 'Serve as a scientist in the management, conduct, execution, interpretation and reporting of assigned nonclinical cancer research studies with a focus on in vitro and in vivo analysis of immune cell function using flow cytometry and other analytical methods.', 'Participate in and coordinate all phases of the experimental planning process with appropriate departments.', 'About Discovery', ' An equivalent combination of education and experience may be accepted as a satisfactory substitute for the specific education and experience listed above.', 'Morrisville, NC', 'Attend scientific meetings, conferences and training courses to enhance job and professional skills.', 'Provide technical and scientific guidance to more junior research staff.']",Associate,Full-time,Research,Research,2020-11-05 11:32:32
"Professional II, Product Planning",Samsung Electronics America,"Mountain View, CA",16 hours ago,Be among the first 25 applicants,"['', 'Position Summary', ' Skills and Qualifications ', ' Role and Responsibilities ']",Entry level,Full-time,Product Management,Information Technology and Services,2020-11-05 11:32:32
"Sr. Data Engineer (Sorry, No Visas or C2C Submissions)",Catalyte,United States,18 hours ago,Be among the first 25 applicants,"['', 'Sr. Data Engineer ', 'Responsibilities:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Collaborating with our Data Science team on data and metrics', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Building and maintaining a dashboard solution and dashboards to enable self-serve business analysis', 'Position will be remote with occasional travel post-COVID', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Working with and evaluating existing data-centric applications and tools', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0At least 3 years experience with Python', '\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Working with stakeholders to help ensure that business needs are met', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Exposure to data security regulation and enforcement - GDPR, HIPAA, etc', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A “can do” attitude and a passion for innovation', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Working on Agile application teams to build high quality and modular back-end data structures\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Excellent skills in both RDBMS (SQL Server, PostgreSQL) and NoSQL technologies', 'Are you a Data Engineering enthusiast with a wide variety of experience across the data lifecycle and with multiple technology stacks? Do you love to organize data and figure out all of the ways it can be used? Do you enjoy mentoring junior and future engineers? We are\xa0looking for an innovative Senior Data Engineer to help us build the future. If you want to put your skills to use to help find and create future developers, come talk to us! You will be working with a variety of technologies and helping to design and build applications and tools with a data and analytics-driven focus.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Mentoring more junior developers to allow them to grow their data career', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0At least 5 years working in a Data Developer, Engineer or Architect role with a broad focus on data movement, querying (SQL), analytics, storage and processing', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Curiosity about data and the ideal way to structure it to extract meaning from it', 'Qualifications:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Building tools and APIs to enhance Data Lake security with an eye to continuing our policy of keeping personal data completely secure using the most up-to-date guidelines', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Building data ingestion pipelines to ensure timely and quality data into our Data Lake', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience building pipelines in a modular, scalable way', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Cloud experience is desired - AWS preferred', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Strong analytical skills', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Automating data pipelines and ensuring that a robust CI/CD process is in place']",Mid-Senior level,Contract,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Engineer (Andrews Air Force Base),QUADGRAPHICS LIMITED,"Andrews AFB, MD",20 hours ago,Be among the first 25 applicants,"['', 'Job Summary', 'Highly Desired Qualifications', 'Additional Job Requirements', 'Mandatory Qualifications']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Research Scientist -Antibody Engineering & Phage Display,Job Juncture,"Brunswick, OH",11 hours ago,Be among the first 25 applicants,"['', 'Ph.D. in Molecular Biology, Genetic Engineering, or Gene Editing', 'Immunology, immuno-oncology, tumor biology, flow cytometry, and ELISA experience are a plus.', '2-5 years of industry or academia experience', 'Requirements', 'Cloning, display libraries, and sequencing experience', ' Ph.D. in Molecular Biology, Genetic Engineering, or Gene Editing 2-5 years of industry or academia experience Cloning, display libraries, and sequencing experience Immunology, immuno-oncology, tumor biology, flow cytometry, and ELISA experience are a plus. ']",Associate,Full-time,Other,"Health, Wellness and Fitness",2020-11-05 11:32:32
Sr. Analyst - RGM,Kimberly-Clark,"Madison, WI",22 hours ago,Be among the first 25 applicants,"['', 'Designs new tools to advance the Revenue Growth Management (RGM) capabilities and improve speed to insight.', 'Essential Functions', 'Worker Type', 'Develops fact-based insights to support RGM projects and recommendations.', '2+ years of general work experience, ideally in an analytical capacity within FMCG companies', 'Maintains and updates existing tools needed for ongoing development of RGM analytics, including but not limited to, pricing and promotional strategies. ', 'Overview Of The Role', 'Experience utilizing a data lake to build new capabilities/reports', 'Individual contributor', 'Time Type', 'Reports to the Trade Promotion and Advanced Analytics LeadIndividual contributor', 'Drives adoption of tools across RGM, Business Unit & Sales partners integrating them into the normal business cadence.', 'Designs new tools to advance the Revenue Growth Management (RGM) capabilities and improve speed to insight.Maintains and updates existing tools needed for ongoing development of RGM analytics, including but not limited to, pricing and promotional strategies. Partners with IT and other organizations to build and maintain robust customer planning tools utilizing most recent elasticities, unit economics, and observed price/promo points to estimate value of multiple planning scenarios and development efficiency opportunities.Drives adoption of tools across RGM, Business Unit & Sales partners integrating them into the normal business cadence.Assists KCNA RGM team by providing data and analysis as needed to deliver insights and recommendations.Develops fact-based insights to support RGM projects and recommendations.Merges multiple data sources to enable Data Scientist to develop new methodologies.', 'Strong problem solver with a customer-service mentality.', 'Additional Locations', 'This role can work remotely from anywhere USA.', 'Merges multiple data sources to enable Data Scientist to develop new methodologies.', 'Worker Sub-Type', 'Bachelor’s degree in a Business, Statistics or IT discipline preferred.', 'Job Description', 'Bachelor’s degree in a Business, Statistics or IT discipline preferred.2+ years of general work experience, ideally in an analytical capacity within FMCG companiesHigh degree of knowledge of Nielsen, IRI, and other syndicated sourcesProven ability to build complex analytical tools and models that incorporate coefficients, elasticities, and other data from disparate syndicated data sources into one tool.Experience utilizing a data lake to build new capabilities/reportsStrong proficiency in Visual Basic and/or Tableau desiredStrong problem solver with a customer-service mentality.', 'Qualifications/Education/Experience Required', 'Primary Location', 'Partners with IT and other organizations to build and maintain robust customer planning tools utilizing most recent elasticities, unit economics, and observed price/promo points to estimate value of multiple planning scenarios and development efficiency opportunities.', 'Strong proficiency in Visual Basic and/or Tableau desired', 'Assists KCNA RGM team by providing data and analysis as needed to deliver insights and recommendations.', 'Proven ability to build complex analytical tools and models that incorporate coefficients, elasticities, and other data from disparate syndicated data sources into one tool.', 'Reports to the Trade Promotion and Advanced Analytics Lead', 'High degree of knowledge of Nielsen, IRI, and other syndicated sources', 'Team Structure']",Associate,Full-time,Research,Packaging and Containers,2020-11-05 11:32:32
Senior Data Engineer,New York Life Insurance Company,"New York, NY",7 hours ago,114 applicants,"['', ' Knowledge of industry standard Business Intelligence (BI) solution tools, such as: Oracle, Business Objects, Tableau, preferred ', 'Please note', 'Knowledge of the ETL (extract, transform and load) process.', ' R and Python, a plus ', ' Create and maintain optimal data pipeline architecture,  Assemble large, complex data sets that meet functional / non-functional business requirements.  Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re- designing infrastructure for greater scalability, etc.  Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and ‘big data’ technologies.  Build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics.  Keep our data secure & protected ', ' 5+ years of experience in a Data Engineer role ', ' Proficient knowledge TOAD, and SQL workbench ', 'Responsibilities', '.', ' Advanced working SQL knowledge and experience working with relational databases. ', ' Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and ‘big data’ technologies. ', ' Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. ', 'Proficient knowledge TOAD, and SQL workbench', ' Strong project management and organizational skills, preferred ', ' Knowledge of the ETL (extract, transform and load) process. ', ' Build analytics tools that utilize the data pipeline to provide actionable insights into key business performance metrics. ', ' Strong analytic skills related to working with unstructured datasets. ', ' Experience supporting and working with cross-functional teams in a dynamic environment. ', ' Keep our data secure & protected ', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets', ' Assemble large, complex data sets that meet functional / non-functional business requirements. ', 'Qualifications', 'R and Python, a plus', ' 5+ years of experience in a Data Engineer role  Passion for data and its fundamental ability to create value!  Bachelor’s in Computer Science, Masters a plus  Advanced working SQL knowledge and experience working with relational databases.  Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.  A successful history of manipulating, processing and extracting value from large disconnected datasets.  Strong analytic skills related to working with unstructured datasets.  Build processes supporting data transformation, data structures, metadata, dependency and workload management.  Proficient knowledge TOAD, and SQL workbench  Knowledge of the ETL (extract, transform and load) process.  R and Python, a plus  Experience working with data from Data warehouses, Data marts and Data Lakes.  Experience with data visualization / distribution and manipulating large data sets leveraging tools such as Hadoop and Data Wrangling tools  Knowledge of industry standard Business Intelligence (BI) solution tools, such as: Oracle, Business Objects, Tableau, preferred  Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.  Strong project management and organizational skills, preferred  Experience supporting and working with cross-functional teams in a dynamic environment. ', ' Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re- designing infrastructure for greater scalability, etc. ', ' Bachelor’s in Computer Science, Masters a plus ', ' Experience working with data from Data warehouses, Data marts and Data Lakes. ', ' A successful history of manipulating, processing and extracting value from large disconnected datasets. ', 'Advanced working SQL knowledge and experience working with relational databases.', ' Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. ', 'Please note: This role requires FINRA licensed and/or FINRA Associated Person pre-hire fingerprinting.', ' Passion for data and its fundamental ability to create value! ', ' Create and maintain optimal data pipeline architecture, ', ' Build processes supporting data transformation, data structures, metadata, dependency and workload management. ', ' Experience with data visualization / distribution and manipulating large data sets leveraging tools such as Hadoop and Data Wrangling tools ']",Not Applicable,Full-time,Information Technology,Financial Services,2020-11-05 11:32:32
"Director, Product & Data (Technology Focus)",PragerU,"Los Angeles, CA",21 hours ago,Be among the first 25 applicants,"['', 'Commitment to PragerU’s mission, and excellence in all endeavors', 'Requirements:\xa0', 'Understand most important metrics for organization, and work with Data Scientist to bring key insights to management teamEvaluate ROI for advertising and media spendsManage process of integrating separate data systems to analyze campaigns (social, web, etc.)\xa0Manage creation of recurring and ad-hoc reporting and data analysis to support execution and measurement of marketing activities', 'Excellent written and verbal communication skills', 'Must be a team player and leader with a collaborative and generative approach to the business', 'Supervisory experience', 'Our Mission', '5+ years of experience in a related field, with strong knowledge of product development and business intelligence with large, complex data setsSupervisory experienceProficiency in web tools, data visualization software and best practicesExperience in conducting database analytics / data-driven marketing with solid understanding of marketing automation concepts and practicesHas understanding of social media APIs and integration with centralized systemUnderstanding of consumer segmentation and testingExcellent written and verbal communication skillsMust be a team player and leader with a collaborative and generative approach to the businessCommitment to PragerU’s mission, and excellence in all endeavors', 'Understand our users, content and distribution methods (website, app, OTT)Work with web and app designers/developers to create a great user experience that highlights our content and organization with the right amount of prioritizationOversee internal and external QA process and needsManagement and oversight of content management systems and video players', 'Experience in conducting database analytics / data-driven marketing with solid understanding of marketing automation concepts and practices', 'Understanding of consumer segmentation and testing', 'Manage process of integrating separate data systems to analyze campaigns (social, web, etc.)\xa0', 'To apply, please first review our website at www.prageru.com. Please submit a resume and cover letter to careers@prageru.com. In your cover letter, please include a section explaining how your values align with ours, and why you would want to work at PragerU specifically.', 'Where Can You Find PragerU', 'Understand most important metrics for organization, and work with Data Scientist to bring key insights to management team', 'Where Can You Find PragerU?', 'Duties and Responsibilities', 'Our Vision', 'Understand our users, content and distribution methods (website, app, OTT)', 'Management and oversight of content management systems and video players', 'Oversee internal and external QA process and needs', 'How to Apply', '5+ years of experience in a related field, with strong knowledge of product development and business intelligence with large, complex data sets', 'Proficiency in web tools, data visualization software and best practices', 'Has understanding of social media APIs and integration with centralized system', 'Website/App/OTT', 'Manage creation of recurring and ad-hoc reporting and data analysis to support execution and measurement of marketing activities', 'Data', 'What We Do', 'PragerU, a fast-growing conservative media nonprofit is looking for an experienced head of product/data (new role!). This role will report to the CMO of the organization, and oversee an in-house data team and freelance technical team. The ideal candidate can roll up their sleeves, project manage and talk ‘tech’ to their direct reports, while translating to concise ‘business terms’ for management. We’re a mid-sized team, and need team players who can work fast, work hard and work efficiently!', 'We make exceptional video content that advances Judeo-Christian values. We distribute that content through a sophisticated marketing strategy. By reaching millions of people every day, we educate, influence and change minds. To learn more about PragerU, visit http://prageru.com.', 'Evaluate ROI for advertising and media spends', 'Duties and Responsibilities:', 'Work with web and app designers/developers to create a great user experience that highlights our content and organization with the right amount of prioritization', 'Our Mission: To promote what is true, what is excellent, and what is noble through digital media.', 'Find us on YouTube, Facebook, Twitter and Instagram', 'Our Vision: A world committed to life, liberty and the pursuit of happiness.', 'How to Apply:']",Director,Full-time,Product Management,Media Production,2020-11-05 11:32:32
"Manager, Business Intelligence",Nexon America,"El Segundo, CA",6 hours ago,38 applicants,"['', ' 10+ years of data analysis, data engineering and data science experience 5+ years of management experience Experience with various machine learning projects. Experience with data extraction and manipulation tools and Data Mining tools Experience with customer data management Online gaming experience preferred ', 'Experience with data extraction and manipulation tools and Data Mining tools', 'Bachelor’s degree in Math, Statistics or related field', 'Excellent time an project management skills', ' Excellent interpersonal and written and verbal communication skills Excellent knowledge of statistical analysis Excellent time an project management skills Very detail-oriented Knowledge of creating custom attributes and measures from raw transaction data Able to understand and translate marketing and analytic needs into solution and data management requirements Ability to extract data by writing your own SQL queries Experience using Tableau or similar BI tools Programming for data analysis (R or Python) preferred Able to manage shifting priorities in a fast-paced environment ', 'Able to understand and translate marketing and analytic needs into solution and data management requirements', 'Manage the day-to-day activities of the team, this includes mentoring and developing team members, provide thought-leadership to drive innovation and produce quality work, manage workload and establish priorities, establish and manage department budget and hire and train staff as needed', 'Nexon’s Benefits And Perks', 'Foster data-informed decision making, hypothesis generation, and experimentation', '5+ years of management experience', 'Education, Professional Training, Technical Training or Certification', 'Work Experience', 'Excellent interpersonal and written and verbal communication skills', 'Very detail-oriented', 'Excellent knowledge of statistical analysis', ' Manage the day-to-day activities of the team, this includes mentoring and developing team members, provide thought-leadership to drive innovation and produce quality work, manage workload and establish priorities, establish and manage department budget and hire and train staff as needed Provide timely, meaningful and actionable insights and recommendations through data analyses and machine learning techniques; identify and conduct data-driven analyses involving our players and games; establish sound methodologies and approaches to analyze business problems; work closely with various departments to understand their needs from a data and analytics perspective; package and present findings Support BI initiatives and reporting needs by helping business users gain access to necessary data, designing, setting up and maintaining reports and dashboards, improving the breadth and scope of existing reports based on business needs and ensuring proper functioning of Tableau, the company’s primary Business Intelligence tool. Help define and improve the tracking capabilities needed for analysis and reporting; work closely with Business Intelligence Engineer and Developers to understand and gain access to pertinent data, Applications, and Systems; QA data to ensure accuracy and understand limitations; leverage existing tools; recommend new tools and processes as needed. Develop deep partnerships with the product, engineering and cross-functional support teams to deliver insightful analytics, testing and measurement frameworks, modeling to define and build data-informed business strategy and roadmaps Through modern machine learning techniques, optimization of business processes using predictive and prescriptive methods. Foster data-informed decision making, hypothesis generation, and experimentation Responsible to research other potential software solutions Other duties as assigned ', 'Knowledge of creating custom attributes and measures from raw transaction data', 'Experience with customer data management', 'Summary Of Position', 'Knowledge/Skills', 'About Nexon', 'Responsible to research other potential software solutions', 'Master’s degree preferred', 'Online gaming experience preferred', 'Develop deep partnerships with the product, engineering and cross-functional support teams to deliver insightful analytics, testing and measurement frameworks, modeling to define and build data-informed business strategy and roadmaps', 'Provide timely, meaningful and actionable insights and recommendations through data analyses and machine learning techniques; identify and conduct data-driven analyses involving our players and games; establish sound methodologies and approaches to analyze business problems; work closely with various departments to understand their needs from a data and analytics perspective; package and present findings', ' Bachelor’s degree in Math, Statistics or related field Master’s degree preferred ', 'Help define and improve the tracking capabilities needed for analysis and reporting; work closely with Business Intelligence Engineer and Developers to understand and gain access to pertinent data, Applications, and Systems; QA data to ensure accuracy and understand limitations; leverage existing tools; recommend new tools and processes as needed.', 'Experience using Tableau or similar BI tools', 'Job Responsibilities', 'Support BI initiatives and reporting needs by helping business users gain access to necessary data, designing, setting up and maintaining reports and dashboards, improving the breadth and scope of existing reports based on business needs and ensuring proper functioning of Tableau, the company’s primary Business Intelligence tool.', 'Programming for data analysis (R or Python) preferred', 'Through modern machine learning techniques, optimization of business processes using predictive and prescriptive methods.', '10+ years of data analysis, data engineering and data science experience', 'Experience with various machine learning projects.', 'Able to manage shifting priorities in a fast-paced environment', 'Ability to extract data by writing your own SQL queries', 'Other duties as assigned']",Mid-Senior level,Full-time,Quality Assurance,Marketing and Advertising,2020-11-05 11:32:32
Data Engineer,"Liberty Personnel Services, Inc.","Philadelphia, PA",6 hours ago,86 applicants,"['', 'Previous financial services experience ', 'Strong C++ experience ', 'Experience in an AWS of Azure environment', ' Previous financial services experience  Experience with low latency systems Experience with large datasets Experience in an AWS of Azure environment Big Data technologies Strong C++ experience  ', 'Experience with large datasets', 'Big Data technologies', 'Experience with low latency systems', 'Job Details']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Sr Scientist / Underwater Acoustics / Sonar / Engineer,Headhunter Group,"Herndon, VA",8 hours ago,Be among the first 25 applicants,"['', 'MS or PhD in Signal Processing, Underwater Acoustics or related field10+ years of research and/or applications development experience in sonar sensor systems technologiesUnderwater acoustic sensor/system performance analysisMatlab software developmentExcellent and verifiable customer and industry peer-group communications skillsProposal preparation experience ', 'Preparation and conduct of oral presentation and demonstration of Adaptive Methods technology products to current and potential military/commercial customers, symposia, and government-industry technical working groups', 'Responsibilities', 'Vector Sensors', 'Desirable Job Skills', 'Design and development of sensor systems technologies to include array design, sensor signal processing, beamforming, acoustic communications, and automated detection / classification processing', 'Technical/Journal peer-reviewed publications in one or more of the sensor systems technology areas', 'Technical direction of sensor systems technology development, performance prediction and assessment, and application programs', 'Matlab software development', 'Excellent and verifiable customer and industry peer-group communications skills', 'Competitive technical proposal preparation', '10+ years of research and/or applications development experience in sonar sensor systems technologies', 'Design and development of sensor systems technologies to include array design, sensor signal processing, beamforming, acoustic communications, and automated detection / classification processingTechnical direction of sensor systems technology development, performance prediction and assessment, and application programsPreparation and conduct of oral presentation and demonstration of Adaptive Methods technology products to current and potential military/commercial customers, symposia, and government-industry technical working groupsCompetitive technical proposal preparation', 'Acoustic and non-acoustic sensor detection and classification', 'Required Job Skills And Education', 'Underwater acoustic propagation modeling, including familiarity with tools such as Bellhop, NSPE, CASS/GRAB, WaveQ3D, etc.', 'MS or PhD in Signal Processing, Underwater Acoustics or related field', 'Proposal preparation experience ', 'Acoustic and non-acoustic sensor detection and classificationUnderwater acoustic communicationsUnderwater acoustic propagation modeling, including familiarity with tools such as Bellhop, NSPE, CASS/GRAB, WaveQ3D, etc.Adaptive beamforming or environmentally adaptive signal processingVector SensorsTechnical/Journal peer-reviewed publications in one or more of the sensor systems technology areas', 'Underwater acoustic sensor/system performance analysis', 'Adaptive beamforming or environmentally adaptive signal processing', 'Underwater acoustic communications']",Associate,Full-time,Research,Insurance,2020-11-05 11:32:32
Staff Scientist I - Center for Cancer Immunology Research,Children's National Hospital,"Washington, DC",19 hours ago,Be among the first 25 applicants,"['', 'The Staff Scientist in the CETI program will assist faculty in conducting research and reporting to a principal investigator. Participates directly to lead projects. Requires technical knowledge and subject expertise in immunology and cellular therapy. Trains technical staff, graduate students and others in laboratory procedures and provides general supervision in the laboratory and assists with data management and analysis. In addition, the Staff Scientist will be responsible for assisting the principal investigator in the planning and execution of research projects, grant applications and publications. Assists in the management of resources, and manages day-to-day activities in the laboratory, such as purchasing, radioactivity, and biosafety issues. May lead the work with peers or other staff to achieve specific assignments or complete large and complex projects.', 'Commitment to Research', '1. Consistently demonstrate adherence with the standards for the responsible conduct of research.', 'Minimum Education', '4. Responsible for appropriate use of funds.', '2. Assist in developing publications for peer-reviewed, scientific, quality and management journals.', 'Responsible Conduct of Research', '3. Interact in a collaborative manner with other team members to accomplish organizational goals; may provide ideas to improve efficiency at group level; network primarily within own technical peer group.', 'Next-Generation sequencing, bioinformatics, molecular genetics', 'Conduct of Research', 'Required Skills/Knowledge', '5. Comply with all annual job-related training requirements.', 'At least two to four years of progressive specialized post-doctoral experience. (Required)', 'Children’s National Health System is an equal opportunity employer that evaluates qualified applicants without regard to race, color, national origin, religion, sex, age, marital status, disability, veteran status, sexual orientation, gender, identity, or other characteristics protected by law.', '2. Maintain confidentiality of data as required.', '3. Plan, conduct, and manage research projects within the federal and institutional regulations and policies under the direction of the laboratory director(s).', '1. Use accepted methods and techniques, solves well-defined problems and performs specific and limited portions of broader projects, under technical guidance of the principal investigator and the senior staff scientist.', ""Children's National Hospital, based in Washington, DC, celebrates 150 years of pediatric care, research and commitment to community. Volunteers opened the hospital in 1870 with 12 beds for children displaced after the Civil War. Today, 150 years stronger, it is among the nation's top 10 children's hospitals. It is ranked No. 1 for newborn care for the fourth straight year and ranked in all specialties evaluated by U.S. News & World Report. Children's National is transforming pediatric medicine for all children. In 2020, construction will be complete on the Children's National Research & Innovation Campus, the first in the nation dedicated to pediatric research. Children's National has been designated twice as a Magnet® hospital, demonstrating the highest standards of nursing and patient care delivery. This pediatric academic health system offers expert care through a convenient, community-based primary care network and specialty outpatient centers in the D.C., metropolitan area, including the Maryland and Northern Virginia suburbs. Children's National is home to the Children's National Research Institute and Sheikh Zayed Institute for Pediatric Surgical Innovation and is the nation's seventh-highest NIH-funded children’s hospital. It is recognized for its expertise and innovation in pediatric care, and as a strong voice for children through advocacy at the local, regional and national levels."", '1. Conduct research and development of new Next-Generation sequencing clinical assays.', '2. Conduct experiments in the laboratory that include developing new methods, taking measurements and recording observations, collecting, compiling and processing data, and analyzing results.', ""About Children's National"", 'Functional Accountabilities', ""Doctor of Philosophy (Ph.D.), or Medical Doctor (M.D.), or Master's Degree with 3 years of relevant work experience."", ""The Center for Cancer Immunology Research is seeking a Staff Scientist I, a junior career research position, to work full-time at Children's National Hospital. The position reports to the Principal Investigator and conducts research of significant scientific value in basic or translational sciences. The incumbent will serve in a research and development role in scientific area and will bring specialized skills, knowledge and experience to research programs or core laboratories. The individual develops and directs the design and conduct of experiments and assists in the management of resource allocations and daily laboratory activities. The staff scientist trains technical staff, students, fellows and physicians in laboratory procedures and assists with data management and analysis. The encumbered may develop and participate in educational programs and teaching assignments and assist the principal investigator in writing of grant applications and publications.""]",Associate,Full-time,Health Care Provider,Hospital & Health Care,2020-11-05 11:32:32
Cell Biologist,Terray Therapeutics,"Pasadena, CA",13 hours ago,Be among the first 25 applicants,"['', ' Proficiency in primary cell isolation, differentiation and culture and flow cytometry preferred', ' Experience with biochemical assays and molecular biology techniques a plus, particularly immunological assays', 'Experience and Qualifications:', ' Adapt assays for medium to high-throughput screening of small molecule hits from our affinity screens', ' Background in small molecule drug discovery preferred', ' Demonstrated technical proficiency, ability to troubleshoot to solve problems and to deliver high quality data', 'Company Overview:', ' Excellent organizational, interpersonal and communication skills and can thrive in a highly collaborative research environment', ' Support organization of lab and equipment as needed', ' Design and optimize biochemical and cell-based assays specific to therapeutic targets of interest', 'Qualifications include:', ' Extensive hands-on experience with cell culture and cell-based assays including reporter assays, and proliferation/viability/apoptosis assays as well as cytokine and gene expression analysis', ' Help evaluate and set up new lab instrumentation', ' Analyze data and communicate results', 'Position Summary:', ' PhD with 2-5 years of research experience in the field of immunology, oncology, cell signaling pathways, molecular biology or biochemistry', ' Design and execute studies to fully characterize the mechanism of action of small molecules', ' Experience with small molecule mechanism of action studies desired']",Entry level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Sr. Security Researcher (Remote),CrowdStrike,"Sunnyvale, CA",18 hours ago,Be among the first 25 applicants,"['', 'Stocked fridges, coffee, soda, and lots of treats', 'Wellness programs', 'Ability to analyze raw network data and to develop custom protocol decoders and decryption tools.', 'Market leader in compensation and equity awardsCompetitive vacation policyComprehensive health benefitsPaid parental leave, including adoptionFlexible work environmentWellness programsStocked fridges, coffee, soda, and lots of treats', 'Market leader in compensation and equity awards', 'Profound knowledge of reverse engineering tools (disassemblers, decompilers, debuggers) and processes (unpacking malware, reconstructing code logic, etc).', 'Knowledge of programming and scripting languages, in particular Python.', 'Key Qualifications Required', 'Responsibilities', 'Experience tracking and emulating botnet activity.', 'Produce high-quality threat intelligence reporting, including actionable mitigation and detection guidance, for all levels of readership.', 'Solid understanding of Windows OS internals and the Windows API.', 'Education', 'Competitive vacation policy', 'A background in exploit and vulnerability analysis is a plus.', 'Comprehensive health benefits', 'Strong knowledge of the most prevalent eCrime malware families and botnets.', 'Ability to express complex technical and non-technical concepts in verbal and graphical products.', 'Experience automating binary analysis and configuration extraction.', 'Experience tracking and emulating botnet activity.A background in intelligence analysis is a plus.A background in exploit and vulnerability analysis is a plus.MA/MS degree, Ph.D. or equivalent experience in Computer Science, or a related field.', 'Profound knowledge of reverse engineering tools (disassemblers, decompilers, debuggers) and processes (unpacking malware, reconstructing code logic, etc).At least three years of experience in static and dynamic malicious code reverse engineering.Strong knowledge of the most prevalent eCrime malware families and botnets.Knowledge of programming and scripting languages, in particular Python.Solid understanding of Windows OS internals and the Windows API.Ability to analyze raw network data and to develop custom protocol decoders and decryption tools.Experience automating binary analysis and configuration extraction.Ability to express complex technical and non-technical concepts in verbal and graphical products.Excellent writing skills are mandatory.', 'Flexible work environment', 'Contribute to active mitigation efforts and support incident response engagements with technical expertise.', 'Benefits Of Working At CrowdStrike', 'A background in intelligence analysis is a plus.', 'This role is open to candidates in the USA (Remote) and Europe (Remote). ', 'About The Role', 'Preferred', 'Write blog articles and present at conferences on novel threats and research results.', 'Develop tools to assist with automation of malware analysis tasks and tracking of threat actors.', 'MA/MS degree, Ph.D. or equivalent experience in Computer Science, or a related field.', 'BA/BS or equivalent experience in Computer Science, or a related field', 'Paid parental leave, including adoption', 'Excellent writing skills are mandatory.', 'Discover, analyze, document and track advanced cyber attack campaigns through malware reverse engineering.', 'Discover, analyze, document and track advanced cyber attack campaigns through malware reverse engineering.Produce high-quality threat intelligence reporting, including actionable mitigation and detection guidance, for all levels of readership.Develop tools to assist with automation of malware analysis tasks and tracking of threat actors.Contribute to active mitigation efforts and support incident response engagements with technical expertise.Write blog articles and present at conferences on novel threats and research results.', 'At least three years of experience in static and dynamic malicious code reverse engineering.']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Service Design Researcher,ServiceTitan,"Glendale, CA",17 hours ago,Be among the first 25 applicants,"['', 'As a Service Design Researcher, You Will', 'Basic understanding of statistics is a plus.', 'Plan, design and conduct qualitative and quantitative research studies, including writing research plans that outline study goals and methodology', 'Visualization', 'Work', 'CCPA Notice for CA Residents applying to Jobs at ServiceTitan', 'Visualization (either through diagramming, storyboarding, or information design). Helping others see the end-to-end and surface-to-core service and customer experience. ', 'Comfortable teaching and training other non-researchers, contributing subject matter expertise in the areas of both generative and formative user research using industry standard best practices.', 'Comfortable thinking end-to-end and surface-to-core. Able to see a high level view as well as a detailed view. Understand and analyze how all aspects of the service integrate and impact each other in the context of the larger service ecosystem.', ' Enrichment: ongoing learning culture with access to Linkedin Learning and professional development workshops, diversity charter groups, orientation program, career pathing opportunities, mentorship programs', 'Identify recruiting requirements, write screeners, and work closely with recruiters to obtain most appropriate customers possible for research studies.', 'A passion for creating new service design and research methods and practices', 'Develop,', 'Life at ServiceTitan ', 'Proven ability to be a contributing member of a cross-functional team, build consensus and inspire team confidence in and respect for the contributions of the Service Design team to enhance internal employee and customer experience as well as customer outcomes', 'three to five years ', 'About ServiceTitan', ' Plan, design and conduct qualitative and quantitative research studies, including writing research plans that outline study goals and methodology Identify recruiting requirements, write screeners, and work closely with recruiters to obtain most appropriate customers possible for research studies. Run qualitative and quantitative research studies both formal and informal with external facing customers as well as internal subject matter experts and stakeholders. Analyze results from all types of qualitative and research and create various types of insights and that synthesize findings into meaningful themes and actionable recommendations for various audiences. Ability to communicate or present research results and illustrate suggestions in clear, compelling, memorable and creative ways Strong storytelling skills with the ability to make ideas understandable, make the future more concrete and the present more impactful. Visualization (either through diagramming, storyboarding, or information design). Helping others see the end-to-end and surface-to-core service and customer experience.  Work closely with analytics, data scientist and customer success teams to collect various metrics to triangulate research data, uncover insights and inform service and design solutions Comfortable teaching and training other non-researchers, contributing subject matter expertise in the areas of both generative and formative user research using industry standard best practices. Engage in cross-functional activities and collaborate across organizational boundaries Develop, organize and facilitate research brainstorming and work sessions (either individually or as part of a team) ', 'Must have a solid understanding of basic software/product development life-cycle ', 'Work closely with analytics, data scientist and customer success teams to collect various metrics to triangulate research data, uncover insights and inform service and design solutions', 'Understand how to balance user experience, service experience, business needs, technically feasibility and time-to-market, and make tradeoffs where appropriate', 'Familiarity with in-lab and remote, research tools (e.g., Google Forms, Qualtrics, Optimal Workshop, etc.)', 'Run', ' Family-Friendly Benefits:', ' Work/Life Balance: flexible work schedule, flexible PTO', ""As a Service Design Researcher, You'll Need"", 'Enrichment: ', ' Family-Friendly Benefits: extended parental leave, pregnancy support, 20k in adoption reimbursement, Snoo Smart Sleeper, back-up childcare credits, legal benefit, discounted pet insurance', 'Foundational understanding of the best practices and fundamentals of interaction, human-centered, goal-directed and service design and research methods across multiple touch points and devices', 'Identify', 'Plan', 'Excellent communication skills with the ability to create and deliver effective, clear and engaging presentations and proposals to top management and/or public groups.', 'A demonstrated ability to effectively partner with and communicate to stakeholders, product managers and engineering team members.', 'Analyze', 'Engage', 'Familiarity with standard design patterns across devices and user interface conventions.', 'Bachelor’s degree must be in a qualitative research-related field such as Psychology, Human Factors Psychology, Cognitive Psychology, Human-Computer Interaction, Anthropology, Experimental Design; plus user research experience must include some experience with consumer or enterprise facing software or equivalent combination of education and experience. ', 'Ability to work independently and take initiative to solve problems.', 'Creative problem solving skills, a curious mind and an enthusiastic work ethic with an intrinsic passion for making things better', ""Bachelor's degree (B. A.) from four-year college or university; or three to five years related experience and/or training; or equivalent combination of education and at least three years of work experience."", 'Foundational experience (2-4 years) with techniques in qualitative research, including formal and informal usability studies, card sorting, ethnographic research, contextual inquiry, persona development, heuristic evaluations, participatory design, etc.', ' Health & Wellness: company-paid medical/vision/dental/life insurance/disability, employer HSA contribution, free One Medical membership, care coordination support, 401(k) with company match, stipend for home office equipment/supplies, gym discounts, monthly cell phone stipend', 'Comfortable', 'Run qualitative and quantitative research studies both formal and informal with external facing customers as well as internal subject matter experts and stakeholders.', 'Equal Opportunity Employer', 'Perks & Benefits', 'Ability to communicate or present research results and illustrate suggestions in clear, compelling, memorable and creative ways', 'Strong', ' Health & Wellness: ', "" Proven ability to be a contributing member of a cross-functional team, build consensus and inspire team confidence in and respect for the contributions of the Service Design team to enhance internal employee and customer experience as well as customer outcomes Comfortable thinking end-to-end and surface-to-core. Able to see a high level view as well as a detailed view. Understand and analyze how all aspects of the service integrate and impact each other in the context of the larger service ecosystem. A demonstrated ability to effectively partner with and communicate to stakeholders, product managers and engineering team members. Express facts, thoughts and ideas in a clear, concise, convincing and organized manner, as well as the ability to ask, as well as answer, meaningful and impactful questions. Understand how to balance user experience, service experience, business needs, technically feasibility and time-to-market, and make tradeoffs where appropriate Foundational understanding of the best practices and fundamentals of interaction, human-centered, goal-directed and service design and research methods across multiple touch points and devices Take inputs of all kinds\u200a—\u200aresearch findings, analytics, customer feedback, ideation, strategic directives\u200a—\u200aand turn this into a clear direction  Ability to work independently and take initiative to solve problems. Familiarity with standard design patterns across devices and user interface conventions. Creative problem solving skills, a curious mind and an enthusiastic work ethic with an intrinsic passion for making things better A passion for creating new service design and research methods and practices Excellent communication skills with the ability to create and deliver effective, clear and engaging presentations and proposals to top management and/or public groups. Must have a solid understanding of basic software/product development life-cycle  Foundational experience (2-4 years) with techniques in qualitative research, including formal and informal usability studies, card sorting, ethnographic research, contextual inquiry, persona development, heuristic evaluations, participatory design, etc. Foundational experience (2-4 years) with techniques in quantitative research, including survey construction, understanding results of analytics and A/B testing Bachelor's degree (B. A.) from four-year college or university; or three to five years related experience and/or training; or equivalent combination of education and at least three years of work experience. Bachelor’s degree must be in a qualitative research-related field such as Psychology, Human Factors Psychology, Cognitive Psychology, Human-Computer Interaction, Anthropology, Experimental Design; plus user research experience must include some experience with consumer or enterprise facing software or equivalent combination of education and experience.  Familiarity with in-lab and remote, research tools (e.g., Google Forms, Qualtrics, Optimal Workshop, etc.) Basic understanding of statistics is a plus. "", 'Strong storytelling skills with the ability to make ideas understandable, make the future more concrete and the present more impactful.', 'Engage in cross-functional activities and collaborate across organizational boundaries', 'Foundational experience (2-4 years) with techniques in quantitative research, including survey construction, understanding results of analytics and A/B testing', 'Ability', ' Work/Life Balance: ', 'Take inputs of all kinds\u200a—\u200aresearch findings, analytics, customer feedback, ideation, strategic directives\u200a—\u200aand turn this into a clear direction ', 'Analyze results from all types of qualitative and research and create various types of insights and that synthesize findings into meaningful themes and actionable recommendations for various audiences.', 'Express facts, thoughts and ideas in a clear, concise, convincing and organized manner, as well as the ability to ask, as well as answer, meaningful and impactful questions.', 'Develop, organize and facilitate research brainstorming and work sessions (either individually or as part of a team)']",Associate,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Sr.  Python Data Engineer,"Samiti Technology, Inc.","Charlotte, NC",15 hours ago,56 applicants,"['', 'At least 1 year of experience building data pipelines, CI/CD pipelines, and fit for purpose data stores', 'FINANCIAL BACKGROUND A PLUS', 'At least 3 years of experience working with unstructured datasets', '2+ years of creating data quality dashboards establishing data standards', 'At least 1 year of experience with a streaming data platform including Apache Kafka and Apache Spark,', 'Preferred Qualifications:', '2+ years of experience working with Azure platforms, services, and component technologies, including Blob store, and Azure Databricks', 'OPEN TO CORP TO CORP', 'At least 8 years of experience with the Software Development Life Cycle (SDLC)', '3+ years of experience with JSON, Parquet, Protobuf or Avro formats', 'Python Centric', 'At least 3 years of experience developing microservices: Python, TwistedPy, PySpark, Django', '1+ years of microservices architecture, RESTful web service and ORM frameworks', 'REMOTE TILL FURTHER NOTICE', '2+ years of experience in RDBMS, NOSQL', 'At least 5 years of experience working on a big data platform', '5+ years of data modeling and data engineering skills', 'At least 1 year of experience in cloud technologies: Azure, Docker, Ansible, or Terraform', 'At least 1 year of Agile experience']",Mid-Senior level,Contract,Engineering,Staffing and Recruiting,2020-11-05 11:32:32
Environmental Data Manager / Scientist,Integral Consulting Inc.,"Seattle, WA",24 hours ago,31 applicants,"['', 'APPLY HERE: https://www.integral-corp.com/career/data-manager/', 'APPLY HERE: ', 'Acquiring, organizing, and summarizing data to support a variety of geospatial, statistical, engineering, and other analyses.\xa0Working independently yet collaboratively with other team members in a variety of disciplines.\xa0Working in a group with other data managers following established standards and approaches.', 'All offers of employment are contingent on candidates passing a background screening that includes employment history, criminal background, Federal Watch List, a drug and alcohol screening, and, if applicable, a degree verification. Candidates will receive a written notice of this requirement. All screenings will be done in accordance with all local, state, and federal laws.', 'Working independently yet collaboratively with other team members in a variety of disciplines.\xa0', 'Integral Consulting Inc.', 'Excellent working knowledge of SQL and client-server databases', 'Experience with environmental sampling procedures, analytical chemistry data, and GIS.', 'We are currently seeking a Data Manager. The desired candidate will be a detail-oriented individual who can support scientific and engineering analyses by ensuring the highest level of data quality, availability, and documentation.', 'Working in a group with other data managers following established standards and approaches.', 'We are currently seeking a Data Manager. ', 'Candidates should hold at least an undergraduate degree in science or engineering and 3\xa0years of demonstrable skills and experience in database management. The ideal candidate will also have:', 'Experience with R and Python programming languages are desirable additional qualifications.', 'Integral Consulting Inc. (www.integral-corp.com) provides technical insight, strategy, and project delivery to help our clients move forward in an evolving world.\xa0We seek to achieve this mission by creating a business culture of client service, technical excellence, innovation, and collaboration.\xa0Equally, we hold ourselves to strong internal commitments to health and safety, sustainability, diversity, mutual respect, collegiality, and the professional development of our staff.', 'Qualifications', 'Candidates should hold at least an undergraduate degree in science or engineering and 3\xa0years of demonstrable skills and experience in database management. ', 'Acquiring, organizing, and summarizing data to support a variety of geospatial, statistical, engineering, and other analyses.\xa0', 'Competitive salary is commensurate with experience.\xa0Integral Consulting Inc. provides an exceptional benefits package with company-subsidized insurance, and an exciting work environment with opportunities for significant professional growth.', 'Integral Consulting Inc. provides equal opportunity in all of our employment practices to all qualified employees and applicants without regard to race; color; religion; gender (including pregnancy, childbirth, or related medical conditions); national origin; age; sexual orientation; disability; marital status; military, veteran, or Vietnam Era Veterans’ Readjustment Assistance Act protected veteran status; gender identity or gender expression; or any other category protected by federal, state, and local laws.\xa0The “EEO is the Law” poster can be viewed here: http://www1.eeoc.gov/employers/upload/eeoc_self_print_poster.pdf.', 'Excellent working knowledge of SQL and client-server databasesAn analytical mindset, attention to detail, and a determination to achieve accuracy\xa0Experience with environmental sampling procedures, analytical chemistry data, and GIS.Experience with R and Python programming languages are desirable additional qualifications.', 'We are proud to be an equal employment opportunity employer and are committed to a proactive program of affirmative action and diversity development.', 'As a Data Manager, your job functions will include, but not be limited to:', 'Day-to-Day Responsibilities', 'An analytical mindset, attention to detail, and a determination to achieve accuracy\xa0']",Associate,Full-time,Engineering,Environmental Services,2020-11-05 11:32:32
Quantum Systems Research Scientist - CIPHER,Georgia Tech Research Institute,"Atlanta, GA",5 hours ago,Be among the first 25 applicants,"['', 'A publication history in the field of experimental quantum sensing or quantum computing.', 'U.S. Citizenship Requirements', 'An ability to effectively communicate technical concepts to technical and non-technical audiences.', ' A Master’s degree in Physics, Applied Physics, or a related field of study and three (3) years of relevant full-time experience after completion of that degree, A Master’s degree in Physics, Applied Physics, or a related field of study and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or A Doctoral degree in Physics, Applied Physics, or a related field of study. ', 'Author technical reports and publications.', 'Education & Length Of Experience', 'Preferred Qualifications', 'Equal Employment Opportunity', 'Travel Requirements', 'Research Scientist II', ' Lab experience with trapped ions, laser cooling, vapor cell sensors and spectroscopy, or solid state color centers, e.g. NV-centers in diamond. Experience designing and demonstrating practical or fielded quantum devices. Skills (any of the following): scientific programming, micro/nano-fabrication methods, integrated photonic design. Excellent written and verbal communication skills. An ability to effectively communicate technical concepts to technical and non-technical audiences. ', ""A Master's degree or Ph.D. in Physics, Applied Physics, or a related field of study."", 'Senior Research Scientist', 'A Master’s degree in Physics, Applied Physics, or a related field of study and seven (7) years of relevant full-time experience after completion of that degree,', 'Job Duties', 'Participate in proposal writing and other business development activities.', 'A Master’s degree in Physics, Applied Physics, or a related field of study and three (3) years of relevant full-time experience after completion of that degree,', 'Required Minimum Qualifications', 'Contribute to existing experimental quantum sensor and simulation/computing research programs.', 'Candidate should be familiar with experimental techniques common in atomic, molecular, and optical physics labs.', 'A Doctoral degree in Physics, Applied Physics, or a related field of study.', 'Clearance Type Required', 'Skills (any of the following): scientific programming, micro/nano-fabrication methods, integrated photonic design.', ""A Doctoral degree in Physics, Applied Physics, or a related field of studyand four (4 ) years of relevant full-time experience after completion of a Bachelor's degree."", 'Job Description', 'Excellent written and verbal communication skills.', "" A Master’s degree in Physics, Applied Physics, or a related field of study and seven (7) years of relevant full-time experience after completion of that degree, A Master’s degree in Physics, Applied Physics, or a related field of study and nine (9) years of relevant full-time experience after completion of a Bachelor’s degree, or A Doctoral degree in Physics, Applied Physics, or a related field of studyand four (4 ) years of relevant full-time experience after completion of a Bachelor's degree. "", 'A Master’s degree in Physics, Applied Physics, or a related field of study and nine (9) years of relevant full-time experience after completion of a Bachelor’s degree, or', 'A Master’s degree in Physics, Applied Physics, or a related field of study and five (5) years of relevant full-time experience after completion of a Bachelor’s degree, or', 'Diversity & Inclusion', "" A Master's degree or Ph.D. in Physics, Applied Physics, or a related field of study. A publication history in the field of experimental quantum sensing or quantum computing. Candidate should be familiar with experimental techniques common in atomic, molecular, and optical physics labs. "", 'Keep up-to-date in relevant published quantum sensor literature.', ' Contribute to existing experimental quantum sensor and simulation/computing research programs. Author technical reports and publications. Keep up-to-date in relevant published quantum sensor literature. Participate in proposal writing and other business development activities. ', 'Lab experience with trapped ions, laser cooling, vapor cell sensors and spectroscopy, or solid state color centers, e.g. NV-centers in diamond.', 'Experience designing and demonstrating practical or fielded quantum devices.']",Associate,Full-time,Other,Research,2020-11-05 11:32:32
UX Researcher,Trissential,"Rochester, MN",7 hours ago,62 applicants,"['', 'Ability to use Adobe Creative Cloud, including Photoshop.', 'Previous experience working on product teams in an Agile environment', 'Able to collaborate effectively with stakeholders and act as a strategic partner in product decisions.', '3+ years conducting user research for software/web-based products', 'Build relationships with key stakeholders and clients to gain deeper insights.', 'Responsibilities', 'Collaborate with other researchers, product managers, and UX designers to ensure research translates into business impact.', 'Bachelor’s or master’s degree in Interaction Design, Graphic Design, Human-Computer Interaction, Industrial Design, or related field', '\xa0', 'Excellent verbal and written communication skills.\xa0\xa0', 'Synthesize and simplify data for sharing', 'Come join a team where benefits start the first day of employment and compensation plans are designed to meet a flexible life style. We are looking for a\xa0UX Researcher\xa0to join a new product team providing digital patient services.', 'Collaborate in a team environment', ""Conduct product user research through interviews, contextual inquiry, work groups, surveys, and analyticsDefine usability\xa0goals and evaluate\xa0usability solutions, including baseline testing and iterative prototype testingDefine Accessibility requirements based on product features\xa0and intended\xa0audienceDefine and execute prototypes\xa0and test approaches for research and assumption validationDevelop user persona's, journey maps, storyboardsPlan and carry out interviews and surveys to inform future product work.Build relationships with key stakeholders and clients to gain deeper insights.Establish and manage relationships with research-related vendors.Collaborate with other researchers, product managers, and UX designers to ensure research translates into business impact.Create a test plan, write a screener, recruit users, schedule users, moderate test, create video clip highlights, compile top-line results, create a findings summary, author durable reports, and effectively present and share results."", 'Listen actively', 'Define usability\xa0goals and evaluate\xa0usability solutions, including baseline testing and iterative prototype testing', 'Quickly develop user-testable prototypes', 'Establish and manage relationships with research-related vendors.', 'Qualifications', 'A mixture of creative and technical skills', 'Experience of using prototyping software tools, for example Axure Pro and Omnigraffle', 'Demonstrated experience with various audiences and levels', 'Experience', 'Able to perform all research-related tasks in the research project lifecycle', 'Conduct product user research through interviews, contextual inquiry, work groups, surveys, and analytics', 'Create a test plan, write a screener, recruit users, schedule users, moderate test, create video clip highlights, compile top-line results, create a findings summary, author durable reports, and effectively present and share results.', 'Define Accessibility requirements based on product features\xa0and intended\xa0audience', 'Co-create innovative solutions to problems', 'Trissential is a trusted partner for end-to-end quality services and management consulting. As a part of our parent company Expleo, we have a footprint in 30+ countries. Our Mission is to have a positive impact on every person who interacts with\xa0Trissential. Clients love us because we are service focused. Employees love us because they are valued and cared for.', 'Overview', 'A mixture of creative and technical skillsCreativity and innovation, to come up with new ideasEnthusiasm for design and technologyEmpathize with users and uncover latent needsSynthesize and simplify data for sharingCo-create innovative solutions to problemsCollaborate in a team environmentQuickly develop user-testable prototypesExcellent verbal and written communication skills.\xa0\xa0Listen activelyAble to collaborate effectively with stakeholders and act as a strategic partner in product decisions.', 'Skills', 'Define and execute prototypes\xa0and test approaches for research and assumption validation', 'Creativity and innovation, to come up with new ideas', 'Enthusiasm for design and technology', 'UX Researcher', 'Plan and carry out interviews and surveys to inform future product work.', 'Empathize with users and uncover latent needs', '3+ years conducting user research for software/web-based productsExperience of using prototyping software tools, for example Axure Pro and OmnigraffleAbility to use Adobe Creative Cloud, including Photoshop.Previous experience working on product teams in an Agile environmentDemonstrated experience with various audiences and levelsAble to perform all research-related tasks in the research project lifecycle', ""Develop user persona's, journey maps, storyboards""]",Mid-Senior level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Staff Data Engineer/Tech Lead, Data Engineering",Curology,"San Francisco, CA",5 hours ago,Be among the first 25 applicants,"['', 'A free subscription to Curology!', 'Company Mission', ""You'll work on initiatives to keep our system elegant and productivity high — such as improving our metrics, analytics, and experimentation infrastructure."", 'What will you do as a Staff Data Engineer/Tech Lead, Data Engineering at Curology?', 'You are willing to use other languages if needed for the right tool. (ie. basic javascript)', "" Data is a product. We believe the true potential of Data teams lies in a product-oriented mindset and that this is even more relevant to data. Exceptional impact. Data engineers are force-multipliers that enable others to work better and faster. Data is deeply integrated into what we do, this role and team are key to our continued success. Develop a modern data stack. We use the best tools for the job and you will be part of growing and cultivating our modern data stack. AWS, Redshift, our S3 Data Lake, we build for the future. Work with a talented and passionate team. Our small team of data engineers has achieved outsize results by maintaining a high bar for ownership and product quality. Join us at a magical time. We've tripled our business in the last year and we aren't planning on slowing down any time soon.Company MissionWe want to make effective skincare accessible to everyone.Humans want to feel confident in their own skin, but it's not easy to see a dermatologist. Curology is revolutionizing dermatology by making effective skincare accessible to everyone. We're part healthtech startup, part skincare lab — and completely focused on helping hundreds of thousands of people get medical care previously available to only a tiny percentage of the population.What will you do as a Staff Data Engineer/Tech Lead, Data Engineering at Curology?You'll design, manage and optimize the flow of data throughout the organization.You'll design a modern stack to build a cloud-first product — we love the cloud and modern tools like Serverless.You'll work with engineers, who are just as excited about data as you are to ensure data quality, integrity and availability.You'll lead the team to integrate consistent and high coding standards.You'll automate manual processes by working closely with teams like Marketing, BizOps, and Product to discover opportunities for programatic efficiency.You'll work on initiatives to keep our system elegant and productivity high — such as improving our metrics, analytics, and experimentation infrastructure.Continue to keep Privacy and Data Protection (PDP) the first-order consideration of data.You might be a good fit if...You have at least 10 years professional experience building and designing software with Python.At least 10 years professional experience modeling SQL and noSQL data.You are willing to use other languages if needed for the right tool. (ie. basic javascript)Have used Airflow to develop and monitor batch data pipelines.Have worked with permissions and regulated or controlled data. (HIPAA/GDPR/CCPA/FDA)Are passionate about getting the right data to the right person.Willing to lead in areas of strength and learn new skills when needed.You've designed systems at scale with AWS Lambda or a similar serverless technology.You've mentored teammatesYou have worked as a tech lead You'll love working at Curology because...Amazing team culture and environment. Awarded Great Place To Work & Inc.’s Best Workplace Competitive salary and stock options.Unlimited, flexible PTO for exempt employees.Excellent medical, dental and vision insurance.401(k) to help you save for the futurePaid maternity and paternity leave.Free catered daily lunch and a kitchen stocked with delicious snacks, drinks, and coffee.Company-sponsored happy hours and outings.A free subscription to Curology!Curology encourages applications from people of all races, religions, national origins, genders, sexual orientations, gender identities, gender expressions and ages, as well as veterans and individuals with disabilities.  Notice to Applicants under the CCPA."", 'Are passionate about getting the right data to the right person.', ' Awarded Great Place To Work & Inc.’s Best Workplace ', ""You'll work with engineers, who are just as excited about data as you are to ensure data quality, integrity and availability."", 'At least 10 years professional experience modeling SQL and noSQL data.', 'Senior/Staff Data Engineer, Data Platforms', ""You'll design a modern stack to build a cloud-first product — we love the cloud and modern tools like Serverless."", ""You'll love working at Curology because..."", ""You'll design, manage and optimize the flow of data throughout the organization.You'll design a modern stack to build a cloud-first product — we love the cloud and modern tools like Serverless.You'll work with engineers, who are just as excited about data as you are to ensure data quality, integrity and availability.You'll lead the team to integrate consistent and high coding standards.You'll automate manual processes by working closely with teams like Marketing, BizOps, and Product to discover opportunities for programatic efficiency.You'll work on initiatives to keep our system elegant and productivity high — such as improving our metrics, analytics, and experimentation infrastructure.Continue to keep Privacy and Data Protection (PDP) the first-order consideration of data."", '401(k) to help you save for the future', ""You've designed systems at scale with AWS Lambda or a similar serverless technology."", "" Join us at a magical time. We've tripled our business in the last year and we aren't planning on slowing down any time soon.Company MissionWe want to make effective skincare accessible to everyone.Humans want to feel confident in their own skin, but it's not easy to see a dermatologist. Curology is revolutionizing dermatology by making effective skincare accessible to everyone. We're part healthtech startup, part skincare lab — and completely focused on helping hundreds of thousands of people get medical care previously available to only a tiny percentage of the population.What will you do as a Staff Data Engineer/Tech Lead, Data Engineering at Curology?You'll design, manage and optimize the flow of data throughout the organization.You'll design a modern stack to build a cloud-first product — we love the cloud and modern tools like Serverless.You'll work with engineers, who are just as excited about data as you are to ensure data quality, integrity and availability.You'll lead the team to integrate consistent and high coding standards.You'll automate manual processes by working closely with teams like Marketing, BizOps, and Product to discover opportunities for programatic efficiency.You'll work on initiatives to keep our system elegant and productivity high — such as improving our metrics, analytics, and experimentation infrastructure.Continue to keep Privacy and Data Protection (PDP) the first-order consideration of data.You might be a good fit if...You have at least 10 years professional experience building and designing software with Python.At least 10 years professional experience modeling SQL and noSQL data.You are willing to use other languages if needed for the right tool. (ie. basic javascript)Have used Airflow to develop and monitor batch data pipelines.Have worked with permissions and regulated or controlled data. (HIPAA/GDPR/CCPA/FDA)Are passionate about getting the right data to the right person.Willing to lead in areas of strength and learn new skills when needed.You've designed systems at scale with AWS Lambda or a similar serverless technology.You've mentored teammatesYou have worked as a tech lead You'll love working at Curology because...Amazing team culture and environment. Awarded Great Place To Work & Inc.’s Best Workplace Competitive salary and stock options.Unlimited, flexible PTO for exempt employees.Excellent medical, dental and vision insurance.401(k) to help you save for the futurePaid maternity and paternity leave.Free catered daily lunch and a kitchen stocked with delicious snacks, drinks, and coffee.Company-sponsored happy hours and outings.A free subscription to Curology!Curology encourages applications from people of all races, religions, national origins, genders, sexual orientations, gender identities, gender expressions and ages, as well as veterans and individuals with disabilities.  Notice to Applicants under the CCPA."", 'Amazing team culture and environment. Awarded Great Place To Work & Inc.’s Best Workplace Competitive salary and stock options.Unlimited, flexible PTO for exempt employees.Excellent medical, dental and vision insurance.401(k) to help you save for the futurePaid maternity and paternity leave.Free catered daily lunch and a kitchen stocked with delicious snacks, drinks, and coffee.Company-sponsored happy hours and outings.A free subscription to Curology!', 'Have used Airflow to develop and monitor batch data pipelines.', 'Unlimited, flexible PTO for exempt employees.', 'Company-sponsored happy hours and outings.', ' Notice to Applicants under the CCPA.', ""You'll design, manage and optimize the flow of data throughout the organization."", 'We want to make effective skincare accessible to everyone.', 'Why this role?', 'Amazing team culture and environment.', ""You'll lead the team to integrate consistent and high coding standards."", ' Work with a talented and passionate team. Our small team of data engineers has achieved outsize results by maintaining a high bar for ownership and product quality.', 'Competitive salary and stock options.', 'Paid maternity and paternity leave.', 'Curology encourages applications from people of all races, religions, national origins, genders, sexual orientations, gender identities, gender expressions and ages, as well as veterans and individuals with disabilities. ', 'You have at least 10 years professional experience building and designing software with Python.', 'You have worked as a tech lead ', 'Willing to lead in areas of strength and learn new skills when needed.', ""You have at least 10 years professional experience building and designing software with Python.At least 10 years professional experience modeling SQL and noSQL data.You are willing to use other languages if needed for the right tool. (ie. basic javascript)Have used Airflow to develop and monitor batch data pipelines.Have worked with permissions and regulated or controlled data. (HIPAA/GDPR/CCPA/FDA)Are passionate about getting the right data to the right person.Willing to lead in areas of strength and learn new skills when needed.You've designed systems at scale with AWS Lambda or a similar serverless technology.You've mentored teammatesYou have worked as a tech lead "", 'You might be a good fit if...', ""You'll automate manual processes by working closely with teams like Marketing, BizOps, and Product to discover opportunities for programatic efficiency."", 'Excellent medical, dental and vision insurance.', 'Continue to keep Privacy and Data Protection (PDP) the first-order consideration of data.', ' Data is a product. We believe the true potential of Data teams lies in a product-oriented mindset and that this is even more relevant to data.', 'Have worked with permissions and regulated or controlled data. (HIPAA/GDPR/CCPA/FDA)', ' Develop a modern data stack. We use the best tools for the job and you will be part of growing and cultivating our modern data stack. AWS, Redshift, our S3 Data Lake, we build for the future.', 'Free catered daily lunch and a kitchen stocked with delicious snacks, drinks, and coffee.', ' Exceptional impact. Data engineers are force-multipliers that enable others to work better and faster. Data is deeply integrated into what we do, this role and team are key to our continued success.', ""You've mentored teammates""]",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
"Research Scientist, Mass Spectrometry Proteomics",Caris Life Sciences,"Phoenix, AZ",6 hours ago,25 applicants,"['', ' Engage in continuous learning and skill development, including both scientific and laboratory technology education. ', ' One to three years of experience in the area of: 1) mass spectrometry operations, 2) proteomic sample preparation, or 3) proteomic data analysis. Demonstration of core competencies in the form of publications, presentations, or patents is required. One to three years of scientific project leadership experience is required. ', ' Strong knowledge of Microsoft Office Suite, specifically Access, Word, Excel, Outlook, and general working knowledge of Internet for business use. ', ' Customer Service Focus – Demonstrate a focus on listening to and understanding client/customer needs and then delighting the client/customer by exceeding service and quality expectations. ', ' Strong team skills, with ability to both lead and work with other employees in a positive and constructive way. ', ' Follow standard workflows, and develop and optimize novel workflows for the preparation of various biological samples for analysis using mass spectrometry. ', 'Interested parties should use the link to apply and email their resume to Kristen Robinson at  krobinson@carisls.com .Thank you for applying!Your resume and application will be carefully reviewed against the requirements of our current open positions. Should your experience and skills match an available position, you will be contacted by a member of our recruiting team.Thank you for your interest in Caris Life Sciences.Sincerely,Caris Life Sciences', ' Assists as needed to perform other related duties and special projects as required. ', ' For mass spectrometry operation positions: desire experience with operating, maintaining, and troubleshooting Thermo Scientific Orbitrap type mass spec instruments, such as the quadrupole-Orbitrap systems or the Tribrid systems. Experience with other vender platforms will be also be considered. Experience with operating, maintaining, and troubleshooting nano-LC and UHPLC chromatography systems is required. ', '  Ph.D. in chemistry-related or biology-related sciences.   Experience and extensive knowledge in the mass spec-based proteomics field of science, with an emphasis on protein biomarker discovery, analysis, and quantitation, as it relates to cancer biology.  ', ' Interested parties should use the link to apply and email their resume to Kristen Robinson at  krobinson@carisls.com .Thank you for applying!Your resume and application will be carefully reviewed against the requirements of our current open positions. Should your experience and skills match an available position, you will be contacted by a member of our recruiting team.Thank you for your interest in Caris Life Sciences.Sincerely,Caris Life Sciences', ' Excellent written and verbal data presentation skills and the ability to use software tools to produce high impact presentations of data, highlighting key takeaways. ', ' Drive for Results (Service, Quality, and Continuous Improvement) – Ensure procedures and processes are in place that lead to delivery of quality results and continually reassess their effectiveness to achieve continuous improvement. ', ' Teamwork – Commitment to the successful achievement of team and organizational goals through a desire to participate with and help other members of the team. ', ' Collaborate with other Research Scientists and Associates to design and conduct experiments, collect data and analyze results in support of department project development objectives. ', ' For proteomic data processing positions: desire experience with vender specific proteomic data analysis software platforms, as well as third-party software platforms such as Max Quant, Byonic, Skyline, and Scaffold. Knowledge and experience with programing platforms such as R (R Studio), and other informatics tools such as MS Stats is a plus. ', ' Good business judgment and ability to align scientific goals with business objectives. ', ' Experience and extensive knowledge in the mass spec-based proteomics field of science, with an emphasis on protein biomarker discovery, analysis, and quantitation, as it relates to cancer biology. ', ' Ph.D. in chemistry-related or biology-related sciences. ', ' Assist in the preparation of scholarly articles for publication. Present results of independent research; write reports/summaries for internal communications as well as patents and complete scientific papers for peer reviewed journals, publishing abstracts, manuscripts, or industry requirements. ', ' Detail oriented with ability to capture and record complex scientific data accurately and reliably. ', ' May perform reviews of analytical data for acceptability of calibration, control values, response curve characteristics and quantitative limits. Provide reports and documentation for quality control performance of instruments and data sets. ', ' Operate, develop methods, and maintain automated platforms for sample preparation. ', ' For proteomic sample preparation positions: desire experience with various standard in-solution and in-gel proteomic sample prep protocols for bottom-up mass spec data collection, as well as with alternative workflows, such as FASP, S-trap, and automated systems such as the Bravo. Desire experience with mass-tag labeling protocols using TMT or ITRAQ, or SILAC. ', ' Outstanding understanding of scientific process, including hypothesis development, experimental design, selection of controls, etc. Ability to weigh the relative pros and cons of alternative experimental designs and make decisions based on a thorough understanding of the potential problems. ', ' Follow all standard operating procedures, safety and security policies and prescribed practices, policies and guidelines; use Standard Operating Procedures (SOP) manual as reference to support work performed. Completes all necessary paperwork related to job duties. ', 'Requirements', ' Operate, maintain, and calibrate LC-MS/MS systems. Diagnose and troubleshoot instrument problems and schedule repair service as required. ', 'Knowledge, Skills, and Experience', ' Accepts other duties as assigned. ', ' Maintain laboratory records in accordance with company standards. ', 'Job Responsibilities', ' Ability to problem solve independently and in collaboration with others. ', ' High level of knowledge with respect to the mathematical methods and theories underlying the various concepts and strategies used for processing mass spec proteomic acquired data. ', ' Communication – Proficient verbal and written communication skills. Willingness to share and receive information and ideas from all levels of the organization in order to achieve the desired results. ', 'Education, Certification/Licensure, and/or Experience', 'Position Summary: ', ' Excellent protein biochemistry or molecular biology skills and experience with implementing biological sample preparation strategies for downstream mass spec analysis. ', ' Ability to develop and deliver complex directions and develop, deliver and defend complicated scientific project plans. ', ' Excellent analytical chemistry skills with a working knowledge and hands-on experience developing bottom-up and top-, middle-down proteomic data collection methods using nano- and microliter flow LC-MS systems. ', ' Process mass spec proteomic data using established workflows for biomarker discovery and relative and absolute quantitation; for bottom-up, middle- and top-down data analysis; using data dependent, data independent, PRM\\MRM acquired data. ']",Associate,Full-time,Other,Biotechnology,2020-11-05 11:32:32
Data Engineer - 20-04016,Infinity Consulting Solutions,"New York, NY",6 hours ago,109 applicants,"['Job Requirements', 'Assist representing CDO on Internal Audit reviews for data quality audits.', 'Strong experience in data related activities (data governance, metadata, data management, data standards, data structures, data aggregation, business requirements)', 'Strong Excel experience', 'Responsibilities:', 'Perform data quality activities including data quality rule creation, edit checks, identification of issues, root cause analysis, value case analysis, remediation planning and 2nd line of defense monitoring etc.', 'Prepare Data Quality Training material for data stewards, Data Quality team and general bank training.', 'Produce Data Quality Assessment reports through interaction with the business consumers.', '3&plus; years in Data Quality related leadership roles or Content-centric/ data-centric roles', 'Provide guidance to the functional area owners, IT leads and data stewards in resolving conflicts. i.e., choosing authoritative sources, business definitions, roles and responsibilities etc. ', 'Perform complex analyses to support business decisions, as well as provide feedback and recommendations to the management regarding results.', 'Specific skills in visualization tool experience implementing Tableau, and SSRS highly desired', 'Drive improvements to maximize value of data quality (e.g. drive changes to have access to required metadata to maximize impact of data quality, quantify the cost/impact of poor data quality).', ""Become the team's technical expert for Data Quality report automation, identification, and data issue visualization."", 'Work with CDO management to introduce tools and capabilities to enhance the Data Quality Program.', ""Bachelor's Degree or above, Master's Degree preferred"", 'Provide data analytics expertise, demonstrate strength working with large data sets outside of Excel. Comfortable managing 200k records with over 200 columns plus across multiple data sets', "" Bachelor's Degree or above, Master's Degree preferred 5&plus; years of professional work experience in the financial services industry focused on data 5&plus; years of strong working knowledge using SQL and Data Quality tools Strong Excel experience 3&plus; years in Data Quality related leadership roles or Content-centric/ data-centric roles Python is a plus Strong experience in data related activities (data governance, metadata, data management, data standards, data structures, data aggregation, business requirements) Specific skills in visualization tool experience implementing Tableau, and SSRS highly desired"", 'Job Description', 'Coordinate Data Quality activities and data remediation activities with the Data Governance team.', "" Produce Data Quality Assessment reports through interaction with the business consumers. Drive improvements to maximize value of data quality (e.g. drive changes to have access to required metadata to maximize impact of data quality, quantify the cost/impact of poor data quality). Perform data quality activities including data quality rule creation, edit checks, identification of issues, root cause analysis, value case analysis, remediation planning and 2nd line of defense monitoring etc. Perform complex analyses to support business decisions, as well as provide feedback and recommendations to the management regarding results. Maintain and enhance Data Quality Score Dashboard. Prepare Data Quality Training material for data stewards, Data Quality team and general bank training. Coordinate Data Quality activities and data remediation activities with the Data Governance team. Work with CDO management to introduce tools and capabilities to enhance the Data Quality Program. Assist representing CDO on Internal Audit reviews for data quality audits. Provide data analytics expertise, demonstrate strength working with large data sets outside of Excel. Comfortable managing 200k records with over 200 columns plus across multiple data sets Become the team's technical expert for Data Quality report automation, identification, and data issue visualization. Provide guidance to the functional area owners, IT leads and data stewards in resolving conflicts. i.e., choosing authoritative sources, business definitions, roles and responsibilities etc.  "", '5&plus; years of strong working knowledge using SQL and Data Quality tools', 'Python is a plus', 'Maintain and enhance Data Quality Score Dashboard.', '5&plus; years of professional work experience in the financial services industry focused on data']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Assay Development Specialist,The Jackson Laboratory,"Farmington, CT",1 day ago,Be among the first 25 applicants,"['', ' Explore new assay and technology options that build on the current and anticipated assay portfolio of the CLIA lab ', ' Bachelor’s or Master’s degree in Molecular Biology, Genetics, Cancer Genomics, Bioinformatics, Biotechnology, or relevant discipline  At least three years’ hands-on laboratory experience and knowledge of molecular technologies, such as NGS, qPCR, ddPCR, RT-PCR, Sanger, microarrays, nucleic acid extraction, nucleic acid quantification, and others  At least two years’ experience with bioinformatics tools and approaches for NGS analysis, particularly related to human genome variation and gene expression  Background in project design, including assay development and assay optimization. Experience in a regulated clinical laboratory preferred  Ability to conduct and perform projects in a highly cooperative team environment  Attention to detail, safety, good laboratory practice, and good documentation practice  Excellent interpersonal, verbal, and written communication skills; strong organizational and analytical skills ', ' Work with CLIA operations team to deploy newly developed assays, including support for validation activities and on-going support ', ' At least three years’ hands-on laboratory experience and knowledge of molecular technologies, such as NGS, qPCR, ddPCR, RT-PCR, Sanger, microarrays, nucleic acid extraction, nucleic acid quantification, and others ', 'Responsibilities', ' Background in project design, including assay development and assay optimization. Experience in a regulated clinical laboratory preferred ', 'About Us', ' Conduct research projects to assess the performance of new approaches for genome characterization in a clinical diagnostic context including targeted sequencing, genotyping, and other approaches, with particular emphasis on oncology and virology application ', 'What do we have to offer?', ' Ability to conduct and perform projects in a highly cooperative team environment ', ' Develop formal research and evaluation plans and documentation to support developmental research project activities ', ' Excellent interpersonal, verbal, and written communication skills; strong organizational and analytical skills ', 'Our Values', 'Qualifications', ' Bachelor’s or Master’s degree in Molecular Biology, Genetics, Cancer Genomics, Bioinformatics, Biotechnology, or relevant discipline ', ' Attention to detail, safety, good laboratory practice, and good documentation practice ', ' Explore new assay and technology options that build on the current and anticipated assay portfolio of the CLIA lab  Develop formal research and evaluation plans and documentation to support developmental research project activities  Responsible for the efficient and quality execution of sample processing and data generation for the Assay Development Laboratory. This includes working with the Scientist to maintain all documentation required for operation under CLIA/CAP certification, including writing andreviewing SOPs as necessary and use of sample tracking systems in accordance with standard operating procedures  Conduct research projects to assess the performance of new approaches for genome characterization in a clinical diagnostic context including targeted sequencing, genotyping, and other approaches, with particular emphasis on oncology and virology application  Work with CLIA operations team to deploy newly developed assays, including support for validation activities and on-going support ', ' Responsible for the efficient and quality execution of sample processing and data generation for the Assay Development Laboratory. This includes working with the Scientist to maintain all documentation required for operation under CLIA/CAP certification, including writing andreviewing SOPs as necessary and use of sample tracking systems in accordance with standard operating procedures ', ' At least two years’ experience with bioinformatics tools and approaches for NGS analysis, particularly related to human genome variation and gene expression ']",Entry level,Part-time,Other,Research,2020-11-05 11:32:32
AWS Data Engineer - Full Time,Cognizant,"Peoria, IL",4 hours ago,28 applicants,"['', 'Experience writing in ETL in AWS using S3, EMR and EC2 or AWS GLUE', 'Developing software applications using relational and NoSQL databases.', 'Must demonstrate solid knowledge of data structures and algorithms.', 'Position Qualifications', 'Data stores such as Redshift and Snowflake', 'Cognizant is an Equal Opportunity Employer M/F/D/V. ', 'AWS Data Engineer – Full Time', 'Cognizant is an Equal Opportunity Employer M/F/D/V', 'Designing, developing, deploying and maintaining software at scale using Java and Spark ', 'About Cognizant', 'Debugging and maintaining software in Linux or UNIX platforms.', ""Location: Peoria, Illinois**You must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.*Position QualificationsDeploying and maintaining software using public clouds such as AWS.Designing, developing, deploying and maintaining software at scale using Java and Spark Developing software applications using relational and NoSQL databases.Experience writing in ETL in AWS using S3, EMR and EC2 or AWS GLUEData stores such as Redshift and SnowflakeDebugging and maintaining software in Linux or UNIX platforms.Must demonstrate solid knowledge of data structures and algorithms.Company DescriptionCognizant is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant, a member of the NASDAQ-100, is ranked 205 on the Fortune 500 and is consistently listed among the most admired companies in the world.Cognizant is an Equal Opportunity Employer M/F/D/V. Cognizant is committed to ensuring that all current and prospective associates are afforded equal opportunities and treatment and a work environment free of harassment.Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.Employee Status : Full Time EmployeeShift : Day JobTravel : NoJob Posting : Oct 01 2020About CognizantCognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information."", 'Company Description', 'Deploying and maintaining software using public clouds such as AWS.', 'Deploying and maintaining software using public clouds such as AWS.Designing, developing, deploying and maintaining software at scale using Java and Spark Developing software applications using relational and NoSQL databases.Experience writing in ETL in AWS using S3, EMR and EC2 or AWS GLUEData stores such as Redshift and SnowflakeDebugging and maintaining software in Linux or UNIX platforms.Must demonstrate solid knowledge of data structures and algorithms.', 'About AI & Analytics']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Big Data Engineer,Quicken Loans,"Detroit, MI",7 hours ago,155 applicants,"['', 'Develop ELT processes from various data repositories and APIs across the enterprise, ensuring data quality and process efficiencyDevelop data processing scripts using SparkDevelop relational and NoSQL data models to help conform data to meet users’ needs using Hive and HBaseIntegrate platform into the existing enterprise data warehouse and various operational systemsDevelop administration processes to monitor cluster performance, resource usage, backup and mirroring to ensure a highly available platformAddress performance and scalability issues in a large-scale data lake environmentProvide big data platform support and issue resolutions to Data Scientists and fellow engineers', 'Develop administration processes to monitor cluster performance, resource usage, backup and mirroring to ensure a highly available platform', 'Responsibilities', 'Provide big data platform support and issue resolutions to Data Scientists and fellow engineers', '2 years of experience with relational and NoSQL databases, including modeling and writing complex queries', '2 years of experience with Hadoop distribution and ecosystem tools such as Hive, Spark, NiFi and Oozie', '2 years of experience developing batch and streaming ETL processes', 'Address performance and scalability issues in a large-scale data lake environment', 'Develop relational and NoSQL data models to help conform data to meet users’ needs using Hive and HBase', 'Integrate platform into the existing enterprise data warehouse and various operational systems', 'Requirements', ""Master's degree in computer science, software engineering or a closely related field2 years of experience with Hadoop distribution and ecosystem tools such as Hive, Spark, NiFi and Oozie2 years of experience developing batch and streaming ETL processes2 years of experience with relational and NoSQL databases, including modeling and writing complex queriesProficiency in at least one programming language, such as Python or JavaExperience with Linux system administration, scripting and basic network skillsExcellent communication, analytical and problem-solving skills"", 'Who We Are', ""Master's degree in computer science, software engineering or a closely related field"", 'Develop data processing scripts using Spark', 'Experience with Linux system administration, scripting and basic network skills', 'Excellent communication, analytical and problem-solving skills', 'Proficiency in at least one programming language, such as Python or Java', 'Develop ELT processes from various data repositories and APIs across the enterprise, ensuring data quality and process efficiency']",Entry level,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Senior Scientific Researcher - In vitro Human Brain Modeling,Genentech,"South San Francisco, CA",9 hours ago,Be among the first 25 applicants,"['', 'Job Facts', 'SCHEDULE', 'The Position', 'JOB TYPE', 'Who We Are', 'in vitro', 'JOB FUNCTION', 'Research COMPANY/DIVISION']",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
"Product Manager, AI/Machine Learning",C3.ai,"Redwood City, CA",6 hours ago,115 applicants,"['', 'Define functional requirements, develop detailed product specifications and associated project work plans for C3.ai Platform AI/ Machine Learning features and key enhancements requests', 'This is an individual contributor role, that focuses chiefly on customers, feature adoption, and market differentiation.', 'Bachelor of Science in Computer Science, Engineering, Statistics, or similar field and Master of Science or Business Administration degrees', 'Experience working in a customer-facing role as a product or program manager, technical product evangelist, or a data scientist', 'Effectively and proactively communicate with customers and build a trusted advisor relationship', ' Competitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people. ', 'Lead go-to-market planning and ensure successful product launches and customer adoption', '5+ years of work experience, with applied experience in AI/ Machine Learning software', 'Regular travel (25+%) to customer sites is required', 'Requirements', 'Mentor and provide expert guidance to data scientists and business leads from customer teams on C3 AI Suite capabilities', 'Your Responsibilities', 'Competitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people.', 'Hands-on experience with modern machine learning libraries, frameworks, and technologies', ' Effectively and proactively communicate with customers and build a trusted advisor relationship Mentor and provide expert guidance to data scientists and business leads from customer teams on C3 AI Suite capabilities Lead go-to-market planning and ensure successful product launches and customer adoption Define functional requirements, develop detailed product specifications and associated project work plans for C3.ai Platform AI/ Machine Learning features and key enhancements requests Regular travel (25+%) to customer sites is required ', ' Experience working in a customer-facing role as a product or program manager, technical product evangelist, or a data scientist 5+ years of work experience, with applied experience in AI/ Machine Learning software Bachelor of Science in Computer Science, Engineering, Statistics, or similar field and Master of Science or Business Administration degrees Hands-on experience with modern machine learning libraries, frameworks, and technologies Excellent verbal and written communication and presentation skills ', 'Excellent verbal and written communication and presentation skills']",Entry level,Full-time,Product Management,Information Technology and Services,2020-11-05 11:32:32
"Scientist II, Biology",Amerit Consulting,"San Diego, CA",,N/A,"['', 'Effective analytical and problem-solving skills.', 'Work hours: 8 am-5 pm, 40 hours/weekOn-site Position3 Must-haves on the resume: Bachelor degree, >2 lab experience, flow cytometry experienceScientist II is responsible for the development and evaluation of new reagents and testing new antibodies for use in flow cytometry applications. The Associate is responsible for routine, accurate, and timely testing of experimental samples according to standard protocols and operating procedures. The ability to execute scientific experiments of moderate scope is key. The successful candidate is expected to set up and execute these experiments, be detail-oriented, skilled at data analysis, and troubleshooting and will be accountable for preparing and presenting data at lab meetings. The Scientist II will prioritize daily workload and work with some supervision.The associate will participate in the analysis and review of data, report results, and complete all required documentation and database entries. In general, Scientist II will receive specific instructions and ongoing guidance regarding required tasks and expected results.Routine, accurate, and timely completion of all assigned experimental tests. Will be expected to efficiently prioritize individual workload.Independently analyze research data, solve problems with appropriate guidance, and effectively plan to follow up experiments. Responsible for the execution of experiments with varying complexity using multi-color Flow Cytometry.Analyze data using FCS Express and FlowJo software, report test results including completion of all required documentation and database entries as required by protocols or operating procedures.Expected under supervision to develop skills and exercise judgment in troubleshooting routine assigned test procedures and in recommending appropriate corrective actions.Keeps abreast of the basic requirements for compliance in your own area of work and complies with those requirements.Promotes a safe work environment. Participates in Environmental, Health, and Safety programs. Addresses corrective actions whenever a hazard is identified.Performs other related duties and assignments as required.', 'Requires a Bachelor’s degree in cell biology, immunology, or related scientific discipline and a minimum of 2-4 years of laboratory experience.Software: BD FACS Diva, FlowJo, FCS Express, and Microsoft Office Suite.Hands-on experience: designing, performing, and analyzing flow cytometry experiments, preferably on BD flow cytometers (LSRII, LSR Fortessa, Canto, Aria).Effective interpersonal skills must be able to work in a cross-functional team-oriented environment to achieve organizational goals.Effective written and oral communication skills.Demonstrated ability to follow established policies and procedures.Demonstrated ability to keep neat, accurate, and complete records.Effective analytical and problem-solving skills.', 'Demonstrated ability to follow established policies and procedures.', 'Routine, accurate, and timely completion of all assigned experimental tests. Will be expected to efficiently prioritize individual workload.', 'Software: BD FACS Diva, FlowJo, FCS Express, and Microsoft Office Suite.', 'Requires a Bachelor’s degree in cell biology, immunology, or related scientific discipline and a minimum of 2-4 years of laboratory experience.', '***3 Must-haves on the resume: Bachelor degree, >2 lab experience, flow cytometry experience***', 'Independently analyze research data, solve problems with appropriate guidance, and effectively plan to follow up experiments. Responsible for the execution of experiments with varying complexity using multi-color Flow Cytometry.', 'Promotes a safe work environment. Participates in Environmental, Health, and Safety programs. Addresses corrective actions whenever a hazard is identified.', 'Performs other related duties and assignments as required.', 'Work hours: 8 am-5 pm, 40 hours/week', 'Scientist II is responsible for the development and evaluation of new reagents and testing new antibodies for use in flow cytometry applications. ', 'Job Requirement:', 'Job Description:', 'Expected under supervision to develop skills and exercise judgment in troubleshooting routine assigned test procedures and in recommending appropriate corrective actions.', 'Demonstrated ability to keep neat, accurate, and complete records.', 'Position: Scientist II, Biology', 'Keeps abreast of the basic requirements for compliance in your own area of work and complies with those requirements.', 'The Associate is responsible for routine, accurate, and timely testing of experimental samples according to standard protocols and operating procedures. The ability to execute scientific experiments of moderate scope is key. ', 'Pay Rate: $25/hr - $31/hr (depending on experience)', '3 Must-haves on the resume: Bachelor degree, >2 lab experience, flow cytometry experience', 'On-site Position', 'Duration: up to 12 Months contract', 'Location: San Diego CA 92121', 'Analyze data using FCS Express and FlowJo software, report test results including completion of all required documentation and database entries as required by protocols or operating procedures.', 'Effective interpersonal skills must be able to work in a cross-functional team-oriented environment to achieve organizational goals.', 'Hands-on experience: designing, performing, and analyzing flow cytometry experiments, preferably on BD flow cytometers (LSRII, LSR Fortessa, Canto, Aria).', 'The successful candidate is expected to set up and execute these experiments, be detail-oriented, skilled at data analysis, and troubleshooting and will be accountable for preparing and presenting data at lab meetings. The Scientist II will prioritize daily workload and work with some supervision.', 'Effective written and oral communication skills.', 'Relocation Expenses/ Assistance: NO', 'The associate will participate in the analysis and review of data, report results, and complete all required documentation and database entries. In general, Scientist II will receive specific instructions and ongoing guidance regarding required tasks and expected results.']",Associate,Contract,Research,Biotechnology,2020-11-05 11:32:32
Clinical Performance Analyst Senior,Banner Health,"Phoenix, AZ",9 hours ago,Be among the first 25 applicants,"['', ' Develop a strong relationship with technology partners and collaborate in several areas, including application design, system optimization, programming complex models, transferring large data feeds, and staying current on emerging technology related to all systems.', 'Position Summary', 'Additional Related Education And/or Experience Preferred.', 'Minimum Qualifications', 'Preferred Qualifications', ' Generate analyses / models that will drive Banner to identify new opportunities and risk-factors with optimal clinical pathways to drive patient outcomes, across the full continuum of patient care. Conducts extensive predictive modeling and data mining. Develop a strong relationship with technology partners and collaborate in several areas, including application design, system optimization, programming complex models, transferring large data feeds, and staying current on emerging technology related to all systems. Establish and define processes, documentation and standards for data quality, and provide expert advice to end users on data access to ensure adherence to critical operating standards of care. Partner across continuum of care and various functional areas to understand internal customer needs related to service excellence, including but not limited to analytical, technology and automated reporting needs and determine the appropriate course of action, and make recommendations in an actionable format including to senior management, to achieve desired business results. Facilitate cross-functional teams and/or leads projects with regional or company-wide scope to implement system or policy changes, determine policies and manage process improvement and redesign. This may also include providing oversight, general work direction or leadership to individuals on the team. Creates presentations and/or reports for management involving significant detailed analysis of multiple or highly complex data sources. Perform analysis of highly complex customer needs. Manages and supports the identification and research of new developments and uses of current systems and applications, as well as upgraded systems and applications to meet customer needs. Products may include, but are not limited to; online applications and complex reports. Maintain optimal operation of departmental applications in partnership with IT or external software vendor, as appropriate. This may include leading the implementation, maintenance, testing and/or functional design. Coordinate activities of any third party data or research vendors to manage quality and consistent reports, always looking for enhancements. Keeps current on industry, standard and regulatory/compliance issues within assigned areas. Provides system and analytic consultation on these issues to customers.', ' Partner across continuum of care and various functional areas to understand internal customer needs related to service excellence, including but not limited to analytical, technology and automated reporting needs and determine the appropriate course of action, and make recommendations in an actionable format including to senior management, to achieve desired business results.', ' Facilitate cross-functional teams and/or leads projects with regional or company-wide scope to implement system or policy changes, determine policies and manage process improvement and redesign. This may also include providing oversight, general work direction or leadership to individuals on the team. Creates presentations and/or reports for management involving significant detailed analysis of multiple or highly complex data sources.', ' Perform analysis of highly complex customer needs. Manages and supports the identification and research of new developments and uses of current systems and applications, as well as upgraded systems and applications to meet customer needs. Products may include, but are not limited to; online applications and complex reports.', ' Establish and define processes, documentation and standards for data quality, and provide expert advice to end users on data access to ensure adherence to critical operating standards of care.', 'Core Functions', ' Generate analyses / models that will drive Banner to identify new opportunities and risk-factors with optimal clinical pathways to drive patient outcomes, across the full continuum of patient care. Conducts extensive predictive modeling and data mining.', 'Department Name', 'Primary City/State', 'Work Shift', ' Keeps current on industry, standard and regulatory/compliance issues within assigned areas. Provides system and analytic consultation on these issues to customers.', 'Job Category', ' Maintain optimal operation of departmental applications in partnership with IT or external software vendor, as appropriate. This may include leading the implementation, maintenance, testing and/or functional design. Coordinate activities of any third party data or research vendors to manage quality and consistent reports, always looking for enhancements.']",Associate,Full-time,Business Development,Nonprofit Organization Management,2020-11-05 11:32:32
Research Professional 2,"Softpath System, LLC","Norwood, MA",1 hour ago,Be among the first 25 applicants,"['', 'Description', 'Highly Desired Skills', 'Responsibilities', 'Position Requirements']",Entry level,Full-time,Research,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Data Engineer / Tech Lead (Hands On),Hays,"Richmond, VA",22 hours ago,Be among the first 25 applicants,"['', 'A Technology Company is seeking a Data Engineer / Tech Lead (Hands On) in Richmond, VA.', 'Hays is an Equal Opportunity Employer.', '• Medical', '• Leadership Qualities', '• Vision', 'Visit the Hays Career Advice section to learn top tips to help you stand out from the crowd when job hunting.', '• AWS', 'Why Hays?', '• 401K', 'Skills & Requirements', '• 1+ years NoSQL (Prefers Amazon DynamoDB)', 'You will be working with a professional recruiter who has intimate knowledge of the Information Technology industry and market trends . Your Hays recruiter will lead you through a thorough screening process in order to understand your skills, experience, needs, and drivers. You will also get support on resume writing, interview tips, and career planning, so when there’s a position you really want, you’re fully prepared to get it.', 'Drug testing may be required; please contact a recruiter for more information.', '• Dental', '• Life Insurance ($20,000 benefit)', '• 5+ years PostgreSQL (looking for someone very strong in data)', 'Data Engineer / Tech Lead (Hands On) – Contract or CTP – Richmond, VA', 'The end client is unable to sponsor or transfer visas for this position; all parties authorized to work in the US without sponsorship are encouraged to apply.', 'Nervous about an upcoming interview? Unsure how to write a new resume?', 'Additionally, this position is a contract role where Hays offers you the opportunity to enroll in full medical, dental or vision benefits.']",Mid-Senior level,Full-time,Information Technology,Staffing and Recruiting,2020-11-05 11:32:32
Staff UX Design Researcher,GE Healthcare,"Chicago, IL",22 hours ago,Be among the first 25 applicants,"['', 'Understands the skills necessary for contributing to constructive conversations utilizing active listening and validating the information needs of stakeholders and users.', 'Asks questions appropriate to translating an abstract problem into a roadmap for identifying solutions', 'Lead constructive design critiques', 'Bachelor’s Degree in Cognitive or Experimental Psychology, Human Computer Interaction, Human Factors; or in “STEAM” Majors (Science, Technology, Engineering, Arts and Math); or equivalent experience', 'Pilots new ideas and processes that have not been utilized before.', '7+ years professional experience with Master’s Degree. 9+ years professional experience with Bachelor’s Degree.; or equivalent experience', 'Select and use appropriate design research methods to address design opportunities.', 'Propose design or product solutions based on research and synthesis outcomes; influence change', 'Any offer of employment is conditioned upon the successful completion of a background investigation and drug screen', 'Legal authorization to work in the U.S. is required. GE may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills. (If Visa Sponsorship is Yes)', 'Demonstrates a deep passion for learning and courage to push the boundaries of one’s own thinking.', 'Plan and conduct interview sessions with users and stakeholders, including executives.', 'Expresses technology options to collaborators on cross functional teams. Goes beyond merely suggesting design technologies and clearly articulates the rationale and benefit of design technology choices.', 'Works with cross-functional teams and cross-business teams and assist in driving broad-reaching solutions across the function / business.Influences change through others and begins to set a vision for future change; evangelizes the practice of interaction design to GE business leaders.Understands the skills necessary for contributing to constructive conversations utilizing active listening and validating the information needs of stakeholders and users.Demonstrates a deep passion for learning and courage to push the boundaries of one’s own thinking.Acts and decides appropriately when all available information may not be possible to obtainDemonstrates the ability to connect, extract information, and communicate with customer groupsAsks questions appropriate to translating an abstract problem into a roadmap for identifying solutionsPilots new ideas and processes that have not been utilized before.', 'Desired Characteristics', 'Demonstrates the ability to connect, extract information, and communicate with customer groups', 'Translates user-centered design requirements into technical implementations for projects. Continuously measures deliverables of self and team against scheduled commitments. Effectively balances different, competing objectives.', 'Bachelor’s Degree in Cognitive or Experimental Psychology, Human Computer Interaction, Human Factors; or in “STEAM” Majors (Science, Technology, Engineering, Arts and Math); or equivalent experience7+ years professional experience with Master’s Degree. 9+ years professional experience with Bachelor’s Degree.; or equivalent experience', 'Leadership', 'Sees patterns within industry issues. Demonstrates how UX provides solutions for internal/external customer challenges.', 'Takes various stakeholders through the design thinking process to frame a project.', 'Works to create an understanding of how individual people and things fit within larger structures (like systems or organizations), as well as the relationships between parts of a system and the system as a whole.', 'Must be willing to travel', 'Acts and decides appropriately when all available information may not be possible to obtain', 'Essential Responsibilities', 'Begin to lead evaluation of current and emerging design, technology, industry, and market trends', 'Understands the value of a rigorous and transparent decision-making process.', 'Influences change through others and begins to set a vision for future change; evangelizes the practice of interaction design to GE business leaders.', 'Structure user-centered research and work with a variety of teams through fieldwork to determine users physical, cognitive, social, emotional, and cultural needs. Research specialists must have proven experience in uncovering unmet user needs, and unpacking meaning from sometimes obscure and disparate findings.', 'Engage fully in conducting research. Design Researchers must be prepared to plan and lead user research in order to discover insights about people first hand.', 'Technical Expertise:', 'Help to facilitate teams through analysis and synthesis of user research, helping to distill the most important insights and link them together in frameworks, principles, and implications for design. Design researchers must be confident about leading teams and users through a range of research analysis and synthesis processes.', 'Provide leadership, research guidance and mentorship to team members; provide coaching on feedback gathering techniques.Frame, scope, and lead execution of design research projectsLead constructive design critiquesPropose design or product solutions based on research and synthesis outcomes; influence changeSelect and use appropriate design research methods to address design opportunities.Plan and conduct interview sessions with users and stakeholders, including executives.Research and evaluate emerging design, technology, and industry trends; champion new ideas as appropriate.Begin to lead evaluation of current and emerging design, technology, industry, and market trendsEngage fully in conducting research. Design Researchers must be prepared to plan and lead user research in order to discover insights about people first hand.Structure user-centered research and work with a variety of teams through fieldwork to determine users physical, cognitive, social, emotional, and cultural needs. Research specialists must have proven experience in uncovering unmet user needs, and unpacking meaning from sometimes obscure and disparate findings.Frame insights in a way that inspires design teams to develop imaginative and appropriate solutions.Help to facilitate teams through analysis and synthesis of user research, helping to distill the most important insights and link them together in frameworks, principles, and implications for design. Design researchers must be confident about leading teams and users through a range of research analysis and synthesis processes.Communicate design insights and opportunities throughout all phases of design. This includes delivering a quick but compelling inspiration to helping distill the most important insights and linking them together in frameworks or principles that inspire design.Compelling storytelling: A critical element of this role is to deliver insights about people and behavior - verbally and visually - in a way that generates empathy, emotion, and engagement from the design team as well as engineering, product management, marketing and others.', 'Must be willing to work out of an office located in Chicago, IL or Waukesha, WI', 'Research and evaluate emerging design, technology, and industry trends; champion new ideas as appropriate.', 'Creates, analyzes and manages projects that provide direct business benefit. Demonstrates detailed knowledge of business operations and strategic direction, including merger & acquisition opportunities.Sees patterns within industry issues. Demonstrates how UX provides solutions for internal/external customer challenges.Takes various stakeholders through the design thinking process to frame a project.Works to create an understanding of how individual people and things fit within larger structures (like systems or organizations), as well as the relationships between parts of a system and the system as a whole.', 'Conducts qualitative and quantitative research activities such as ethnographic studies and usability studies, including surveys (qualitative and quantitative) and overseeing the work of external research partners and agencies', 'Leads and recommends both short- and long-term research activities, contributing to the creation of a research planConducts qualitative and quantitative research activities such as ethnographic studies and usability studies, including surveys (qualitative and quantitative) and overseeing the work of external research partners and agenciesCreates and communicates research artifacts, findings, reports, and recommendations with stakeholdersParticipates in planning of research topics and usability tests and contributes to the analysis and synthesis of research findingsContributes to management of usage analytics and Voice of the Customer solutions, mining usage data, and communicating findings to stakeholdersHigh attention to detail; extremely strong written and verbal communication skillsDeep knowledge of research tools and survey, acquisition tools', 'GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable).', 'Frame, scope, and lead execution of design research projects', 'Communicate design insights and opportunities throughout all phases of design. This includes delivering a quick but compelling inspiration to helping distill the most important insights and linking them together in frameworks or principles that inspire design.', 'Leads and recommends both short- and long-term research activities, contributing to the creation of a research plan', 'Compelling storytelling: A critical element of this role is to deliver insights about people and behavior - verbally and visually - in a way that generates empathy, emotion, and engagement from the design team as well as engineering, product management, marketing and others.', 'Works with cross-functional teams and cross-business teams and assist in driving broad-reaching solutions across the function / business.', 'Participates in planning of research topics and usability tests and contributes to the analysis and synthesis of research findings', 'Job Description', 'Qualifications/Requirements', 'Relocation Assistance Provided: ', 'Personal Attributes', 'Contributes to management of usage analytics and Voice of the Customer solutions, mining usage data, and communicating findings to stakeholders', 'Creates, analyzes and manages projects that provide direct business benefit. Demonstrates detailed knowledge of business operations and strategic direction, including merger & acquisition opportunities.', 'Keeps participants focused on task and end process. Guides participation to include all present; solicits information about absent stakeholders.', 'Frame insights in a way that inspires design teams to develop imaginative and appropriate solutions.', 'Additional Eligibility Qualifications', 'Deep knowledge of research tools and survey, acquisition tools', 'Legal authorization to work in the U.S. is required. GE may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills. (If Visa Sponsorship is Yes)Any offer of employment is conditioned upon the successful completion of a background investigation and drug screenMust be willing to travelMust be willing to work out of an office located in Chicago, IL or Waukesha, WI', 'Translates user-centered design requirements into technical implementations for projects. Continuously measures deliverables of self and team against scheduled commitments. Effectively balances different, competing objectives.Keeps participants focused on task and end process. Guides participation to include all present; solicits information about absent stakeholders.Expresses technology options to collaborators on cross functional teams. Goes beyond merely suggesting design technologies and clearly articulates the rationale and benefit of design technology choices.Understands the value of a rigorous and transparent decision-making process.', 'Provide leadership, research guidance and mentorship to team members; provide coaching on feedback gathering techniques.', 'In This Role, You Will', 'Creates and communicates research artifacts, findings, reports, and recommendations with stakeholders', 'Business Acumen', 'High attention to detail; extremely strong written and verbal communication skills']",Associate,Full-time,Information Technology,Hospital & Health Care,2020-11-05 11:32:32
"Senior Software Engineer, Data Infrastructure",EasyPost,"San Francisco, CA",12 hours ago,Be among the first 25 applicants,"['', ' Propose, research, prototype, and test new ideas ', ' Use data to understand the availability, reliability, and sustainability of our infrastructure ', ' Build and maintain the automation that manages data storage technologies ', ' Experience diagnosing and resolving complex multi-system performance problems. ', "" Establish standard methodologies for creating systems and datasets for the entire company's use "", ' Involvement in building and deploying large, complex distributed systems with an eye toward reliability ', ' Mentor fellow teammates on algorithms, data structures, design patterns, and best practices ', ' Strong desire to work in a fast-paced, start-up environment with multiple releases a day ', '  Competitive salary and equity   Comprehensive medical, dental, and vision and commuter benefits   Flexible work schedule and paid time off   Collaborative culture with a supportive team   The opportunity to make massive technical contributions at a fast-growing start-up   A great place to work with unlimited growth opportunities  ', ' Work with scalable API services based on ML and statistic models ', 'What You’ll Do', ' Collaborative culture with a supportive team ', ' A passion for working as part of a team, both communicating and collaborating with others ', ' Comfortable in a Polyglot environment ', ' Find new ways to improve data pipelines and workflow orchestration ', ' A great place to work with unlimited growth opportunities ', ' Evolve the pub-sub systems to provide service developers an easy-to-use, reliable and robust data ingestion and processing infrastructure ', '  Involvement in building and deploying large, complex distributed systems with an eye toward reliability   Comfortable in a Polyglot environment   Experience diagnosing and resolving complex multi-system performance problems.   3+ years exposure to utilizing an open-source stream-processing software platform   Work with scalable API services based on ML and statistic models   Strong desire to work in a fast-paced, start-up environment with multiple releases a day   A passion for working as part of a team, both communicating and collaborating with others  ', ' Flexible work schedule and paid time off ', ' 3+ years exposure to utilizing an open-source stream-processing software platform ', ' Comprehensive medical, dental, and vision and commuter benefits ', ' The opportunity to make massive technical contributions at a fast-growing start-up ', 'Data Privacy Notice For Job Applicants', 'About You', ' Enhance internal batch computation frameworks and workflow management to assist other teams in building out their data pipelines ', "" Work with data scientist to create highly scalable API services that's based on ML and statistic models "", 'What We Can Offer You', ' Work closely with other teams from across the organization ', ' Identify and document feature gaps, and design as well as implement solutions ', ""  Use data to understand the availability, reliability, and sustainability of our infrastructure   Establish standard methodologies for creating systems and datasets for the entire company's use   Work closely with other teams from across the organization   Identify and document feature gaps, and design as well as implement solutions   Propose, research, prototype, and test new ideas   Build and maintain the automation that manages data storage technologies   Mentor fellow teammates on algorithms, data structures, design patterns, and best practices   Evolve the pub-sub systems to provide service developers an easy-to-use, reliable and robust data ingestion and processing infrastructure   Build and maintain scalable and reliable data warehouse to serve both offline pipeline and business analytics   Find new ways to improve data pipelines and workflow orchestration   Work with data scientist to create highly scalable API services that's based on ML and statistic models   Enhance internal batch computation frameworks and workflow management to assist other teams in building out their data pipelines  "", ' Build and maintain scalable and reliable data warehouse to serve both offline pipeline and business analytics ', ' Competitive salary and equity ']",Associate,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Research Scientist, Immuno-Oncology",Gilead Sciences,"Foster City, CA",6 hours ago,52 applicants,"['', 'Strong motivation, independence and ability to think critically and creatively to resolve problems', 'May manage Research Associates or direct members of project teams in the initiation and execution of laboratory experimentation', 'Experience with the study design/execution of in vivo tumor models', 'Independently plan, design, execute, analyze, and interpret key in vitro and in vivo proof of concept studies to support novel I/O drug development effortsProactively evaluate new technologies and develop new assays to support early-stage discovery activities and build strong internal scientific expertiseManage multiple projects simultaneously and work cross-functionally with colleagues in the oncology, virology, protein engineering, chemistry, translational medicine, biomarker and clinical groupsPresent research findings and recommendations to senior staff and contribute to preparation of research reports, manuscripts, INDs, and patent filingsMay manage Research Associates or direct members of project teams in the initiation and execution of laboratory experimentation', 'Present research findings and recommendations to senior staff and contribute to preparation of research reports, manuscripts, INDs, and patent filings', 'Preferred Qualifications', 'integrity, inclusion, teamwork, accountability and excellence – are evident in everything we do.', 'Proactively evaluate new technologies and develop new assays to support early-stage discovery activities and build strong internal scientific expertise', 'PhD degree in immunology, cancer immunotherapy, cancer biology or cell biology with 0-3 years of experienceMinimum of 2 years post-doctoral experience focused on innovative research in immunology with proven achievements in industrial or academic settings is preferredDirect experience in general molecular and cell biology methods (e.g., Western blot)Direct experience in immunological assays and techniques, including multi-parameter flow cytometry and primary human and/or mouse tissue cultureAttention to detail with excellent organizational and record keeping skillsStrong motivation, independence and ability to think critically and creatively to resolve problemsExcellent communication and interpersonal skills and ability to integrate into a high-paced multidisciplinary environment', 'Minimum of 2 years post-doctoral experience focused on innovative research in immunology with proven achievements in industrial or academic settings is preferred', 'Experience in dendritic cell and/or NK cell biology', 'Manage multiple projects simultaneously and work cross-functionally with colleagues in the oncology, virology, protein engineering, chemistry, translational medicine, biomarker and clinical groups', 'For Current Gilead Employees And Contractors', 'Experience in dendritic cell and/or NK cell biologyDirect experience in research drug discovery in immuno-oncologyExperience with the study design/execution of in vivo tumor models', 'Research Scientist – Immuno-Oncology', 'For Jobs In The United States', 'Level is flexible and commensurate based on candidates experience', 'Required Qualifications', 'Excellent communication and interpersonal skills and ability to integrate into a high-paced multidisciplinary environment', 'Independently plan, design, execute, analyze, and interpret key in vitro and in vivo proof of concept studies to support novel I/O drug development efforts', 'Job Description', 'Direct experience in general molecular and cell biology methods (e.g., Western blot)', 'Attention to detail with excellent organizational and record keeping skills', 'Key Responsibilities', 'Direct experience in immunological assays and techniques, including multi-parameter flow cytometry and primary human and/or mouse tissue culture', 'in vivo', 'Direct experience in research drug discovery in immuno-oncology', 'in vitro', 'PhD degree in immunology, cancer immunotherapy, cancer biology or cell biology with 0-3 years of experience']",Not Applicable,Full-time,Research,Biotechnology,2020-11-05 11:32:32
UX Researcher Associate,Delta Dental Ins.,"Oakland, CA",4 hours ago,115 applicants,"['', '12 days starting vacation plus 12 holidays and your birthday off!', 'Work closely with design and product to understand the complexities of product challenges and related research questions.', 'Social responsibility and volunteer opportunities', 'Value customers and cultivate positive experiences: ', 'Technology allowance', 'Benefits And Perks', 'ABOUT Delta Dental', ""Bachelor's or Master’s degree in Anthropology, Human-Computer Interaction (HCI), Human Factors, Psychology, Sociology, or a related field or equivalent practical experience. "", 'Experience with iterative and agile enterprise framework or developing, delivering, and sustaining complex digital products.', 'Multiple medical insurance options: 100% paid or low cost premiums ', '12 days starting vacation plus 12 holidays and your birthday off!Multiple medical insurance options: 100% paid or low cost premiums 100% paid dental insurance100% paid vision insuranceOnsite gym and/or gym discount and fitness incentive Culture of learning: substantial tuition reimbursement to improve your skillsCareer growth: we love promoting from within Strong commitment to work/life balance Technology allowanceSocial responsibility and volunteer opportunities', 'Proficiency in evangelizing and communicating user research findings with cross-functional partners to drive impact.', 'Strong understanding of the strengths and shortcomings of different research methods, including when and how to apply them during the product development process.', 'Career growth: we love promoting from within ', 'Strong commitment to work/life balance ', 'Engage with stakeholders, product owners, engineers, content strategists, business owners, and other designers.', 'How You Will Make An Impact', 'At Delta Dental We', ""Bachelor's or Master’s degree in Anthropology, Human-Computer Interaction (HCI), Human Factors, Psychology, Sociology, or a related field or equivalent practical experience. 3 -5 years of relevant work experience within User Experience, Human-Computer Interaction, applied research setting, and/or product research and development.Experience with research design utilizing various methods including but not limited to usability studies, in-depth interviews, contextual inquiry, concept testing, and surveys.Relevant product research experience, an end-to-end, usability, in a generative or evaluative setting.Strong understanding of the strengths and shortcomings of different research methods, including when and how to apply them during the product development process.Proficiency in evangelizing and communicating user research findings with cross-functional partners to drive impact.Entrepreneurial, self-driven, growth mindset with a professional presence.Strong organizational and time management skills.Background in product interaction design or similar preferred.Experience utilizing user research and insights to inform design and content decisions.Experience with iterative and agile enterprise framework or developing, delivering, and sustaining complex digital products.Positive can-do collaborative attitude and motivation to deliver timely and high-quality work."", 'Work with the manager of design operations to continually evolve and standardize research toolkit.', 'Foster professional development:', 'Follow us @lifeatDDins on Instagram , lifeatDDins on Facebook , @lifeatDDins on Twitter ', 'Entrepreneurial, self-driven, growth mindset with a professional presence.', 'Communicate research insights concretely and intuitively for the greatest impact.', 'Note taking, scheduling, participant recruiting are essential basic skills for this role. ', 'Identify user research approach, priorities, and deliverables that address design goals and provide appropriate recommendations.', '3 -5 years of relevant work experience within User Experience, Human-Computer Interaction, applied research setting, and/or product research and development.', 'Strong organizational and time management skills.', 'Promote accountability, integrity and collaboration: ', 'Background in product interaction design or similar preferred.', 'Positive can-do collaborative attitude and motivation to deliver timely and high-quality work.', 'Onsite gym and/or gym discount and fitness incentive ', '100% paid dental insurance', 'Note taking, scheduling, participant recruiting are essential basic skills for this role. Utilize a repertoire of tools and techniques to gather insights and feedback regarding customers and product experiences.Work closely with design and product to understand the complexities of product challenges and related research questions.Identify user research approach, priorities, and deliverables that address design goals and provide appropriate recommendations.Engage with stakeholders, product owners, engineers, content strategists, business owners, and other designers.Communicate research insights concretely and intuitively for the greatest impact.Work with the manager of design operations to continually evolve and standardize research toolkit.Contribute to a thriving UX team with a strong growth mindset and appreciation for peer feedback.Planning and executing research.', 'What We Look For', 'Utilize a repertoire of tools and techniques to gather insights and feedback regarding customers and product experiences.', 'Relevant product research experience, an end-to-end, usability, in a generative or evaluative setting.', 'Experience with research design utilizing various methods including but not limited to usability studies, in-depth interviews, contextual inquiry, concept testing, and surveys.', 'Planning and executing research.', 'Experience utilizing user research and insights to inform design and content decisions.', 'Culture of learning: substantial tuition reimbursement to improve your skills', 'Contribute to a thriving UX team with a strong growth mindset and appreciation for peer feedback.', '100% paid vision insurance']",Associate,Full-time,Information Technology,Insurance,2020-11-05 11:32:32
Sr. User Researcher,Intuitive,"Sunnyvale, CA",7 hours ago,Be among the first 25 applicants,"['', ""Perform all aspects of research and implementation studies including study design, instrument development, data collection (both desktop and in the field) and management, quantitative and qualitative data analysis, reporting and dissemination, and communication with partners.Create actionable insights for improving products and services and their implementation based on results of internal and external research.Present results of user and implementation research throughout the organization.Serve as a member of a team that acts as a 'repository' of evidence-based user knowledge.Support the implementation of new technologies and systems to support user and implementation research.Reinforce a human-centered design approach across the organization."", 'Present results of user and implementation research throughout the organization.', 'Self-motivated.', 'Ability to work with and across various groups and levels of management within the organization, including other engineering groups, marketing, clinical engineering, and design. Excellent collaboration skills.', ""Serve as a member of a team that acts as a 'repository' of evidence-based user knowledge."", 'Support the implementation of new technologies and systems to support user and implementation research.', 'Superior ability to write accurate, clear, and concise protocols and reports in a timely manner.', 'Ability to travel internationally, as well as domestically (up to 40%).', 'Ability to conduct user research (e.g. development of user profiles, use case scenarios, journey maps) and implementation research (e.g. evaluating products and services in the field) in diverse populations demonstrated by a portfolio of designing and executing research studies.', 'BS in Human Factors Engineering (specialized in Organizational or Product Ergonomics), Health Services Research, Psychology, Anthropology or related field, or related field. MS preferred.', 'Perform all aspects of research and implementation studies including study design, instrument development, data collection (both desktop and in the field) and management, quantitative and qualitative data analysis, reporting and dissemination, and communication with partners.', 'Ability to collect, analyze and synthesize large quantities of qualitative and quantitative data using QDA software and statistical software; experience with e.g. NVivo, MAXQDA, atlas.ti, Stata, R, SPSS, Qualtrics a plus.', 'Roles And Responsibilities', 'Primary Function Of Position', 'BS in Human Factors Engineering (specialized in Organizational or Product Ergonomics), Health Services Research, Psychology, Anthropology or related field, or related field. MS preferred.5+ years of relevant user and/or implementation research experience specific to health care.Ability to conduct user research (e.g. development of user profiles, use case scenarios, journey maps) and implementation research (e.g. evaluating products and services in the field) in diverse populations demonstrated by a portfolio of designing and executing research studies.Ability to collect, analyze and synthesize large quantities of qualitative and quantitative data using QDA software and statistical software; experience with e.g. NVivo, MAXQDA, atlas.ti, Stata, R, SPSS, Qualtrics a plus.Superior ability to write accurate, clear, and concise protocols and reports in a timely manner.Excellent verbal communication and presentation skills.Strong problem solving skills and ability to guide complex projects in challenging environments.Ability to interface with customers and consultants in a highly professional manner.Ability to work with and across various groups and levels of management within the organization, including other engineering groups, marketing, clinical engineering, and design. Excellent collaboration skills.Self-motivated.Ability to travel internationally, as well as domestically (up to 40%).', 'Ability to interface with customers and consultants in a highly professional manner.', 'Reinforce a human-centered design approach across the organization.', 'Strong problem solving skills and ability to guide complex projects in challenging environments.', 'Skill/Job Requirements', 'Create actionable insights for improving products and services and their implementation based on results of internal and external research.', '5+ years of relevant user and/or implementation research experience specific to health care.', 'Excellent verbal communication and presentation skills.']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Researcher (Sr. User Experience Researcher),"Intelliswift Software, Inc.","Bellevue, WA",1 hour ago,Be among the first 25 applicants,"['', 'Primary Responsibilities']",Entry level,Full-time,Information Technology,Internet,2020-11-05 11:32:32
Senior Data Engineer ,"HireStarter, Inc.","Austin, Texas Metropolitan Area",2 hours ago,76 applicants,"['', '• Familiarity with a cloud provider, e.g. AWS, GCP, Azure (We use Azure)', 'As a Data Engineer, you will be working on projects that help bridge the gap between the engineering and analytics teams. As a member of the team, you will be expected to share knowledge, relentlessly problem solve, have a superior work ethic and be an excellent communicator in an easy-going environment. ', 'Responsibilities:', '• Optimize our search engine and help build relevancy models around results', 'Requirements:', '• Design monitoring around ingestion and processing tasks and develop runbooks in case of an outage.', '• Build systems with reusability and scalability in mind', '• Design and implement ingestion pipelines to handle and transform large amounts of structured and semi-structured data from a multitude of sources.', '• Experience building RESTful APIs for serving processed data', '• Collaborate with the technology and analytics teams on developing new conventions and processes.', '• Experience with Databricks', '• Experience with R', '• Write, optimize, and automate data processing tasks.', '• Experience with PostgreSQL, or a similar RBDMS', '• Experience with Airflow or Luigi', '• 3+ years of experience with Python', '• Knowledge of design patterns and software engineering best practices.', '• Experience with Elasticsearch', 'Ideally based in Austin or Nashville, but open to remote. No C2C. Unable to sponsor or transfer visas.', 'Bonus!']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Engineering Team Lead,Schneider,"Green Bay, WI",19 hours ago,Be among the first 25 applicants,"['', 'Medical, Dental, Vision, Prescription, Short Term Disability and Life Insurance, and wellness programs available to include smoking cessation & adoption benefits, flexible spending account', 'Experience with statistical software (R, Python, MATLAB, SPSS, SAS), data access/manipulation (SQL, pandas, dplyr) and NoSQL databases (MongoB, Cassandra, HBase) required; experience with cloud computation (AWS, Azure) highly desired.', 'Paid vacation, flex days and Holiday pay as well as a company matched 401K, fully funded Retirement and Profit Share plan', 'PhD degree in a quantitative discipline (Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering or Industrial Engineering) plus a minimum of\xa04 years of relevant work experience (data scientist / statistician / computational biologist / bioinformatician), including deep expertise and experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods, or Masters Degree plus a minimum of 6 years of relevant work experience\xa0\xa0\xa0Expert in designing and implementing mathematical optimization models using open source as well as commercial LP/IP solvers and/or advanced skills with predictive modeling using machine learning techniques and algorithms.\xa0Demonstrated ability to understand the uses and limitations of statistical and optimization methodologies to select the appropriate methodology to complete assignments.Able to understand and frame complex problems in a way that overcomes ambiguity and develop high performance innovative solutions that hands data imperfections.\xa0Experience articulating business questions and using mathematical techniques to arrive at an answer using data.\xa0Experience translating analysis results into business recommendations. Demonstrated ability to influence without authority and self-direction.Experience with statistical software (R, Python, MATLAB, SPSS, SAS), data access/manipulation (SQL, pandas, dplyr) and NoSQL databases (MongoB, Cassandra, HBase) required; experience with cloud computation (AWS, Azure) highly desired.Demonstrated proficiency with Java and/or Python, modeling interfaces such as ILOG Concert, DoCPLEX or Gurobipyn, one or more high level modeling languages such as AMPL, GAMS or MOSEL.\xa0\xa0', 'Performance based pay plan, paid weekly with hourly rate vs flat rate, referral rewards program', 'PhD degree in a quantitative discipline (Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering or Industrial Engineering) plus a minimum of\xa04 years of relevant work experience (data scientist / statistician / computational biologist / bioinformatician), including deep expertise and experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods, or Masters Degree plus a minimum of 6 years of relevant work experience\xa0\xa0\xa0', 'As an Associate you will enjoy:', 'Education reimbursement program plus individual development opportunities, active leadership involvement and more than 170 online personal development courses.', 'Ideal candidates will have:', 'About the role:', '• Set priorities for associates in accordance with stakeholder interest.\xa0Collaborate and communicate across departments to facilitate schedule adherence.\xa0', 'Demonstrated ability to influence without authority and self-direction.', 'Demonstrated proficiency with Java and/or Python, modeling interfaces such as ILOG Concert, DoCPLEX or Gurobipyn, one or more high level modeling languages such as AMPL, GAMS or MOSEL.\xa0\xa0', '• Stay up to date on current industry trends, technology offerings and best practices, and through participation in knowledge sharing, educate the team on the same to effectively tackle current projects.\xa0', '•Provide project leadership and technical direction to the development of engineering models, services and capabilities that support the achievement of line of business and enterprise goals and objectives.\xa0', 'Schneider is seeking a driven Engineering\xa0Team Leader\xa0as both a leader of a team and a hands-on practitioner responsible for organizational thought leadership in Engineering.\xa0This includes proactively evaluating new technologies and identifying industry best practices, while leveraging our existing process and technological capabilities across the enterprise to deliver results that consistently meet enterprise strategic objectives.\xa0As a supervisor, the Engineering Team Leader provides technical oversight, guidance and assistance to other team members as required to meet deadlines and budgets.\xa0As a hands-on practitioner\xa0the\xa0Engineering\xa0Team Leader\xa0will perform the skills and responsibilities of the appropriate technical Lead position.', 'Schneider offers a clean, safe working environment, with company paid training, safety shoe program and uniforms provided by the company', 'Able to understand and frame complex problems in a way that overcomes ambiguity and develop high performance innovative solutions that hands data imperfections.\xa0Experience articulating business questions and using mathematical techniques to arrive at an answer using data.\xa0Experience translating analysis results into business recommendations. ', '• Proactively seek out and identify opportunities within and across the Tech organization and/or within a specific area of the business.\xa0Leverage broad cross functional business knowledge to produce results that improve business performance and help gain buy-in from the internal customers. ', 'Expert in designing and implementing mathematical optimization models using open source as well as commercial LP/IP solvers and/or advanced skills with predictive modeling using machine learning techniques and algorithms.\xa0Demonstrated ability to understand the uses and limitations of statistical and optimization methodologies to select the appropriate methodology to complete assignments.']",Associate,Full-time,Engineering,Transportation/Trucking/Railroad,2020-11-05 11:32:32
2021 BSMH Intern Program: HR - Strategy and Well Being Intern,Bon Secours Mercy Health,"Cincinnati, OH",20 hours ago,Be among the first 25 applicants,"['', 'Professionalism & Integrity', 'Accepts personal responsibility', 'Currently pursuing a degree in Data Analytics, Business Analytics, Mathematics, Data Science, or an Analytical/Mathematical related degreeSenior/Graduate preferredFamiliarity with Python/R programming languageProficient in Microsoft Office suite – specifically Excel, Word, PowerPoint, OutlookGood communication (verbal, written, and listening)Strong interpersonal and presentations skillsSelf-motivated, capable of taking initiative, successfully handle and prioritize multiple competing priorities, and effectively manage deadlinesAbility to work effectively in a team environment and have strong rapport with the leaders and colleaguesAbility to work independentlyStrong analytical skillsStrong time management and organization skills', 'Technical Skills', 'Delivers a high-quality work product ensuring its completeness and organization is logicalUses effective time management skills to complete project work within specified deadlinesPerforms thorough self-reviews of workMeets assigned deadlines while performing assigned tasksKeeps supervisor informed on a routine basis as to the status of various projects, particularly when a delay or problem arises', 'Currently pursuing a degree in Data Analytics, Business Analytics, Mathematics, Data Science, or an Analytical/Mathematical related degree', 'Meets assigned deadlines while performing assigned tasks', 'Assist team with predictive analytics & forecasting projects', 'Scheduled Weekly Hours', 'Strong time management and organization skills', 'Requests challenging assignments to ensure continuous learning', 'Exhibits professional behavior, integrity and ethical behavior consistently', 'Delivers a high-quality work product ensuring its completeness and organization is logical', 'Hours: ', 'Qualifications', 'All applicants will receive consideration for employment without regard to race, color, national origin, religion, sex, sexual orientation, gender identity, age, genetic information, or protected veteran status, and will not be discriminated against on the basis of disability. If you’d like to view a copy of the affirmative action plan or policy statement for ', 'Displays positive attitude and work ethicAdheres to Mission and Mercy Health’s Core ValuesExhibits professional behavior, integrity and ethical behavior consistentlyAccepts personal responsibility', 'Basic working knowledge of Microsoft Office Suite', 'Demonstrates ability to work well with others and builds positive relationships with team membersRepresents own interests while working for the good of the team', 'Work with R/Python (Knowledge of R/Python programming language preferred)', 'Demonstrates ability to adjust communication style of the audience', 'Bon Secours Mercy Health!', 'Forecast monthly system wide turnover, based on historical data and present insights for different demographics', 'Comprehensive, affordable medical, dental and vision plans', 'Keeps supervisor informed on a routine basis as to the status of various projects, particularly when a delay or problem arises', 'Delivers communications, both oral and written, that are timely, clear and concise', 'Educational Assistance', 'Responsibilities', 'Applies effective listening skills', 'Develops understanding of projects and how tasks relate to the “big picture”', 'Senior/Graduate preferred', 'Displays positive attitude and work ethic', 'We’ll Also Reward Your Hard Work With', 'Ability to work effectively in a team environment and have strong rapport with the leaders and colleagues', 'Life insurance w/AD&D', 'Uses effective time management skills to complete project work within specified deadlines', 'Proficient in Microsoft Office suite – specifically Excel, Word, PowerPoint, Outlook', 'Work Shift', 'Basic programming skills', 'recruitment@mercy.com', 'Thank you for considering a career at ', 'Good communication (verbal, written, and listening)', 'Represents own interests while working for the good of the team', 'Takes initiative and is willing to attempt new tasks/responsibilities. Asks questions when unclear of a concept or ideaRequests challenging assignments to ensure continuous learningActively solicits feedback on performance', 'About Bon Secours Mercy Health', 'HR – Data Analytics Internship ', 'Location: ', 'Support statistical work for various survey analyses', 'Utilize Machine learning models and data visualization tools to make binary predictions', 'An employer-matched 403(b) for those who qualify', 'Ability to work independently', 'Work with our data scientist to support current projects', 'Familiarity with Python/R programming language', 'Data cleanup and modeling', 'Provide analytical insights for various HR programs (eg: Student Loan Forgiveness Program)', 'Adheres to Mission and Mercy Health’s Core Values', 'Comprehensive, affordable medical, dental and vision plansPrescription drug coverageFlexible spending accountsLife insurance w/AD&DAn employer-matched 403(b) for those who qualifyPaid time offEducational AssistanceAnd much more', 'Actively solicits feedback on performance', 'Paid time off', 'Dates: ', 'Strong interpersonal and presentations skills', 'Takes initiative and is willing to attempt new tasks/responsibilities. Asks questions when unclear of a concept or idea', 'Basic programming skillsBasic working knowledge of Microsoft Office SuiteDevelops understanding of projects and how tasks relate to the “big picture”Demonstrates ability to research, analyze and conclude on issuesAsks the right questions to garner an appropriate level of understanding', 'Communication', 'Focus on Quality & Workload Management', 'Delivers communications, both oral and written, that are timely, clear and conciseApplies effective listening skillsDemonstrates ability to adjust communication style of the audience', 'Performs thorough self-reviews of work', 'Flexible spending accounts', 'Accountabilities', 'Perform ad-hoc queries', 'Create decision trees, regressions, and random forests', 'Prescription drug coverage', ', which are Affirmative Action and Equal Opportunity Employers, please email recruitment@mercy.com. If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact The Talent Acquisition Team at ', 'Teamwork', 'Self-motivated, capable of taking initiative, successfully handle and prioritize multiple competing priorities, and effectively manage deadlines', 'Demonstrates ability to work well with others and builds positive relationships with team members', 'Personal Effectiveness', 'Department', 'Strong analytical skills', 'Demonstrates ability to research, analyze and conclude on issues', 'And much more', 'Other Information', 'Asks the right questions to garner an appropriate level of understanding', 'Data cleanup and modelingAssist team with predictive analytics & forecasting projectsSupport statistical work for various survey analysesWork with our data scientist to support current projectsCreate decision trees, regressions, and random forestsWork with R/Python (Knowledge of R/Python programming language preferred)Forecast monthly system wide turnover, based on historical data and present insights for different demographicsUtilize Machine learning models and data visualization tools to make binary predictionsProvide analytical insights for various HR programs (eg: Student Loan Forgiveness Program)Perform ad-hoc queries']",Not Applicable,Full-time,Education,"Health, Wellness and Fitness",2020-11-05 11:32:32
Senior Market Researcher,Panasonic North America,"Denver, CO",6 hours ago,88 applicants,"['', 'Casual Dress Code', 'Excellent analytical, decision-making, project management, written/verbal communication, and presentation skills;', 'Education & Experience:', 'Excellent analytical, decision-making, project management, written/verbal communication, and presentation skills;Strong business acumen;Self-starter—always looking for opportunities to improve something and will jump in to fix things without being asked;An expert storyteller with the ability to influence business decisions;An independent, strategic, and creative thinker who is a strong team player (no job is too small or too large) and willing to take on additional responsibilities as necessary;Flourishes in ambiguity;Exceptional interpersonal and communication skills;Ability to think both analytically and creatively—balance left and right brain—people person as well as data person.', 'Competitive compensation packageComprehensive benefitsPet InsurancePaid Parental Care LeaveEmployee Referral ProgramEducational AssistanceFlexible Work ProgramVolunteer time OffCasual Dress CodeTotal Well Being Program', 'Flourishes in ambiguity;', 'Create clear and compelling market research storylines that are strategically sound and emotionally provocative to inform business strategy, the development of product roadmaps, enhance marketing efforts, drive engineering efforts, and provide early warning for strategic course corrections;Develop a deep understanding of the transportation landscape including, but not limited to, products, markets, competitors, etc., and develop frameworks to synthesize this understanding into insights for the business, e.g. segmentation models, competitive analysis, etc.Lead innovation and design workshops with cross-functional partners to convert insights into action.Develop comprehensive research plans designed to explore, and subsequently validate, business or product opportunities.Identify and explore white space opportunities in the connected mobility space.', 'Exceptional interpersonal and communication skills;', 'Employee Referral Program', ' Watch this video', 'Competitive compensation package', 'Volunteer time Off', 'An expert storyteller with the ability to influence business decisions;', 'Other Requirements', 'Paid Parental Care Leave', 'Educational Assistance', 'Minimum of 5 years of experience conducting market research in a technology-related field;', 'Self-starter—always looking for opportunities to improve something and will jump in to fix things without being asked;', 'Majority of team sits in Denver, Colorado. Will consider remote candidates.Travel for research post-Covid up to 35%.', 'Proficient in methodological design (including approach, protocol, survey/questionnaire and output/deliverables)', 'Majority of team sits in Denver, Colorado. Will consider remote candidates.', 'Develop comprehensive research plans designed to explore, and subsequently validate, business or product opportunities.', 'Travel for research post-Covid up to 35%.', 'Total Well Being Program', 'A Bachelor’s Degree in Market Research, Psychology, Social Science, or related field (bonus for a Master’s);', 'Demonstrated ability to conduct end-to-end research studies', 'Develop a deep understanding of the transportation landscape including, but not limited to, products, markets, competitors, etc., and develop frameworks to synthesize this understanding into insights for the business, e.g. segmentation models, competitive analysis, etc.', 'What You’ll Get To Do', 'Competencies', 'Ability to think both analytically and creatively—balance left and right brain—people person as well as data person.', 'Pet Insurance', 'Experience with Design Thinking;', 'Lead innovation and design workshops with cross-functional partners to convert insights into action.', 'What We Offer', 'Strong business acumen;', 'Market research, consumer insights, or related experience in either a supplier-side or client-side environment strong consumer focus;', 'Demonstrated ability to forge strong relationships across an organization to align insights to each line of business and ensure research projects meet today and future business needs.', 'Flexible Work Program', 'Deep understanding, and experience with, leading-edge qualitative research methodologies and technologies to deliver consumer and market insights;', 'Comprehensive benefits', 'Identify and explore white space opportunities in the connected mobility space.', 'About You', 'It would be a bonus if you understand and are able to implement the “Jobs to be Done” framework to articulate opportunities and business strategies within existing customers and future ones, grounded in data and insights', 'What You’ll Bring', 'A Bachelor’s Degree in Market Research, Psychology, Social Science, or related field (bonus for a Master’s);Minimum of 5 years of experience conducting market research in a technology-related field;Demonstrated ability to conduct end-to-end research studiesDeep understanding, and experience with, leading-edge qualitative research methodologies and technologies to deliver consumer and market insights;Market research, consumer insights, or related experience in either a supplier-side or client-side environment strong consumer focus;Experience conducting B2B market research a plus;Experience with Design Thinking;Experience managing vendors relationships a plus;Proficient in methodological design (including approach, protocol, survey/questionnaire and output/deliverables)Demonstrated ability to forge strong relationships across an organization to align insights to each line of business and ensure research projects meet today and future business needs.It would be a bonus if you understand and are able to implement the “Jobs to be Done” framework to articulate opportunities and business strategies within existing customers and future ones, grounded in data and insights', 'Experience conducting B2B market research a plus;', 'An independent, strategic, and creative thinker who is a strong team player (no job is too small or too large) and willing to take on additional responsibilities as necessary;', 'Click here to learn more', 'Create clear and compelling market research storylines that are strategically sound and emotionally provocative to inform business strategy, the development of product roadmaps, enhance marketing efforts, drive engineering efforts, and provide early warning for strategic course corrections;', 'Experience managing vendors relationships a plus;']",Associate,Full-time,Marketing,Information Technology and Services,2020-11-05 11:32:32
Senior Analytics Manager,Flexport,"Chicago, IL",6 hours ago,58 applicants,"['', 'Analytic ownership – discover the highest value-add projects and see them through from ideation to impact.', 'Creating insights to revolutionize an industry', ' 4+ year(s) of experience managing or leading an analytics group 6+ years as a Data Analyst, Data Scientist, Business Analyst or similar role using SQL and/or Python/R; Exceptional SQL fluency with applied exposure to data modeling; fluency with a scripting language like Python or R encouraged. Best-in-class communication skills and empathy to understand and discover business pain points and build solutions to improve the user experience at all levels of the global trade process. ', ' Set and own analytics priorities  Work with company leadership to discover actionable insights. Translate questions from the business into projects that will inform the business and facilitate informed decision making. Create scalable enablement programs and self-service tools to empower everyone at Flexport to use data to improve our business Contribute and grow the culture of excellence on our team by bringing processes and best practices to our group Collaborate with technical leadership to elevate our brand, recruit top analytic talent, and build a world class team Uplevel the members of the Analytics team by enabling their success in their roles and help them grow in their careers ', 'What You’ll Do', 'We know this industry is complex. That’s why we invest in education starting day one with Flexport Academy, a one week intensive onboarding program designed specifically to set every new Flexport employee up for success. ', 'Work with company leadership to discover actionable insights. Translate questions from the business into projects that will inform the business and facilitate informed decision making.', 'Uplevel the members of the Analytics team by enabling their success in their roles and help them grow in their careers', 'Exceptional SQL fluency with applied exposure to data modeling; fluency with a scripting language like Python or R encouraged.', 'Experience at a fast-growing company that lives and breathes data;', 'Don’t! be We’re building the first Operating System for Global Trade. That’s why it’s incredibly important for us to bring people from diverse backgrounds and experiences together with our industry veterans to help move the freight forwarding industry forward.', 'Best-in-class communication skills and empathy to understand and discover business pain points and build solutions to improve the user experience at all levels of the global trade process.', 'Contribute and grow the culture of excellence on our team by bringing processes and best practices to our group', 'What’s freight forwarding and why does it matter? Listen to Ryan, our CEO explain what freight forwarding is and why improving global trade can help to connect the world and break down economic barriers in this Fast Company Freethink Original Series video.', 'Create scalable enablement programs and self-service tools to empower everyone at Flexport to use data to improve our business', 'About Flexport', '4+ year(s) of experience managing or leading an analytics group', '6+ years as a Data Analyst, Data Scientist, Business Analyst or similar role using SQL and/or Python/R;', ' Don’t! be We’re building the first Operating System for Global Trade. That’s why it’s incredibly important for us to bring people from diverse backgrounds and experiences together with our industry veterans to help move the freight forwarding industry forward. What’s freight forwarding and why does it matter? Listen to Ryan, our CEO explain what freight forwarding is and why improving global trade can help to connect the world and break down economic barriers in this Fast Company Freethink Original Series video. We know this industry is complex. That’s why we invest in education starting day one with Flexport Academy, a one week intensive onboarding program designed specifically to set every new Flexport employee up for success.  ', 'Set and own analytics priorities ', 'What You’ll Need', ' Experience at a fast-growing company that lives and breathes data; The opportunity to define data culture Analytic ownership – discover the highest value-add projects and see them through from ideation to impact. ', 'What You’ll Get', 'Worried about not having any freight forwarding experience?', 'Collaborate with technical leadership to elevate our brand, recruit top analytic talent, and build a world class team', 'The opportunity to define data culture']",Mid-Senior level,Full-time,Business Development,Computer Software,2020-11-05 11:32:32
"Senior Engineer, Technology II",AbbVie,"Lake County, IL",14 hours ago,Be among the first 25 applicants,"['', 'Job Level Code', 'Curating content to support the key business initiatives', 'Participating in the acquisition, cataloging, and harmonization of data aligned with the needs of business stakeholders. Supports data consumers in understanding information context, generating fit for purpose datasets, and effectively utilizing advance analytic tools.', 'Planning, building, and running enterprise class information management solutions across a variety of technologies (Big Data, master data, data profiling, ETL batch processing, streaming, and data indexing technologies)', 'Equal Employment Opportunity', 'Responsibilities', 'Experience with Informatica tools (PowerCenter, Big Data Management / Data Engineering Integration, Master Data Management), Cloudera CDH/ CDP and ecosystem tools (SOLR, Spark, Impala, Hive, Hue, Ranger, etc.), Oracle, SQL Server, MarkLogic, SAS Analytics, python, R and Amazon Web Services preferred.', 'Working with data scientist and data analysts across functional disciplines ', ' Planning, building, and running enterprise class information management solutions across a variety of technologies (Big Data, master data, data profiling, ETL batch processing, streaming, and data indexing technologies) Curating content to support the key business initiatives Working with data scientist and data analysts across functional disciplines  Participating in the acquisition, cataloging, and harmonization of data aligned with the needs of business stakeholders. Supports data consumers in understanding information context, generating fit for purpose datasets, and effectively utilizing advance analytic tools. Ensuring appropriate security and compliance policies are followed for information access and dissemination Defining and applying information quality and consistency business rules throughout the data processing lifecycle Collaborating with information providers to ensure quality data updates are processed in a timely fashion Enforcing and expanding use of AbbVie Common Data Model and industry standard information descriptions (ontologies, taxonomies, vocabularies, lexicons, dictionaries, thesaurus, glossaries etc.) Managing the information portal and its customer-facing resources (data catalog, data portal, etc.) ', 'Collaborating with information providers to ensure quality data updates are processed in a timely fashion', 'Travel', 'At least 10 years of experience in a several data Engineering roles such as database developer/administrator, ETL developer, data analyst, BI analytics developer, and/or solution developer of contextual search applications', 'Schedule', 'Qualifications', 'Bachelor’s Degree with 10+ years of related work experience and a strong understanding of specified functional area. Degree in Computer Science or related discipline preferred. Advanced degree preferred.', 'Managing the information portal and its customer-facing resources (data catalog, data portal, etc.)', 'Defining and applying information quality and consistency business rules throughout the data processing lifecycle', 'Qualifications:', 'About AbbVie', 'Ensuring appropriate security and compliance policies are followed for information access and dissemination', 'Significant Work Activities', 'Job Type', 'Enforcing and expanding use of AbbVie Common Data Model and industry standard information descriptions (ontologies, taxonomies, vocabularies, lexicons, dictionaries, thesaurus, glossaries etc.)', ' Bachelor’s Degree with 10+ years of related work experience and a strong understanding of specified functional area. Degree in Computer Science or related discipline preferred. Advanced degree preferred. At least 10 years of experience in a several data Engineering roles such as database developer/administrator, ETL developer, data analyst, BI analytics developer, and/or solution developer of contextual search applications Experience with Informatica tools (PowerCenter, Big Data Management / Data Engineering Integration, Master Data Management), Cloudera CDH/ CDP and ecosystem tools (SOLR, Spark, Impala, Hive, Hue, Ranger, etc.), Oracle, SQL Server, MarkLogic, SAS Analytics, python, R and Amazon Web Services preferred. ']",Not Applicable,Full-time,Project Management,Marketing and Advertising,2020-11-05 11:32:32
Senior Data Engineer,The Spur Group,"Redmond, WA",17 hours ago,29 applicants,"['', 'Data & AI ', '3+ years of Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.).', 'Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like Azure', 'You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you.', 'Experience in data architecture, databases (e.g., MySQL, Redshift, PostgreSQL), SQL and DDD/ER/ORM design.', 'Design, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems.', '.', '\xa0', ""You are able to put yourself into your customer's shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them."", 'BS in Computer Science or related field, or an equivalent in relevant work experience.', 'Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area.', ""You've made mistakes in the past and have learned a lot from them. You apply this learning regularly."", ""Who You Are (What you'd bring to Spur)"", ""\xa0What You'll Do"", 'Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets.', 'Data Engineer', 'Build large-scale distributed data processing systems, data lakes, and optimize for both computational and storage efficiency on cloud platforms like AzureDesign, implement and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems.Design data schema and operate cloud-based data warehouses and SQL database systems.Write Extract-Transform-Load (ETL) jobsDesign, implement and automate integrations with analytical tool (i.e., juypter, excel, SAS) and business intelligence (i.e., PowerBI, Tableau) toolsOwn the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions.Provide insightful code reviews, receive code reviews constructively and take ownership of outcomes (“you ship it, you own it”), working very efficiently and routinely deliver the right things in the front-end UI area.', 'You believe there are generally multiple ways to solve a technical problem, each with different trade-offs.', 'The Role', '\ufeffThe Spur Group is an equal employment opportunity employer. We are committed to building a diverse and inclusive culture that represents a variety of backgrounds, perspectives, and skills. We consider all candidates regardless of race, religion, color, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, disability status, or characteristic protected by federal, state, and local law.\xa0', 'Experience implementing big data processing technology: Hadoop, Apache Spark, etc.', 'At The Spur Group, we’re committed to diversity, inclusion, equity and belonging. We live and breathe our core values of Inclusion, Courage, Accountability, Respect and Excellence, and we hope to see them in every employee. Visit our\xa0website\xa0to learn more about us and why we’ve been voted one of the best places to work in Seattle.', 'Requirements', 'Design data schema and operate cloud-based data warehouses and SQL database systems.', 'Write Extract-Transform-Load (ETL) jobs', 'We are go-to-market consultants who drive results that matter. As the leading authority on go-to-market solutions, we act as an extension of our client teams, providing the support, tools, and strategies to achieve important outcomes. If you tackle challenges with unmatched persistence and believe learning is critical to ongoing growth, we want you on our team.', ""You have a background in data and software engineering and a passion to learn.You've made mistakes in the past and have learned a lot from them. You apply this learning regularly.You believe there are generally multiple ways to solve a technical problem, each with different trade-offs.You approach projects, tasks, and unknowns with curiosity, and enjoy sharing what you know and what you learn with the people around you.You believe that a team is strongest when it is diverse and includes multiple perspectives.You are able to put yourself into your customer's shoes. You frequently immerse yourself in the customer experience to understand how you can better serve them."", 'Design, implement and automate integrations with analytical tool (i.e., juypter, excel, SAS) and business intelligence (i.e., PowerBI, Tableau) tools', 'Senior', 'Why Spur', 'You believe that a team is strongest when it is diverse and includes multiple perspectives.', '3+ years experience in cloud-first design, preferably Azure', 'You have a background in data and software engineering and a passion to learn.', 'Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.', 'BS in Computer Science or related field, or an equivalent in relevant work experience.Experience implementing big data processing technology: Hadoop, Apache Spark, etc.3+ years of Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc.).Experience writing and optimizing advanced SQL queries in a business environment with large-scale, complex datasets.3+ years experience in cloud-first design, preferably AzureExperience in data architecture, databases (e.g., MySQL, Redshift, PostgreSQL), SQL and DDD/ER/ORM design.Knowledge of software engineering practices & best practices for the software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.', 'Drive architectural plans and implementation for future data storage, ETL, reporting, and analytic solutions.', 'The Spur Group is looking for a\xa0Senior Data Engineer to join our Data & AI organization. As a Data Engineer, you will lead the design, implementation, and successful delivery of large-scale, critical, and complex data architecture, storage, and pipelines that improve the lives of tens of millions of people every single day. Best of all, you’ll be part of a team-centric culture where fellow consultants and managers support you and encourage you to grow every day.', 'Own the design, development and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.']",Mid-Senior level,Full-time,Consulting,Management Consulting,2020-11-05 11:32:32
Senior Data Engineer,LeaseLock,"Los Angeles, CA",17 hours ago,87 applicants,"['', 'The Senior Data Engineer will be a member of LeaseLock’s Data Services Team and report to the VP of Engineering. This role will work collaboratively with product managers and engineers to execute against a data roadmap focused on making data accessible, expressive, and clean. The Data Services Team enables data scientists and data analysts to do their jobs effectively. Experience with data pipelines, SQL, and ETL workloads is a must. As a fintech company, LeaseLock has a huge appetite for data.', '401k matching', 'Participate in both schema design and architectural design', 'Unlimited vacation time', 'Compensation', 'About LeaseLock', 'Competitive + Stock Options + Full Benefits', 'Powered by insurance technology, we deliver a modern lease experience that replaces expensive security deposits. Renters pay an affordable monthly fee, which provides up to $5000 in coverage for the property on every lease—significantly more than a deposit. Renters save thousands of dollars at move-in while properties drive more leasing traffic and close more leases.', 'W2', 'Experience working with large datasets', 'Experience building data pipelines on AWS or equivalent', 'Responsibilities', 'Senior Data Engineer', '\xa0', 'Deep understanding of database technologies (and the tradeoffs between them)', 'Benefits', 'Role Summary', 'home', 'A degree in computer science or related field', 'Full health, medical and dental benefits', '4+ years of software engineering experience in data-focused roleExperience working with large datasetsAdvanced SQLDeep understanding of database technologies (and the tradeoffs between them)Experience building data pipelines on AWS or equivalentA degree in computer science or related fieldPrevious startup experience is a plus', 'Flexible work from home days', 'Help make a difference in housing affordability in America', 'Implement data pipelines to normalize data from disparate sources', 'Further LeaseLock’s data infrastructureParticipate in both schema design and architectural designImplement data pipelines to normalize data from disparate sourcesEnable data scientists and analysts with clean & actionable data\xa0', 'Full health, medical and dental benefits401k matchingUnlimited vacation timeOpportunity to own and build a brand from the ground upHelp make a difference in housing affordability in AmericaOffice located four blocks from the beach in sunny Marina del Rey, walkable to Abbott Kinney and plenty of restaurantsFlexible work from home days', 'Further LeaseLock’s data infrastructure', 'Qualifications', 'Enable data scientists and analysts with clean & actionable data\xa0', 'Advanced SQL', 'Office located four blocks from the beach in sunny Marina del Rey, walkable to Abbott Kinney and plenty of restaurants', 'Opportunity to own and build a brand from the ground up', 'Previous startup experience is a plus', '4+ years of software engineering experience in data-focused role', 'Employment Type', 'LeaseLock helps the world find home. We are transforming the rental housing market for the better—making leasing faster, simpler and more affordable.', 'We are the only nationwide insurance technology of our kind, and we’re growing quickly. LeaseLock has insured over $500 million in leases, and has secured over $25 million in venture financing from leading funds including Liberty Mutual Strategic Ventures. We are headquartered a few blocks from the ocean in sunny Marina Del Rey, and are walkable to restaurants, bars and the beach.']",Associate,Full-time,Information Technology,Insurance,2020-11-05 11:32:32
Lead Data Engineer,Samba TV,San Francisco Bay Area,15 hours ago,Be among the first 25 applicants,"['', 'Strong command of a programming language or two – while we code primarily in Python, we acknowledge that engineers with sound fundamentals can pick up new languages relatively quickly.Excellent problem solving skills. Ability to interpret and analyze data is a must. Consequently, mathematical inclination is a major plus.7+ years of professional development experience building high-performance, large-scale applications/pipelines.Solid foundation in computer science, with strong competencies in data structures, algorithms and software design.Experience with Hadoop, Spark, or similar technologies is desirable.Experience with running production systems on AWS is also a plus.', 'Excellent problem solving skills. Ability to interpret and analyze data is a must. Consequently, mathematical inclination is a major plus.', 'Strong command of a programming language or two – while we code primarily in Python, we acknowledge that engineers with sound fundamentals can pick up new languages relatively quickly.', 'Analyze and improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes for our core systems.', 'Help us transform the TV viewing experience for everyone!', 'Responsibilities', 'Create new data processing systems as necessary to support our Data Scientists and Research Analysts.', 'Create and manage platform-specific APIs.', 'Ultimately, build robust, high-volume production software.', 'Requirements', 'Analyze and improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes for our core systems.Create and manage platform-specific APIs.Create new data processing systems as necessary to support our Data Scientists and Research Analysts.Ultimately, build robust, high-volume production software.', 'Experience with Hadoop, Spark, or similar technologies is desirable.', 'Experience with running production systems on AWS is also a plus.', 'At Samba TV, we are on a mission to fundamentally change television viewing for everyone. We are doing this by leveraging our data to enable advertisers to engage and measure TV viewers across all their devices. We have an amazing story with a unique perspective formed by innovative technology.', 'Solid foundation in computer science, with strong competencies in data structures, algorithms and software design.', '7+ years of professional development experience building high-performance, large-scale applications/pipelines.']",Not Applicable,Full-time,Information Technology,Internet,2020-11-05 11:32:32
Senior Data Engineer,Virtusa,San Francisco Bay Area,20 hours ago,Over 200 applicants,"['', 'Participate in systems implementation projects (i.e. requirements documentation, systems configuration, test documentation and execution, issue identification and resolution).Plan, prioritize, and deliver systems enhancements.Support and upgrade implemented systems.Develop and test financial reports and reporting solutions using sql and google proprietary tools .', '\xa0', 'Support and upgrade implemented systems.', 'MS in Computer Science or related field.', 'Responsibilities:\xa0', 'Strong hands-on skills using SQL and relational database management systems (Oracle, MySQL, Sybase, SQL Server).', 'Development experience using Java, Python is a plus', '5+ years of relevant hands on work experience. Knowledge of Finance domain is a plus', 'Minimum qualifications:', 'Develop and test financial reports and reporting solutions using sql and google proprietary tools .', 'Participate in systems implementation projects (i.e. requirements documentation, systems configuration, test documentation and execution, issue identification and resolution).', 'Plan, prioritize, and deliver systems enhancements.', 'MS in Computer Science or related field.5+ years of relevant hands on work experience. Knowledge of Finance domain is a plusStrong hands-on skills using SQL and relational database management systems (Oracle, MySQL, Sybase, SQL Server).Development experience using Java, Python is a plus']",Mid-Senior level,Contract,Engineering,Information Technology and Services,2020-11-05 11:32:32
Application Developer,ADP,"Alpharetta, GA",17 hours ago,Be among the first 25 applicants,"['', 'Position Summary', 'Develop & enhance effective programs & data structures that successfully meet the objective.', 'Web Application Development Background Experience with Relational Databases, scripting languages, UI / User Interface development experience and related technologies preferred.', 'Investigate and resolve application issues as needed Package, configure and deploying software Collaborate with clients, Product Managers, Architects, & Analysts to develop and review requirements & design.', 'Must be available to work evenings and weekends as needed.', 'Responsibilities', 'Higher level jobs would be expected to manage broader or multiple projects at a time.', '3 - 5 years of directly related experience.', 'Review and create system, software and functional design specifications that address requirements.', 'Qualifications Required', 'Participate effectively in relevant aspects of software development life cycle (SDLC) including planning, construction, testing, reviews and demonstrations.', 'Performs other related duties as assigned. 10-20% Travel required.', 'Technical experience with Object Oriented Design and Development (Java, C++, etc), Web Technologies (HTML, CSS, JavaScript, JSP, etc)', 'Acts as an expert source of technology and application knowledge within their domain. Research, recommend, and introduce new technologies and new uses of existing technologies Participating in Business planning, IT strategy and setting direction.', 'Uses resources to resolve routine issues regarding technology & business Resolves issues regarding relationships & leadership on own merit', 'Web Application Development Background Experience with Relational Databases, scripting languages, UI / User Interface development experience and related technologies preferred.Uses resources to resolve routine issues regarding technology & business Resolves issues regarding relationships & leadership on own merit', 'Some situations may require more travels.', 'Participate in project planning and release management.', 'CORE', ' Insightful Expertise, Integrity is Everything, Service Excellence, Inspiring Innovation, Each Person Counts, Results-Driven, & Social Responsibility.', 'Technical Degree or equivalent in education & experience.', 'Develop & enhance effective programs & data structures that successfully meet the objective.Participate effectively in relevant aspects of software development life cycle (SDLC) including planning, construction, testing, reviews and demonstrations.Collaborate with team to design, develop, test and refine deliverables.Investigate and resolve application issues as needed Package, configure and deploying software Collaborate with clients, Product Managers, Architects, & Analysts to develop and review requirements & design.Review and create system, software and functional design specifications that address requirements.Participate in project planning and release management.Higher level jobs would be expected to manage broader or multiple projects at a time.Acts as an expert source of technology and application knowledge within their domain. Research, recommend, and introduce new technologies and new uses of existing technologies Participating in Business planning, IT strategy and setting direction.Performs other related duties as assigned. 10-20% Travel required.Some situations may require more travels.Must be available to work evenings and weekends as needed.', 'Unlock Your Career Potential: Technology at ADP.', 'Related Searches: ', 'Technical Degree or equivalent in education & experience.3 - 5 years of directly related experience.Technical experience with Object Oriented Design and Development (Java, C++, etc), Web Technologies (HTML, CSS, JavaScript, JSP, etc)', 'Collaborate with team to design, develop, test and refine deliverables.']",Not Applicable,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
"Senior Director, Data Science and AI in Cybersecurity",Visa,"Foster City, CA",18 hours ago,Be among the first 25 applicants,"['', 'Experience working with Docker development and deployment workflows', 'Chief data scientist:', 'R&D:', 'Experience working on Behavior Biometrics and anomaly detection/fraud related usecases is a plus', 'Preferred Qualifications', 'Essential Functions', 'Mental/Physical Requirements ', 'Demonstrated expertise and experience with advanced and 0-day threats, intrusions, malware infection, packet analysis', 'Basic Qualifications', 'Have a Masters, PhD, or equivalent experience in a quantitative field (Applied Mathematics, Computer Science, Statistics, Physics, or related field)', 'We’re', 'R&D: Lead and instrument work around developing AI prototypes and algorithms.', 'Together', 'Work Hours ', 'Chief data scientist: The candidate will be using their core competencies around AI and data science and help drive their teams build models that work at scale, harnessing Petabytes of data while applying it to products that need to respond with cyber analytics in milliseconds.', 'Experience working on Cybersecurity Insider Threat usecases and Investigations is a plus', 'Hiring and talent management', 'Additional Information', 'Core responsibility of team: This team is responsible for the design, implementation, and product engineering of Visa’s cyber security data analytics solutions. This team has products defending the perimeter using behavior biometrics and internally against Insider threat attacks. Using data science techniques, the team will build the tools and use cases to successfully help in the prevention of cyber attacks. ', 'Engineering muscle: The candidate should be an engineer at heart, possessing software engineering skills besides data science skills, allowing them to lead teams that build some of the most critical and marquee products in the entire company.', 'Qualifications', 'Have a Masters, PhD, or equivalent experience in a quantitative field (Applied Mathematics, Computer Science, Statistics, Physics, or related field)10+ years of experience in Machine Learning, Data Science, data engineering, or Software Engineering, with atleast 5+ of those years managing and leading Data Science or ML/software Engineering teams.Experience designing a data science roadmap and executing the vision behind it.Track record of delivering data-driven products and insights, and influencing product and engineering decisions.', 'Engineering muscle:', 'Track record of delivering data-driven products and insights, and influencing product and engineering decisions.', ""Core responsibility: Provide leadership and direction in the innovation of bleeding-edge cybersecurity analytics based technologies with a focus on data science and applied artificial intelligence techniques. This will drive Visa's competitive advantage in payments by facilitating a best in class security infrastructure. You will be heavily engaged and will collaborate with two core teams. First - Visa's insider threat team and second - PD technology/IAM/fraud teams defending against authentication related threats. In addition, you will collaborate with colleagues in technology and product offices to establish effective, productive business relationships.Fiscal discipline: You will be leading multi-million dollar global projects, working with your team and PMO organization to develop timelines, constructing business case, cost estimates, ROI, and drive deliverables on time and budgetHiring and talent management: Build and manage a team of the very top talent with a track record of recruiting talent in cybersecurity analytics, data science, and software engineering.Presentation & communication skills: Be able to present results to a cross section of employees, including C-Level and other senior most leadership at Visa.Core responsibility of team: This team is responsible for the design, implementation, and product engineering of Visa’s cyber security data analytics solutions. This team has products defending the perimeter using behavior biometrics and internally against Insider threat attacks. Using data science techniques, the team will build the tools and use cases to successfully help in the prevention of cyber attacks. Engineering muscle: The candidate should be an engineer at heart, possessing software engineering skills besides data science skills, allowing them to lead teams that build some of the most critical and marquee products in the entire company.Chief data scientist: The candidate will be using their core competencies around AI and data science and help drive their teams build models that work at scale, harnessing Petabytes of data while applying it to products that need to respond with cyber analytics in milliseconds.R&D: Lead and instrument work around developing AI prototypes and algorithms."", 'Fiscal discipline', 'Travel Requirements ', 'EEO Statement ', 'Experience with Advanced Persistent Threat (APT) and criminal actors and advanced knowledge of associated Tactics, Techniques and Procedures (TTP) is a plus', 'Fiscal discipline: You will be leading multi-million dollar global projects, working with your team and PMO organization to develop timelines, constructing business case, cost estimates, ROI, and drive deliverables on time and budget', 'Company Description', 'Experience working on Cybersecurity Insider Threat usecases and Investigations is a plusExperience working on Behavior Biometrics and anomaly detection/fraud related usecases is a plusExperience with Advanced Persistent Threat (APT) and criminal actors and advanced knowledge of associated Tactics, Techniques and Procedures (TTP) is a plusDemonstrated expertise and experience with advanced and 0-day threats, intrusions, malware infection, packet analysisExperience working with cloud platforms (e.g., AWS, GCP, Azure) and infrastructure-as-code (e.g., Terraform)Experience working with Docker development and deployment workflows', 'Job Description', ""Core responsibility: Provide leadership and direction in the innovation of bleeding-edge cybersecurity analytics based technologies with a focus on data science and applied artificial intelligence techniques. This will drive Visa's competitive advantage in payments by facilitating a best in class security infrastructure. You will be heavily engaged and will collaborate with two core teams. First - Visa's insider threat team and second - PD technology/IAM/fraud teams defending against authentication related threats. In addition, you will collaborate with colleagues in technology and product offices to establish effective, productive business relationships."", 'Hiring and talent management: Build and manage a team of the very top talent with a track record of recruiting talent in cybersecurity analytics, data science, and software engineering.', 'Experience working with cloud platforms (e.g., AWS, GCP, Azure) and infrastructure-as-code (e.g., Terraform)', 'Experience designing a data science roadmap and executing the vision behind it.', 'You’re', 'Core responsibility', 'Presentation & communication skills: Be able to present results to a cross section of employees, including C-Level and other senior most leadership at Visa.', 'Presentation & communication skills:', '10+ years of experience in Machine Learning, Data Science, data engineering, or Software Engineering, with atleast 5+ of those years managing and leading Data Science or ML/software Engineering teams.', 'Core responsibility of team']",Not Applicable,Full-time,Information Technology,Consumer Services,2020-11-05 11:32:32
Senior Data Engineer,"Audible, Inc.","Newark, NJ",6 hours ago,29 applicants,"['', ' Experience with AWS cloud technologies such as Elastic Map Reduce (EMR), Kinesis, Athena. Hands on experience with BI and Visualization platforms such as MicroStrategy and AWS Quicksight.', ' Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design', 'Preferred Qualifications', ' Proficiency in processing and modeling large, complex data sets for Analytical use cases', ' Ability to communicate effectively and work independently with little supervision to deliver on time quality products.', 'Company', ' 5+ years of hands on experience in building large scale data-centric systems using MPP Database technologies and Hadoop, Spark, Kafka or AWS equivalents.', 'Basic Qualifications', 'Description', ' Peer review work. Actively mentor other members of the team, improving their skills, their knowledge of our systems and their ability to get things done', ' Hands on experience with BI and Visualization platforms such as MicroStrategy and AWS Quicksight.', ' Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines', ' Willingness to learn, be open minded to new ideas and different opinions yet knowing when to stop, analyze, and reach a decision.', ' Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts', ' Experience with AWS cloud technologies such as Elastic Map Reduce (EMR), Kinesis, Athena.', ' Familiarity with Business Intelligence (BI) and Visualization platforms such as MicroStrategy and AWS Quicksight.', ' Expertise in Database technologies such as AWS Redshift, Teradata or equivalent.', ' Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design 1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems. 2+ years of non-internship professional software development experience A Bachelor’s degree or higher in Computer Science, Engineering, Mathematics, Physics, or a related field. Proficiency in functional programming languages (e.g. Python) as well as declarative programming languages (e.g. SQL, SPARQL) 5+ years of hands on experience in building large scale data-centric systems using MPP Database technologies and Hadoop, Spark, Kafka or AWS equivalents. Proficiency in processing and modeling large, complex data sets for Analytical use cases Expertise in Database technologies such as AWS Redshift, Teradata or equivalent. Familiarity with Business Intelligence (BI) and Visualization platforms such as MicroStrategy and AWS Quicksight. Ability to communicate effectively and work independently with little supervision to deliver on time quality products. Willingness to learn, be open minded to new ideas and different opinions yet knowing when to stop, analyze, and reach a decision.', 'About Audible', ' Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications', 'About The Role', 'About You', ' Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices', ' 1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.', ' Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet business needs Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices Analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines Effectively communicate with various teams and stakeholders, escalate technical and managerial issues at the right time and resolve conflicts Peer review work. Actively mentor other members of the team, improving their skills, their knowledge of our systems and their ability to get things done', ' Proficiency in functional programming languages (e.g. Python) as well as declarative programming languages (e.g. SQL, SPARQL)', ' A Bachelor’s degree or higher in Computer Science, Engineering, Mathematics, Physics, or a related field.', 'Key Responsibilities', ' Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet business needs', ' 2+ years of non-internship professional software development experience']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Lead Big Data Engineer ,Grid Dynamics,"Atlanta, GA",20 hours ago,Be among the first 25 applicants,"['', 'Opportunity to work on bleeding-edge projectsWork with a highly motivated and dedicated teamCompetitive salaryFlexible scheduleBenefits programMedical insuranceProfessional development opportunities', 'Requirements:\xa0', 'Strong analytical, problem-solving skills.', 'We work in close collaboration with our clients on digital transformation initiatives that span strategy consulting, early prototypes and enterprise-scale delivery of new digital platforms. We help organizations become more agile and create innovative digital products and experiences using deep expertise in emerging technology, top global engineering talent, lean software development practices, and high-performance product culture.\xa0', 'Benefits program', 'Headquartered in Silicon Valley with over 1,300 technologists located in engineering delivery centers throughout the US, Central and Eastern Europe, Grid Dynamics has architected and delivered some of the most extensive digital transformation programs in the retail, technology and financial sectors to help its clients win market share, shorten time to market and reduce costs of digital operations on a massive scale.', 'Medical insurance', 'Flexible schedule', 'Experience working on a cloud environment, preferably, Microsoft Azure Cloud Data Warehouse solutions (Snowflake, Azure DW)', 'data warehouse (data modeling, programming),', 'RDBMS Exposure in Microsoft technologies like SSIS, SQL Server, SSRS', 'We are looking for a Lead/Senior Data Engineer for the Enterprise Data Organization to build and manage data pipelines (Data ingest, data transformation, data distribution, quality rules, data storage etc.) for an Azure cloud-based data analytics platform. The candidate will possess strong technical, analytical, programming and critical thinking skills. The ideal candidate will have familiarity with data transformation, data modeling, Master data management, and Meta data management.\xa0This candidate will act as a onsite lead of a team of engineers based out of Eastern Europe, and will interact with the client stakeholders.', 'Java Hands-on design and development experience in data space : data processing / data transformation using ETL tools,', 'Understanding of data science and visualization technologies (Hadoop, Spark, Databricks)', 'Work well independently, and be a team player.', 'A go-getter and a problem solver.', 'Versatile, creative temperament, ability to think out-of-the box while defining sound and practical solutions.', 'To learn more about Grid Dynamics, visit\xa0www.griddynamics.com, or follow us on Twitter @GridDynamics.', 'Grid Dynamics is a leading provider of technology consulting, agile co-creation, scalable engineering and data science services for Fortune 500 corporations undergoing digital transformation.\xa0', 'Experience of working in a matrix organization, self-driven.', 'What we offer:', 'Good interpersonal skills; comfort and competence in dealing with different teams within the organization.', 'Professional development opportunities', 'Ability to prioritize, work to deadlines, work under pressure.', 'Professional data engineering experience focused on batch and real time data pipelines using Spark, PySpark, Python, SQL', 'Ability to master new skills.', 'Good interpersonal skills; comfort and competence in dealing with different teams within the organization.Requires an ability to interface with multiple constituent groups and build sustainable relationships.Strong and effective communication skills (verbal and written).Strong analytical, problem-solving skills.Experience of working in a matrix organization, self-driven.A go-getter and a problem solver.Ability to prioritize, work to deadlines, work under pressure.Results-oriented, flexible, adaptable.Work well independently, and be a team player.Versatile, creative temperament, ability to think out-of-the box while defining sound and practical solutions.Ability to master new skills.Proactive approach to problem solving with effective influencing skills.Familiar with Agile practices and methodologiesProfessional data engineering experience focused on batch and real time data pipelines using Spark, PySpark, Python, SQLJava Hands-on design and development experience in data space : data processing / data transformation using ETL tools,data warehouse (data modeling, programming),RDBMS Exposure in Microsoft technologies like SSIS, SQL Server, SSRSExperience with a DevOps model utilizing a CI/CD toolHands-on Talend work experience (anyone with this skill will have an advantage over other candidates)Understanding of data science and visualization technologies (Hadoop, Spark, Databricks)Experience working on a cloud environment, preferably, Microsoft Azure Cloud Data Warehouse solutions (Snowflake, Azure DW)', 'Proactive approach to problem solving with effective influencing skills.', 'Requires an ability to interface with multiple constituent groups and build sustainable relationships.', 'Experience with a DevOps model utilizing a CI/CD tool', 'About Us:\xa0', 'Work with a highly motivated and dedicated team', 'Results-oriented, flexible, adaptable.', 'Strong and effective communication skills (verbal and written).', 'Competitive salary', 'Opportunity to work on bleeding-edge projects', 'Hands-on Talend work experience (anyone with this skill will have an advantage over other candidates)', 'Familiar with Agile practices and methodologies']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Senior Data Engineer,Databricks,"San Francisco, CA",5 hours ago,69 applicants,"['', 'Employee referral bonus program ', 'Outcomes', 'Mission', 'Analytics: ', 'Gym reimbursement ', 'Unlimited Paid Time Off', 'Collaboration:', 'Benefits', 'Maternity and paternity plans ', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Competencies', 'Experience with building data pipeline from various business applications like Salesforce, Marketo, NetSuite, Workday etc. ', ' We are looking for a candidate with 8+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. In depth knowledge of Model and Design of DB schemas for read and write performance. Extensive working knowledge of API or Stream based data extraction processes like Salesforce API and Bulk API is must. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Experience supporting and working with cross-functional teams in a dynamic environment. Experience with building data pipeline from various business applications like Salesforce, Marketo, NetSuite, Workday etc.  Experience with big data tools: Hadoop, Spark, Kafka, Spark & Kafka Streaming, Python, Scala, Talend etc. Working knowledge of BI Tools like Tableau, Looker etc is plus ', '401k Retirement Plan ', 'Extensive working knowledge of API or Stream based data extraction processes like Salesforce API and Bulk API is must.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Working knowledge of BI Tools like Tableau, Looker etc is plus', 'Experience with big data tools: Hadoop, Spark, Kafka, Spark & Kafka Streaming, Python, Scala, Talend etc.', ' Medical, dental, vision 401k Retirement Plan  Unlimited Paid Time Off Gym reimbursement  Employee referral bonus program  Maternity and paternity plans  ', 'About Databricks', 'Design/Strategy:', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'We are looking for a candidate with 8+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', 'Medical, dental, vision', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. In depth knowledge of Model and Design of DB schemas for read and write performance.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Engineering Scientist Sr.,Ball Aerospace,"Fairborn, OH",6 hours ago,Be among the first 25 applicants,"['', ' Additionally, research, design, and prototype changes to the bistatic radar software for increasing automation of Tasking, Exploitation and Processing functions. Conducts or participates in the design, specification and development of systems and/or tools for new program as well as enhancements, modifications and corrections to existing systems and tools. ', ' Applicant must have a strong background working with bistatic radar(s) and understand the science and operational aspects of the system. ', ' Maintain a regular and predictable work schedule. ', 'Us Citizenship Is Required', ' Establish and maintain effective working relationships within the department, the Strategic Business Units, Strategic Support Units and the Company. Interact appropriately with others in order to maintain a positive and productive work environment. ', ' Perform other duties as necessary. ', ' Each higher-level degree, i.e. master’s degree or Ph.D., may substitute for two years of experience. Two years of related experience may be substituted for each year of education. Degree must be from a university, college, or school which is accredited by an agency recognized by the US Secretary of Education, US Department of Education. ', ' May access other facilities in various weather conditions. ', ' Applicant must be able to work within a team of engineers supporting the Government across the spectrum of bistatic research, software development, prototyping changes and enhancements. ', ' BS degree or higher in Engineering or a related technical field is required plus 8 or more years related experience. ', ' Work is performed in an office, laboratory, production floor, or clean room, outdoors or remote research environment. ', ' BS degree or higher in Engineering or a related technical field is required plus 8 or more years related experience.  Each higher-level degree, i.e. master’s degree or Ph.D., may substitute for two years of experience. Two years of related experience may be substituted for each year of education. Degree must be from a university, college, or school which is accredited by an agency recognized by the US Secretary of Education, US Department of Education.  Applicant must have a strong background working with bistatic radar(s) and understand the science and operational aspects of the system.  Applicant must be able to work within a team of engineers supporting the Government across the spectrum of bistatic research, software development, prototyping changes and enhancements. ', ' Engineering Scientist Sr. ', ""What You'll Do"", ' Research, design, and prototype new or modified applications supporting bistatic radar processing, exploitation, tasking and collection functionality. ', ' Travel and local commute between Ball campuses and other possible non-Ball locations may be required. ', 'Working Conditions', 'Current Clearance Required', ' Work is performed in an office, laboratory, production floor, or clean room, outdoors or remote research environment.  May occasionally work in production work centers where use of protective equipment and gear is required.  May access other facilities in various weather conditions.  Travel and local commute between Ball campuses and other possible non-Ball locations may be required. ', ' May occasionally work in production work centers where use of protective equipment and gear is required. ', ' Research, design, and prototype new or modified applications supporting bistatic radar processing, exploitation, tasking and collection functionality.  Additionally, research, design, and prototype changes to the bistatic radar software for increasing automation of Tasking, Exploitation and Processing functions. Conducts or participates in the design, specification and development of systems and/or tools for new program as well as enhancements, modifications and corrections to existing systems and tools.  Maintain a regular and predictable work schedule.  Research, design and prototype changes to the bistatic radar software to support different transmitter and receiver combinations.  Research and develop activities to identify and mature GEOINT bistatic radar capabilities and develop plans to integrate approved capabilities into operational baselines.  Establish and maintain effective working relationships within the department, the Strategic Business Units, Strategic Support Units and the Company. Interact appropriately with others in order to maintain a positive and productive work environment.  Perform other duties as necessary. ', ' Research, design and prototype changes to the bistatic radar software to support different transmitter and receiver combinations. ', ' Research and develop activities to identify and mature GEOINT bistatic radar capabilities and develop plans to integrate approved capabilities into operational baselines. ', 'What You’ll Need']",Mid-Senior level,Full-time,Research,Defense & Space,2020-11-05 11:32:32
Senior Technician,Plenty,"Laramie, WY",3 hours ago,Be among the first 25 applicants,"['', 'Assist in a broad range of scientific activities including but not limited to applied literature review, preparing plant tissue samples, and practicing safe chemical material handling', 'Experience with common data collection, analysis and documentation tools', 'Experience with plant research in a nursery production or lab setting', 'Flexibility to work weekends as scheduled', 'Experimental set-up and execution', 'Sanitizing lab/plant materials and equipment', 'Ability to assist in a wide array of activities in operating a large-scale hydroponic research farm', ' BS in Botany, Agronomy, Horticulture or agriculture-related field or 2 years of related work experience Experience with plant research in a nursery production or lab setting Understanding of plant science, horticulture and plant materials, propagation, pest management, crop production Technical problem solving and prioritization skills Experience with common data collection, analysis and documentation tools Humble, teachable team-player who is enthusiastic and hard-working Ability to take direction and implement changes quickly Flexibility to work weekends as scheduled Interest in hydroponic fruit and vegetable production Ability to lift 30 pounds, climb ladders, and work in confined spaces in varied conditions around bees Ability to assist in a wide array of activities in operating a large-scale hydroponic research farm Bonus points: Basic comprehension of hydroponic systems & plumbing ', 'Humble, teachable team-player who is enthusiastic and hard-working', 'Ability to take direction and implement changes quickly', 'Ability to lift 30 pounds, climb ladders, and work in confined spaces in varied conditions around bees', 'Chemical mixing and calculating chemical ratios for plant nutrient solutions', ' Plant, harvest, and transplant crops and ensuring overall plant health Assist the Research Scientist with controlling and optimizing the production environment to maximize product quality & yield Work with high-intensity plant production equipment Pest and nutrient management Collect plant and environmental data with sophisticated measuring equipment Experimental set-up and execution Chemical mixing and calculating chemical ratios for plant nutrient solutions Sanitizing lab/plant materials and equipment Assist in a broad range of scientific activities including but not limited to applied literature review, preparing plant tissue samples, and practicing safe chemical material handling ', 'Pest and nutrient management', 'BS in Botany, Agronomy, Horticulture or agriculture-related field or 2 years of related work experience', 'Collect plant and environmental data with sophisticated measuring equipment', 'About Plenty', 'Work with high-intensity plant production equipment', 'Plant, harvest, and transplant crops and ensuring overall plant health', 'Technical problem solving and prioritization skills', 'Bonus points: Basic comprehension of hydroponic systems & plumbing', 'Assist the Research Scientist with controlling and optimizing the production environment to maximize product quality & yield', 'Understanding of plant science, horticulture and plant materials, propagation, pest management, crop production', 'About Role', 'Interest in hydroponic fruit and vegetable production']",Associate,Full-time,Information Technology,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Sr Data Engineer,7-Eleven,"Irving, TX",7 hours ago,26 applicants,"['', 'redefining convenience and the customer experience', ' Knowledge of Oracle ERP will be huge plus', ' Be Courageous with Your Point of View ', ' An understanding of “big picture” business requirements that drive architecture ', 'better serve the needs of our customers', ' Work with technologies such as Spark, Kafka, Oracle MoM, EBS etc.  A deep knowledge of performant SQL and understanding of relational database technology  Hands-on RDBMS experience (data modeling, analysis, programming, stored procedures)  Expertise in developing ETL/ELT workflows with one or more of the following: Python, Scala, Java  An understanding of “big picture” business requirements that drive architecture  Demonstrated ability to adapt to new technologies and learn quickly  Knowledge of Oracle ERP will be huge plus', ' Understand and document business requirements; analyze existing and/or new information and applications; propose potential solutions; and execute selected technology solutions ', ' Be Accountable ', ' Have an “It Can Be Done” Attitude ', ' Act Like an Entrepreneur ', '▶ Who We Are', ' Work closely with cross-domain Financial Solution teams and business partners efforts to develop and test any cross-functional solutions ', ' innovation', 'continuous improvement', 'entrepreneurial spirit', '▶ How We Lead', ' Do the Right Thing ', ' Implementing data orchestration pipelines, data sourcing, cleansing, and augmentation and quality control processes  Build complex ETL code and SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL  Create connectors using Python, Java or other OO languages for ingesting data from third party databases, APIs, and web sites  Optimize data structures, improve code execution, and reduce memory consumption of existing implementation  Work closely with cross-domain Financial Solution teams and business partners efforts to develop and test any cross-functional solutions  Articulate complex concepts in a way that is understandable to non-technical stakeholders  Understand and document business requirements; analyze existing and/or new information and applications; propose potential solutions; and execute selected technology solutions  Strong knowledge in Python/Java, Apache Beam, Airflow, Flink ', ' Be Customer Obsessed ', ' Strong knowledge in Python/Java, Apache Beam, Airflow, Flink ', ' Build complex ETL code and SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL ', ' Hands-on RDBMS experience (data modeling, analysis, programming, stored procedures) ', ' A deep knowledge of performant SQL and understanding of relational database technology ', ' Expertise in developing ETL/ELT workflows with one or more of the following: Python, Scala, Java ', ' Challenge the Status Quo ', 'come make history with us', ' Work with technologies such as Spark, Kafka, Oracle MoM, EBS etc. ', ' Articulate complex concepts in a way that is understandable to non-technical stakeholders ', ' Demonstrated ability to adapt to new technologies and learn quickly ', ' Optimize data structures, improve code execution, and reduce memory consumption of existing implementation ', ' Create connectors using Python, Java or other OO languages for ingesting data from third party databases, APIs, and web sites ', 'Leadership Principles', '▶ About This Opportunity', ' Implementing data orchestration pipelines, data sourcing, cleansing, and augmentation and quality control processes ']",Associate,Full-time,Information Technology,Retail,2020-11-05 11:32:32
Sr Research Scientist-Automation Lead,Eli Lilly and Company,"Indianapolis, IN",7 hours ago,Be among the first 25 applicants,"['', 'Provide analytical support, project leadership, and/or technical direction as needed for the automation team.', 'Support manufacturing implementation. ', 'A Research Scientist in the Global Quality Laboratory is an automation lead position responsible for the evaluation of new technologies to modernize and improve analytical analyses for testing in a clinical and manufacturing environment. The Research Scientist will be responsible for coordinating automation activities and will be an integral part of multidisciplinary teams.', 'Demonstrated ability to communicate effectively to customers, business partners, and staff including good oral, written, and visual presentations.', 'Actively partner and collaborate with Lilly Research Laboratories (LRL) Automation, Bioprocess Research Development (BRD), Global Robotics, Manufacturing, Quality Control Lab Informatics, and Information Digital Services.', ' Additional Skills/ Preferences ', 'Responsibilities', 'Present at or attend external scientific conferences ', 'Basic Qualifications', 'Effective management of multiple projects.', 'Ability to influence diverse groups and effectively manage relationships,', 'Manage project development work and implementation (including laboratory work, training/transfer, change controls, and regulatory submissions).', 'Influence development and QC laboratories to utilize new technologies for product/process monitoring and control. Work with product development teams to improve quality of deliverables for new chemical entities or formulation line extensions.', 'Additional Information', 'Openly share key technical developments including contributions to internal/external scientific forums', 'Mentor technical talent.', 'Demonstrated ability to utilize and implement various tools, systems, and processes resulting in improved operational excellence of laboratory and business operations.', 'Some travel (up to 20%) may be incurred', 'PhD degree in Chemistry, Biochemistry, Pharmacy, Engineering, Biology or BS/ MS with equivalent experience. Minimum of 5 years industry experience working with method development, optimization, validation, and remediation in GMP analytical testing laboratories or equivalent.', 'Ensure consistent practices between global laboratories.', 'The Research Scientist must complete Learning Plan for the analytical scientistSome travel (up to 20%) may be incurred', 'Doctorate in Chemistry, Biochemistry, Pharmacy, Engineering, Biology or BS/MS with equivalent experience; industry related experience in pharmaceuticals is preferred.', 'Doctorate in Chemistry, Biochemistry, Pharmacy, Engineering, Biology or BS/MS with equivalent experience; industry related experience in pharmaceuticals is preferred.Demonstrated ability to utilize and implement various tools, systems, and processes resulting in improved operational excellence of laboratory and business operations.Demonstrated ability to communicate effectively to customers, business partners, and staff including good oral, written, and visual presentations.Demonstrated ability to interpret and apply solutions to different situations by understanding customer needs and applying strong problem solving skills.Demonstrated experience with various spectroscopic and analytical investigational techniques including but not limited to automation.Ability to influence diverse groups and effectively manage relationships,Thorough technical understanding of the quality systems and regulatory requirements.', 'Manage the automation team project program, budget, timeline, and deliverables.', 'Provide analytical support, project leadership, and/or technical direction as needed for the automation team.Actively partner and collaborate with Lilly Research Laboratories (LRL) Automation, Bioprocess Research Development (BRD), Global Robotics, Manufacturing, Quality Control Lab Informatics, and Information Digital Services.Manage the automation team project program, budget, timeline, and deliverables.Support manufacturing implementation. Manage project development work and implementation (including laboratory work, training/transfer, change controls, and regulatory submissions).Implement new technologies into the labs and improve existing methodologies.Influence development and QC laboratories to utilize new technologies for product/process monitoring and control. Work with product development teams to improve quality of deliverables for new chemical entities or formulation line extensions.Openly share key technical developments including contributions to internal/external scientific forumsEnsure consistent practices between global laboratories.Mentor technical talent.Effective management of multiple projects.Present at or attend external scientific conferences ', 'Demonstrated ability to interpret and apply solutions to different situations by understanding customer needs and applying strong problem solving skills.', 'Research Scientist R1/R2', 'The Research Scientist must complete Learning Plan for the analytical scientist', 'Demonstrated experience with various spectroscopic and analytical investigational techniques including but not limited to automation.', 'Implement new technologies into the labs and improve existing methodologies.', 'Thorough technical understanding of the quality systems and regulatory requirements.']",Associate,Full-time,Other,Biotechnology,2020-11-05 11:32:32
Postdoctoral Researcher,Icahn School of Medicine at Mount Sinai,"New York, United States",17 hours ago,Over 200 applicants,"['Computational postdoctoral position is now available in the group of Prof. Luksza at the Icahn School of Medicine and the Center for Computational Immunology and Genomics at Mount Sinai in New York. The lab studies the dynamics of evolution of rapidly evolving systems, including cancer and viruses, focusing on their interactions with the immune system. We develop computational models that combine machine learning, information theory, and biophysics with novel algorithmic solutions to understand patterns in biological datasets.', '', 'Collaborate with researchers and other members in interpretation of data.', 'Programming and software development skills in (e.g. Python, R, Java or C++)', 'Please send a CV, a cover letter, contact information for three references, and two or three relevant publications/preprints to Marta Łuksza at marta.luksza@mssm.edu. In the cover letter, please describe your research interests (max 2 pages)', 'Perform independent research in one of the above-mentioned topic areas.Collaborate with researchers and other members in interpretation of data.Participate in the preparation of manuscripts and presentations.', 'Job responsibilities:', 'Job responsibilities', 'Team-oriented with abilities to think creatively and work independently', 'Ph.D. in computer science, physics, mathematics, computational biology, bioinformatics or other quantitative disciplinesProgramming and software development skills in (e.g. Python, R, Java or C++)Experience with developing and implementing of algorithms and software packagesExperience managing and curating large datasets and with machine learning techniques desiredTeam-oriented with abilities to think creatively and work independently', 'Perform independent research in one of the above-mentioned topic areas.', 'Requirements:', 'Experience with developing and implementing of algorithms and software packages', 'Experience managing and curating large datasets and with machine learning techniques desired', 'Participate in the preparation of manuscripts and presentations.', 'The current projects at the lab include new methods and theory for prediction of viral evolution, with a specific focus on influenza and novel SARS-CoV-2 coronavirus. Our predictive models for influenza inform the process of vaccine strain selection by the World Health Organization. With the research support from the Centers of Excellence for Influenza Research and Surveillance, we work on strategies to design universal influenza vaccines. In collaboration with clinicians at the Memorial Sloan Kettering, we build computational models for the evolution of cancer under immune selection and principled treatment strategies. We are particularly interested in understanding the impact of tumor-immune interactions on tumor evolution.', 'We are looking for candidates with computational background and interests in biological systems and data analysis. The postdoctoral project will involve development and implementation of models and algorithms for the analysis of genetic and phenotypic data, including genome and immune repertoire sequencing. Several projects are available. Creative thinking, new ideas, and independence are welcome. The projects will be carried in close collaboration with experimentalists at the Memorial Sloan Kettering Cancer Center in New York and the Microbiology department at Mount Sinai.', 'Ph.D. in computer science, physics, mathematics, computational biology, bioinformatics or other quantitative disciplines']",Not Applicable,Full-time,Research,Hospital & Health Care,2020-11-05 11:32:32
Senior Data Engineer,Bill.com,"Palo Alto, CA",6 hours ago,70 applicants,"['', 'Design and operation of robust distributed systems', 'Demonstrated ability to build complex, scalable systems with high quality', '5+ years of experience owning and building data pipelines.', 'Own the data expertise and data quality for the pipelines', 'Ability to absorb business problems and understand how to service required data needs', 'Drive the collection of new data and refinement of existing data sources', 'Passionate – Love what you do', 'Proven experience building data platforms from scratch for data consumption across a wide variety of use cases (e.g data science, ML, scalability etc)', 'About Bill.com', 'Expected Outcomes', 'Bill.com Culture', 'Design and implement data infrastructure and processing workflows required to support data science, machine learning, BI and reporting in AWSBuild robust, efficient and reliable data pipelines consisting of diverse data sourcesDesign and develop real time streaming and batch processing pipeline solutionsOwn the data expertise and data quality for the pipelinesDrive the collection of new data and refinement of existing data sourcesIdentify shared data needs across Bill.com , understand their specific requirements, and build efficient and scalable pipelines to meet various needsBuild data stores for feature variables required for machine learning', 'Design and implement data infrastructure and processing workflows required to support data science, machine learning, BI and reporting in AWS', 'Experience with containerized workloads, Kubernetes and infrastructure-as-code principles a big plus', 'Experience in SQL and one or more of Python, Java and Scala', 'Identify shared data needs across Bill.com , understand their specific requirements, and build efficient and scalable pipelines to meet various needs', 'Build data stores for feature variables required for machine learning', 'Design and develop real time streaming and batch processing pipeline solutions', 'Dedicated – To each other and the customer', 'Fun – Celebrate the moments', 'Humble – No ego', '5+ years of experience owning and building data pipelines.Extensive knowledge of data engineering tools, technologies and approachesAbility to absorb business problems and understand how to service required data needsDesign and operation of robust distributed systemsProven experience building data platforms from scratch for data consumption across a wide variety of use cases (e.g data science, ML, scalability etc)Demonstrated ability to build complex, scalable systems with high qualityExperience with multiple data technologies and concepts such as Airflow, Kafka, Hadoop, Hive, Spark, MapReduce, SQL, NoSQL, and Columnar databases. Experience with specific AWS technologies (such as S3, Redshift, EMR, and Kinesis) a plusExperience in SQL and one or more of Python, Java and ScalaExperience with containerized workloads, Kubernetes and infrastructure-as-code principles a big plus', 'Build robust, efficient and reliable data pipelines consisting of diverse data sources', 'Authentic – We are who we are', 'Experience with multiple data technologies and concepts such as Airflow, Kafka, Hadoop, Hive, Spark, MapReduce, SQL, NoSQL, and Columnar databases. ', 'Experience with specific AWS technologies (such as S3, Redshift, EMR, and Kinesis) a plus', 'Professional Experience/Background To Be Successful In This Role', 'Our Applicant Privacy Notice describes how Bill.com treats the personal information it receives from applicants.', 'Extensive knowledge of data engineering tools, technologies and approaches']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior UX Researcher,Rylem Consulting,"Redmond, WA",21 hours ago,Be among the first 25 applicants,"['', 'Partner closely with design, program management, customer experience, and data science to develop a deep understanding of our customers to inform the product roadmap.', 'Solid background/skills in UX/UR Presentation skills', 'Responsibilities', 'Senior UX Researcher with Program Management Experience', '18 - Months Contract', 'Build a trusted partnership with stakeholders to inform the roadmap for your area.', 'Design, execute, and analyze research to deliver insightful and actionable results.', 'Program Management experience.The ideal candidate will have at least 5+ years of research and design work experience, with strong theoretical and practical knowledge of both qualitative (e.g., ethnography), and quantitative (e.g., data analytics), research methodologies, and statistics.The candidate must have a proven ability to help teams develop and drive progress on key metrics as well as have experience in creating research plans.Must have excellent interpersonal skills. Ability to communicate with, and persuade, varied audiences and argue for results (both orally and in writing) is a plus.Solid background/skills in UX/UR Presentation skills', 'Pull from a broad portfolio of research techniques from generative to evaluative to inform product and design decisions throughout the entire product cycle.', 'Qualifications', 'Must have excellent interpersonal skills. Ability to communicate with, and persuade, varied audiences and argue for results (both orally and in writing) is a plus.', 'Work with stakeholders to understand research needs and develop research plans for your product area.', 'The candidate must have a proven ability to help teams develop and drive progress on key metrics as well as have experience in creating research plans.', 'The ideal candidate will have at least 5+ years of research and design work experience, with strong theoretical and practical knowledge of both qualitative (e.g., ethnography), and quantitative (e.g., data analytics), research methodologies, and statistics.', 'Program Management experience.', 'Communicate research findings in clear and compelling ways to all levels of the product team, with ability to explain methodology, insights, and design recommendations.', 'Redmond, WA', 'Work with stakeholders to understand research needs and develop research plans for your product area.Partner closely with design, program management, customer experience, and data science to develop a deep understanding of our customers to inform the product roadmap.Pull from a broad portfolio of research techniques from generative to evaluative to inform product and design decisions throughout the entire product cycle.Design, execute, and analyze research to deliver insightful and actionable results.Communicate research findings in clear and compelling ways to all levels of the product team, with ability to explain methodology, insights, and design recommendations.Build a trusted partnership with stakeholders to inform the roadmap for your area.Contribute to the formation of the research culture across our team.', 'Contribute to the formation of the research culture across our team.', '$35/hour W2']",Mid-Senior level,Contract,Information Technology,Staffing and Recruiting,2020-11-05 11:32:32
Senior Data Engineer,Verizon,"Cary, NC",6 hours ago,51 applicants,"['', 'You are highly analytical and are able to transform complex data into easily understood, actionable information. You flourish in a fast-paced environment and quickly adapt to changing priorities. Lastly, you have exceptional critical thinking skills, like to uncover solutions, be flexible, be curious, be dependable and work well individually and as part of a team.', 'Equal Employment Opportunity', 'Diversity and Inclusion at Verizon', ""Bachelor's degree or four or more years of experience."", 'Experience in data engineering with Python and pyspark.', 'Strong analytical and problem-solving skills.', 'Develop data pipelines (data lake / data warehouses) for analytical solutions.', 'diversity and inclusion', 'Experience with Hadoop, Map/Reduce, Spark, HBase, CouchDB and Hive.', 'Identify gaps and implement solutions for data quality and automation of processes, with security in mind.', 'Even Better If You Have', 'What We’re Looking For...', 'A master’s degree in Computer Science, Engineering, Statistics, IT, or related field.Strong analytical and problem-solving skills.Experience in network operations.Experience as an open source contributor.Experience with reporting and BI packages (i.e., Tableau, QlikView, Oracle BI, etc.).', ""Bachelor's degree or four or more years of experience.Six or more years of relevant work experience.Experience in Python development.Experience in data engineering with Python and pyspark.Experience using SQL (i.e., PL/SQL or T-SQL with RDBMSs like Teradata, MS SQL Server, Oracle etc.).Experience with Hadoop, Map/Reduce, Spark, HBase, CouchDB and Hive.Experience building production data/feature pipelines for the deployment of models (i.e., Apache Airflow).Experience with UNIX shell scripting.Willingness to travel (approximately 10%)"", 'Work closely with the Data Architect and Data Scientists to develop plans to enhance the Data Science practice.Gather requirements, assess gaps and build roadmaps and architectures to help the analytics driven organization achieve its goals.Works closely with Data Analysts to ensure data quality and availability for analytical modelling.Define extract, load, and transform (ELT) based on jointly defined requirements.Develop data pipelines (data lake / data warehouses) for analytical solutions.Identify gaps and implement solutions for data quality and automation of processes, with security in mind.Support maintenance, bug fixes and performance analysis along data pipelines.', 'A master’s degree in Computer Science, Engineering, Statistics, IT, or related field.', 'Experience in Python development.', 'Experience with reporting and BI packages (i.e., Tableau, QlikView, Oracle BI, etc.).', 'Support maintenance, bug fixes and performance analysis along data pipelines.', 'We areadding a Senior Data Engineerto work on a portfolio of innovative projects to enable digital operational excellence in Verizon Business Group (VBG) Customer Operations. The program direction includes artificial intelligence, operations automation, and industry leading omnichannel technology to improve the efficiency and client experience of our services. The Sr. Data Engineer will be using critical thinking skills to analyze a global network operations environment to transform data into actionable intelligence. This individual will develop data tools and products for automation and accessibility. This individual will also design and jointly develop the data architecture with a Data Architect and ensure security and maintenance. Moreover, this individual will build data assets that enhance the quality of overall data structures feeding the data science program.', 'Experience using SQL (i.e., PL/SQL or T-SQL with RDBMSs like Teradata, MS SQL Server, Oracle etc.).', 'When you join Verizon...', 'Work closely with the Data Architect and Data Scientists to develop plans to enhance the Data Science practice.', 'Experience in network operations.', 'Gather requirements, assess gaps and build roadmaps and architectures to help the analytics driven organization achieve its goals.', 'What You’ll Be Doing...', ""You'll Need To Have"", 'Works closely with Data Analysts to ensure data quality and availability for analytical modelling.', 'Experience building production data/feature pipelines for the deployment of models (i.e., Apache Airflow).', 'Willingness to travel (approximately 10%)', 'Experience with UNIX shell scripting.', 'Six or more years of relevant work experience.', 'Experience as an open source contributor.', 'Define extract, load, and transform (ELT) based on jointly defined requirements.']",Director,Full-time,Information Technology,Telecommunications,2020-11-05 11:32:32
"Sr Principal Scientist/Sr Research Scientist - Merrimack, NH",Getinge,"Merrimack, NH",7 hours ago,Be among the first 25 applicants,"['', ' Getinge is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, pregnancy, genetic information, national origin, disability, protected veteran status or any other characteristic protected by law. ', '  Background in toxicology and experience with toxicological risk analysis.   Work in a medical device, pharmaceutical, or biotechnology contract research organization (CRO).  ', ' Minimum of ten-fifteen years of related experience in the medical device or pharmaceutical industry is required. ', ' MS/PhD in Physical or Biological science/engineering. ', ' Assists in special projects as needed. ', 'ten-fifteen years of related experience', ' Create Biological Evaluation of Risk (BER) files and maintain compliance of the Design History File. ', '  Experience in pre-clinical science/Biocompatibility testing in medical device, pharmaceutical, or biotechnology industries.   Demonstrated research effectiveness; patents and/or publication in peer review journals, presentations forums, etc.   Strong statistical analysis skills.   Excellent communication, interpersonal, writing and computer skills.   Chemical, medical device, hygiene and/or Packaging industry experience strongly desired.   Good laboratory and sciences skills expected, including documentation of activity.   A detailed understanding of the product development process is preferred.  ', ' Pre-clinical Science and Biocompatibility: ', 'Job Function Summary', ' Work in a medical device, pharmaceutical, or biotechnology contract research organization (CRO). ', ' Analyses of test data of new scientific theories and hypotheses. ', ' Good laboratory and sciences skills expected, including documentation of activity. ', 'Additional Preferred Knowledge, Skills And Abilities', ' Provide guidance and risk assessments on new product mat. ', ' A detailed understanding of the product development process is preferred. ', ' Planning, executing, documenting and reporting lab activity to provide scientific date supporting marketing proof points of features on existing and new devices. ', 'Ignite Your Passion!', ' Lead pre-clinical science and Biocompatibility programs. ', 'Other Job Functions', 'Research And New Technology Evaluations', ' Perform scientific risk assessments to support design control activities. ', 'Required Knowledge, Skills And Abilities', ' Chemical, medical device, hygiene and/or Packaging industry experience strongly desired. ', ' Demonstrated research effectiveness; patents and/or publication in peer review journals, presentations forums, etc. ', ' Provide technical leadership for project team activities, team members, peers, and cross functional counterparts. ', '  Lead pre-clinical science and Biocompatibility programs.   Serve as a subject matter expert in cross-functional team meetings.   Prepare and defend regulatory documents.   Provide guidance and risk assessments on new product mat.   Provide technical leadership for project team activities, team members, peers, and cross functional counterparts.   Provide oversight for Non-Clinical studies by designing, reviewing, approving and managing studies with Contract Research Organizations (CRO).   Create Biological Evaluation of Risk (BER) files and maintain compliance of the Design History File.   Perform scientific risk assessments to support design control activities.  ', '  MS/PhD in Physical or Biological science/engineering.   Minimum of ten-fifteen years of related experience in the medical device or pharmaceutical industry is required.  ', ' Contributes to team effort by accomplishing related duties as requested. ', ' Background in toxicology and experience with toxicological risk analysis. ', '  Assists in special projects as needed.   Contributes to team effort by accomplishing related duties as requested.   May include management of technical staff.  ', ' Prepare and defend regulatory documents. ', ' Serve as a subject matter expert in cross-functional team meetings. ', 'Job Functions', ' Excellent communication, interpersonal, writing and computer skills. ', '  Identify, adapt, and advance new technology initiatives.   Analyses of test data of new scientific theories and hypotheses.   Planning, executing, documenting and reporting lab activity to provide scientific date supporting marketing proof points of features on existing and new devices.   Develop internal procedures and standards for maintenance of laboratory investigation records, quality of invention releases, and feasibility experiment design.  ', ' Experience in pre-clinical science/Biocompatibility testing in medical device, pharmaceutical, or biotechnology industries. ', ' Provide oversight for Non-Clinical studies by designing, reviewing, approving and managing studies with Contract Research Organizations (CRO). ', ' Develop internal procedures and standards for maintenance of laboratory investigation records, quality of invention releases, and feasibility experiment design. ', ' Strong statistical analysis skills. ', 'Minimum Requirements', ' May include management of technical staff. ', ' Identify, adapt, and advance new technology initiatives. ']",Mid-Senior level,Full-time,Research,Medical Devices,2020-11-05 11:32:32
Lead Data Engineer – QIS Technology,Goldman Sachs,"New York, NY",7 hours ago,Be among the first 25 applicants,"['', ' 5+ years acting as a Tech Lead for a team focused on Data Engineering, Data Pipelines, etc.  Hands-on expertise in Hadoop and Hadoop ecosystem such as Spark/Scala  Data ingestion and management, Data APIs (multi-language support), and Big Data processing  Working experience with Enterprise Java development, JSI web stack, various visualization toolkits.  Knowledge of leading technology trends and best practices  Proven to in ETL and data processing, know how to transform data to meet business goals.  Meaningful experience in using AWS stack is a plus ideal, but not required ', ' Hands-on expertise in Hadoop and Hadoop ecosystem such as Spark/Scala ', ' This role will focus on leading the effort to advance data strategies for portfolio management teams across QIS  Manage any necessary development team  Evolve state-of-the-art data infrastructure to drive the investment process and thus the firms bottom line  Work closely with Senior and Executive leadership, to ensure QIS Infrastructure platform remains best in class  Designing, developing, and maintaining a world-class, high-performing data platform to enhance research and portfolio management  Developing rigorous and scalable data management/analysis tools to support the data-intensive quantitative investment process ', ' 5+ years acting as a Tech Lead for a team focused on Data Engineering, Data Pipelines, etc. ', ' Evolve state-of-the-art data infrastructure to drive the investment process and thus the firms bottom line ', ' This role will focus on leading the effort to advance data strategies for portfolio management teams across QIS ', ' Data ingestion and management, Data APIs (multi-language support), and Big Data processing ', ' Meaningful experience in using AWS stack is a plus ideal, but not required ', ' Designing, developing, and maintaining a world-class, high-performing data platform to enhance research and portfolio management ', 'Primary Responsibilities', ' Developing rigorous and scalable data management/analysis tools to support the data-intensive quantitative investment process ', 'Requirements', ' Proven to in ETL and data processing, know how to transform data to meet business goals. ', ' Knowledge of leading technology trends and best practices ', ' Work closely with Senior and Executive leadership, to ensure QIS Infrastructure platform remains best in class ', 'About Goldman Sachs', ' Working experience with Enterprise Java development, JSI web stack, various visualization toolkits. ', ' Manage any necessary development team ', ' RESPONSIBILITIES AND QUALIFICATIONS ']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Hookit | AI-Powered Sponsorship,"San Diego, CA",22 hours ago,Be among the first 25 applicants,"['', 'Collaborate with senior engineers on the creation and application of technical roadmaps, standards, tooling and frameworks required to continue to build a modern, high quality, data rich application suite.', 'Hands-on experience with Snowflake.Working knowledge of virtualization (e.g., VMware, Docker, Kubernetes, etc.).Experience with scripting languages: e.g., Python.Happy to diagram and tech spec as needed.Strong interpersonal, whiteboard and communication skills.Love what you do!', 'Experience guiding fellow developers.', 'Experience with SQL, NoSQL Database.', 'Strong interpersonal, whiteboard and communication skills.', 'Become an expert with a handful of global social networks APIs (FB, IG, Twitter, VK, Weibo).', 'Collaborate with senior engineers on the creation and application of technical roadmaps, standards, tooling and frameworks required to continue to build a modern, high quality, data rich application suite.Investigate and resolve complex issues in the entire application stack with strength weighted toward middle-to-back.Identify technical debt and articulate workable plan for rewrites.Introduce technology to improve system and subsystems performance, reliability, and productivity.Think & discuss architecture, reliability, optimization with others.Become an expert with a handful of global social networks APIs (FB, IG, Twitter, VK, Weibo).Contribute to guiding of the adoption of automated test and CI/CD practices.Crank out complex queries for both core apps and analysis.', 'Investigate and resolve complex issues in the entire application stack with strength weighted toward middle-to-back.', 'Experience in implementing highly scalable, data intensive web and backend systems.', '7+ years of software engineering experience.', 'Authorized to work in the U.S.', 'Considerable years leading tech stack buildout, re-engineering inefficient & outmoded front & back-end code, and wrangling lots of data.', 'Working knowledge of virtualization (e.g., VMware, Docker, Kubernetes, etc.).', 'Love what you do!', 'Introduce technology to improve system and subsystems performance, reliability, and productivity.', 'Expert implementing REST based APIs.', 'Crank out complex queries for both core apps and analysis.', 'Experience with Cloud Software development (AWS).', 'Experience with scripting languages: e.g., Python.', 'Requirements', 'Identify technical debt and articulate workable plan for rewrites.', 'Happy to diagram and tech spec as needed.', 'Bachelors or Masters degree in Computer Science or equivalent.', 'Hands-on experience with Snowflake.', 'Exposure to strategies of source code control systems like GIT, Agile mindset, secure coding practices.', 'Think & discuss architecture, reliability, optimization with others.', 'Bachelors or Masters degree in Computer Science or equivalent.7+ years of software engineering experience.Considerable years leading tech stack buildout, re-engineering inefficient & outmoded front & back-end code, and wrangling lots of data.Experience in implementing highly scalable, data intensive web and backend systems.Technical Expertise in .Net Core, C#, ASP.Net, WCF, MVC architecture.Expert implementing REST based APIs.Experience with SQL, NoSQL Database.Experience with Cloud Software development (AWS).Exposure to strategies of source code control systems like GIT, Agile mindset, secure coding practices.Experience guiding fellow developers.Authorized to work in the U.S.', 'Technical Expertise in .Net Core, C#, ASP.Net, WCF, MVC architecture.', 'Contribute to guiding of the adoption of automated test and CI/CD practices.']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Principal Scientist - Chemometrics,HireMinds,"Cambridge, MA",,N/A,"['', '•Support intellectual property, marketing and sales departments with relevant expertise', 'Skills:\xa0Leadership, influencing, critical thinking and decision-making, effective communication, customer focus, business acumen, quality and compliance oriented, project management skills with a demonstrated ability to lead projects', 'Responsibilities:', 'Education and Experience:\xa0Masters/Doctoral degree with 5+ years’ experience in the field of analytical/ bioanalytical chemistrySoftware: : Matlab, SIMCA, SIMCA+, Unscrambler, Process Pulse, Python, SQLExperiences with spectroscopy and chromatography techniques is a plusSkills:\xa0Leadership, influencing, critical thinking and decision-making, effective communication, customer focus, business acumen, quality and compliance oriented, project management skills with a demonstrated ability to lead projects', 'Remote during the COVID era, this role will sit just west of Boston. This is the perfect role for someone interested in leading high profile projects and eventually building a team. This role comes with a competitive compensation package and a spot on a talented team. Relocation assistance offered - apply today!', 'Experiences with spectroscopy and chromatography techniques is a plus', 'Education and Experience:\xa0Masters/Doctoral degree with 5+ years’ experience in the field of analytical/ bioanalytical chemistry', '•Set milestones as project goals while providing direction', 'Principal Data Scientist, Chemometrics', '•Lead a high priority project within analytics and controls, propose concepts and plans to management while performing technical tasks', '•Opportunity to mentor and develop a team', 'Software: : Matlab, SIMCA, SIMCA+, Unscrambler, Process Pulse, Python, SQL', 'Qualifications:', ""Our client is a scientific leader, a Fortune 500 organization that's helped bring dozens of therapies to life. They're looking for a Principal Data Scientist, Chemometrics as they build the next generation of their large molecule platform."", '•Develop a vision, framework, approach and plan for each of your projects', 'The right candidate is a chemometrician with a strong background developing processes to create biologics. This is a high profile role that will develop new technologies and drive process improvement.', '•Lead and support the development, optimization and migration of new or existing technologies', '•Build and maintain broad process and technology development and implementation skills', '•Bring the technology challenges into R&D through translating problems to implementation']",Associate,Full-time,Science,Biotechnology,2020-11-05 11:32:32
Clinical Lab Scientist,Blue Signal Search,"Irvine, CA",18 hours ago,Be among the first 25 applicants,"['Clear definition of success supported by achievable goals from the onset. ', 'Opportunity to have a hand in decision-making for staffing, certification expectations, and equipment to stay ahead of the nursing curve. ', 'Competitive base salary, plus comprehensive benefits including medical, vision, and dental insurance and 401K. The chance to work in a close-knit healthcare group – giving you the opportunity to come in and hit the ground running. Make a difference managing a lab to ensure excellent patient care. Clear definition of success supported by achievable goals from the onset. Opportunity to have a hand in decision-making for staffing, certification expectations, and equipment to stay ahead of the nursing curve. Develop strong professional relationships based on communication, understanding and trust. Work to provide the motivation, tools, steps, and confidence that will produce lasting outcomes. Culture of integrity, high performance, and quality customer care. ', 'Skill Set: ', 'Monitor test analyses and specimen examinations to ensure that acceptable levels of analytic performances are maintained. ', 'Maintain diagnostic viability of all specimens and ensure correct patient labeling of all materials. Evaluate, recommend, and implement new technology, testing, equipment, and policies to improve quality and increase efficiency and revenue. Maintain medical laboratory equipment performance by establishing quality standards; developing operations, quality, and troubleshooting procedures; ensuring staff compliance; certifying instrument performance; arranging equipment replacement, service, and repair. Monitor test analyses and specimen examinations to ensure that acceptable levels of analytic performances are maintained. Implement new programs, tests, methods, instrumentation, and procedures by investigating alternatives; preparing proposals; developing and performing parallel testing; monitoring progress. Follow all Standard Operating Procedures to ensure safety and quality standards. Maintain record logs in a timely and efficient manner. Maintain a clean and safe work environment. Attention to detail to verify relevant data and process specimens ensuring appropriate specimens are handled according to process. ', 'The chance to work in a close-knit healthcare group – giving you the opportunity to come in and hit the ground running. ', 'Maintain diagnostic viability of all specimens and ensure correct patient labeling of all materials. ', 'Make a difference managing a lab to ensure excellent patient care. ', '\xa0', 'This Role Offers: ', 'Work to provide the motivation, tools, steps, and confidence that will produce lasting outcomes. ', 'The ideal candidate will perform various medical support specialist duties and help to achieve optimal laboratory workflow and excellent customer service in accordance with practice policies and procedures. The Clinical Lab Scientist be responsible for working closely with lab techs to help test and prep samples and ensure records are up to date and compliant with requirements. ', 'Valid Sate Laboratory License required. ', 'This Role Offers:', 'Focus:', 'Thorough understanding of medical terminology and excellent record keeping/organizational skills. ', 'Shift: Wednesday – Friday. Must be available for night shift once a month.', 'Develop strong professional relationships based on communication, understanding and trust. ', 'Follow all Standard Operating Procedures to ensure safety and quality standards. ', 'Maintain medical laboratory equipment performance by establishing quality standards; developing operations, quality, and troubleshooting procedures; ensuring staff compliance; certifying instrument performance; arranging equipment replacement, service, and repair. ', 'Bachelor’s degree in applicable bioscience field. ', 'Focus: ', 'Maintain a clean and safe work environment. ', 'Skill Set:', 'Must have recent LCMS experience. Sciex experience a plus. ', '2+ years of experience in clinical labs. Background as a Generalist, Chemist, or Toxicology Clinical Lab Scientist. Bachelor’s degree in applicable bioscience field. Comfortability with handling biological specimens. Thorough understanding of medical terminology and excellent record keeping/organizational skills. Must have recent LCMS experience. Sciex experience a plus. Ability to gain knowledge of, interpret, apply, and adhere to guidelines, policies, procedures, regulations, The Joint Commission Standards and CLIA regulations. Valid Sate Laboratory License required. Shift: Wednesday – Friday. Must be available for night shift once a month.', 'Evaluate, recommend, and implement new technology, testing, equipment, and policies to improve quality and increase efficiency and revenue. ', 'Our client is a local full-service laboratory practice focused on addiction treatment and medication monitoring. They are hiring a Clinical Lab Scientist to provide support laboratory testing and initiatives. ', '2+ years of experience in clinical labs. ', 'Comfortability with handling biological specimens. ', 'Culture of integrity, high performance, and quality customer care. ', 'Ability to gain knowledge of, interpret, apply, and adhere to guidelines, policies, procedures, regulations, The Joint Commission Standards and CLIA regulations. ', 'Background as a Generalist, Chemist, or Toxicology Clinical Lab Scientist. ', 'Maintain record logs in a timely and efficient manner. ', 'Implement new programs, tests, methods, instrumentation, and procedures by investigating alternatives; preparing proposals; developing and performing parallel testing; monitoring progress. ', '\xa0 ', 'Competitive base salary, plus comprehensive benefits including medical, vision, and dental insurance and 401K. ', 'Attention to detail to verify relevant data and process specimens ensuring appropriate specimens are handled according to process. ']",Mid-Senior level,Full-time,Health Care Provider,"Health, Wellness and Fitness",2020-11-05 11:32:32
Lead User Experience Researcher,PayPal,"Chicago, IL",16 hours ago,Be among the first 25 applicants,"['', '10+ years experience in user experience research and design.', 'Craft a thoughtful program of mixed-methods research that takes the team through the product development lifecycle. You have a fundamental understanding of research design and craft bespoke, rigorous study designs to elicit answers to key questions.', 'Responsibilities:', 'Present actionable, creative, compelling insights and recommendations to multiple teams and stakeholders across the organization.', 'Requirements:', 'Responsibilities', 'Analyze data, develop impactful insights and deliverables, often triangulating with other data sources like VOC, Sales, Product Analytics, Market Research and PMM.', '10+ years experience in user experience research and design.Bachelors and/or Master’s Degree in the study of user experience, design, research or related fields; for example, Design, Information Architecture, Human Factors/HCI, Psychology, Cognitive Sciences OR alternative equivalent project/portfolio experience.Experience with a range of mixed methods research approaches: in context qualitative research, diary studies, IDIs, moderated and unmoderated usability and surveys.', 'Advocate for the customer, representing their needs, their desires, and their challenges. Use this advocacy to influence your Design, Content, Product and Engineering partners to build experiences that exceed customer expectations and make a meaningful difference in their personal financial lives and business successes.Craft a thoughtful program of mixed-methods research that takes the team through the product development lifecycle. You have a fundamental understanding of research design and craft bespoke, rigorous study designs to elicit answers to key questions.Execute research studies from beginning to end: identifying the right research questions, defining the participant sample, designing the study and executing with attention to detail and quality.Analyze data, develop impactful insights and deliverables, often triangulating with other data sources like VOC, Sales, Product Analytics, Market Research and PMM.Present actionable, creative, compelling insights and recommendations to multiple teams and stakeholders across the organization.Let your creativity shine in how you plan and deliver research, always with a focus on impact and delivering quality work within budget and timelines.Contribute to the community, providing support to junior team members, leveraging your strengths to help others grow and evolve our team, the UX Research practice, and our culture.', 'Experience with a range of mixed methods research approaches: in context qualitative research, diary studies, IDIs, moderated and unmoderated usability and surveys.', 'Job Description:', 'Execute research studies from beginning to end: identifying the right research questions, defining the participant sample, designing the study and executing with attention to detail and quality.', 'Contribute to the community, providing support to junior team members, leveraging your strengths to help others grow and evolve our team, the UX Research practice, and our culture.', 'Requirements', 'Job Description Summary:', 'Let your creativity shine in how you plan and deliver research, always with a focus on impact and delivering quality work within budget and timelines.', 'Advocate for the customer, representing their needs, their desires, and their challenges. Use this advocacy to influence your Design, Content, Product and Engineering partners to build experiences that exceed customer expectations and make a meaningful difference in their personal financial lives and business successes.', 'Bachelors and/or Master’s Degree in the study of user experience, design, research or related fields; for example, Design, Information Architecture, Human Factors/HCI, Psychology, Cognitive Sciences OR alternative equivalent project/portfolio experience.']",Not Applicable,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Assistant Research Scientist II (Pharmacology),Exelixis,"Alameda, CA",,N/A,"['', ' Ability to conduct organ harvesting; transcardial perfusion and fixation from small animals', ' Assist in the planning, design and implementation related to animal studies of pharmacokinetics, pharmacodynamics, and efficacy to evaluate and differentiate lead validation and lead optimization programs under general supervision', ' General knowledge of pharmacokinetics, pharmacology and immunology techniques, theories, and practices General understanding of how the individual experiments fit within a larger research program to meet organizational goals General understanding and application of scientific principles, theories and concepts in field of specialty and other related disciplines Ability to perform in a fast-paced environment and be flexible and Ability to adapt to changing work conditions Must be self-motivated, able to multi-task and detail-oriented Strong communication skills, excellent work ethic, self-motivation, and ability to work effectively in a either a team environment or independently Understanding of regulatory requirements to run an in vivo facility Collaborate with other project team members', ' Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors', ' Adept at sample processing, homogenization, or generation of single-cell suspensions for ex vivo analysis', ' BS in a relevant biological scientific discipline and two to four years of related experience; or, MS in a relevant biological scientific discipline and zero to two years of related experience Equivalent combination of education and experience', ' General knowledge of pharmacokinetics, pharmacology and immunology techniques, theories, and practices', ' Exercise judgment within generally defined practices and policies in selecting methods and techniques for obtaining solutions', ' Adhere to good health and safety practices and compliance with applicable EH&S rules, and participating in mandatory safety training programs', ' Compliance with IACUC protocols and AAALAC regulations in conducting general research duties within assigned area of responsibility', ' Excellent data analysis skills and experience with a variety of scientific software applications is preferred', ' Maintain familiarity with current scientific literature relevant to the research experiments or programs', 'Knowledge/Skills/Abilities', 'Position Requirements', 'Education', ' Ability to perform in a fast-paced environment and be flexible and', ' General understanding and application of scientific principles, theories and concepts in field of specialty and other related disciplines', ' Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors Exercise judgment within generally defined practices and policies in selecting methods and techniques for obtaining solutions Use professional concepts and company policies and procedures to solve a wide range of difficult problems in imaginative and practical ways', ' General understanding of how the individual experiments fit within a larger research program to meet organizational goals', ' Ability to adapt to changing work conditions', ' Experience with immunology-related biological assays, flow cytometry, MSD and Luminex is a plus', 'Position Description', ' Strong communication skills, excellent work ethic, self-motivation, and ability to work effectively in a either a team environment or independently', ' Proficiency with in vivo techniques including iv, ip, sc, po administration, and blood collection (tail vein, retroorbital, cardiac puncture, submandibular and etc.) is required', ' Proficiency with computers including MS Word, MS PowerPoint, and MS Excel is required', ' Maintain laboratory notebook in a complete, consistent, and concise manner in accordance with company intellectual property policies and practices', 'Experience', ' Collaborate with other project team members', ' Proficiency in animal tumor model development and execution including but not limited to syngeneic, xenograft and humanized mouse model is essential', ' Understanding of regulatory requirements to run an in vivo facility', ' Equivalent combination of education and experience', ' Good practice with in vitro sterile cell culture and scale-up for tumor implantation is required', ' BS in a relevant biological scientific discipline and two to four years of related experience; or,', ' Must be self-motivated, able to multi-task and detail-oriented', ' Prepare and organize data for presentation using analysis and visualization software; present data and reports on project status at individual, group, and departmental research meetings under general supervision', ' Assist in the planning, design and implementation related to animal studies of pharmacokinetics, pharmacodynamics, and efficacy to evaluate and differentiate lead validation and lead optimization programs under general supervision Compliance with IACUC protocols and AAALAC regulations in conducting general research duties within assigned area of responsibility Prepare and organize data for presentation using analysis and visualization software; present data and reports on project status at individual, group, and departmental research meetings under general supervision Maintain familiarity with current scientific literature relevant to the research experiments or programs Maintain laboratory notebook in a complete, consistent, and concise manner in accordance with company intellectual property policies and practices Adhere to good health and safety practices and compliance with applicable EH&S rules, and participating in mandatory safety training programs', ' Proficiency with in vivo techniques including iv, ip, sc, po administration, and blood collection (tail vein, retroorbital, cardiac puncture, submandibular and etc.) is required Proficiency in animal tumor model development and execution including but not limited to syngeneic, xenograft and humanized mouse model is essential Good practice with in vitro sterile cell culture and scale-up for tumor implantation is required Ability to conduct organ harvesting; transcardial perfusion and fixation from small animals Adept at sample processing, homogenization, or generation of single-cell suspensions for ex vivo analysis Experience with immunology-related biological assays, flow cytometry, MSD and Luminex is a plus Excellent data analysis skills and experience with a variety of scientific software applications is preferred Proficiency with computers including MS Word, MS PowerPoint, and MS Excel is required', ' MS in a relevant biological scientific discipline and zero to two years of related experience', 'Job Complexity', ' Use professional concepts and company policies and procedures to solve a wide range of difficult problems in imaginative and practical ways']",Entry level,Full-time,Science,Biotechnology,2020-11-05 11:32:32
Senior UX Researcher,Sumo Logic,"Redwood City, CA",6 hours ago,52 applicants,"['', 'Within 6 Months You Will', ' Ability to plan and conduct research in close collaboration with people in a variety of roles, including design, engineering, and product management ', ' Excellent communication, presentation, and interpersonal skills ', ' Be highly adaptable in an ever-changing startup environment ', ' Mentor and support UX researchers, designers and other cross-functional team members ', ' Experience with data analysis and data visualization ', ' What we do:We are a cloud-native SaaS machine data analytics platform, solving complex monitoring problems for DevOps, SecOps and ITOps teams. Customers love our product because it allows them to easily monitor and optimize their mission critical, large scale applications.', ' Become familiar with the Sumo Logic product, customers, and a specific area of the product ', ' Knowledge of quantitative, behavioral analysis, and statistical concepts ', 'Responsibilities', ' Plan and execute research studies with cross-functional scrum teams ', ' Build processes as the UX research team continues to grow ', ' Funding and Growth:We have raised $345 million in funding to date, with the most recent round being May 2019. Investors include Battery Ventures, Greylock Partners, Sutter Hill Ventures, Accel Partners, Sequoia Capital, Sapphire Ventures and DFJ Growth. Our recurring revenue and customer base are growing steadily. We serve over 2,000 customers across the globe including AirBnB, Alaska Airlines, Anheuser Busch, Hootsuite, Hearst, Hudl, Major League Baseball, Marriott, Medidata, Sauce Labs, Samsung SmartThings, SPS Commerce, Twitter, Telstra, Toyota, Zuora and more.', '  BA/BS degree in Anthropology, Human Factors, Psychology, HCI/Computer Science or other related fields or equivalent practical experience   5+ years of experience in applied product research   Strong strategic, analytical, and creative skills with a history of tackling and solving complex design research opportunities   Ability to plan and conduct research in close collaboration with people in a variety of roles, including design, engineering, and product management   Highly skilled in a range of user-centered design methodologies, with tangible deliverables   Excellent communication, presentation, and interpersonal skills   Knowledge of quantitative, behavioral analysis, and statistical concepts   Be highly adaptable in an ever-changing startup environment   A portfolio that highlights your strengths  ', '  Work closely with product designers, engineers, and product managers to identify research topics and define studies to address user behavior and attitudes   Plan and conduct research using a wide variety of qualitative and quantitative methods, and analyze through the lens of UX, HCI, and social science   Recruit research participants   Synthesize qualitative and quantitative insights and translate insights into actionable recommendations   Collect feedback and champion iterative refinements of the product until the usability and experience reach desired expectations   Communicate and present research findings cross-functionally to inform business decisions and build greater empathy for our customers   Build processes as the UX research team continues to grow  ', ' A portfolio that highlights your strengths ', ' Communicate and present research findings cross-functionally to inform business decisions and build greater empathy for our customers ', ' Mission:Democratize machine data analytics through the Sumo Logic platform, bringing real-time data insights securely through the cloud.', 'Location', 'Nice to have', '   Take ownership of the research vision for cross-functional scrum teams   Implement processes to mature UX research at Sumo Logic   Mentor and support UX researchers, designers and other cross-functional team members    ', '  Take ownership of the research vision for cross-functional scrum teams   Implement processes to mature UX research at Sumo Logic   Mentor and support UX researchers, designers and other cross-functional team members  ', ' Synthesize qualitative and quantitative insights and translate insights into actionable recommendations ', ' BA/BS degree in Anthropology, Human Factors, Psychology, HCI/Computer Science or other related fields or equivalent practical experience ', "" Master's degree or PhD in a related field "", ' Massive Scale:Our microservices architecture in AWS ingests hundreds of terabytes daily across many geographic regions. Millions of queries a day analyze hundreds of petabytes of data.', ' Take ownership of the research vision for cross-functional scrum teams ', '  Take ownership of the research vision for cross-functional scrum teams   Implement processes to mature UX research at Sumo Logic   Mentor and support UX researchers, designers and other cross-functional team members   ', ' Strong strategic, analytical, and creative skills with a history of tackling and solving complex design research opportunities ', ' Experience with leading design workshops ', 'About Us: https://app.box.com/v/SLGeneralDossier', 'Senior UX Researcher', ' Influence product development decision-making, based on your research insights ', ' Highly skilled in a range of user-centered design methodologies, with tangible deliverables ', '  Become familiar with the Sumo Logic product, customers, and a specific area of the product   Plan and execute research studies with cross-functional scrum teams   Influence product development decision-making, based on your research insights  ', ' Implement processes to mature UX research at Sumo Logic ', ' Collect feedback and champion iterative refinements of the product until the usability and experience reach desired expectations ', ' Experience with remote unmoderated research techniques ', ""  Master's degree or PhD in a related field   Experience with leading design workshops   Experience with data analysis and data visualization   Experience with remote unmoderated research techniques  "", 'Senior UX Researcher ', 'Minimum Requirements', ' Work closely with product designers, engineers, and product managers to identify research topics and define studies to address user behavior and attitudes ', ' What we do:We are a cloud-native SaaS machine data analytics platform, solving complex monitoring problems for DevOps, SecOps and ITOps teams. Customers love our product because it allows them to easily monitor and optimize their mission critical, large scale applications. Massive Scale:Our microservices architecture in AWS ingests hundreds of terabytes daily across many geographic regions. Millions of queries a day analyze hundreds of petabytes of data. Mission:Democratize machine data analytics through the Sumo Logic platform, bringing real-time data insights securely through the cloud. Funding and Growth:We have raised $345 million in funding to date, with the most recent round being May 2019. Investors include Battery Ventures, Greylock Partners, Sutter Hill Ventures, Accel Partners, Sequoia Capital, Sapphire Ventures and DFJ Growth. Our recurring revenue and customer base are growing steadily. We serve over 2,000 customers across the globe including AirBnB, Alaska Airlines, Anheuser Busch, Hootsuite, Hearst, Hudl, Major League Baseball, Marriott, Medidata, Sauce Labs, Samsung SmartThings, SPS Commerce, Twitter, Telstra, Toyota, Zuora and more.', ' Recruit research participants ', ' Plan and conduct research using a wide variety of qualitative and quantitative methods, and analyze through the lens of UX, HCI, and social science ', 'Within 3 Months You Will', ' 5+ years of experience in applied product research ']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Mid to Senior Data Engineer--Consulting Services--Remote Work Possible,Standav Corp,"Denver, CO",23 hours ago,177 applicants,"['', 'Knowledge of distributed databases such as Redshift, Snowflake, Azure Synapse, and BigQuery\xa0', 'Vertical--Services.', 'A passion to learn and improve your skills to deliver the best possible solutions to customers', '2+ years designing and developing data analytics solutions', '2+ years with databases such as SQL Server, Oracle, MySQL', 'Responsibilities:', 'Term-Full Time', 'Data migrations and conversions to the cloud and to cloud data warehouse services', 'Location--Denver area--some possible remote work as long as the candidate can go to a downtown office and metro Denver based end customers as necessary.', '$-Open', 'Data Engineers analyze and develop on-premises and/or cloud data and ETL solutions to solve the client’s challenges.\xa0They enjoy the challenges of consulting and thrive to knock the socks off of clients', 'Experience with cloud based data services offered by Azure, AWS and Google', 'Previous consulting experience preferred', 'Please note that this role is open to remote candidates provided that they lives relatively close to Denver CO to include neighboring states.', 'Create data visualizations, dashboards and reports as needed', 'Develop data models to meet client needs', 'Develop and scope requirements', 'Experience with data visualization tools such as Power BI and Tableau', 'Hands-on development and serve as technical expert on projectsDevelop data solutions leveraging traditional and cloud product offerings from leading vendorsDevelop data models to meet client needsDevelop data models to meet client needs, including transactional, third-normal form, dimensional, columnar, distributed and NoSQLDevelop ETL/ELT processes and patterns to efficiently move dataCreate data visualizations, dashboards and reports as neededData migrations and conversions to the cloud and to cloud data warehouse servicesDevelop and scope requirementsTravel as needed (currently less than 5%)Maintain effective communication with team and customers', 'Degree in computer science, information technology, engineering or business', 'Develop data solutions leveraging traditional and cloud product offerings from leading vendors', 'Open to mid to senior level resources.', 'Qualifications', 'Please note that this role is vendor agnostic in regards to what ETL tools are used, so having multi vendor experience would be ideal.', 'Travel as needed (currently less than 5%)', '2+ years data warehouse, dimensional modeling design and architecture', 'Hands-on development and serve as technical expert on projects', 'Maintain effective communication with team and customers', 'Customer needs team members that excel when working directly with clients to meet their goals. They understand the client’s needs and requirements and build a collaborative environment to ensure a successful project delivery.', 'Develop ETL/ELT processes and patterns to efficiently move data', '2+ years designing and developing data analytics solutions2+ years with databases such as SQL Server, Oracle, MySQL2+ years data warehouse, dimensional modeling design and architectureKnowledge of distributed databases such as Redshift, Snowflake, Azure Synapse, and BigQuery\xa0A passion to learn and improve your skills to deliver the best possible solutions to customersExperience with cloud based data services offered by Azure, AWS and GoogleExperience with data visualization tools such as Power BI and TableauPrevious consulting experience preferredDegree in computer science, information technology, engineering or business', 'Develop data models to meet client needs, including transactional, third-normal form, dimensional, columnar, distributed and NoSQL', 'Thanks for your interest. Please apply for further information.']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Compunnel Staffing,"New York, United States",20 hours ago,Over 200 applicants,"['', '-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa02+ years of experience in Data bricks', '-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa03+ years in Azure Analysis Service or Synapse Analytics', '-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Hands-on Experience with Data warehousing and BI', '-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with Scala or shell or python', '-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Need to be hands on Development – as this is an agile project , there would be deliverables for each individuals', '-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Understand client requirement and guide Offshore team on Development', 'Skill Expectation: ', '-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Good communication', 'Job Description:', '-\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Overall Understanding on Azure Stack']",Mid-Senior level,Contract,Engineering,Staffing and Recruiting,2020-11-05 11:32:32
Senior Data Engineer,Viant Technology,"Irvine, CA",5 hours ago,Be among the first 25 applicants,"['', 'Writing ETL and ELT jobs using various tools and programming languages.', 'Working with product owners, QA engineers and fellow engineers.', 'Exposure to NoSQL technologies a plus', 'Fully stocked kitchen', 'Writing ETL and ELT jobs using various tools and programming languages.Writing complex SQL queries.SQL query optimizations for speed and accuracy.Designing, developing, testing, debugging and deploying applications and reports using various technologies.Importing and exporting large amounts of data in formats like CSV, JSON, XML, etc.Need to be able to easily switch between different technologies.Solving complex performance problems, architectural challenges and production issues.Working with product owners, QA engineers and fellow engineers.Following organization processes and procedures.Ad-hoc duties as needed.', 'Experience with cloud based technologies like Google Cloud Platform, AWS.', 'Minimum B.S in computer science, mathematics or related field.', 'Ongoing Education & Training', 'Ability to troubleshoot queries, stored procedures, functions, packages and triggers.', 'Responsibilities', 'Experience with creating and consumption of REST API services.', 'Writing complex SQL queries.', 'Benefits', 'Importing and exporting large amounts of data in formats like CSV, JSON, XML, etc.', 'Excellent problem solving, critical thinking, and communication skills.', 'Competitive Salary and Bonuses', '401k', 'Casual Office Atmosphere', 'Paid benefits for the employees: Medical, Dental, Vision, LTD, Life insurance/AD&D', 'Commuter Benefits Program', '4-6 years of experience in data engineering.Minimum B.S in computer science, mathematics or related field.Strong foundation in computer science and OOP.Experience with Python, Java.Experience with cloud based technologies like Google Cloud Platform, AWS.Experience with creating and consumption of REST API services.Experience with MySQL, Oracle and other database technologies. Exposure to NoSQL technologies a plusAbility to troubleshoot queries, stored procedures, functions, packages and triggers.Excellent problem solving, critical thinking, and communication skills.Ability to learn newer technologies in a short period of time.A team player.Exposure to machine learning a plus', 'Experience with Python, Java.', 'Ability to learn newer technologies in a short period of time.', 'Ad-hoc duties as needed.', 'Qualifications', '4-6 years of experience in data engineering.', 'Employee discounts – e.g. gym memberships, wireless plans, entertainment tickets', 'Competitive Salary and BonusesPaid benefits for the employees: Medical, Dental, Vision, LTD, Life insurance/AD&DPaid parental leave401kSummer “Work from Anywhere” FridaysWellness programs – info sessions and occasional chair massagesEmployee discounts – e.g. gym memberships, wireless plans, entertainment ticketsFully stocked kitchenCasual Office AtmosphereCommuter Benefits ProgramOngoing Education & TrainingCompany Sponsored Events & Team Building Experiences', 'Following organization processes and procedures.', 'SQL query optimizations for speed and accuracy.', 'Summer “Work from Anywhere” Fridays', 'Designing, developing, testing, debugging and deploying applications and reports using various technologies.', 'Solving complex performance problems, architectural challenges and production issues.', 'Need to be able to easily switch between different technologies.', 'Experience with MySQL, Oracle and other database technologies. ', 'Wellness programs – info sessions and occasional chair massages', 'A team player.', 'Exposure to machine learning a plus', 'Company Sponsored Events & Team Building Experiences', 'Strong foundation in computer science and OOP.', 'Paid parental leave', 'About Viant']",Mid-Senior level,Full-time,Advertising,Marketing and Advertising,2020-11-05 11:32:32
Clinical Laboratory Scientist,TargetDx Laboratory,"San Francisco, CA",17 hours ago,30 applicants,"['', 'Troubleshoots and resolves technical problems.', 'Health insuranceDental insuranceVision insuranceRetirement 401k planPaid time offShort Term and Long-Term Disability', 'Document all corrective actions taken when test systems deviate from the laboratory’s established performance specifications.', 'Position Summary', 'All qualified applicants are encouraged to apply, and will be considered without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, disability or any other legally protected status.', 'Prior automation experience preferred', 'Perform accurate documentation, maintain of records related to the test lab, and ensure compliance with all federal and state regulations (CLIA laboratory).', 'Health insurance', 'Manage multiple tasks to meet the timelines.', 'Vision insurance', 'Dental insurance', 'Perform quality control procedures to ensure accuracy of clinical data.', '\xa0', 'Benefits', 'Lung Cancer Proteomics is a growing biotechnology company with a mission of developing sensitive and specific blood tests to detect high mortality cancers early as well as provide COVID and other virology tests. By adhering to a data driven approach and using rigorous scientific processes, we strive to innovate, simplify, and improve early diagnostic tools, which lead to an increase survival rate and better quality of life.', '2 years qPCR experience required', 'Organize specimens and prepare reagents for testing.', 'Perform stock inventory and monitor reagents.', 'Schedule:\xa0\xa0Monday to Friday, 8-hour day shift', 'Bachelor’s degree in chemical, biological, clinical laboratory, or related field', 'Bachelor’s degree in chemical, biological, clinical laboratory, or related field2 years RNA extraction experience required2 years qPCR experience requiredPrior automation experience preferredCurrently licensed Clinical Laboratory Scientist', '2 years RNA extraction experience required', 'Calibrate and maintain lab equipments.', 'Receive specimen shipments; judge the adequacy and quality of specimen submitted for testing; and accessions specimens according to SOP.Organize specimens and prepare reagents for testing.Perform quality control procedures to ensure accuracy of clinical data.Validate test results through correlation with test parameters and QC metrics.Perform preventative maintenance and troubleshooting on instrument(s) and equipment.Troubleshoots and resolves technical problems.Records any repair, replacement, and maintenance needed of equipment.Calibrate and maintain lab equipments.Document all corrective actions taken when test systems deviate from the laboratory’s established performance specifications.Perform proficiency testing successfully and record results accuratelyPerform accurate documentation, maintain of records related to the test lab, and ensure compliance with all federal and state regulations (CLIA laboratory).Perform stock inventory and monitor reagents.Manage multiple tasks to meet the timelines.Follow all laboratory policies and procedures including, but not limited to, general processes, safety, and quality.Demonstrates high level of integrity and honesty in maintaining compliance in regard to PHI.', 'Lung Cancer Proteomics is proud to be an Equal Opportunity Employer. We are committed to ensuring a diverse and inclusive workplace environment, and welcome people of different backgrounds, experiences, abilities and perspectives. ', 'Records any repair, replacement, and maintenance needed of equipment.', 'Perform preventative maintenance and troubleshooting on instrument(s) and equipment.', 'Retirement 401k plan', 'We are seeking a Clinical Lab Scientist (CLS) to perform complex laboratory procedures, including for the detection of the SARS-CoV-2 virus, in a prompt, accurate, and reliable manner according to established procedures and quality control guidelines. The CLS will be responsible for specimen processing, test performance, reporting test results, perform quality control, and verification of controls. The CLS will review results for accuracy and precision; repeat tests or perform confirmatory tests as appropriate.', 'Job Type: Full Time', 'Paid time off', 'Validate test results through correlation with test parameters and QC metrics.', 'Equal Opportunity Employer', 'Receive specimen shipments; judge the adequacy and quality of specimen submitted for testing; and accessions specimens according to SOP.', 'Responsibilities and Duties', 'Short Term and Long-Term Disability', 'Schedule:', 'Demonstrates high level of integrity and honesty in maintaining compliance in regard to PHI.', 'Job Type: ', 'Currently licensed Clinical Laboratory Scientist', 'Minimum Qualification', 'Perform proficiency testing successfully and record results accurately', 'Follow all laboratory policies and procedures including, but not limited to, general processes, safety, and quality.']",Entry level,Full-time,Research,Medical Devices,2020-11-05 11:32:32
Data Engineer With Google Cloud,itechstack,"San Jose, CA",13 hours ago,Be among the first 25 applicants,[''],Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Integrations Data Engineer,Nesco Resource,"Cleveland, OH",18 hours ago,Be among the first 25 applicants,"['', 'Job Description', 'Must Have', 'Nice To Have', 'Nesco Resource is an equal employment opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, or veteran status, or any other legally protected characteristics with respect to employment opportunities.']",Associate,Full-time,Information Technology,Construction,2020-11-05 11:32:32
Clinical Trial Management Associate,Net2Source Inc.,"Madison, NJ",,N/A,"['', '12. Provide input and support in the development and distribution of monthly site newsletters. ', '13. Support the Regional Site Managers by providing study related information and supplies, as requested. ', 'Want to read more about Net2Source? Visit us at www.net2source.com', 'Equal Employment Opportunity', 'Location: Madison NJ', '7. Participate in testing of specifications and edit checks for internal (i.e. electronic data capture (EDC) and external (e.g. Interactive Voice/Web Response Systems (IVRS/IWRS), laboratory vendors) systems. ', '10. Assist with ongoing data review and discuss comments with the clinical study team as needed. ', 'Travel Requirements:', 'Net2Source is a total talent management solutions company with its presence in 50+ countries.\xa0Our creative solution service offerings aim at becoming your one stop destination for hiring talent needs globally.', 'Role: Clinical Trial Management Associate', 'we are hiring ""Job Title"" for one of our clients', '8. Assist senior team members with in the planning, preparation, and on-site support of investigators meetings. ', 'Additional Information', 'Paul.Higgins@net2source.com', 'Required Education/Experience: Associate degree or higher preferred Experience: 1-2 year relevant experience in pharmaceutical industry or CRO Experience supporting clinical trials preferred.', 'Job Description:', '3. Organize and maintain project working files and track critical documents. Report discrepancies to the appropriate clinical team member in a timely manner. ', 'Hours: 40 hours/week', '9. Generate reports in various applications to assist the Clinical Scientist to perform clinical data review. ', 'About Net2Source, Inc.', 'SME Pharma', '15. Support and correspond with sites to identify site specific needs (e.g. order and track study drug/other trial related supplies).', '14. Communicate with IRBs and outside vendors to provide information and/or resolution to specific requests/issues.', 'The United States Government does not discriminate in employment on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factor.', 'Rajesh@net2source.com', 'Net2Source is a Global Workforce Solutions Company headquartered at NJ, USA with its branch offices in Asia Pacific Region.\xa0\xa0We are one of the fastest growing IT Consulting company across the USA and we are hiring ""Job Title"" for one of our clients.\xa0\xa0We offer a wide gamut of consulting solutions customized to our 450+ clients ranging from Fortune 500/1000 to Start-ups across various verticals like Technology, Financial Services, Healthcare, Life Sciences, Oil & Gas, Energy, Retail, Telecom, Utilities, Technology, Manufacturing, the Internet, and Engineering.', 'Compensation: Open for Negotiation. (Including assignment completion bonus).', '4. Reconcile and transmit all essential documentation to CDIC as per Forest policy. ', '11. Assist with the preparation and distribution of meeting agendas and minutes. Actively participate in team meetings. ', 'Primary Job Responsibilities', 'Free to message me here, call or text at [201-479-2046] to get you ready for your next assignment. You can also email me at [Rajesh@net2source.com] @Amrit.a@net2source.com, Paul.Higgins@net2source.com', 'Shift : 1st', 'Up to 20% travel both domesic and international.', '2. Work closely with the Site Start Up (SSU) and ensure all study related regulatory and financial documents are collected and reviewed in support of study activation. ', '5. Track and assist with processing site/vendor payments. Follow up on any issues as required. 6. Collect and track patient enrollment information and update study management reports as necessary. ', 'Net2Source Inc. is one of the fastest growing Global Workforce Solutions company with a growth of 100% YoY for last consecutive 3 years with over 4100+ employees globally and 30+ locations in US and operations in 50+ countries. With an experience of over a decade we offer unmatched workforce solutions to our clients by developing an in-depth understanding of their business needs. We specialize in Contingent hiring, Direct Hires, Statement of Work, Payroll Management, IC Compliance, VMS, RPO and Managed IT Services.', 'Duration: 12 Months', '1. Support study feasibility activities and perform database/web searches for sites as needed. ', 'Rajesh Kumar', 'Office: (201) 479 2046 Fax: (201) 221-8131| Email: Rajesh@net2source.com', 'Amrit.a@net2source.com', 'Regards', 'Refer someone and receive up to $500 referral bonus. Contact me for more info!']",Associate,Contract,Research,Staffing and Recruiting,2020-11-05 11:32:32
Staff Software Engineer,MinTech Agency ~ Diversity Recruiting,"Duluth, GA",2 hours ago,Be among the first 25 applicants,"['', 'Evaluate the applicability of leading-edge technologies and use this information to significantly influence future business strategies', 'Building self-service platforms to power across functional teams and drive the whole organization to be data driven. Serve data models as a product to entire organization.', 'Work independently and provides technical guidance, applying in-depth knowledge of multiple technologies, as appropriate. Provides technical leadership and mentoring to other team members.', 'Essential Functions', '5+ years of “hands on” experience with Python, Scala, Java developing ETL pipelines and data manipulation scripts using SQL, and modern relational, analytical and graph databases.', 'Education/Experience:', 'Serve as a coach and mentor to more junior developers to include delegating and managing tasks, as appropriate', "" Bachelor's degree in Computer Science and/or Engineering with 10+ years of related experience or an equivalent combination of education and experience; Master's degree preferred 8+ years of experience in data engineering, batch and stream processing technologies, data science, and related data-centric fields using large-scale data environments. 5+ years of “hands on” experience with Python, Scala, Java developing ETL pipelines and data manipulation scripts using SQL, and modern relational, analytical and graph databases. Good understanding of data engineering, ingestion and processing of data within Big Data ecosystems and performing complex query analysis on the data using cloud technologies, preferably with Google Cloud Platform . Evaluate the applicability of leading-edge technologies and use this information to significantly influence future business strategies Hands-on experience and deep technical understanding of including (but not limited to) Hadoop, Spark, BigQuery, Composer, Dataflow, Pub/Sub, Kafka etc. Evaluate the applicability of leading-edge technologies and use this information to significantly influence future business strategies Work independently and provides technical guidance, applying in-depth knowledge of multiple technologies, as appropriate. Provides technical leadership and mentoring to other team members. Experience working closely with cross functional analytics and Data Science teams. Experience in CI/CD, DevOps process and tools."", 'Lead team to deliver large-scale projects, set and drive roadmap execution through resource planning and allocation.', 'Experience in CI/CD, DevOps process and tools.', 'Thinking through long-term impacts of key design decisions and handling failure scenarios. Evolve platform maturity in automation, operations, stability, and support.', '8+ years of experience in data engineering, batch and stream processing technologies, data science, and related data-centric fields using large-scale data environments.', 'This is a remote position.', 'Lead overall team in innovation of technical and business concepts and drive the test and learn mindset across the team.', 'Good understanding of data engineering, ingestion and processing of data within Big Data ecosystems and performing complex query analysis on the data using cloud technologies, preferably with Google Cloud Platform .', 'Requirements', 'Experience working closely with cross functional analytics and Data Science teams.', 'Design, test, and implement data engineering solutions for various consumers of the data.', 'Hands-on experience and deep technical understanding of including (but not limited to) Hadoop, Spark, BigQuery, Composer, Dataflow, Pub/Sub, Kafka etc.', 'Perform other duties as assigned', ""Bachelor's degree in Computer Science and/or Engineering with 10+ years of related experience or an equivalent combination of education and experience; Master's degree preferred"", 'Architect and design large scale data analytics infrastructure in cloud (performance, reliability, monitoring, self-service).', 'Maintain awareness of industry trends and evaluate applicability of new software tools to platform development.', ' This is a remote position.', ' Lead team to deliver large-scale projects, set and drive roadmap execution through resource planning and allocation. Architect and design large scale data analytics infrastructure in cloud (performance, reliability, monitoring, self-service). Design, test, and implement data engineering solutions for various consumers of the data. Thinking through long-term impacts of key design decisions and handling failure scenarios. Evolve platform maturity in automation, operations, stability, and support. Lead overall team in innovation of technical and business concepts and drive the test and learn mindset across the team. Building self-service platforms to power across functional teams and drive the whole organization to be data driven. Serve data models as a product to entire organization. Maintain awareness of industry trends and evaluate applicability of new software tools to platform development. Serve as a coach and mentor to more junior developers to include delegating and managing tasks, as appropriate Perform other duties as assigned ']",Mid-Senior level,Full-time,Engineering,Retail,2020-11-05 11:32:32
Sr Big Data Engineer,Crown Castle,"Houston, PA",7 hours ago,Be among the first 25 applicants,"['', 'Ability to work in a team-oriented, collaborative environment; good interpersonal skills', ' Bachelor’s degree in Computer Science, Engineering, Information Science, Math or related discipline Data engineering, data management or cloud certification is a plus ', 'Ability to present and explain technical information to diverse types of audiences in a way that establishes rapport and gains understanding', 'Two (2)+ years’ experience building data platforms using Azure stack (Azure Data Factory, Azure DataBricks, etc.)', 'Experience with parsing data formats such as XML/JSON and leveraging external APIs', 'Position Summary', 'Working Conditions:', 'Collaborate with data architects and modelers on data store designs and best practices', 'Experience/Minimum Requirements', 'Position Title:', 'Other Skills/Abilities', 'Education/Certifications', ' Five (5)+ years’ experience in traditional and modern Big Data technologies (HDFS, Hadoop, Hive, Pig, Sqoop, Kafka, Apache Spark, hBase, Oozie, No SQL databases, PostgreSQL, GIT, Python, REST API, Snowflake, etc.) Two (2)+ years’ experience building data platforms using Azure stack (Azure Data Factory, Azure DataBricks, etc.) Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala Experience extracting/querying/joining large data sets at scale Experience utilizing Snowflake to build data marts with the data residing in Azure storage is a plus ', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data pipeline performance, re-designing infrastructure for greater scalability and access to information.', 'Five (5)+ years’ experience in traditional and modern Big Data technologies (HDFS, Hadoop, Hive, Pig, Sqoop, Kafka, Apache Spark, hBase, Oozie, No SQL databases, PostgreSQL, GIT, Python, REST API, Snowflake, etc.)', 'Data engineering, data management or cloud certification is a plus', 'Experience utilizing Snowflake to build data marts with the data residing in Azure storage is a plus', 'Assess new data sources to better understand availability and quality of data.', 'Strong customer service orientation', 'Design, develop and maintain an optimal data pipeline architecture using both structured data sources and big data for both on-premise and cloud-based environments in both streaming and real time.', 'Develop and automate ETL code using scripting languages, ETL tools and job scheduling software to support all reporting and analytical data needs.', 'Assemble large, complex data sets that meet the analytical needs of the data science team.', 'Experience extracting/querying/joining large data sets at scale', 'Thorough understanding of relational, columnar and NoSQL database architectures and industry best practices for development', 'Design and build dimensional data models to support the data warehouse initiatives.', 'Excellent advanced SQL coding and performance tuning skills', 'Strong analytical and problem-solving skills; ability to weigh various suggested technical solutions against the original business needs and choose the most cost-effective solution', ' Design, develop and maintain an optimal data pipeline architecture using both structured data sources and big data for both on-premise and cloud-based environments in both streaming and real time. Develop and automate ETL code using scripting languages, ETL tools and job scheduling software to support all reporting and analytical data needs. Design and build dimensional data models to support the data warehouse initiatives. Assemble large, complex data sets that meet the analytical needs of the data science team. Assess new data sources to better understand availability and quality of data. Identify, design, and implement internal process improvements: automating manual processes, optimizing data pipeline performance, re-designing infrastructure for greater scalability and access to information. Participate in requirements gathering sessions to distill technical requirements from business requests. Collaborate with business partners to productionize, optimize, and scale enterprise analytics. Collaborate with data architects and modelers on data store designs and best practices ', 'Keen attention to detail and ability to access impact of design changes prior to implementation', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala', 'Collaborate with business partners to productionize, optimize, and scale enterprise analytics.', 'Participate in requirements gathering sessions to distill technical requirements from business requests.', 'Understanding of dimensional data modeling for designing and building data warehouses', 'Company Summary', ' Thorough understanding of relational, columnar and NoSQL database architectures and industry best practices for development Understanding of dimensional data modeling for designing and building data warehouses Excellent advanced SQL coding and performance tuning skills Experience with parsing data formats such as XML/JSON and leveraging external APIs Understanding of agile development methodologies Ability to work in a team-oriented, collaborative environment; good interpersonal skills Strong analytical and problem-solving skills; ability to weigh various suggested technical solutions against the original business needs and choose the most cost-effective solution Keen attention to detail and ability to access impact of design changes prior to implementation Self-driven, highly motivated and ability to learn quick Ability to effectively prioritize and execute tasks in a high-pressure environment Strong customer service orientation Ability to present and explain technical information to diverse types of audiences in a way that establishes rapport and gains understanding Work experience with geospatial data and spatial analytics is preferred ', 'Bachelor’s degree in Computer Science, Engineering, Information Science, Math or related discipline', 'Key Responsibilities', 'Ability to effectively prioritize and execute tasks in a high-pressure environment', 'Understanding of agile development methodologies', 'Self-driven, highly motivated and ability to learn quick', 'Work experience with geospatial data and spatial analytics is preferred']",Associate,Full-time,Engineering,Telecommunications,2020-11-05 11:32:32
Engagement Managers,RomAnalytics,"Princeton, NJ",22 hours ago,40 applicants,"['', 'Bachelor of Science Degree required.', 'Deep understanding of Pharma and Biotech industry trends and organizational structure and business functions. Past experience in multiple therapeutic areas: primary care, oncology, specialty etc.Ability to translate business problems into powerful analytical solutions and concrete project plans.Articulate and engaging professional, a self-starter and problem solver.Strong Analytics background and working knowledge of datasets and data sources in the Pharma/Biotech space including Claims, EMR/EHS, Specialty Pharmacy data, Remit Data, Lab/Diagnostics data.Working knowledge of one or more of programming tools such as SAS, SQL, R, or Python preferred (not required).Proven experience and Ability to manage combination of on site and offshore Project teams internally and externally at the client end.Ability to build relationships across hierarchy and at senior levels within client organizations.Ability to identify cross sell and up sell opportunities at the client organization by being aware of and engaging in their core day to day business issues.Ability to set and manage expectations and deliver on them to maintain high client satisfaction.Strong project management skills, analytical skills & communication skills.6-12 years’ experience in Business Analytics and or as a Data Scientist.Bachelor of Science Degree required.', 'Articulate and engaging professional, a self-starter and problem solver.', 'Responsible for day to day project needs of the client with the ability to provide quick analytical solutions. Incumbent may work as an individual contributor and/or manage a project team with on site and off-shore support. Ability to manage and prioritize across multiple deadlines and projects and excellent client management and project management skills are a must.', 'Manage & Execute projects in areas of Marketing, Sales & Market Access related Commercial Analytics', 'Leads client engagement and project management from the delivery standpoint. Responsible for proactively identifying opportunities and for scoping projects by translating client business questions into an analytical framework. Partners closely with stakeholders, manages and executes projects successfully, communicating milestones and results.Responsible for day to day project needs of the client with the ability to provide quick analytical solutions. Incumbent may work as an individual contributor and/or manage a project team with on site and off-shore support. Ability to manage and prioritize across multiple deadlines and projects and excellent client management and project management skills are a must.Works actively in partnership with Sales lead to identify and generate cross sell and upsell opportunities within client organization/s. Builds and maintains relationships across cross functional teams and partners with client teams to deliver client satisfaction', 'Working knowledge of one or more of programming tools such as SAS, SQL, R, or Python preferred (not required).', 'Proven experience and Ability to manage combination of on site and offshore Project teams internally and externally at the client end.', '6-12 years’ experience in Business Analytics and or as a Data Scientist.', '\xa0', 'Ability to set and manage expectations and deliver on them to maintain high client satisfaction.', 'Strong project management skills, analytical skills & communication skills.', 'Role Description:', 'Leads client engagement and project management from the delivery standpoint. Responsible for proactively identifying opportunities and for scoping projects by translating client business questions into an analytical framework. Partners closely with stakeholders, manages and executes projects successfully, communicating milestones and results.', 'Ability to build relationships across hierarchy and at senior levels within client organizations.', 'Create insightful summary and deck (storyboarding) in order to provide strategic recommendations to clients and other stakeholders.', 'RomAnalytics is recruiting this position on behalf of a rapidly growing cutting edge Healthcare Analytics company powered by AI/ML & Technology, deep Domain expertise in Pharma & Biotech, as well as a High Touch Consultative relationship based approach.', 'Deep understanding of Pharma and Biotech industry trends and organizational structure and business functions. Past experience in multiple therapeutic areas: primary care, oncology, specialty etc.', 'Functions and Responsibilities:', 'Manage & Execute projects in areas of Marketing, Sales & Market Access related Commercial AnalyticsBusiness Analytics projects including Performance trackers and dashboards, analytics on KPIs and related data metricsPatient Insights & Analytics projects include Analytics include Patient Finder Analysis, Claims Data Analysis. Patient Journey Analysis and require gaining knowledge in a given therapeutic area and market dynamics within it. Predictive analytics projects using claims data and/or specialty pharmacy data.Create insightful summary and deck (storyboarding) in order to provide strategic recommendations to clients and other stakeholders.Maintain seamless communication with client, get necessary clarifications and resolve outstanding issues proactively.', 'Patient Insights & Analytics projects include Analytics include Patient Finder Analysis, Claims Data Analysis. Patient Journey Analysis and require gaining knowledge in a given therapeutic area and market dynamics within it. Predictive analytics projects using claims data and/or specialty pharmacy data.', 'Ability to translate business problems into powerful analytical solutions and concrete project plans.', 'Business Analytics projects including Performance trackers and dashboards, analytics on KPIs and related data metrics', 'Works actively in partnership with Sales lead to identify and generate cross sell and upsell opportunities within client organization/s. Builds and maintains relationships across cross functional teams and partners with client teams to deliver client satisfaction', 'Qualifications / Requirements:', 'Ability to identify cross sell and up sell opportunities at the client organization by being aware of and engaging in their core day to day business issues.', 'Strong Analytics background and working knowledge of datasets and data sources in the Pharma/Biotech space including Claims, EMR/EHS, Specialty Pharmacy data, Remit Data, Lab/Diagnostics data.', 'Maintain seamless communication with client, get necessary clarifications and resolve outstanding issues proactively.']",Director,Full-time,Marketing,Management Consulting,2020-11-05 11:32:32
"Director, Model Risk and Validation - CPG",Harnham,Cincinnati Metropolitan Area,,N/A,"['', 'Cincinnati, OH', 'YOUR SKILLS AND EXPERIENCE', 'A Fortune 500 business with a huge amount of data is looking for a Model Risk Director to lead a new division focused on validating machine learning models. This is an amazing opportunity to work with wide-ranging data sets while leading the strategic vision for a new team. \xa0', 'Model Risk, Model Validation, Machine Learning, Data Science, Data Scientist, Deep Learning, Asset, Liability, Fraud, Risk, Data Engineer, Standards, SAS, SQL, Python, Director, Manager, VP, SVP.\xa0', 'Deep subject matter expertise to automate model development and validation.You will ideally have worked in a client-facing analytics position at a leadership level.Senior-level stakeholder engagement is a must!', 'KEYWORDS', 'Lead a cross-functional team of data engineers, data scientists and technologists to ensure best practice for the development and implementation of machine learning models.', 'Responsible for oversight of all model risk and validation in a centralized function.', '$160,000 - $180,000 + Bonus', 'Interact with senior stakeholders and act as an analytics evangelist.', 'Lead a cross-functional team of data engineers, data scientists and technologists to ensure best practice for the development and implementation of machine learning models.Responsible for oversight of all model risk and validation in a centralized function.Mentor and manage junior team members.Interact with senior stakeholders and act as an analytics evangelist.', 'The successful Director, Model Risk and Validation can expect a salary of $160,000 - $180,000 plus a comprehensive bonus and benefits package.', 'For more information about the role press “apply now”.', 'Director, Model Risk and Validation - CPG', 'Senior-level stakeholder engagement is a must!', 'SALARY AND BENEFITS', 'DIRECTOR, MODEL RISK AND VALIDATION – ROLE OVERVIEW', 'Mentor and manage junior team members.', 'You will ideally have worked in a client-facing analytics position at a leadership level.', 'HOW TO APPLY', 'Deep subject matter expertise to automate model development and validation.']",Director,Full-time,Analyst,Consumer Goods,2020-11-05 11:32:32
Technical Data Engineer,Valley Bank,"Wayne, NJ",6 hours ago,179 applicants,"['', 'Agile project methodology and waterfall where required.', 'Solid track record of data integration showing excellent execution and attention to detail.', 'Experience in SQL, MySQL and SQL Server databases. Experience in MapReduce is a plus.', 'Experience in a cloud environment (MS Azure preferred).', 'Ability to learn to create a data-driven culture and impactful data strategies.', 'Knowledge of Data warehousing best practices for optimal performance in an MPP environment.', 'Write query to filter data or to join multiple data sets.', 'Ability to communicate both verbally and written to employees in the business units utilizing non-technical language.', 'Financial Services, Retail Banking, Credit Card data or related domain / industry experience of at least 2 years.', 'B.S in computer science or a related IT degree with a minimum of 2 years of big data engineering experience.', 'Cloudera Pig, Sqoop, HIVEW, MapRedue, Scala, Spark, Trifacta, etc. Cloud (Azure/AWS) experience preferred.', 'Knowledge of data mining, machine learning, natural language processing or information retrieval. Knowledge of integration concepts as they relate to sourcing data from disparate sources.', 'Experience in production support and troubleshooting.', 'Import and export data between an external RDBMS and the Hadoop Cloudera cluster, including the ability to import specific subsets, change the delimiter and file format of imported data during ingest and alter the data access pattern or privileges.', 'Programming experience ideally in Spark and a willingness to learn new languages to meet goals and objectives. Experience in Python, Kafka, Java, C, Perl, Javascript or other programming languages is a plus.', ' B.S in computer science or a related IT degree with a minimum of 2 years of big data engineering experience. Working with Big Data projects. Must have experience developing and integrating solutions for Big Data Platforms, including Azure. Financial Services, Retail Banking, Credit Card data or related domain / industry experience of at least 2 years. Cloudera Pig, Sqoop, HIVEW, MapRedue, Scala, Spark, Trifacta, etc. Cloud (Azure/AWS) experience preferred.', 'Build scalable databases for the consumption of structured and unstructured data, work with external data providers to maximize competitor data throughout Valley National Bank.', ' Build scalable databases for the consumption of structured and unstructured data, work with external data providers to maximize competitor data throughout Valley National Bank. Import and export data between an external RDBMS and the Hadoop Cloudera cluster, including the ability to import specific subsets, change the delimiter and file format of imported data during ingest and alter the data access pattern or privileges. Automate data pipelines from various systems to create advanced analytics and Machine Learning. Ingest real-time and near real time (NRT) streaming data into HDFS, including the ability to distribute to multiple data sources and convert data from on ingest from one format to another. Convert data from one file format to another, Evolve an Avro or Parquet schema for performance optimization. Develop RESTful web services. Write query to filter data or to join multiple data sets. Agile project methodology and waterfall where required. ', 'Automate data pipelines from various systems to create advanced analytics and Machine Learning.', 'Convert data from one file format to another, Evolve an Avro or Parquet schema for performance optimization.', ' Solid track record of data integration showing excellent execution and attention to detail. Programming experience ideally in Spark and a willingness to learn new languages to meet goals and objectives. Experience in Python, Kafka, Java, C, Perl, Javascript or other programming languages is a plus. Experience in SQL, MySQL and SQL Server databases. Experience in MapReduce is a plus. Knowledge of data mining, machine learning, natural language processing or information retrieval. Knowledge of integration concepts as they relate to sourcing data from disparate sources. Experience in a cloud environment (MS Azure preferred). Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources. Knowledge of Data warehousing best practices for optimal performance in an MPP environment. Experience with Apache Avro and Apache Parquet. Experience with Impala with Kudo (interactive SQL). Experience with BI Visualization tools like MS PowerBI. Experience with test automation and QA. Knowledge of Machine Learning and Computational Statistics. Ability to communicate both verbally and written to employees in the business units utilizing non-technical language. Willingness to explore new alternatives or options to solve data integration issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done. Experience in production support and troubleshooting. Ability to learn to create a data-driven culture and impactful data strategies. ', 'Required Experience', 'Knowledge of Machine Learning and Computational Statistics.', 'Requirements', 'Must have experience developing and integrating solutions for Big Data Platforms, including Azure.', 'Responsibilities Include But Are Not Limited To', 'Ingest real-time and near real time (NRT) streaming data into HDFS, including the ability to distribute to multiple data sources and convert data from on ingest from one format to another.', 'Required Skills', 'Develop RESTful web services.', 'Working with Big Data projects.', 'Experience with Apache Avro and Apache Parquet. Experience with Impala with Kudo (interactive SQL). Experience with BI Visualization tools like MS PowerBI. Experience with test automation and QA.', 'Willingness to explore new alternatives or options to solve data integration issues, and utilize a combination of industry best practices, data innovations and your experience to get the job done.', 'Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources.']",Entry level,Full-time,Information Technology,Banking,2020-11-05 11:32:32
"Senior Scientist, IVD",Guardant Health,"Redwood City, CA",6 hours ago,36 applicants,"['', 'Guardant Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.', 'Employee may be required to lift routine office supplies and use office equipment. Majority of the work is performed in a desk/office environment; however, there may be exposure to high noise levels, fumes, and biohazard material in the laboratory environment. Ability to sit for extended periods of time.', 'Education', 'Experience with assay development and validation under an FDA regulated environment for IVD product', 'Strong data analysis skills (Python, R, JMP etc.) and fundamental understanding of statistics, preferably experience with NGS data', 'Be highly committed and deliver results in a fast-paced environment', 'Curiosity and drive', 'Demonstrated ability to contribute in a team environment where numerous inputs are required to accomplish complex goals', 'Work in a team environment and independently develop, test and validate technologies for early cancer detection with next-generation sequencing under design controlThink creatively and apply knowledge to design validation and analyze data for NGS applications in oncology diagnosticsApply previous experience to author study protocols and write technical reports to support FDA submissionsBe highly committed and deliver results in a fast-paced environment', 'Essential Duties And Responsibilities', 'Qualifications', 'Extensive experience in assay set up, reagent development and experimental design of nucleic acids technologies with a preference for sequencing-based assays', 'Think creatively and apply knowledge to design validation and analyze data for NGS applications in oncology diagnostics', 'Apply previous experience to author study protocols and write technical reports to support FDA submissions', 'Company Description', 'Job Description', 'Experience with assay development and validation under an FDA regulated environment for IVD productExtensive experience in assay set up, reagent development and experimental design of nucleic acids technologies with a preference for sequencing-based assaysStrong data analysis skills (Python, R, JMP etc.) and fundamental understanding of statistics, preferably experience with NGS dataDemonstrated ability to organize, document, and communicate scientific data with attention to detailDemonstrated ability to contribute in a team environment where numerous inputs are required to accomplish complex goalsCuriosity and drive', 'Work in a team environment and independently develop, test and validate technologies for early cancer detection with next-generation sequencing under design control', 'Demonstrated ability to organize, document, and communicate scientific data with attention to detail', 'Privacy Notice for Job Applicants', 'All your information will be kept confidential according to EEO guidelines.']",Associate,Full-time,Research,Computer Software,2020-11-05 11:32:32
Postdoctoral Researcher/Research Specialist D,Gene Therapy Program | University of Pennsylvania,"Philadelphia, PA",,N/A,"['', 'As a Postdoc/Research Specialist D, in collaboration with your Research Director and other Investigators on your team, you will execute on designed work plans. You will be working in the setting of large interdisciplinary teams, where you will function with limited oversight in the execution of in vitro and in vivo experiments while working cross-functionally with core labs and resources. With oversight of the Research Director, you will perform design, optimize, and implement complex experiments within specified timelines. You will work closely with the research director to assure that the research program adheres to the work plan and stays within budget. Also, you will have the opportunity to present research externally and you may contribute to writing/reviewing manuscripts, protocols, and SOPs.', 'Qualified candidates will have expertise with in vitro and in vivo experiments as well as a background in various disease models,\xa0', 'Joining GTP offers scientific professionals the unique opportunity of seeing their research go from bench to bedside and discoveries that could one day lead to cures.', 'Postdoc/Research Specialist D', 'The laboratory of Dr. Jim Wilson, at\xa0GTP\xa0of the University of Pennsylvania, has been a leader in the development of innovative vector technology for close to three decades. We have emerged as the ‘go-to’ organization for public and private partners, who want to participate in the gene therapy space. Currently, we are positioned to lead another round of vector innovation and establish pre-clinical and clinical proof-of-concept in therapeutic applications of in-vivo genome editing.', 'Ph.D. degree in the field of immunology, molecular biology, gene therapy, or related fields required.\xa0', 'As a top candidate, you will possess: ', 'Penn adheres to a policy that prohibits discrimination on the basis of race, color, sex, sexual orientation, gender identity, religion, creed, national or ethnic origin, citizenship status, age, disability, veteran status, or any other legally protected class.', 'Must thrive in a team environment, be an independent/critical thinker, have excellent written and oral communication skills, and ability to prioritize/multitask in a fast-paced environment.', 'Ph.D. degree in the field of immunology, molecular biology, gene therapy, or related fields required.\xa0Experience working with small animal models requiredMust thrive in a team environment, be an independent/critical thinker, have excellent written and oral communication skills, and ability to prioritize/multitask in a fast-paced environment.', 'The Gene Therapy Program (GTP) is entering a new era of unprecedented opportunity with great potential to reshape the face of medicine as we know it. Our discoveries have set the stage for successful treatments and possibly even cures for devastating genetic diseases.\xa0', 'Due to the continued growth of our program, we are searching for a new Postdoc/Research Specialist D to collaborate on gene therapeutic development research projects to treat or cure rare disease, performing both theoretical and bench research.\xa0', 'Experience working with small animal models required']",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Nuclear Reactor Modeling and Simulation Researcher,Idaho National Laboratory,"Idaho Falls, ID",16 hours ago,Be among the first 25 applicants,"['', 'Demonstrated oral and published written communication skills (in English)', 'Preferable Additional Skills', 'PhD or MS and 1 year OR BS and 2 years experience in a technical field such as nuclear engineering, mechanical engineering, applied mathematics or comparable.', 'Experience in RELAP5-3D analysis or development', ' PhD or MS and 1 year OR BS and 2 years experience in a technical field such as nuclear engineering, mechanical engineering, applied mathematics or comparable. US Citizens or applicants with up to date visas and eligibility to work in the US will be considered for this position. Demonstrated oral and published written communication skills (in English) Knowledge of Fortran and at least an object-oriented language (i.e. C++, python, etc.) Expertise in CFD and/or TH applied to nuclear systems. Experience in implementing production codes and knowledge of at least one major programming language Solid understanding of numerical methods for discretizing partial differential equations. Proficient in fluid mechanics, thermal-hydraulics, multi-physics simulations, and reactor engineering. Must be able to work in a culturally diverse environment. ', 'US Citizens or applicants with up to date visas and eligibility to work in the US will be considered for this position.', 'Expertise in reduced order modeling and data driven techniques.', 'Must be able to work in a culturally diverse environment.', 'Grade: ', 'Expertise in C++ programming language.', 'Knowledge of any of the following softwares: OpenFOAM, RELAP-5, STAR-CCM+, NEK-5000, Serpent.', 'Organization', 'Analysis of traditional and advanced nuclear reactors using MOOSE, RELAP-5, or other software.', 'Expertise in turbulence modeling.', ""Development, implementation, and testing of CFD and TH capabilities in INL's multiphysics object oriented simulation environment (MOOSE) or other software."", ' Knowledge of the MOOSE tools. Expertise in turbulence modeling. Expertise in reduced order modeling and data driven techniques. Proven track record of multiphysics simulations. Knowledge of any of the following softwares: OpenFOAM, RELAP-5, STAR-CCM+, NEK-5000, Serpent. Expertise in C++ programming language. Expertise in git version control. Experience in RELAP5-3D analysis or development ', 'Expertise in CFD and/or TH applied to nuclear systems.', 'Schedule', 'Unposting Date', 'Expertise in git version control.', 'Knowledge of Fortran and at least an object-oriented language (i.e. C++, python, etc.)', 'Responsibilities Include But Are Not Limited To', 'Development of novel ideas that advance the state of the art in CFD/TH models of advanced nuclear reactors.', 'Publication of research that advances the state of the art of nuclear CFD/TH.', 'Primary Location', 'Proficient in fluid mechanics, thermal-hydraulics, multi-physics simulations, and reactor engineering.', 'Solid understanding of numerical methods for discretizing partial differential equations.', 'Job', 'Proven track record of multiphysics simulations.', 'Job Posting', 'Multiphysics simulation of advanced nuclear systems.', 'WORK LOCATION: ', 'Experience in implementing production codes and knowledge of at least one major programming language', "" Development, implementation, and testing of CFD and TH capabilities in INL's multiphysics object oriented simulation environment (MOOSE) or other software. Analysis of traditional and advanced nuclear reactors using MOOSE, RELAP-5, or other software. Multiphysics simulation of advanced nuclear systems. Development of novel ideas that advance the state of the art in CFD/TH models of advanced nuclear reactors. Publication of research that advances the state of the art of nuclear CFD/TH. "", 'Employee Status', 'ORGANIZATION: ', 'Knowledge of the MOOSE tools.']",Associate,Full-time,Engineering,Construction,2020-11-05 11:32:32
Specimen Laboratory Processor (Temporary) - Santa Fe Springs,Sonic Healthcare USA,"Santa Fe Springs, CA",13 hours ago,Be among the first 25 applicants,"['', 'Knowledge of basic laboratory and phlebotomy terminology along with clinical laboratory safety procedures.', 'Complete all required written documentation legibly and within assigned timeframe.', 'Ability to budget time and complete tasks/work assignments by predetermined deadline.', 'Ability to see, hear, and respond adequately.', 'Knowledge of basic laboratory and phlebotomy terminology along with clinical laboratory safety procedures.Possesses the ability to read, write, and speak English language. Must have legible handwriting.Must be proficient at data entry and be detail-oriented. Skilled with oral and written comprehension. Understanding of administrative and clerical procedures and systems such as word processing software and electronic files and records.Demonstrates ability to prioritize tasks and engage in multi-tasking.Ability to budget time and complete tasks/work assignments by predetermined deadline.Must be able to demonstrate a high degree of autonomy and possess exceptional time management skills.Ability to use logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions, or approaches to problems.Ability to work with computer systems, telephones, copiers, and fax machines.', 'Associate degree or Bachelors’ degree from an accredited college or university preferred. Valid State of California Phlebotomy Certification. Continuing education as dictated by governmental agencies required to certification validity.Experience as Medical Laboratory Assistant.Basic Life Support (BLS) / Cardiopulmonary Resuscitation (CPR) training. Bilingual/Multilingual is a plus.Two years of technical laboratory experience preferred.', 'High school diploma or equivalent. ', 'High school diploma or equivalent. Medical background or knowledge of medical terminology.Ability to type 40 Words Per Minute (WPM).Experience in a high volume, fast-paced work environment.', 'Company', 'Centrifuge samples and store them at the correct temperature as dictated by accepted specimen requirement and handling procedures.', 'Meet or exceed all performance expectations including maintaining strong attendance, adhering to work schedule, and demonstrating core WestPac values and behaviors as reflected by work performance and interaction with team.', 'In addition to an employee’s typical work schedule, this position requires employees to work weekends, split shifts, overtime, and holidays if needed by the Company. Other duties may apply as necessary.', 'Must be proficient at data entry and be detail-oriented. ', 'Ability to use logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions, or approaches to problems.', 'Moderate to frequent computer work.', 'Manually process and/or load patient samples onto pre-analytical automated equipment for specimen processing.', 'Meet standards for production and accuracy within six (6) months', 'Two years of technical laboratory experience preferred.', 'Required Education And Experience', 'Essential Job Functions', 'Demonstrate an understanding of the compliance policies related to test ordering, which requires developing ability to research test ordering information on translation tables, computer system, and the directory of services.', 'Scheduled Weekly Hours', 'Pushing/pulling.', 'Travel', 'URGENT NEED!!!', 'Understanding of administrative and clerical procedures and systems such as word processing software and electronic files and records.', 'Basic Life Support (BLS) / Cardiopulmonary Resuscitation (CPR) training.', 'General Description', 'Complete appropriate routing, handling, and processing of various medical specimens by: properly verifying samples to laboratory requisitions, verifying the correct sample(s) were received for the test(s) ordered, and documenting date and time specimen is received and/or any specimen discrepancies upon receipt of sample.Manually process and/or load patient samples onto pre-analytical automated equipment for specimen processing.Centrifuge samples and store them at the correct temperature as dictated by accepted specimen requirement and handling procedures.Demonstrate an understanding of the compliance policies related to test ordering, which requires developing ability to research test ordering information on translation tables, computer system, and the directory of services.Meet standards for production and accuracy within six (6) monthsPerform data entry and send out processing.Complete all required written documentation legibly and within assigned timeframe.Meet or exceed all performance expectations including maintaining strong attendance, adhering to work schedule, and demonstrating core WestPac values and behaviors as reflected by work performance and interaction with team.Participate in and support all Quality Assurance and Quality Improvement endeavors for the laboratory, as applicable.Demonstrate strong interpersonal skills to foster a positive environment.In addition to an employee’s typical work schedule, this position requires employees to work weekends, split shifts, overtime, and holidays if needed by the Company. Other duties may apply as necessary.', 'Valid State of California Phlebotomy Certification. Continuing education as dictated by governmental agencies required to certification validity.', 'Job Functions, Duties, Responsibilities And Position Qualifications', 'Physical Demands', 'Occasional travel required in order to interact with Division personnel, attend meetings, or participate in educational training.', 'Walking.', 'Stooping/bending.', 'Medical background or knowledge of medical terminology.', 'Talking.', 'Demonstrates ability to prioritize tasks and engage in multi-tasking.', 'Moderate to frequent use of telephone and fax.', 'Must be able to demonstrate a high degree of autonomy and possess exceptional time management skills.', 'Ability to work with computer systems, telephones, copiers, and fax machines.', 'Perform data entry and send out processing.', ' BE PART OF THE SOLUTION DURING THIS PANDEMIC; WESTPAC LABS IS PROVIDING COVID-19 TESTING AND ANTIBODY TESTING.. .  ', 'Kneeling/crouching.', ' URGENT NEED!!! ', 'Reaching.', 'Experience as Medical Laboratory Assistant.', 'Preferred Education And Experience', 'If required to drive or operate a company vehicle for the performance of their duties, must meet applicable company insurance guidelines and will be required to release Department of Motor Vehicle driving records. Must also comply with company driving policies and procedures.Occasional travel required in order to interact with Division personnel, attend meetings, or participate in educational training.', ' Bilingual/Multilingual is a plus.', 'If required to drive or operate a company vehicle for the performance of their duties, must meet applicable company insurance guidelines and will be required to release Department of Motor Vehicle driving records. Must also comply with company driving policies and procedures.', 'Possesses the ability to read, write, and speak English language. Must have legible handwriting.', 'Participate in and support all Quality Assurance and Quality Improvement endeavors for the laboratory, as applicable.', 'The normal performance of duties may require lifting and carrying of objects up to 25 pounds.Reaching.Stooping/bending.Kneeling/crouching.Pushing/pulling.Walking.Talking.Moderate to frequent computer work.Moderate to frequent use of telephone and fax.Ability to see, hear, and respond adequately.', 'Knowledge, Skills, And Abilities', 'Complete appropriate routing, handling, and processing of various medical specimens by: properly verifying samples to laboratory requisitions, verifying the correct sample(s) were received for the test(s) ordered, and documenting date and time specimen is received and/or any specimen discrepancies upon receipt of sample.', 'Skilled with oral and written comprehension. ', 'Work Shift:', 'Ability to type 40 Words Per Minute (WPM).', 'Experience in a high volume, fast-paced work environment.', 'The normal performance of duties may require lifting and carrying of objects up to 25 pounds.', 'BE PART OF THE SOLUTION DURING THIS PANDEMIC; WESTPAC LABS IS PROVIDING COVID-19 TESTING AND ANTIBODY TESTING.. . ', 'Demonstrate strong interpersonal skills to foster a positive environment.', 'Associate degree or Bachelors’ degree from an accredited college or university preferred. ']",Entry level,Part-time,Research,Construction,2020-11-05 11:32:32
"Senior Scientist, Biochemistry and Chemistry Process Development",Element Biosciences,"San Diego, CA",21 hours ago,42 applicants,"['', '2-5 years experience for Scientist or 5+ years for Sr Scientist in relevant industry such as life sciences, medical devices, diagnostics, biotechnology, pharmaceutical or related scientific field', 'Responsibilities:', 'Develop well characterized, robust and reliable QC assays and processes to QC and manufacturing teams.Establish relationship between product requirements, product performance, and manufacturing capabilities to determine meaningful QC specifications.Support product commercialization at interface of R&D and QC/ Manufacturing.Design, plan and execute experiments, complete data analysis, present results and make recommendations based on data.Source and qualify external vendors.Identify opportunities for process improvements.Author QC and production documents. Train QC and manufacturing personnel.', 'Effective verbal and written communication skills.', 'The process development scientist will have strong biochemistry and molecular biology skills as well as experience in reagent life sciences field. Experience in NGS technology is desirable. The job requires hands-on laboratory work for assay and product development. Operational skills require the ability to structure manufacturing processes such as BOMs. This person may have experience in utilizing various project management tools, design tools, and statistical analysis tools to ensure the delivery of robust, reliable, and accurate processes to routine manufacturing.\xa0', 'Author QC and production documents. Train QC and manufacturing personnel.', 'Establish relationship between product requirements, product performance, and manufacturing capabilities to determine meaningful QC specifications.', 'Requirements:', 'Masters or Ph.D. in Biochemistry, Chemical Biology, Molecular Biology, or related scientific discipline preferred2-5 years experience for Scientist or 5+ years for Sr Scientist in relevant industry such as life sciences, medical devices, diagnostics, biotechnology, pharmaceutical or related scientific fieldExperience in a relevant life science product development & operations environment.Expertise in biochemistry, chemical biology, and/or molecular biology .Hands on in the laboratory.Effective verbal and written communication skills.Skilled in experimental design and statistical data analysis / visualization (e.g. JMP).Strong collaborative and team work attributes.Ability to take initiative, multi-task, and independently drive projects to completion with detailed and efficient execution and reporting.Knowledge of business process systems is a plus.', 'Source and qualify external vendors.', 'Skilled in experimental design and statistical data analysis / visualization (e.g. JMP).', ""Element Biosciences is a multi-disciplinary startup focused on innovating genetic analysis tools for the research and clinical markets. The Company's technology will broaden the end user experience through improved data quality and simplified workflows to benefit discoveries and diagnosis in healthcare."", 'Strong collaborative and team work attributes.', 'Design, plan and execute experiments, complete data analysis, present results and make recommendations based on data.', 'We foster an environment such that all people are afforded the freedom to pursue their passions without\xa0regard to race, color, religion, national or ethnic origin, gender (including pregnancy), sexual orientation, gender identity or expression, age, disability, veteran status or any other characteristics protected by law.', 'Support product commercialization at interface of R&D and QC/ Manufacturing.', 'We are passionate about our mission to develop high performing products to study genomics in an unprecedented flexibility and to understand biology for the improvement of healthcare. We have built a highly efficient product-driven organization where employees can learn, grow and thrive in a challenging but encouraging environment.\xa0We are committed to scientific integrity, collegiality, honesty, objectivity, and openness.\xa0\xa0We offer excellent benefits, which include a 401K plan, competitive health benefits, flexible vacation, and equity incentives.\xa0', 'Masters or Ph.D. in Biochemistry, Chemical Biology, Molecular Biology, or related scientific discipline preferred', 'Ability to take initiative, multi-task, and independently drive projects to completion with detailed and efficient execution and reporting.', 'Identify opportunities for process improvements.', 'Develop well characterized, robust and reliable QC assays and processes to QC and manufacturing teams.', 'Experience in a relevant life science product development & operations environment.', 'Element Biosciences is seeking a highly motivated Sr/ Scientist in Biochemistry & Chemistry Process Development to develop assays and processes. The position is integrated with our technology and product development teams, with a focus on pulling the technology out of the lab and enabling it in Operations. In this position, the candidate will lead assay development and product transfer activities for enzyme biology, formulations chemistry, and sample prep products. Candidate will also be responsible for vendor qualifications, specification development, stability studies, QC and production documentation (e.g. SOP, WI), and QC training/ transfer. The job is highly cross-functional across multiple departments and technical disciplines. The candidate must exhibit demonstrated success working in a fast-paced environment with varied responsibilities and rapidly changing priorities. Candidate must have excellent communication skills and proven track record of interfacing between R&D and Operations teams.', 'Knowledge of business process systems is a plus.', 'Hands on in the laboratory.', 'Expertise in biochemistry, chemical biology, and/or molecular biology .']",Mid-Senior level,Full-time,Science,Biotechnology,2020-11-05 11:32:32
Field Engineer,Domino Data Lab,"Palm Coast, FL",6 hours ago,Be among the first 25 applicants,"['', 'Help evolve the way domino deploys and maintains our software by being in constant communication with core-development', 'Knowledge of data science workflows', 'Responsibilities', 'Programming experience (Python or R preferred)', 'Build integrations to support custom/advanced Data science workflows and how they integrate with the Domino API', ' Responsible for working with Domino’s most strategic customers to ensure their success Build integrations to support custom/advanced Data science workflows and how they integrate with the Domino API Play an advisory role to our customers to help leverage domino and data science best practice. Actively commit to our knowledge base to evolve the way customer success operates at Domino. Help evolve the way domino deploys and maintains our software by being in constant communication with core-development ', 'Deep experience with system architecture, both cloud (AWS, Azure, or GCP) and on-prem environments.', 'Previous working and troubleshooting experience with distributed computing frameworks such as: Spark, Hadoop, Dask, etc.', 'Play an advisory role to our customers to help leverage domino and data science best practice.', 'Excellent troubleshooting skills', 'Qualifications', 'Understanding of Data integrations and data pipelining tools', 'Actively commit to our knowledge base to evolve the way customer success operates at Domino.', ' Excellent troubleshooting skills Strong interpersonal and communication skills Willingness to travel up to 40% of the time Deep experience with system architecture, both cloud (AWS, Azure, or GCP) and on-prem environments. Programming experience (Python or R preferred) Knowledge of data science workflows Hands-on DevOps experience in Docker and Kubernetes preferred Understanding of Data integrations and data pipelining tools Previous working and troubleshooting experience with distributed computing frameworks such as: Spark, Hadoop, Dask, etc.', 'Willingness to travel up to 40% of the time', 'Hands-on DevOps experience in Docker and Kubernetes preferred', 'Strong interpersonal and communication skills', 'Responsible for working with Domino’s most strategic customers to ensure their success']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Senior User Experience Researcher, Science",Chan Zuckerberg Initiative,"Redwood City, CA",6 hours ago,67 applicants,"['', 'Experience in selecting and executing qualitative methods: interviews, contextual inquiry, focus groups, diary studies, concept/usability evaluation', ' We aim to be daring, but humble: We look for bold ideas — regardless of structure and stage — and help them scale by pairing engineers with subject matter experts to build tools that accelerate the pace of social progress. We want to learn fast, but build for the long-term: We want to iterate fast and help bring new solutions to the table, but we also realize that important breakthroughs often take decades, or even centuries. Stay close to the real problems: We engage directly in the communities we serve because no one understands our society’s challenges like those who live them every day.  ', 'We want to learn fast, but build for the long-term: We want to iterate fast and help bring new solutions to the table, but we also realize that important breakthroughs often take decades, or even centuries.', 'Familiarity and experience conducting end-to-end research through the full product lifecycle - generative to evaluative. ', 'Passion for impacting the future of science. Prior experience working in a biomedical or life sciences field or working closely with scientists and researchers in biomedicine and life sciences is a plus, but not required.', 'Participate in critiques by sharing and receiving constructive feedback', 'A commitment to actively seeking feedback and improving from it ', 'Strong analytical thinking, problem-solving, and ability to prioritize', 'Involve team members in research to identify high impact problems faced by scientists and researchers', 'A strong background and experience in human-computer interaction, psychology, sociology, or related field', 'Stay close to the real problems: We engage directly in the communities we serve because no one understands our society’s challenges like those who live them every day. ', 'Demonstrated ability to communicate research insights to cross-functional product teams in a way that promotes impact on product design, development, and strategy', 'We aim to be daring, but humble: We look for bold ideas — regardless of structure and stage — and help them scale by pairing engineers with subject matter experts to build tools that accelerate the pace of social progress.', 'Work closely with scientists and researchers in biomedical and/or life sciences', 'Demonstrated ability to identify new product opportunities by connecting people problems, analytics, and organizational goals', 'Experience in selecting and executing quantitative methods: surveys, statistical analysis, experimentation', 'Ideally, 4+ years experience in applied product research', ' Work closely with scientists and researchers in biomedical and/or life sciences Collaborate with cross-functional partners to translate their curiosities into actionable research questions Design mixed-methods studies to help your teams learn about scientist/researcher behaviors and attitudes  Familiarity and experience conducting end-to-end research through the full product lifecycle - generative to evaluative.  Involve team members in research to identify high impact problems faced by scientists and researchers Collaborate with product teams to generate concepts that address problems faced by biomedical and life scientists Iteratively evaluate low and high fidelity software concepts with appropriate user groups Analyze data and convey insights in clear, illustrative ways that help the product team learn about scientific and research processes, inspire product strategy, and encourage design iteration Combine quantitative and qualitative data to determine the success of features during pilots and post-launch Participate in critiques by sharing and receiving constructive feedback Build a library of insights over time for the organization to continually reference ', 'Iteratively evaluate low and high fidelity software concepts with appropriate user groups', 'Analyze data and convey insights in clear, illustrative ways that help the product team learn about scientific and research processes, inspire product strategy, and encourage design iteration', ' A strong background and experience in human-computer interaction, psychology, sociology, or related field Ideally, 4+ years experience in applied product research Experience in selecting and executing qualitative methods: interviews, contextual inquiry, focus groups, diary studies, concept/usability evaluation Experience in selecting and executing quantitative methods: surveys, statistical analysis, experimentation Demonstrated ability to communicate research insights to cross-functional product teams in a way that promotes impact on product design, development, and strategy Demonstrated ability to identify new product opportunities by connecting people problems, analytics, and organizational goals A commitment to actively seeking feedback and improving from it  Passion for impacting the future of science. Prior experience working in a biomedical or life sciences field or working closely with scientists and researchers in biomedicine and life sciences is a plus, but not required. Willingness to occasionally travel to meet with scientists and researchers to conduct in-context research A curious streak and enjoy learning about new topics and domains (note: we do not expect individuals to be science experts or to become science experts in this role) Strong analytical thinking, problem-solving, and ability to prioritize Ability to thrive in fast-paced, growing organizations Passion for impacting the future of science', 'A curious streak and enjoy learning about new topics and domains (note: we do not expect individuals to be science experts or to become science experts in this role)', 'Combine quantitative and qualitative data to determine the success of features during pilots and post-launch', 'Collaborate with product teams to generate concepts that address problems faced by biomedical and life scientists', 'Willingness to occasionally travel to meet with scientists and researchers to conduct in-context research', 'Ability to thrive in fast-paced, growing organizations', 'Build a library of insights over time for the organization to continually reference', 'Design mixed-methods studies to help your teams learn about scientist/researcher behaviors and attitudes ', 'Passion for impacting the future of science', 'Collaborate with cross-functional partners to translate their curiosities into actionable research questions']",Associate,Full-time,Information Technology,Nonprofit Organization Management,2020-11-05 11:32:32
"Talent Researcher, Executive Recruiting",HubSpot,"Remote, OR",6 hours ago,122 applicants,"['', ' Have experience in a research-driven role in industries and functions such as (but not limited to) executive search, corporate recruiting, market research, venture capital, legal research, etc. Seek out opportunities to find and engage talent from a range of backgrounds and experience that would bring new and distinct perspectives to HubSpot and our broader network Are experts at independently owning and driving search strategies including having the ability to thoughtfully set out a target company universe and rank effectively based on key market insights Are able to get up to speed quickly on new markets and run a thorough leadership candidate research process including mapping out organizational charts Show knowledge of research methods (tools, frameworks, etc.) Have a deep understanding and appreciation for the company culture Are experienced at working in a team-based environment Have a keen and quick understanding of a range of business situations/contexts ', 'Regularly track pipeline activity to share with internal stakeholders and hiring managers', 'About HubSpot', 'Have experience in a research-driven role in industries and functions such as (but not limited to) executive search, corporate recruiting, market research, venture capital, legal research, etc.', 'Plan different ways to build leadership pipelines and execute tactical research, referral generation, events and sourcing campaigns', 'Develop search strategies through market research for open roles by identifying, calibrating, and prioritizing potential candidates', 'Are experts at independently owning and driving search strategies including having the ability to thoughtfully set out a target company universe and rank effectively based on key market insights', 'Are able to get up to speed quickly on new markets and run a thorough leadership candidate research process including mapping out organizational charts', 'Recommend and drive process improvements that positively impact our ability to identify, attract and nurture top talent globally', 'Build and offer deep market insights on key initiatives', 'Work closely with the Executive Recruitment team and hiring managers to deeply understand the requirements of open roles, the functions and the ways in which each role fits into the broader organization', 'Have a keen and quick understanding of a range of business situations/contexts', 'We Are Looking For People Who', 'Have a deep understanding and appreciation for the company culture', 'Pioneer and lead the usage of new tools for talent mapping, candidate nurturing, and building market intelligence', 'Seek out opportunities to find and engage talent from a range of backgrounds and experience that would bring new and distinct perspectives to HubSpot and our broader network', ' Work closely with the Executive Recruitment team and hiring managers to deeply understand the requirements of open roles, the functions and the ways in which each role fits into the broader organization Pioneer and lead the usage of new tools for talent mapping, candidate nurturing, and building market intelligence Plan different ways to build leadership pipelines and execute tactical research, referral generation, events and sourcing campaigns Develop search strategies through market research for open roles by identifying, calibrating, and prioritizing potential candidates Build and offer deep market insights on key initiatives Regularly track pipeline activity to share with internal stakeholders and hiring managers Recommend and drive process improvements that positively impact our ability to identify, attract and nurture top talent globally ', 'In This Role, You’ll Get To', 'Are experienced at working in a team-based environment', 'Show knowledge of research methods (tools, frameworks, etc.)']",Associate,Full-time,Human Resources,Information Technology and Services,2020-11-05 11:32:32
Investor Relation - Reporting Team Manager,Fortress Investment Group,"New York, NY",2 hours ago,Be among the first 25 applicants,"['·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Extremely organized and obsessively detail-oriented', 'The ideal candidate will have an appreciation for data and technology paired with commercial instincts of a front office professional.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Dynamo, Intralinks, Investran, Cvent experience is a plus', 'Responsibilities:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Must have advanced Microsoft Excel skills', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Bachelor’s degree with at least 6-7 years of financial services experience –\xa0consulting, client service, data scientist/technology experience is preferred', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Liaison between the sales professionals and technology team to administer, quality check, and improve the CRM system, data and associated processes', 'The new member of the team will focus exclusively on the group’s CRM system and related responsibilities.', '\xa0', 'Fortress is seeking a new member to join their Credit & Real Estate Funds Capital Formation Group.\xa0The Capital Formation Group is responsible for capital raising, client service, and relationship management for a $32 billion platform.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Excellent oral and written communication skills', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Positive attitude and team player with the ability to forge relationships across the firm', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Co-ordinate regular meetings between Client Service team and IT teams to discuss projects and their progress', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Ability to multi-task and prioritize among many time-sensitive demands', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Work with internal technology teams to streamline various process automation like data management, event management, reporting, and data quality checks\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Leadership skills to focus the entire CFG group on the mission', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Manage weekly pipeline process and data for the group – in integral part to fundraising organization and success', 'Qualifications:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Help build and manage the technology roadmap (with a partnership of the CFG IT team) – That aligns with internal needs of the team and builds risk reduction and efficiency.\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Thrives in an extremely fast-paced environment', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Initially manage at least one team member', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Produce ad-hoc reports for senior management using CRM data', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Exhibit a thoughtful ability to manage data quality using appropriate quality control methods\xa0and building/utilizing proper QC checks from the technology team', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Understand and dissect data based on the needs of the Sales/IR teams', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Contribute data to production of various regulatory filings such as Form ADV and Form PF']",Associate,Full-time,Finance,Financial Services,2020-11-05 11:32:32
Senior Security Researcher,Lookout,United States,21 hours ago,Be among the first 25 applicants,"['', 'Able to code in Python or Ruby or Java.', 'Lookout is a cybersecurity company that makes it possible for individuals and enterprises to be both mobile and secure. With 100 million mobile sensors fueling a dataset of virtually all the mobile code in the world, the Lookout Security Cloud can identify connections that would otherwise go unseen -- predicting and stopping mobile attacks before they do harm. The world’s leading mobile network operators, including AT&T, Deutsche Telekom, EE, KDDI, Orange, Sprint, T-Mobile and Telstra, have selected Lookout as its preferred mobile security solution. Lookout is also partnered with such enterprise leaders as AirWatch, Ingram Micro and MobileIron. Headquartered in San Francisco, Lookout has offices in Amsterdam, Boston, London, Sydney, Tokyo, Toronto and Washington, D.C. To learn more, visit www.lookout.com', 'Able to read assembly code as well as C and related languages.', 'Reverse engineer system code, exploits, and applications to determine how they work. Apply the results to improve the way Lookout detects threats and gathers telemetry.', 'A desire to help build a diverse team of researchers with different backgrounds.', 'Contribute to the long-term design of our telemetry analysis, data stores, mobile client, and tooling.', 'Experience in reverse engineering of software at the system level.', 'We are open to candidates across North America to work remotely. ', 'Hunt down and classify new threats and vulnerabilities before they affect our users.', 'Reverse engineer system code, exploits, and applications to determine how they work. Apply the results to improve the way Lookout detects threats and gathers telemetry.Hunt down and classify new threats and vulnerabilities before they affect our users.Identify current and future attacks on user privacy and device security, using telemetry data from our Mobile Threat Network.Contribute to the long-term design of our telemetry analysis, data stores, mobile client, and tooling.', 'Experience in reverse engineering of software at the system level.Able to read assembly code as well as C and related languages.Able to code in Python or Ruby or Java.Experience using some of the following tools: IDA Pro, Hopper, gdb, Frida.A desire to help build a diverse team of researchers with different backgrounds.Build and maintain positive relationships with security and developer communities.', 'We are looking for Senior Researchers to join our Device Security Intelligence team, a group of world-class mobile researchers who work on device compromises and other mobile platform-based threats. As a member of this team you will hunt and neutralize threats to mobile devices, research system vulnerabilities, work with exploit code, and contribute to an extensive arsenal of detection tools and technologies.', 'Experience using some of the following tools: IDA Pro, Hopper, gdb, Frida.', 'Responsibilities', 'Build and maintain positive relationships with security and developer communities.', 'Identify current and future attacks on user privacy and device security, using telemetry data from our Mobile Threat Network.', 'Required Qualifications & Skills']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Career Search Partners,New York City Metropolitan Area,14 hours ago,81 applicants,"['', 'We’re looking for someone who:', 'You will work on:', '-Reflexively tests and measures your results', '-Is driven to unlock the potential of data to positively impact the real world', '-Constantly questions how things are done and use evidence to convince people to try different approaches', '-Knows Spark inside and out.\xa0Optimizing Spark code and cluster configuration is second nature.\xa0You can quickly reason about and diagnose unexpected issues.', '-Prides yourself on writing highly readable, thoroughly tested code (we use PySpark)', '-Thrives on small, focused and highly collaborative teams', 'Entity resolution is a hard problem and they’re continuously tuning our algorithms and experimenting with new methods. Data freshness and accuracy are critical.\xa0We maintain reliability and quality while operating at a large scale. The world is always changing--They’re continuously adding new data sources and calculators to provide better intelligence on SMBs', '-You will be building and extending a sophisticated data pipeline with predictive models embedded at multiple stages.\xa0You’ll need to simultaneously balance system reliability, rigorous data quality requirements and an ambitious forward development plan.', '-The Data Infrastructure team has solved many problems.\xa0And yet there are more open questions than closed ones.\xa0We love people who bring new ideas and show us how to make our data more powerful.', 'Rapidly growing global data intelligence firm seeks Senior Data Infrastructure Engineer.\xa0The Data Infrastructure is the factory that converts hundreds of sources of raw data on small and medium businesses (SMBs) into actionable intelligence for decision makers to provide credit, insurance and other services to SMBs.\xa0In today’s environment, where millions of SMBs in the United States are struggling, their mission has never been more important. The team synthesizes billions of records from hundreds of different data sources, identifies common businesses in these billions of records (entity resolution) and runs dozens of calculators to extract signal on each business’ growth, health and continuity risk.']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Engineer (Data Warehouse),Rodan + Fields,"San Ramon, CA",6 hours ago,28 applicants,"['', 'Good understanding of various data file formats', 'Strong organizational skills with the ability to multi-task, prioritize and execute on assigned deliverables', 'Strong understanding of modern big data technologies', 'Strong analytical and problem-solving skills with excellent verbal and oral communication is mandatory', 'A well-grounded data engineer, technically skilled in modern big data principles and technologies.', 'Define and develop data pipeline solutions– architect end to end design, mapping, and hands-on development - for GCP, following integration, security and development best practices.Work with Enterprise Architecture, Data Management, DevOps, QA, Release Management, Change Management teams through the lifecycle of the project and agile sprints for promoting continuous data pipeline releases.Manage integration of data from various data sources, both internal and externalSME on GCP, BQ, Dataflow, Pub Sub, cloud functions, DataprocFollow Incident and Problem Management processes in providing production support, utilizing organizational ITIL processes.Work with internal business and technical partners to collect and document the functional and non-functional requirements in JIRA stories for business projects and technical enhancements.Collaborate with internal developers and internal stakeholders from e-Commerce, ERP, Salesforce, business team and product development teams in evolving the Enterprise BI Center for Excellence. ', 'Responsibilities', 'Familiarity with pub/sub event streaming platforms (e.g. Kafka) is beneficial', 'Description', '7+ years of experience implementing data warehousing solutions including public cloud big data platforms.A well-grounded data engineer, technically skilled in modern big data principles and technologies.Experience with GCP Big Data platform is strongly preferred (BigTable, BigQuery, Data Fusion)Prefer experience in data pipeline development in SQL, Python, Spark, DataProc, and event-streamingWorking knowledge and experience in Google Cloud Data Fusion, Cask, AirflowExcellent Python coding and SQL skillsFamiliarity with pub/sub event streaming platforms (e.g. Kafka) is beneficialPrior experience developing ETL/ELT solutions for enterprise analyticsStrong understanding of modern big data technologiesGood understanding of various data file formatsFamiliar with Confluence, JIRA. Should be comfortable working in Field Mappings between Source, Target Systems, creating Design Documents and following Agile Sprints methodology.Support new launch hyper-care and be well-versed with Integration Cutover & Go-Live activities.Strong analytical and problem-solving skills with excellent verbal and oral communication is mandatoryStrong organizational skills with the ability to multi-task, prioritize and execute on assigned deliverablesAble to work with ambiguity and the ability to troubleshoot and problem solve with minimal supervision and guidance.Able to handle fast-paced environment supporting Operations and Engineering activities simultaneously.Ability to communicate effectively to all layers with business, technology, peers, and management.', 'Able to work with ambiguity and the ability to troubleshoot and problem solve with minimal supervision and guidance.', 'Work with Enterprise Architecture, Data Management, DevOps, QA, Release Management, Change Management teams through the lifecycle of the project and agile sprints for promoting continuous data pipeline releases.', 'Familiar with Confluence, JIRA. Should be comfortable working in Field Mappings between Source, Target Systems, creating Design Documents and following Agile Sprints methodology.', 'The Company', 'Ability to communicate effectively to all layers with business, technology, peers, and management.', 'Define and develop data pipeline solutions– architect end to end design, mapping, and hands-on development - for GCP, following integration, security and development best practices.', 'Experience with GCP Big Data platform is strongly preferred (BigTable, BigQuery, Data Fusion)', 'Collaborate with internal developers and internal stakeholders from e-Commerce, ERP, Salesforce, business team and product development teams in evolving the Enterprise BI Center for Excellence. ', 'Excellent Python coding and SQL skills', 'Qualifications', 'Prior experience developing ETL/ELT solutions for enterprise analytics', 'SME on GCP, BQ, Dataflow, Pub Sub, cloud functions, Dataproc', '7+ years of experience implementing data warehousing solutions including public cloud big data platforms.', 'The Opportunity', 'Working knowledge and experience in Google Cloud Data Fusion, Cask, Airflow', 'Follow Incident and Problem Management processes in providing production support, utilizing organizational ITIL processes.', 'Work with internal business and technical partners to collect and document the functional and non-functional requirements in JIRA stories for business projects and technical enhancements.', 'Able to handle fast-paced environment supporting Operations and Engineering activities simultaneously.', 'Support new launch hyper-care and be well-versed with Integration Cutover & Go-Live activities.', 'Regarding COVID-19', 'Manage integration of data from various data sources, both internal and external', 'Prefer experience in data pipeline development in SQL, Python, Spark, DataProc, and event-streaming']",Associate,Full-time,Business Development,Information Technology and Services,2020-11-05 11:32:32
Customer Success Director,Altitude Networks - Cloud Native DLP,"San Francisco, CA",7 hours ago,Be among the first 25 applicants,"['', 'Work with customer and product to validate, recreate, and report bugs or feature requests', 'Ability to translate customer feedback into product feature requests or bug reports ', ' Establish a customer success program that begins prior to sales and engages with the customer throughout their entire lifecycle with Altitude Networks. Develop key customer success strategy and build the function from the ground up, delivering high touch, consultative experience to customers Collect comprehensive feedback from key customer stakeholders to drive company roadmap with the product team Plan and drive requirements for internal tooling to build a world class customer success organization Maintain a deep understanding of the product and current product health through ownership of the product portion of the demo environment Understand and surface trends for customer via product or backend data review that can be tested for customer interest and lead to future features Work with customer and product to validate, recreate, and report bugs or feature requests ', ' 4+ years within the cybersecurity industry  3+ years experience managing customer service teams ', 'Ability to perform basic sql queries for high level data review ', 'Great organization skills ', 'Plan and drive requirements for internal tooling to build a world class customer success organization', 'Establish a customer success program that begins prior to sales and engages with the customer throughout their entire lifecycle with Altitude Networks.', 'Responsibilities', 'Develop key customer success strategy and build the function from the ground up, delivering high touch, consultative experience to customers', 'Understand and surface trends for customer via product or backend data review that can be tested for customer interest and lead to future features', '3+ years experience managing customer service teams', 'Strong knowledge of cybersecurity risks & threats facing SMB, mid market and enterprise customers', 'Location', 'Previous experience in security startups a plus', '8+ years of customer service experience', 'Requirements', '4+ years within the cybersecurity industry ', 'Previous experience in SaaS cybersecurity products a plus', 'Collect comprehensive feedback from key customer stakeholders to drive company roadmap with the product team', 'Job Description', 'Maintain a deep understanding of the product and current product health through ownership of the product portion of the demo environment', 'Experience driving requirements and best practices for internal tooling for customer management, health monitoring, performance tracking', ' 8+ years of customer service experience', 'Expert at building relationships and establishing effective communication channels with customers', 'Strong communication skills with ability to effectively navigate business/security objectives with C-Suite and engineers/IT ', 'About Altitude Networks']",Director,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Two positions: a Postdoctoral Researcher and an Imagery Scientist,Saint Louis University,Greater St. Louis,17 hours ago,64 applicants,"['', 'Ideal candidates will have a Ph.D. in geospatial science with remote sensing and computer vision focus, or a computer engineering or science degree with remote sensing expertise.', 'Computer vision: remote sensing and photogrammetry', 'Imagery analysis, and data science', 'Artificial intelligence and machine learning', 'Geospatial Institute at Saint Louis University (http://www.slu.edu/geoslu) is seeking applicants to fill a Postdoc and an Imagery Scientist positions in Geospatial Science Starting 1 Nov 2020.', 'Areas of interest:', 'Plant phenotyping: yield and seed quality estimation', 'Apply for the postdoc position here: https://slu.wd5.myworkdayjobs.com/Careers/job/Des-Peres-Hall/Geospatial-Institute-Postdoctoral-Fellow-3_2020-00745-1', ""To apply for the Imagery Scientist position, please contact me directly. The salary for the Imagery Scientist is commensurate with the applicant's experience."", 'Computer vision: remote sensing and photogrammetryArtificial intelligence and machine learningPlant phenotyping: yield and seed quality estimationImagery analysis, and data science']",Not Applicable,Full-time,Research,Higher Education,2020-11-05 11:32:32
Senior Big Data Engineer- Data Warehouse,Integral Ad Science,"Chicago, IL",7 hours ago,45 applicants,"['', 'Excellent interpersonal and communication skills', 'Experience working with AWS technologies such EMR, step functions, data pipeline, cloudformation, etc.', 'Data warehouse experience in SnowFlake and experience writing ETL pipelines in SnowFlake ', 'IAS is an equal opportunity employer, committed to our diversity and inclusiveness. We will consider all qualified applicants without regard to race, color, nationality, gender, gender identity or expression, sexual orientation, religion, disability or age. We strongly encourage women, people of color, members of the LGBTQIA community, people with disabilities and veterans to apply.', 'Experience developing and maintaining ETL applications and data pipelines using big data technologies', 'Work on Big Data technologies, lead the design, coding and maintenance of highly scalable backend data processing platform for large throughput', 'What Puts You Over The Top', 'https://muse.cm/2t8eGlN', 'Understanding of full software development life cycle, agile development and continuous integration', ""Attention agency/3rd party recruiters: IAS does not accept any unsolicited resumes or candidate profiles. If you are interested in becoming an IAS recruiting partner, please send an email introducing your company to recruitingagencies@integralads.com. We will get back to you if there's interest in a partnership."", 'Lead the entire software lifecycle including hands-on development, code reviews, testing, continuous integration, continuous deployment and documentation using modern programming languages (such as Java, Scala, Python)', 'Perform tuning of systems for optimal performance', 'Good understanding of collections, multi-threading, JVM memory model, algorithms, scalability and various tradeoffs in a Big Data setting.', 'Strong SQL knowledge (OLAP) and experience working with mpp columnar databases (Vertica, SnowFlake,etc)', 'We collect personal information (PI) from you in connection with your application for employment or engagement with IAS, including the following categories of PI: identifiers, personal records, commercial information, professional or employment or engagement information, non-public education records, and inferences drawn from your PI. We collect your PI for our purposes, including performing services and operations related to your potential employment or engagement. For additional details or if you have questions, contact us at compliance@integralads.com.', 'You Should Apply If You Have Most Of This', ' Data warehouse experience in SnowFlake and experience writing ETL pipelines in SnowFlake  Experience working with AWS technologies such EMR, step functions, data pipeline, cloudformation, etc. Experience working with hadoop mapreduce, spark, pig, hive, etc. ', 'Mentor junior team members', ' Work on Big Data technologies, lead the design, coding and maintenance of highly scalable backend data processing platform for large throughput Work on the data modelling for the MPP columnar databases to handle high volume of queries with sub-second response times Lead the entire software lifecycle including hands-on development, code reviews, testing, continuous integration, continuous deployment and documentation using modern programming languages (such as Java, Scala, Python) Perform tuning of systems for optimal performance Mentor junior team members ', ' and ', 'To learn more about us, please visit ', 'Experience working with hadoop mapreduce, spark, pig, hive, etc.', ""What You'll Do"", 'About Integral Ad Science', 'Work on the data modelling for the MPP columnar databases to handle high volume of queries with sub-second response times', 'Equal Opportunity Employer', ' 5+ years of recent hands-on experience in one or more of the modern programming languages (Java, Scala, Python) Good understanding of collections, multi-threading, JVM memory model, algorithms, scalability and various tradeoffs in a Big Data setting. Experience developing and maintaining ETL applications and data pipelines using big data technologies Strong SQL knowledge (OLAP) and experience working with mpp columnar databases (Vertica, SnowFlake,etc) Excellent interpersonal and communication skills Understanding of full software development life cycle, agile development and continuous integration ', 'California Applicant Pre-Collection Notice', 'About Our Team', '5+ years of recent hands-on experience in one or more of the modern programming languages (Java, Scala, Python)', 'http://integralads.com/']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
"Technician IV, Animal Research & Diag",Boehringer Ingelheim,"Worthington, MN",10 hours ago,Be among the first 25 applicants,"['', ' Must be legally authorized to work in the United States without restriction.  Must be willing to take a drug test and post-offer physical (if required).  Must be 18 years of age or older. ', ' May assist in writing reports, scientific abstracts, preparing slides/marketing material. ', ' Knowledge of good manufacturing, laboratory and clinical practices and working knowledge of 9CFR (103.3) USDA guidelines for vaccine production and testing ', ' Demonstrated basic understanding of either: ', ' Basic understanding of microbiology (theory and application) and able to work in laboratory handling animal and zoonotic pathogens. ', ' Must be able to work in extreme environments (hot, cold, noisy, humid, etc.) ', ' Must be willing to take a drug test and post-offer physical (if required). ', 'Description', ' Attention to detail and commitment to customer service. ', ' Ability to evaluate and interpret data and formulate logical and sound conclusions. ', ' Must be able to maintain even temperament when working with livestock. ', ' Requires ability to handle multiple projects, effective time management, and discipline. ', ' Biologics, including the principles of veterinary biologics, research anddevelopment of biologics, diagnostic assays, vaccine production, quality control and regulatory agencies - AND/OR - ', ' Maintains, adjusts, and repairs animal pens, feeders, drinking systems, and livestock handling equipment. Performs cleaning and sanitation of animal rooms and equipment.Performs advanced site biosecurity functions including water system sanitation, bagged feed and fomite decontamination, environmental auditing sample collection, and in-house bacterial growth assessment. Disposal of hazardous waste and expired chemicals.Update Chemical Inventory annually. ', ' Must be able to lift up to 70 pounds occasionally and up to 50 pounds frequently. ', ' Must be able to read and see clearly. Prescription eye wear is permitted. ', ' *Proficiency in basic computing skills such as e-mail communication, word processing, spreadsheets and use of databases. ', ' Provides assistance at the NPL-BI animal research sites, including animal husbandry and care, provision of feed, water, and enrichment materials, maintaining records of animal care, preventive medicine, USDA-required and study protocol-driven documents. Restrains and manipulates animals for routine and emergency procedures. Conducts daily animal health and welfare assessments. Recognizes when animals are sick, distressed or otherwise abnormal and communicates these observations to the Site Veterinarian or Group Leader.Administers treatment to animals, administers and monitors sedation, and conducts euthanasia in accordance with study protocols at the direction of the Site Veterinarian or delegate.  Maintains, adjusts, and repairs animal pens, feeders, drinking systems, and livestock handling equipment. Performs cleaning and sanitation of animal rooms and equipment.Performs advanced site biosecurity functions including water system sanitation, bagged feed and fomite decontamination, environmental auditing sample collection, and in-house bacterial growth assessment. Disposal of hazardous waste and expired chemicals.Update Chemical Inventory annually.  Conducts scientific clinical observations and disease outcome assessments. Administers experimental treatment articles in accordance with study protocols. Records all scientific information on documents provided with study protocols or standard department forms as appropriate. Conduct assigned projects, experiments or departmental activities to meet the project goals and time line. Conducts clinical R&D and Diagnostics sample collection pre-and post-mortem in accordance with study protocols and direction of Investigator or delegate.  Conduct assigned projects, experiments or departmental activities to meet the project goals and time line.  Collect, maintain, and organize data in the form of a laboratory notebook, bench record, animal record, electronic project database, and/or production record. Communicate data/results to Department Head or to Scientist II/III, or Senior Scientist in the form of written or oral reports. Assist in the analysis of data/results and provide suggestions for next steps. Prepare the challenge material for animal studies.  Engage with Diagnostics and/or R&D to set-up and independently run daily PCRs and other assays as directed by Molecular and R&D Team leaders. Incumbent will also assist with vaccine formulation/preparation, vaccine QC, and monitor vaccine stability. Assist with pathogen Inactivation Kinetics.  May be assigned management responsibility for programs such as biosecurity, hazardous shipping, supply systems, or controlled drug inventories at direction of Group Leader. May serve on cross-site or whole-company committees or workgroups.  May assist in writing reports, scientific abstracts, preparing slides/marketing material.  Complies with applicable regulations and company policies.Completes all company mandated training and complies. Adhere to confidentiality polices as directed while handling R&D and company data. Operates in accordance with experimental protocol and Animal Welfare Act/Regulations, NIH Guide for the Care and Use of Laboratory Animals, Guide for the Care and Use of Agricultural Animals in Research and Teaching, BI AH policies and Veterinary Sciences standard operating procedures, USDA, EPA, and then fundamental requirements for AAALAC. ', ' Collect, maintain, and organize data in the form of a laboratory notebook, bench record, animal record, electronic project database, and/or production record. Communicate data/results to Department Head or to Scientist II/III, or Senior Scientist in the form of written or oral reports. Assist in the analysis of data/results and provide suggestions for next steps. Prepare the challenge material for animal studies. ', ' Must be 18 years of age or older. ', ' Good written and verbal communication skills ', ' BS degree from an accredited institution in Veterinary Technology, Microbiology or related biological field, and one to two (1-2) years of experience working in a laboratory.  Must possess or be willing to obtain Assistant Laboratory Animal Technician (ALAT) certification, preferably within 18 months of employment. Certification time lines will be dependent upon prior education and experience.  Experience in livestock handling, husbandry, and healthcare, veterinary clinical assistance, and/or scientific animal research preferred  Demonstrated basic understanding of either: ', ' Biologics, including the principles of veterinary biologics, research anddevelopment of biologics, diagnostic assays, vaccine production, quality control and regulatory agencies - AND/OR -  Basic understanding of microbiology (theory and application) and able to work in laboratory handling animal and zoonotic pathogens. ', ' Effective interpersonal skills with a diverse group of individuals at all organizational levels ', 'Requirements', ' Able to handle multiple projects and meet deadlines. ', ' Engage with Diagnostics and/or R&D to set-up and independently run daily PCRs and other assays as directed by Molecular and R&D Team leaders. Incumbent will also assist with vaccine formulation/preparation, vaccine QC, and monitor vaccine stability. Assist with pathogen Inactivation Kinetics. ', ' Must not have allergies to animals or livestock/feed dust. ', ' Complies with applicable regulations and company policies.Completes all company mandated training and complies. Adhere to confidentiality polices as directed while handling R&D and company data. Operates in accordance with experimental protocol and Animal Welfare Act/Regulations, NIH Guide for the Care and Use of Laboratory Animals, Guide for the Care and Use of Agricultural Animals in Research and Teaching, BI AH policies and Veterinary Sciences standard operating procedures, USDA, EPA, and then fundamental requirements for AAALAC. ', ' Able to manage processes, projects, and conduct experiments and clinical trials as directed. ', 'Who We Are', 'Duties & Responsibilities', ' Conduct assigned projects, experiments or departmental activities to meet the project goals and time line. ', ' Experience in livestock handling, husbandry, and healthcare, veterinary clinical assistance, and/or scientific animal research preferred ', ' Must possess or be willing to obtain Assistant Laboratory Animal Technician (ALAT) certification, preferably within 18 months of employment. Certification time lines will be dependent upon prior education and experience. ', ' Must be legally authorized to work in the United States without restriction. ', ' Conducts scientific clinical observations and disease outcome assessments. Administers experimental treatment articles in accordance with study protocols. Records all scientific information on documents provided with study protocols or standard department forms as appropriate. Conduct assigned projects, experiments or departmental activities to meet the project goals and time line. Conducts clinical R&D and Diagnostics sample collection pre-and post-mortem in accordance with study protocols and direction of Investigator or delegate. ', ' May be assigned management responsibility for programs such as biosecurity, hazardous shipping, supply systems, or controlled drug inventories at direction of Group Leader. May serve on cross-site or whole-company committees or workgroups. ', ' Provides assistance at the NPL-BI animal research sites, including animal husbandry and care, provision of feed, water, and enrichment materials, maintaining records of animal care, preventive medicine, USDA-required and study protocol-driven documents. Restrains and manipulates animals for routine and emergency procedures. Conducts daily animal health and welfare assessments. Recognizes when animals are sick, distressed or otherwise abnormal and communicates these observations to the Site Veterinarian or Group Leader.Administers treatment to animals, administers and monitors sedation, and conducts euthanasia in accordance with study protocols at the direction of the Site Veterinarian or delegate. ', ' BS degree from an accredited institution in Veterinary Technology, Microbiology or related biological field, and one to two (1-2) years of experience working in a laboratory. ', ' Must maintain knowledge of current scientific literature and developments in animal health industry. ', 'Eligibility Requirements']",Not Applicable,Full-time,Research,Hospital & Health Care,2020-11-05 11:32:32
W2 only Data Engineer-United State,"Pyramid Consulting, Inc","Charlotte, NC",22 hours ago,Be among the first 25 applicants,"['o Partner with architecture and infrastructure, security, and administration to design, implement, and operate a data integration, standardization, and consumption platform to ensure consistent use of information across partner organizations. ', 'o Partner with architecture and infrastructure, security, and administration to design, implement, and operate a data integration, standardization, and consumption platform to ensure consistent use of information across partner organizations.', 'o Develop and operationalize full life-cycle of data and analytic solutions into business processes to maximize the value. ', 'o Build the core data management and analytics framework to drive the end-to-end digital platform for the Company. ', 'Databricks( Spark, Delta lake, Python), Azure or any other cloud native knowledge or exp, knowledge or exp of Machine learning ', 'o Collaborate with architecture, product management, and other engineering teams to enable the development of complex data and analytics solutions ', 'o Manage, support and modernize analytic capabilities as a managed service including research environments, ad-hoc reporting and analysis, and shifting of tactical solutions to industrialized frameworks. ']",Mid-Senior level,Contract,Consulting,Banking,2020-11-05 11:32:32
Email Marketing Specialist,"Anderson Young Associates, Inc.","Denver, CO",2 hours ago,Be among the first 25 applicants,"['', 'partner programs and customer engagement that will have a sizable impact on revenue growth.', 'conceptualize and write creative emails, and also consistently test and analyze data driven experiments on our email program. The EMS will create a significant volume of emails on behalf of the company and will play an integral role in supporting internal and external communication,', 'Project Management', '• Tracking success by monitoring performance of campaigns on a daily and weekly basis including', 'how people are', 'Measuring Success', 'and implementing into our marketing automation platform, Pardot.', 'and external brand communication, partner programs, promotions and customer engagement', 'on each project,', '• End-to-end conceptualization and implementation of email campaigns that include but are not', 'The specialist role is broken up into equal parts technical, creative and analytical – ready to', 'Reports To: VP of Marketing', 'limited to internal', 'engaging with the email program and how it’s driving marketing key metrics.', 'Please Remember to attach resume**', '• Work with Salesforce engineer and systems teams to properly sync and track performance across all platforms.', 'campaigns for all', '• Building the email flow logic, writing creative error-free copy, collaborating with key stakeholders', '• Work with Data Scientist to create accurate email lists, manage customer database within Pardot.', 'Our client, a Global Financial Services compa ,seeks an Email Marketing Specialist\xa0', 'Amur Equipment Finance.', 'Key Responsibilities']",Associate,Full-time,Finance,Staffing and Recruiting,2020-11-05 11:32:32
Senior Research Scientist - Global Water Treatment,"CPS, Inc.","Covington, TN",6 hours ago,32 applicants,"['', 'If you’d like to hear more about this opportunity and others we are currently working on, please contact Devin Heffernan at dheffernan@cps4jobs.com.', ' Ph.D. in Chemical Engineering, Material Science, Chemistry, Applied Surfactant Science, Colloid or Physical Chemistry, Analytical Chemistry, or Physics with 2+ years of experience in relevant industry, or M.S. degree with 5+ years of experience in relevant industry, or Bachelor degree with 10+ years of experience in relevant industry Ability to provide hands-on support of field trials at industrial locations Preferred experience in the development of products to manage cooling water, boiler water, produced water and water reuse Ability to conduct organic structure validation using classical methods as well as most modern instrumental techniques (GC; LC; NMR/FTIR/Mass Spectrometry; etc.) ', 'Providing support of field trials, marketing materials development, and customer facing presentations', 'Ability to provide hands-on support of field trials at industrial locations', 'Senior Research Scientist - Global Water Treatment', 'Demonstrated ability to develop testing methods and design equipment to simulate customer process conditions, such as pilot cooling towers, flow loops, on-line chemical treatment systems, etc.', 'Preferred experience in the development of products to manage cooling water, boiler water, produced water and water reuse', 'A track record of creative contributions in one of several fields such as specialty chemicals industry, corrosion and deposit control, functional formulation development, sensors, automation, or industrial water treatment', ' A track record of creative contributions in one of several fields such as specialty chemicals industry, corrosion and deposit control, functional formulation development, sensors, automation, or industrial water treatment Demonstrated ability to develop testing methods and design equipment to simulate customer process conditions, such as pilot cooling towers, flow loops, on-line chemical treatment systems, etc. Competency with the use of a wide range of modern instrumentation Planning and executing product/technology development from lab scale to commercialization Providing support of field trials, marketing materials development, and customer facing presentations ', 'Technical Qualifications', 'Ability to conduct organic structure validation using classical methods as well as most modern instrumental techniques (GC; LC; NMR/FTIR/Mass Spectrometry; etc.)', 'Ph.D. in Chemical Engineering, Material Science, Chemistry, Applied Surfactant Science, Colloid or Physical Chemistry, Analytical Chemistry, or Physics with 2+ years of experience in relevant industry, or M.S. degree with 5+ years of experience in relevant industry, or Bachelor degree with 10+ years of experience in relevant industry', 'Planning and executing product/technology development from lab scale to commercialization', 'Competency with the use of a wide range of modern instrumentation']",Associate,Full-time,Other,Food & Beverages,2020-11-05 11:32:32
"Vice President, Senior Data Engineer - Analytics",JPMorgan Chase & Co.,"Columbus, OH",21 hours ago,Be among the first 25 applicants,"['', ""Exposure to AWS Cloud Technologies (S3, RDS, EC2, Aurora, etc.), Erwin Enterprise Data Modeler/DM Workgroup. Exposure to GCP / BigQuery- performance analysis - reduce number of bytes read by your query and optimizing costs. At least 5 years of hands-on experience in data architecture and meeting non-functional requirements. At least 3 years in financial services, specifically data engineering with compliance for origination, servicing and transactional data to support core banking and operational processes and analytics. Any of the following is a plus - AWS Certified Cloud Practitioner, AWS Certified Solutions Architect - Associate, AWS Certified DevOps Engineer - Professional and/or AWS Certified Solutions Architect - Professional Experience with 'Big Data' architecture: Flume, Sqoop, Kafka, Spark, Hortonworks, HBase, data lakes, logical data warehouses, NO-SQL, graph databases, etc. Experience with data governance and data management approaches, including data quality. Experience with business intelligence and advanced analytics: canned reporting, self-service insights, integrated data platforms, dash boarding, visualization, data science, machine learning. Experience with traditional data architecture: operational data stores, sourcing and staging data, data integration, master data management, dimensional/snowflake and de-normalized design, managed views, multidimensional cubes, data marts and analytical sandboxes.  BS/BA degree or equivalent experience.   Strong experience in SQL and dealing with multiple databases e.g. Teradata, DB2, SQL Server, Oracle etc.   Strong experience in reporting tools like Alteryx, Query Grid, Trifacta, Tableau, COGNOS etc.   Strong analytical abilities.   Strong experience with complex data models and data relationships - expertise in application, data and infrastructure architecture disciplines.   Proficiency in multiple modern programming languages SQL, Unix, Java.   Strong understanding of algorithms, OOP &SOA principles, design patterns, industry best practices.  "", 'Conducting POCs for defining the path towards making analytic solutions scalable.', 'Exposure to GCP / BigQuery- performance analysis - reduce number of bytes read by your query and optimizing costs.', ' Strong analytical abilities. ', 'Experience with traditional data architecture: operational data stores, sourcing and staging data, data integration, master data management, dimensional/snowflake and de-normalized design, managed views, multidimensional cubes, data marts and analytical sandboxes.', 'Define advanced vendor tool deployment solutions in the cloud and on-prem with a goal towards zero customer impacts through feature or version upgrades.', 'Experience with business intelligence and advanced analytics: canned reporting, self-service insights, integrated data platforms, dash boarding, visualization, data science, machine learning.', 'Design and Build impactful telemetry and usage tracking solutions for BI tools to improve tool governance and monitoring.', 'At least 5 years of hands-on experience in data architecture and meeting non-functional requirements.', 'Evaluating Public and Private Cloud enablement options for Analytical and Reporting tools and contribute tool maturity.', ""Experience with 'Big Data' architecture: Flume, Sqoop, Kafka, Spark, Hortonworks, HBase, data lakes, logical data warehouses, NO-SQL, graph databases, etc."", ' BS/BA degree or equivalent experience. ', 'Building audit compliant cloud solutions and simplifying access mechanism to make self-service offering more robust, efficient and secure.', 'At least 3 years in financial services, specifically data engineering with compliance for origination, servicing and transactional data to support core banking and operational processes and analytics.', 'Exposure to AWS Cloud Technologies (S3, RDS, EC2, Aurora, etc.), Erwin Enterprise Data Modeler/DM Workgroup.', ' Strong experience in SQL and dealing with multiple databases e.g. Teradata, DB2, SQL Server, Oracle etc. ', 'Any of the following is a plus - AWS Certified Cloud Practitioner, AWS Certified Solutions Architect - Associate, AWS Certified DevOps Engineer - Professional and/or AWS Certified Solutions Architect - Professional', 'Maturing modern data pipeline streams for analytics use-cases.', 'Experience with data governance and data management approaches, including data quality.', 'Evaluating Public and Private Cloud enablement options for Analytical and Reporting tools and contribute tool maturity. Conducting POCs for defining the path towards making analytic solutions scalable. Building audit compliant cloud solutions and simplifying access mechanism to make self-service offering more robust, efficient and secure. Define advanced vendor tool deployment solutions in the cloud and on-prem with a goal towards zero customer impacts through feature or version upgrades. Design and Build impactful telemetry and usage tracking solutions for BI tools to improve tool governance and monitoring. Maturing modern data pipeline streams for analytics use-cases. ', ' Strong experience with complex data models and data relationships - expertise in application, data and infrastructure architecture disciplines. ', ' Strong understanding of algorithms, OOP &SOA principles, design patterns, industry best practices. ', ' Proficiency in multiple modern programming languages SQL, Unix, Java. ', ' Strong experience in reporting tools like Alteryx, Query Grid, Trifacta, Tableau, COGNOS etc. ']",Associate,Full-time,Information Technology,Banking,2020-11-05 11:32:32
Infection Prevention Specialist,St. Joseph Health,"Mission Viejo, CA",3 hours ago,Be among the first 25 applicants,"['', 'Ability to abstract information from medical and laboratory records.', 'Ability to identify, assess and implement solutions to problems at point of service.', ""Associate's Degree Nursing, Clinical Lab Scientist, Medical Technologist, or health care related science degree.Bachelor's Degree Nursing, Clinical Lab Scientist, Medical Technologist, or health care related science degree."", 'Applies statistical analysis and rate basing to summary reports.', 'Maintenance of databases for infection control and epidemiological data and analyses.', 'Knowledge of Infection Prevention and Control, Microbiology, and Performance Improvement.Interpersonal skills in communicating with all customers.Ability to identify, assess and implement solutions to problems at point of service.Ability to abstract information from medical and laboratory records.Applies statistical analysis and rate basing to summary reports.Maintenance of databases for infection control and epidemiological data and analyses.Reviews and abstracts data from hospital databases.Proficient in the use of Microsoft Office (Work, Excel).', 'Preferred Position Requirements', 'Education', 'Within 2 years of hire:', 'Interpersonal skills in communicating with all customers.', 'Proficient in the use of Microsoft Office (Work, Excel).', 'We are looking for a Infection Prevention Specialist with Infection Prevention -MV Department at Mission Hospital Regional Medical Center.Location: ', 'Reviews and abstracts data from hospital databases.', ""Associate's Degree Nursing, Clinical Lab Scientist, Medical Technologist, or health care related science degree."", 'Shift:', 'Job Summary', ""Bachelor's Degree Nursing, Clinical Lab Scientist, Medical Technologist, or health care related science degree."", ' Current Certification in Infection Control (CIC).', 'License And Certificate', 'Education:', 'Experience: ', 'Skills', 'Knowledge of Infection Prevention and Control, Microbiology, and Performance Improvement.', ' Current License in related field (RN, CLS, MT), or', 'Schedule:', 'Position Requirements:', 'Experience:']",Entry level,Full-time,Other,Nonprofit Organization Management,2020-11-05 11:32:32
"Travel Medical Tech - COVID19 - $1,850 per week",NurseFly,"Fort Worth, TX",24 hours ago,Be among the first 25 applicants,"['', ' 401(k) and Flex Spending', ' Refer a friend and earn extra cash!', 'Medical Tech', '13 weeks', 'About The Company', 'Allied Health Professional', 'Preferred Qualifications', 'Duration: 13 weeks', 'Shift: 12 hours, evenings, nights', 'Discipline: Allied Health Professional', 'Facility Location', '12 hours, evenings, nights', '  Competitive pay rates  Medical, Dental, Vision  401(k) and Flex Spending  Life Insurance  Accident and Short-term Disability Coverage  Free Continuing Education  Free Private Housing  Refer a friend and earn extra cash! ', 'Travel', ' Free Continuing Education', 'Start Date: ASAP', ' Life Insurance', '36.00 hours per week', ' Competitive pay rates', ' Medical, Dental, Vision', 'About Club Staffing', 'Job Description & Requirements', 'Required Qualifications', 'ASAP', ' Accident and Short-term Disability Coverage', 'Job Benefits', 'Specialty: Medical TechDiscipline: Allied Health ProfessionalStart Date: ASAPDuration: 13 weeks36.00 hours per weekShift: 12 hours, evenings, nightsEmployment Type: Travel', ' Free Private Housing', 'Employment Type: Travel', 'Specialty: Medical Tech']",Not Applicable,Part-time,Other,Staffing and Recruiting,2020-11-05 11:32:32
Software Development Engineer in Test (SDET) Product Engineer-Mapping,Esri,"Redlands, CA",7 hours ago,44 applicants,"['', 'Design, develop, implement, and maintain test automation frameworks to be used by development and test engineers using C# as a primary programming language', '1+ years of experience using an application development language, such as C#, Java, C++, or Python', 'Collaborate with software engineers, product engineers, and other stakeholders to build and test ArcGIS Pro functionality related to general mapping, cartography, GPS, and map service capabilities', '1+ years of software testing experience1+ years of experience using an application development language, such as C#, Java, C++, or PythonA self-motivated team player with an interest in continuous learning and building software productsBachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level', 'Assist in determining product quality and release readiness', 'Responsibilities', 'Familiarity with ArcGIS Pro, ArcMap, and ArcGIS platform technologies', '1+ years of experience with software testing tools such as CodedUI, Appium, TestNG, Selenium, Cucumber, or related tools', 'Recommended Qualifications', 'A self-motivated team player with an interest in continuous learning and building software products', 'Design, develop, implement, and maintain test automation frameworks to be used by development and test engineers using C# as a primary programming languageWork with a team of dedicated software engineers and product engineers to design and author test cases for unit, functional, performance, scalability, and durability testing based on user requirementsCollaborate with software engineers, product engineers, and other stakeholders to build and test ArcGIS Pro functionality related to general mapping, cartography, GPS, and map service capabilitiesAssist in determining product quality and release readiness', '1+ years of software testing experience', 'Requirements', '1+ years of experience using web technologies such as JSON, REST, or JavaScript', 'Overview', 'Experience with relational databases', 'About Esri', 'Familiarity with ArcGIS Pro, ArcMap, and ArcGIS platform technologiesExperience with relational databases1+ years of experience using web technologies such as JSON, REST, or JavaScript1+ years of experience with software testing tools such as CodedUI, Appium, TestNG, Selenium, Cucumber, or related tools', 'Work with a team of dedicated software engineers and product engineers to design and author test cases for unit, functional, performance, scalability, and durability testing based on user requirements', 'Bachelor’s or master’s in computer science, engineering, geography, GIS, mathematics, or related field, depending on position level']",Not Applicable,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Director of Product Marketing,Prevedere Inc.,"Columbus, Ohio Metropolitan Area",21 hours ago,Be among the first 25 applicants,"['', 'Medical/Dental/Vision', 'Relocation possible', 'We are looking for someone who loves collaborating with others across functions to drive cohesive go to market programs.\xa0We are looking for someone who brings ideas and opinions, yet who is also willing and able to hear and incorporate the voices of others.\xa0We are looking for someone who thinks fast and acts even faster.\xa0We are looking for someone who sees the possibilities that we see for our company and who wants to be a key player in bringing this to reality.', 'While most companies can easily report on internal performance, Prevedere’s external real-time insights engine constantly monitors the world’s activity, identifying future threats or opportunities to business performance. Along with a team of industry experts, data scientist, and economists, Prevedere helps business leaders make the right decisions in an ever-changing world.', 'Ability to drive complex, cross-functional initiatives without a proven playbook (while building such a playbook for repeatability)', 'Excellent presentation skills, having excelled at presenting to senior business leaders within enterprises.', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States\xa0(i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).', 'Drive campaign and content strategy for initiatives that result in pipeline for the sales organization.', '\xa0', 'Demonstrated experience in managing the build out of an array of content for technical and business decision makers, sales enablement training and tools, and partner joint solution marketing', 'Define and track KPIs for solutions GTM, while evaluating solution-based SKUs and pricing', '8+ years of product marketing / solutions marketing at a B2B SaaS company', '401k', 'What you will get', 'Work closely with leadership across the company to define and evolve our GTM strategy and plans for execution', 'Competitive SalaryBonusVacation/PTOMedical/Dental/Vision401kRelocation possible', 'Drive sales enablement through solution content, case studies, competitive analysis, and training\xa0', 'Deliver key messages that enable our go-to-market teams to execute relevant strategic campaigns and programs.\xa0', 'What you will bring', 'The Director of Product Marketing role is a highly strategic and cross-functional position focused on evolving and executing our go to market strategy.\xa0From driving thought leadership to enabling our field sales to collaborating with partners on joint solutions to partnering with corporate marketing, this role covers a wide set of responsibilities with plenty of room for continued growth and advancement.\xa0In this role, you will report to the Chief Revenue Officer and be a key part of developing and leading our go to market efforts to generate accelerated growth.\xa0', '8+ years of product marketing / solutions marketing at a B2B SaaS company2+ years of experience managing a product or solutions marketing team preferredProven track record of working across functions to build and execute on go-to-market plans for business solutions to large enterprisesPassion for measurement, metrics and continuous improvement across the organizationAbility to drive complex, cross-functional initiatives without a proven playbook (while building such a playbook for repeatability)Excellent presentation skills, having excelled at presenting to senior business leaders within enterprises.Demonstrated experience in managing the build out of an array of content for technical and business decision makers, sales enablement training and tools, and partner joint solution marketing', '2+ years of experience managing a product or solutions marketing team preferred', 'Competitive Salary', 'Proven track record of working across functions to build and execute on go-to-market plans for business solutions to large enterprises', 'Work closely with leadership across the company to define and evolve our GTM strategy and plans for executionPartner with the rest of the marketing team, Business Development, Sales, and Product to align our solutions and team with our GTM strategy and tacticsDrive sales enablement through solution content, case studies, competitive analysis, and training\xa0Engage with partners, both existing strategic partners as well as prospective partners, to assess, define, and drive market strategies for joint solution offeringsRepresent Prevedere externally as a thought leader on Intelligent Forecasting and the strategic value it provides to business executivesDefine and track KPIs for solutions GTM, while evaluating solution-based SKUs and pricingDeliver key messages that enable our go-to-market teams to execute relevant strategic campaigns and programs.\xa0Drive campaign and content strategy for initiatives that result in pipeline for the sales organization.', 'Passion for measurement, metrics and continuous improvement across the organization', 'Vacation/PTO', 'What you will do', 'Prevedere is a fast-growing company backed by top Silicon Valley Investors and Microsoft Ventures.', ' ', 'Bonus', 'Prevedere is an industry insights and predictive analytics company helping business leaders make better decisions by providing a real-time view of their company’s future.', 'Represent Prevedere externally as a thought leader on Intelligent Forecasting and the strategic value it provides to business executives', 'About Prevedere', 'Named a 2017 Red Herring North America Top 100 Company and the Most Innovative Tech Company of the Year by the 2016 American Business Awards, Prevedere works with over 40 top global companies.', 'Partner with the rest of the marketing team, Business Development, Sales, and Product to align our solutions and team with our GTM strategy and tactics', 'Engage with partners, both existing strategic partners as well as prospective partners, to assess, define, and drive market strategies for joint solution offerings']",Mid-Senior level,Full-time,Marketing,Information Technology and Services,2020-11-05 11:32:32
Sr. UX Researcher,HUNTER Technical - htrjobs.com,"Irvine, CA",6 hours ago,42 applicants,"['', 'Job Description', 'Essential Skills, Knowledge And Competencies', 'Position Responsibilities']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Program Scheduler,"Global Technology Associates, Ltd. ","Batavia, IL",1 hour ago,Be among the first 25 applicants,"['', 'Pay Rate', "" Provide project control services for the managers of the Short Baseline Neutrino (SBN) program at Fermilab.  Project controls services for SBN comprise  Maintain the existing schedule (Microsoft Project); update as requested by managers Generate monthly and quarterly financial reports using Fermilab's financial systems Integrate schedule and financial data with Cobra to provide Earned Value Management reporting and forecasting (baseline, forecast, SPI, CPI, EAC, etc.) Expected hours per week between 10 and 20 hours with an average of about 12 hours per week. The SBN Program manages the construction of two detectors for a particle physics experiment. The SBN schedule and budget plan is maintained in a Microsoft Project file holding approximately 2500 tasks. The Program is 70% complete. Many procedures for schedule and financial reporting are well entrenched and management is not seeking to change them. The Scheduler works with a management team of scientists and engineers, and participates in weekly meetings with this team, and also participates in monthly meetings where SBN management reports status to Lab management. "", ""Develop/maintain resource needs (Labor and M&S) and the project's Basis of Estimate (BOE process Estimate to Complete (ETC) updates to generate the project's Estimate at Completion (EAC)"", ""Minimum 10 years' experience with Microsoft Project (MSP)"", ""Experience using the Cobra program, which is used to interface to Fermilab's accounting data and for generating Earned Value reports"", 'What is your ""acceptable and ""ideal base compensation for this position? We would like to make sure we don\'t price you out of consideration, but you know what the numbers are that you need (Please Do Not put negotiable)', ""Manage and incorporate changes to the PMB using the project's Change Control process"", 'Position Summary', 'Generate performance measurement monthly reports for the management team', 'Develop/maintain a fully integrated resource-loaded MSP schedule', 'Variance analysis', 'The SBN Program manages the construction of two detectors for a particle physics experiment.', 'Are you currently working? If not, when was your last day of employment?', 'Experience using Visual Basic macros incorporated within MSP', ' generous referral bonus program detailed below. ', 'Maintain the existing schedule (Microsoft Project); update as requested by managers', 'Pre-Screening Questionnaire', 'Position Requirements', 'Present earned value analysis data at project management meetings and internal/external reviews', 'Integrate schedule and financial data with Cobra to provide Earned Value Management reporting and forecasting (baseline, forecast, SPI, CPI, EAC, etc.) Expected hours per week between 10 and 20 hours with an average of about 12 hours per week.', ""Process Estimate to Complete (ETC) updates to generate the project's Estimate at Completion (EAC)"", "" Develop/maintain a fully integrated resource-loaded MSP schedule Assist technical management in developing/maintaining resource requirements to support the project cost estimates Analysis of the project schedule using critical path methodology Manage and incorporate changes to the PMB using the project's Change Control process Maintaining Earned Value (EV) data with Cobra cost processor software. Performing project EV data analysis in conjunction with the Control Account Managers (CAM) and Project Manager including: Develop/maintain resource needs (Labor and M&S) and the project's Basis of Estimate (BOE) Process Estimate to Complete (ETC) updates to generate the project's Estimate at Completion (EAC) Develop presentations pertaining to the project schedules, resources, and project performance Variance analysis Corrective actions "", 'Performing project EV data analysis in conjunction with the Control Account Managers (CAM) and Project Manager including:', 'Experience developing schedules with engineers and/or scientist for the construction of complex scientific instruments', ""Develop/maintain resource needs (Labor and M&S) and the project's Basis of Estimate (BOE)"", 'Assist technical management in developing/maintaining resource requirements to support the project cost estimates', 'Corrective actions', 'The Scheduler works with a management team of scientists and engineers, and participates in weekly meetings with this team, and also participates in monthly meetings where SBN management reports status to Lab management.', 'Location', 'Extraction of MSP data to formatted Excel files', 'Project controls services for SBN comprise ', 'Analysis of the project schedule using critical path methodology', ""Generate monthly and quarterly financial reports using Fermilab's financial systems"", 'What is the highest level of education you have completed? Which field of study is this degree in and from which university did you graduate? Are you currently working? If not, when was your last day of employment? Can you please list why you left or why you are looking to leave your most recent employer? What is your ""acceptable and ""ideal base compensation for this position? We would like to make sure we don\'t price you out of consideration, but you know what the numbers are that you need (Please Do Not put negotiable) When would you be available to interview and start this position, if selected? Do you require visa sponsorship? If you currently have sponsorship, other than a TN visa, please state the type of sponsorship and when it will expire. Please give month and year. If you can receive extensions to the sponsorship, please note how many additional years.  ', 'Title: Program Scheduler - Financial Systems', 'Performing customized accounting calculations, following Fermilab accounting practices', 'What is the highest level of education you have completed? Which field of study is this degree in and from which university did you graduate?', 'Provide project control services for the managers of the Short Baseline Neutrino (SBN) program at Fermilab. ', 'Additional Benefits', 'Demonstrates understanding and implementation of ANSI 748 EVMS Standards', 'Additional Review And Reporting Responsibilities', 'Demonstrates Expert skills with basic MS Office (Word, PowerPoint, and Excel)', 'we can offer up to $250 for contractors after they are on the job for 90 days and up to $500 for direct hires after they are on the job between 90 days to 180 days', "" Performing project EV data analysis in conjunction with the Control Account Managers (CAM) and Project Manager including: Develop/maintain resource needs (Labor and M&S) and the project's Basis of Estimate (BOE process Estimate to Complete (ETC) updates to generate the project's Estimate at Completion (EAC) Develop presentations pertaining to the project schedules, resources, and project performance Variance analysis Corrective actions Generate performance measurement monthly reports for the management team Present earned value analysis data at project management meetings and internal/external reviews "", 'Can you please list why you left or why you are looking to leave your most recent employer?', 'The Program is 70% complete. Many procedures for schedule and financial reporting are well entrenched and management is not seeking to change them.', 'When would you be available to interview and start this position, if selected?', 'Develop presentations pertaining to the project schedules, resources, and project performance', 'Do you require visa sponsorship? If you currently have sponsorship, other than a TN visa, please state the type of sponsorship and when it will expire. Please give month and year. If you can receive extensions to the sponsorship, please note how many additional years. ', "" Minimum 10 years' experience with Microsoft Project (MSP) Demonstrates Expert skills with basic MS Office (Word, PowerPoint, and Excel) Experience using Visual Basic macros incorporated within MSP Performing customized accounting calculations, following Fermilab accounting practices Extraction of MSP data to formatted Excel files Demonstrates understanding and implementation of ANSI 748 EVMS Standards Experience using the Cobra program, which is used to interface to Fermilab's accounting data and for generating Earned Value reports Experience developing schedules with engineers and/or scientist for the construction of complex scientific instruments "", 'Maintaining Earned Value (EV) data with Cobra cost processor software.', 'Please note that if you are a current GTA employee or have been placed by GTA at one of our clients, we will not be able to entertain moving you. However, we are hopeful that you may know someone else who is qualified and as such you would still be eligible for our  generous referral bonus program detailed below. ', 'Referral Bonus Program', 'Performance Measurement Baseline (PMB) Responsibilities', 'The SBN schedule and budget plan is maintained in a Microsoft Project file holding approximately 2500 tasks.', 'Type of hire']",Entry level,Contract,Project Management,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Senior AWS Data Engineer / Architect,"Pinnacle Group, Inc.",Dallas-Fort Worth Metroplex,43 minutes ago,Be among the first 25 applicants,"['', 'Full lifecycle solution development and deployment best practices for the AWS cloud environment', 'Manage and document data footprint within the Data Warehouse', 'Own and drive strategic technical direction with team in AWS environment', 'Architect MDM solutions & components', 'Experience translating and documenting business requirements into conceptual, logical, and physical data models', 'Requirements:', 'Hands on development acquiring, ingestion, and processing data from multiple sources and systems into AWS and Snowflake data platforms', '5+ years’ experience with Python, SQL, and AWS services', 'Create, deploy and manage data environments in the AWS cloud', 'Experience leading teams of developers both onshore and offshore', 'Provide team leadership to data integration team members', 'AWS certification a plus', 'Work with insights and analytical team members to understand data requirements', 'Lead, manage and guide technical project teams on all technical design and components', 'Leverage information security principles to ensure compliant handling and management of data', 'Architect and hands on implementation of solutions to improve current environments', 'Experience with Snowflake a plus', 'Study existing technology landscape and understand current application workloads to optimize performance and identify cost saving opportunities within AWS environment', 'Design and develop best in class AWS cloud-based data management solutions', '\ufeff', 'Develop, document and ensure adherence to standards and best practices and facilitate technology/solution checkpoints', '7+ years’ experience working on projects in a global setting, often working on multiple projects simultaneously', 'Develop architecture blueprints and detailed documentation in the AWS cloud environment', '5+ years’ experience designing cloud solutions incorporating Information Security principles and best practices to ensure designs are in accordance with regulatory data security and data governance principles', 'Experience with data replication, ELT or ETL tool(s) a plus', 'Job Description', 'Hands on solution development leveraging relevant data management and integration technologies', 'Design and develop best in class AWS cloud-based data management solutionsPlan and execute secure, good practice data integration strategies and approaches in AWSStudy existing technology landscape and understand current application workloads to optimize performance and identify cost saving opportunities within AWS environmentHands on development acquiring, ingestion, and processing data from multiple sources and systems into AWS and Snowflake data platformsCreate, deploy and manage data environments in the AWS cloudManage and document data footprint within the Data WarehouseLeverage information security principles to ensure compliant handling and management of dataDevelop architecture blueprints and detailed documentation in the AWS cloud environmentImplement AWS Cloud Services such as EC2, S3 EMR and data pipeline, etc.Architect and hands on implementation of solutions to improve current environmentsWork with insights and analytical team members to understand data requirementsProvide team leadership to data integration team membersHands on solution development leveraging relevant data management and integration technologiesArchitect MDM solutions & componentsLead, manage and guide technical project teams on all technical design and componentsOwn and drive strategic technical direction with team in AWS environmentDevelop, document and ensure adherence to standards and best practices and facilitate technology/solution checkpoints', 'Plan and execute secure, good practice data integration strategies and approaches in AWS', 'Implement AWS Cloud Services such as EC2, S3 EMR and data pipeline, etc.', '5+ years’ experience with cloud data management technologies such as AWS Redshift and Snowflake', '7+ years’ experience working on projects in a global setting, often working on multiple projects simultaneously5+ years’ experience designing cloud solutions incorporating Information Security principles and best practices to ensure designs are in accordance with regulatory data security and data governance principlesExperience leading teams of developers both onshore and offshoreExperience translating and documenting business requirements into conceptual, logical, and physical data modelsFull lifecycle solution development and deployment best practices for the AWS cloud environment5+ years’ experience with cloud data management technologies such as AWS Redshift and Snowflake5+ years’ experience with Python, SQL, and AWS servicesAWS certification a plusExperience with Snowflake a plusExperience with data replication, ELT or ETL tool(s) a plus']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Intern - Data Scientist,Solar Turbines,"San Diego, CA",11 hours ago,Be among the first 25 applicants,"['', 'Excellent communications skills, both written and verbal', 'Visa Eligibility', 'Ability to process abstract conceptsData analyticsCoding: C#, Python etc.Statistics & probabilistic theoryPragmaticCreative problem-solving capabilitiesSelf-motivatedTeam workingExcellent communications skills, both written and verbal', 'Minimum Qualifications', 'Preferred Qualifications', 'Auto req ID', 'Minimum Education Level', 'Company', 'Travel Requirements', 'Responsibilities', 'Coding: C#, Python etc.', 'Country', 'State/Region/Province', ""Currently in the process of obtaining a minimum of a Bachelor's degree in Data Science, Material Science, Mathematics, or related field."", 'Data analytics', 'Position Category External', 'Location', 'EOE Plus', 'Creative problem-solving capabilities', 'Shift', 'Company Info', 'Self-motivated', 'Team working', 'GPA of at least 2.7 on a 4.0 scale.', 'Currently a sophomore or junior, or a senior planning to attend grad school, or grad student in the process of attaining an advanced degree', 'Minimum Years Experience', 'Job Description', 'Relocation Eligibility', 'Benefits Eligibility', 'Statistics & probabilistic theory', ""GPA of at least 2.7 on a 4.0 scale.Currently in the process of obtaining a minimum of a Bachelor's degree in Data Science, Material Science, Mathematics, or related field.Currently a sophomore or junior, or a senior planning to attend grad school, or grad student in the process of attaining an advanced degree"", 'Job Category', 'Ability to process abstract concepts', 'Pragmatic']",Internship,Full-time,Engineering,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Sr Cyber Security Researcher,GE,"Glen Allen, VA",22 hours ago,Be among the first 25 applicants,"['', 'Partner with business IT security teams to drive improvement in IT security as a result of Cyber Security Research engagements ', 'Research, develop, implement, test and document tools, techniques and tactics used by adversaries to compromise and maintain control of information assets', 'Conduct adversary simulation to determine if flaws and exposures can be exploited by unfriendly forces', 'Participate in cross-team Task Forces to drive impact of Cyber Security Research findings as appropriate', 'Change oriented - suggests and implements process improvements; supports and drives change, and confronts difficult circumstances in creative ways', 'Desired Characteristics', 'Minimum 2 years of experience in scripting ', 'Experience conducting threat simulation or penetration testing engagements in an enterprise environment', ""Bachelor's Degree in Computer Science or a related technical degree plus 4 years of professional IT experience OR in lieu of a degree, a minimum 8 years of professional IT experienceMinimum 2 years of experience in scripting Minimum 2 years of deep, hands-on, technical security experience with at least one year of experience in: Wired Network technologies (CISCO routers / switches, Checkpoint), Wireless (WLAN, WIMAX, RFID), Enterprise Storage Systems, UNIX / Linux, Windows / AD, iSeries / zSeries, Database administration, Web applications and Services, Cryptography, Social Engineering and Open Source Intelligence Gathering (OSINT), Mobile platforms, Software Security (Source Code Auditing and Binary Reversing), Systems or OS-native programming (especially Windows), Cloud Administration, Container-based VirtualizationLocation: Flexible"", ""Bachelor's Degree in Computer Science or a related technical degree plus 4 years of professional IT experience OR in lieu of a degree, a minimum 8 years of professional IT experience"", 'Experience with the command line in Windows and / or Linux', 'Strong team player - collaborates well with others to solve problems and actively incorporates input from various sources', 'Location: Flexible', 'Experience developing exploit code or novel attacksExperience conducting penetration testing engagementsExperience with the command line in Windows and / or LinuxAbility to rapidly find, assimilate and synthesize information in pursuit of attacksExtreme resourcefulness with willingness to learn and teach how to characterize adversary tools and techniques, assess and test Company resources, and improve Company defenses Demonstrated ability to compromise complex IT systems / applications in enterprise environmentsExperience conducting threat simulation or penetration testing engagements in an enterprise environmentProven vulnerability analysis skillsExcellent communication skills including both verbal and writtenHardware / electronics experienceStrong track record of understanding and interest in current and emerging technologies demonstrated through training, job experience and / or industry activitiesStrong team player - collaborates well with others to solve problems and actively incorporates input from various sourcesDemonstrated customer focus - evaluates decisions through the eyes of the customer and can build strong customer relationshipsChange oriented - suggests and implements process improvements; supports and drives change, and confronts difficult circumstances in creative waysAbility to read / write foreign languagesGE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer . Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable).Relocation Assistance Provided:  No', 'Proven vulnerability analysis skills', 'Experience conducting penetration testing engagements', 'Extreme resourcefulness with willingness to learn and teach how to characterize adversary tools and techniques, assess and test Company resources, and improve Company defenses', 'Strong track record of understanding and interest in current and emerging technologies demonstrated through training, job experience and / or industry activities', 'Executing engagements; defining scope, coordinating attacks, executing tests and reporting findings, following an established methodology in accordance with defined processes ', 'Ability to rapidly find, assimilate and synthesize information in pursuit of attacks', 'Essential Responsibilities :', 'Ability to read / write foreign languages', 'Partner with business IT security teams to drive improvement in IT security as a result of Cyber Security Research engagements Executing engagements; defining scope, coordinating attacks, executing tests and reporting findings, following an established methodology in accordance with defined processes Conduct adversary simulation to determine if flaws and exposures can be exploited by unfriendly forcesResearch, develop, implement, test and document tools, techniques and tactics used by adversaries to compromise and maintain control of information assetsCoordinate with other teams in IT Risk in development of threat agent profiles Participate in cross-team Task Forces to drive impact of Cyber Security Research findings as appropriate', 'Hardware / electronics experience', 'Excellent communication skills including both verbal and written', 'Coordinate with other teams in IT Risk in development of threat agent profiles ', 'Job Description', 'Qualifications/Requirements', 'Relocation Assistance Provided: ', 'Minimum 2 years of deep, hands-on, technical security experience with at least one year of experience in: Wired Network technologies (CISCO routers / switches, Checkpoint), Wireless (WLAN, WIMAX, RFID), Enterprise Storage Systems, UNIX / Linux, Windows / AD, iSeries / zSeries, Database administration, Web applications and Services, Cryptography, Social Engineering and Open Source Intelligence Gathering (OSINT), Mobile platforms, Software Security (Source Code Auditing and Binary Reversing), Systems or OS-native programming (especially Windows), Cloud Administration, Container-based Virtualization', 'Demonstrated customer focus - evaluates decisions through the eyes of the customer and can build strong customer relationships', 'Experience developing exploit code or novel attacks', ' Demonstrated ability to compromise complex IT systems / applications in enterprise environments']",Associate,Full-time,Information Technology,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Data Scientist Intern,Silicon Labs,"Austin, TX",10 hours ago,Be among the first 25 applicants,"['', ' you’ll ', 'Work on ad-hoc analysis of customer engagement, buyer’s journey’s, and campaigns to provide deeper insights.', 'Wireless', 'Knowledgeable use of Excel and Pivot Tables for analysis ', '’s in a World-Class Internship?', 'Develop and implement databases, data collection systems, data analytics visualizations and other strategies that optimize statistical efficiency and quality. Collaborate with our Marketing and IT business intelligence team to drive analytics, give updates to the business, and gain a deeper understanding of our development process. Understand our tool integrations that bring data into a central location for analysis and help optimize.Work on ad-hoc analysis of customer engagement, buyer’s journey’s, and campaigns to provide deeper insights.', 'iscover why we attract the best and brightest!', 'Interaction with data sources and working with data lakes ', ' IoT (', 'Intern', 'Sensors', 'We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.', 'Any coursework or internship experience in the follow areas will be considered a plus:Experience with Microsoft Power BI or Tableau Familiarity with Mark-Ops tools, Adobe Analytics, Marketo, Salesforce Interaction with data sources and working with data lakes Knowledgeable use of Excel and Pivot Tables for analysis ', 'Develop and implement databases, data collection systems, data analytics visualizations and other strategies that optimize statistical efficiency and quality. ', 'Experience with Microsoft Power BI or Tableau Familiarity with Mark-Ops tools, Adobe Analytics, Marketo, Salesforce Interaction with data sources and working with data lakes Knowledgeable use of Excel and Pivot Tables for analysis ', 'Completion of 2+ years of study Enrollment in BS/MS Information Systems, Marketing, Computer Science, or Statistics ', 'MCU,', 'Description', 'What You’ll Do', 'Learn more about the I&A (', 'Collaborate with our Marketing and IT business intelligence team to drive analytics, give updates to the business, and gain a deeper understanding of our development process. ', 'Familiarity with Mark-Ops tools, Adobe Analytics, Marketo, Salesforce ', 'Take It From Our Previous Interns', 'Labs:', 'Isolation', 'Understand our tool integrations that bring data into a central location for analysis and help optimize.', 'As a Silicon Labs ', ') products and', 'D', 'Completion of 2+ years of study ', 'Data Science', ') products', 'à', ' ', 'have exposure to.', 'Who You Are', ', ', 'What', 'Power', 'Enrollment in BS/MS Information Systems, Marketing, Computer Science, or Statistics ', 'Most Respected Public Semiconductor Company ', 'licon ', 'Timing', 'More About Si', 'Experience with Microsoft Power BI or Tableau ']",Internship,Internship,Engineering,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
AI Scientist Intern,Electronic Arts (EA),"Redwood City, CA",6 hours ago,Be among the first 25 applicants,"['', ' Research and implement novel AI approaches for new business problems. ', ' Experience with SQL and MPP databases ', ' Establish scalable, efficient, automated processes for enterprise-level management of AI applications ', ' The Challenge Ahead ', ' Create scalable solutions for problems in the gaming domain ', ' The next great EA AI Scientist should have ', ' Be in pursuit of a Ph.D. or MS with experience in Computer Science, or related fields (focus in AI or ML a plus) ', ' Develop state-of-the-art algorithms and extract key insights from EA’s rich store of data to empower intelligent agents within the EA ecosystem  Create scalable solutions for problems in the gaming domain  Design, develop and evaluate highly innovative AI applications for content creation, NPC behavior, game balance evaluation, and recommendations  Work closely with the core development teams to deploy AI applications seamlessly as part of production systems  Establish scalable, efficient, automated processes for enterprise-level management of AI applications  Research and implement novel AI approaches for new business problems. ', ' Work closely with the core development teams to deploy AI applications seamlessly as part of production systems ', ' Develop state-of-the-art algorithms and extract key insights from EA’s rich store of data to empower intelligent agents within the EA ecosystem ', ' Be in pursuit of a Ph.D. or MS with experience in Computer Science, or related fields (focus in AI or ML a plus)  Track record of having developed novel AI algorithms, and major journal and conference publications  Strong problem-solving ability  Strong programming skills (object-oriented and functional paradigms)  Experience with large-scale data and distributed systems – Experience with Apache Hadoop, Spark, and Tensorflow a plus  Experience with SQL and MPP databases  Excellent written and verbal communication skills', ' Excellent written and verbal communication skills', 'We are EA ', ' Design, develop and evaluate highly innovative AI applications for content creation, NPC behavior, game balance evaluation, and recommendations ', ' Experience with large-scale data and distributed systems – Experience with Apache Hadoop, Spark, and Tensorflow a plus ', ' Track record of having developed novel AI algorithms, and major journal and conference publications ', ' Strong programming skills (object-oriented and functional paradigms) ', ' Strong problem-solving ability ', 'What An AI Scientist Intern Does At EA']",Not Applicable,Full-time,Other,Computer Games,2020-11-05 11:32:32
Machine Learning Engineer Intern,Lenovo,"Raleigh, NC",8 hours ago,Be among the first 25 applicants,"['', ' Must be a rising Sophomore or higher pursuing a degree in Computer Science or related field.', ' Experience with one or more general-purpose programming languages including but not limited to: Java, C/C++, or Python', ' Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, recommendation systems, targeting systems, ranking systems, or similar.', 'Have strong problem solving and analytical skills.', ' Ability to work well on your own and on teams; experience with and an appreciation for agile principles and practices', 'Position Description:']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Data Scientist Apprentice Conversion,IBM,"New York, NY",1 hour ago,Be among the first 25 applicants,"['', 'You will implement and validate predictive models as well as create and maintain statistical models with a focus on big data. ', 'Must have completed the IBM apprenticeship program', 'Basic knowledge of statistical concepts such as regression, time series, mixed model, Bayesian clustering, etc., to analyze data and provide insights.', 'About IBM', 'About Business Unit', ' Experience with programming/scripting in a language such as Java or Python ', 'You’ll work in an agile, collaborative environment, partnering with other scientists, engineers, and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'What You’ll Do As Data Scientist', 'Preferred Technical And Professional Expertise', 'You are great at solving problems, debugging, troubleshooting, and designing & implementing solutions to complex technical issues.', ' Must have basic understanding of statistical programming in a language such as R, SAS or Python  Experience with programming/scripting in a language such as Java or Python Basic knowledge of statistical concepts such as regression, time series, mixed model, Bayesian clustering, etc., to analyze data and provide insights.Must have completed the IBM apprenticeship program', 'You will implement and validate predictive models as well as create and maintain statistical models with a focus on big data. You will be exposed to and incorporate a variety of statistical and machine learning techniques such as logistic regression, experimental design, generalized linear models, mixed modeling, CHAID/decision trees, neural networks and ensemble models.You will communicate with internal and external clients to understand business needs and provide analytical solutions.You will use leading edge tools such as COGNOS, Watson Studio and Watson Machine Learning. You’ll work in an agile, collaborative environment, partnering with other scientists, engineers, and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.', 'Advanced knowledge of statistical concepts such as regressions, time series, mixed model, Bayesian methods, clustering, etc., to analyze data and provide insights', 'You will use leading edge tools such as COGNOS, Watson Studio and Watson Machine Learning. ', 'You have strong technical and analytical abilities, a knack for driving impact and growth, and some experience with programming/scripting in a language such as Java or Python.', 'Who You Are', 'You will be exposed to and incorporate a variety of statistical and machine learning techniques such as logistic regression, experimental design, generalized linear models, mixed modeling, CHAID/decision trees, neural networks and ensemble models.', 'One or more internship or co-op experiences', 'Advanced knowledge of statistical concepts such as regressions, time series, mixed model, Bayesian methods, clustering, etc., to analyze data and provide insightsOne or more internship or co-op experiences', ' Must have basic understanding of statistical programming in a language such as R, SAS or Python ', 'You will communicate with internal and external clients to understand business needs and provide analytical solutions.', 'You thrive on teamwork and have excellent verbal and written communication skills. ', 'You have an interest in, understanding of, or experience with Design Thinking and Agile Development methodologies.', 'You are great at solving problems, debugging, troubleshooting, and designing & implementing solutions to complex technical issues.You thrive on teamwork and have excellent verbal and written communication skills. You have strong technical and analytical abilities, a knack for driving impact and growth, and some experience with programming/scripting in a language such as Java or Python.You have an interest in, understanding of, or experience with Design Thinking and Agile Development methodologies.']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Base and Marketing Analytics Intern,Tractor Supply Company,"Brentwood, TN",6 hours ago,77 applicants,"['', ' Analytics within Cloud Environment  Data Scientist Experience  Machine Learning Experimentation  Statistics  Customer Marketing Focused  Working cross divisionally ', 'Summer 2021 Internship', ' Data Scientist Experience ', ' Machine Learning Experimentation ', ' Analytical Skills ', ' Junior, Senior or Graduate student ', ' Current student at an accredited university  Junior, Senior or Graduate student  Math, Computer Science, Engineering Major Preferred  Analytical Skills  Excel  Project Management  Strong Communication Skills ', ' Tractor Supply Company (TSCO), ', 'Responsibilities', ' Current student at an accredited university ', 'Projects you will be working on will include:', ' Working cross divisionally ', ' Analytics within Cloud Environment ', ' Excel ', 'Qualifications', ' Strong Communication Skills ', ' Statistics ', ' Customer Marketing Focused ', ' Project Management ', ' Math, Computer Science, Engineering Major Preferred ', '“Life out Here”!', 'Company Overview']",Entry level,Internship,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data & Applied Scientist,Microsoft,United States,20 hours ago,Be among the first 25 applicants,"['', 'Minimum of 5 years of related work experience.', ' Demonstrated ability to engage with and influence business teams in order to drive alignment', 'You', 'Ability to work cross-functionally, building and maintaining trust with internal stakeholders', 'Responsibilities', ' Own the delivery of the reporting and insights on a regular cadence to the stakeholders and senior leadership teams', 'The Team', 'Minimum of 5 years of related work experience.Demonstrated ability to manage own projects or programs including work prioritization, planning, and coordinationStrong communication and data presentation skills, experience analyzing data and communicating the results to senior business leadersAbility to work cross-functionally, building and maintaining trust with internal stakeholdersSolid SQL skills are a requirement - hands on use of big data in large projects using Power BI, Azure, Data Bricks, Presto or SparkProven experience of using R (or similar tools) to structure, transform and visualize big dataSolid understanding of online marketing, preferably in a past or current role, with experience of Search EngineMarketing, Revenue Optimization or Content targeting a plusProven ability to solve complex quantitative business challenges; experience in the development and measurement of multi-variant testing is a plus.Bachelor’s degree or higher in an analytical area such as Computer Science, Management information Systems, Mathematics, Statistics, Engineering or similar field preferred', ' Ensuring insights are both actionable and measurable and you should be able to build these insights and hypothesis with awareness of practical implementation and implications for the business', 'Proven ability to solve complex quantitative business challenges; experience in the development and measurement of multi-variant testing is a plus.', ' Freedom - Microsoft values everyone’s talent and skillset and provides the freedom to explore and enhance them.', 'Qualifications', 'Strong communication and data presentation skills, experience analyzing data and communicating the results to senior business leaders', ' Partnering with our Digital Analytics and Data Engineering teams to ensure robust and accurate data capture and continuous improvement of data available for both analytics and the wider business', 'Demonstrated ability to manage own projects or programs including work prioritization, planning, and coordination', ' Reach - Microsoft’s resources and scale empowers employees to utilize their skills for lasting impact.', 'Bachelor’s degree or higher in an analytical area such as Computer Science, Management information Systems, Mathematics, Statistics, Engineering or similar field preferred', 'Solid understanding of online marketing, preferably in a past or current role, with experience of Search Engine', 'Marketing, Revenue Optimization or Content targeting a plus', 'Proven experience of using R (or similar tools) to structure, transform and visualize big data', ' Build analytics to measure program impact, identify trends and anomalies, and influence marketing program investments', ' Knowledge sharing through presentations at regional, channel and business wide events, as well as building relationships with analytics teams across the group.', 'Solid SQL skills are a requirement - hands on use of big data in large projects using Power BI, Azure, Data Bricks, Presto or Spark', ' Inspiration - inspiration can be found through our products and how they can improve our customers’ lives.', ' Understanding and proactively communicating factors affecting content performance to stakeholders by partnering with business leaders, other analysts and data engineering teams.', ' Learn and understand a broad range of data resources and know when, how, and which to use and which not to at any given time.']",Not Applicable,Full-time,Other,Computer Hardware,2020-11-05 11:32:32
Data Scientist,Gap Inc.,"San Francisco, CA",5 hours ago,Be among the first 25 applicants,"['', 'Synthesize findings, prepare presentations and assist in presenting findings to all levels of management', 'Merchandise discount for our brands: 50% off regular-priced merchandise at Gap, Banana Republic and Old Navy, 30% off at Outlet and 25% off at Athleta for all employees.', 'Employee stock purchase plan.*', ' Merchandise discount for our brands: 50% off regular-priced merchandise at Gap, Banana Republic and Old Navy, 30% off at Outlet and 25% off at Athleta for all employees. One of the most competitive Paid Time Off plans in the industry.* Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.* Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.* Employee stock purchase plan.* Medical, dental, vision and life insurance.* See more of the benefits we offer. ', 'Build, validate, and maintain Operations Research (OR) and/or AI( Machine Learning (ML) /Deep learning), models', 'Skills to collaborate with cross-functional teams and influence product and analytics roadmap', 'Proven experience in areas of optimization, statistics, machine learning, and inventory theory', 'Extensive 401(k) plan with company matching for contributions up to four percent of an employee’s base pay.*', ' Masters in Operations Research, Statistics, Math, Computer Science, Industrial Engineering or related field. PhD is a plus. Proven experience in areas of optimization, statistics, machine learning, and inventory theory Ability to develop and apply analytic solutions to solve business problems Skills to collaborate with cross-functional teams and influence product and analytics roadmap Hands-on experience with data analysis, statistical, optimization and simulation packages (SQL, Python, SAS, Tensorflow, Hive, etc) ', 'Work with large quantities of data in scripting languages', 'Ability to develop and apply analytic solutions to solve business problems', 'Hands-on experience with data analysis, statistical, optimization and simulation packages (SQL, Python, SAS, Tensorflow, Hive, etc) ', 'Employees can take up to five “on the clock” hours each month to volunteer at a charity of their choice.*', 'Medical, dental, vision and life insurance.*', 'About Gap Inc.', 'One of the most competitive Paid Time Off plans in the industry.*', 'For eligible employees', 'Collaborate within the team and outside the team to solve complex problems', 'About The Role', 'See more of the benefits we offer.', 'Masters in Operations Research, Statistics, Math, Computer Science, Industrial Engineering or related field. PhD is a plus.', 'Provide framework/methodology for measurement and feedback mechanism for models', ' Build, validate, and maintain Operations Research (OR) and/or AI( Machine Learning (ML) /Deep learning), models Work with large quantities of data in scripting languages Synthesize findings, prepare presentations and assist in presenting findings to all levels of management Provide framework/methodology for measurement and feedback mechanism for models Collaborate within the team and outside the team to solve complex problems']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Caterpillar Inc.,"Chicago, IL",22 hours ago,66 applicants,"['', 'MS degree or higher in quantitative discipline such as applied statistics, data science, data analytics, computer science, computer engineering, engineering or other related degreeMinimum cumulative GPA requirement 3.0/ 4.0 (no rounding)Graduation date between May 2020 through May 2021Proficient in Python and SQL', 'Completed research or class projects in machine learning (classification, regression, unsupervised learning)', 'Passion for working in a dynamic environment where digital is still evolving as a core offering', ' Works on application/technical problem identification and resolution, including off-shift and weekend support functions', ' Fully knowledgeable of programming languages, program design and specification development, programming logic, logic diagrams, testing and debugging', 'Knowledge of visualization tools like Tableau, MS Power BI, Kibana, etc.', 'MS degree or higher in quantitative discipline such as applied statistics, data science, data analytics, computer science, computer engineering, engineering or other related degree', ' Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time', 'Completed coursework in machine learning and/or computational methods in statistics and data mining', 'Description', 'Strong verbal and written communication skills', ' Works independently on complex programs/subroutines', 'Familiarity with AWS (SageMaker, Athena, S3, RDS, DynamoDB, Lambda, EC2)', 'Top Candidates Will Also Have', 'Knowledge of relational data bases; the knowledge of NoSQL data bases is a definite plus', 'Effective time management skills', ' Fully qualified to perform most programming assignments without close supervision', 'Ability to work independently or as a collaborative team member', 'JOB DUTIES', 'Qualifications', 'Completed coursework or projects in natural language processing', 'Completed coursework in machine learning and/or computational methods in statistics and data miningCompleted coursework or projects in natural language processingCompleted research or class projects in machine learning (classification, regression, unsupervised learning)Knowledge of relational data bases; the knowledge of NoSQL data bases is a definite plusFamiliarity with AWS (SageMaker, Athena, S3, RDS, DynamoDB, Lambda, EC2)Experience with SnowflakeKnowledge of visualization tools like Tableau, MS Power BI, Kibana, etc.Good analytical and problem-solving skills and be detail orientedEffective time management skillsStrong verbal and written communication skillsAbility to work independently or as a collaborative team memberAbility to learn and comply with company policies and proceduresAbility to clearly communicate technical ideas, regardless of the technical capacity of the audiencePassion for technology and an eagerness to contribute to a team-orientated environmentPassion for working in a dynamic environment where digital is still evolving as a core offering', 'Good analytical and problem-solving skills and be detail oriented', 'Ability to learn and comply with company policies and procedures', 'Ability to clearly communicate technical ideas, regardless of the technical capacity of the audience', 'Passion for technology and an eagerness to contribute to a team-orientated environment', 'Proficient in Python and SQL', ' Under the direction of more experienced staff, assists in the development of major system modules and programs', 'Minimum cumulative GPA requirement 3.0/ 4.0 (no rounding)', 'Graduation date between May 2020 through May 2021', ' Evaluates recommended software and/or program changes and their potential impact on the environment and execution results', ' Designs, codes, tests, and debugs programs of varying degrees of complexity', 'BASIC QUALIFICATIONS:', 'Experience with Snowflake', ' May perform integration tasks for in-house developed systems and/or purchased software solutions', ' Improves development and support processes']",Not Applicable,Full-time,Engineering,Construction,2020-11-05 11:32:32
Data Scientist - 100% Remote Available,Wiley Job Network,"Converse, TX",15 hours ago,Be among the first 25 applicants,"['', 'Preferred Requirements', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree."", 'Relocation', 'Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions.', 'Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.', 'Works with IT to research architecture for new products, services, and features.', ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization."", 'Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.', 'Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.', 'Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.', 'Develops algorithms and supporting code such that research efforts are based on the highest quality data.', 'Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required.', 'Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree.4 or more years of related experience and accountability for complex tasks and/or projects required.Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required."", 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.', '4 or more years of related experience and accountability for complex tasks and/or projects required.', ""Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation."", ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization.Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation.Works with IT to research architecture for new products, services, and features.Develops algorithms and supporting code such that research efforts are based on the highest quality data.Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions."", 'available', 'Minimum Requirements', 'Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).', 'PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).', 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).', 'Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.', 'Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).']",Entry level,Full-time,Engineering,Higher Education,2020-11-05 11:32:32
Data Scientist,My3Tech Inc,"Pierre, SD",,N/A,"['', 'Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)', '\xa0', 'Analyze raw data: assessing quality, cleansing, structuring for downstream processing ', 'Qualifications', 'Collaborate with engineering team to bring analytical prototypes to production ', ""Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.) At least 1 - 2 years' of experience in quantitative analytics or data modeling Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms Fluency in a programming language (Python, C,C++, Java, SQL) Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)"", 'Fluency in a programming language (Python, C,C++, Java, SQL) ', 'Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms ', ""The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.\xa0"", ""At least 1 - 2 years' of experience in quantitative analytics or data modeling "", 'Design accurate and scalable prediction algorithms ', 'Analyze raw data: assessing quality, cleansing, structuring for downstream processing Design accurate and scalable prediction algorithms Collaborate with engineering team to bring analytical prototypes to production Generate actionable insights for business improvements', 'Responsibilities', 'Generate actionable insights for business improvements', ""Bachelor's degree or equivalent experience in quantative field (Statistics, Mathematics, Computer Science, Engineering, etc.) ""]",Not Applicable,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist (remote),deepwatch,"Denver, CO",18 hours ago,34 applicants,"['', 'An ability to work successfully across a globally distributed team and geographical boundaries to deliver joint initiatives ', '10 Company Holidays', 'History of diving into data to discover hidden patterns and of conducting error/deviation analysis', 'Gathering and processing data at scale, writing scripts and queries, and building and calling APIs', 'Visualize threat signal data and uncover how bad actors use security vulnerabilities, malware, and patterns to spread across networks and drive analytic development to build libraries for persistent detection ', '401k retirement plan with employer match', ""Bachelor's Degree with an emphasis in Data Science or related field such as Mathematics or Computer Science2+ years-experience with various data analysis and visualization tools AWS/Azure/Google Cloud data engineering experienceProficiency in Python and other programming / scripting languagesExperience with various machine learning techniques and parameters that affect technique/model outputs and performanceDeep understanding of machine learning techniques and algorithms, such as Random Forests, Gradient Boosting, Ridge/Lasso, SVM, time series techniques et. al.Exceptional numerical and statistical ability, with excitement for applying analytics to client challenges and significant experience using analytic / database software and languages such as SAS, SQL, SPSS, R, Python, et. al.Experience with analytics programming languages (Python, Ruby, Shell) and automation tools (Ansible, Chef, Puppet etc.)Exemplified critical thinking and creative problem solving skills Competency with common data science toolkits, such as NumPy, pandas, sparkML, scikitLearn, et. al.Capable of leading and executing on data acquisition, cleansing, and storage for individual initiativesWilling to tackle big problems that have unknown solutions at the outsetStrong oral and written communication skills, including the ability to communicate effectively to non-technical audiences Team player with a passion for coaching colleagues and customers in the areas of data science "", 'Willing to tackle big problems that have unknown solutions at the outset', 'Solving difficult data problems while embracing cyber security challenges with open arms ', 'A highly collaborative environment with very bright minds and inquisitive thinking', 'Competency with common data science toolkits, such as NumPy, pandas, sparkML, scikitLearn, et. al.', 'Work with engineers to develop efficient data analysis and data modeling infrastructure ', 'Company paid Life Insurance, Short Term Disability and Long Term Disability', 'Attractive referral bonus program', 'Significant annual allowance per employee for Professional Development', 'Responsibilities', 'Team player with a passion for coaching colleagues and customers in the areas of data science ', 'Present proposals and results in a clear manner backed by data and coupled with actionable conclusions that drive analytics, content libraries, and automation outcomes ', 'Strong ability to accurately determine cause and effect relationships', 'Description', 'Collaborate with colleagues from Product, Delivery, Content, and Threat Hunting teams ', 'Capable of leading and executing on data acquisition, cleansing, and storage for individual initiatives', 'Career paths and the opportunity to do cool and different things as our growth continues', 'Deep understanding of machine learning techniques and algorithms, such as Random Forests, Gradient Boosting, Ridge/Lasso, SVM, time series techniques et. al.', '2+ years-experience with various data analysis and visualization tools ', 'Exceptional numerical and statistical ability, with excitement for applying analytics to client challenges and significant experience using analytic / database software and languages such as SAS, SQL, SPSS, R, Python, et. al.', 'deepwatch is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, marital status, sexual orientation, gender identity, genetic information, protected veteran status, or any other characteristic protected by law. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.', 'A highly collaborative environment with very bright minds and inquisitive thinkingAwesome benefits - we pay a significant portion of our employees’ medical and dental premiums (100% for the HDHP plan) and a very generous portion for dependentsFSA (medical and dependent) and HSA with employer contributionCompany paid Life Insurance, Short Term Disability and Long Term Disability401k retirement plan with employer matchPaid Time Off (PTO)10 Company HolidaysPaid time off for votingAs a fully remote company, we offer the responsible balancing of your time between work & lifeAll employees are paid a generous mobile phone and home internet allowanceApple productsAttractive referral bonus programCareer paths and the opportunity to do cool and different things as our growth continuesSignificant annual allowance per employee for Professional Development', 'Build models that elevate the customer experience and track value of security outcomes for deepwatch customers over time', 'Understands relevant statistical measures such as mathematical modeling, confidence intervals, significance of error measurements, development and evaluation data sets', 'Required Experience, Skills and Knowledge', 'Paid Time Off (PTO)', 'Experience with various machine learning techniques and parameters that affect technique/model outputs and performance', 'Awesome benefits - we pay a significant portion of our employees’ medical and dental premiums (100% for the HDHP plan) and a very generous portion for dependents', 'deepwatch Offers', 'Ensure data quality and normalization throughout all stages of acquisition and processing ', 'As a fully remote company, we offer the responsible balancing of your time between work & life', 'Requirements', 'Preferred Experience, Skills And Knowledge', 'FSA (medical and dependent) and HSA with employer contribution', 'Ability to develop both experimental and analytical plans for data modeling processes, use of scaling baselines (trends)', 'Who We Are', 'Data Scientist', 'Provide documentation to Threat Hunt, Research and Analyst teams around data analytics and mathematical decisions, with actionable workflows for threat investigation of ML alerts', 'Proficiency in Python and other programming / scripting languages', 'Drive the development of Machine Learning use cases to detect malicious activity in customer environments with regular content updates', 'Equal Opportunity Employer', 'Clean, analyze and select data to achieve goals that create desired security outcomes for deepwatch customers ', 'Experience with analytics programming languages (Python, Ruby, Shell) and automation tools (Ansible, Chef, Puppet etc.)', 'Exemplified critical thinking and creative problem solving skills ', 'Apple products', ""Master's degree or PhD in relevant field(s) such as computer science, mathematics, or data scienceHistory of diving into data to discover hidden patterns and of conducting error/deviation analysisAbility to develop both experimental and analytical plans for data modeling processes, use of scaling baselines (trends)Strong ability to accurately determine cause and effect relationshipsUnderstands relevant statistical measures such as mathematical modeling, confidence intervals, significance of error measurements, development and evaluation data setsAn ability to work successfully across a globally distributed team and geographical boundaries to deliver joint initiatives "", ""Master's degree or PhD in relevant field(s) such as computer science, mathematics, or data science"", ""Bachelor's Degree with an emphasis in Data Science or related field such as Mathematics or Computer Science"", 'Paid time off for voting', 'Solving difficult data problems while embracing cyber security challenges with open arms Gathering and processing data at scale, writing scripts and queries, and building and calling APIsVisualize threat signal data and uncover how bad actors use security vulnerabilities, malware, and patterns to spread across networks and drive analytic development to build libraries for persistent detection Drive the development of Machine Learning use cases to detect malicious activity in customer environments with regular content updatesProvide documentation to Threat Hunt, Research and Analyst teams around data analytics and mathematical decisions, with actionable workflows for threat investigation of ML alertsEnsure data quality and normalization throughout all stages of acquisition and processing Clean, analyze and select data to achieve goals that create desired security outcomes for deepwatch customers Build models that elevate the customer experience and track value of security outcomes for deepwatch customers over timeCollaborate with colleagues from Product, Delivery, Content, and Threat Hunting teams Present proposals and results in a clear manner backed by data and coupled with actionable conclusions that drive analytics, content libraries, and automation outcomes Work with engineers to develop efficient data analysis and data modeling infrastructure ', 'Strong oral and written communication skills, including the ability to communicate effectively to non-technical audiences ', 'AWS/Azure/Google Cloud data engineering experience', 'All employees are paid a generous mobile phone and home internet allowance']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Machine Learning Researcher,Comcast,"Schaumburg, IL",10 hours ago,Be among the first 25 applicants,"['PhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. Strong programming and software skills, with Python experience preferred. Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. ', 'Has excellent interpersonal skills and can communicate effectively. Chart a solid research path given available requirements. Quickly understands entertainment media and its semantic and technical structure. Is innovative and can find unique solutions to problems. Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. Plans, organizes, and time-manages independently. Prioritizes and assesses the implications of decisions. ', 'Preferred Skills', 'Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. ', 'Computer Science, Engineering, Applied Mathematics, or Statistics', 'Strong programming and software skills, with Python experience preferred. ', 'Other duties and responsibilities as assigned. ', 'PhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. ', 'Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. ', 'Research and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. ', 'Prioritizes and assesses the implications of decisions. ', 'Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. ', ""Understand our Operating Principles; make them the guidelines for how you do your jobOwn the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and servicesKnow your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiencesWin as a team - make big things happen by working together and being open to new ideasBe an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joininghuddles, making call backs and helping us elevate opportunities to do better for our customersDrive results and growthRespect and promote inclusion and diversityDo what's right for each other, our customers, investors and our communities"", 'Bachelor’s Degree', 'Consistent exercise of independent judgment and discretion in matters of significance. ', 'Chart a solid research path given available requirements. ', 'Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. ', 'Is innovative and can find unique solutions to problems. ', 'Job Summary:', ""Job Summary:Research and implement new detection capabilities for use within our Media Analysis Framework (MAF). You will rely on your experience in computer vision, signal processing, machine learning, and deep learning to extract insightful metadata from the video. You will create algorithms for multi-modal analysis of video. Additionally, you’ll ensure that your components are well-tested, production-ready, and performant at scale. The position is open in for placement in either Chicago or Washington, DC. We feature an innovative, informal, open atmosphere, and cultivate a start-up culture with the backing of a Fortune 50 company. To better serve our community, we believe the diversity of our team should reflect the diversity of our customers.Employees At All Levels Are Expected ToUnderstand our Operating Principles; make them the guidelines for how you do your jobOwn the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and servicesKnow your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiencesWin as a team - make big things happen by working together and being open to new ideasBe an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joininghuddles, making call backs and helping us elevate opportunities to do better for our customersDrive results and growthRespect and promote inclusion and diversityDo what's right for each other, our customers, investors and our communitiesCore ResponsibilitiesResearch and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. Consistent exercise of independent judgment and discretion in matters of significance. Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. Other duties and responsibilities as assigned. Desired QualificationsPhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. Strong programming and software skills, with Python experience preferred. Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. Preferred SkillsThe preferred candidate will have the following skills and qualities:Has excellent interpersonal skills and can communicate effectively. Chart a solid research path given available requirements. Quickly understands entertainment media and its semantic and technical structure. Is innovative and can find unique solutions to problems. Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. Plans, organizes, and time-manages independently. Prioritizes and assesses the implications of decisions. Job SpecificationBachelor’s DegreeComputer Science, Engineering, Applied Mathematics, or StatisticsGenerally requires 5-8 years related experience.Comcast is an EOE/Veterans/Disabled/LGBT employer"", 'Research and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. Consistent exercise of independent judgment and discretion in matters of significance. Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. Other duties and responsibilities as assigned. ', 'Quickly understands entertainment media and its semantic and technical structure. ', 'Core Responsibilities', 'Has excellent interpersonal skills and can communicate effectively. ', 'Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. ', 'Desired Qualifications', 'Plans, organizes, and time-manages independently. ', 'Drive results and growth', 'Business Unit', 'Generally requires 5-8 years related experience.', 'huddles, making call backs and helping us elevate opportunities to do better for our customers', 'Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. ', 'Employees At All Levels Are Expected To', 'Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences', 'Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services', 'Respect and promote inclusion and diversity', 'The position is open in for placement in either Chicago or Washington, DC.', 'Win as a team - make big things happen by working together and being open to new ideas', 'Job Specification', 'Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. ', 'Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining', 'Understand our Operating Principles; make them the guidelines for how you do your job', 'Bachelor’s DegreeComputer Science, Engineering, Applied Mathematics, or StatisticsGenerally requires 5-8 years related experience.', ""Do what's right for each other, our customers, investors and our communities"", 'Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. ']",Not Applicable,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Health Analytics Data Scientist,Berkeley Research Group LLC,"Phoenix, AZ",21 hours ago,Be among the first 25 applicants,"['', ' Plan and manage of all aspects of small to medium-sized client engagements and discrete segments of larger projects.', 'Responsibilities', ' Manage client relationships and communicate results and work product as appropriate.', ' Keen interest in economic or financial analysis and research.', ' Demonstrate creativity and efficient use of relevant software tools, analytical methods, and computer models to develop solutions.', ' A degree (e.g., BS, BBA, MBA, M.A., M.S., etc.) with a focus in business analytics (accounting, finance, economics, information systems) or equivalent experience.', ' 2-6 years of work experience with a focus on data analytics.', ' Strong verbal and written communication skills.', 'Qualifications', ' Participate in group practice meetings, contribute to business development initiatives and office functions such as staff training and recruiting.', 'BRG is an Equal Employment Opportunity/Affirmative Action Employer. All qualified candidates will receive consideration for employment without regard to race, color, religion, sex, gender identity, sexual orientation, national origin, disability, or protected veteran status.', 'Candidate must be able to submit verification of his/her legal right to work in the United States, without company sponsorship.', ' Proven capability with MS Excel and relational database program(s) (e.g., SAS, SPSS, Stata, MS SQL Server, MS Access). A desire to expand those capabilities is required, as is the ability to train others to use such tools.', ' A degree (e.g., BS, BBA, MBA, M.A., M.S., etc.) with a focus in business analytics (accounting, finance, economics, information systems) or equivalent experience. 2-6 years of work experience with a focus on data analytics. Proven capability with MS Excel and relational database program(s) (e.g., SAS, SPSS, Stata, MS SQL Server, MS Access). A desire to expand those capabilities is required, as is the ability to train others to use such tools. Desire and ability to manage processes and projects. Commitment to producing high-quality analysis and attention to detail. Keen interest in economic or financial analysis and research. Strong verbal and written communication skills. Desire to work within a team environment.', ' Desire to work within a team environment.', 'Overview', ' Delegate assignments to staff, instruct and monitor progress, and review work product for completeness and accuracy.', ' Develop analyses and financial models using transactional data and/or financial data.', ' Desire and ability to manage processes and projects.', ' Commitment to producing high-quality analysis and attention to detail.', ' Plan and manage of all aspects of small to medium-sized client engagements and discrete segments of larger projects. Delegate assignments to staff, instruct and monitor progress, and review work product for completeness and accuracy. Develop analyses and financial models using transactional data and/or financial data. Generate client deliverables and make valuable contributions to expert reports. Manage client relationships and communicate results and work product as appropriate. Demonstrate creativity and efficient use of relevant software tools, analytical methods, and computer models to develop solutions. Participate in group practice meetings, contribute to business development initiatives and office functions such as staff training and recruiting. Prioritize assignments and responsibilities in order to meet goals and deadlines.', ' Generate client deliverables and make valuable contributions to expert reports.', ' Prioritize assignments and responsibilities in order to meet goals and deadlines.']",Entry level,Full-time,Engineering,Management Consulting,2020-11-05 11:32:32
Summer IT Intern,State Auto Insurance,"Columbus, OH",8 hours ago,Be among the first 25 applicants,"['', ' Communicating and Collaborating effectively with cross-functional product teams ', ' Worker Sub-Type ', ' Prototype and build software products and AI/ML algorithms including voice to text translation and sentiment analysis ', ' Prototyping, Developing specifications and implementing various solutions to Customer needs ', ' Present work to internal partners, supervisors and members of senior leadership ', ' Develop data analysis algorithms and processes to analyze behavior patterns of target populations ', ' Writing, UI testing and Debugging code for various Software products ', ' Web Development using various technologies such as React ', ""If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!"", ' Develop user analytics & graph databases to provide operational insights from data relationships ', 'Full Time', ' Prototype and build software products and AI/ML algorithms including voice to text translation and sentiment analysis  Writing, UI testing and Debugging code for various Software products  Prototyping, Developing specifications and implementing various solutions to Customer needs  Communicating and Collaborating effectively with cross-functional product teams  Ability to learn evolving/next generation technical stack across systems  Develop user analytics & graph databases to provide operational insights from data relationships  Develop data analysis algorithms and processes to analyze behavior patterns of target populations  Present work to internal partners, supervisors and members of senior leadership ', 'Qualifications', ' Python Developer  Web Development using various technologies such as React  TensorFlow Developer / Data Scientist ', 'Full Time / Part Time', ' Python Developer ', 'Worker Sub-Type', ' TensorFlow Developer / Data Scientist ', ' / Part Time', 'Summary & Key Responsibilities', 'Minimum Experience / Education', 'Experience/Skillset(s)', 'Key Responsibilities', ' Ability to learn evolving/next generation technical stack across systems ', ""It's fun to work in a company where people truly BELIEVE in what they're doing!"", ""We're committed to bringing passion and customer focus to the business.""]",Internship,Full-time,Education,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist,CVS Health,Greater Boston,22 hours ago,44 applicants,"['', 'Position Summary :', '-  You will monitor and bug fix solutions', '-  3+ years’ experience – Experience with Big Data and Machine Learning in cloud environment (Azure/Databricks experience strongly)', 'MS of PhD in Electrical or Computer Engineering, Computer Science, Physics, Mathematics or related engineering or information sciences discipline and in lieu of a MS, a BS and 4+ years of experience will be considered.', '-  You will provide technical expertise in building and maintaining artificial intelligence product in cloud environment', '-  3+ years’ experience - Computer Science, Programming skills', 'We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer.  We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities', '-  Experience with Natural Language Processing (NLP)', '-  Experience in retail or loyalty programs preferred', '-  You will build scalable solutions as part of artificial intelligence pipeline', '-  You will collaborate with IT/Engineering to ensure proposed solutions are implemented/supported', '-  3+ years’ experience – Expert programming skills in at least two of the following: Python, R, Scala, Spark or Java. Strong preference for Python/Spark/Keras', '-  You will build Machine Learning pipelines and train models', '-  3+ years’ experience - Probability and Statistics', 'Preferred Qualifications :', 'Business Overview :', '-  3+ years’ experience - in model selection and sampling', '-  You will work in code notebooks', '-  Deep knowledge base in Machine Learning and in- depth expertise in applying automated solutions in Decision Optimization/Workflow processes. ', '-  You will build & validate models', '-  3+ years’ experience - Data Modeling and Evaluation', ' ', '-  2+ years’ experience – Building Machine Learning pipeline ( data ingestion, feature engineering, modeling including ensemble methods, predicting, explaining, deploying and diagnosing over fitting )', 'Education :', '-  1+ years’ experience - deep learning and neural nets (strong preference for experience with Keras)', '-  You will monitor & retrain models', 'Required Qualifications :', '-  2+ years’ experience - in applying supervised, unsupervised and semi-supervised learning techniques', 'At CVS Health, we are joined in a common purpose: helping people on their path to better health.  We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.', '-  You will ensure implemented solutions within production meet design requirement']",Mid-Senior level,Full-time,Analyst,Hospital & Health Care,2020-11-05 11:32:32
Data Scientist,Netskope,"Santa Clara, CA",17 hours ago,36 applicants,"['', 'Mining data from primary and secondary sources, then reorganizing the data in a format that can be easily read by either human or machine.', 'Great team player who has a strong desire to change the way people use their data and have a huge impact on a small team', 'Collaborating with programmers, engineers, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance.', 'About This Role', 'Excellent communication and presentation skills', 'Education', 'Data Scientist ', 'Core skills: SQL, R, or Python', 'Experience with Big Data e.g. Hadoop, MapR', ' Mining data from primary and secondary sources, then reorganizing the data in a format that can be easily read by either human or machine. Using statistical tools to interpret data sets, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts. Preparing reports for executive leadership that effectively communicate trends, patterns, and predictions using relevant data. Collaborating with programmers, engineers, and organizational leaders to identify opportunities for process improvements, recommend system modifications, and develop policies for data governance. Creating appropriate documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary. ', 'Working knowledge of NoSQL databases e.g. MongoDB', 'Using statistical tools to interpret data sets, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts.', ' BSCS or equivalent required, MSCS or equivalent strongly preferred', 'Required Skills', 'Responsibilities Include', 'BSCS or equivalent required, MSCS or equivalent strongly preferred', 'Creating appropriate documentation that allows stakeholders to understand the steps of the data analysis process and duplicate or replicate the analysis if necessary.', 'Preparing reports for executive leadership that effectively communicate trends, patterns, and predictions using relevant data.', 'About Netskope', ' Core skills: SQL, R, or Python Working knowledge of NoSQL databases e.g. MongoDB Experience with Big Data e.g. Hadoop, MapR Excellent communication and presentation skills Great team player who has a strong desire to change the way people use their data and have a huge impact on a small team ']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist (remote to start),FootBridge Consulting,"Boston, MA",21 hours ago,102 applicants,"['', ""Experience taking raw data and transforming it into visualization/insights for SME's"", '\xa0', 'Experience with Salesforce.com, Marketing Cloud, and a knowledge of conversion funnel using SFDC', 'Ability to write and run SQL database queries', ""3+ years of experience serving as a Data Scientist/BI DeveloperExperience taking raw data and transforming it into visualization/insights for SME'sExperience with Salesforce.com, Marketing Cloud, and a knowledge of conversion funnel using SFDCExperience with BI tools such as Tableau or Spotfire a mustScripting languages such as Python, R or MATLABAbility to write and run SQL database queriesExperience in data wrangling, data cleaning, and machine learning"", 'The right candidate will possess:', 'Scripting languages such as Python, R or MATLAB', 'For immediate consideration, please send your most recent resume to\xa0msalemi@footbridgeconsulting.com\xa0', 'Data Scientist (remote to start)', 'Experience with BI tools such as Tableau or Spotfire a must', 'Experience in data wrangling, data cleaning, and machine learning', 'Our client in the Boston, MA area is looking to hire a (2) Junior to Mid-Level Data Scientist for a Contract opportunity. The role will start off remotely, and eventually transition back to onsite post COVID.', '3+ years of experience serving as a Data Scientist/BI Developer']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Research Scientist,Amazon,"Cambridge, MA",6 hours ago,Be among the first 25 applicants,"['', ' Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc.', ' Ability to think creatively and solve problems', ' Work with engineers to develop efficient data querying infrastructure for both offline and online use cases', ' The motivation to achieve results in a fast-paced environment.', ' Exceptional level of organization', ' Master’s or PhD in a relevant field', 'Preferred Qualifications', "" PhD or equivalent Master's degree plus 4+ years of research experience in a quantitative filed Experience investigating the feasibility of applying scientific principals and concepts to business problems and products Master’s or PhD in a relevant field 2+ years experience with various data analysis and visualization tools Experience in Perl, Python, or another scripting language; command line usage Experience with various machine learning techniques and parameters that affect their performance"", ' Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc.', 'Company', ' Strong attention to detail', 'Basic Qualifications', 'Description', ' Build and release models that elevate the customer experience and track impact over time', ' Experience in Perl, Python, or another scripting language; command line usage', ' 2+ years experience with various data analysis and visualization tools', ' Comfortable working in a fast paced, highly collaborative, dynamic work environment', ' Experience with various machine learning techniques and parameters that affect their performance', ' Collaborate with colleagues from science, engineering and business backgrounds.', ' Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations', 'You Will', "" PhD or equivalent Master's degree plus 4+ years of research experience in a quantitative filed"", ' Experience investigating the feasibility of applying scientific principals and concepts to business problems and products', ' Clean, analyze and select data to achieve goals', ' Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc. Clean, analyze and select data to achieve goals Build and release models that elevate the customer experience and track impact over time Collaborate with colleagues from science, engineering and business backgrounds. Present proposals and results in a clear manner backed by data and coupled with actionable conclusions Work with engineers to develop efficient data querying infrastructure for both offline and online use cases', ' Present proposals and results in a clear manner backed by data and coupled with actionable conclusions', ' Experience with statistical modelling / machine learning', ' Track record of diving into data to discover hidden patterns and of conducting error/deviation analysis', ' Track record of diving into data to discover hidden patterns and of conducting error/deviation analysis Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. The motivation to achieve results in a fast-paced environment. Experience with statistical modelling / machine learning Strong attention to detail Exceptional level of organization Comfortable working in a fast paced, highly collaborative, dynamic work environment Ability to think creatively and solve problems']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
Data Intelligence Product Analyst/ Data Scientist - Strategy & Growth,Salesforce,"Austin, TX",4 hours ago,Be among the first 25 applicants,"['', 'Posting Statement', 'Curious, creative, opinionated thinker with a talent for detecting patterns and elevating through strategy.', 'Advanced expert in SQL. Experience with Splunk, Python/R, and BI tools is a plus.', 'Contribute to expanding the Salesforce data culture by growing new relationships, hosting learning sessions, integrating or designing new tools, improving team processes, and other lateral activities.', 'What You Will Do', 'Salesforce.com', 'Produce insights (e.g. performance drivers, retention analysis, behavioral personas) to help grow Salesforce Cloud businesses. This requires acquiring, cleaning, structuring data from multiple sources (e.g. Hadoop, Splunk), and analyzing the data using SQL / Python / R.', 'Accommodations ', 'To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.', 'Job Details', 'Lover of math with solid understanding of statistical methods.', 'Thought leader in analytics (4-9 years of experience in product analytics, sales analytics, marketing analytics or similar, as IC or people manager).', 'Laser focused on impact, balancing effort to value, and getting things done.', 'Partner with Senior Leadership (VP+) to understand their business and advise on strategic objectives, product direction, roadmaps, growth goals, retention strategies, etc. Develop and own the relationships with senior stakeholders across the companyProduce insights (e.g. performance drivers, retention analysis, behavioral personas) to help grow Salesforce Cloud businesses. This requires acquiring, cleaning, structuring data from multiple sources (e.g. Hadoop, Splunk), and analyzing the data using SQL / Python / R.When analyses are ready to be productized, own the delivery by working with engineers and data scientists to turn insights into self-service dashboards or data products.Evangelize the insights through storytelling. Create easy-to-consume media that inspires into action anyone from senior execs to fellow analysts.Contribute to expanding the Salesforce data culture by growing new relationships, hosting learning sessions, integrating or designing new tools, improving team processes, and other lateral activities.', 'Who You Are', 'Partner with Senior Leadership (VP+) to understand their business and advise on strategic objectives, product direction, roadmaps, growth goals, retention strategies, etc. Develop and own the relationships with senior stakeholders across the company', 'Accommodations  - ', 'Salesforce.org', 'Charismatic storyteller ready to lead growth conversations with senior leadership.', 'Expert in building relationships and collaborating in matrixed environments.', 'Job Category', 'Department Overview - Data Intelligence', 'Salesfore.com', 'Evangelize the insights through storytelling. Create easy-to-consume media that inspires into action anyone from senior execs to fellow analysts.', 'When analyses are ready to be productized, own the delivery by working with engineers and data scientists to turn insights into self-service dashboards or data products.', 'Thought leader in analytics (4-9 years of experience in product analytics, sales analytics, marketing analytics or similar, as IC or people manager).Laser focused on impact, balancing effort to value, and getting things done.Curious, creative, opinionated thinker with a talent for detecting patterns and elevating through strategy.Charismatic storyteller ready to lead growth conversations with senior leadership.Expert in building relationships and collaborating in matrixed environments.Advanced expert in SQL. Experience with Splunk, Python/R, and BI tools is a plus.Lover of math with solid understanding of statistical methods.Enterprise software geek. Passion for Salesforce product is a plus!', 'Enterprise software geek. Passion for Salesforce product is a plus!']",Not Applicable,Full-time,Business Development,Computer Software,2020-11-05 11:32:32
"Machine Learning Engineer, Computer Vision",Optello,"Seattle, WA",2 hours ago,Be among the first 25 applicants,"['', 'Salary:', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : BB7-1608646 -- in the email subject line for your application to be considered.***', 'Optello is proud to be an Equal Opportunity Employer', 'Masters degree and/or PhD in computer science or related fieldExperience developing practical ML solutions (preferably within the AI domain)Strong knowledge of Algorithm DevelopmentAbility to take ML models into productionKnowledge of OCR, Test Processing, Document verification/processing or related AI technologies is highly desiredBONUS: Experience with AWS is highly preferred', ' Certification / educational reimbursements', ' 100% work from home!', ' Tons of room for upward career growth', ' 401(k) and much more!', 'Ability to take ML models into production', 'Knowledge of OCR, Test Processing, Document verification/processing or related AI technologies is highly desired', ' Industry Leading AI Software', 'Masters degree and/or PhD in computer science or related field', ' Talented Technical Team', ' Medical, Dental, Vision', 'Experience developing practical ML solutions (preferably within the AI domain)', ' Industry Leading AI Software Talented Technical Team Tons of room for upward career growth', 'Develop, test, and optimize ML algorithms', 'Location:', 'Build, integrate and extend code for prototype models to be put into production', 'You will be a key member of our development team, producing high-performance computer vision products for document verification, text segmentation and related OCR solutions', 'Position:', ' Competitive salaries (DOE) 100% work from home! Bonuses Vacation / PTO Certification / educational reimbursements Medical, Dental, Vision 401(k) and much more!', ' Bonuses', 'You will be a key member of our development team, producing high-performance computer vision products for document verification, text segmentation and related OCR solutionsDevelop, test, and optimize ML algorithmsBuild, integrate and extend code for prototype models to be put into production', 'Email Your Resume In Word To', 'Strong knowledge of Algorithm Development', ' Competitive salaries (DOE)', 'BONUS: Experience with AWS is highly preferred', ' Vacation / PTO', 'Your Right to Work', 'AND SALARY']",Entry level,Full-time,Information Technology,Construction,2020-11-05 11:32:32
Machine Learning Engineer - Data Science,Systems & Technology Research,"Arlington, VA",19 hours ago,Be among the first 25 applicants,"['', 'A U.S. citizen and have ability to obtain and maintain a security clearance', 'Motivated collaborator who’s comfortable communicating to both technical and non-technical audiences', 'Track record of developing, implementing, and evaluating statistical algorithms against real datasets', 'Previous experience (internships and academic work included) working with complex datasets and building statistical, machine learning, or deep learning models', 'Experience working with large datasets and familiarity with big data infrastructure, such as AWS, Hadoop, Spark, Dask, or MapReduce', 'Understanding of and experience with statistical and machine learning techniques', 'About the Team', 'Description', 'Degree in a scientific field such as Computer Science, Math, Statistics, Data Science, or Physics', ' MS or PhD in a scientific field such as Computer Science, Statistics, Mathematics, or Physics Track record of developing, implementing, and evaluating statistical algorithms against real datasets Specialized expertise in a data-rich field such as time-series analysis, graph analytics, geospatial analysis, image processing, or Bayesian programming Experience with one or more deep learning frameworks such as PyTorch or Tensorflow Experience working with large datasets and familiarity with big data infrastructure, such as AWS, Hadoop, Spark, Dask, or MapReduce Active TS or TS/SCI security clearance ', 'Active TS or TS/SCI security clearance', 'Experience with one or more deep learning frameworks such as PyTorch or Tensorflow', 'The Role', 'Machine Learning Engineer – Data Science', ' Degree in a scientific field such as Computer Science, Math, Statistics, Data Science, or Physics Understanding of and experience with statistical and machine learning techniques Proficiency with a one or more programming language such as Python, MATLAB, Java, or C++ Previous experience (internships and academic work included) working with complex datasets and building statistical, machine learning, or deep learning models Motivated collaborator who’s comfortable communicating to both technical and non-technical audiences A U.S. citizen and have ability to obtain and maintain a security clearance ', 'Specialized expertise in a data-rich field such as time-series analysis, graph analytics, geospatial analysis, image processing, or Bayesian programming', 'Requirements', 'Even Better', 'Who You Are', 'MS or PhD in a scientific field such as Computer Science, Statistics, Mathematics, or Physics', 'Proficiency with a one or more programming language such as Python, MATLAB, Java, or C++']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist - Sand Lake,N/A,"Sand Lake, FL",13 hours ago,Be among the first 25 applicants,[],Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Principal Data Scientist,Crossix Solutions,"New York, NY",10 hours ago,Be among the first 25 applicants,"['', 'Have a curiosity to figure out new problems', 'Enjoy having clear ownership of a goal even if the path to get there is not entirely clear', 'Strong organizational, management and leadership skills', ""What You've Done"", 'Apply machine learning, data mining, and statistical analysis techniques to large health data sets to build new products and methodologies', '10+ years of hands-on data science experience, demonstrating increasing responsibility and impact over time, including experience leading projectsExtensive and in-depth knowledge and professional experience in machine learning and statisticsHighly proficient in Python and SQL; experience working with AWS preferredStrong organizational, management and leadership skillsStrong communication skills and agility to work across internal teams', 'Flexible PTOAllocations for continuous learning & developmentHealth & wellness programs', 'Master core parts of the Crossix technology platform. Technologies include Spark, SQL, Python, R, AWS, and proprietary data mining software', '10+ years of hands-on data science experience, demonstrating increasing responsibility and impact over time, including experience leading projects', 'Flexible PTO', 'Allocations for continuous learning & development', 'Own responsibilities related to project and people leadership, including leading data scientists and analysts', 'Have a desire and preference for working in a fast-paced, entrepreneurial environment', 'Health & wellness programs', 'Explore and find meaning in high volumes of data to evaluate data quality and extract actionable insights that will help drive business decisions; execute data querying, data cleansing, and experiment design', 'Are humble and truly think about the success of the group before your own contribution', ""What You'll Do"", 'Highly proficient in Python and SQL; experience working with AWS preferred', 'Apply machine learning, data mining, and statistical analysis techniques to large health data sets to build new products and methodologiesOwn responsibilities related to project and people leadership, including leading data scientists and analystsCollaborate closely with a team of data scientists, product managers, and executives to discover and deliver product offerings from prototype to massive scaleExplore and find meaning in high volumes of data to evaluate data quality and extract actionable insights that will help drive business decisions; execute data querying, data cleansing, and experiment designRapidly build prototype product solutions, communicate findings, and iterateDraw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solvedWork with product and engineering teams to improve and implement methods and featuresMaster core parts of the Crossix technology platform. Technologies include Spark, SQL, Python, R, AWS, and proprietary data mining software', 'Are comfortable challenging existing norms, thinking and teammates, always doing so respectfully', 'Who You Are', 'Perks & Benefits', 'Collaborate closely with a team of data scientists, product managers, and executives to discover and deliver product offerings from prototype to massive scale', 'Rapidly build prototype product solutions, communicate findings, and iterate', 'Draw from prior experience and technical expertise to identify product improvements and inform testing plans; break overall objectives down into underlying problems that can be prioritized and solved', 'Work with product and engineering teams to improve and implement methods and features', 'Extensive and in-depth knowledge and professional experience in machine learning and statistics', 'Strong communication skills and agility to work across internal teams', 'Have a desire and preference for working in a fast-paced, entrepreneurial environmentEnjoy having clear ownership of a goal even if the path to get there is not entirely clearHave a curiosity to figure out new problemsAre humble and truly think about the success of the group before your own contributionAre comfortable challenging existing norms, thinking and teammates, always doing so respectfully']",Not Applicable,Full-time,Management,Computer Software,2020-11-05 11:32:32
Data Scientist,Booz Allen Hamilton,"Annapolis Junction, MD",7 hours ago,34 applicants,"['', 'Experience with performing behavioral analysis and anomaly detection on data sets, including identifying true versus false and positives versus negatives', 'Job Number: R0090813', 'Build Your Career', 'Ability to work both independently and as a team member', 'Possession of excellent analytical, data mining, and problem-solving skills', 'BA or BS degree', 'MS degree', 'Experience with the transition of a research capability to an operational product', 'TS/SCI clearance with a polygraph required', 'You Have', 'Experience with using Python to perform data analysis, mining, and data visualization', 'The Challenge', 'Ability to author complex documents describing and visualizing analytical results', '2+ years of experience in a professional work environment using data science tools', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', 'Experience with SIGINT or Cybersecurity operations', 'Possession of excellent oral and written communication skills', 'Nice If You Have', 'participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunkchange the world with the Data Science Bowl—the world’s premier data science for social good competitionparticipate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Clearance', 'Experience with Netflow', 'change the world with the Data Science Bowl—the world’s premier data science for social good competition']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Principal Data Scientist,Tapjoy,"San Francisco, CA",11 hours ago,Be among the first 25 applicants,"['', 'Constantly experiment and improve machine learning models for the recommendation/ad optimization system ', 'Solid Python programming skills', 'Core Competencies', 'Work with the product/engineering team to implement, test and deploy the solution on Google Cloud Platform', 'Domain and/or marketplace knowledge', 'Responsibilities', 'Senior level understanding of Algorithms, Data Structures, and Machine Learning/Data Mining ', ' Build a data/stats-driven ad machine learning models, working closely with the product team  Constantly experiment and improve machine learning models for the recommendation/ad optimization system  Invent and analyze big data for given business cases and help implement them in production  Work with the product/engineering team to implement, test and deploy the solution on Google Cloud Platform ', 'Invent and analyze big data for given business cases and help implement them in production ', 'Experience with Hadoop/Hbase/Pig or PySpark is a plus', 'Must have hands-on Machine-learning related industry project experience.', 'Understanding of various ad optimization algorithms (CTR prediction, eCPM optimization, user targeting and segmentation, RTB and real-time optimization) is a plus ', 'Motivated to test at billions scaled data and follow up machine learning models in product', 'Understanding of RDBMS, SQL and NoSQL alternatives ', 'Ability to work in a fast paced, test-driven collaborative and iterative programming environment ', 'Position Title: ', 'Great communication about complex algorithmic works as easy-to-understand story telling', 'Build a data/stats-driven ad machine learning models, working closely with the product team ', 'Requirements', 'Passionate about machine learning and big data', ' Domain and/or marketplace knowledge Understanding of various ad optimization algorithms (CTR prediction, eCPM optimization, user targeting and segmentation, RTB and real-time optimization) is a plus  Experience with Hadoop/Hbase/Pig or PySpark is a plus ', 'Bonus', 'Ph. D in Computer Science or Statistics, or 5 years or more of similar working experience in the technical field.', ' Passionate about machine learning and big data Great communication about complex algorithmic works as easy-to-understand story telling Motivated to test at billions scaled data and follow up machine learning models in product ', 'Understanding of major recommendation algorithms (Collaborative Filtering, Matrix factorization, Gradient Boosting, etc.) ', ' Ph. D in Computer Science or Statistics, or 5 years or more of similar working experience in the technical field. Must have hands-on Machine-learning related industry project experience. Solid Python programming skills Ability to work in a fast paced, test-driven collaborative and iterative programming environment  Understanding of major recommendation algorithms (Collaborative Filtering, Matrix factorization, Gradient Boosting, etc.)  Senior level understanding of Algorithms, Data Structures, and Machine Learning/Data Mining  Understanding of RDBMS, SQL and NoSQL alternatives  ']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Data Scientist - Shop Recommendations,Stitch Fix,"San Francisco, CA",18 hours ago,62 applicants,"['', 'We believe in autonomy & taking initiative', 'We have a smart, experienced leadership team that wants to do it right & is open to new ideas', 'We are a group of people who are bright, kind and motivated by challenges. You can be your authentic self here, and are empowered to encourage others to do the same! ', 'We take what we do seriously. We don’t take ourselves seriously', 'About The Team', 'Solve problems related to discovering user preferences efficiently and delivering relevant rankings rapidly', 'We’re Excited About You Because…', 'Collaborate with multiple teams and functions', 'Glue together disparate production systems to make your model work in real-time applications', 'You have a degree in a quantitative field such as Computer Science, Statistics, Physics or a related field.', 'We are committed to our clients and connected through our vision of “Transforming the way people find what they love”', 'We offer competitive compensation packages and comprehensive health benefits', 'You possess a solid understanding of ML & engineering and want to grow even deeper in the field', 'We are a technologically and data-driven business', 'You are innovative and inspired to take on new challenges and you do not shy away from potential failure', ' Address machine learning problems around recommendation engines with multi-modal feedback, and with trends changing temporally and spatially Solve problems related to discovering user preferences efficiently and delivering relevant rankings rapidly Experiment and build new algorithmic capabilities from the ground up Glue together disparate production systems to make your model work in real-time applications Collaborate with multiple teams and functions ', ' You have production machine learning experience and are proficient in deploying apps in Python You have a degree in a quantitative field such as Computer Science, Statistics, Physics or a related field. You have strong cross-functional, communication skills that help simplify and move complex problems forward with business partners  You are innovative and inspired to take on new challenges and you do not shy away from potential failure You possess a solid understanding of ML & engineering and want to grow even deeper in the field You are excited to expand your knowledge of Recommendation Systems You think about ethics in AI, the impact of machine learning on society, and want to bring that to bear in our work here ', 'About Stitch Fix', ' We are a group of people who are bright, kind and motivated by challenges. You can be your authentic self here, and are empowered to encourage others to do the same!  We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation We are a technologically and data-driven business We are committed to our clients and connected through our vision of “Transforming the way people find what they love” We love solving problems, thinking creatively and trying new things We believe in autonomy & taking initiative We are challenged, developed, and have meaningful impact We take what we do seriously. We don’t take ourselves seriously We have a smart, experienced leadership team that wants to do it right & is open to new ideas We offer competitive compensation packages and comprehensive health benefits You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day ', ""Why you'll love working at Stitch Fix..."", ""You're Excited About This Opportunity Because You Will…"", 'About The Role', ""Please Review Stitch Fix's Recruiting Privacy Policy Here"", 'Address machine learning problems around recommendation engines with multi-modal feedback, and with trends changing temporally and spatially', 'We love solving problems, thinking creatively and trying new things', 'You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day', 'You have strong cross-functional, communication skills that help simplify and move complex problems forward with business partners ', 'You are excited to expand your knowledge of Recommendation Systems', 'We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation', 'We are challenged, developed, and have meaningful impact', 'You have production machine learning experience and are proficient in deploying apps in Python', 'You think about ethics in AI, the impact of machine learning on society, and want to bring that to bear in our work here', 'Experiment and build new algorithmic capabilities from the ground up']",Mid-Senior level,Full-time,Research,Apparel & Fashion,2020-11-05 11:32:32
Data Scientist - Clinical Supply Chain,GSK,"Zebulon, NC",1 hour ago,Be among the first 25 applicants,"['', 'Develop strong relationships with key functional stakeholders', 'Experience with Machine Learning and/or Artificial Intelligence', ""Bachelor's degree from an accredited institution in Data Science, Mathematics, Computer Science, Computational Biology, Computational Chemistry, or Engineering."", 'Experience with developing solutions following a defined Software Development Life Cycle', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.', 'As GSK Focuses On Our Values And Expectations And a Culture Of Innovation, Performance, And Trust, The Successful Candidate Will Demonstrate The Following Capabilities', 'Why GSK?', 'Develop project plans with flexibility to account for variable business resource availability', 'Site Name:', 'Preferred Qualifications', 'Basic Qualifications', 'Continuously looking for opportunities to learn, build skills and share learning.', 'Experience and comprehensive understanding of data collection, transformation and presentation processes.', 'Analyze disparate data sources, producing insights to uncover opportunities', 'Building strong relationships and collaboration, honest and open conversations.', 'Clearly document technical and business requirements from stakeholders using Agile methods', 'Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.', 'Experience using data visualization tools (eg Spotfire, Tableau, Microsoft Power BI, etc)', 'Experience with pharmaceutical clinical supply chain', 'Develop value-based proposals suitable for senior stakeholders', 'Experience with Machine Learning and/or Artificial IntelligenceExperience with pharmaceutical clinical supply chainExperience with GxP regulationsExperience with developing solutions following a defined Software Development Life Cycle', 'Analyze disparate data sources, producing insights to uncover opportunitiesQuickly create tactical solutions for pilots/POC’s to verify value and develop strong business casesAssist clinical supply chain teams with process mapping, data extraction/modeling/visualization for quality investigation and robustness improvement initiativesDevelop value-based proposals suitable for senior stakeholdersDevelop project plans with flexibility to account for variable business resource availabilityDevelop strong relationships with key functional stakeholdersClearly document technical and business requirements from stakeholders using Agile methodsDevelop solution designs and manage technical change control projectsManage automated data extractions and intermediate transformation platformsEffectively work with IT professionals to deliver industrialized analytic solutions', 'Experience with GxP regulations', 'Posted Date:', 'Develop solution designs and manage technical change control projects', 'Operating at pace and agile decision-making – using evidence and applying judgement to balance pace, rigour and risk.Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.Continuously looking for opportunities to learn, build skills and share learning.Sustaining energy and well-beingBuilding strong relationships and collaboration, honest and open conversations.Budgeting and cost-consciousness', 'Manage automated data extractions and intermediate transformation platforms', 'Assist clinical supply chain teams with process mapping, data extraction/modeling/visualization for quality investigation and robustness improvement initiatives', '>3 years experience with data visualization tools.', 'Effectively work with IT professionals to deliver industrialized analytic solutions', 'Five (5) years of experience in a relevant business environment, including three (3) years of experience developing complex data models & visualizations.', 'Budgeting and cost-consciousness', 'Why you?', 'Quickly create tactical solutions for pilots/POC’s to verify value and develop strong business cases', 'Experience using statistical computer languages (R, Python, Java, SQL, MATLAB, etc.) to manipulate data and draw insights from large data sets.', 'Sustaining energy and well-being', ""Bachelor's degree from an accredited institution in Data Science, Mathematics, Computer Science, Computational Biology, Computational Chemistry, or Engineering.Five (5) years of experience in a relevant business environment, including three (3) years of experience developing complex data models & visualizations.Experience and comprehensive understanding of data collection, transformation and presentation processes.>3 years experience with data transformation tools.>3 years experience with data visualization tools.Experience with application design, testing and deploymentExperience using statistical computer languages (R, Python, Java, SQL, MATLAB, etc.) to manipulate data and draw insights from large data sets.Experience using data visualization tools (eg Spotfire, Tableau, Microsoft Power BI, etc)"", '>3 years experience with data transformation tools.', 'These Responsibilities Include Some Of The Following', 'Experience with application design, testing and deployment']",Not Applicable,Full-time,Research,Pharmaceuticals,2020-11-05 11:32:32
Data Scientist,GoHealth,"Chicago, IL",4 hours ago,195 applicants,"['', 'current and future', '2+ years of experience demonstrating trajectory of professional growth in software engineering, data science, or data engineering', 'Frequently cited statistics show that women and members of underrepresented groups apply to jobs only if they meet 100% of the qualifications. GoHealth encourages you to break that statistic and to apply. No one ever meets 100% of the qualifications. We look forward to your application. ', 'Medical, dental, vision, and life insurance benefits', ' Open vacation policy because work life balance is important 401k program with company match Employee Stock Purchase Program Medical, dental, vision, and life insurance benefits Paid maternity and paternity leave Professional growth opportunities Generous employee referral bonuses Employee Resource Groups Work from Home Stipend GoHealth is an Equal Opportunity Employer ', 'Benefits And Perks', 'Expertise in applying common machine learning algorithms such as Linear Regression, Random Forests, XGBoost.', 'Lead quantitative analyses with product management, your team, and data engineers in solving problems', 'Present information in front of large groups of users', 'Proficient in Python and related libraries, such as Pandas, Numpy, Scikit-Learn, TensorFlow, Pytorch', 'Responsibilities', 'Stay current with leading edge systems, methods, and best practices for data science and analytics; and introduce technology and process changes across the organization', 'Work from Home Stipend', ""Find ways to improve how the team operates and aligns with GoHealth's goals."", 'Employee Resource Groups', '401k program with company match', 'Generous employee referral bonuses', 'Experience working with Scrum and other Agile methodologies, and Version control systems such as Git or Bitbucket', "" Lead quantitative analyses with product management, your team, and data engineers in solving problems Present information in front of large groups of users Find new ways to combine data that do not naturally mesh together Stay current with leading edge systems, methods, and best practices for data science and analytics; and introduce technology and process changes across the organization Improve the collaboration around actual performance and forecasts to directly help our decisions and actions Find ways to improve how the team operates and aligns with GoHealth's goals. "", 'Find new ways to combine data that do not naturally mesh together', 'Skills And Experience', 'Paid maternity and paternity leave', ""Master's in Statistics, Mathematics, Computer Science, or related quantitative field"", 'Experience deploying real-time prediction models.', 'Employee Stock Purchase Program', ' the unprecedented situation of COVID-19, GoHealth has decided to protect our ', 'Open vacation policy because work life balance is important', "" Master's in Statistics, Mathematics, Computer Science, or related quantitative field 2+ years of experience demonstrating trajectory of professional growth in software engineering, data science, or data engineering Proficient in Python and related libraries, such as Pandas, Numpy, Scikit-Learn, TensorFlow, Pytorch Expertise in applying common machine learning algorithms such as Linear Regression, Random Forests, XGBoost. Experience deploying real-time prediction models. Experience working with Scrum and other Agile methodologies, and Version control systems such as Git or Bitbucket "", 'Improve the collaboration around actual performance and forecasts to directly help our decisions and actions', 'Due to', "" employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities’ and the CDC."", 'GoHealth is an Equal Opportunity Employer', 'Professional growth opportunities']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Staff Data Scientist,ServiceNow,"Chicago, IL",9 hours ago,Be among the first 25 applicants,"['', 'Unstructured data (utterances, descriptions, documents, …)', 'Company', 'Collaborate day-to-day with an energetic team of like-minded data scientists, developers, product managers and quality engineers.Master new functional areas and take ownership of customer-critical features', 'Mentor and help grow the data science team', 'Bring intelligence to customer workflows by leveraging their individual data -', 'Strong background in statistics, probability, and machine learning', 'Solid software development skills and understanding of computer science fundamentalsStrong proficiency with Python scientific stack (scikit-learn, pandas, numpy, …)Experience with neural network-based NLP technologies (Transformers, BERT, etc.) desiredProficient in Java, SQL, source code control systems (git), and basic UNIX utilitiesStrong educational background (M.S.) in a quantitative discipline (Ph.D. preferred)', 'Structured data (workflow state evolution, database tables)Unstructured data (utterances, descriptions, documents, …)Adapting to their unique and complex workflowsAt Scale: 7000+ customers with a wide range of data volumes', 'Strong educational background (M.S.) in a quantitative discipline (Ph.D. preferred)', 'Experience with neural network-based NLP technologies (Transformers, BERT, etc.) desired', 'Co-pilot the expansion of machine learning into new products with our product management, internal operations teams and development teams', 'Providing technical leadership to data science teams', 'In order to be successful in this role, we need someone who has:', 'Experience evaluating and developing new machine learning algorithms', 'Solid software development skills and understanding of computer science fundamentals', 'Master new functional areas and take ownership of customer-critical features', 'Team ', 'At Scale: 7000+ customers with a wide range of data volumes', 'Staff Data ScientistKirkland, WA, Boston, Ma, Chicago, IL, Bay Area, Ca', 'Demonstrated ability to deploy machine learning solutionsProven track record solving industrial problems with dataExperience evaluating and developing new machine learning algorithmsProviding technical leadership to data science teams', 'Excellent written and oral communication skills', 'Role ', 'Ability to explain models in simple terms to a broader audience', 'Structured data (workflow state evolution, database tables)', 'Adapting to their unique and complex workflows', 'Collaborate day-to-day with an energetic team of like-minded data scientists, developers, product managers and quality engineers.', 'Strong proficiency with Python scientific stack (scikit-learn, pandas, numpy, …)', 'Demonstrated ability to deploy machine learning solutions', 'Proficient in Java, SQL, source code control systems (git), and basic UNIX utilities', 'In This Role, You Will', '6+ years’ experience in a commercial setting:', 'Proven track record solving industrial problems with data']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist, CX Understanding",Robinhood,"Menlo Park, CA",6 hours ago,Be among the first 25 applicants,"['', 'Experience with machine learning techniques and advanced analytics (e.g. regression, classification, time series, econometrics, causal inference, mathematical optimization, text analytics)', 'Executing our experimentation strategy (the hypothesize - test - validate cycle), extracting actionable insights from data, proposing and designing improvements from first principles', 'About The Company', 'Proficiency in Python or R', 'Experience with A/B testing, executing product experimentation strategies', '3+ years of experience as a data scientist focusing on building data solutions and/or machine learning products', 'Your Day-to-day Will Involve', ' Executing our experimentation strategy (the hypothesize - test - validate cycle), extracting actionable insights from data, proposing and designing improvements from first principles Using analytical methodologies to identify customer pain points and empowering data-driven decision making. Demonstrating problem solving skills with a can-do attitude Data sanitization and hygiene; noise and anomaly detection Collaborating with cross-functional teams; informing our stakeholders by articulating our insights and storytelling with data ', ' Experience collaborating with user researchers and designers Experience with data visualization libraries Experience with common ML/NLP libraries, like NLTK, TensorFlow, Keras ', 'Collaborating with cross-functional teams; informing our stakeholders by articulating our insights and storytelling with data', 'Using analytical methodologies to identify customer pain points and empowering data-driven decision making. Demonstrating problem solving skills with a can-do attitude', 'Passion for working and learning in a fast-growing company', 'Masters or PhD in a quantitative field such as mathematics, statistics, operations research and engineering', 'Experience working with very large datasets that reflect real life problems such as noisy, highly imbalanced datasets', 'Data sanitization and hygiene; noise and anomaly detection', 'About The Role', 'Experience with common ML/NLP libraries, like NLTK, TensorFlow, Keras', 'Experience with data visualization libraries', 'Experience collaborating with user researchers and designers', 'Great communication skills and ability to articulate how insights map to solutions and action items', 'Some Things We Consider Critical For This Role', ' Masters or PhD in a quantitative field such as mathematics, statistics, operations research and engineering 3+ years of experience as a data scientist focusing on building data solutions and/or machine learning products Experience with A/B testing, executing product experimentation strategies Experience with machine learning techniques and advanced analytics (e.g. regression, classification, time series, econometrics, causal inference, mathematical optimization, text analytics) Experience working with very large datasets that reflect real life problems such as noisy, highly imbalanced datasets Proficiency in Python or R Great communication skills and ability to articulate how insights map to solutions and action items Passion for working and learning in a fast-growing company ', 'Bonus Points']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Scientist,LexisNexis Risk Solutions,"New Providence, NJ",60 minutes ago,Be among the first 25 applicants,"['', 'Creates new data collection frameworks for structured      and unstructured data ', 'Solves complex problems; takes a broad perspective to      identify innovative solutions ', 'Develops and maintains infrastructure systems that      connect internal data sets; ', 'New Providence, NJ', 'New Providence, NJ ', 'XpertHR is part of RELX Group, a world-leading provider of information and analytics for professional and business customers. RELX Group is one of the 30 biggest listed companies in the UK and one of the 500 biggest companies in the world. The Group serves customers in more than 180 countries and has offices in some 40 countries. It employs around 30,000 people. ', '\xa0Works independently, with guidance in only the      most complex situations ', 'Recognized expert within the function Requires      specialized depth and/or breadth of expertise ', '\xa0Trains/mentors junior staff ', 'You will be joining a small data science team, providing critical input to the development of a major new product launch.  \xa0Working within a friendly mixed team of data scientists, product, UX and developers you will use your skills to develop and field NLP-led technologies/products to address a critical challenge facing HR teams in organizations across the US and the world. ', 'Serves as an expert of own discipline to clients', 'XpertHR ', 'The role ', ' Recognized expert within the function Requires      specialized depth and/or breadth of expertise  Interprets internal or external business issues and      recommends best practices  Solves complex problems; takes a broad perspective to      identify innovative solutions  \xa0Works independently, with guidance in only the      most complex situations  \xa0Trains/mentors junior staff  Serves as an expert of own discipline to clients', 'Applies and integrates statistical, mathematical,      predictive modeling and business analysis skills to manage and manipulate      complex high volume data from a variety of sources ', 'XpertHR', 'Sr. Data Scientist ', ' 5 years’ experience  BS in Computer Science, Mathematics, Statistics or      equivalent experience  ', 'Interprets internal or external business issues and      recommends best practices ', 'Qualifications: ', ' ', ' Applies and integrates statistical, mathematical,      predictive modeling and business analysis skills to manage and manipulate      complex high volume data from a variety of sources  Develops and maintains infrastructure systems that      connect internal data sets;  Creates new data collection frameworks for structured      and unstructured data  ', 'Technical Skills: ', 'BS in Computer Science, Mathematics, Statistics or      equivalent experience ', '5 years’ experience ', 'Sr. Data Scientist', 'Responsibilities: ', 'XpertHR is the most comprehensive source of employment law, HR good practice and benchmarking information available, providing solutions and expertise for employers in the UK, USA and the Netherlands. Increasingly the challenges and opportunities facing HR practitioners involve the mastery of data, creating an opportunity for data scientists work with our development teams to build successful data-led products in this exciting area. ']",Mid-Senior level,Full-time,Product Management,Information Technology and Services,2020-11-05 11:32:32
Lead Data Scientist,Brunel,"Houston, TX",2 hours ago,Be among the first 25 applicants,"['', 'Providing technical leadership to other data scientists on the product team. ', 'Masters or Ph.D degree in quantitative field like Statistics, Computer Science, Engineering, Mathematics or related field required.  Advanced degree is a strong plus. ', 'Relevant Cloud Certifications (i.e. Certified AWS Machine Learning or Data Analytics Specialty) a plus. ', 'Collaborating with model developers to implement and deploy scalable solutions. ', 'Experience with coaching and mentoring technical team members. Evidence of well-developed written and verbal communications skills. Ability to communicate technical contents to non-technical audience. ', 'Responsibilities:', '\xa0 ', 'What We Offer:', 'Conducting advanced statistical analysis to provide actionable insights, identify trends, and measure performance. ', '\xa0', 'Attitude to thrive in a fun, fast-paced start-up like environment. ', '10+ years’ experience in a data science role with emphasis on solving large-scale industrial size problems. ', 'Developing the data science team’s approach and methods to be used to solve specific business problems. ', 'Deep knowledge of machine learning, statistics, optimization or related field as evident through a tertiary higher education degree and/or several years of industry experience. ', 'Understanding business problems and designing end-to-end analytics use cases. Developing the data science team’s approach and methods to be used to solve specific business problems. Developing complex models and algorithms that drive innovation throughout the organization. This may include improving on-time performance, network planning, etc., Conducting advanced statistical analysis to provide actionable insights, identify trends, and measure performance. Providing technical leadership to other data scientists on the product team. Collaborating with model developers to implement and deploy scalable solutions. Providing thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders. Collaborating with product software teams to ensure model functionality using cloud solutions and monitoring the quality and effectiveness of the models in operations. Providing thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders. ', 'Brunel has a reputation for working with some of the best in the business. That’s what we continually strive for. Over 45 years, we’ve created a global network of interesting clients and talented individuals working together through a vast array of services. Join us today.', 'We’re currently hiring an experienced Lead Data Scientist to join our client’s new team within their organization. The Lead Data Scientist will be critical in leading the successful development and implementation of machine-learning and model-based digital solutions and products, as model based decision making is at the heart of the Digital Factory solutions. ', 'Requirements: ', 'Understanding business problems and designing end-to-end analytics use cases. ', 'About Us:', '10+ years’ experience in a data science role with emphasis on solving large-scale industrial size problems. Masters or Ph.D degree in quantitative field like Statistics, Computer Science, Engineering, Mathematics or related field required.  Advanced degree is a strong plus. Deep knowledge of machine learning, statistics, optimization or related field as evident through a tertiary higher education degree and/or several years of industry experience. Experience leading data science teams. Experience working with large data sets, time series data, simulation/ optimization and distributed computing tools. Experience in working with large databases, relational databases (SQL), and distributed systems (Hadoop, Hive), and cloud analytic architectures. Experience Proficiency in R, Python, C++, Java and/or SAS; additional knowledge of other statistical software (SPSS, RapidMiner, etc.) is helpful. Relevant Cloud Certifications (i.e. Certified AWS Machine Learning or Data Analytics Specialty) a plus. Advanced knowledge of statistical techniques, data mining, machine learning (regression, decision trees, clustering, random forests, generalized linear models, etc.) Excellent scientific computing skills, including creativity in the design and development of efficient algorithms. Experience or interest in working in a team environment, with ability to manage competing deadlines. Experience with coaching and mentoring technical team members. Evidence of well-developed written and verbal communications skills. Ability to communicate technical contents to non-technical audience. Attitude to thrive in a fun, fast-paced start-up like environment. ', 'Developing complex models and algorithms that drive innovation throughout the organization. This may include improving on-time performance, network planning, etc., ', 'Providing thought leadership by researching best practices, conducting experiments, and collaborating with industry leaders. ', 'Excellent scientific computing skills, including creativity in the design and development of efficient algorithms. ', 'Experience Proficiency in R, Python, C++, Java and/or SAS; additional knowledge of other statistical software (SPSS, RapidMiner, etc.) is helpful. ', 'Experience or interest in working in a team environment, with ability to manage competing deadlines. ', 'What We Offer: ', 'Advanced knowledge of statistical techniques, data mining, machine learning (regression, decision trees, clustering, random forests, generalized linear models, etc.) ', 'Experience in working with large databases, relational databases (SQL), and distributed systems (Hadoop, Hive), and cloud analytic architectures. ', 'Experience working with large data sets, time series data, simulation/ optimization and distributed computing tools. ', 'About Us: ', 'Experience leading data science teams. ', 'Responsibilities: ', 'Why work with Brunel? We are proud to offer exciting career opportunities from over 100 offices globally in 42 countries. Advancing your career takes time and effort – let us match you to your ideal position. ', 'Collaborating with product software teams to ensure model functionality using cloud solutions and monitoring the quality and effectiveness of the models in operations. ']",Mid-Senior level,Full-time,Information Technology,Oil & Energy,2020-11-05 11:32:32
Data Scientist,Tata Consultancy Services,"Bloomfield, NJ",20 hours ago,52 applicants,"['', ' Expertise in machine learning algorithms and statistical modeling techniques such as clustering, classification, regression, decision trees, neural nets, support vector machines, ensemble modeling and text mining techniques such as sentiment analysis, topic modeling and entity extraction.', ' Clearly present findings to leadership and be able to articulate and influence the Business Case for change.', 'Role ', ' Responsibilities span> ', 'Qualifications', ' Apply data mining techniques and perform statistical analysis as needed.', ' Work individually and/or with team members to design and develop machine learning models for prototyping or ad-hoc analyses.', ' Collect and organize information from a variety of data sources. Write queries to underlying Microsoft SQL Server and Oracle databases.', ' Interview stakeholders in order to understand pain points.', ' Work with business partners to learn and understand the specific domain (i.e. Claim Ops, Call/Contact Center, Client Services…).', ' Work individually and/or with team members to design and develop machine learning models for prototyping or ad-hoc analyses. Apply data mining techniques and perform statistical analysis as needed. Collect and organize information from a variety of data sources. Write queries to underlying Microsoft SQL Server and Oracle databases. Work with business partners to learn and understand the specific domain (i.e. Claim Ops, Call/Contact Center, Client Services…). Interview stakeholders in order to understand pain points. Clearly present findings to leadership and be able to articulate and influence the Business Case for change.', ' The Position ']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist – Remote, Full-time",Toptal,"Indianapolis, IN",5 hours ago,Be among the first 25 applicants,"['', ' A keen attention to detail', ' Full-time availability is a strong advantage', ' Project management skills', ' At least 3 years of professional experience in Data Science']",Mid-Senior level,Contract,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist, Payments Data Science, WPC Analytics - SCV",Apple,"Cupertino, CA",6 hours ago,Over 200 applicants,"['', 'Description', 'Key Qualifications', 'Education & Experience', 'Summary']",Not Applicable,Full-time,Engineering,Consumer Electronics,2020-11-05 11:32:32
"Machine Learning Engineer: up to $250,000 base+equity",Apptronic Labs,"Austin, TX",7 hours ago,Be among the first 25 applicants,"['', 'Responsibilities:', 'Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher level abstractions for various common AI/ML techniques.', 'Candidates will need to have a BS or MS from top notch CS programs with industry experience. We are looking for machine learning software engineers who have experience building at least one of the following: ML/AI models which are in production New neural network algorithms based on research papers Low level performance optimization of deep learning systems Machine learning platforms', 'Company Description:', 'Job Description:', 'General Requirements:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. They have also previously been founders and early employees at startups. We raised $18 million in Series A from Decibel Ventures and Eric Schmidt. We are looking for talented machine learning software engineers, systems software engineers and research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Data Scientist - CI Poly,Stanley Reid & Company,"McLean, VA",21 hours ago,Be among the first 25 applicants,"['', ' US citizenship plus current TS/SCI + CI Poly', 'Any Of The Following Is Beneficial', ' Experience with Matlab', ' Experience with SPSS, SAS, KNIME, RapidMiner, or Statistica Experience with Matlab Experience with SQL and Oracle Experience with Java, Pig, or Spark People-centric analytics (human behavior, user activity, risk ranking, psychology, security, CI, etc.) Supervised and unsupervised learning techniques (neural networks, regressions, clustering, segmentation, etc.)', ' People-centric analytics (human behavior, user activity, risk ranking, psychology, security, CI, etc.)', ' Experience with R/Shiny or Python', ' Experience with Java, Pig, or Spark', ' Supervised and unsupervised learning techniques (neural networks, regressions, clustering, segmentation, etc.)', "" Bachelor's Degree (MS or PhD preferred)"", ' Experience with Data Science, Statistics, Machine Learning, NLP, Predictive Analytics, or similar discipline', ' Experience with SQL and Oracle', ' Experience with SPSS, SAS, KNIME, RapidMiner, or Statistica', "" US citizenship plus current TS/SCI + CI Poly Bachelor's Degree (MS or PhD preferred) Experience with Data Science, Statistics, Machine Learning, NLP, Predictive Analytics, or similar discipline Experience with R/Shiny or Python""]",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist/Machine Learning ,Eliassen Group,"Boston, MA",2 hours ago,Be among the first 25 applicants,"['', 'The Purpose of Your Role', 'Expertise with deep learning frameworks/tools such as TensorFlow, PyTorch/PyCharm, Keras, MXNET, and/or H2O', 'This is a multi-disciplinary role requiring both expert model-building and software engineering skills, so the successful candidate will be capable of developing and supporting core, reusable AI capabilities across many areas, and must have a proven record of providing thought leadership on end-to-end AI/machine learning pipelines and related components for other data science associates.', 'PyTorch', 'PhD or MS in Computer Science, Physics, Engineering, Information Technology, Applied Mathematics, or related fields with, preferably, 10+ years of experience prototyping and deploying Machine/Deep Learning solutions into production environments.', 'Most people that are following the trend and behind the curve will list Tensorflow and Keras - competing technologies that are more widely publicized but the experts/researchers are using pytorch. So listing pytorch instead of keras is a plus. Conversely when I see Keras I usually hypothesize the person is following the trend more than leading it.', 'Engineering expertise for building production ML/DL model containers and pipelines at scale, specifically with Kubernetes, Docker, and big data technologies, AWS-related experience a plus, e.g., SageMaker, EKS, S3, SQS, Kinesis, Snowflake, shell scripting, etc.', 'We are looking for engineers with strong backgrounds in computer science/engineering to build and support complex, scalable AI frameworks, models, tools and APIs for a variety of Artificial Intelligence initiatives across the firm.', 'Why?', 'Education and Experience', 'Full stack development and an understanding of Reach design principles/components a plus.', 'A lot of the state-of-the-art natural language processing (NLP) algorithms use huggingface. This differentiates people that are at least familiar with recent trends vs. those that only have exposure to more traditional NLP projects.', 'In-depth knowledge of software/engineering lifecycle and principles (source control/git, debugging, testing, Jenkins, deployment, model retraining, CI/CD).', 'Huggingface', 'The individual will engage in high profile data science and artificial intelligence projects working closely with multiple business units to define and implement next generation AI-based production solutions. Candidate must be comfortable in a fast-paced, unpredictable and sometimes ambiguous environment working with current and emerging AI technologies.', 'Hands-on experience with one or more of the following: Deep learning/neural network architectures, reinforcement learning, generative modeling, conversational AI, virtual assistants, automated speech recognition, unstructured text pipelines/modeling, anomaly detection, text summarization, classification, especially with NL/NLU/NLGP-related language models and encoders, e.g., Word2Vec, Glove, Bi-LSTMs, Attention Models, BERT, ALBERT, DeepCT, etc.', 'A passion for clean, reusable, object-oriented and/or functional software design principles.', 'Micro Service/API/API gateway, HTML, ES6, SQLAlchemy, and CSS development experience a plus', 'Fluent in data science programming languages such as Python, R and at least one other programming language, e.g., C/C++, Scala, Julia, Java, Go, especially on GPU. CUDA experience a plus.', 'PhD or MS in Computer Science, Physics, Engineering, Information Technology, Applied Mathematics, or related fields with, preferably, 10+ years of experience prototyping and deploying Machine/Deep Learning solutions into production environments.Hands-on experience with one or more of the following: Deep learning/neural network architectures, reinforcement learning, generative modeling, conversational AI, virtual assistants, automated speech recognition, unstructured text pipelines/modeling, anomaly detection, text summarization, classification, especially with NL/NLU/NLGP-related language models and encoders, e.g., Word2Vec, Glove, Bi-LSTMs, Attention Models, BERT, ALBERT, DeepCT, etc.Expertise with deep learning frameworks/tools such as TensorFlow, PyTorch/PyCharm, Keras, MXNET, and/or H2OFluent in data science programming languages such as Python, R and at least one other programming language, e.g., C/C++, Scala, Julia, Java, Go, especially on GPU. CUDA experience a plus.Engineering expertise for building production ML/DL model containers and pipelines at scale, specifically with Kubernetes, Docker, and big data technologies, AWS-related experience a plus, e.g., SageMaker, EKS, S3, SQS, Kinesis, Snowflake, shell scripting, etc.In-depth knowledge of software/engineering lifecycle and principles (source control/git, debugging, testing, Jenkins, deployment, model retraining, CI/CD).A passion for clean, reusable, object-oriented and/or functional software design principles.Full stack development and an understanding of Reach design principles/components a plus.Micro Service/API/API gateway, HTML, ES6, SQLAlchemy, and CSS development experience a plus']",Mid-Senior level,Contract,Engineering,Staffing and Recruiting,2020-11-05 11:32:32
"Staff Data Scientist, Algorithms",Lyft,"Seattle, WA",6 hours ago,118 applicants,"['', 'Mental health benefits', 'End-to-end experience with data, including querying, aggregation, analysis, and visualization', ' M.S. or Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, or other quantitative fields or related work experience 5+ years professional experience Passion for solving unstructured and non-standard, ambiguous mathematical problems by leveraging expertise in one or multiple fields. End-to-end experience with data, including querying, aggregation, analysis, and visualization Proficiency with Python, or another interpreted programming language like R or Matlab Strong communicator. Able to coordinate with several teams of data scientists to deliver on complex initiatives.  Strong business sense and understanding of experimentation methodologies. ', 'Lyft is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. Lyft does not make hiring or employment decisions on the basis of race, color, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender identity, sexual orientation, disability, age, military or veteran status, or any other basis protected by applicable local, state, or federal laws or prohibited by Company policy. Lyft also strives for a healthy and safe workplace and strictly prohibits harassment of any kind. ', 'Pursuant to', 'Partner with Engineers, Product Managers, and Business Partners to frame problems, both mathematically and within the business context', 'Responsibilities', 'Strong communicator. Able to coordinate with several teams of data scientists to deliver on complex initiatives. ', '5+ years professional experience', 'Benefits', 'Develop and fit statistical, machine learning, or optimization models', 'Design and implement both simulated and live experiments', '18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible', 'Pre-tax commuter benefits', 'Passion for solving unstructured and non-standard, ambiguous mathematical problems by leveraging expertise in one or multiple fields.', ' the San Francisco Fair Chance Ordinance and other similar state laws and local ordinances, and its internal policy, Lyft will also consider for employment qualified applicants with arrest and conviction records.', 'In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off', 'Strong business sense and understanding of experimentation methodologies.', ' Partner with Engineers, Product Managers, and Business Partners to frame problems, both mathematically and within the business context Perform exploratory data analysis to gain a deeper understanding of the problem Develop and fit statistical, machine learning, or optimization models Write production model code; collaborate with Software Engineers to implement algorithms in production Design and implement both simulated and live experiments Analyze experimental and observational data; communicate findings; facilitate launch decisions ', 'Experience', 'Great medical, dental, and vision insurance options', 'Perform exploratory data analysis to gain a deeper understanding of the problem', 'M.S. or Ph.D. in Statistics, Operations Research, Mathematics, Computer Science, or other quantitative fields or related work experience', '401(k) plan to help save for your future', 'Analyze experimental and observational data; communicate findings; facilitate launch decisions', 'Write production model code; collaborate with Software Engineers to implement algorithms in production', 'Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program', ' Great medical, dental, and vision insurance options Mental health benefits In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off 401(k) plan to help save for your future 18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible Pre-tax commuter benefits Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program ', 'Proficiency with Python, or another interpreted programming language like R or Matlab']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist, Manager",Guidehouse,"Atlanta, GA",5 hours ago,Be among the first 25 applicants,"['', ' Identify and assess project risks ', ' The successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described. ', 'About Guidehouse', 'Benefits Include', 'Disclaimer', ' Visualization skills such as Tableau, Power BI, or R Shiny ', 'Responsibilities', ' Experience in ""Big 4"" or equivalent established consultant firm highly desired ', ' Operate with a high-degree of professional skepticism, independence, and objectivity - including considering the big picture while meeting the client’s analytics needs ', ' Manage contracts, projects, or teams responsible for delivering advanced analytics services and products ', 'Desired Experience', ' Analyzing large and complex data sets, with strong aptitude for conducting quantitative and qualitative analysis ', ' Experience with public sector clients, especially the CDC and/or a large public healh organization ', ' Disclaimer ', ' Communicate effectively to various audiences, including various levels of management and external clients, in a professional environment ', ' Selecting and applying the appropriate analytical techniques ', ' Analytics for business, operations, human capital analytics, or financial management ', ' Create and manage project plans, and execute work accordingly ', 'Qualifications', ' Cultivate relationships with clients or other non-team member stakeholders ', ' Advanced proficiency in an analytics programming language, such as R, Python, or SAS ', 'Significant Experience In And Ability To', 'Additional Requirements', ' Guide analytics initiatives and provide thought leadership ', ' Statistical analysis, predictive modelling, simulation, machine learning, and artificial intelligence ', 'Overview', ' Manage contracts, projects, or teams responsible for delivering advanced analytics services and products  Guide analytics initiatives and provide thought leadership  Create and manage project plans, and execute work accordingly  Supervise multiple direct reports, providing constructive feedback and guidance on work performance  Cultivate relationships with clients or other non-team member stakeholders  Operate with a high-degree of professional skepticism, independence, and objectivity - including considering the big picture while meeting the client’s analytics needs  Identify and address client needs and demonstrate flexibility in prioritizing and completing tasks  Identify and assess project risks  Communicate effectively to various audiences, including various levels of management and external clients, in a professional environment  Self-organize, self-manage, take initiative and follow through  Ability to juggle multiple tasks and responsibilities ', ' Ability to juggle multiple tasks and responsibilities ', ' Identify and address client needs and demonstrate flexibility in prioritizing and completing tasks ', ' Self-organize, self-manage, take initiative and follow through ', ' Statistical analysis, predictive modelling, simulation, machine learning, and artificial intelligence  Selecting and applying the appropriate analytical techniques  Analyzing large and complex data sets, with strong aptitude for conducting quantitative and qualitative analysis  Analytics for business, operations, human capital analytics, or financial management  Advanced proficiency in an analytics programming language, such as R, Python, or SAS  Visualization skills such as Tableau, Power BI, or R Shiny  Experience with public sector clients, especially the CDC and/or a large public healh organization  Experience in ""Big 4"" or equivalent established consultant firm highly desired ', ' Supervise multiple direct reports, providing constructive feedback and guidance on work performance ']",Mid-Senior level,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Research Scientist,Upstart,"San Mateo, CA",5 hours ago,70 applicants,"['', 'Rigorous quantitative background', 'The Team', 'Enthusiasm for and alignment with Upstart’s mission and values', 'Numerically-savvy with ability to operate at a speedy pace', ' Competitive compensation (base + bonus & equity) Comprehensive medical, dental, and vision coverage Personal development and technology & ergonomic budgets  Life insurance and disability benefits  Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams)  Generous vacation policy 401(k) retirement plan Catered lunches + snacks & drinks ', 'Strong sense of intellectual curiosity balanced with humility', 'Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams) ', 'The Role', 'Strong academic credentials with a M.S. in statistics, mathematics, computer science or a related quantitative field of study with a preference for a PhD', '401(k) retirement plan', 'Competitive compensation (base + bonus & equity)', 'What We’re Looking For', 'Comprehensive medical, dental, and vision coverage', 'Life insurance and disability benefits ', 'Comfort with programming (ideally in Python and R)', 'Generous vacation policy', ' Strong academic credentials with a M.S. in statistics, mathematics, computer science or a related quantitative field of study with a preference for a PhD Comfort with programming (ideally in Python and R) Rigorous quantitative background Predictive modeling experience is preferred Strong sense of intellectual curiosity balanced with humility Numerically-savvy with ability to operate at a speedy pace Enthusiasm for and alignment with Upstart’s mission and values ', 'Personal development and technology & ergonomic budgets ', 'Catered lunches + snacks & drinks', 'Predictive modeling experience is preferred', 'What You’ll Love']",Associate,Full-time,Other,Computer Software,2020-11-05 11:32:32
Principal Data Scientist,Ntelicor,"Sunnyvale, CA",23 hours ago,30 applicants,"['Data Source Identification: Understands the priority order of requirements and service level agreements. Defines and identifies the most suitable sources for required data that is fit for purpose, referring to external sources as required. Performs initial data quality checks on the extracted data. Reviews the deliverables of junior associates and provides guidance. ', 'Code Development & Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. ', 'Qualifications', ""Problem Formulation: Analyzes the business problem within one's discipline and questions assumptions to help the business identify the root cause. Identifies and recommends approach to resolve the business problem. Sets data analytics, big data analytics, automation goals, and deliverables based on the established success criteria and define key metrics to measure progress and effectiveness of the solution. Quantifies business impact. "", 'Publications or active peer reviewer in related journals or conference.', ""Data Source Identification: Understands the priority order of requirements and service level agreements. Defines and identifies the most suitable sources for required data that is fit for purpose, referring to external sources as required. Performs initial data quality checks on the extracted data. Reviews the deliverables of junior associates and provides guidance. Data Strategy: Understands, articulates, interprets, and applies the principles of the defined strategy to unique, moderately complex business problems that may span one or main functions or domains. Problem Formulation: Analyzes the business problem within one's discipline and questions assumptions to help the business identify the root cause. Identifies and recommends approach to resolve the business problem. Sets data analytics, big data analytics, automation goals, and deliverables based on the established success criteria and define key metrics to measure progress and effectiveness of the solution. Quantifies business impact. Analytical Modeling: Selects appropriate modeling techniques for complex problems with large scale, multiple structured and unstructured data sets. Selects and develops variables and features iteratively based on model responses in collaboration with the business. Conducts exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available dataCode Development & Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. "", 'PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, or related field.', '6 years’ experience using open source frameworks (for example, scikit learn, tensorflow, torch).', 'Data Strategy: Understands, articulates, interprets, and applies the principles of the defined strategy to unique, moderately complex business problems that may span one or main functions or domains. ', 'Analytical Modeling: Selects appropriate modeling techniques for complex problems with large scale, multiple structured and unstructured data sets. Selects and develops variables and features iteratively based on model responses in collaboration with the business. Conducts exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data', 'Essential Functions', ""8 years' experience in data science, machine learning, optimization models, or related field."", 'Successful completion of one or more assessments in Python, Spark, Scala, or R.', ""PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, or related field.8 years' experience in data science, machine learning, optimization models, or related field.Successful completion of one or more assessments in Python, Spark, Scala, or R.6 years’ experience using open source frameworks (for example, scikit learn, tensorflow, torch).Publications or active peer reviewer in related journals or conference.""]",Mid-Senior level,Full-time,Information Technology,Airlines/Aviation,2020-11-05 11:32:32
Data Engineer,CGI,"Cleveland, OH",10 hours ago,Be among the first 25 applicants,"['', ' 5+ years of professional experience in: software development and/or data engineering; and in working with relational databases including Oracle, Teradata, MySQL.', ' Deliver high quality work and adapt to new challenges, as an individual or as part of a team', ' 5+ years of development experience in Oracle Business intelligence tool (OBIEE) and /BIP', ' Provide expertise in performing application development, configuration and unit testing of Data Integration (using ODI, PL/SQL, SQL), and Oracle Business Intelligence (OBIEE) applications', ' Performance tuning of the analysis and dashboards for response time, data rendering, and user interface experience', 'Desired Qualifications/Non-essential Skills Required', 'Required Qualifications To Be Successful In This Role', ' Oracle ', ' Provide hands-on technical solutions to business challenges & translates them into process/ technical solutions', ' Experience designing, building, and maintaining real-time or near real-time data pipelines using technologies such as Apache Kafka and/or Spark Stream', ' Experience working with Big Data tools and frameworks like Hadoop, Spark, Hive and Impala', ' Strong experience in SQL and dealing with multiple databases e.g. Teradata, DB2, SQL Server, Oracle etc.', ' Experience performance and tuning in a large OBIEE environment', ' Oracle  SQL', 'Build your career with us.', 'Job Description', 'Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned', ' Experience implementing BI Visualization and Reporting toolsets such as Tableau, Power BI', 'Skills', ' Excellent communication and thought leadership skills', ' SQL', ' Develop data analysis reports using graphs, charts, pivot tables, gauges, KPI’s, and Pie charts', ' Design and develop OBIEE Dashboards/Analysis with enhanced drill down, guided navigation, prompts, filters, and variables options for efficient performance', ' Excellent interpersonal skills including the ability to work with diverse personality types and understand technical issues.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Machine Learning Engineer,Forefront Solutions & Consultancies Ltd,"Austin, TX",5 hours ago,Over 200 applicants,"['', 'Machine learning platforms', 'ML/AI models which are in production', 'ML/AI models which are in productionNew neural network algorithms based on research papersLow level performance optimization of deep learning systemsMachine learning platformsNLP', 'NLP', 'Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher level abstractions for various common AI/ML techniques.', 'Low level performance optimization of deep learning systems', 'New neural network algorithms based on research papers', 'Candidates will need to have a BS or MS from top notch CS programs with industry experience. We are looking for machine learning software engineers who have experience building at least one of the following:']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
"Machine Learning Engineer: up to $250,000 base+equity",Scovios,"Austin, TX",9 hours ago,Be among the first 25 applicants,"['', 'Responsibilities:', 'Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher level abstractions for various common AI/ML techniques.', 'Candidates will need to have a BS or MS from top notch CS programs with industry experience. We are looking for machine learning software engineers who have experience building at least one of the following: ML/AI models which are in production New neural network algorithms based on research papers Low level performance optimization of deep learning systems Machine learning platforms', 'Company Description:', 'Job Description:', 'General Requirements:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. They have also previously been founders and early employees at startups. We raised $18 million in Series A from Decibel Ventures and Eric Schmidt. We are looking for talented machine learning software engineers, systems software engineers and research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
"Data Scientist, Ads Measurement",Pinterest,"Seattle, WA",7 hours ago,Be among the first 25 applicants,"['', ' Strong focus on understanding ads domain and advertiser-focused objectives, measuring ad effectiveness, or similar. Experience with experimentation at web scale. Familiarity with online experimentation and its pitfalls. Experience in the strategic analytics side of data science: shaping decisions rather than just building models Proficiency in SQL/Hive', 'Deep strategic analysis', ' Deep strategic analysis to improve our understanding of our advertising platform and its ability to enable us to meet advertiser objectives. Answer core ads measurement questions such as: How can we prove the effectiveness of ads to advertisers? Can we quantify how new ad features will impact key business metrics? How accurate is our offsite conversion data, and how well can we match incoming conversions to Pinterest users? What features of a conversion can help us inform decisions on ad distribution?', ' 4+ years of combined post-graduate academic and industry experience applying scientific methods to solve real-world problems on web-scale data Proven ability to apply scientific methods to solve real-world problems on web-scale data Expertise in at least one scripting language (ideally Python/R) Strong business and product sense: delight in shaping vague questions into well-defined analyses and success metrics that drive business decisions Excellent communication skills: able to communicate findings with leadership and product teams  ', 'Proficiency in SQL/Hive', ' Experimentation: Evolve our experimentation capabilities and tools to evaluate the efficacy of our ad products on advertiser goals and KPIs. Advise on experimentation best practices; identify flaws in experiment practices and results; build tools and frameworks for experiment analysis.', 'What You’ll Do', 'Opportunity sizing and analysis', ' Opportunity sizing and analysis. Where is attribution breaking down? Are our brand lift studies biased? What do people do on Pinterest before purchasing? How closely related are the products that a user viewed and purchased? Write clear, actionable analyses that help teams identify areas of improvement and investment.', 'Experience in the strategic analytics side of data science: shaping decisions rather than just building models', 'Strong focus on understanding ads domain and advertiser-focused objectives, measuring ad effectiveness, or similar.', 'Excellent communication skills: able to communicate findings with leadership and product teams ', ' Product recommendations. Clearly communicate recommendations to Product and Engineering teams on how we can evolve our internal strategy to address shortcomings observed through deep analysis. Partner closely with Product to develop and evolve our long-term advertiser measurement strategy.', 'What We’re Looking For', '4+ years of combined post-graduate academic and industry experience applying scientific methods to solve real-world problems on web-scale data', 'Expertise in at least one scripting language (ideally Python/R)', 'Strong business and product sense: delight in shaping vague questions into well-defined analyses and success metrics that drive business decisions', '  Deep strategic analysis to improve our understanding of our advertising platform and its ability to enable us to meet advertiser objectives. Answer core ads measurement questions such as: How can we prove the effectiveness of ads to advertisers? Can we quantify how new ad features will impact key business metrics? How accurate is our offsite conversion data, and how well can we match incoming conversions to Pinterest users? What features of a conversion can help us inform decisions on ad distribution?  Product recommendations. Clearly communicate recommendations to Product and Engineering teams on how we can evolve our internal strategy to address shortcomings observed through deep analysis. Partner closely with Product to develop and evolve our long-term advertiser measurement strategy.  Opportunity sizing and analysis. Where is attribution breaking down? Are our brand lift studies biased? What do people do on Pinterest before purchasing? How closely related are the products that a user viewed and purchased? Write clear, actionable analyses that help teams identify areas of improvement and investment.  Experimentation: Evolve our experimentation capabilities and tools to evaluate the efficacy of our ad products on advertiser goals and KPIs. Advise on experimentation best practices; identify flaws in experiment practices and results; build tools and frameworks for experiment analysis. ', 'The Best Candidates Will Also Have', 'Experience with experimentation at web scale. Familiarity with online experimentation and its pitfalls.', 'Proven ability to apply scientific methods to solve real-world problems on web-scale data', 'Product recommendations.', 'Experimentation: ']",Mid-Senior level,Full-time,Information Technology,Internet,2020-11-05 11:32:32
Sr. Data Scientist,MSC Industrial Supply Co.,"Davidson County, NC",23 hours ago,Be among the first 25 applicants,"['', 'Architects, builds and maintains data driven machine learning models, experiments, forecasting algorithms, and optimization models.', 'Equal Opportunity Statement ', 'Bachelor’s degree in a quantitative field such as Data Science, Computer Science, Quantitative Finance, Math, Statistics, Physics or a related Engineering degree required. Master’s degree preferred.', 'Communicates final recommendations and drive decision making.', ' Provides technical leadership and guidance in advanced analytics solutions as well as:', 'Experience with data visualization libraries such as D3, Matplotlib, Pyplot, ggplot2 required.', 'Mentors others as needed on best practices for design and implementation of cutting-edge analytics solutions.', ' Drives the MSC Culture in the department and throughout the company to ensure fulfillment of MSC’s vision and unity of purpose.', 'Work Location :', 'Other Requirements', 'Collaborates with cross-functional data and product teams across business applications to access and manipulate data, explain data gathering requirements, make recommendations, display results, and build efficient and scalable analytics solutions.', 'Strong Knowledge about Agile techniques: User Stories, Continuous Integration, Test Driven Development, Continuous Testing, Pairing, Automated Testing, Burn Down Metrics, Velocity etc.', 'Strong knowledge of software development processes and procedures to understand team needs includes fundamentals of iterative and incremental development', 'Partner swith internal stakeholders on projects to identify and articulate opportunities, see beyond the data to identify solutions that will raise the bar for decision making.', ' Participation in special projects and performs additional duties as required', 'Potential Work Location :', 'Minimum three years of experience in SQL in big data environments (i.e. Hadoop) and data modeling required.', 'A valid driver’s license and the ability to travel up to 15% of the time may be required.', 'Experience with DevOps process (exposure to GitHub, Jenkins or other CI/CD tools) required.', 'Experience with scientific computing and analysis packages such as NumPy, SciPy, Pandas, Scikit-learn, dplyr, or ggplot2 required.', 'Experience writing testable code and shipping code into production required.', 'People. Collaboration. Insight. That’s how you build something that works.', 'Requisition ID : 5550 ', 'Why MSC ', 'Brief Position Summary', 'State or Province :', 'Knowledge of deep learning research. Familiarity with object-oriented programming languages (such as C++ or Java) and visualization tools from at least one toolset (e.g. Tableau, MicroStrategy,, Looker, SAS, Power BI, etc.)', 'Build a better career with MSC. ', 'EDUCATION And EXPERIENCE', 'INDICATES ESSENTIAL DUTIES', 'Bachelor’s degree in a quantitative field such as Data Science, Computer Science, Quantitative Finance, Math, Statistics, Physics or a related Engineering degree required. Master’s degree preferred.Minimum five years of experience in building models and developing algorithms for machine learning, statistics, mathematical programming, and simulation in industry and/or academia required.Minimum five years of experience in managing and analyzing large-scale structured and unstructured data using R or Python required.Minimum three years of experience in SQL in big data environments (i.e. Hadoop) and data modeling required.Experience with scientific computing and analysis packages such as NumPy, SciPy, Pandas, Scikit-learn, dplyr, or ggplot2 required.Experience with data visualization libraries such as D3, Matplotlib, Pyplot, ggplot2 required.Experience with Machine Learning, Statistics, or other data analysis tools and techniques required.Experience with statistics methods such as forecasting, time series, hypothesis testing, classification, clustering or regression analysis required.Experience writing testable code and shipping code into production required.Experience with DevOps process (exposure to GitHub, Jenkins or other CI/CD tools) required.Experience with machine learning libraries and packages such as PyTorch, Caffe2, TensorFlow, Keras or Theano preferred.', 'Analysis of operational data and user behavior to improve overall business performance.', 'Minimum five years of experience in managing and analyzing large-scale structured and unstructured data using R or Python required.', 'Strong Knowledge about Agile techniques: User Stories, Continuous Integration, Test Driven Development, Continuous Testing, Pairing, Automated Testing, Burn Down Metrics, Velocity etc.Strong knowledge of software development processes and procedures to understand team needs includes fundamentals of iterative and incremental developmentKnowledge of deep learning research. Familiarity with object-oriented programming languages (such as C++ or Java) and visualization tools from at least one toolset (e.g. Tableau, MicroStrategy,, Looker, SAS, Power BI, etc.)', 'Skills', ' Stays current with latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. May be required to present ideas to larger audience for review and buy-in.', 'Minimum five years of experience in building models and developing algorithms for machine learning, statistics, mathematical programming, and simulation in industry and/or academia required.', 'Employment Type :', 'JOB TITLE:', 'DUTIES And RESPONSIBILITIES', 'Job Category :', 'Experience with Machine Learning, Statistics, or other data analysis tools and techniques required.', 'Experience with statistics methods such as forecasting, time series, hypothesis testing, classification, clustering or regression analysis required.', 'Defines, computes, tracks, and continuously validate business metrics with diagnostic, predictive, prescriptive analytics.', 'Experience with machine learning libraries and packages such as PyTorch, Caffe2, TensorFlow, Keras or Theano preferred.']",Not Applicable,Full-time,Information Technology,Business Supplies and Equipment,2020-11-05 11:32:32
Sr. Machine Learning Engineer,Zoom,"Pittsburgh, PA",5 hours ago,Be among the first 25 applicants,"[' Clear understanding of text pre-processing and normalization techniques, such as tokenization, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level.', ' Research latest technology in NLP, machine learning, create and improve machine learning models and algorithms. Design and develop AI / machine learning solutions to enhance Zoom meeting experience; Develop machine learning systems for Zoom applications. Train deep learning models with large datasets and accelerating the training process with GPU and CUDA. Research for open sourced labeled dataset and build data pipeline to perform data extraction, transformation and loading. Develop requirement guideline and evaluation criteria for text based data labeling. Integrate machine learning program with Zoom’s core product. Work closely with the Product team to understand current challenges when it comes to use, understand and present the results of text analytics. Work closely with offshore team, providing requirements, technical leadership, and evaluating results.', ' Train deep learning models with large datasets and accelerating the training process with GPU and CUDA.', ' Integrate machine learning program with Zoom’s core product.', 'Responsibilities', ' At least 3 years industry working experience or research experience in the field of machine learning.', ' Develop requirement guideline and evaluation criteria for text based data labeling.', '  M.S., prefer Ph.D in NLP, Machine Learning, Computational Linguistics, Computer Science, Electrical Engineering, Statistics, Mathematics or a related technical field. Familiar with latest development in neural network and the application in machine learning. Experience with developing machine learning systems and familiar with machine learning pipeline components and process. At least 3 years industry working experience or research experience in the field of machine learning. Clear understanding of text pre-processing and normalization techniques, such as tokenization, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level. Strong fundamentals on Machine Learning (ML) / Deep Learning (DL) and NLP algorithms (Word embedding, CNN, LSTM, BERT, etc), techniques (transfer learning, transformers, etc.). Hands-on experience on developing and training models with large- scale text data. Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, SpaCy, AllenNLP, NLTK, gensim, etc. Familiar with software development. Strong analytical skills and attention to detail. Strong mastery of python and general software development skills (source code management, debugging, testing, deployment, etc.)', ' Experience with developing machine learning systems and familiar with machine learning pipeline components and process.', ' OUR IDEAL CANDIDATE: This role requires experience with machine learning in research and application development, creative problem solving and strong communication skills to work with different teams and stakeholders. This person should be highly organized, with the ability to manage requests efficiently and accurately. ', ' Develop machine learning systems for Zoom applications.', ' Strong fundamentals on Machine Learning (ML) / Deep Learning (DL) and NLP algorithms (Word embedding, CNN, LSTM, BERT, etc), techniques (transfer learning, transformers, etc.). Hands-on experience on developing and training models with large- scale text data.', ' Work closely with the Product team to understand current challenges when it comes to use, understand and present the results of text analytics.', ' Research latest technology in NLP, machine learning, create and improve machine learning models and algorithms.', '   M.S., prefer Ph.D in NLP, Machine Learning, Computational Linguistics, Computer Science, Electrical Engineering, Statistics, Mathematics or a related technical field. Familiar with latest development in neural network and the application in machine learning. Experience with developing machine learning systems and familiar with machine learning pipeline components and process. At least 3 years industry working experience or research experience in the field of machine learning. Clear understanding of text pre-processing and normalization techniques, such as tokenization, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level. Strong fundamentals on Machine Learning (ML) / Deep Learning (DL) and NLP algorithms (Word embedding, CNN, LSTM, BERT, etc), techniques (transfer learning, transformers, etc.). Hands-on experience on developing and training models with large- scale text data. Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, SpaCy, AllenNLP, NLTK, gensim, etc. Familiar with software development. Strong analytical skills and attention to detail. Strong mastery of python and general software development skills (source code management, debugging, testing, deployment, etc.)', ' Work closely with offshore team, providing requirements, technical leadership, and evaluating results.', 'Requirements', ' Research for open sourced labeled dataset and build data pipeline to perform data extraction, transformation and loading.', ' Design and develop AI / machine learning solutions to enhance Zoom meeting experience;', ' Familiar with latest development in neural network and the application in machine learning. Experience with developing machine learning systems and familiar with machine learning pipeline components and process. At least 3 years industry working experience or research experience in the field of machine learning. Clear understanding of text pre-processing and normalization techniques, such as tokenization, NER, POS (Part-Of-Speech) tagging and parsing and how they work at a low level. Strong fundamentals on Machine Learning (ML) / Deep Learning (DL) and NLP algorithms (Word embedding, CNN, LSTM, BERT, etc), techniques (transfer learning, transformers, etc.). Hands-on experience on developing and training models with large- scale text data. Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, SpaCy, AllenNLP, NLTK, gensim, etc. Familiar with software development. Strong analytical skills and attention to detail. Strong mastery of python and general software development skills (source code management, debugging, testing, deployment, etc.)', ' Familiar with latest development in neural network and the application in machine learning.', 'Zoom is an award-winning workplace. We have been recognized by Comparably as #1 CEO, Company Happiness, Benefits, Compensation, Diversity, and more! Not to mention we’ve been awarded by Glassdoor as the 2nd Best US workplace & Best Large Company US CEO in 2018, Wealthfront, and Business Insider. Our culture focuses on delivering happiness, our commitment to transparency, and the tangible benefits we provide our employees and our customers. ', ' Experience with open-source ML / DL / NLP toolkits such as TensorFlow, Caffe, PyTorch, CoreNLP, OpenNLP, SpaCy, AllenNLP, NLTK, gensim, etc.', ' Familiar with software development. Strong analytical skills and attention to detail. Strong mastery of python and general software development skills (source code management, debugging, testing, deployment, etc.)']",Not Applicable,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Research Scientist,Visiting Nurse Service of New York,"Manhattan, NY",13 hours ago,Be among the first 25 applicants,"['', 'Manages the accumulation, computation, and analysis of data (both quantitative and qualitative).', 'Prepares and publishes research results in peer reviewed, independent journals and other publications.', 'Plans and evaluates staffing needs for project activities and oversees, trains, evaluates and terminates assigned research project staff.', 'Overview', 'Participates in the planning and implementation of Center activities focused on increasing the involvement and visibility of VNSNY clinical staff in Center projects and publications.', 'Qualifications', 'Performs other administrative and/or supervisory duties as required.', 'Monitors availability of funding sources (e.g. governmental, private foundation and corporate) for research.', 'Works with research management to identify critical research and practice issues in home health care that are of significance to VNSNY and the national home care community; recommends research and policy projects for study.Participates in the development of the Research Center’s annual goals and objectives; identifies key research issues and trends and helps design policy relevant projects and practice improvements.Develops study designs, methodologies and protocols, and manages ongoing research and practice/policy studies on the organization, financing, use, cost and outcomes of home and community-based and long-term care.Manages the accumulation, computation, and analysis of data (both quantitative and qualitative).Monitors availability of funding sources (e.g. governmental, private foundation and corporate) for research.Develops and submits grant proposals and applications toward developing an independent program of research.Prepares and publishes research results in peer reviewed, independent journals and other publications.Plans and evaluates staffing needs for project activities and oversees, trains, evaluates and terminates assigned research project staff.Keeps abreast of latest developments in research field, identifies trends for possible future investigation and maintains cooperative relationships with the Agency, and outside experts from academia, nursing and medical field.Participates in the planning and implementation of Center activities focused on increasing the involvement and visibility of VNSNY clinical staff in Center projects and publications.Performs other administrative and/or supervisory duties as required.', 'Keeps abreast of latest developments in research field, identifies trends for possible future investigation and maintains cooperative relationships with the Agency, and outside experts from academia, nursing and medical field.', 'Participates in the development of the Research Center’s annual goals and objectives; identifies key research issues and trends and helps design policy relevant projects and practice improvements.', 'Develops study designs, methodologies and protocols, and manages ongoing research and practice/policy studies on the organization, financing, use, cost and outcomes of home and community-based and long-term care.', 'Develops and submits grant proposals and applications toward developing an independent program of research.', 'Experience:', 'Works with research management to identify critical research and practice issues in home health care that are of significance to VNSNY and the national home care community; recommends research and policy projects for study.', 'Responsibilities', 'Education:']",Associate,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Senior Principal Data Scientist [Dialogue Management/NLU]],LivePerson,United States,10 hours ago,Be among the first 25 applicants,"['Faceted unsupervised learning -- how can we inject knowledge into unsupervised tasks? How can we inject knowledge into clustering/similarity tasks to reflect facets we care about (intent) and orthogonalize irrelevant facets?', ""LivePerson was named to Fast Company's World’s most innovative companies of 2020 list for the Artificial Intelligence category. We offer top tier tech & data science colleagues, along with opportunities to push your own limits. We embrace invention and experimentation. You’ll have great benefits, flexible time off, plus snacks and drinks to keep your mind fresh and stomach full. Most importantly, you’ll have an ability to make an impact at work and at brands across the globe as we build the future with trusted Conversational AI together.\xa0"", 'You can operate in a fast paced, dynamic environmentYou can advance the SOTA in dialogue systems with experiments and code that are well-designed and well-implemented.You can build partnerships that move our business forwardYou see feedback or failure as motivation to learn and to growYou believe data-driven decision making is the normYou relate to our core principles (link) and want to work with Conversational AI experts', 'Learning NLP systems using self-supervision from unannotated dialogue - Leveraging latent structure within task-oriented dialogue data to solve classification and dialogue problems more accurately and label-efficiently.Faceted unsupervised learning -- how can we inject knowledge into unsupervised tasks? How can we inject knowledge into clustering/similarity tasks to reflect facets we care about (intent) and orthogonalize irrelevant facets?Lightly/distantly supervised dialog management ML systems - How can we utilize self-supervision and reinforcement learning to learn representations of conversational goals and policies from unlabelled historical conversations in a goal-oriented setting?Controllable natural language generation -- How can we build adaptable natural language generation systems that can be easily controlled/configured?', 'You will thrive here if: ', 'Demonstrated capacity to work closely with teammates in a highly collaborative environment, as well as providing strong individual contributions', 'Expertise in NLP techniques to solve problems in dialogue management: either direct experience in dialogue systems OR experience in reinforcement learning', 'You relate to our core principles (link) and want to work with Conversational AI experts', 'Work with one of the world’s largest goal-oriented conversational data sets to push the boundaries of computational linguistics and drive innovative new products at scale.', 'Preferred qualifications:', 'SOTA in dialogue system', '\xa0', 'In addition to a world-class data set, you’ll also have an at-scale population of expert data annotators (contact center agents) to help drive investigation and learning.', 'Learning NLP systems using self-supervision from unannotated dialogue - Leveraging latent structure within task-oriented dialogue data to solve classification and dialogue problems more accurately and label-efficiently.', 'Publish and present cutting-edge research derived from our conversational data', 'You can advance the SOTA in dialogue systems with experiments and code that are well-designed and well-implemented.', 'You believe data-driven decision making is the norm', 'All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.', 'Some areas of research of particular interest:', 'We are an innovative, intent-driven company that believes in building the future and we are looking for growth minded, unconventional thinkers, developers and builders to join the team.\xa0', 'Propose and execute research efforts that drive product strategy', 'You can build partnerships that move our business forward', 'Degree in Computational Linguistics, Computer Science, Statistics, or Mathematics', 'LivePerson is a transformational force in how brands and consumers communicate. With over 18,000 brands, including HSBC, Disney, Verizon, and Home Depot, we are on a mission to make life easier for people and brands everywhere through trusted Conversational AI. We believe in a future where conversations are the norm for getting your intentions fulfilled - whatever they are.\xa0\xa0', 'You can operate in a fast paced, dynamic environment', 'Record of publications in competitive journals/conferences in the field, such as EMNLP, ACL, ICLR, NIPS, NAACL.', 'Writing Python code that is efficient and clean in a Linux environment', 'Your qualifications are:', 'Develop state of the art approaches to unsupervised/semi-supervised problems in intent and dialog management.', 'Controllable natural language generation -- How can we build adaptable natural language generation systems that can be easily controlled/configured?', '3-5 years post-graduate experience in ML, specifically in NLU/NLP', 'Lightly/distantly supervised dialog management ML systems - How can we utilize self-supervision and reinforcement learning to learn representations of conversational goals and policies from unlabelled historical conversations in a goal-oriented setting?', 'Why you’ll love working here:', 'Proven track record of problem-solving, communication, and critical-thinking skills', 'Experience with Python packages for Machine Learning (Scikit-Learn), NLP (SpaCy), and Deep Learning (Pytorch)', 'You see feedback or failure as motivation to learn and to grow', 'At LivePerson, people from diverse backgrounds come together to do their best work and be their authentic selves. We are proud to be an equal opportunity employer. ', 'Degree in Computational Linguistics, Computer Science, Statistics, or Mathematics3-5 years post-graduate experience in ML, specifically in NLU/NLPExpertise in NLP techniques to solve problems in dialogue management: either direct experience in dialogue systems OR experience in reinforcement learningTrack record of applied research on NLP or related fields, e.g. NLU, NLG, ASR/TTS and/or experience with dialogue systemsWriting Python code that is efficient and clean in a Linux environmentExperience with Python packages for Machine Learning (Scikit-Learn), NLP (SpaCy), and Deep Learning (Pytorch)Proven track record of problem-solving, communication, and critical-thinking skillsDemonstrated capacity to work closely with teammates in a highly collaborative environment, as well as providing strong individual contributions', 'Why you’ll love working here:\xa0', 'In this role you will:', 'Track record of applied research on NLP or related fields, e.g. NLU, NLG, ASR/TTS and/or experience with dialogue systems', 'Work with one of the world’s largest goal-oriented conversational data sets to push the boundaries of computational linguistics and drive innovative new products at scale.In addition to a world-class data set, you’ll also have an at-scale population of expert data annotators (contact center agents) to help drive investigation and learning.Propose and execute research efforts that drive product strategyPublish and present cutting-edge research derived from our conversational dataApply cutting-edge methods of NLP/NLU to learn and derive value from one of the world’s largest goal-oriented conversational data sets.Develop state of the art approaches to unsupervised/semi-supervised problems in intent and dialog management.', 'Apply cutting-edge methods of NLP/NLU to learn and derive value from one of the world’s largest goal-oriented conversational data sets.']",Director,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Machine Learning Engineer,KLA,"Ann Arbor, MI",6 hours ago,Over 200 applicants,"['', ' Serve the machine learning model in a stand-alone application or through a robust API', '  Deeply understand the data in the context of KLA business and assess technologies that can be leveraged to generate useful and actionable insights from data to help KLA gain competitive advantage.  Provide technology vision to a group of data scientists and software engineers in the field of natural language processing, anomaly detection, classification and/or regression problems, deep learning model architecture, statistical modeling, time series, feature engineering, computer vision, etc.  Quickly build a proof of concept machine learning pipeline from data collection, model training, to metrics to evaluate the effectiveness of the proposed methodology.  Build a machine learning platform/application for the end-to-end machine learning lifecycle: rapid prototyping; full-scale training; deploying, monitoring, maintaining models; and iterating on modeling ideas based on user feedback.  Serve the machine learning model in a stand-alone application or through a robust API  Collaborate with other teams to understand their sometimes ambiguous requirements, collect their feedback on machine learning results, and incorporate various signals into the machine learning models.  Review codes submitted by junior team members. Mentor junior machine learning engineers.', ' Experience working with open-source software is a plus', ' Deeply understand the data in the context of KLA business and assess technologies that can be leveraged to generate useful and actionable insights from data to help KLA gain competitive advantage.', ' Ability to solve problems independently, good sense of teamwork and communication skills', 'Minimum Qualifications', 'Responsibilities', ' Practical experience with implementing a machine learning system that may mix with heuristic rules, prior knowledge, and other constraints.', ' Provide technology vision to a group of data scientists and software engineers in the field of natural language processing, anomaly detection, classification and/or regression problems, deep learning model architecture, statistical modeling, time series, feature engineering, computer vision, etc.', ' Deep understanding of all well-known machine learning algorithms. The candidate should know the assumptions, advantages, limitations of each model and grasp the trade-off when choosing among different models. ', ' Hands-on experience with R', ' Hands-on experience with building machine learning models using scikit-learn, Tensorflow, Keras or Pytorch', ' Quickly build a proof of concept machine learning pipeline from data collection, model training, to metrics to evaluate the effectiveness of the proposed methodology.', ' Experience with Cloud Computing (AWS/Azure)', ' Strong core CS fundamentals (data structures, algorithms, architecting systems).', ' Passionate about applied machine learning and deep learning', ' Ph.D. with 3+ years or Masters with 6+ years of software engineering with ML focus', 'We offer a competitive, family friendly total rewards package. We design our programs to reflect our commitment to an inclusive environment, while ensuring we provide benefits that meet the diverse needs of our employees. ', ' Proof of record of delivering a machine learning system to generate ROI', 'Required Qualifications', ' Understanding of front-end application development. (Javascript, HTML)', ' Group/Division ', 'Preferred Qualications', '  Experience with Cloud Computing (AWS/Azure)  Experience working with open-source software is a plus  Understanding of front-end application development. (Javascript, HTML)  Hands-on experience with R', ' Review codes submitted by junior team members. Mentor junior machine learning engineers.', ' Collaborate with other teams to understand their sometimes ambiguous requirements, collect their feedback on machine learning results, and incorporate various signals into the machine learning models.', 'KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com to request accommodation.', '  Passionate about applied machine learning and deep learning  Ph.D. with 3+ years or Masters with 6+ years of software engineering with ML focus  Deep understanding of all well-known machine learning algorithms. The candidate should know the assumptions, advantages, limitations of each model and grasp the trade-off when choosing among different models.   Hands-on experience with building machine learning models using scikit-learn, Tensorflow, Keras or Pytorch  Strong core CS fundamentals (data structures, algorithms, architecting systems).  Practical experience with implementing a machine learning system that may mix with heuristic rules, prior knowledge, and other constraints.  Proof of record of delivering a machine learning system to generate ROI  Ability to solve problems independently, good sense of teamwork and communication skills', ' Build a machine learning platform/application for the end-to-end machine learning lifecycle: rapid prototyping; full-scale training; deploying, monitoring, maintaining models; and iterating on modeling ideas based on user feedback.', 'Company Overview']",Entry level,Full-time,Engineering,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Software Engineer - Data,Juniper Networks,"Cupertino, CA",5 hours ago,Be among the first 25 applicants,"['', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Software Engineer, Data', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Assemble large, complex data sets that meet functional / non-functional business requirements.', '3+ years experiences building data pipelines for data science-driven solutions', 'Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', 'Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', ' Experience with AWS cloud services: EC2, EMR, RDS, Redshift', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc.', ' Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources', 'Experience with AWS cloud services: EC2, EMR, RDS, Redshift', ' Master in Computer Science, Electrical Engineering, Statistics, Applied Math or equivalent fields with strong mathematical background 3+ years experiences building data pipelines for data science-driven solutions Strong hands-on coding skills (preferably in Python) processing large-scale data set and developing machine learning model Familiar with one or more machine learning or statistical modeling tools such as Numpy, ScikitLearn, MLlib, Tensorflow Good team worker with excellent communication skills written, verbal and presentation Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Work with data and analytics experts to strive for greater functionality in our data systems.', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Experience with AWS, S3, Flink, Spark, Kafka, ElasticSearch', 'Experience with big data tools: Hadoop, Spark, Kafka, etc.', 'Work with data and analytics experts to strive for greater functionality in our data systems.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', ' Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.', ' Strong hands-on coding skills (preferably in Python) processing large-scale data set and developing machine learning model Familiar with one or more machine learning or statistical modeling tools such as Numpy, ScikitLearn, MLlib, Tensorflow Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytic skills related to working with unstructured datasets. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Strong project management and organizational skills. Experience supporting and working with cross-functional teams in a dynamic environment. Experience with big data tools: Hadoop, Spark, Kafka, etc. Experience with relational SQL and NoSQL databases, including Postgres and Cassandra. Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc Experience with AWS cloud services: EC2, EMR, RDS, Redshift Experience with stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Master in Computer Science, Electrical Engineering, Statistics, Applied Math or equivalent fields with strong mathematical background', ' Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.', ' Previous work in a start-up environment', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', 'Strong analytic skills related to working with unstructured datasets.', ' Experience with AWS, S3, Flink, Spark, Kafka, ElasticSearch  Previous work in a start-up environment Master in Computer Science, Electrical Engineering, Statistics, Applied Math or equivalent fields with strong mathematical background We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:', 'We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:', 'Strong hands-on coding skills (preferably in Python) processing large-scale data set and developing machine learning model', 'Familiar with one or more machine learning or statistical modeling tools such as Numpy, ScikitLearn, MLlib, Tensorflow', 'Strong project management and organizational skills.', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'Good team worker with excellent communication skills written, verbal and presentation', ' Responsibilities ', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', ' Experience with stream-processing systems: Storm, Spark-Streaming, etc.', ' Qualification And Desired Experiences ', ' Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.', 'Create and maintain optimal data pipeline architecture,']",Entry level,Full-time,Engineering,Computer & Network Security,2020-11-05 11:32:32
Senior Data Engineer,Ampersand,"New York, NY",13 hours ago,Be among the first 25 applicants,"['', 'Advanced SQL, Big Data, Python and Scala knowledge and experience working with relational databases', 'Knack for writing clean, readable, and easily maintainable code', 'Experience implementing automated testing platforms and unit tests', 'Define + Find\xa0a strategic audience or select from traditional Nielsen demos\xa0', 'Design, build, and maintain efficient, reusable, and reliable code', 'Skill for writing reusable code', 'Measure + Report\xa0both reach\xa0and\xa0frequency\xa0and\xa0business outcomes\xa0', 'BENEFITS:', 'Design and build our data pipeline', 'EDUCATION, SKILLS, AND EXPERIENCE:', 'Experience building and optimizing ‘big data’ data pipelines, architectures, data sets and tools (Hadoop, Spark, Presto, etc.)Advanced SQL, Big Data, Python and Scala knowledge and experience working with relational databasesStrong knowledge and experience working with AWS eco-systemSkill for writing reusable codeFamiliar with various design and architectural patternsKnack for writing clean, readable, and easily maintainable codeExperience implementing automated testing platforms and unit testsProficient understanding of code versioning tools such as GIT, SVN, VSTS', 'Identify bottlenecks and bugs, and devise solutions to mitigate and address these issues', 'Assemble, combine and transform large multiple complex data sets', 'Build analytics tools using the data pipeline to provide actionable insights to end users', 'Define + Find\xa0a strategic audience or select from traditional Nielsen demos\xa0Plan + Execute\xa0against an optimized schedule across multi-screen TV\xa0\xa0 \xa0\xa0Measure + Report\xa0both reach\xa0and\xa0frequency\xa0and\xa0business outcomes\xa0', 'Plan + Execute\xa0against an optimized schedule across multi-screen TV\xa0\xa0 \xa0\xa0', 'Strong knowledge and experience working with AWS eco-system', 'Help maintain code quality, organization, and automatization', 'Proficient understanding of code versioning tools such as GIT, SVN, VSTS', 'JOB AT A GLANCE: ', 'ESSENTIAL FUNCTIONS:', 'Design and build our data pipelineAssemble, combine and transform large multiple complex data setsBuild analytics tools using the data pipeline to provide actionable insights to end usersDesign, build, and maintain efficient, reusable, and reliable codeIdentify bottlenecks and bugs, and devise solutions to mitigate and address these issuesHelp maintain code quality, organization, and automatization', 'Familiar with various design and architectural patterns', 'Experience building and optimizing ‘big data’ data pipelines, architectures, data sets and tools (Hadoop, Spark, Presto, etc.)']",Mid-Senior level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
"Data Scientist, SME",ManTech,"Springfield, VA",7 hours ago,Be among the first 25 applicants,"['', 'Capable of presenting data to vendor, customer or company to audiences of different technical levels.', 'Secure our Nation, Ignite your Future', 'Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.', 'Preferred Qualifications', 'TS/SCI with polygraph (FSP)', 'Needs to occasionally move about inside the office to access file cabinets, office machinery, etc.', 'Must be able to remain in a stationary position 50%.Needs to occasionally move about inside the office to access file cabinets, office machinery, etc.Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.Frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations.', 'Designs and develops methods, processes, and systems to consolidate and analyze data, both structured and unstructured, and its sources, including big data.', 'Basic Qualifications', 'Must be able to remain in a stationary position 50%.', 'Requires BS and 4 - 8 years of prior relevant experience or Masters with 2 - 6 years of prior relevant experience.', 'Hands-on experience working with data science methods such as statistical modeling, information retrieval, graph analysis, data minding, machine learning and data visualization.', 'Security Clearance Requirements', 'Models complex business problems and is familiar with natural language processing, machine learning, predictive modeling, statistical analysis and hypothesis testing.', 'Hands on experience working with data science methods such as: statistical modeling, information retrieval, graph analysis, data mining, machine learning', 'Experience working in an Agile based environment.', 'Supports defining specific process improvement projects, identifies meaningful insights, interprets and communicates findings and makes recommendations including process improvement opportunities. Continual process improvement activities include data, processes, interfaces, tools and technology insertion. ', 'Frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations.', 'Years of Experience in creating complex SQL queries and functions, data structures and strong analytical problem-solving skills.', 'Develops and uses advanced software programs, algorithms, querying and automated processes to cleanse, integrate and evaluate datasets.', 'Works with cross-discipline teams to ensure connectivity between various databases and systems. Experience working with various self-service business intelligence and data visualization tools such as Tableau, Power BI, Business Objects, etc.', 'Responsibilities Include, But Are Not Limited To', 'Bachelor’s degree or master’s degree in Computer Science, Mathematics, Information Technology or STEM related discipline', 'Years of Experience using Python, R, or other languages to build statistical models or analyze data. Experience with Python, SQL, Bash, Scala, Java, Hadoop, Apache, spark, Kafka or Hive.', 'May develop information tools, algorithms, dashboards, and queries to monitor and improve business performance. Maintains awareness of emerging analytics and big-data technologies.', 'none', 'Designs and develops methods, processes, and systems to consolidate and analyze data, both structured and unstructured, and its sources, including big data.Develops and uses advanced software programs, algorithms, querying and automated processes to cleanse, integrate and evaluate datasets.Hands on experience working with data science methods such as: statistical modeling, information retrieval, graph analysis, data mining, machine learningModels complex business problems and is familiar with natural language processing, machine learning, predictive modeling, statistical analysis and hypothesis testing.May develop information tools, algorithms, dashboards, and queries to monitor and improve business performance. Maintains awareness of emerging analytics and big-data technologies.Hands-on experience working with data science methods such as statistical modeling, information retrieval, graph analysis, data minding, machine learning and data visualization.Years of Experience using Python, R, or other languages to build statistical models or analyze data. Experience with Python, SQL, Bash, Scala, Java, Hadoop, Apache, spark, Kafka or Hive.Years of Experience in creating complex SQL queries and functions, data structures and strong analytical problem-solving skills.Works with cross-discipline teams to ensure connectivity between various databases and systems. Experience working with various self-service business intelligence and data visualization tools such as Tableau, Power BI, Business Objects, etc.Capable of presenting data to vendor, customer or company to audiences of different technical levels.Supports defining specific process improvement projects, identifies meaningful insights, interprets and communicates findings and makes recommendations including process improvement opportunities. Continual process improvement activities include data, processes, interfaces, tools and technology insertion. Experience working in an Agile based environment.', 'Requires BS and 4 - 8 years of prior relevant experience or Masters with 2 - 6 years of prior relevant experience.Bachelor’s degree or master’s degree in Computer Science, Mathematics, Information Technology or STEM related discipline', 'Physical Requirements']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Medix™,Atlanta Metropolitan Area,2 hours ago,Be among the first 25 applicants,"['', 'The primary responsibilities of this Sr. Data Engineer will include:\xa0', 'Making enhancements to the existing database structures -- evaluate code for performance and quality, identify opportunities for improvement, etc.', 'Recommending, implementing and managing data validation and testing methods to ensure data quality across all systems and applications.', 'In addition, this Sr. Data Engineer will be responsible for working directly with business stakeholders and product managers to design, develop and implement Data solutions (Microsoft SQL, SSRS, SQL Stored Procedures along with some NoSQL Data - MongoDB, Redis and Cassandra)', 'Required Experience / Technical Qualifications\xa0', 'Please note that this role is 100% remote (and will continue to be in the future)\xa0', 'Our client is a Healthcare Analytics firm that specializes in Population Health Management.\xa0 This project is specifically dedicated to HEDIS Medicare-Medicaid Plan analytics and reporting. \xa0 We are seeking a Sr Data Engineer who has significant experience in developing, testing, implementing and maintaining data quality\xa0 measures related to HEDIS Measures related topics (QPP, MIPS, APP, ACOs, etc).\xa0\xa0', 'Benefits ', 'Working primarily with Microsoft SQL Server, as well as NoSQL databases (MongoDB, Redis and Cassandra)', 'Duration: 6 Months', 'Microsoft SQL Server Reporting Services (SSRS) Experience\xa0', 'Medix is currently seeking a Sr. Data Engineer for a 100% Remote contract opportunity with one of our top healthcare industry clients.', 'Developing new stored procedures and tuning / redesigning existing stored procedures for optimal performance\xa0', 'Compensation Range: Negotiable, Based on Experience\xa0', 'Advanced Microsoft SQL Data Engineering\xa0', 'T-SQL Scripting', 'Strong Data Quality Management experience\xa0\xa0', 'Leveraging a strong knowledge of the healthcare industry and government measures related to Medicare & Medicare in implementing new clinical quality measures\xa0', 'Partnering with the Application Development and DBA teams to help support production data loads and ongoing refreshes of development, test/QA, and production database systems.', 'Position Type: W2 - Contract to Hire\xa0', 'Developing and implementing Data Quality Measures for Medicare & Medicaid Plan reporting (HEDIS, CAPHS, QPP, MIPS, APP, ACO, etc)Leveraging a strong knowledge of the healthcare industry and government measures related to Medicare & Medicare in implementing new clinical quality measures\xa0Recommending, implementing and managing data validation and testing methods to ensure data quality across all systems and applications.Working with business stakeholders and product managers\xa0 to capture requirements for reporting and analytics.Analyzing data flow requirements and creating/ managing systems documentation (manuals/runbooks/SOPs/Checklists) as needed.Developing the data solutions from inception through testing, delivery and ongoing managementDeveloping new stored procedures and tuning / redesigning existing stored procedures for optimal performance\xa0Making enhancements to the existing database structures -- evaluate code for performance and quality, identify opportunities for improvement, etc.Working primarily with Microsoft SQL Server, as well as NoSQL databases (MongoDB, Redis and Cassandra)Partnering with the Application Development and DBA teams to help support production data loads and ongoing refreshes of development, test/QA, and production database systems.', 'About our client / About this role:', 'NoSQL Databases: Redis, Cassandra, MongoDB', 'Working with business stakeholders and product managers\xa0 to capture requirements for reporting and analytics.', 'Duration', 'Stored Procedures (Expert)\xa0', 'Please note that talent must be authorized to work for any employer in the US, without the need for visa sponsorship now or in the future.', 'Compensation Range: ', 'Required 7 + years professional experience', 'Developing the data solutions from inception through testing, delivery and ongoing management', 'Significant experience in HEDIS Measures reporting\xa0', 'Benefits :Medix offers an impressive Talent Benefits Package, which includes Medical/Dental/Vision insurance options, prescription drug, short/long-term disability and life insurance.\xa0 There is accrued paid time off (PTO) in addition to a 401K Retirement Savings Plan with Medix Matching.\xa0', 'Analyzing data flow requirements and creating/ managing systems documentation (manuals/runbooks/SOPs/Checklists) as needed.', 'Required Bachelor of Science in a Computer Science or related field', 'Position Type: ', 'Significant industry knowledge of Medicare / Medicare Plans', 'Developing and implementing Data Quality Measures for Medicare & Medicaid Plan reporting (HEDIS, CAPHS, QPP, MIPS, APP, ACO, etc)', 'Required Bachelor of Science in a Computer Science or related fieldRequired 7 + years professional experienceSignificant industry knowledge of Medicare / Medicare PlansSignificant experience in HEDIS Measures reporting\xa0Strong Data Quality Management experience\xa0\xa0Advanced Microsoft SQL Data Engineering\xa0T-SQL ScriptingMicrosoft SQL Server Reporting Services (SSRS) Experience\xa0Stored Procedures (Expert)\xa0NoSQL Databases: Redis, Cassandra, MongoDB']",Mid-Senior level,Contract,Information Technology,Hospital & Health Care,2020-11-05 11:32:32
Data Engineer ,Johnson & Johnson,"Spring House, PA",4 hours ago,Be among the first 25 applicants,"['', 'Job Description', ' Working experience in data science projects using predictive technologies, data mining and/or text mining of datasets in the clinical or healthcare domain is preferred.', ' Bachelors Degree in Bioinformatics, Statistics, Computer Science, Information Technology, Operation Research or a related discipline is required. Familiarity with machine learning techniques is required. Proficient with one or more programming language such as SQL, Python, R, or Java is required. Working knowledge of a cloud platform such as AWS is desirable. Experience in the use of a data science workbench is desirable. Working experience in data science projects using predictive technologies, data mining and/or text mining of datasets in the clinical or healthcare domain is preferred. Excellent communication, interpersonal, and written skills are required.', ' Bachelors Degree in Bioinformatics, Statistics, Computer Science, Information Technology, Operation Research or a related discipline is required.', ' Working knowledge of a cloud platform such as AWS is desirable.', 'Qualifications', ' Excellent communication, interpersonal, and written skills are required.', ' Implement data & analytics engineering strategy for R&D Data Science community. Partner closely with Janssen R&D IT and external partners for implementation and execution Work closely with R&D data scientists to design, build and implement data solutions to support R&D Data Science initiative with a focus on research and translational data Introduce/Lead/Participate in evaluations of algorithms, tools and technologies that enable R&D data science initiative', ' Experience in the use of a data science workbench is desirable.', ' Work closely with R&D data scientists to design, build and implement data solutions to support R&D Data Science initiative with a focus on research and translational data', ' Familiarity with machine learning techniques is required.', ' Implement data & analytics engineering strategy for R&D Data Science community. Partner closely with Janssen R&D IT and external partners for implementation and execution', ' Introduce/Lead/Participate in evaluations of algorithms, tools and technologies that enable R&D data science initiative', ' Proficient with one or more programming language such as SQL, Python, R, or Java is required.', 'The Data Engineer Will']",Not Applicable,Full-time,Information Technology,Hospital & Health Care,2020-11-05 11:32:32
Principal Data Engineer,Insight,"Detroit, MI",13 hours ago,Be among the first 25 applicants,"['', 'APPLY', 'We are looking for an experienced Senior Data Engineer ', 'Aggressively grow your skillset and expertise to meet emerging needs', 'Scripting: PowerShell, Azure Automation', 'Analysis Services (SSAS) and DAX', 'Fortune Top 100 Best Companies for Diversity', '30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizesMicrosoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOpsFortune Top 100 Best Companies for DiversityFortune Top 50 Best Workplaces in TechnologyWinner of several “Best Places to Work” awards30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Predictive Analytics: R, Azure Machine Learning ', 'Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity2+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala5+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)Strong analytical and reasoning skills that result in clear technical executionSkill at translating requirements into clean, efficient, quality code Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team', 'Prioritize, self-direct and execute at velocity', 'Fortune Top 50 Best Workplaces in Technology', 'Skill at translating requirements into clean, efficient, quality code ', 'Strong analytical and reasoning skills that result in clear technical execution', 'About Insight', 'Lead discussions with clients and recommend technical solutions for business cases', 'Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity', 'Winner of several “Best Places to Work” awards', 'Integration Services (SSIS)', 'Design and code modern solutions to tough data challenges leveraging the cloud and ', 'Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data Factory', 'Development Languages: .NET, Java or Scala', 'most', '5+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)', '2+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'SQL Server', 'Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team', 'Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externally', 'Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Design and develop cutting-edge enterprise data solutions in a fast-paced environmentLead discussions with clients and recommend technical solutions for business casesDesign and code modern solutions to tough data challenges leveraging the cloud and Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externallyPrioritize, self-direct and execute at velocityAggressively grow your skillset and expertise to meet emerging needs', 'Reporting Tools: Power BI, Tableau, Qlik, SSRS ', 'SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizes', 'Azure Big Data Technologies: Azure Data Lake and Azure Data Lake Analytics', 'Design and develop cutting-edge enterprise data solutions in a fast-paced environment', 'What We Do', 'What We Look For', 'Ready to join?', 'Big Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystem', 'What can Insight offer?', 'Microsoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOps', 'Requisition Number: 78957 ']",Mid-Senior level,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Data Engineer - BS/MS,Procter & Gamble,"Boston, MA",9 hours ago,Be among the first 25 applicants,"['', ' Support and collaborate with Data Scientists developing advanced machine learning and statistical models ', ' Strong data wrangling skills ', ' Familiarity with data privacy and data governance ', ' Overall G.P.A. of 3.0 or above on a 4.0 scale ', ' Familiarity with machine learning workflows (desirable) ', ' Experience with cloud services (AWS, Azure or GCP) ', 'Description', ' A BS or MS in Computer Science, Computer or Electrical Engineering, but we also consider other, similar engineering degree ', ' Experience with NoSQL databases ', ' Strong interpersonal communication and collaboration skills  History of working independently and effectively multi-tasking  Familiarity with machine learning workflows (desirable)  Have experience with sensors and IoT cloud architecture (desirable)  Familiarity with RESTful Application Programming Interface (API), containers and microservices  Familiarity with data privacy and data governance  Experience with NoSQL databases ', ' Hands on experience with relational databases and the use of SQL to extract and manipulate data ', ' Strong problem-solving skills paired with extensive experience programming (Python, Java, C++, etc...)  Strong data wrangling skills  Hands on experience with relational databases and the use of SQL to extract and manipulate data  Experience with cloud services (AWS, Azure or GCP) ', ' Familiarity with RESTful Application Programming Interface (API), containers and microservices ', ' Deliver optimal data solution architectures, automation and technology choices starting from experimentation through proof of concept and often through delivery ', 'Qualifications', ' Strong interpersonal communication and collaboration skills ', ' Develop and maintain scalable data pipelines that will ingest, transform, and distribute numerous data streams and batches in support of key R&D initiatives ', ' Have experience with sensors and IoT cloud architecture (desirable) ', ' History of working independently and effectively multi-tasking ', ' If you want to join us, you will need: ', 'We Are Also Looking For Someone Who Has', 'In this role you will:', ' Strong problem-solving skills paired with extensive experience programming (Python, Java, C++, etc...) ', ' Evaluate tools and develop pipelines to capture, integrate and clean data to support edge analytics solutions ', ' A BS or MS in Computer Science, Computer or Electrical Engineering, but we also consider other, similar engineering degree  Overall G.P.A. of 3.0 or above on a 4.0 scale ', ' Develop and maintain scalable data pipelines that will ingest, transform, and distribute numerous data streams and batches in support of key R&D initiatives  Support and collaborate with Data Scientists developing advanced machine learning and statistical models  Evaluate tools and develop pipelines to capture, integrate and clean data to support edge analytics solutions  Deliver optimal data solution architectures, automation and technology choices starting from experimentation through proof of concept and often through delivery ', 'The Ideal Candidate']",Not Applicable,Full-time,Research,Consumer Goods,2020-11-05 11:32:32
BI Data Engineer,Brooksource,"Indianapolis, IN",1 day ago,Be among the first 25 applicants,"['', 'Requirements & Qualifications', '· \xa0 \xa0 \xa0 \xa0Strong analytic skills related to working with structured and semi-structured datasets preferred ', 'Job Description ', ""Seeking a BI Data Engineer to be part of our client's Carmel, Indiana based Business Intelligence team. The growing, multi-billion dollar business is investing heavily in BI technology and people, and are hungry for data and analytics. We work in a collaborative, fast paced environment and are looking for individuals who are self-motivated and excited about the ever-evolving data and technology space. We are actively recruiting for multiple positions and willing to invest in training for the right candidates. "", 'Caramel, IN ', '· \xa0 \xa0 \xa0 \xa0Build analytics tools that provide actionable insights into customer acquisition and retention, operational efficiency, and other key business performance metrics ', '· \xa0 \xa0 \xa0 \xa0ETL and data pipeline experience preferred ', '· \xa0 \xa0 \xa0 \xa0Object-oriented/object function scripting language experience preferred (Python, Java, C++, Scala, R, etc.) ', '· \xa0 \xa0 \xa0 \xa0Intermediate data warehousing and mart experience ', '· \xa0 \xa0 \xa0 \xa0Strong project management and organizational skills ', '· \xa0 \xa0 \xa0 \xa0Cloud experience preferred ', '· \xa0 \xa0 \xa0 \xa0Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases ', '· \xa0 \xa0 \xa0 \xa0Build processes supporting data transformation, data structures, metadata, dependency and workload management ', 'o \xa0AWS (RDS / Aurora, Redshift, EMR, S3, Data Pipeline) ', '· \xa0 \xa0 \xa0 \xa0A successful history of manipulating, processing and extracting value from large disconnected datasets. ', '· \xa0 \xa0 \xa0 \xa0Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud based ‘big data’ technologies (Azure PaaS offerings preferred) ', 'o \xa0Azure (SQL Database, SQL Data Warehouse, HDInsight, Data Lake Store / Blob Storage, Data Factory) ', '· \xa0 \xa0 \xa0 \xa0Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader ', 'Caramel, IN', '· \xa0 \xa0 \xa0 \xa03+ years of data engineering experience in the context of data warehousing and BI ', '· \xa0 \xa0 \xa0 \xa0Big data technology experience preferred (Hadoop, Hive, Spark, etc.) ', '· \xa0 \xa0 \xa0 \xa0Opportunity to lead BI modernization in order satisfy our data starved business partners ', '· \xa0 \xa0 \xa0 \xa0Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement ', '· \xa0 \xa0 \xa0 \xa0Work with data and analytics experts to strive for greater functionality in our data systems ', '· \xa0 \xa0 \xa0 \xa0Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs ', '· \xa0 \xa0 \xa0 \xa0Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores preferred', ' ', 'BI Data Engineer', '· \xa0 \xa0 \xa0 \xa0Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. ', 'Job Description', 'In this role, you will collaborate with business partners, for assessing needs and gathering requirements, as well as with technical system owners, for determining data location and system specifications. This role will also require extensive data profiling and analysis, including the ability to provide interactive visualizations. This role will be expected to perform multiple functions, including data discovery and analysis, data modeling, data movement, and data transformation. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. ', 'Direct Hire ', 'BI Data Engineer ', '· \xa0 \xa0 \xa0 \xa0Self-motivated and committed to quality work ', 'Requirements & Qualifications ', 'Responsibilities & Duties ', 'Direct Hire', 'Responsibilities & Duties', '· \xa0 \xa0 \xa0 \xa0Advanced ability to visualize data (Tableau experience preferred) ']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Cloud Data Engineer,Zencon Group,"Austin, TX",12 hours ago,Be among the first 25 applicants,"['', 'Title: Cloud Data EngineerLocation: Austin, TX (Remote until COVID restrictions are lifted)Duration: Until 8/31/2021Job Type: ContractJob Description:', 'Minimum Requirements:']",Mid-Senior level,Contract,Information Technology,Government Administration,2020-11-05 11:32:32
"Machine Learning Engineer, 1+ Years Experience - Mountain View",Snap Inc.,"Mountain View, CA",5 hours ago,Over 200 applicants,"['', ' Experience in solving open ambiguous problems from end to end ', ' Experience working with machine learning, ranking infrastructures, and system designs ', ' Strong understanding of machine learning approaches and algorithms  Ability to prioritize tasks and work independently  Excellent verbal and written communication skills, with high attention to detail  Experience collaborating with internal and external stakeholders at all levels of a company  Experience in solving open ambiguous problems from end to end  Possesses a desire to learn and help others ', ' Create models which help drive value for users, advertisers, and our company ', ' Ability to proactively learn new concepts and apply them at work ', 'Minimum Qualifications', 'Preferred Qualifications', ' Experience with mobile apps and/or databases ', 'What You’ll Do', ' Create models which help drive value for users, advertisers, and our company  Evaluate the technical tradeoffs of every decision  Perform code reviews and ensure exceptional code quality  Build robust, lasting, and scalable products  Iterate quickly without compromising quality ', ' Excellent verbal and written communication skills, with high attention to detail ', ' Iterate quickly without compromising quality ', ' accommodations-ext@snap.com ', ' 1+ years ML industry experience or PhD in related field ', 'Knowledge, Skills & Abilities', ' BS/BA degree in technical field such as Computer Science, Mathematics, Statistics or equivalent years of experience  1+ years ML industry experience or PhD in related field ', 'Snapchat', ' Experience working with machine learning frameworks such as TensorFlow, Caffe2, PyTorch, Spark ML, scikit-learn, or related frameworks ', ' Perform code reviews and ensure exceptional code quality ', ' Ability to prioritize tasks and work independently ', 'Snap Engineering', ' Experience working with distributed systems ', ' Experience working with machine learning frameworks such as TensorFlow, Caffe2, PyTorch, Spark ML, scikit-learn, or related frameworks  Experience with mobile apps and/or databases  Experience working with distributed systems  M.S. degree and/or PhD in computer science or related field  Experience working with machine learning, ranking infrastructures, and system designs  Ability to proactively learn new concepts and apply them at work ', ' Strong understanding of machine learning approaches and algorithms ', ' Possesses a desire to learn and help others ', ' Evaluate the technical tradeoffs of every decision ', ' M.S. degree and/or PhD in computer science or related field ', ' our values', 'Our Benefits', ' Experience collaborating with internal and external stakeholders at all levels of a company ', ' BS/BA degree in technical field such as Computer Science, Mathematics, Statistics or equivalent years of experience ', ' Build robust, lasting, and scalable products ']",Entry level,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Tableau Consultant,Accenture,"Los Angeles, CA",10 hours ago,Be among the first 25 applicants,"['', 'You know your way around other data visualization toolsets such as Qlikview or Spotfire ', 'Here’s What You Need: ', 'Minimum of 2 year’s experience designing or developing with Tableau, including dashboards, reports, and/or front-end visualizations ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', 'You’re familiar with Business Intelligence tools including Cognos, Business Objects, OBIEE, methodologies, and/or responsibilities ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'You’re no newbie to Data Platforms such as Teradata, IBM, TM1, Netezza, DataMirror, Oracle, Essbase, GoldenGate, EMS, Greenplum', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Experience with database development including Custom SQL design, PLSQL, and/or Data Modeling ', 'Accenture Overview', 'Bonus Points If:', 'Equal Employment Opportunity:', 'Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'You’ve had experience with, or exposure to custom data visualization frameworks such as d3.js ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Accenture is committed to providing veteran employment opportunities to our service men and women. ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'You’ve got experience of full life-cycle development in a BI or Analytics environment ', 'The Work:', 'You Are:', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Business Development,Information Technology and Services,2020-11-05 11:32:32
Big Data Engineer,Client Company,"San Francisco, CA",8 hours ago,Be among the first 25 applicants,"['', 'Preferred Skills/exp', 'Must be able to work independently/no 3rd parties Seeking a Big Data Data Engineer to design, develop and document microservice and system components consisting of several objects working together to execute a business function of the larger system. Interact with software architects or other business/technical leaders to understand subsystems, component specifications and recommend changes to facilitate efficient and effective development. Interact with representatives of other cross functional teams to understand and/or recommend requirements and strategies for the project.As a Big Data Engineer You WouldWork with the business and IT team to understand business problems, and to design, implement, and deliver an appropriate solution using agile methodology across the larger program.Develops code and test artifacts that reuse subroutines or objects, is well structured, backed by automated tests, includes sufficient comments and is easy to maintain.Work independently to implement solutions on multiple platform (DEV, QA, UAT, PROD).Provide technical direction, leadership, and reviews to other engineers working on the same project.Implement and debug subsystems/microservice and components.Participate in integrated test sessions of components and subsystems on test and production servers.Follows automate-first/automate-everything philosophy.Determine and communicate the implications of system-level decisions on subsystems and components and help determine how best to mitigate or take advantage of these implications.Perform tasks efficiently and work together with team to ensure project success.Support management of the team’s technical infrastructure (e.g., repository, build system, testing system) under guidance from the systems engineer or another project leader.Hands on in multiple programming paradigms, Object Oriented, etc.Skills/expAt least 5 yrs of IT-Software/Software product developmentBachelor of Science-Computer Science or equivalent.Exp with Data Engineering languages and technologies - AWS Glue, Python, PySpark, Spark, Informatica, Git and Jenkins CI.SQL Server, Oracle, PostgreSQL and stored procedures.AWS Technologies - S3, AWS Glue, RDS, lambda and cloud watchDW concepts.Apache Kafka & Spark Streaming is nice to have.Preferred Skills/expExp across programming languages, patterns and data structures.Adequate hands on exp with data modeling, locks, database concurrency.Applied knowledge of Object Orientated programming concept (OOPS), Operating System (OS) concept.Proficient with software architecture, design patterns and strong demonstrated exp in building frameworks.Strong computer science background including distributed computing.Good knowledge of software development tools and methodologies.Good knowledge of secure coding practices is a plus.Thorough understanding and hands-on experience in the development of all layers of enterprise applications to analyze system scalability, integration, and performance issues as well as internationalization utilizing either Unicode and/or multi-byte databases.Good exposure of software development life cycle, development process flow and their tools usage.Must be aware of agile, incremental or spiral development methodology.Excellent diagnostic and troubleshooting skills, problem solving, and an ability to learn quickly.Domain knowledge in financial services is a plus.Good communication skill to articulate views/thoughts with team and partners or customers without any gap.Willingness and ability to learn new technologies.Expert knowledge of computer languages, data structures, program design methods and techniques.Ability to troubleshoot complex problems systematically.Self-motivated, thorough, and methodical.Overall knowledge of the computing environment at large, e.g. typical uses and user populations of operating systems, communications protocols, hardware platforms, etc.', 'Skills/exp', 'As a Big Data Engineer You Would']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Engineer,Foot Locker,"Chicago, IL",3 hours ago,Be among the first 25 applicants,"['', 'Performance analysis and tuning using SQL', 'Requires a Bachelor’s Degree in Computer Science, Management Information Systems or closely related field ', 'Experience with schema design and ongoing maintenance of transactional databases', 'Working with Hybris Ecommerce engine is a plus, along with tools like Go anywhere/control M knowledge would be a plus', 'Experience using Kafka or other data event publishing technologies', '1+ years of experience on either Mongo/Cosmos/Cassandra', '4+ experience on ETL tools like SSIS/ Talend and 2 year + on Data factory', 'Responsibilities', 'Analyze, design and build Integration solutions using open source products or Azure Web Services for transaction based systemsDevelop functional and design specifications for client data integration solutionsApply complex problem-solving skills using database management, data mapping, RESTFul APIs and Web Services skills to solve business data problemsBuild self-monitoring, robust, scalable data event handling system for near real time data updatesPerformance analysis and tuning using SQL', 'Passionate about data-driven approaches', '1+ years of experience with Microsoft Azure products', 'Strong SQL skills, including experience querying large, complex data sets and performance analysis', 'Click Here!', 'Develop functional and design specifications for client data integration solutions', 'Qualifications', 'Analyze, design and build Integration solutions using open source products or Azure Web Services for transaction based systems', 'Experience in Java, Python, or any other scripting languages', 'Strong experience with working in a high volume transactional databases using MySQL, SQL server; working knowledge using NoSQL databases is a plus', 'Overview', 'Should have good knowledge on azure back up and restore process along with dba activities with regards Mongo/Cassandra/MySQL', 'Apply complex problem-solving skills using database management, data mapping, RESTFul APIs and Web Services skills to solve business data problems', 'Requires a Bachelor’s Degree in Computer Science, Management Information Systems or closely related field 4+ years of experience on RDBMS system such as SQL Server /MySQL4+ experience on ETL tools like SSIS/ Talend and 2 year + on Data factory1+ years of experience with Microsoft Azure products1+ years of experience on either Mongo/Cosmos/CassandraStrong SQL skills, including experience querying large, complex data sets and performance analysisShould have good knowledge on azure back up and restore process along with dba activities with regards Mongo/Cassandra/MySQLWorking with Hybris Ecommerce engine is a plus, along with tools like Go anywhere/control M knowledge would be a plusStrong experience with working in a high volume transactional databases using MySQL, SQL server; working knowledge using NoSQL databases is a plusExperience using Kafka or other data event publishing technologiesExperience in Java, Python, or any other scripting languagesExperience with schema design and ongoing maintenance of transactional databasesPassionate about data-driven approaches', 'Build self-monitoring, robust, scalable data event handling system for near real time data updates', '4+ years of experience on RDBMS system such as SQL Server /MySQL']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Machine Learning Engineer - Comment Team,TikTok,"Mountain View, CA",19 hours ago,64 applicants,"['', '• Great communication and teamwork skills;', '• Work with cross-functional teams to deliver results.', '• Experience in a popular open source machine learning platform is a plus.', '• Bachelor or higher degree in computer science or a related technical discipline, with 2+ years of industrial experience;', 'Qualifications', '• Develop highly-scalable classifiers, models and algorithms, and tools to filter bad contents which violate our community guidelines;', '• Solid coding skills and a good understanding of algorithms;', '• Understand product objectives and take full advantage of modern machine learning and NLP techniques to improve comment user experience;', ""Responsibilities - What You'II Do"", '• Passion about techniques and solving challenging problems;', 'TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at usrc@tiktok.com.', '• Solid experience in at least one of the following areas: machine learning, NLP, or data mining;', ""In TikTok's Comment team, you’ll have the opportunity to build a modern machine learning system on our large-scale data. Our team is responsible for comment systems, content safety, and comment ranking to provide the best comment user experience for all TikTok users."", 'TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.', ""TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too.""]",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Senior Data Scientist,Virgin Pulse,"Providence, RI",7 hours ago,Be among the first 25 applicants,"['', ' Leverage existing studies, literature, and analyses into current research and analysis projects ', ' Conduct ad-hoc analysis using varied analytical tools and techniques, including advanced statistics ', ' A Master’s degree in statistics, computer science, economics, or related field; further Advanced degree is a plus ', ' Troubleshoot and perform  data  audits to ensure and improve  data  integrity; investigate and resolve  data  discrepancies ', ' Comfort working in a global environment with remote teams ', ' Employee health management/health engagement industry preferred ', 'We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to any protected class status.', ' Experience with clinical/medical data and work in employee health management/health engagement industry preferred ', 'Responsibilities', ' Creative energy, self-starter, works equally well independently and collaboratively ', ' Work with Insights departmental processes, projects and programs using Smartsheet, MS and Atlassian toolsets to keep projects and milestones on schedule, our collaborative and internal work organized as well as externally facing documentation comprehensive, updated, and accessible ', 'Minneapolis, MN', ' Strong analytical ability, with an emphasis on quantitative analysis, descriptive and inferential statistics ', ' Aptitude to learn new technologies and troubleshoot complex problems independently ', ' Consult to and collaborate with Product, Reporting, Analytics and Client Success team members to ensure appropriate data is analyzed and that results are provided in a format consistent with standard and customized client reporting services ', ' Write Python, R and SQL programs to access, clean, and transform required data prior to analysis and reporting ', 'Options', ' Design, conduct and manage new analytical research projects and experiments, starting with project planning, hypothesis development and data gathering, then to analysis and modeling, and through to communications and recommendations ', ' Experience in managing medium and large-scale analytics projects from end to end ', 'To Represent The Best Of What We Have To Offer, You Come To Us With a Multitude Of Positive Attributes, Including', ' Excellent communication and organization skills with the ability to manage competing priorities, meet deadlines, and process ad-hoc requests ', ' Design, conduct and manage new analytical research projects and experiments, starting with project planning, hypothesis development and data gathering, then to analysis and modeling, and through to communications and recommendations  Leverage existing studies, literature, and analyses into current research and analysis projects  Write Python, R and SQL programs to access, clean, and transform required data prior to analysis and reporting  Troubleshoot and perform  data  audits to ensure and improve  data  integrity; investigate and resolve  data  discrepancies  Develop and deliver analysis results using various visualization and presentation software/tools, such as R/Toolkit, Tableau, MS Powerpoint, MS Word, etc.  Consult to and collaborate with Product, Reporting, Analytics and Client Success team members to ensure appropriate data is analyzed and that results are provided in a format consistent with standard and customized client reporting services  Conduct ad-hoc analysis using varied analytical tools and techniques, including advanced statistics  Support Sales, Marketing, and Client Success staff with Virgin Pulse clients and prospects by directly communicating on data and analytics processes and projects, as well as the results of analyses  Work with Insights departmental processes, projects and programs using Smartsheet, MS and Atlassian toolsets to keep projects and milestones on schedule, our collaborative and internal work organized as well as externally facing documentation comprehensive, updated, and accessible  Achieve annual Key Performance Indicator objectives, which can include report volumes and scope, internal and external client satisfaction, introducing new areas of data and analysis, and influencing company product and process decisions ', ' Experience with producing and delivering results using varied media (i.e. multiple MS office formats, dashboards/visualization tools) ', ' Develop and deliver analysis results using various visualization and presentation software/tools, such as R/Toolkit, Tableau, MS Powerpoint, MS Word, etc. ', 'Qualifications', ' Strong organizing and coordination of work products, documents, and content for publication and distribution ', ' Experience in providing consultative guidance and contributing to the growth and development of others ', ' Flexibility and ability to adapt to changes in priority quickly and seamlessly ', 'Overview', 'Skills', ' Experience working with large-scale datasets and multiple projects simultaneously ', ' Knowledge of data visualization tools preferred (i.e. Tableau, R: Shiny, ggplot2) ', ' A Master’s degree in statistics, computer science, economics, or related field; further Advanced degree is a plus  A minimum of seven years of work experience in a similar path, history of increasing responsibilities a plus ;  Employee health management/health engagement industry preferred  Advanced knowledge and recent hands-on experiences in SQL databases, Redshift preferred  Extensive experience coding in at least one scripting language, such as R or Python  Knowledge of data visualization tools preferred (i.e. Tableau, R: Shiny, ggplot2)  Experience with producing and delivering results using varied media (i.e. multiple MS office formats, dashboards/visualization tools)  Experience in managing medium and large-scale analytics projects from end to end  Experience with clinical/medical data and work in employee health management/health engagement industry preferred  Comfort working in a global environment with remote teams ', ' Strong collaboration, process and project management skills  Strong analytical ability, with an emphasis on quantitative analysis, descriptive and inferential statistics  Experience working with large-scale datasets and multiple projects simultaneously  Aptitude to learn new technologies and troubleshoot complex problems independently  Creative energy, self-starter, works equally well independently and collaboratively  Flexibility and ability to adapt to changes in priority quickly and seamlessly  Strong organizing and coordination of work products, documents, and content for publication and distribution  Excellent communication and organization skills with the ability to manage competing priorities, meet deadlines, and process ad-hoc requests  Experience in providing consultative guidance and contributing to the growth and development of others ', ' Strong collaboration, process and project management skills ', ' Who you are ', ' A minimum of seven years of work experience in a similar path, history of increasing responsibilities a plus ; ', ' Advanced knowledge and recent hands-on experiences in SQL databases, Redshift preferred ', ' data ', 'Providence, RI', ' Achieve annual Key Performance Indicator objectives, which can include report volumes and scope, internal and external client satisfaction, introducing new areas of data and analysis, and influencing company product and process decisions ', 'Remote', ' In addition, you possess the following additional competencies and characteristics: ', ' Extensive experience coding in at least one scripting language, such as R or Python ', ' Support Sales, Marketing, and Client Success staff with Virgin Pulse clients and prospects by directly communicating on data and analytics processes and projects, as well as the results of analyses ']",Associate,Full-time,Other,Computer Software,2020-11-05 11:32:32
Data Engineer,PulsePoint,"New York, NY",1 day ago,42 applicants,"['', 'BA/BS degree in Computer science or related field', 'Complimentary annual memberships to One Medical, NY Citi Bike and SF Ford GoBike', 'Emergency childcare credits', 'Hive - SQL data warehouse layer for data in HDFS', 'Design, build and maintain reliable and scalable enterprise level distributed transactional data processing systems for scaling the existing business and supporting new business initiatives', 'Ingest, validate and process internal & third party data', 'Team lunches, Sip & Social Thursdays, Game Nights, Movie Nights', 'Design, build and maintain reliable and scalable enterprise level distributed transactional data processing systems for scaling the existing business and supporting new business initiativesOptimize jobs to utilize Kafka, Hadoop, Presto, Spark Streaming and Kubernetes resources in the most efficient wayMonitor and provide transparency into data quality across systems (accuracy, consistency, completeness, etc)Increase accessibility and effectiveness of data (work with analysts, data scientists, and developers to build/deploy tools and datasets that fit their use cases)Collaborate within a small team with diverse technology backgroundsProvide mentorship and guidance to junior team members', 'Kafka- distributed commit log storage\xa0', 'And there’s a lot more!', 'Impala- faster SQL layer on top of Hive', 'Strong understanding of RDBMS, SQL;', 'Airflow - for job scheduling', 'Required Skills:', 'Healthy snacks and drinks', '401(k) Match and free access to a financial advisorGenerous paid vacation/company holidaysVacation reimbursement (we give you $500 to take vacation), sabbatical, pawternity leave, marriage leave, honeymoon bonusComprehensive healthcare with 100%-paid medical, vision, life & disability insurance$2,000 annual training and development budgetComplimentary annual memberships to One Medical, NY Citi Bike and SF Ford GoBikeMonthly chair massagesFree fitness classes (spin, yoga, boxing)Gym reimbursement, local gym membership discountsOnsite flu shots, dental cleanings and vision examsAnnual company retreatPaid parental leave and a lot of new parent perksEmergency childcare creditsVolunteer Time Off and Donation Matching, ongoing group volunteer opportunitiesTeam lunches, Sip & Social Thursdays, Game Nights, Movie NightsHealthy snacks and drinks', 'Team Responsibilities:', 'Installation, upkeep, maintenance and monitoring of Kafka, Hadoop, Presto, RDBMS', 'Collaborate within a small team with diverse technology backgrounds', '\xa0', '24*7 On call rotation for Production support', 'Graphite/Beacon - for monitoring data flows', 'Fluency in Python, Experience in Scala/Java is a huge plus', 'Docker - Packaged container image with all dependencies', 'PulsePoint Data Engineering team plays a key role in our technology company that’s experiencing exponential growth. Our data pipeline processes over 80 billion impressions a day (> 20TB of data, 220 TB uncompressed). This data is used to generate reports, update budgets, and drive our optimization engines. We do all this while running against extremely tight SLAs and provide stats and reports as close to real-time as possible.', 'Willingness to participate in 24x7 on-call rotation', 'Annual company retreat', 'Comprehensive healthcare with 100%-paid medical, vision, life & disability insurance', 'Free fitness classes (spin, yoga, boxing)', 'Knowledge and exposure to Cloud migration is a plus', 'Maintain and enhance framework for jobs(primarily aggregate jobs in Hive)\xa0', 'Backups/Retention/High Availability/Capacity Planning', 'Installation, upkeep, maintenance and monitoring of Kafka, Hadoop, Presto, RDBMSIngest, validate and process internal & third party dataCreate, maintain and monitor data flows in Hive, SQL and Presto for consistency, accuracy and lag timeMaintain and enhance framework for jobs(primarily aggregate jobs in Hive)\xa0Create different consumers for data in Kafka using Spark Streaming for near time aggregationTrain Developers/Analysts on tools to pull dataTool evaluation/selection/implementationBackups/Retention/High Availability/Capacity PlanningReview/Approval - DDL for database, Hive Framework jobs and Spark Streaming to make sure they meet our standards24*7 On call rotation for Production support', 'Presto - fast parallel data warehouse and data federation layer', 'Knowledge and exposure to distributed production systems i.e Hadoop is a huge plus', 'Tool evaluation/selection/implementation', 'What we offer:', 'Train Developers/Analysts on tools to pull data', 'Monthly chair massages', 'Passion for engineering and computer science around data', 'Gym reimbursement, local gym membership discounts', 'Provide mentorship and guidance to junior team members', 'BA/BS degree in Computer science or related field5+ years of software engineering experienceKnowledge and exposure to distributed production systems i.e Hadoop is a huge plusKnowledge and exposure to Cloud migration is a plusProficiency in LinuxFluency in Python, Experience in Scala/Java is a huge plusStrong understanding of RDBMS, SQL;Passion for engineering and computer science around dataWillingness to participate in 24x7 on-call rotation', 'Optimize jobs to utilize Kafka, Hadoop, Presto, Spark Streaming and Kubernetes resources in the most efficient way', 'Generous paid vacation/company holidays', '$2,000 annual training and development budget', 'Onsite flu shots, dental cleanings and vision exams', 'Spark Streaming - Near time aggregation', 'Create different consumers for data in Kafka using Spark Streaming for near time aggregation', 'SQL Server - Reliable OLTP RDBMS\xa0', 'The most exciting part about working at PulsePoint is the enormous potential for personal and professional growth. We are always seeking new and better tools to help us meet challenges such as adopting proven open-source technologies to make our data infrastructure more nimble, scalable and robust.\xa0Some of the cutting edge technologies we have recently implemented are Kafka, Spark Streaming, Presto, Airflow, and Kubernetes.\xa0\xa0', 'Paid parental leave and a lot of new parent perks', 'Kubernetes - Distributed cluster resource manager', 'Vacation reimbursement (we give you $500 to take vacation), sabbatical, pawternity leave, marriage leave, honeymoon bonus', 'Volunteer Time Off and Donation Matching, ongoing group volunteer opportunities', 'Increase accessibility and effectiveness of data (work with analysts, data scientists, and developers to build/deploy tools and datasets that fit their use cases)', 'Create, maintain and monitor data flows in Hive, SQL and Presto for consistency, accuracy and lag time', 'Airflow - for job schedulingDocker - Packaged container image with all dependenciesGraphite/Beacon - for monitoring data flowsHive - SQL data warehouse layer for data in HDFSImpala- faster SQL layer on top of HiveKafka- distributed commit log storage\xa0Kubernetes - Distributed cluster resource managerPresto - fast parallel data warehouse and data federation layerSpark Streaming - Near time aggregationSQL Server - Reliable OLTP RDBMS\xa0Sqoop - Import/Export data to RDBMS', 'Review/Approval - DDL for database, Hive Framework jobs and Spark Streaming to make sure they meet our standards', 'Sqoop - Import/Export data to RDBMS', 'Technologies We Use:', '401(k) Match and free access to a financial advisor', 'Proficiency in Linux', ""What you'll be doing:"", '5+ years of software engineering experience', 'Monitor and provide transparency into data quality across systems (accuracy, consistency, completeness, etc)']",Mid-Senior level,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Senior Data Engineer,Credera,"Houston, TX",13 hours ago,Be among the first 25 applicants,"['', ' Candidate with 5+ years of experience in a Data Engineering role Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field Experience building and optimizing data pipelines and data architecture Experience with wrangling, exploring, and analyzing data to answer specific business questions and identify opportunities for improvement Strong project management and organizational skills Consulting experience is preferred The ideal candidate will have working knowledge of the following: Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.)   Experience with one or more of the following cloud service providers: AWS cloud services Google Cloud Platform Azure cloud services   ', 'Scripting languages (e.g. Python, Java, C++, Scala, etc.)', 'Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.)', 'Stream-processing systems (e.g. Storm, Spark-Streaming, etc.)', ' Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.) ', 'Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.)', ' QUALIFICATIONS: Candidate with 5+ years of experience in a Data Engineering role Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field Experience building and optimizing data pipelines and data architecture Experience with wrangling, exploring, and analyzing data to answer specific business questions and identify opportunities for improvement Strong project management and organizational skills Consulting experience is preferred The ideal candidate will have working knowledge of the following: Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.)   Experience with one or more of the following cloud service providers: AWS cloud services Google Cloud Platform Azure cloud services     ', 'QUALIFICATIONS: Candidate with 5+ years of experience in a Data Engineering role Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field Experience building and optimizing data pipelines and data architecture Experience with wrangling, exploring, and analyzing data to answer specific business questions and identify opportunities for improvement Strong project management and organizational skills Consulting experience is preferred The ideal candidate will have working knowledge of the following: Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.)   Experience with one or more of the following cloud service providers: AWS cloud services Google Cloud Platform Azure cloud services    ', 'Strong project management and organizational skills', 'Candidate with 5+ years of experience in a Data Engineering role', 'The ideal candidate will have working knowledge of the following: Big data tools (e.g. Hadoop, Spark, Kafka, etc.) Relational SQL and NoSQL databases (e.g. Postgres, MySQL, SQL Server, Cassandra, MongoDB, etc.) Data pipeline and workflow management tools (e.g. Azkaban, Oozie, Luigi, Airflow, etc.) Stream-processing systems (e.g. Storm, Spark-Streaming, etc.) Scripting languages (e.g. Python, Java, C++, Scala, etc.) Container Orchestration (e.g. Kubernetes, Docker, etc.)  ', 'AWS cloud services', 'voluntary', 'LEARN MORE:', 'Experience with wrangling, exploring, and analyzing data to answer specific business questions and identify opportunities for improvement', 'Experience with one or more of the following cloud service providers: AWS cloud services Google Cloud Platform Azure cloud services  ', 'U.S. Equal Opportunity Employment Information (Completion is voluntary)', 'Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field', 'We do not currently commence ""sponsor"" immigration cases in order to employ candidates.', 'Container Orchestration (e.g. Kubernetes, Docker, etc.)', 'Big data tools (e.g. Hadoop, Spark, Kafka, etc.)', 'Along with a great company culture, Credera provides an outstanding compensation package including a competitive salary and a comprehensive benefit plan (e.g., medical, dental, disability, matching 401k, PTO, etc.). This position is an exempt position.', 'Google Cloud Platform', 'Consulting experience is preferred', 'Travel: ', 'Experience building and optimizing data pipelines and data architecture', 'Azure cloud services', ' AWS cloud services Google Cloud Platform Azure cloud services ']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Engineer,Apex Systems,"Milwaukee, WI",9 hours ago,Be among the first 25 applicants,"['', ' Experience with pipeline\\ETL tooling such as MS SQL Server Integration Services (SSIS), Azure Data Factory, AWS Glue, PowerBI Dataflows, Informatica Data Integration, etc.', ' Design, build, and support data pipelines to facilitate BI and Analytic solutions among our team (e.g. ETL) Support establishing a self-service BI data environment including data sourcing, modeling and distribution for consumption by citizen BI developers. Accountable for ensuring data within our store meets quality and security requirements. Build consensus and trust with partnered organizations on future state patterns. Drive the sharing of standards on our team and the greater community through coaching, mentoring, and articles around core methodologies and processes. Build reports/dashboards for consumption within our team using BI tooling; such as Tableau or Power BI. Collecting data systematically and consider a broad range of issues or factors to promote sustainability of the dataset.', ' Support establishing a self-service BI data environment including data sourcing, modeling and distribution for consumption by citizen BI developers.', ' Working with a range of data sources Traditional DBMS (MS SQL, IBM DB2, etc.), No SQL DBMS (e.g. Mongo), Flat Files (csv,xls,etc.), Web (XML, JSON, etc.)', ' Strong customer/client orientation.', ' Bachelors degree in Computer Science, MIS, or direct experience will be considered.', ' Design, build, and support data pipelines to facilitate BI and Analytic solutions among our team (e.g. ETL)', ' Can execute alone but is a collaborative teammate.', ' Accountable for ensuring data within our store meets quality and security requirements.', ' Collecting data systematically and consider a broad range of issues or factors to promote sustainability of the dataset.', ' Knowledge of pipeline\\ETL development standard methodologies for batch and near real-time integrations.', ' Bachelors degree in Computer Science, MIS, or direct experience will be considered. 5-8 years of professional experience in data. Strong SQL background including writing and solving complexity within SQL code and performance tuning. Working with a range of data sources Traditional DBMS (MS SQL, IBM DB2, etc.), No SQL DBMS (e.g. Mongo), Flat Files (csv,xls,etc.), Web (XML, JSON, etc.) Knowledge of pipeline\\ETL development standard methodologies for batch and near real-time integrations. Experience with pipeline\\ETL tooling such as MS SQL Server Integration Services (SSIS), Azure Data Factory, AWS Glue, PowerBI Dataflows, Informatica Data Integration, etc. Grasp of APIs (SOAP and REST). Solid grasp on summarizing technical situations into concise and meaningful proposals. Embraces continuous learning, curiosity, experimentation, and ambiguity. Strong customer/client orientation. Can execute alone but is a collaborative teammate.', ' Strong SQL background including writing and solving complexity within SQL code and performance tuning.', ' Build consensus and trust with partnered organizations on future state patterns.', ' Build reports/dashboards for consumption within our team using BI tooling; such as Tableau or Power BI.', ' Solid grasp on summarizing technical situations into concise and meaningful proposals.', 'Requirements', ' Grasp of APIs (SOAP and REST).', ' Embraces continuous learning, curiosity, experimentation, and ambiguity.', 'Job Responsibilities', ' Drive the sharing of standards on our team and the greater community through coaching, mentoring, and articles around core methodologies and processes.', ' 5-8 years of professional experience in data.']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,ClearedJobs.Net,"Chantilly, VA",8 hours ago,Be among the first 25 applicants,"['', 'Develop technical documentation and standard operating procedures', 'Design, develop, implement and maintain data ingestion process from various disparate datasets using StreamSets (experience with StreamSets not mandatory)', 'Knowledge Skills And Abilities', 'Basic Qualifications', 'Develop processes to identify data drift and malformed records', 'Ability to multi-task', 'Leads technical tasks for small teams or projects', 'Experience with messages systems like Kafka', 'Experience with NoSQL and/or graph databases like MongoDB or ArangoDB', 'Excellent use and understanding of data engineering concepts, principles, and theories', 'Creative thinker', 'Clearance Requirements', 'Representative Duties And Tasks', 'General Dynamics Mission Systems (GDMS)', 'Working experience with ETL processing', 'Experience with Hadoop and Hive/Impala', 'Understanding of pySpark Leadership experience', 'Working experience with Python RESTful API services, JDBC', 'Any of the following databases: SQL, MongoDB, Oracle, Postgres', 'Working experience with data workflow products like StreamSets or NiFi', 'Experience with Cloudera Data Science Workbench is a plus', 'Company Overview']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
2021 University Graduate - Application Security Researcher,Adobe,"San Jose, CA",5 hours ago,115 applicants,"['', 'Perform architecture review and threat modeling for our world-class products and services built on cloud platforms. ', 'Bachelor’s degree in computer science, engineering or a related discipline and 3 - 4 years of experience in a similar role; Master’s degree in computer science, engineering or a related discipline and 1 - 2 years of experience in similar role; Doctorate degree in computer security. ', 'Check-In', 'Preferred Qualifications', 'Clear understanding of security concepts e.g., Authentication, Authorization. ', 'Understanding of industry best practices in Application security. ', 'Familiarity with security issues in mobile and desktop applications. ', 'Knowledge of emerging threats, mitigations and industry trends. ', 'Basic Qualifications', 'Perform architecture review and threat modeling for our world-class products and services built on cloud platforms. Enumerate security risks and the controls to mitigate them. Research new technologies and present security best practices to product teams. Guide teams on adoption and execution of a Secure Product Life Cycle. ', 'What You’ll Do', 'https://blogs.adobe.com/security', 'Bachelor’s degree in computer science, engineering or a related discipline and 3 - 4 years of experience in a similar role; Master’s degree in computer science, engineering or a related discipline and 1 - 2 years of experience in similar role; Doctorate degree in computer security. Clear understanding of security concepts e.g., Authentication, Authorization. Deep knowledge of application security vulnerabilities (OWASP Top 10) and mitigation techniques. ', 'Best Companies lists', 'Self-motivated and results-oriented, with excellent interpersonal and verbal and written communication skills. ', 'Basic understanding of concepts relevant to public cloud providers e.g., AWS, Azure, GCP. ', 'Deep knowledge of application security vulnerabilities (OWASP Top 10) and mitigation techniques. ', 'Experience in threat modeling complex distributed web applications and microservices. ', 'Knowledge of emerging threats, mitigations and industry trends. Familiarity with security issues in mobile and desktop applications. Basic understanding of concepts relevant to public cloud providers e.g., AWS, Azure, GCP. 1-2 years of experience in Java or Python. ', 'Our Company', 'Guide teams on adoption and execution of a Secure Product Life Cycle. ', 'Adobe is an equal opportunity and affirmative action employer. We welcome and encourage diversity in the workplace regardless of gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other characteristics protected by law.', '1-2 years of experience in Java or Python. ', 'Build tools to automate security checks across Adobe Products. ', 'Research new technologies and present security best practices to product teams. ', 'Deep knowledge of web protocols and standards. ', 'Experience in threat modeling complex distributed web applications and microservices. Deep knowledge of web protocols and standards. Understanding of industry best practices in Application security. ', 'Enumerate security risks and the controls to mitigate them. ']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
User Experience Researcher,The Judge Group,Greater Minneapolis-St. Paul Area,22 hours ago,Be among the first 25 applicants,"[' Qualifications & Requirements: ', 'At least 7 years of experience working in a UX Research / Usability related role\xa0 Experience gathering insights and validating solutionss using quantitative and qualitative research methods. Ability to createg research roadmaps, journey maps, personas, research plans, moderator guides, and research reports Experence managing multiple research requests\xa0 Experience and desire to mentor and lead junior team members ', 'Advocate for user research principles\xa0 ', 'Work with product teams to identify and prioritize user research requirements, including timelines, scope, and methodologies. ', 'Experience gathering insights and validating solutionss using quantitative and qualitative research methods. ', 'Job Description: ', 'Ability to createg research roadmaps, journey maps, personas, research plans, moderator guides, and research reports ', 'At least 7 years of experience working in a UX Research / Usability related role\xa0 ', 'Collaborate with product teams to develop research goals, identify tasks and scenarios, and establish a test environment\xa0 ', 'Experience and desire to mentor and lead junior team members ', 'Establish research and usability metrics strategies for project teams', 'Design, conduct, analyze, and report data gathered from qualitative and quantitative research techniques including key-stroke level modeling (KLM), usability testing, contextual inquiry / field studies, surveys, interviews, heuristic evaluations, focus groups, card sorts, ethnography and persona development, and rapid iterative testing within an Agile environment.\xa0 ', 'Create and deliver test result reports including statistical analysis\xa0 ', 'Experence managing multiple research requests\xa0 ', 'Qualifications & Requirements:', 'Design, conduct, analyze, and report data gathered from qualitative and quantitative research techniques including key-stroke level modeling (KLM), usability testing, contextual inquiry / field studies, surveys, interviews, heuristic evaluations, focus groups, card sorts, ethnography and persona development, and rapid iterative testing within an Agile environment.\xa0 Work with product teams to identify and prioritize user research requirements, including timelines, scope, and methodologies. Collaborate with product teams to remediate issues identified from research\xa0 Advocate for user research principles\xa0 Collaborate with product teams to develop research goals, identify tasks and scenarios, and establish a test environment\xa0 Create and deliver test result reports including statistical analysis\xa0 Establish research and usability metrics strategies for project teams', 'Collaborate with product teams to remediate issues identified from research\xa0 ', 'contract to hire', ' ', 'Job Description', 'If you are an experienced UX Researcher looking for an opportunity to join an amazing team with fantastic leadership please reach out!\xa0\xa0 ', 'Senior / Lead UX Resarcher', 'If you are an experienced UX Researcher looking for an opportunity to join an amazing team with fantastic leadership please reach out!\xa0\xa0']",Mid-Senior level,Full-time,Design,Hospital & Health Care,2020-11-05 11:32:32
Lead Quantitative Execution Researcher,Selby Jennings,"New York, NY",1 day ago,130 applicants,"['Expert in Python', '4+ years of execution      research or trading experience at a top tier financial institution ', 'This firm is looking to add a Quantitative Execution Researcher to the team. This person would lead the build-out of their execution business, conducting transaction cost analysis and performing other execution-related research while also contributing to alpha generation. The ideal candidate would have 4+ years of experience with being hands-on with execution, some exposure to alpha research, and a strong academic background. This is an excellent opportunity to have a very impactful role within an elite team of a growing firm. ', 'Experience with alpha      research and generation a strong plus ', 'Advanced degree in a      quantitative field, PhD preferred in hard sciences (i.e. physics,      mathematics, computer science) ', ' Advanced degree in a      quantitative field, PhD preferred in hard sciences (i.e. physics,      mathematics, computer science)  4+ years of execution      research or trading experience at a top tier financial institution  Experience with alpha      research and generation a strong plus  Software engineering      background a plus  Expert in Python', 'Software engineering      background a plus ', 'Quantitative Execution Researcher', 'Qualifications: ', '\xa0 ']",Mid-Senior level,Full-time,Research,Financial Services,2020-11-05 11:32:32
Senior Applied Researcher,eBay,"San Jose, CA",1 day ago,Be among the first 25 applicants,"['', '- Experience with Python or R, and Java or Scala.\xa0', 'We are looking for stellar applied researchers to join us and build the next generation of content understanding technologies in eBay search. If you enjoy the scale and technical complexity of NLP problems and want to be at the frontier of applied research in information retrieval in e-commerce, join now.', 'Basic Qualifications', '- Work through others as a technical leader to drive vision, define and standardize methodologies, establish processes, and operationalize machine learning solutions across teams and projects', 'eBay Inc. is an equal opportunity employer.\xa0 All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status.\xa0 If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com.\xa0 We will make every effort to respond to your request for disability assistance as soon as possible.', 'View our accessibility info', 'accessibility info', '- Experience in big data processing, e.g. Hadoop, SQL, Spark', '- Strong Industrial experience with one or more of the following: classification, regression, recommendation systems, targeting systems, ranking systems, fraud detection, online advertising, or related', '- Seek scientific solutions to multiple complex and ambiguous problems by crafting a technical vision and driving consensus across teams', 'This website uses cookies to enhance your experience. By continuing to browse the site, you agree to our\xa0use of cookies', '- Present key technical and novel research work in public forums and conferences', 'For more information see:', '- 2 or more related publications in quality conferences or journals', 'Looking to make an impact on the future of global commerce? Do you want to shape how millions of people buy, sell, and engage around the world?', '- Think through complex research problems, simplify where necessary, invent when needed, to drive a principled vision from thought to reality', '- Mentor junior team members', 'EEO is the Law Poster', 'Job Responsibilities', 'View our privacy policy', 'The Search Content, Item and Inventory Understanding team is part of the biggest organization that drives eBay’s world-wide impact. We innovate at the heart of ecommerce search, with the ambitious goal of redefining ecommerce search. We craft optimized experiences for buyers and sellers on eBay. We innovate rapidly in this space and there is no shortage of new challenges for motivated individuals.', '- 5-8 years (with PhD) or 8-12 years (with MS) of industrial experience in a related field', 'EEO is the Law Poster Supplement', '- MS or PhD in Computer Science, Statistics, Mathematics, or equivalent']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
"Researcher, Health Communication & Behavior Change Communication",Fors Marsh Group,"Arlington, VA",8 hours ago,Be among the first 25 applicants,"['', 'Supporting the design, execution, and management of projects employing quantitative and qualitative data analysisAssisting in the development of surveys and supporting materials including study protocols, data analysis plans, and quality control plansIndependently applying a variety of analysis types from fields such as statistics, survey methodology, and/or other social science disciplines (e.g., univariate analyses, ANOVA, regression)Interpreting study results to identify patterns and solutions; converting complex data and findings into understandable tables, charts, and written reportsPreparing research reports, briefs, presentation decks, and other external communications summarizing research methods, findings, and implications for marketing strategies and advertising messaging. Tailoring these materials for non-technical audiencesSupporting projects employing qualitative design, data collection, and analysis methods. Lead or contribute to the creation of study protocols, developing interview and moderator guides, protocol testing, and quality control plansOverseeing project tasks and collaborating with project team on a day-to-day basis to work under tight deadlines to fulfill client requestsBalancing roles and responsibilities across multiple concurrent studies and/or tasksAnticipating potential barriers to project completion, proposing solutions to team leadership', 'Preparing research reports, briefs, presentation decks, and other external communications summarizing research methods, findings, and implications for marketing strategies and advertising messaging. Tailoring these materials for non-technical audiences', 'Experience conducting message or concept testing', 'Experience with data visualization tools and techniques to present data in different forms', 'Applicants may be subject to a low-level government security investigation and must meet eligibility criteria for access to sensitive information', 'Independently applying a variety of analysis types from fields such as statistics, survey methodology, and/or other social science disciplines (e.g., univariate analyses, ANOVA, regression)', 'Interpreting study results to identify patterns and solutions; converting complex data and findings into understandable tables, charts, and written reports', 'Strong proficiency and experience working with and interpreting data in at least one quantitative statistical analysis software package (e.g., SPSS, STATA, SAS) and Microsoft Excel', 'Advanced degree (MA, MS, PhD)', 'Strong knowledge of syntax/code in statistical software packages', 'Supporting projects employing qualitative design, data collection, and analysis methods. Lead or contribute to the creation of study protocols, developing interview and moderator guides, protocol testing, and quality control plans', 'A highly collegial and intellectually stimulating work environment.A company culture promoting work/life balance.Highly competitive benefit/compensation package.', 'Experience presenting statistical analysis results to groups with non-data backgrounds', 'Experience working with government agencies such as FDA, CDC, CPSC, HHS, or similar preferred', 'Balancing roles and responsibilities across multiple concurrent studies and/or tasks', 'Experience in applied research as part of a government contract', 'Minimum of three years of professional research experience required', 'Assisting in the development of surveys and supporting materials including study protocols, data analysis plans, and quality control plans', 'Anticipating potential barriers to project completion, proposing solutions to team leadership', 'A company culture promoting work/life balance.', 'Experience with qualitative and quantitative data collection and analysis.', 'Supporting the design, execution, and management of projects employing quantitative and qualitative data analysis', 'BA/BS degree in communication, social science, public health, or related field, Advanced degree preferredMinimum of three years of professional research experience requiredExperience conducting message or concept testingExperience with qualitative and quantitative data collection and analysis.Strong proficiency and experience working with and interpreting data in at least one quantitative statistical analysis software package (e.g., SPSS, STATA, SAS) and Microsoft ExcelExperience presenting statistical analysis results to groups with non-data backgroundsExperience with data visualization tools and techniques to present data in different formsAbility to work well with others, as well as independently under minimal supervisionStrong verbal and written communications skillsApplicants may be subject to a low-level government security investigation and must meet eligibility criteria for access to sensitive information', 'Native-level Spanish fluency', 'Overseeing project tasks and collaborating with project team on a day-to-day basis to work under tight deadlines to fulfill client requests', 'Advanced degree (MA, MS, PhD)Native-level Spanish fluencyStrong knowledge of syntax/code in statistical software packagesProficiency with NVIVO or other qualitative analysis programsExperience in applied research as part of a government contractExperience working with government agencies such as FDA, CDC, CPSC, HHS, or similar preferred', 'A highly collegial and intellectually stimulating work environment.', 'Ability to work well with others, as well as independently under minimal supervision', 'BA/BS degree in communication, social science, public health, or related field, Advanced degree preferred', 'Proficiency with NVIVO or other qualitative analysis programs', 'Strong verbal and written communications skills', 'Highly competitive benefit/compensation package.']",Associate,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Senior Data Engineer,Capital,"New York, NY",2 hours ago,Be among the first 25 applicants,"['', 'Have been involved in the full life cycle of data pipeline development- from requirement gathering and architecture to implementation and maintenance.', 'Stocked office with 24/7 access and custom workstations', 'Who we are', '5+ years of experience architecting, building and maintaining production-level data pipelinesStrong understanding of distributed systemsExperience building ETL pipelines with data warehouse solutions and preparing data for machine learning algorithmsHave been involved in the full life cycle of data pipeline development- from requirement gathering and architecture to implementation and maintenance.You have experience working on--or are interested in learning about and solving--hard financial problems', 'What you’ll contribute', 'Platinum medical, vision and dental coverage and OneMedical membership for you and your dependents. Includes FSA & HSA options', 'Unlimited PTO and flexible WFH policy', ""401k plans and co-investment opportunities so you can be a part of Capital's stellar investment performance"", 'Learning stipend to pursue any kind of professional development or continuing education related or unrelated to your field', 'Stipends for wellness, transportation, and electronics (laptops, headphones, monitors - anything you need to do your best work)', 'Unlimited parental leave plus fertility benefits', 'Experience building ETL pipelines with data warehouse solutions and preparing data for machine learning algorithms', 'Who you are', 'The Capital Machine is a systematic financial analysis tool that functions like Bloomberg, but for private companies. Private companies connect their data to the machine and receive financing offers within hours from Capital’s balance sheet. On the back-end, the machine analyzes and benchmarks company data, facilitating data-driven engagement between those who invest capital and those who need it to scale their businesses.', 'Another request? Just let us know!', 'We are a team of passionate and intellectually diverse individuals, who are building financial services that help companies grow to their fullest potential. We believe that fast, fair, and equitable access to financial intelligence can level the playing field for high performing and high potential companies at any stage in their financing.', 'Strong understanding of distributed systems', 'As a Senior Data Engineer at Capital, you will work on mission-critical problems related to building performant, reliable financial analytics pipelines. You’ll work closely with investors and quantitative analysts to understand what type of questions they are trying to answer and then build end-to-end solutions that scale that analysis across terabytes of private financial data.', 'You have experience working on--or are interested in learning about and solving--hard financial problems', '5+ years of experience architecting, building and maintaining production-level data pipelines', ""Unlimited PTO and flexible WFH policyLearning stipend to pursue any kind of professional development or continuing education related or unrelated to your fieldPlatinum medical, vision and dental coverage and OneMedical membership for you and your dependents. Includes FSA & HSA optionsUnlimited parental leave plus fertility benefits401k plans and co-investment opportunities so you can be a part of Capital's stellar investment performanceStipends for wellness, transportation, and electronics (laptops, headphones, monitors - anything you need to do your best work)Stocked office with 24/7 access and custom workstationsAnother request? Just let us know!"", 'How you’ll be supported at Capital']",Mid-Senior level,Full-time,Information Technology,Financial Services,2020-11-05 11:32:32
Staff Data Scientist III AI,Riot Games,"Los Angeles, CA",42 minutes ago,Be among the first 25 applicants,"['', 'Our Perks', '1+ years experience setting up and using cloud infrastructure (e.g., GCP or AWS)', ' 2+ years experience working on games or with a game development team Familiarity with traditional game AI Ph.D. in AI, ML, Computer Science, Statistics, Mathematics, or related field ', ' 2+ years experience in reinforcement learning in various forms 3+ years experience in deep learning frameworks (PyTorch, Keras, or Tensorflow) 6+ years research or industry experience in AI, ML, or related fields 1+ years experience setting up and using cloud infrastructure (e.g., GCP or AWS) Experience in stakeholder management Advanced degree in AI, ML, Computer Science, Statistics, Mathematics, or related field ', 'Responsibilities', 'Guide and empower teams across Riot to solve high-impact and complex technical challenges with AI and ML.', '6+ years research or industry experience in AI, ML, or related fields', ""Improve team's technical craft with peer reviews, paper reading, and tech prototyping."", 'Familiarity with traditional game AI', ""It’s our policy to provide equal employment opportunity for all applicants and members of Riot Games, Inc. Riot Games makes reasonable accommodations for handicapped and disabled Rioters and does not unlawfully discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, handicap, veteran status, marital status, criminal history, or any other category protected by applicable federal and state law, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance relating to an applicant's criminal history (LAMC 189.00)."", 'Desired Qualifications', '2+ years experience in reinforcement learning in various forms', 'The Role', 'Research and prototype AI across a wide spectrum of problem spaces for games in various genres.', 'Ph.D. in AI, ML, Computer Science, Statistics, Mathematics, or related field', 'Identify new product opportunities and collaboratively develop them with partners.', "" Research and prototype AI across a wide spectrum of problem spaces for games in various genres. Inform and contribute to the development of the distributed AI frameworks and standards at Riot. Guide and empower teams across Riot to solve high-impact and complex technical challenges with AI and ML. Identify new product opportunities and collaboratively develop them with partners. Improve team's technical craft with peer reviews, paper reading, and tech prototyping. "", 'Required Qualifications', 'Inform and contribute to the development of the distributed AI frameworks and standards at Riot.', 'Advanced degree in AI, ML, Computer Science, Statistics, Mathematics, or related field', '3+ years experience in deep learning frameworks (PyTorch, Keras, or Tensorflow)', '2+ years experience working on games or with a game development team', 'Experience in stakeholder management']",Not Applicable,Full-time,Engineering,Computer Games,2020-11-05 11:32:32
Data Science Support Analyst,JM&A Group,"Deerfield Beach, FL",6 hours ago,137 applicants,"['', 'Job Requirements', ' Continually check metrics and validate models, compute model performance metrics.  Access, analyze, cleanse, pre-process data.  Retrieve data from multiple stores CSV/Teradata/Oracle/API/.  Train new models per specifications from Data Scientist.  Deploy new models and determine when to replace existing.  Configure Linux server web sites and update code base as needed.  Monitor web application performance and fix issues accordingly.  Configure SQLite/SQL/Mongo databases and stored queries, updating as needed.  Participate in meetings and offer ideas and solutions to present problems. ', ' Configure Linux server web sites and update code base as needed. ', ' Excellent communication skills (both written and verbal) with ability to effectively communicate to all levels with varying degrees of technical knowledge ', ' Deploy new models and determine when to replace existing. ', 'Data Science Support Analyst', ' Configure SQLite/SQL/Mongo databases and stored queries, updating as needed. ', "" Python (numpy/pandas/matplotlib/sklearn/flask)  Version control (git)  SQL and database APIs (cx_oracle, pymysql, sqlalchemy)  Cloud deployment experience (AWS, containerization) and familiarity with AWS services  Experience working in an Agile/Scrum environment  Machine Learning algorithm development experience.  Ability to learn new technologies rapidly and turn around implementations.  Excellent communication skills (both written and verbal) with ability to effectively communicate to all levels with varying degrees of technical knowledge  Critical thinking Independent problem resolution  Ability to work in a team and collaborate with others  Bachelor's Degree (Data Science, Analytics, Business, Finance, Computer Science, Engineering or related field)  2-4 years experience (candidates with a relevant Masters degree and less experience will also be considered)."", ' Train new models per specifications from Data Scientist. ', ' Python (numpy/pandas/matplotlib/sklearn/flask) ', 'Responsibilities', ' Experience working in an Agile/Scrum environment ', ' Ability to work in a team and collaborate with others ', ' Retrieve data from multiple stores CSV/Teradata/Oracle/API/. ', ' 2-4 years experience (candidates with a relevant Masters degree and less experience will also be considered).', ' Continually check metrics and validate models, compute model performance metrics. ', ' SQL and database APIs (cx_oracle, pymysql, sqlalchemy) ', ' Critical thinking Independent problem resolution ', 'JM&A Group', ' Access, analyze, cleanse, pre-process data. ', ' Version control (git) ', ' Machine Learning algorithm development experience. ', 'Job Description', ' Ability to learn new technologies rapidly and turn around implementations. ', ' Monitor web application performance and fix issues accordingly. ', ' Cloud deployment experience (AWS, containerization) and familiarity with AWS services ', ' Participate in meetings and offer ideas and solutions to present problems. ', "" Bachelor's Degree (Data Science, Analytics, Business, Finance, Computer Science, Engineering or related field) ""]",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Principal Research Scientist-DMPK,Aligos Therapeutics,San Francisco Bay Area,13 hours ago,Be among the first 25 applicants,"['', 'PhD or Pharm D. in Pharmacokinetics, Pharmaceutical Sciences, or related field with a specific focus on small molecule and oligonucleotide pharmacokinetics and metabolism with 5 to 8 years of relevant industry experience.', 'NOTE: ONLY APPLICANTS CURRENTLY RESIDING IN THE BAY AREA WILL BE CONSIDERED', 'This position is responsible for providing DMPK expertise for new chemical entities, small molecule and oligonucleotides, as a project representative on multi-disciplinary drug discovery and development teams.\xa0The candidate will work closely with nonclinical discovery scientist, clinicians and cross-functional project team members.\xa0Responsibilities include guiding discovery project teams for candidate selection, developing and driving DMPK strategies for lead optimization and solving ADME-related issue, designing and interpreting in vitro and in vivo DMPK studies. ', 'Extensive understanding of DMPK principles. A proven track record of supporting drug discovery and development as a functional representative on multidisciplinary project teams, authoring regulatory documents, supporting worldwide regulatory filings and interactions.', 'Proven skills in pharmacokinetic data analysis using Phoenix WinNonlin.\xa0Familiarity with NONMEM, SimCyp and/or Gastroplus PBPK modeling is nice to have.', 'Responsibilities also includes determining PK parameters for nonclinical studies using WinNonlin and assisting with the application of modeling approaches (in silico, PK, PBPK) to support human pharmacokinetics and dose predictions, quantitative risk assessment of drug-drug interactions, monitoring of GLP bioanalysis, and CRO management. To support GLP toxicology and clinical studies, this position is responsible for monitoring methods development, validation, sample analysis and reviewing and approving reports. The candidate will be required to generate, analyze and present data, both orally and as written reports, author and review various regulatory documents and interact with worldwide regulatory authorities.\xa0\xa0\xa0', 'The ability to work independently, excellent interpersonal and organizational skills, excellent oral/written communication, proven track record of teamwork, ability to multitask and prioritize to delivery results within tight timelines is a must.', 'Aligos Therapeutics, Inc. is a biotechnology company located in South San Francisco, California that is developing novel medicines to treat liver diseases in virology, inflammation/fibrosis and oncology. Aligos is pursuing the development of both oligonucleotide-based and small molecule therapeutics, each addressing major commercial market opportunities.', 'PhD or Pharm D. in Pharmacokinetics, Pharmaceutical Sciences, or related field with a specific focus on small molecule and oligonucleotide pharmacokinetics and metabolism with 5 to 8 years of relevant industry experience.Extensive understanding of DMPK principles. A proven track record of supporting drug discovery and development as a functional representative on multidisciplinary project teams, authoring regulatory documents, supporting worldwide regulatory filings and interactions.Proven skills in pharmacokinetic data analysis using Phoenix WinNonlin.\xa0Familiarity with NONMEM, SimCyp and/or Gastroplus PBPK modeling is nice to have.Knowledge of GLP, GCP, drug development and regulatory guidelines is required.The ability to work independently, excellent interpersonal and organizational skills, excellent oral/written communication, proven track record of teamwork, ability to multitask and prioritize to delivery results within tight timelines is a must.', ""At Aligos, our science is the key to our success with the ultimate goal of improving patients' quality of life. Our pipeline of developing novel compounds and investigative therapies reflects our commitment to bring innovative products to patients with unmet needs in the area of liver diseases. This is an exciting opportunity to become an employee a high energy Research and Development company.\xa0We are looking for an enthusiastic person who understands and appreciates the entrepreneurial environment and who is willing to do what it takes to contribute to the success of the company."", 'Knowledge of GLP, GCP, drug development and regulatory guidelines is required.', 'Qualifications and requirements: ']",Director,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Principal Machine Learning Scientist,"Sage Intacct, Inc.","San Francisco, CA",21 hours ago,33 applicants,"['What it’s like to work here: ', 'Experience communicating projects to both technical and non-technical audiences.\xa0', 'Working with product managers and engineers to translate product/business problems into tractable machine learning problems and drive the ideas into production using machine leaning\xa0', 'Writing production-quality/ optimized code.\xa0', 'You may be a fit for this role if you: ', 'Responsibilities:', 'Today, unfortunately, financial management and services are universally manual, tedious, and error prone. At the same time, these processes often follow well-defined rules, abide by industry standardization, and have become increasingly\xa0data-rich. Our team, within the Medium Segment Native Cloud Solutions at Sage, builds cloud-based AI-powered features and products that fundamentally change the way businesses operate.\xa0', 'Preferred Qualifications : ', '5+ years industry experience training and shipping production machine learning models.\xa0', 'You may be a fit for this role if you:', 'Every business on the face of Earth must, in some way, do bookkeeping, accounting, and financial planning to operate. At the outset, these functions may seem like mundane facts-of-life in the process of running a business; however, the skill with which a company does them can have a profound impact not only on their business, but also the world.\xa0A poorly forecasted budget,\xa0could mean the abrupt end to the clinical trial of a potentially life-saving drug. On the other hand, a highly accurate hiring plan can lead to successful team growth that allows a company to design a brand-new material that helps reverse climate change.\xa0', 'You often think about applications of machine learning in your personal life.\xa0', 'Minimum Qualifications:', 'PhD in Computer Science, Electrical Engineering, Statistics, Physics, or similar quantitative fields.\xa0Publications in top conferences (ICML,\xa0NeurIPS, ICLR, ACL, EMNLP, ICCV).\xa0Experience wrangling data, writing complex SQL queries and basic bash scripting.\xa0You have deep experience\xa0with:\xa0logistic regression, gradient descent, regularization, cross-validation, overfitting, bias, variance, convex optimization, eigenvectors, sampling, latency, computational complexity, sparse matrices.\xa0', 'We are looking for a Principal Machine Learning Scientist in San Francisco to help us ship AI-powered products and services.\xa0', 'Publications in top conferences (ICML,\xa0NeurIPS, ICLR, ACL, EMNLP, ICCV).\xa0', 'Strong production level programming skills in Python or C++.\xa0', 'Building, experimenting, training, tuning, and shipping machine learning models in the areas\xa0of:\xa0classification, clustering, time-series modeling and\xa0forecasting.\xa0Writing production-quality/ optimized code.\xa0Working with product managers and engineers to translate product/business problems into tractable machine learning problems and drive the ideas into production using machine leaning\xa0Working with machine learning infrastructure engineers to ship models.\xa0Presenting findings, results, and performance metrics to stakeholders.\xa0', 'What it’s like to work here:', 'You’re comfortable with investigating open-ended problems and coming up with concrete approaches to solve them.\xa0', 'Minimum Qualifications: ', ""You don't only use machine learning models but can implement many machine learning and statistical learning models from scratch and know when/how to apply them to real world noisy data.\xa0"", 'You will have an opportunity to work on a small and growing team based in San Francisco in an environment where engineering is central to what we do. The products we build are breaking new ground, and we have a focus on providing the best environment to allow you to do what you do best - solve problems, collaborate with your team and push first class software. We promote an open diverse environment, encourage contributions to open-source software and invest heavily in our staff. Our team is talented, capable and inclusive. We know that great things can only be done with great teams and look forward to building and working with a great people.\xa0', 'Have a strong intuition into different modeling techniques and their suitability to different problems.\xa0', 'Working with machine learning infrastructure engineers to ship models.\xa0', 'You can consume research ideas and papers and translate them into production models.\xa0', 'Building, experimenting, training, tuning, and shipping machine learning models in the areas\xa0of:\xa0classification, clustering, time-series modeling and\xa0forecasting.\xa0', 'Preferred Qualifications :', '5+ years of hands-on experience in working with several of:\xa0pytorch,\xa0tensorflow,\xa0numpy,\xa0scipy, scikit-learn, pandas.\xa0', 'MS in Computer Science, Electrical Engineering, Statistics, Physics, or similar quantitative field.\xa0Strong theoretical and mathematical foundations in linear algebra, probability theory, multivariate optimization.\xa0Have a strong intuition into different modeling techniques and their suitability to different problems.\xa0Strong production level programming skills in Python or C++.\xa05+ years of hands-on experience in working with several of:\xa0pytorch,\xa0tensorflow,\xa0numpy,\xa0scipy, scikit-learn, pandas.\xa05+ years industry experience training and shipping production machine learning models.\xa0Experience communicating projects to both technical and non-technical audiences.\xa0', 'You’re a deeply curious person and eager to learn and grow.\xa0', 'Presenting findings, results, and performance metrics to stakeholders.\xa0', 'You have deep experience\xa0with:\xa0logistic regression, gradient descent, regularization, cross-validation, overfitting, bias, variance, convex optimization, eigenvectors, sampling, latency, computational complexity, sparse matrices.\xa0', 'Experience wrangling data, writing complex SQL queries and basic bash scripting.\xa0', ""You’re comfortable with investigating open-ended problems and coming up with concrete approaches to solve them.\xa0You can consume research ideas and papers and translate them into production models.\xa0You don't only use machine learning models but can implement many machine learning and statistical learning models from scratch and know when/how to apply them to real world noisy data.\xa0You’re a deeply curious person and eager to learn and grow.\xa0You often think about applications of machine learning in your personal life.\xa0"", 'MS in Computer Science, Electrical Engineering, Statistics, Physics, or similar quantitative field.\xa0', 'Strong theoretical and mathematical foundations in linear algebra, probability theory, multivariate optimization.\xa0', 'Responsibilities: ', 'PhD in Computer Science, Electrical Engineering, Statistics, Physics, or similar quantitative fields.\xa0']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Contract - Data Engineer - Python and Spark,CyberCoders,"San Francisco, CA",22 hours ago,Be among the first 25 applicants,"['', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Supportive Team and Management', ' Fun and Exciting Projects! Supportive Management! Great Pay!', 'Your Right to Work', ' Supportive Management!', 'Nice To Haves', ' Great Pay!', ' Python and Spark Creating and maintaining data ingestion pipelines', 'Email Your Resume In Word To', ' Competitive Pay', ' AWS Big Data technologies like Glue, S3, and RedShift', ' Flexibility', ' Python and Spark', ' Fun and Exciting Projects!', ' Creating and maintaining data ingestion pipelines', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : TR4-1610136 -- in the email subject line for your application to be considered.***', ' Competitive Pay Supportive Team and Management Flexibility']",Mid-Senior level,Full-time,Information Technology,Management Consulting,2020-11-05 11:32:32
Data Engineer,Dell,"Hopkinton, MA",7 hours ago,Over 200 applicants,"['', 'Experience working in an Agile environment', 'Experience in root cause analysis', 'Essential Requirements', 'Deep-dive into business problems relating to our quota planning and sales compensation efforts', 'Benefits', 'Strong project management and organizational skills', 'Deep-dive into business problems relating to our quota planning and sales compensation effortsDesign and maintain optimal data architecture for our data science products; partner with your peer data engineers to build reliable systems that scaleBuild, clean, and maintain data sets that feed our machine learning algorithms and discovery processes (based in PostgreSQL database)Identify opportunities for process improvements (may results in automating, optimizing, or fully rebuilding workflows)Work with the greater Decision Sciences team to help with data related issues and analysis needs', 'Creative thinker who is success-driven both individually and as a team leader/mentor', 'Data Engineer', 'Decision Sciences', 'Expertise with Python, Java, or a similar object-oriented language', 'Bachelors or Masters (preferred) in Computer Science/Engineering or related field', 'Detail-oriented with the ability to effectively prioritize tasks', 'Good written and oral communications skills', 'Self-learner who is driven to learn new methods and techniques to fulfill business needsCreative thinker who is success-driven both individually and as a team leader/mentorDetail-oriented with the ability to effectively prioritize tasksExperience working in an Agile environmentExpertise in PostgreSQL (experience with GreenPlum a plus)Expertise with Python, Java, or a similar object-oriented languageExperience building and optimizing data workflowsExperience architecting data pipelinesExperience in root cause analysisGood written and oral communications skillsStrong project management and organizational skills1+ year(s) of experience (preferred) in a data engineering capacity, preferably on a data science or advanced analytics teamBachelors or Masters (preferred) in Computer Science/Engineering or related field', 'Remote Role in Massachusetts USA', '1+ year(s) of experience (preferred) in a data engineering capacity, preferably on a data science or advanced analytics team', 'Build, clean, and maintain data sets that feed our machine learning algorithms and discovery processes (based in PostgreSQL database)', 'Identify opportunities for process improvements (may results in automating, optimizing, or fully rebuilding workflows)', 'Experience building and optimizing data workflows', 'Key Responsibilities', 'Work with the greater Decision Sciences team to help with data related issues and analysis needs', 'Expertise in PostgreSQL (experience with GreenPlum a plus)', 'Design and maintain optimal data architecture for our data science products; partner with your peer data engineers to build reliable systems that scale', 'Data EngineerRemote Role in Massachusetts USA', 'Experience architecting data pipelines', 'Self-learner who is driven to learn new methods and techniques to fulfill business needs']",Not Applicable,Full-time,Information Technology,Computer Hardware,2020-11-05 11:32:32
Senior Data Engineer,Motion Recruitment,"New York, NY",18 hours ago,Be among the first 25 applicants,"['', 'Job Description', 'Data audit and QA experience', 'Extensive experience with cloud services (AWS preferred)', 'Experience with ETL using Hive, advanced use of SQL in Hive, worked with CSV, JSON, and Parque', 'Some knowledge of statistical modelling and machine learning', 'Basic understanding of RESTful APIs, webservices', 'Proven track record of handling data at scale, using Hadoop and Spark', 'Competitive Salary: Up to $180k/year ', ' Competitive Salary: Up to $180k/year  Robust Healthcare and Benefits package including Medical, Dental, Vision, Disability coverage and various other benefit options', ' A solid foundation in Python, Linux (prefer RedHat), and Java Proven track record of handling data at scale, using Hadoop and Spark Experience with ETL using Hive, advanced use of SQL in Hive, worked with CSV, JSON, and Parque Extensive experience with cloud services (AWS preferred) Data audit and QA experience Basic understanding of RESTful APIs, webservices Some knowledge of statistical modelling and machine learning ', 'Robust Healthcare and Benefits package including Medical, Dental, Vision, Disability coverage and various other benefit options', 'The Offer', 'Required Skills', 'A solid foundation in Python, Linux (prefer RedHat), and Java']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Engineer,Genesis10,"Milwaukee, WI",24 hours ago,Be among the first 25 applicants,"['', 'Working with a range of data sources Traditional DBMS (MS SQL, IBM DB2, etc.), No SQL DBMS (e.g. Mongo), Flat Files (csv,xls,etc.), Web (XML, JSON, etc.)', 'Design, build, and support data pipelines to facilitate BI and Analytic solutions among our team (e.g. ETL)', 'About Genesis10:', 'Responsibilities:', 'Collecting data systematically and consider a broad range of issues or factors to promote sustainability of the dataset planning.', '.\xa0\xa0“Genesis10 is an Equal Opportunity Employer, M/F/D/V”', 'Design, build, and support data pipelines to facilitate BI and Analytic solutions among our team (e.g. ETL)Support establishing a self-service BI data environment including data sourcing, modeling and distribution for consumption by citizen BI developers.Accountable for ensuring data within our store meets quality and security requirements.Build consensus and trust with partnered organizations on future state patterns.Drive the sharing of standards on our team and the greater community through coaching, mentoring, and articles around core methodologies and processes.Build reports/dashboards for consumption within our team using BI tooling; such as Tableau or Power BI.Collecting data systematically and consider a broad range of issues or factors to promote sustainability of the dataset planning.', 'Accountable for ensuring data within our store meets quality and security requirements.', 'Support establishing a self-service BI data environment including data sourcing, modeling and distribution for consumption by citizen BI developers.', 'Bachelor’s degree in Computer Science, MIS, or direct experience will be considered.', 'Experience with pipeline\\ETL tooling such as MS SQL Server Integration Services (SSIS), Azure Data Factory, AWS Glue, PowerBI Dataflows, Informatica Data Integration, etc.', '\xa0About Genesis10:Genesis10 is a leading U.S. business and technology consulting firm with hundreds of clients needing proven talent and solutions to power their strategic initiatives.\xa0 If you are a high performing business or IT professional with solid, referenced experience, we want to meet you.\xa0 Genesis10 recruiters and delivery professionals are highly accomplished career advocates, who get to know you beyond your resume to position you with the opportunities that fit your skills, experience and aspirations.\xa0 We have benefit options to fit your needs and a support staff that works with you from placement throughout your engagement - project after project.\xa0\xa0 To learn more about Genesis10 and to view all our available career opportunities, please visit us at ', 'Embraces continuous learning, curiosity, experimentation, and ambiguity.', 'Genesis10 is currently seeking a Sr. Data Engineer for a contract position lasting through 10/29/2021, working with a major insurance client in the Milwaukee, WI area.', 'Description:Our org provides BI\\analytic solutions for senior and executive leadership within our IT function. In addition, we provide data solutions and guidance to empower self-service BI Developers and Analysts across our IT function.', 'Knowledge of pipeline\\ETL development standard methodologies for batch and near real-time integrations.', 'Can execute alone but is a collaborative teammate.', 'Build reports/dashboards for consumption within our team using BI tooling; such as Tableau or Power BI.', 'Strong SQL background including writing and solving complexity within SQL code and performance tuning.', 'www.genesis10.com', 'If you are a qualified candidate interested in this opportunity, please apply.', 'Qualifications:', 'Build consensus and trust with partnered organizations on future state patterns.', 'Description:', 'Grasp of APIs (SOAP and REST).', '5-8 years of professional experience in data.', 'Bachelor’s degree in Computer Science, MIS, or direct experience will be considered.5-8 years of professional experience in data.Strong SQL background including writing and solving complexity within SQL code and performance tuning.Working with a range of data sources Traditional DBMS (MS SQL, IBM DB2, etc.), No SQL DBMS (e.g. Mongo), Flat Files (csv,xls,etc.), Web (XML, JSON, etc.)Knowledge of pipeline\\ETL development standard methodologies for batch and near real-time integrations.Experience with pipeline\\ETL tooling such as MS SQL Server Integration Services (SSIS), Azure Data Factory, AWS Glue, PowerBI Dataflows, Informatica Data Integration, etc.Grasp of APIs (SOAP and REST).Solid grasp on summarizing technical situations into concise and meaningful proposals.Embraces continuous learning, curiosity, experimentation, and ambiguity.Strong customer/client orientation.Can execute alone but is a collaborative teammate.', 'Drive the sharing of standards on our team and the greater community through coaching, mentoring, and articles around core methodologies and processes.', 'Strong customer/client orientation.', 'This role will help shape and drive the data warehouse\\lake for BI and Analytic solutions built by our team as well as the data solution behind the self-service function for our community of BI Developers and Analysts.', 'Solid grasp on summarizing technical situations into concise and meaningful proposals.']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Research Scientist I - EX,Seattle Children's,"Seattle, WA",5 hours ago,35 applicants,"['', 'Contribute to writing for publication of results; generate figures for papers and grants. ', 'Perform in vitro B cell culture and cell activation assays.', 'Work Status: Regular;', ""This position is open to either a Res Scientist I or II level contingent upon selected candidate's qualifications and position needs."", 'Job ID:', "" Bachelor's Degree in Immunology, Molecular Biology, Biochemistry and/or related field."", 'The people who work at Seattle Children’s are members of a community that seeks to respect and celebrate all the qualities that make each of us unique. Each of us is empowered to be ourselves within this community, which cultivates and promotes equity, diversity, and inclusion at all levels. ', 'Area of Interest: Research & Development;', 'Work Status:', 'About Us', 'U.S. News & World Report’s', 'Department:', 'FTE/Hours per pay period:', 'Analyse data and present data at group meetings. ', 'Shift:', 'Job ID: 36126;', 'Assist with genotyping and management of mouse colony, and perform experiments using tissues harvested from mice.', 'Design experiments to assess B cell responses to activation using flow cytometry and western blot analysis.Perform in vitro B cell culture and cell activation assays.Analyze intracellular B cell compartment trafficking by confocal microscopy.Assist with genotyping and management of mouse colony, and perform experiments using tissues harvested from mice.Analyse data and present data at group meetings. Contribute to writing for publication of results; generate figures for papers and grants. ', 'FTE/Hours per pay period: 1.0 FTE (80 hours per bi-weekly pay periods);', 'Seattle Children’s is proud to be an Equal Opportunity Workplace and Affirmative Action Employer.', 'Hope. Care. Cure. These three simple words capture what we do at Seattle Children’s - to help every child live the healthiest and most fulfilling life possible. Are you ready to engage with a mission-driven organization that is life-changing to many, and touches the hearts of all? #HOPECARECURE', ' Prior experience in a laboratory setting; may include relevant educational programs.', 'Requirements', ' See other preferred qualifications listed below', 'Preferred', 'Area of Interest:', 'Overview', 'Design experiments to assess B cell responses to activation using flow cytometry and western blot analysis.', 'Analyze intracellular B cell compartment trafficking by confocal microscopy.', 'Key Responsibilities', 'Area of Interest: Research & Development;FTE/Hours per pay period: 1.0 FTE (80 hours per bi-weekly pay periods);Work Status: Regular;Department: Immunity & Immunotherapies;Shift: Day Shift;Job ID: 36126;', 'Shift: Day Shift;', 'Our community welcomes diverse experiences, backgrounds, and thoughts as this is what drives our spirit of inquiry and allows us to better connect with our increasingly diverse patients and families. Our organization recruits, employs, trains, compensates, and promotes without regard to race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. ', "" Minimum to two (2) year's experience in a related area/laboratory setting."", 'Our Commitment to Diversity', 'Department: Immunity & Immunotherapies;']",Associate,Full-time,Research,Nonprofit Organization Management,2020-11-05 11:32:32
Senior Machine Learning Engineer,Cruise,"San Francisco, CA",4 hours ago,129 applicants,"['', 'We’re Funded', 'Passionate about self driving car technology and its impact on the world', ""We're Vested You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow.   "", 'Strong programming skills in Python or C++', 'On the development end, the ML engineer optimizes, productionizes, and monitors / refines on-road performance for their models', 'We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the bleeding-edge of technology, but also define it.', ' BS, MS, or higher degree, in CS/CE/EE, or equivalent industry experience Extensive experience with ML frameworks such as Tensorflow, Caffe, and PyTorch  Strong experience with machine learning and classification  Strong programming skills in Python or C++ Excellent mathematical reasoning skills, especially with probability  Passionate about self driving car technology and its impact on the world ', 'We also consider for employment qualified applicants regardless of criminal histories, consistent with applicable laws. And, if you believe that you will need any type of accommodation, please let us know.', ' GM, Honda, SoftBank, and T. Rowe Price have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed. ', 'We’re Integrated', 'Healthy meals and snacks provided', 'Commuter benefits', 'Champion engineering excellence, coming up with solutions not just identifying problems', ' We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the bleeding-edge of technology, but also define it. ', 'Competitive salary and benefits ', 'Cruise LLC is an equal opportunity employer. All applicants for employment will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, gender identity or expression, veteran status, genetics or any other legally protected basis. Below, you have the opportunity to share your preferred gender pronouns, gender, ethnicity, and veteran status with Cruise to help us identify areas of improvement in our hiring and recruitment processes. Completion of these questions is entirely voluntary. Any information you choose to provide will be kept confidential, and will not impact the hiring decision in any way.', 'Experience in deploying perception algorithms into real world environments', 'Medical / dental / vision, AD+D and Life', 'BS, MS, or higher degree, in CS/CE/EE, or equivalent industry experience', 'Note to Recruitment Agencies: Cruise does not accept unsolicited agency resumes. Furthermore, Cruise does not pay placement fees for candidates submitted by any agency other than its approved partners.', 'Invent pragmatic long term and stable software solutions to complex problems', 'Strong experience with machine learning and classification ', 'Experience with CUDA', 'Why Cruise?', ' Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale. ', ' PhD in machine learning or computer science Experience with ROS, OpenCV, Gazebo, or PCL Experience with CUDA Experience in deploying perception algorithms into real world environments ', ""We're Vested"", 'We’re Integrated Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale.  ', 'Extensive experience with ML frameworks such as Tensorflow, Caffe, and PyTorch ', 'On the research end, the ML engineer explores, prototypes, validates, and iterates new algorithm', 'Paid parental leave & family expansion stipend', 'We’re Independent We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the bleeding-edge of technology, but also define it.  ', "" Our benefits are here to support the whole you: Competitive salary and benefits  401(k) Cruise matching program  Medical / dental / vision, AD+D and Life Flexible vacation and company paid holidays Healthy meals and snacks provided Paid parental leave & family expansion stipend Monthly wellness stipend Commuter benefits   We’re Integrated Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale.   We’re Funded GM, Honda, SoftBank, and T. Rowe Price have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed.   We’re Independent We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the bleeding-edge of technology, but also define it.   We're Vested You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow.    "", ' Competitive salary and benefits  401(k) Cruise matching program  Medical / dental / vision, AD+D and Life Flexible vacation and company paid holidays Healthy meals and snacks provided Paid parental leave & family expansion stipend Monthly wellness stipend Commuter benefits ', ' On the research end, the ML engineer explores, prototypes, validates, and iterates new algorithm On the development end, the ML engineer optimizes, productionizes, and monitors / refines on-road performance for their models Invent pragmatic long term and stable software solutions to complex problems Champion engineering excellence, coming up with solutions not just identifying problems ', 'Bonus Points! ', 'What You Must Have', 'Experience with ROS, OpenCV, Gazebo, or PCL', 'We’re Funded GM, Honda, SoftBank, and T. Rowe Price have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed.  ', 'GM, Honda, SoftBank, and T. Rowe Price have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed.', 'You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow. ', 'Our benefits are here to support the whole you:', ""What You'll Be Doing"", 'Our benefits are here to support the whole you: Competitive salary and benefits  401(k) Cruise matching program  Medical / dental / vision, AD+D and Life Flexible vacation and company paid holidays Healthy meals and snacks provided Paid parental leave & family expansion stipend Monthly wellness stipend Commuter benefits  ', 'Monthly wellness stipend', 'We’re Independent', 'PhD in machine learning or computer science', 'Flexible vacation and company paid holidays', 'Note to Recruitment Agencies:', ' You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow.  ', 'Excellent mathematical reasoning skills, especially with probability ', 'Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale.', '401(k) Cruise matching program ']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Engineer (Azure, Hadoop)",TEK Connexion,"Pittsburgh, PA",21 hours ago,Be among the first 25 applicants,[],Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Senior Machine Learning Engineer (MLOps, Kubeflow, Cloud Computing)",Understanding Recruitment,United States,3 hours ago,Over 200 applicants,"['', 'The ideal candidate will have experience working with cutting-edge machine learning techniques/frameworks (TensorFlow, reinforcement learning, etc.), hands-on knowledge of model development and deployment into production, and preferably experience working with MLOps pipelines (Kubeflow, guild.ai, etc.).', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A collaborative team and culture that looks after talent, cultivate success and celebrates accomplishments as a team', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Intellectual challenges that you would not experience in most companies.', 'Key Skills: Machine Learning (ML), Deep Learning, Reinforcement Learning, TensorFlow, PyTorch, Keras, Machine Learning Operations (MLOps), Kubeflow, guild.ai, Guild AI, AirFlow, MLflow, ML Flow, SaaS, Software as a Service, Cloud Computing, Amazon Web Services (AWS), Google Cloud Platform (GCP), Azure, Model Deployment, Test-Driven Development (TDD), Big Data, Hadoop, Spark, Dask, MapReduce, DevOps, Docker, Kubernetes, Containerization, CI/CD, Jenkins', 'We are looking for a\xa0Senior Machine Learning Engineer (MLOps, Kubeflow, Cloud Computing)\xa0to join a well-funded quantum computing startup (> $60M Series B) whose vision is to break through the global market with their unique cloud software that combines a powerful platform and quantum algorithm libraries to deliver real-world solutions across a full range of classical and quantum technologies.', ""Headquartered in Boston, MA [2nd office in Canada], this company has conducted state-of-the-art research centered around delivering solutions for optimization, simulation & modeling, as well as machine learning across various industries. As a Senior MLOps Engineer, you will work very closely alongside a world-class team of quantum computing experts (collectively > 36,000 citations in the Quantum Computing domain) daily, aiding in the development and optimization of the company's novel quantum workflow platform."", 'Senior Machine Learning Engineer (MLOps, Kubeflow, Cloud Computing)', 'What we can offer a Senior Machine Learning Engineer:', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Competitive salaries, equity and benefits packages', ""·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0A chance to develop a 'first-of-its-kind' quantum workflow platform alongside world-renowned quantum computing and software engineering experts""]",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Charleston, WV",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Research Engineer- AWS AI,Amazon Web Services (AWS),"Palo Alto, CA",7 hours ago,72 applicants,"['', ' 4+ years of professional software development experience 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems Graduate degree (MS or PhD) in Electrical Engineering, Computer Science, Mathematics or Physics with specialization in speech recognition, natural language processing, machine translation, time series analysis, signal processing, or machine learning. 3+ years of related work experience OR a PhD Strong development skills in programming languages such as C/C++, Python, Java or Perl.', ' 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design', 'Preferred Qualifications', ' Experience with at least one of the modern distributed ML frameworks such as TensorFlow, PyTorch, MxNet', ' Experience with AWS technology stack', 'Company', ' Strong development skills in programming languages such as C/C++, Python, Java or Perl.', 'Basic Qualifications', 'Description', ' Industry experience as a Machine Learning Engineer or related work experience (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting insights from large datasets.', ' Working with scientists and other engineers to investigate design approaches, prototype new technology, and evaluate technical feasibility', ' Comfortable working in a fast paced, highly collaborative, dynamic work environment', ' Designing, developing and maintaining core system features, services and engines', ' Knowledge of or experience in building production quality and large scale deployment of applications related to natural language processing and machine learning.', 'Additional Responsibilities Include', ' 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems', ' 3+ years of related work experience OR a PhD', ' Designing, developing and maintaining core system features, services and engines Helping define product features, drive the system architecture, and spearhead the best practices that enable a quality product Working with scientists and other engineers to investigate design approaches, prototype new technology, and evaluate technical feasibility', ' Industry experience as a Machine Learning Engineer or related work experience (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting insights from large datasets. Knowledge of or experience in building production quality and large scale deployment of applications related to natural language processing and machine learning. Basic understanding of Deep Learning Experience with at least one of the modern distributed ML frameworks such as TensorFlow, PyTorch, MxNet Comfortable working in a fast paced, highly collaborative, dynamic work environment Experience with AWS technology stack', ' Graduate degree (MS or PhD) in Electrical Engineering, Computer Science, Mathematics or Physics with specialization in speech recognition, natural language processing, machine translation, time series analysis, signal processing, or machine learning.', ' Helping define product features, drive the system architecture, and spearhead the best practices that enable a quality product', ' 4+ years of professional software development experience', ' Basic understanding of Deep Learning']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
Quantitative UX Researcher,Creative Circle,"San Jose, CA",6 hours ago,Be among the first 25 applicants,"['', '3-5 years of experience in industry UXRA quantitative researchFluency in SQL.Mastery of R or PythonBS/BA degree in Computer Science, Human-Computer Interaction, Psychology, Statistics or a related field (MS preferred)Expertise in multivariate statistics and the design of experiments.', 'Ideal Qualifications', 'Examine existing data and product designs to generate hypotheses and plans for high-impact research.', 'Fluency in SQL.', 'Mastery of R or Python', 'Define and measure quantitative UX goals and metrics in collaboration with Designers, -Qualitative Researchers, Engineers and Program Managers.', '3-5 years of experience in industry UXRA quantitative research', 'Expertise in multivariate statistics and the design of experiments.', 'Top Responsibilities', 'Support existing research initiatives, prioritize and drive research to quantify and improve the advertiser user experience.Support product development and design and provide confidence in decision making through thorough quantitative insights.Define and measure quantitative UX goals and metrics in collaboration with Designers, -Qualitative Researchers, Engineers and Program Managers.Examine existing data and product designs to generate hypotheses and plans for high-impact research.', 'Support product development and design and provide confidence in decision making through thorough quantitative insights.', 'BS/BA degree in Computer Science, Human-Computer Interaction, Psychology, Statistics or a related field (MS preferred)', 'Support existing research initiatives, prioritize and drive research to quantify and improve the advertiser user experience.']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Lead Data Scientist - Generative Adversarial Networks (GANs),Lawrence Harvey,"New York, United States",1 hour ago,87 applicants,"['', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience coding GANs - Generative Adversarial Networks', 'My client is looking for a Machine Learning Engineer to collaborate with highly talented individuals and conduct applied research in generative adversarial networks (GANs) and related methods to generate content. You will have experience with machine learning and computer vision algorithms and deep learning frameworks with experience in GANs and related deep learning methods. ', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience in applying and adapting the latest research in machine learning and computer vision to support business objectives including prototype development and product integration.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience in selecting or developing algorithms for performing a variety of machine learning and computer vision tasks ', 'Qualifications', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Master’s or Ph.D. degree in Engineering, Computer Science, Machine Learning, Math, Statistics or related fields with specialization in machine learning and/or computer vision.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Programming languages such as Java, C++, Python, R, or JavaScript.', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience performing model training / algorithm development optimizing for speed, size or accuracy and developing / refining new and existing training sets as required.', 'Preferred Qualifications', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Deep understanding of recent ANN/GAN concepts such as Spectral Normalization, Lipschitz Continuity, the Wasserstein Metric, Attention Mechanisms, Instance Normalization, and/or Perceptual Losses.', ' Qualifications', ' ', '·\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Experience with deep learning frameworks such as TensorFlow, Keras, or Torch']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Remote Sr. Data Engineer (Python/GCP),Cypress HCM,"New York, NY",23 hours ago,Be among the first 25 applicants,"['', 'Knowledge of Git, Jinja2, Docker(containerization), Bitbucket, and Bamboo ', 'Responsibilities:', 'Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud ', 'Preferred: ', 'Required', '*Must be able to work EST hours*', 'Requirements:', 'Google Cloud Certified - Professional Data Engineer certification would be a plus ', 'Strong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow or Google Composer) ', 'Strong communication & interpersonal skills ', 'Preferred:', 'Perform data integration related work for the company which includes Ad stack Tech integration, BI continuity and other data integration required for running our business Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery Develop and promote best practices in data engineering Develop real-time data processing applications using Google Cloud Be part of the on-call rotation supporting our SLA’s Participate in design and code reviews ', 'Develop real-time data processing applications using Google Cloud ', '5+ years of hands-on experience working in data engineering environment ', 'Advanced SQL programming skills - Ability to write complex SQL to perform common types of analysis and aggregations ', 'Familiar with version control systems (Git and Bitbucket) ', 'Requirements: ', 'Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery ', 'Familiar with Atlassian products Jira and Confluence ', 'Can-do attitude on problem-solving, quality and ability to execute ', 'Google Cloud Certified - Professional Data Engineer certification would be a plus Knowledge of Git, Jinja2, Docker(containerization), Bitbucket, and Bamboo Familiar with a NoSQL database such as MongoDB Familiar with version control systems (Git and Bitbucket) Familiar with Atlassian products Jira and Confluence Hands-on experience with Apache Airflow or Google Composer Knowledge of Application Programming Interfaces ', 'Required: ', ""Bachelor's degree in Computer Science or equivalent experience in a related field "", 'Be part of the on-call rotation supporting our SLA’s ', 'Develop and promote best practices in data engineering ', 'The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting. This engineer’s duty is to monitor the existing metrics, analyze data, and lead partnerships with other Data and Analytics teams in an effort to identify and implement systems and process improvements. This engineer also designs, architects, implements, and supports key datasets. ', 'Experience with Apache Airflow or Google Composer ', 'Perform data integration related work for the company which includes Ad stack Tech integration, BI continuity and other data integration required for running our business ', 'Strong proficiency in Python with an emphasis in building data pipelines ', 'Knowledge of Application Programming Interfaces ', 'Experience developing data solutions on GCP (airflow experience) ', 'Familiar with a NoSQL database such as MongoDB ', 'Hands-on experience with Apache Airflow or Google Composer ', ""Bachelor's degree in Computer Science or equivalent experience in a related field 5+ years of hands-on experience working in data engineering environment Strong proficiency in Python with an emphasis in building data pipelines Advanced SQL programming skills - Ability to write complex SQL to perform common types of analysis and aggregations Experience developing data solutions on GCP (airflow experience) Experience with Apache Airflow or Google Composer Can-do attitude on problem-solving, quality and ability to execute Strong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow or Google Composer) Strong communication & interpersonal skills "", 'Responsibilities: ', '\xa0 ', 'Participate in design and code reviews ']",Mid-Senior level,Contract,Engineering,Computer Software,2020-11-05 11:32:32
Staff Machine Learning Engineer,Spotify,"New York, NY",7 hours ago,97 applicants,"['', 'Help drive optimization, testing and tooling to improve data quality', 'You care about agile software processes, data-driven development, reliability, and responsible experimentation', 'Take on complex data-related problems involving some of the most diverse datasets available and determine the feasibility of projects through quick prototyping with respect to performance, quality, time and cost using Agile methodologies', 'You preferably have machine learning publications or work on open source to share with us', 'Support the engineering team in formulating the technical vision and strategy for our Machine Learning based automated marketing stackApply machine learning, collaborative filtering, NLP, and deep learning methods to massive data setsTake on complex data-related problems involving some of the most diverse datasets available and determine the feasibility of projects through quick prototyping with respect to performance, quality, time and cost using Agile methodologiesArchitect best-in-class infrastructure (platforms, tools, and approaches) to accelerate our research to the product phase and set up efficient deployment, optimization, and testing of automated marketing modelsBe a leading voice in an active community of machine learning practitioners across Spotify and leverage existing state-of-the-art tooling in the Spotify ecosystem (TensorFlow, DataFlow, python-beam, Google Cloud Platform)Contribute to our team-wide product ideation in collaboration with other engineers, researchers, product managers and tech leads on the teamHelp drive optimization, testing and tooling to improve data qualityIterate on recommendation quality through continuous A/B testing', 'Support the engineering team in formulating the technical vision and strategy for our Machine Learning based automated marketing stack', 'Apply machine learning, collaborative filtering, NLP, and deep learning methods to massive data sets', 'Contribute to our team-wide product ideation in collaboration with other engineers, researchers, product managers and tech leads on the team', 'PhD or M.Sc. in Machine Learning, or related field', 'Be a leading voice in an active community of machine learning practitioners across Spotify and leverage existing state-of-the-art tooling in the Spotify ecosystem (TensorFlow, DataFlow, python-beam, Google Cloud Platform)', ""What You'll Do"", 'Architect best-in-class infrastructure (platforms, tools, and approaches) to accelerate our research to the product phase and set up efficient deployment, optimization, and testing of automated marketing models', 'Iterate on recommendation quality through continuous A/B testing', 'Who You Are', 'You have 4+ years of machine learning product development experience leveraging large scale data processing technologies (e.g. TensorFlow, SciKit learn, Dataflow, Hadoop, Scalding, Spark, Storm).', 'PhD or M.Sc. in Machine Learning, or related fieldYou have 4+ years of machine learning product development experience leveraging large scale data processing technologies (e.g. TensorFlow, SciKit learn, Dataflow, Hadoop, Scalding, Spark, Storm).You preferably have experience in digital marketing analytics and strategy, and experience in leveraging Machine Learning techniques to optimize digital campaignsYou have a strong mathematical background in statistics and Machine LearningYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou preferably have machine learning publications or work on open source to share with us', 'You have a strong mathematical background in statistics and Machine Learning', 'You preferably have experience in digital marketing analytics and strategy, and experience in leveraging Machine Learning techniques to optimize digital campaigns']",Not Applicable,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Senior Designer/Researcher (Remote Work Available),USAA,"Plano, TX",22 hours ago,Be among the first 25 applicants,"['', 'Preferred Requirements', 'not', 'Real Estate or Fintech domain knowledge and understanding of sales funnel and conversion optimization', 'Relocation', 'Excellent written and verbal communication skills, interpersonal skills, time management skills and strong attention to detail.', ""Identifies and manages existing and emerging risks that stem from business activities and the job role.Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.Follows written risk and compliance policies and procedures for business activities.Supports design team in defining business problems, design requirements, and demonstrate a solution's potential success for moderately complex projects.Co-facilitates a cross-functional understanding of business problems and potential design solutions using human-centered design sessions and group discussions to achieve actionable outcomes.Navigates multiple workstreams from discovery to implementation, balancing efforts, priorities, and partnerships for each.Guides the development and facilitation of human-centered research efforts, the synthesis of research findings and the generation of insights.Works autonomously to create holistic member experiences leveraging extensive knowledge of interaction design, visual design, and/or content design.Articulates ideas and solutions using a range of storytelling techniques to inspire and compel audiences to align on direction.Mentors developing designers across the Chief Design Office. Provides constructive day-to-day feedback and guidance to team members.Applies advanced understanding of human-centered and service design practices and leverages multiple methods to solve complex design problems.Stays abreast of current digital and mobile technology trends, in the area of application architecture with best practices within the digital development ecosystem"", 'Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.', 'Articulates ideas and solutions using a range of storytelling techniques to inspire and compel audiences to align on direction.', 'Demonstrated experience designing user interfaces for web and mobile applications (iOS, Android, etc.)', 'Guides the development and facilitation of human-centered research efforts, the synthesis of research findings and the generation of insights.', 'Highly organized, with the ability to work on multiple projects/task at once while managing a diverse group of employees.', 'Works autonomously to create holistic member experiences leveraging extensive knowledge of interaction design, visual design, and/or content design.', 'Follows written risk and compliance policies and procedures for business activities.', 'A portfolio that demonstrates extensive experience designing digital experiences for mobile and web-based applications.', 'Bachelor’s Degree or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree (10+ years of experience in lieu of degree).6 years of relevant, on-the-job experience in a Product Design, UX Design, Service Design or Design Research role delivering complex design systems for web and native applications.Highly organized, with the ability to work on multiple projects/task at once while managing a diverse group of employees.Extensive experience designing and supporting digital products inside an Agile environment using human-centered design principles, methods and problem-solving strategies.A portfolio that demonstrates extensive experience designing digital experiences for mobile and web-based applications.Demonstrated ability to work fluently in standard applications, including Sketch, InVision (or comparable prototyping tools), Adobe CC and Microsoft Office Suite.Advanced facilitation, collaboration and consensus-building skills, with extensive experience in presenting to cross-functional terms and Senior/Executive leaders.Excellent written and verbal communication skills, interpersonal skills, time management skills and strong attention to detail.Demonstrated advanced understanding of new technologies and best practices in website navigation, browsers, mobile patterns, information architecture and usability.Demonstrated experience designing user interfaces for web and mobile applications (iOS, Android, etc.)Demonstrates a strategic mindset by decomposing complex problems into a clear and achievable workstream requiring limited support and direction for decision making.', 'Extensive experience designing and supporting digital products inside an Agile environment using human-centered design principles, methods and problem-solving strategies.', 'Advanced facilitation, collaboration and consensus-building skills, with extensive experience in presenting to cross-functional terms and Senior/Executive leaders.', 'Demonstrated experience using behavioral and/or transactional data to help prioritize design efforts.', 'Mentors developing designers across the Chief Design Office. Provides constructive day-to-day feedback and guidance to team members.', '6 years of relevant, on-the-job experience in a Product Design, UX Design, Service Design or Design Research role delivering complex design systems for web and native applications.', 'Working knowledge of Accessibility principles and guidelines; experience creating inclusive designs.', ""Supports design team in defining business problems, design requirements, and demonstrate a solution's potential success for moderately complex projects."", 'BOUT USAA', 'About Usaa’s Chief Design Office', 'Experience working with internal design systems, component libraries, web application frameworks.', 'Identifies and manages existing and emerging risks that stem from business activities and the job role.', '3+ years of experience planning and conducting both qualitative and quantitative design research. Experience should include establishing recruitment criteria/screening, creating protocols/interview guides, conducting test/interview sessions, identifying top-level findings and documenting recommendations.Demonstrated experience using behavioral and/or transactional data to help prioritize design efforts.Experience working with internal design systems, component libraries, web application frameworks.Working knowledge of Accessibility principles and guidelines; experience creating inclusive designs.Real Estate or Fintech domain knowledge and understanding of sales funnel and conversion optimization', 'Bachelor’s Degree or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree (10+ years of experience in lieu of degree).', 'available', 'Co-facilitates a cross-functional understanding of business problems and potential design solutions using human-centered design sessions and group discussions to achieve actionable outcomes.', '3+ years of experience planning and conducting both qualitative and quantitative design research. Experience should include establishing recruitment criteria/screening, creating protocols/interview guides, conducting test/interview sessions, identifying top-level findings and documenting recommendations.', 'Demonstrates a strategic mindset by decomposing complex problems into a clear and achievable workstream requiring limited support and direction for decision making.', 'Stays abreast of current digital and mobile technology trends, in the area of application architecture with best practices within the digital development ecosystem', 'Demonstrated ability to work fluently in standard applications, including Sketch, InVision (or comparable prototyping tools), Adobe CC and Microsoft Office Suite.', 'Tasks', 'Minimum Requirements', 'Applies advanced understanding of human-centered and service design practices and leverages multiple methods to solve complex design problems.', 'Demonstrated advanced understanding of new technologies and best practices in website navigation, browsers, mobile patterns, information architecture and usability.', 'Navigates multiple workstreams from discovery to implementation, balancing efforts, priorities, and partnerships for each.']",Not Applicable,Full-time,Design,Financial Services,2020-11-05 11:32:32
"Associate Research Scientist, Neuroscience","InVitro Cell Research, LLC",New York City Metropolitan Area,,N/A,"['', 'Culturing human cell lines including stem cell neuronal lines and primary human lines', 'Working with other ICR scientists to leverage company resources and maximize productivity', 'with strong backgrounds in cell culture', 'InVitro Cell Research (ICR)', 'Want to join us?', 'Hands-on experience with fluorescence microscopy', 'neurodegeneration', 'Solid knowledge of modern molecular and cell biology lab techniques', ""We'd love to hear from you if your background includes:"", ""As an Associate Research Scientist in our Neuroscience Group at ICR, you'll play an integral part in:"", 'Hands-on experience with fluorescence microscopyExperience with flow cytometry', 'Performing a variety of cell-based assays', 'To have a friendly, easy going personalityExcellent English-language communication skillsThe ability to work in the United States without sponsorship', 'Managing many day-to-day aspects of a dynamic neuroscience research labCulturing human cell lines including stem cell neuronal lines and primary human linesPerforming a variety of cell-based assaysMaking and maintaining custom cell culture mediaWorking with other ICR scientists to leverage company resources and maximize productivity', 'A BS or MS in a biomedical sciences field', ""It would be ideal if you're already living in the greater NYC area!"", 'A BS or MS in a biomedical sciences fieldExtensive mammalian cell culture experienceSolid knowledge of modern molecular and cell biology lab techniques', 'Managing many day-to-day aspects of a dynamic neuroscience research lab', 'BS or MS', 'highly collaborative environment', 'The ability to work in the United States without sponsorship', 'Excellent English-language communication skills', 'Associate Research Scientists with strong backgrounds in cell culture.', 'neuroregeneration', 'Please note: compensation is commensurate with experience.', ""And you'll definitely need:"", 'mammalian cell culture experience', 'modern molecular and cell biology lab techniques', 'Experience with flow cytometry', 'greater NYC area!', 'a small-group vibe', 'neuroprotection', ""InVitro Cell Research (ICR) is dedicated to solving some of the most difficult problems in aging and age-related disease, including aspects of neuroscience like neurodegeneration, neuroprotection and neuroregeneration. We're a growing company with a small-group vibe and a highly collaborative environment."", 'To have a friendly, easy going personality', 'It would be great if you also have:', ""We're hiring Associate Research Scientists with strong backgrounds in cell culture. This is a great opportunity for a bright undergraduate looking to go to medical or veterinary school in a few years!"", 'Please note:', 'Making and maintaining custom cell culture media', 'Extensive mammalian cell culture experience']",Entry level,Full-time,Research,Research,2020-11-05 11:32:32
Data Engineer,Idexcel,"McLean, VA",3 hours ago,156 applicants,"['', 'Job Description', 'Contract 2 Hire/Lon Term', 'Top Skills: Spark and Scala', 'Measuring data quality and making improvements to data standards, helping application teams to publish data in the correct format so it becomes easy for downstream consumption.', 'Build out data consumption views and provisioning self-service reporting needs via demonstrated dimensional modeling skills.', 'McLean,VA', 'Data Engineer', 'Apply domain driven design practices to build out data applications. Experience in building out conceptual and logical models.', 'Develop sustainable data driven solutions with current new gen data technologies to meet the needs of our organization and business customers.', 'Big Data applications using Open Source frameworks like Apache Spark, Scala and Kafka on AWS and Cloud based data warehousing services such as Snowflake.']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Research Associate II (Scientific),Experis,"Framingham, MA",21 hours ago,Be among the first 25 applicants,"['', 'BS/MS/PhD in science related disciplineExperience with LC/MS analysis', 'Scientist position in LC-MS', 'BS/MS/PhD in science related discipline', 'Responsible for LC-MS analysis for small molecule (especially lipids).', 'Investigate basic technical problems and performs routine scientific procedures and experiments under general supervision.', 'Integrate, compile, and tabulate data and assist supervisor in the analysis and interpretation of the results.', 'Experience with LC/MS analysis', 'Employee Responsibilities:', 'Position Details: ', 'Develop, qualify and implement LC-MS based analytical methods', 'Location: Framingham, MA 01701', 'Job Title: Research Associate II (Scientific) ', 'Responsibilities for this position also include sample preparation, mass spectrometry, and data analysis.', 'Description:', ' ', 'ManpowerGroup is an Equal Opportunity Employer (EOE/AA)', 'Contribute to the completion of milestones associated with specific projects.', 'Desired Skills and Experience', 'Duration: 6+ months(+ extension)', 'Plan and prioritize concurrent experimental procedures.', 'Position is full-time, Monday-Friday, 8 a.m.-5 p.m., with overtime as needed. Candidates currently living in MA are encouraged to apply.', 'JOB DESCRIPTION']",Associate,Full-time,Science,Pharmaceuticals,2020-11-05 11:32:32
"Principal Research Scientist, AAV Gene Therapy",Novartis Institutes for BioMedical Research (NIBR),"Cambridge, MA",6 hours ago,Be among the first 25 applicants,"['', 'Job Description', 'Country', 'Functional Area', 'Company/Legal Entity', 'Employment Type', 'The Novartis Group of Companies are Equal Opportunity Employers and take pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status.', 'Business Unit', 'Division', 'Minimum requirements', 'Job Type', 'Minimum Requirements', 'Shift Work', 'EEO Statement', 'Work Location']",Associate,Full-time,Research,Pharmaceuticals,2020-11-05 11:32:32
Product Designer,Hire Velocity,"Tampa, FL",9 hours ago,Be among the first 25 applicants,"['', 'Coordinate with other teams on UI issues like navigation, page routing, product page design and more', 'Cherries on Top', 'Partner with engineering to ensure a high-quality implementation and user experience.', 'Incorporate market research and user research into design solutions', 'Work with marketing, product management, operations, and engineering to generate ideas and turn them into a seamless product experience.', 'BA/BS degree', 'Lead multiple design projects across different product development lifecycles', 'About Us', '4+ years of experience in product design (UX / UI) for responsive web applications, and experience working with cross-functional teams (development, marketing, product, ops, customer care, etc.).', 'Solid understanding of how to create usable, accessible, and modular designs that can scale to millions of users.', 'Ability to pitch and communicate your design work and drive conversations with stakeholders.', 'BA/BS degree4+ years of experience in product design (UX / UI) for responsive web applications, and experience working with cross-functional teams (development, marketing, product, ops, customer care, etc.).Experience conducting user tests, in person, and on platforms like UserTesting.comSolid understanding of how to create usable, accessible, and modular designs that can scale to millions of users.Experience partnering with product managers and other company leaders to execute on the strategy for product features.Experience with prototyping to explore and convey design solutions.Excellent written and verbal communication skills.', 'Experience with prototyping to explore and convey design solutions.', 'Corestream', 'Collaborate closely with product teammates to define your features and contribute to the overall direction of your product area.', 'Conduct usability tests, track usability goals and prepare reports of your findings for development guidance', 'Recipe for Success', 'Partner with marketing team to create a content development strategy', 'Use industry tools (figma, invision, sketch) to design flows, prototypes, sketches, and high-fidelity visuals for your features.', 'Improve your team’s work by asking for and offering feedback from other product teammates and cross-functional teammates.', 'A portfolio demonstrating deep attention to detail, and experience in simplifying complex problems into human interfaces.', 'Experience conducting user tests, in person, and on platforms like UserTesting.com', 'Experience partnering with product managers and other company leaders to execute on the strategy for product features.', 'Excellent written and verbal communication skills.', 'Overview', 'Lead creative direction to drive user acquisitions and product adoption', 'Work with marketing, product management, operations, and engineering to generate ideas and turn them into a seamless product experience.Collaborate closely with product teammates to define your features and contribute to the overall direction of your product area.Partner with engineering to ensure a high-quality implementation and user experience.Use industry tools (figma, invision, sketch) to design flows, prototypes, sketches, and high-fidelity visuals for your features.Improve your team’s work by asking for and offering feedback from other product teammates and cross-functional teammates.Partner with product leaders to establish project goal and hypothesis, and collaborate with engineers and data scientist to setup design experimentsLead multiple design projects across different product development lifecyclesIncorporate market research and user research into design solutionsLead creative direction to drive user acquisitions and product adoptionPartner with marketing team to create a content development strategyCoordinate with other teams on UI issues like navigation, page routing, product page design and moreConduct usability tests, track usability goals and prepare reports of your findings for development guidance', 'A portfolio demonstrating deep attention to detail, and experience in simplifying complex problems into human interfaces.Ability to pitch and communicate your design work and drive conversations with stakeholders.', 'About LLR Partners', 'Partner with product leaders to establish project goal and hypothesis, and collaborate with engineers and data scientist to setup design experiments', 'Your Mission']",Associate,Full-time,Design,Construction,2020-11-05 11:32:32
Senior Scientific Researcher - In vitro Human Brain Modeling,Genentech,"South San Francisco, CA",9 hours ago,Be among the first 25 applicants,"['', 'Job Facts', 'SCHEDULE', 'The Position', 'JOB TYPE', 'Who We Are', 'in vitro', 'JOB FUNCTION', 'Research COMPANY/DIVISION']",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
"Sr. Analyst, Consumer Financing",SmileDirectClub,"Nashville, TN",8 hours ago,Be among the first 25 applicants,"['', ' What are our customers saying? Link here. ', ' What is SmileDirectClub? Link here.  What are our customers saying? Link here.  What is a SmileShop? Link here.  What is our culture like? Link here.  How do we celebrate your team members? Link here. ', ' Be fluent in one or more of our markets’ lending landscape ', ' Medical, Dental and Vision Insurance  401K with match  PTO  Aligner and Whitening Benefit  Collaborative work environment and positive culture ', ' Collaborate closely with Analytics teams to understand the data landscape and how to work within it ', ' Expert in Excel and SQL ', ' How do we celebrate your team members? Link here. ', 'Job Type ', ' competitive advantage for SmileDirectClub ', ' Flexible, adaptable, and able to work in an entrepreneurial environment ', 'Responsibilities', ' What is our culture like? Link here. ', ' Need help finding the right job? ', ' Help build out and own our analytics tool, Looker. Be the most passionate that data is a  competitive advantage for SmileDirectClub  Be fluent in one or more of our markets’ lending landscape  Use data to optimize payment authorization rates and collections  Develop and maintain KPI reports and dashboards that communicate key business trends and  highlight opportunities for growth and operational improvements  Work with the executive team to understand weekly, monthly, and quarterly business performance. This role will have significant exposure to Senior Leadership  Collaborate closely with Analytics teams to understand the data landscape and how to work within it ', 'Company Profile', ' Collaborative work environment and positive culture ', ' An excellent communicator who loves to share findings and actionable insights ', ' Medical, Dental and Vision Insurance ', ' highlight opportunities for growth and operational improvements ', 'Options', ' 3-5 years experience in consumer credit risk management or lending analytics preferred ', ' PTO ', ' Naturally curious; seeks out answers by diving deep into the data ', ' Experience as a Data Analyst, Data Scientist or Management Consultant preferred ', 'Qualifications', ' What is a SmileShop? Link here. ', ' 401K with match ', ' Aligner and Whitening Benefit ', 'Benefits Of Joining The Club', ' Highly motivated self-starter ', ' Work with the executive team to understand weekly, monthly, and quarterly business performance. This role will have significant exposure to Senior Leadership ', ' Interested in leveraging technology to do cutting edge reporting and analysis ', 'Overview', ' Experience as a Data Analyst, Data Scientist or Management Consultant preferred  Expert in Excel and SQL  Experience with data visualization tools, Python, and R a plus  Interested in leveraging technology to do cutting edge reporting and analysis  3-5 years experience in consumer credit risk management or lending analytics preferred  Naturally curious; seeks out answers by diving deep into the data  An excellent communicator who loves to share findings and actionable insights  Highly motivated self-starter  Flexible, adaptable, and able to work in an entrepreneurial environment ', ' Use data to optimize payment authorization rates and collections ', ' Experience with data visualization tools, Python, and R a plus ', ' Develop and maintain KPI reports and dashboards that communicate key business trends and ', ' Help build out and own our analytics tool, Looker. Be the most passionate that data is a ', ' What is SmileDirectClub? Link here. ']",Associate,Full-time,Finance,Marketing and Advertising,2020-11-05 11:32:32
Senior Developer Technology Engineer - AI,NVIDIA,"Santa Clara, CA",5 hours ago,32 applicants,"['', 'Study and develop cutting-edge techniques in deep learning, graphs, machine learning, and data analytics, and perform in-depth analysis and optimization to ensure the best possible performance on current- and next-generation GPU architectures.Work directly with key customers to understand the current and future problems they are solving and provide the best AI solutions using GPUs.Collaborate closely with the architecture, research, libraries, tools, and system software teams at NVIDIA to influence the design of next-generation architectures, software platforms, and programming models.', 'Collaborate closely with the architecture, research, libraries, tools, and system software teams at NVIDIA to influence the design of next-generation architectures, software platforms, and programming models.', 'Experience with parallel programming, ideally CUDA C/C++.', 'We are now looking for a Senior Developer Technology Engineer focused on Deep Learning and AI:', 'What You Will Be Doing', 'A Masters or PhD in a Computer Engineering or Computer Science related discipline (or have equivalent experience), with 3+ years of relevant work or research experience.', 'Work directly with key customers to understand the current and future problems they are solving and provide the best AI solutions using GPUs.', 'Strong communication and organization skills, with a logical approach to problem solving, good time management, and task prioritization skills.', 'What We Need To See', 'Your work displays a strong knowledge of C/C++, software design, programming techniques, and AI algorithms.', 'Study and develop cutting-edge techniques in deep learning, graphs, machine learning, and data analytics, and perform in-depth analysis and optimization to ensure the best possible performance on current- and next-generation GPU architectures.', 'Some travel is required for conferences and for on-site visits with developers.', 'A Masters or PhD in a Computer Engineering or Computer Science related discipline (or have equivalent experience), with 3+ years of relevant work or research experience.Your work displays a strong knowledge of C/C++, software design, programming techniques, and AI algorithms.Experience with parallel programming, ideally CUDA C/C++.Strong communication and organization skills, with a logical approach to problem solving, good time management, and task prioritization skills.Some travel is required for conferences and for on-site visits with developers.']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Sr UX Design Researcher,GE Healthcare,"Chicago, IL",22 hours ago,Be among the first 25 applicants,"['', 'Maintain, input and help manage the research repository and candidate recruitment database', 'Optionally, also lead design thinking / co-creation/ service design workshops that take stakeholders through the design thinking process to frame a project.', 'Understands the skills necessary for contributing to constructive conversations utilizing active listening and validating the information needs of stakeholders and users.', 'Flexibility in research approaches and strong, pragmatic bias for action, always trying to seek the most expedient path to get the insights needed without compromising on findings or integrity', 'Legal authorization to work in the U.S. is required. GE may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills.Any offer of employment is conditioned upon the successful completion of a background investigation and drug screenMust be willing to travel for research activities in the futureMust be willing to work out of an office located in CHICAGO IL or WAUKESHA WI', 'Extremely strong written and verbal communication skills', 'Bachelor’s Degree in Cognitive or Experimental Psychology, Human Computer Interaction, Human Factors; or in “STEAM” Majors (Science, Technology, Engineering, Arts and Math); or equivalent experience', 'Frame reports, write-ups and insights in a way that inspires design teams to develop imaginative and appropriate solutions. Help to facilitate teams through analysis and synthesis of user research, helping to distill the most important insights and link them together in frameworks, principles, and implications for design. Design researchers must be confident about leading teams and users through a range of research analysis and synthesis processes.', 'Demonstrates a deep passion for learning and courage to push the boundaries of one’s own thinking.', 'Any offer of employment is conditioned upon the successful completion of a background investigation and drug screen', 'Can create and communicate research artifacts, findings, reports, and recommendations with stakeholders in compelling ways: Executive summaries, reports, key findings and insights, case studies', 'Plan and conduct interview sessions with users and stakeholders, including executives.', 'Communicate design insights and opportunities throughout all phases of design process and product lifecycle, from concept to release. Utilize Compelling storytelling to deliver insights about people and behavior - verbally and visually - in a way that generates empathy, emotion, and engagement from the design team as well as engineering, product management, marketing and others.', 'If Discovery research is needed, structure user-centered research and work with a variety of teams through fieldwork to determine users physical, cognitive, social, emotional, and cultural needs. Research specialists must have proven experience in uncovering unmet user needs, and unpacking meaning from sometimes obscure and disparate findings.', 'Desired Characteristics', 'High attention to detail', 'Awareness and enjoyment of using Lean research / informal testing methods earlier in the design process to obtain early insights, when possible', 'Strongly Desired: Knowledge of FDA formative & summative usability testing and past medical device or healthcare research experience', 'Expresses technology options to collaborators on cross functional teams. Goes beyond merely suggesting design technologies and clearly articulates the rationale and benefit of design technology choices.', 'Research and evaluate emerging design, technology, and industry trends and competitive products; champion new ideas and approaches as appropriate.', 'Lead / facilitate constructive design critiques', 'Demonstrates the ability to connect, extract information, and communicate with customer groups', 'Select and use appropriate user research methods to address UX and product research needs. Be equally comfortable with discovery research and concept and validation testing', 'Can evaluate and prioritize research priorities and backlog based on user, business and product criticality.', 'Keeps current on industry landscape and brings new ideas to the team. Maps customer feedback, industry trends, market research and competitive product research to internal vision and recommendations', 'Exceedingly organized, proactive and self-motivated', 'Joins and participates in industry associations and conferences.', 'Propose designs, features or changes to product solutions based on research and synthesis outcomes; influence change', 'Frame, scope, and lead execution of UX and Design research projects, largely independentlyLead / facilitate constructive design critiquesPropose designs, features or changes to product solutions based on research and synthesis outcomes; influence changeSelect and use appropriate user research methods to address UX and product research needs. Be equally comfortable with discovery research and concept and validation testingPlan and conduct interview sessions with users and stakeholders, including executives.Research and evaluate emerging design, technology, and industry trends and competitive products; champion new ideas and approaches as appropriate.If Discovery research is needed, structure user-centered research and work with a variety of teams through fieldwork to determine users physical, cognitive, social, emotional, and cultural needs. Research specialists must have proven experience in uncovering unmet user needs, and unpacking meaning from sometimes obscure and disparate findings.Frame reports, write-ups and insights in a way that inspires design teams to develop imaginative and appropriate solutions. Help to facilitate teams through analysis and synthesis of user research, helping to distill the most important insights and link them together in frameworks, principles, and implications for design. Design researchers must be confident about leading teams and users through a range of research analysis and synthesis processes.Maintain, input and help manage the research repository and candidate recruitment databaseHelp manage, oversee, monitor and optimize candidate recruitment, approvals, costs and 3rd party vendorsCommunicate design insights and opportunities throughout all phases of design process and product lifecycle, from concept to release. Utilize Compelling storytelling to deliver insights about people and behavior - verbally and visually - in a way that generates empathy, emotion, and engagement from the design team as well as engineering, product management, marketing and others.Participates in planning and scoping of research topics and usability testsLead FDA-mandated formative & summative usability testing for healthcare productsRun standardized distance, accessibility and metaphor evaluation tests for Edison Design System componentsMine existing product usage analytics as a research sourceOptionally, also lead design thinking / co-creation/ service design workshops that take stakeholders through the design thinking process to frame a project.', 'Acts and decides appropriately when all available information may not be possible to obtain', 'Help manage, oversee, monitor and optimize candidate recruitment, approvals, costs and 3rd party vendors', 'Run standardized distance, accessibility and metaphor evaluation tests for Edison Design System components', 'Deep knowledge of research tools and methods from discovery to post-launch evaluation and survey, recruitment, acquisition tools and methods', 'Excellent facilitator; Keeps participants focused on task and end process. Guides participation to include all present; solicits information about absent stakeholders.', 'Essential Responsibilities :', 'Legal authorization to work in the U.S. is required. GE may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills.', 'Must be willing to work out of an office located in CHICAGO IL or WAUKESHA WI', 'As a systems thinker in a platform team, works with cross-functional teams and cross-business teams and assists in driving broad-reaching solutions across the function / business.', '3+ years professional experience with Master’s Degree. 6+ years professional experience with Bachelor’s Degree.; or equivalent experience', 'Mine existing product usage analytics as a research source', 'Experience with conducting qualitative and quantitative research activities such as ethnographic studies and usability studies, including surveys (qualitative and quantitative) and overseeing the work of external research partners and agencies', 'GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable).', 'Leads and recommends both short- and long-term research activities, contributing to the creation of a research planExperience with conducting qualitative and quantitative research activities such as ethnographic studies and usability studies, including surveys (qualitative and quantitative) and overseeing the work of external research partners and agenciesCan create and communicate research artifacts, findings, reports, and recommendations with stakeholders in compelling ways: Executive summaries, reports, key findings and insights, case studiesHigh attention to detailExceedingly organized, proactive and self-motivatedExtremely strong written and verbal communication skillsDeep knowledge of research tools and methods from discovery to post-launch evaluation and survey, recruitment, acquisition tools and methodsFlexibility in research approaches and strong, pragmatic bias for action, always trying to seek the most expedient path to get the insights needed without compromising on findings or integrityAwareness and enjoyment of using Lean research / informal testing methods earlier in the design process to obtain early insights, when possibleStrongly Desired: Knowledge of FDA formative & summative usability testing and past medical device or healthcare research experienceDesired: knowledge of usage analytics and use of aggregate analytics data as a research sourceDesired but optional: design thinking / co-creation/ service design facilitation experience, takes various stakeholders through the design thinking process to frame a project.Creates, analyzes and can self-manage research projects independentlyCan evaluate and prioritize research priorities and backlog based on user, business and product criticality.Understands key principles of design thinking and research, what it is and why it is important. Explores all ideas, regardless of their source.', 'Creates, analyzes and can self-manage research projects independently', 'Continuously measures deliverables of self against scheduled commitments. Effectively balances different, competing objectives.', 'Lead FDA-mandated formative & summative usability testing for healthcare products', 'Leads and recommends both short- and long-term research activities, contributing to the creation of a research plan', 'Understands key principles of design thinking and research, what it is and why it is important. Explores all ideas, regardless of their source.', 'Job Description', 'Qualifications/Requirements', 'Relocation Assistance Provided: ', 'Systems process approach; aims to limit research rework, improve research process efficiencies and leverage existing research findings', 'Continuously measures deliverables of self against scheduled commitments. Effectively balances different, competing objectives.Excellent facilitator; Keeps participants focused on task and end process. Guides participation to include all present; solicits information about absent stakeholders.Expresses technology options to collaborators on cross functional teams. Goes beyond merely suggesting design technologies and clearly articulates the rationale and benefit of design technology choices.Can advocate forthe value of a rigorous and transparent, research-based decision-making process.Joins and participates in industry associations and conferences.Keeps current on industry landscape and brings new ideas to the team. Maps customer feedback, industry trends, market research and competitive product research to internal vision and recommendationsSystems thinker, mapping findings from one product to another and understanding the impact of research based on platform relationships, interdependencies and product commonalitiesSystems process approach; aims to limit research rework, improve research process efficiencies and leverage existing research findingsAs a systems thinker in a platform team, works with cross-functional teams and cross-business teams and assists in driving broad-reaching solutions across the function / business.Understands the skills necessary for contributing to constructive conversations utilizing active listening and validating the information needs of stakeholders and users.Demonstrates a deep passion for learning and courage to push the boundaries of one’s own thinking.Acts and decides appropriately when all available information may not be possible to obtainDemonstrates the ability to connect, extract information, and communicate with customer groups', 'Bachelor’s Degree in Cognitive or Experimental Psychology, Human Computer Interaction, Human Factors; or in “STEAM” Majors (Science, Technology, Engineering, Arts and Math); or equivalent experience3+ years professional experience with Master’s Degree. 6+ years professional experience with Bachelor’s Degree.; or equivalent experience', 'Frame, scope, and lead execution of UX and Design research projects, largely independently', 'Participates in planning and scoping of research topics and usability tests', 'Desired: knowledge of usage analytics and use of aggregate analytics data as a research source', 'Can advocate forthe value of a rigorous and transparent, research-based decision-making process.', 'Must be willing to travel for research activities in the future', 'Additional Eligibility Qualifications', 'Desired but optional: design thinking / co-creation/ service design facilitation experience, takes various stakeholders through the design thinking process to frame a project.', 'In This Role, You Will', 'Leadership and Personal Attributes', 'Systems thinker, mapping findings from one product to another and understanding the impact of research based on platform relationships, interdependencies and product commonalities', 'Eligibility Requirements']",Associate,Full-time,Information Technology,Hospital & Health Care,2020-11-05 11:32:32
BHJOB15656_15399 -  ETL Data Engineer,Myticas Consulting ULC,Greater Chicago Area,4 hours ago,159 applicants,"['', 'Design, develop and maintain data models, database architectures, and associated database objects in Snowflake, Oracle, and other database solutions such as Azure.', 'Hands on experience in writing and understanding complex SQL (e.g. CTE’s others).', '3+ years of experience in data engineering, data warehousing, business intelligence, ETL on databases such as Oracle or SQL Server, and/or big data is required.', 'Design, develop, and maintain data integrations using Informatica Power Center, Informatica Integrated Cloud Services, and data prep tools.', 'Production experience in OBIEE, Oracle Analytics Cloud (OAC) and Tableau is nice to have.Familiarity with big data technologies such as Microsoft Azure Data or AWS is nice to have.', 'Come join our growing data engineering team! We are looking for a someone with a passion for data integration, analytics, and innovation.', 'Create and maintain necessary technical documentation, including requirements, design, and test documents.', 'A collaborative working style and ability to work well within the team and with business consumers is required.', 'Participate in or drive project activities such as requirements gathering, design, develop, test, and deploy.', 'A Master’s or Bachelor’s degree in Computer Science, MIS, engineering, or a related technical discipline is required.', 'Design, develop and maintain data models, database architectures, and associated database objects in Snowflake, Oracle, and other database solutions such as Azure.Design, develop, and maintain data integrations using Informatica Power Center, Informatica Integrated Cloud Services, and data prep tools.Participate in or drive project activities such as requirements gathering, design, develop, test, and deploy.Assist in the set-up of, and administer, on premise and cloud tools used in the\xa0analytics infrastructure.Create and maintain necessary technical documentation, including requirements, design, and test documents.Identify emerging trends, processes, and techniques impacting our\xa0analytics infrastructure and make suggestions for incorporation of these into the analytics infrastructure.', ""Nice to have's:"", 'Working experience in one of Python/R/Scala, Snowflake is required.', 'Thorough understanding of relational database design and best practices, including dimensional (star, snowflake) models is required.', 'Ability to clearly communicate to technical and non-technical audience by written and verbal is required.', 'A Master’s or Bachelor’s degree in Computer Science, MIS, engineering, or a related technical discipline is required.3+ years of experience in data engineering, data warehousing, business intelligence, ETL on databases such as Oracle or SQL Server, and/or big data is required.3+ years of experience in ETL/ data integration is required with 2+ years of experience in Informatica PowerCenter or similar, job scheduling tools is required.Working experience in one of Python/R/Scala, Snowflake is required.Hands on experience in writing and understanding complex SQL (e.g. CTE’s others).Thorough understanding of relational database design and best practices, including dimensional (star, snowflake) models is required.A collaborative working style and ability to work well within the team and with business consumers is required.Ability to clearly communicate to technical and non-technical audience by written and verbal is required.Independent analytical, critical thinking, and problem-solving ability in complex technical environments is required.', 'Assist in the set-up of, and administer, on premise and cloud tools used in the\xa0analytics infrastructure.', 'Independent analytical, critical thinking, and problem-solving ability in complex technical environments is required.', 'Production experience in OBIEE, Oracle Analytics Cloud (OAC) and Tableau is nice to have.', 'Specific duties include:', ""Must have's:"", 'Identify emerging trends, processes, and techniques impacting our\xa0analytics infrastructure and make suggestions for incorporation of these into the analytics infrastructure.', 'Familiarity with big data technologies such as Microsoft Azure Data or AWS is nice to have.', '3+ years of experience in ETL/ data integration is required with 2+ years of experience in Informatica PowerCenter or similar, job scheduling tools is required.', ""The Data Engineer we hire will perform a variety of project and technical tasks supporting our analytics infrastructure, including data integration and ETL, database architecture and design, data prep, and reporting. You will contribute to all aspects of the project lifecycle, including requirements gathering, design, development, testing, and deployment. Your knowledge of trends, architectures, and tools in the analytics landscape will be integral in incorporating them into our\xa0analytics landscape. Look forward to learning quickly and juggle multiple tasks for various customers. You'll communicate complex technical problems effectively to management and to the business. This role will feature collaboration\xa0with other technical team members on solutions.\xa0""]",Mid-Senior level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Cognizant,"Riverwoods, IL",4 hours ago,Be among the first 25 applicants,"['', 'AWS EMR', 'Kafka', 'AWS', 'Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers.', 'Responsibilities', 'Spark', 'Strong teamwork skills', 'Provide system support as part of a support rotation with other team members.', 'Works with key stakeholders to design complex solutions and lead from inception to production', 'Develop real-time data ingestion and stream-analytic solutions leveraging technologies such as Kafka, Apache Spark, Python, AWS', 'Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.', 'Qualifications', 'About Cognizant', 'Cognizant will not be able to provide sponsorship for this role. Candidates have the option of working remotely.', 'Python', 'Snowflake', 'Develop data driven solutions utilizing current and next generation technologies to meet evolving business needs.', 'Strong desire and capability to automate everything.', 'Company Description', 'Ability to quickly identify an opportunity and recommend possible technical solutions.', 'Strong analytical and problem-solving skills', 'Develop data driven solutions utilizing current and next generation technologies to meet evolving business needs.Ability to quickly identify an opportunity and recommend possible technical solutions.Strong desire and capability to automate everything.Develop real-time data ingestion and stream-analytic solutions leveraging technologies such as Kafka, Apache Spark, Python, AWSCustom Data pipeline development (Cloud and locally hosted)Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers.Provide subject matter expertise in the analysis, preparation of specifications and plans for the development of data processes.Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.Works with key stakeholders to design complex solutions and lead from inception to productionProvide system support as part of a support rotation with other team members.', 'Provide subject matter expertise in the analysis, preparation of specifications and plans for the development of data processes.', 'AWSAWS EMRSparkPythonSnowflakeKafkaStrong teamwork skillsStrong analytical and problem-solving skills', 'Custom Data pipeline development (Cloud and locally hosted)']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Databricks,"San Francisco, CA",4 hours ago,105 applicants,"['', 'Employee referral bonus program ', 'Outcomes', 'Mission', 'Analytics: ', 'Gym reimbursement ', 'Unlimited Paid Time Off', 'Collaboration:', 'Benefits', 'Maternity and paternity plans ', 'Experience supporting and working with cross-functional teams in a dynamic environment.', 'Competencies', 'Experience with building data pipeline from various business applications like Salesforce, Marketo, NetSuite, Workday etc. ', ' We are looking for a candidate with 8+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. In depth knowledge of Model and Design of DB schemas for read and write performance. Extensive working knowledge of API or Stream based data extraction processes like Salesforce API and Bulk API is must. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Build processes supporting data transformation, data structures, metadata, dependency and workload management. A successful history of manipulating, processing and extracting value from large disconnected datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Experience supporting and working with cross-functional teams in a dynamic environment. Experience with building data pipeline from various business applications like Salesforce, Marketo, NetSuite, Workday etc.  Experience with big data tools: Hadoop, Spark, Kafka, Spark & Kafka Streaming, Python, Scala, Talend etc. Working knowledge of BI Tools like Tableau, Looker etc is plus ', '401k Retirement Plan ', 'Extensive working knowledge of API or Stream based data extraction processes like Salesforce API and Bulk API is must.', 'Build processes supporting data transformation, data structures, metadata, dependency and workload management.', 'Working knowledge of BI Tools like Tableau, Looker etc is plus', 'Experience with big data tools: Hadoop, Spark, Kafka, Spark & Kafka Streaming, Python, Scala, Talend etc.', ' Medical, dental, vision 401k Retirement Plan  Unlimited Paid Time Off Gym reimbursement  Employee referral bonus program  Maternity and paternity plans  ', 'About Databricks', 'Design/Strategy:', 'A successful history of manipulating, processing and extracting value from large disconnected datasets.', 'We are looking for a candidate with 8+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', 'Medical, dental, vision', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. In depth knowledge of Model and Design of DB schemas for read and write performance.', 'Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Sr. Design Researcher,"Intelliswift Software, Inc.","San Jose, CA",1 day ago,Be among the first 25 applicants,"['4+ years of experience in an applied user research settingAdvanced Degree in Human Factors, Human-Computer Interaction, Cognitive or Experimental Psychology, Cognitive Science, or a related fieldConsistent track record of building and curating a Design Research program, employing a range of methodologies depending on needPractical experience in deploying qualitative and quantitative research methods throughout the product development lifecycle, from conceptualization to launchAbility to solve complex problems and support the team in delivery of insightsStrong communication skills, experienced influencer, storyteller, and advocate for user research', ""Human-centered insights and a deep understanding of people and cultures are critical to how we do our best work. Our team of Design Researchers guide design partners and cross-functional teams at Client to Client, interpret, and communicate insights and opportunities in an inspiring way, while contributing to all phases of the design process.We're looking for a driven researcher who is radically inspired by people and excels at leading the charge of gathering and communicating insights that put our users at the center of our product thinking. The ideal candidate loves working with peers and leaders to mine for insights that drive elegant solutions to tough problems.In this role, you will work alongside partners from Design, Product Management, Engineering, Marketing, and other core teams to ensure your research is optimized to develop key insights to drive great experiences. You will also work closely with our team of talented Design Researchers in designing, planning, conducting, and socializing user research across a spectrum of methodologies."", '4+ years of experience in an applied user research setting', 'Responsibilities:', 'Establish and maintain an efficient strategy for scoping research, execution, visual storytelling and utilization of findings and artifacts to ensure alignment and action across internal partners', 'Utilize a mixed-methods practice of gathering both generative and evaluative insights. Methods may include: in-lab and field studies, online surveys, usability testing, moderated and unmoderated remote testing, participatory design, customer journey mapping, personas, benchmarking, heuristic evaluations, in-depth user interviews, as well as stakeholder interviews', '\xa0', 'Utilize a mixed-methods practice of gathering both generative and evaluative insights. Methods may include: in-lab and field studies, online surveys, usability testing, moderated and unmoderated remote testing, participatory design, customer journey mapping, personas, benchmarking, heuristic evaluations, in-depth user interviews, as well as stakeholder interviewsEstablish and maintain an efficient strategy for scoping research, execution, visual storytelling and utilization of findings and artifacts to ensure alignment and action across internal partnersMonitor the impact of insights generated by the team and take part in the always-growing Design Research practice at Client', 'eCommerce/global research experience desired', 'Ability to solve complex problems and support the team in delivery of insights', 'Practical experience in deploying qualitative and quantitative research methods throughout the product development lifecycle, from conceptualization to launch', 'Human-centered insights and a deep understanding of people and cultures are critical to how we do our best work. Our team of Design Researchers guide design partners and cross-functional teams at Client to Client, interpret, and communicate insights and opportunities in an inspiring way, while contributing to all phases of the design process.', 'Qualifications:', 'Monitor the impact of insights generated by the team and take part in the always-growing Design Research practice at Client', 'Advanced Degree in Human Factors, Human-Computer Interaction, Cognitive or Experimental Psychology, Cognitive Science, or a related field', 'In this role, you will work alongside partners from Design, Product Management, Engineering, Marketing, and other core teams to ensure your research is optimized to develop key insights to drive great experiences. You will also work closely with our team of talented Design Researchers in designing, planning, conducting, and socializing user research across a spectrum of methodologies.', 'Consistent track record of building and curating a Design Research program, employing a range of methodologies depending on need', ""We're looking for a driven researcher who is radically inspired by people and excels at leading the charge of gathering and communicating insights that put our users at the center of our product thinking. The ideal candidate loves working with peers and leaders to mine for insights that drive elegant solutions to tough problems."", 'Strong communication skills, experienced influencer, storyteller, and advocate for user research']",Mid-Senior level,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Glocomms,San Francisco Bay Area,19 hours ago,Over 200 applicants,"['', 'Maintaining data platform and managing computing infrastructureWorking with vast amounts of structured and unstructured dataImplementing big data frameworks such as Hive and ImpalaDesigning and Developing ETL tools', 'Working with vast amounts of structured and unstructured data', 'One of the fastest-growing and most innovative Autonomous Driving Technology companies is actively looking to add a Senior Data Engineer on their Analytics team.\xa0As part of a newly developed Engineering team, you will work on designing and building out the AWS data pipeline to fuel the company along its digital journey. The ideal candidate will be a self-starter with superior communication skills (verbal and written).\u202fA solid understanding of data science, advanced statistics, machine learning, data mining and visualization techniques are a must. In addition to the following qualifications, the desire and ability to learn quickly is vital.', 'Requirements:', 'Senior Data Engineer - Analytics', '\xa0', 'Leading Autonomous Driving Company', 'The future Sr. Data Engineer will be responsible for:', 'Maintaining data platform and managing computing infrastructure', 'Implementing big data frameworks such as Hive and Impala', 'Experience working with multiple cloud technologies (AWS, GCP, AZURE)', 'Previous experience working in a Hadoop eco-system (Spark, HDFS)', 'Designing and Developing ETL tools', 'Salary: $180 - $200k + Bonus and Equity', 'Proficient in Python and SQL', '5-7 years’ experience in a previous Data Engineering role or Software Engineering, Big Data role', 'SF Bay Area', 'Previous programming experience in Scala', '5-7 years’ experience in a previous Data Engineering role or Software Engineering, Big Data roleProficient in Python and SQLPrevious programming experience in ScalaPrevious experience working in a Hadoop eco-system (Spark, HDFS)Experience working with multiple cloud technologies (AWS, GCP, AZURE)']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Senior Data Engineer,Samba TV,"San Francisco, CA",15 hours ago,54 applicants,"['', 'Responsibilities', 'Solid foundation in computer science, with strong competencies in data structures, algorithms and software design.', 'Strong command of a programming language or two – while we code primarily in Python, we acknowledge that engineers with sound fundamentals can pick up new languages relatively quickly.', 'As a member of this team, you will help architect, build, operate, and maintain our data pipelines responsible for aggregating television viewing data and deriving metrics and insights that power a variety of our data products and offerings. You will not only work on our pipeline jobs, but you will also have the opportunity to help build out and further evolve our internal frameworks upon which we process and deliver data at scale.', 'Create new data processing systems as necessary to support our Data Scientists and Research Analysts.', 'Analyze and improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes for our core systems.Create and manage platform-specific APIs.Create new data processing systems as necessary to support our Data Scientists and Research Analysts.Ultimately, build robust, high-volume production software.', 'Experience with Hadoop, Spark, or similar technologies is desirable.', 'At Samba TV, we are on a mission to fundamentally change television viewing for everyone. We are doing this by leveraging our data to enable advertisers to engage and measure TV viewers across all their devices. We have an amazing story with a unique perspective formed by innovative technology.', 'Ultimately, build robust, high-volume production software.', 'Create and manage platform-specific APIs.', 'Requirements', 'Experience with running production systems on AWS is also a plus.', '3+ years of professional development experience building high-performance, large-scale applications/pipelines.', 'Excellent problem solving skills. Ability to interpret and analyze data is a must. Consequently, mathematical inclination is a major plus.', 'Analyze and improve the efficiency, scalability, and stability of data collection, storage, and retrieval processes for our core systems.', 'Help us transform the TV viewing experience for everyone!', 'Strong command of a programming language or two – while we code primarily in Python, we acknowledge that engineers with sound fundamentals can pick up new languages relatively quickly.Excellent problem solving skills. Ability to interpret and analyze data is a must. Consequently, mathematical inclination is a major plus.3+ years of professional development experience building high-performance, large-scale applications/pipelines.Solid foundation in computer science, with strong competencies in data structures, algorithms and software design.Experience with Hadoop, Spark, or similar technologies is desirable.Experience with running production systems on AWS is also a plus.', 'Core Viewership is responsible for the data processing pipelines that produce key datasets consumed by our data scientists, research analysts, and external customers, as well as power our analytics platform. This team deals with data at scale — on a continuous basis, we ingest, process, and ultimately make sense of incoming viewing data from millions of televisions.']",Not Applicable,Full-time,Information Technology,Internet,2020-11-05 11:32:32
Senior UX Researcher,hear.com,"Denver, CO",1 day ago,Be among the first 25 applicants,"['', 'Create concise research reports', 'Analyze competitors and their products', 'Teleaudiology team', ' Understand product specifications and user psychology Define and refine personas as well as their user journeys Identify user needs before the users recognize them Mentor the whole team on research methodologies Create concise research reports Advocate for our users during ideation and other meetings Analyze competitors and their products Conduct user tests together with our product managers and designers Lead both in-person as well as remote interviews Validate our current product portfolio Utilize both qualitative and quantitative data to generate recommendations ', 'Your Profile', 'Experience in mentoring teams', 'Utilize both qualitative and quantitative data to generate recommendations', 'Identify user needs before the users recognize them', 'Excellent salary and benefits package with entrepreneurial incentives', 'Experience researching complex systems with multiple personas and stakeholders', 'A unique content-driven, top-performing and family-type work culture', 'Define and refine personas as well as their user journeys', 'Nice to have: Experience in the medical sector', 'A chance to shape the future of a health-technology leader', ' Working as an UX Researcher for 5+ years Experience researching complex systems with multiple personas and stakeholders Degree in Psychology or similar Strong analytical skills and no fear in pointing out areas of improvement of existing solutions Organized and able to work independently Excellent communication skills Experience in mentoring teams Knowledge in tools like Hotjar or Domo for qualitative and quantitative research Nice to have: Experience in the medical sector ', 'hear.com ', 'A high degree of autonomy and responsibility from day one', ' An opportunity to work with happy and grateful customers every single day A chance to shape the future of a health-technology leader A unique content-driven, top-performing and family-type work culture A high degree of autonomy and responsibility from day one An open-minded and international working environment that fosters creativity Excellent salary and benefits package with entrepreneurial incentives ', 'What We Offer', 'Conduct user tests together with our product managers and designers', 'An opportunity to work with happy and grateful customers every single day', 'Lead both in-person as well as remote interviews', 'Degree in Psychology or similar', 'Working as an UX Researcher for 5+ years', 'Understand product specifications and user psychology', 'Senior UX Researcher', 'Knowledge in tools like Hotjar or Domo for qualitative and quantitative research', 'Mentor the whole team on research methodologies', 'Excellent communication skills', 'Strong analytical skills and no fear in pointing out areas of improvement of existing solutions', 'Main Tasks', 'Organized and able to work independently', 'An open-minded and international working environment that fosters creativity', 'Advocate for our users during ideation and other meetings', 'Validate our current product portfolio']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Data Engineer with Security Clearance,ClearanceJobs,"Quantico, VA",17 hours ago,Be among the first 25 applicants,"['', ' Develop a data catalog to help organize and find data stored in their many systems. The data catalog shall include information about tables, files, and databases from the Enterprise Resource Planning (ERP), human resources (HR), finance, capability platforms, and social media feeds. The data catalog must also show where all the data entities are located.', ' Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements.', 'Schemas', ' Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms).', ' Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities. Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs.', ' Identify and manage risks proactively.', ' Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Java, and C++.', ' Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management.', 'Metadata', 'Data Transformation', ' Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners.', ' Optimize and consolidate business and operational data while augmenting it with data about, and often generated by customers. Expand the data infrastructure to include sensor, device data, and other data sources.', ' Minimum six years or more of work experience in data management disciplines including [data integration, modeling, optimization and data quality], and/or other areas directly relevant to data engineering responsibilities and tasks.', 'Required Skills', ' Minimum six years or more of work experience in data management disciplines including [data integration, modeling, optimization and data quality], and/or other areas directly relevant to data engineering responsibilities and tasks. Strong experience with advanced analytics tools for Object-oriented/object function scripting using languages such as R, Python, Java, and C++. Strong ability to design, build and manage data pipelines for data structures encompassing:Data TransformationData ModelsSchemasMetadataWorkload Management Apply today! Please send your resume to bpavelka@beaconhillstaffing today for immediate consideration.', ' Make recommendations to improve the efficiency and effectiveness in how DATA IS acquired, stored, managed, and shared.', ' Establish shared operational data and integrated enterprise data, all while managing and/or improving data quality and security through the creation of business-driven governance structures and culture change management. Establish data policies, standards, and procedures that improve data quality, availability, accessibility, security, usability, and enforcement of enterprise information management (EIM) program requirements. Establish enterprise standards – including a uniform and repeatable system development lifecycle methodology for Reference Data and Master Data (e.g., a common set of standards for data naming, abbreviations, and acronyms). Develop a data catalog to help organize and find data stored in their many systems. The data catalog shall include information about tables, files, and databases from the Enterprise Resource Planning (ERP), human resources (HR), finance, capability platforms, and social media feeds. The data catalog must also show where all the data entities are located. Develop a Master Data Management (MDM) Plan that focuses on the technology, tools, and processes ensuring master data is coordinated across the enterprise. MDM is a method used to define and manage the critical data of an organization to provide, with data integration, a single point of reference. The data that is mastered may include reference data – the set of permissible values, and the analytical data supporting decision making. MDM provides a unified master data service intended to provide accurate, consistent and complete master data across the enterprise and to business partners. Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry. Optimize and consolidate business and operational data while augmenting it with data about, and often generated by customers. Expand the data infrastructure to include sensor, device data, and other data sources. Make recommendations to improve the efficiency and effectiveness in how DATA IS acquired, stored, managed, and shared. Engage business users and stakeholders for the increased release of actionable high-quality data on key operational and tactical activities. Develop technology solutions to provide the platform, training, and standardized tools enabling querying, data mining, statistical analysis, reporting, scenario modeling, data visualization, and dash-boarding, and processes for a centralized, or analytics as a service model, allowing for the sharing of data across the enterprise from a common hub, facilitates cross-organizational data initiatives due to its enterprise-wide view of data assets and needs. Identify and manage risks proactively.', 'Workload Management Apply today! Please send your resume to bpavelka@beaconhillstaffing today for immediate consideration.', 'Data Models', ' Recommend solutions based on performing industry-specific analysis, such as case studies describing data management best practices, identifying trends across the industry.', ' Strong ability to design, build and manage data pipelines for data structures encompassing:']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Principal Big Data Engineer,"Plume Design, Inc","Palo Alto, CA",6 hours ago,Be among the first 25 applicants,"['', ' BA/BS in Computer Science, Information Systems or equivalent. Experienced: 6+ years building, scaling, tuning, managing and supporting production ETL pipelines for multiple terabytes of data. Prolific Programmer - 3+ years of Scala or Java. Technology Framework Expert - in a variety of data infrastructures, such as: Batch processing: Apache Spark Messaging: Kafka, Zookeeper, Pulsar Storage: Hive, Mongo DB, Athena, Cassandra, PostgreSQL   A technical leader: you make intuitive decisions about what services, frameworks, and capabilities need to be in place before they are needed. Self Driven - able to own a project from inception to completion Mentor - open and active in sharing knowledge as well as excellent communication skills SQL Savvy - able to query and discover data with SQL', 'Batch processing: Apache Spark', 'Interact with business stakeholders to understand and analyze BI requirements and design and document updates to dimensional model and schemas to support desired queries', 'Build infrastructure and abstractions that can enable anyone (engineer or data scientist) to craft scalable pipelines for whatever the purpose is: metrics, analysis, machine learning, dashboard visualizations', 'Be responsive in triaging and fixing any issues related to production data quality and availability.', ' Batch processing: Apache Spark Messaging: Kafka, Zookeeper, Pulsar Storage: Hive, Mongo DB, Athena, Cassandra, PostgreSQL ', 'Prolific Programmer - 3+ years of Scala or Java.', 'Storage: Hive, Mongo DB, Athena, Cassandra, PostgreSQL', 'Experienced: 6+ years building, scaling, tuning, managing and supporting production ETL pipelines for multiple terabytes of data.', 'A technical leader: you make intuitive decisions about what services, frameworks, and capabilities need to be in place before they are needed.', 'What You Will Do', 'Scala or Java', 'Mentor - open and active in sharing knowledge as well as excellent communication skills', 'Mentor and assist junior team members and new hires to become successful and productive.', '6+ years', 'Self Driven - able to own a project from inception to completion', 'Messaging: Kafka, Zookeeper, Pulsar', 'Adhere to data protection requirements including data access, retention, residency and de-identification.', ' Interact with business stakeholders to understand and analyze BI requirements and design and document updates to dimensional model and schemas to support desired queries Understand available sources of data and design, implement, validate, deploy, manage, tune and monitor data pipelines to deliver the target schemas to the performance and quality spec. Adhere to data protection requirements including data access, retention, residency and de-identification. Create data validation checks and scripts to ensure high data quality and availability. Be responsive in triaging and fixing any issues related to production data quality and availability. Mentor and assist junior team members and new hires to become successful and productive. Build infrastructure and abstractions that can enable anyone (engineer or data scientist) to craft scalable pipelines for whatever the purpose is: metrics, analysis, machine learning, dashboard visualizations ', 'SQL Savvy - able to query and discover data with SQL', 'A technical leader', 'The Opportunity', 'Who You Are', 'Technology Framework Expert - in a variety of data infrastructures, such as: Batch processing: Apache Spark Messaging: Kafka, Zookeeper, Pulsar Storage: Hive, Mongo DB, Athena, Cassandra, PostgreSQL  ', 'Understand available sources of data and design, implement, validate, deploy, manage, tune and monitor data pipelines to deliver the target schemas to the performance and quality spec.', 'BA/BS in Computer Science, Information Systems or equivalent.', 'Create data validation checks and scripts to ensure high data quality and availability.', 'Summary']",Associate,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Sr. Software Engineer,MinTech Agency ~ Diversity Recruiting,"Duluth, GA",2 hours ago,Be among the first 25 applicants,"['', ' Strong attention to detail when identifying data relationships, trends, and anomalies.', ' Bachelor’s Degree and 5+ years of related experience or an equivalent combination of education and experience. 5+ years hands-on experience with SQL like relational data stores (For example: Oracle, Hive or similar), NoSQL data stores (Cassandra, Elasticsearch or similar), and Web based technologies (For example: Bootstrap, Angular, node.js or similar), 2+ years deep hands-on skills in Big Data stack, namely GCP (BigQuery, Dataflow, Composer, Pub/Sub), EMS, Kafka, Flume, Hadoop, Apache open source frameworks Experience building scalable web services, ESB and event/stream processing. Good understanding of data engineering, ingestion and processing of data within Big Data ecosystems and performing complex query analysis and analytics on the data. Deep understanding of technology including (but not limited to) Hadoop (Flume, HDFS, Hive, HBase, YARN etc…), Spark, Kafka, Elasticsearch, Kibana, Tomcat, stream processing, RDBMS, NoSQL databases, and so on. Expert understanding of all application development processes including software development methodology; ability to serve as a resource to others.  Expert in existing applications supporting the business area. Able to serve as a key resource to ensure the system is performing up to requirements.  Possesses understanding of multiple systems/customer areas, gained through previous experience in different areas and leverages that knowledge to support current customer(s).  Works independently and provides guidance within technical area, applying in-depth knowledge of multiple technologies, as appropriate. Understands architectural issues, and factors them into decisions and recommendations. Provides technical leadership in areas of specialization. ', ' Ability to extract, analyze, and report the data.', 'Works independently and provides guidance within technical area, applying in-depth knowledge of multiple technologies, as appropriate.', 'Essential Functions', ' Perform coding/configuration, testing, implementation and documentation on solutions developed including design specifications.', 'Experience building scalable web services, ESB and event/stream processing.', 'Understands architectural issues, and factors them into decisions and recommendations.', 'Good understanding of data engineering, ingestion and processing of data within Big Data ecosystems and performing complex query analysis and analytics on the data.', 'Bachelor’s Degree and 5+ years of related experience or an equivalent combination of education and experience.', ' Consistently demonstrate regular, dependable attendance and punctuality.', 'Expert understanding of all application development processes including software development methodology; ability to serve as a resource to others. ', 'This is a remote position.', 'Qualifications', '2+ years deep hands-on skills in Big Data stack, namely GCP (BigQuery, Dataflow, Composer, Pub/Sub), EMS, Kafka, Flume, Hadoop, Apache open source frameworks', ' Perform other duties as assigned', 'Requirements', ' Building self-service platforms to power cross functional teams and drive the whole organization to be data-driven. Serve data models as a product to entire organization.', ' Maintain awareness of industry trends and evaluate applicability of new software tools to platform development.', ' Commit to overall deliverables with customers and/or management', '5+ years hands-on experience with SQL like relational data stores (For example: Oracle, Hive or similar), NoSQL data stores (Cassandra, Elasticsearch or similar), and Web based technologies (For example: Bootstrap, Angular, node.js or similar),', 'Expert in existing applications supporting the business area. Able to serve as a key resource to ensure the system is performing up to requirements. ', ' Thinking through long-term impacts of key design decisions and handling failure scenarios.', ' Serve as a coach and mentor to more junior developers to include delegating and managing tasks, as appropriate', ' This is a remote position.', ' Perform applications programming activities, to include code, test, debug, document, maintain, and modify applications programs.', 'Deep understanding of technology including (but not limited to) Hadoop (Flume, HDFS, Hive, HBase, YARN etc…), Spark, Kafka, Elasticsearch, Kibana, Tomcat, stream processing, RDBMS, NoSQL databases, and so on.', 'Possesses understanding of multiple systems/customer areas, gained through previous experience in different areas and leverages that knowledge to support current customer(s). ', 'Provides technical leadership in areas of specialization.', 'Education/Experience']",Mid-Senior level,Full-time,Engineering,Retail,2020-11-05 11:32:32
"Sr. Research Scientist I, Formulation Process Development",Gilead Sciences,"San Mateo, CA",5 hours ago,71 applicants,"['', 'Works on complex problems where analysis of situations or data requires evaluation of intangible variables, requiring regular use of ingenuity and creativity.', 'Demonstrates excellent verbal communication skills and interpersonal skills.', 'Must think critically and creatively and be able to work independently, determine appropriate resources for resolution of problems and have strong organizational and planning skills.', 'PhD in a related scientific discipline 3+ years’ industry experience.BS or MS degree with extensive industry experience.Ideal candidate will have degree in pharmaceutical sciences, chemical engineering, physical organic chemistry.', 'Excellent communication skills (both verbal and written) and interpersonal skills are required. ', 'Demonstrates collaborative communication and problem solving spirit.', 'Experienced in formulation and process development, manufacture, and scale-up of parenteral drug products.', 'Works independently to design execute and analyze laboratory experimentation.', 'Expertise in parenteral drug delivery technologies, including sustained release. Knowledge of basic analytical skills required: HPLC/UPLC, UV, solid state characterization.', 'For Current Gilead Employees And Contractors', 'Maintains full working knowledge of state-of-the art principles and theories, applying such knowledge to the direction that supports Company interests.', 'For Jobs In The United States', 'Presents results of work, interprets data, and draws conclusions regarding presented material and nature of work.', 'PhD in a related scientific discipline 3+ years’ industry experience.', 'Essential Duties And Job Functions', 'Job Description', 'Sr. Research Scientist I - Formulation & Process Development', 'Knowledge, Experience And Skills', 'BS or MS degree with extensive industry experience.', 'Experienced in formulation and process development, manufacture, and scale-up of parenteral drug products.Expertise in parenteral drug delivery technologies, including sustained release. Knowledge of basic analytical skills required: HPLC/UPLC, UV, solid state characterization.Excellent communication skills (both verbal and written) and interpersonal skills are required. Works independently to design execute and analyze laboratory experimentation.Works on complex problems where analysis of situations or data requires evaluation of intangible variables, requiring regular use of ingenuity and creativity.Presents results of work, interprets data, and draws conclusions regarding presented material and nature of work.Maintains full working knowledge of state-of-the art principles and theories, applying such knowledge to the direction that supports Company interests.Demonstrates technical proficiency, scientific creativity, collaboration with others and independent thought in suggesting experimental design and strategy.Must think critically and creatively and be able to work independently, determine appropriate resources for resolution of problems and have strong organizational and planning skills.Demonstrates excellent verbal communication skills and interpersonal skills.Demonstrates collaborative communication and problem solving spirit.', 'Demonstrates technical proficiency, scientific creativity, collaboration with others and independent thought in suggesting experimental design and strategy.', 'Ideal candidate will have degree in pharmaceutical sciences, chemical engineering, physical organic chemistry.']",Not Applicable,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Postdoctoral Researcher/Research Specialist D,Gene Therapy Program | University of Pennsylvania,"Philadelphia, PA",,N/A,"['', 'Qualified candidates will have a background in biologics sample management in a regulated environment.\xa0', ""Bachelor's Degree w/ 3-5 years industry/relevant professional experience.\xa0Independent thinker with a track record of working collaboratively to achieve goals.Highly functioning, detail-oriented, and analytical mind-set required.GLP experience preferred but not required.Excellent oral/written communication skills required."", 'Independent thinker with a track record of working collaboratively to achieve goals.', 'GLP experience preferred but not required.', 'As the Sample Manager, you will coordinate the day to day operations of the sample team. This team is responsible for the processes involving sample receipt, sample tracking, sample inventory, sample disposal, and sample logistics. This includes communicating with multiple departments within GTP and external contract manufacturing organization vendors. Also, you will maintain all sample records with good documentation practices.\xa0', 'Excellent oral/written communication skills required.', 'Highly functioning, detail-oriented, and analytical mind-set required.', 'The laboratory of Dr. Jim Wilson, at\xa0GTP\xa0of the University of Pennsylvania, has been a leader in the development of innovative vector technology for close to three decades. We have emerged as the ‘go-to’ organization for public and private partners, who want to participate in the gene therapy space. Currently, we are positioned to lead another round of vector innovation and establish pre-clinical and clinical proof-of-concept in therapeutic applications of in-vivo genome editing.', 'Qualifications:', ""Our Vector Core is a state-of-the-art facility that provides vector-related materials and services in support of basic and translational research worldwide, producing vectors in support of IND-enabling research, conduct GLP assays, oversee CMO's in vector production, and is expanding to conduct state-of-the-art process development."", ""Bachelor's Degree w/ 3-5 years industry/relevant professional experience.\xa0"", 'Penn adheres to a policy that prohibits discrimination on the basis of race, color, sex, sexual orientation, gender identity, religion, creed, national or ethnic origin, citizenship status, age, disability, veteran status, or any other legally protected class.', 'Sample Manager ', 'Due to the growth of our program, the Vector Core is looking to add a Sample Manager to contribute to the end-to-end management of all samples needed for quality control testing and plasmid inventory for the manufacturing of AAV vectors.\xa0', 'The Gene Therapy Program (GTP) is entering a new era of unprecedented opportunity with great potential to reshape the face of medicine as we know it. Our discoveries have set the stage for successful treatments and possibly even cures for devastating genetic diseases.\xa0']",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
"Scientist II, Reagents Sustainment and Troubleshooting",Guardant Health,"Redwood City, CA",6 hours ago,Be among the first 25 applicants,"['', 'Guardant Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.', 'PhD degree in molecular biology, biomedical sciences, bioinformatics, genetics, biochemistry, or related fieldConsummate team player: demonstrated ability to contribute in an environment where numerous contributions are required to accomplish complex goals. Strong foundation in molecular biology techniques and NGS assay development, exemplified by publications, patent applications, or previous product development experienceDemonstrated ability to organize, document and communicate scientific dataStrong data analysis skills with experience with Python and R and the experience in handling large datasetsEnjoy working independently and collaboratively in a fast-paced environment and able to adapt to changeHighly motivated, self-starter and independent problem solver with inherent curiosity and ownership ethos', 'Preferred Skills', '1+ years of industry work experience preferred', 'Duties And Responsibilities', 'Ensure all work is performed and documented in compliance with applicable regulatory and quality practices (FDA, ISO13485)', 'Strong Python or R skill set and experience interrogating large datasets and building distributed tools to support other non-expert users, analysis within organizations', 'http://www.guardanthealth.com/jobs/', '1+ years of industry work experience preferredExperience with assay development especially in automated liquid handling platformsStrong Python or R skill set and experience interrogating large datasets and building distributed tools to support other non-expert users, analysis within organizations', 'Collaborate cross-functionally with operations, process engineering, and bioinformatics to facilitate effective delivery sustaining and support deliverablesPresent data, proposals, and progress in various forums and to technical and non-technical audiencesUtilize strong data analysis skills with Python or R and experience interrogating large datasets to identify areas for improvement in assay and propose and implement solutionsDesign and perform experiments to continually improve our assay workstreamsDevelop and perform longitudinal analytics of clinical lab performance and provide regular updates to cross-functional teamsWrite experiment reports and update SOPs as neededLead in troubleshooting efforts with our Operations teams and capture lessons learnedManage the escalation process between Operations, Supply Chain and Technology teamsEnsure all work is performed and documented in compliance with applicable regulatory and quality practices (FDA, ISO13485)Be a mentor to grow junior team members', 'Please visit our career page at: http://www.guardanthealth.com/jobs/', 'Utilize strong data analysis skills with Python or R and experience interrogating large datasets to identify areas for improvement in assay and propose and implement solutions', 'Consummate team player: demonstrated ability to contribute in an environment where numerous contributions are required to accomplish complex goals. ', 'Strong data analysis skills with experience with Python and R and the experience in handling large datasets', 'Qualifications', 'Lead in troubleshooting efforts with our Operations teams and capture lessons learned', 'Demonstrated ability to organize, document and communicate scientific data', 'Strong foundation in molecular biology techniques and NGS assay development, exemplified by publications, patent applications, or previous product development experience', 'Employee may be required to lift routine office supplies and use office equipment. Majority of the work is performed in a desk/office environment. Ability to sit for extended periods of time.', 'Develop and perform longitudinal analytics of clinical lab performance and provide regular updates to cross-functional teams', 'Present data, proposals, and progress in various forums and to technical and non-technical audiences', 'PhD degree in molecular biology, biomedical sciences, bioinformatics, genetics, biochemistry, or related field', 'Highly motivated, self-starter and independent problem solver with inherent curiosity and ownership ethos', 'Experience with assay development especially in automated liquid handling platforms', 'Collaborate cross-functionally with operations, process engineering, and bioinformatics to facilitate effective delivery sustaining and support deliverables', 'Be a mentor to grow junior team members', 'Company Description', 'Manage the escalation process between Operations, Supply Chain and Technology teams', 'Job Description', 'Write experiment reports and update SOPs as needed', 'Enjoy working independently and collaboratively in a fast-paced environment and able to adapt to change', 'Design and perform experiments to continually improve our assay workstreams', 'Privacy Notice for Job Applicants', 'All your information will be kept confidential according to EEO guidelines.']",Associate,Full-time,Research,Computer Software,2020-11-05 11:32:32
Principal Engineer- Image Scientist,Ball Aerospace,"Fairborn, OH",6 hours ago,Be among the first 25 applicants,"['', ' Characterize geolocation uncertainty of EO remote sensing systems and relate geolocation performance to factors such as viewing geometry. ', ' Serve as organizational spokesperson, primary customer interface, and advisor on advanced technical applications ', ' Strong Science and Math foundation ', ' Responsible for guiding design and execution of advanced technological concepts on small to large-sized, complex projects ', ' Develop or direct the development of solutions to complex technical problems where little or no precedent exists and innovation is required ', ' Maintain a regular and predictable work schedule. ', ' BS degree or higher in Engineering or a related technical field is required plus 12 or more years related experience.  Each higher-level related degree, i.e., Master’s Degree or Ph.D., may substitute for two years of related experience. Related technical experience may be considered in lieu of education. Degree must be from a university, college, or school which is accredited by an agency recognized by the US Secretary of Education, US Department of Education.  Preferred: Master’s degree with twelve years or PhD with ten years of experience and a Top Secret clearance.  Ability to communicate effectively through verbal presentations and report writing.  Strong Science and Math foundation  Programming skills with preference on high-level scripting languages such as Matlab, Interactive Data Language (IDL), or Python ', 'Us Citizenship Is Required', ' Design sensor collection strategies for existing sensors to develop new intelligence products. Includes modeling spectral signatures of targets of interest including atmospheric effects and sensor behavior to determine the expected signature and design optimal collection strategies. ', ' Principal Engineer- Image Scientist ', ' ***Position is contingent upon contract award*** ', ' Establish and maintain effective working relationships within the department, the Strategic Business Units, Strategic Support Units and the Company. Interact appropriately with others in order to maintain a positive and productive work environment. ', ' Analyze EO payload hardware, viewing geometry, and data processing specifications and relate to desired mission need and intelligence utility ', ' Perform other duties as necessary. ', ' Preferred: Master’s degree with twelve years or PhD with ten years of experience and a Top Secret clearance. ', ' Characterize the performance of advanced EO remote sensing systems and relate sensor characteristics to the performance of automated and manual detection, classification, and characterization of targets. ', ' May access other facilities in various weather conditions. ', ' Develop signal and image processing algorithms for remote sensor data processing and exploitation. Optimize performance of existing algorithms. ', ' Develop, enhance, test, evaluate, and integrate scientific algorithms in high-level scientific computing languages (MATLAB, Python, IDL). Experience with object-oriented programming, C/C++, Java, application development, a plus. ', ' Actively engage in business development by leading and contributing to group efforts to develop and document technical solutions in white papers and proposals ', ' Collaborates with people at all levels and with outside customers, able and willing to contribute wherever and however needed, provide leadership and guidance to program activities and senior level team members. ', ' Evaluate quality of imagery and intelligence products, assess performance of remote sensing algorithms, and recommend improvements to existing collection configurations and processing workflows. ', ' Each higher-level related degree, i.e., Master’s Degree or Ph.D., may substitute for two years of related experience. Related technical experience may be considered in lieu of education. Degree must be from a university, college, or school which is accredited by an agency recognized by the US Secretary of Education, US Department of Education. ', ' Work is performed in an office, laboratory, production floor, or clean room, outdoors or remote research environment. ', ' Document research through technical briefings, reports, and papers ', ""What You'll Do"", ' Ability to communicate effectively through verbal presentations and report writing. ', ' Programming skills with preference on high-level scripting languages such as Matlab, Interactive Data Language (IDL), or Python ', ' Travel and local commute between Ball campuses and other possible non-Ball locations may be required. ', 'Working Conditions', ' Analyze utility of and rapidly develop applications for multi-spectral and hyper-spectral sensor data ', ' Apply, interpret, and innovate advanced engineering or scientific theories, concepts, and techniques ', ' Work both independently and in a team environment to apply technical expertise in one or more areas across multiple programs of varying complexity  Responsible for guiding design and execution of advanced technological concepts on small to large-sized, complex projects  Serve as organizational spokesperson, primary customer interface, and advisor on advanced technical applications  Apply, interpret, and innovate advanced engineering or scientific theories, concepts, and techniques  Develop or direct the development of solutions to complex technical problems where little or no precedent exists and innovation is required  Document research through technical briefings, reports, and papers  Actively engage in business development by leading and contributing to group efforts to develop and document technical solutions in white papers and proposals  Maintain an understanding of the expertise available within our organization and among our corporate partners to define strategies that offer our customers the best possible technical solutions  Collaborates with people at all levels and with outside customers, able and willing to contribute wherever and however needed, provide leadership and guidance to program activities and senior level team members.  Design sensor collection strategies for existing sensors to develop new intelligence products. Includes modeling spectral signatures of targets of interest including atmospheric effects and sensor behavior to determine the expected signature and design optimal collection strategies.  Characterize the performance of advanced EO remote sensing systems and relate sensor characteristics to the performance of automated and manual detection, classification, and characterization of targets.  Analyze EO payload hardware, viewing geometry, and data processing specifications and relate to desired mission need and intelligence utility  Evaluate quality of imagery and intelligence products, assess performance of remote sensing algorithms, and recommend improvements to existing collection configurations and processing workflows.  Apply rigorous statistical methods and analysis to data collected from a variety of sensors to ensure findings are complete and accurate.  Develop signal and image processing algorithms for remote sensor data processing and exploitation. Optimize performance of existing algorithms.  Characterize geolocation uncertainty of EO remote sensing systems and relate geolocation performance to factors such as viewing geometry.  Analyze utility of and rapidly develop applications for multi-spectral and hyper-spectral sensor data  Develop, enhance, test, evaluate, and integrate scientific algorithms in high-level scientific computing languages (MATLAB, Python, IDL). Experience with object-oriented programming, C/C++, Java, application development, a plus.  Maintain a regular and predictable work schedule.  Establish and maintain effective working relationships within the department, the Strategic Business Units, Strategic Support Units and the Company. Interact appropriately with others in order to maintain a positive and productive work environment.  Perform other duties as necessary. ', 'Future Clearance Required', ' Work is performed in an office, laboratory, production floor, or clean room, outdoors or remote research environment.  May occasionally work in production work centers where use of protective equipment and gear is required.  May access other facilities in various weather conditions.  Travel and local commute between Ball campuses and other possible non-Ball locations may be required. ', ' Work both independently and in a team environment to apply technical expertise in one or more areas across multiple programs of varying complexity ', ' May occasionally work in production work centers where use of protective equipment and gear is required. ', '***Position is contingent upon contract award***', ""What You'll Need"", ' Maintain an understanding of the expertise available within our organization and among our corporate partners to define strategies that offer our customers the best possible technical solutions ', ' Apply rigorous statistical methods and analysis to data collected from a variety of sensors to ensure findings are complete and accurate. ', ' BS degree or higher in Engineering or a related technical field is required plus 12 or more years related experience. ']",Mid-Senior level,Full-time,Engineering,Defense & Space,2020-11-05 11:32:32
Solutions Architect -Cloud,Cedrus Digital,United States,22 hours ago,111 applicants,"['', 'Researches relevant emerging empirical methods and quantitative tools', 'Extracts data from various data sources and performs exploratory data analysis, cleanses, wrangles, and transforms dataEmploys scaling & automation to data preparation techniquesIntroduces incremental improvements to data analysis, visualization, and presentation techniques to communicate discoveriesResearches relevant emerging empirical methods and quantitative toolsLeads innovative packaging and presentation of insights to business and broader analytics communityDevelops processes to automate and scale insights operationalizationLead a team of software engineers and application developers to develop automation solution for customers leveraging AI and Robotic Software', 'Architecture', 'Technical Leadership', 'Extracts data from various data sources and performs exploratory data analysis, cleanses, wrangles, and transforms data', 'Expertise in several Analytic Languages (R, SAS, SPSS, Stata)', 'Expertise in several Modeling & Machine Learning Techniques (regression, tree models, survival analysis, cluster analysis, forecasting, anomaly detection, association rules, etc.)', 'We’d love to hear from people with:', 'Strong Inter-personal skills, Excellent Communication Skills, Great Leardership Skills', 'Develops processes to automate and scale insights operationalization', 'Lead a team of software engineers and application developers to develop automation solution for customers leveraging AI and Robotic Software', 'Leads innovative packaging and presentation of insights to business and broader analytics community', 'As a Lead, Data Scientist, you will…', 'Expertise in several Modeling & Machine Learning Techniques (regression, tree models, survival analysis, cluster analysis, forecasting, anomaly detection, association rules, etc.)Expertise in several Data ETL (Teradata, Oracle, SQL, Python, Java, Ruby, Pig)Expertise in several Analytic Languages (R, SAS, SPSS, Stata)3 + years of experience in this disciplineTechnical LeadershipArchitectureSystem IntegrationStrong Inter-personal skills, Excellent Communication Skills, Great Leardership Skills', 'Expertise in several Data ETL (Teradata, Oracle, SQL, Python, Java, Ruby, Pig)', 'Introduces incremental improvements to data analysis, visualization, and presentation techniques to communicate discoveries', '3 + years of experience in this discipline', 'Employs scaling & automation to data preparation techniques', 'System Integration']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Principal Scientist/Principal Scientist - Respiratory Diseases,Boehringer Ingelheim,"Ridgefield, CT",20 hours ago,Be among the first 25 applicants,"['', ' Doctoral degree with at least 5 years drug discovery experience in pharmaceutical industry or biotech, or equivalent.  A proven track record of high research productivity in immunology and respiratory diseases. Deep understanding of mechanisms and pathways in respiratory diseases and current treatment modalities.  Ability to mentor Ph.D. scientists and lead a group of bench scientist(s) to deliver high quality data to contribute to overall program goals. Ability to proactive identification of critical issues and communicate effectively both orally and in writing in an inter-disciplinary environment.  The successful candidate will be an ambitious self-starter, be motivated to apply his/her skills to impact project needs and drive key innovative scientific concepts, and enjoy working in a fast-paced dynamic team environment and proven ability to focus and deliver high quality data that support timely decisions for projects. ', ' A proven track record of high research productivity in immunology and respiratory diseases. Deep understanding of mechanisms and pathways in respiratory diseases and current treatment modalities. ', ' Collaborate with in vivo group to enable back translation of human disease-relevant mechanisms to in vivo models ', ' As appropriate, serve as project Leader on portfolio projects.Responsible for working in collaboration with the Medicinal Chemistry or Biotherapeutics project leaders to shape and drive project strategy and advance the project up to start of clinical development. ', ' Ability to lead a group of scientists by directing and overseeing the design, execution and interpretation of studies. ', ' Doctoral degree with at least 7 years drug discovery experience in pharmaceutical industry or biotech, or equivalent.  A proven track record of high research productivity in immunology and respiratory diseases. Deep understanding of mechanisms and pathways in respiratory diseases and current treatment modalities.  Ability to mentor Ph.D. scientists and lead a group of bench scientist(s) to deliver high quality data to contribute to overall program goals. Ability to proactive identification of critical issues and communicate effectively both orally and in writing in an inter-disciplinary environment.  The successful candidate will be an ambitious self-starter, be motivated to apply his/her skills to impact project needs and drive key innovative scientific concepts, and enjoy working in a fast-paced dynamic team environment and proven ability to focus and deliver high quality data that support timely decisions for projects. ', ' Doctoral degree with at least 5 years drug discovery experience in pharmaceutical industry or biotech, or equivalent. ', ' Skilled in human cellular assay systems linked to fibrosis to establish strong NTC to disease linkage concepts using state of the art human disease ex vivo/in vitro models. ', ' Influence overall portfolio through engagement of departmental scientific reviews and providing strategic recommendations that will have impact on project direction and progression. ', ' Develop and implement experimental ideas for delivering highly differentiated disease positioning concepts for targets in portfolio. Keep abreast of current literature and drive novel science by bringing new methods and assays relevant to Pulmonary Fibrosis-Interstitial Lung Diseases. ', 'Description', ' The successful candidate will be an ambitious self-starter, be motivated to apply his/her skills to impact project needs and drive key innovative scientific concepts, and enjoy working in a fast-paced dynamic team environment and proven ability to focus and deliver high quality data that support timely decisions for projects. ', ' Responsible for leading external collaborations and for establishing an external network to recruit and develop entry level Ph.D. and laboratory staff within the Disease positioning group. ', 'Sr. Principal Scientist or Principal Scientist', 'Principal Scientist Requirements', ' Ensure compliance with all required training, safety, regulatory, HR, laboratory notebook, and intellectual property activities and corporate policies. ', ' Develop scientific staff and mentor them in their experiments and for creating growth opportunities ', 'Candidate will be hired at level commensurate with experience and education ', 'Who We Are', 'Duties & Responsibilities', 'Sr. Principal Scientist Requirements', ' Develop and implement experimental ideas for delivering highly differentiated disease positioning concepts for targets in portfolio. Keep abreast of current literature and drive novel science by bringing new methods and assays relevant to Pulmonary Fibrosis-Interstitial Lung Diseases.  Ability to lead a group of scientists by directing and overseeing the design, execution and interpretation of studies.  As appropriate, serve as project Leader on portfolio projects.Responsible for working in collaboration with the Medicinal Chemistry or Biotherapeutics project leaders to shape and drive project strategy and advance the project up to start of clinical development.  Skilled in human cellular assay systems linked to fibrosis to establish strong NTC to disease linkage concepts using state of the art human disease ex vivo/in vitro models.  Collaborate with in vivo group to enable back translation of human disease-relevant mechanisms to in vivo models  Responsible for leading external collaborations and for establishing an external network to recruit and develop entry level Ph.D. and laboratory staff within the Disease positioning group.  Influence overall portfolio through engagement of departmental scientific reviews and providing strategic recommendations that will have impact on project direction and progression.  Develop scientific staff and mentor them in their experiments and for creating growth opportunities  Ensure compliance with all required training, safety, regulatory, HR, laboratory notebook, and intellectual property activities and corporate policies. ', ' Doctoral degree with at least 7 years drug discovery experience in pharmaceutical industry or biotech, or equivalent. ', ' Ability to mentor Ph.D. scientists and lead a group of bench scientist(s) to deliver high quality data to contribute to overall program goals. Ability to proactive identification of critical issues and communicate effectively both orally and in writing in an inter-disciplinary environment. ', 'Eligibility Requirements']",Not Applicable,Full-time,Research,Hospital & Health Care,2020-11-05 11:32:32
"Travel Medical Tech - COVID19 - $1,850 per week",NurseFly,"Fort Worth, TX",24 hours ago,Be among the first 25 applicants,"['', ' 401(k) and Flex Spending', ' Refer a friend and earn extra cash!', 'Medical Tech', '13 weeks', 'About The Company', 'Allied Health Professional', 'Preferred Qualifications', 'Duration: 13 weeks', 'About Med Travelers', 'Shift: 12 hours, evenings, nights', 'Discipline: Allied Health Professional', 'Facility Location', '12 hours, evenings, nights', '  Competitive pay rates  Medical, Dental, Vision  401(k) and Flex Spending  Life Insurance  Accident and Short-term Disability Coverage  Free Continuing Education  Free Private Housing  Refer a friend and earn extra cash! ', 'Travel', ' Free Continuing Education', 'Start Date: ASAP', ' Life Insurance', '36.00 hours per week', ' Competitive pay rates', ' Medical, Dental, Vision', 'Job Description & Requirements', 'Required Qualifications', 'ASAP', ' Accident and Short-term Disability Coverage', 'Job Benefits', 'Specialty: Medical TechDiscipline: Allied Health ProfessionalStart Date: ASAPDuration: 13 weeks36.00 hours per weekShift: 12 hours, evenings, nightsEmployment Type: Travel', ' Free Private Housing', 'Employment Type: Travel', 'Specialty: Medical Tech']",Not Applicable,Temporary,Other,Staffing and Recruiting,2020-11-05 11:32:32
AWS Data Engineer with Lake Formation Experience,HTC Global Services,"Bloomington, IL",18 hours ago,Be among the first 25 applicants,"['', 'Description:\xa0', 'Experience with\xa0Infrastructure as code\xa0tools like\xa0Terraform, AWS cloud formation.', 'Proficient in coding using\xa0Python/ Linux\xa0shell scripting.Aware of Lake formation access models,\xa0IAM principles,\xa0best practices on\xa0cross-account access patterns.Worked on\xa0Data lake monitoring\xa0using tools like\xa0Cloudwatch/cloud trail/Lambda.Extensive experience on\xa0S3\xa0storage models, S3 access, configuration, AWS config.Experience in both\xa0EC2\xa0and\xa0serverless computing\xa0on AWS.Experience with\xa0Infrastructure as code\xa0tools like\xa0Terraform, AWS cloud formation.Experience in\xa0reporting\xa0tools using\xa0AWS quick sight.', 'We are currently looking for an\xa0AWS Data Engineer. We will consider relocation for candidates with exceptional skills.', 'Be sure to reference the job number and title in the subject line. A relevant degree or its foreign equivalent is required.', 'EEO/M/F/V/H', 'Benefits:', 'Proficient in coding using\xa0Python/ Linux\xa0shell scripting.', 'Candidates should e-mail resume to gunasekaran.L@htcinc.com or call\xa0248-466-0663 to discuss.', 'Extensive experience on\xa0S3\xa0storage models, S3 access, configuration, AWS config.', 'Worked on\xa0Data lake monitoring\xa0using tools like\xa0Cloudwatch/cloud trail/Lambda.', ""HTC's competitive package includes besides compensation Health, Dental, Vision, Disability Cover, both Short and Long term, Life Insurance, Flexible Spending, 401k, and Paid Vacation"", 'Experience in both\xa0EC2\xa0and\xa0serverless computing\xa0on AWS.', 'Experience in\xa0reporting\xa0tools using\xa0AWS quick sight.', 'Aware of Lake formation access models,\xa0IAM principles,\xa0best practices on\xa0cross-account access patterns.', 'About the Job:']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Email Marketing Specialist,"Anderson Young Associates, Inc.","Lincoln, Nebraska Metropolitan Area",18 hours ago,30 applicants,"['', 'partner programs and customer engagement that will have a sizable impact on revenue growth.', 'Our client, a Global Financial Services company ,seeks an Email Marketing Specialist\xa0', 'conceptualize and write creative emails, and also consistently test and analyze data driven experiments on our email program. The EMS will create a significant volume of emails on behalf of the company and will play an integral role in supporting internal and external communication,', 'Project Management', '• Tracking success by monitoring performance of campaigns on a daily and weekly basis including', 'how people are', 'Measuring Success', 'and implementing into our marketing automation platform, Pardot.', 'and external brand communication, partner programs, promotions and customer engagement', 'on each project,', '• End-to-end conceptualization and implementation of email campaigns that include but are not', 'The specialist role is broken up into equal parts technical, creative and analytical – ready to', 'Reports To: VP of Marketing', 'limited to internal', 'engaging with the email program and how it’s driving marketing key metrics.', 'Please Remember to attach resume**', '• Work with Salesforce engineer and systems teams to properly sync and track performance across all platforms.', 'campaigns for all', '• Building the email flow logic, writing creative error-free copy, collaborating with key stakeholders', '• Work with Data Scientist to create accurate email lists, manage customer database within Pardot.', 'Amur Equipment Finance.', 'Key Responsibilities']",Associate,Full-time,Finance,Staffing and Recruiting,2020-11-05 11:32:32
Senior AWS Cloud Data Engineer,JPMorgan Chase & Co.,"Plano, TX",22 hours ago,Be among the first 25 applicants,"['', 'Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture', 'Demonstrable experience of successfully delivering big data projects using Kafka', 'In depth knowledge of design principles and patterns', 'technical leadership', 'Innovators Wanted!!!', 'Provide technical leadership in developing data solutions and building frameworks Experience building Data Lake using AWS and Hands-on experience in AWS Glue, AWS KMS, AWS Firehose, EMR, Athena, Redshift, Quick Sight and Lake Formation Conduct code reviews and strive for improvement in software engineering quality Review data architecture and develop detailed implementation design Hands-on experience in production rollout and infrastructure configuration Extensive experience in Spark leveraging Python, Scala or and In depth experience in Java 8 Excellent understand of Spring framework Demonstrable experience of successfully delivering big data projects using Kafka Experience working on NoSQL Databases such as Cassandra, HBase, DynamoDB, and Elastic Search Hands on experience with leveraging CI/CD to rapidly build & test application code Experience in developing software solutions leveraging Test Driven Development (TDD) Expertise in Data governance and Data Quality Experience leveraging Ansible, Terraform , Cloud formation scripting for infrastructure automation Experience working with PCI Data and working with data scientists is a plus In depth knowledge of design principles and patterns Able to tune big data solutions to improve performance ', 'Hands on experience with leveraging CI/CD to rapidly build & test application code', 'Provide technical leadership in developing data solutions and building frameworks', 'Review data architecture and develop detailed implementation design', 'Experience working with PCI Data and working with data scientists is a plus', 'Hands-on experience in production rollout and infrastructure configuration', ""7+ years' experience with building large scale big data applications development"", 'Experience in developing software solutions leveraging Test Driven Development (TDD)', 'Excellent understand of Spring framework', 'Able to tune big data solutions to improve performance', 'Experience leveraging Ansible, Terraform , Cloud formation scripting for infrastructure automation', 'Proficiency in multiple modern programming languages', 'BS/BA degree or equivalent experience Expertise in application, data and infrastructure architecture disciplines Proficiency in multiple modern programming languages Knowledge of industry wide technology trends and best practices Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture ', 'Expertise in application, data and infrastructure architecture disciplines', 'Extensive experience in Spark leveraging Python, Scala or and In depth experience in Java 8', 'Conduct code reviews and strive for improvement in software engineering quality', 'BS/BA degree or equivalent experience', 'Knowledge of industry wide technology trends and best practices', 'Experience building Data Lake using AWS and Hands-on experience in AWS Glue, AWS KMS, AWS Firehose, EMR, Athena, Redshift, Quick Sight and Lake Formation', 'Experience working on NoSQL Databases such as Cassandra, HBase, DynamoDB, and Elastic Search', 'Expertise in Data governance and Data Quality']",Associate,Full-time,Information Technology,Banking,2020-11-05 11:32:32
Data & Applied Scientist,Microsoft,"Redmond, WA",20 hours ago,Be among the first 25 applicants,"['', 'Minimum of 5 years of related work experience.', ' Demonstrated ability to engage with and influence business teams in order to drive alignment', 'You', 'Ability to work cross-functionally, building and maintaining trust with internal stakeholders', 'Responsibilities', ' Own the delivery of the reporting and insights on a regular cadence to the stakeholders and senior leadership teams', 'The Team', 'Minimum of 5 years of related work experience.Demonstrated ability to manage own projects or programs including work prioritization, planning, and coordinationStrong communication and data presentation skills, experience analyzing data and communicating the results to senior business leadersAbility to work cross-functionally, building and maintaining trust with internal stakeholdersSolid SQL skills are a requirement - hands on use of big data in large projects using Power BI, Azure, Data Bricks, Presto or SparkProven experience of using R (or similar tools) to structure, transform and visualize big dataSolid understanding of online marketing, preferably in a past or current role, with experience of Search EngineMarketing, Revenue Optimization or Content targeting a plusProven ability to solve complex quantitative business challenges; experience in the development and measurement of multi-variant testing is a plus.Bachelor’s degree or higher in an analytical area such as Computer Science, Management information Systems, Mathematics, Statistics, Engineering or similar field preferred', ' Ensuring insights are both actionable and measurable and you should be able to build these insights and hypothesis with awareness of practical implementation and implications for the business', 'Proven ability to solve complex quantitative business challenges; experience in the development and measurement of multi-variant testing is a plus.', ' Freedom - Microsoft values everyone’s talent and skillset and provides the freedom to explore and enhance them.', 'Qualifications', 'Strong communication and data presentation skills, experience analyzing data and communicating the results to senior business leaders', ' Partnering with our Digital Analytics and Data Engineering teams to ensure robust and accurate data capture and continuous improvement of data available for both analytics and the wider business', 'Demonstrated ability to manage own projects or programs including work prioritization, planning, and coordination', ' Reach - Microsoft’s resources and scale empowers employees to utilize their skills for lasting impact.', 'Bachelor’s degree or higher in an analytical area such as Computer Science, Management information Systems, Mathematics, Statistics, Engineering or similar field preferred', 'Solid understanding of online marketing, preferably in a past or current role, with experience of Search Engine', 'Marketing, Revenue Optimization or Content targeting a plus', 'Proven experience of using R (or similar tools) to structure, transform and visualize big data', ' Build analytics to measure program impact, identify trends and anomalies, and influence marketing program investments', ' Knowledge sharing through presentations at regional, channel and business wide events, as well as building relationships with analytics teams across the group.', 'Solid SQL skills are a requirement - hands on use of big data in large projects using Power BI, Azure, Data Bricks, Presto or Spark', ' Inspiration - inspiration can be found through our products and how they can improve our customers’ lives.', ' Understanding and proactively communicating factors affecting content performance to stakeholders by partnering with business leaders, other analysts and data engineering teams.', ' Learn and understand a broad range of data resources and know when, how, and which to use and which not to at any given time.']",Not Applicable,Full-time,Other,Computer Hardware,2020-11-05 11:32:32
Data Scientist - 100% Remote Available,Wiley Job Network,"San Antonio, TX",15 hours ago,Be among the first 25 applicants,"['', 'Preferred Requirements', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree."", 'Relocation', 'Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions.', 'Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.', 'Works with IT to research architecture for new products, services, and features.', ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization."", 'Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.', 'Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.', 'Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.', 'Develops algorithms and supporting code such that research efforts are based on the highest quality data.', 'Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required.', 'Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree.4 or more years of related experience and accountability for complex tasks and/or projects required.Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required."", 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.', '4 or more years of related experience and accountability for complex tasks and/or projects required.', ""Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation."", ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization.Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation.Works with IT to research architecture for new products, services, and features.Develops algorithms and supporting code such that research efforts are based on the highest quality data.Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions."", 'available', 'Minimum Requirements', 'Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).', 'PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).', 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).', 'Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.', 'Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).']",Entry level,Full-time,Engineering,Higher Education,2020-11-05 11:32:32
Machine Learning Researcher,Comcast,"Washington, DC",10 hours ago,Be among the first 25 applicants,"['PhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. Strong programming and software skills, with Python experience preferred. Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. ', 'Has excellent interpersonal skills and can communicate effectively. Chart a solid research path given available requirements. Quickly understands entertainment media and its semantic and technical structure. Is innovative and can find unique solutions to problems. Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. Plans, organizes, and time-manages independently. Prioritizes and assesses the implications of decisions. ', 'Preferred Skills', 'Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. ', 'Computer Science, Engineering, Applied Mathematics, or Statistics', 'Strong programming and software skills, with Python experience preferred. ', 'Other duties and responsibilities as assigned. ', 'PhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. ', 'Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. ', 'Research and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. ', 'Prioritizes and assesses the implications of decisions. ', 'Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. ', ""Understand our Operating Principles; make them the guidelines for how you do your jobOwn the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and servicesKnow your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiencesWin as a team - make big things happen by working together and being open to new ideasBe an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joininghuddles, making call backs and helping us elevate opportunities to do better for our customersDrive results and growthRespect and promote inclusion and diversityDo what's right for each other, our customers, investors and our communities"", 'Bachelor’s Degree', 'Consistent exercise of independent judgment and discretion in matters of significance. ', 'Chart a solid research path given available requirements. ', 'Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. ', 'Is innovative and can find unique solutions to problems. ', 'Job Summary:', ""Job Summary:Research and implement new detection capabilities for use within our Media Analysis Framework (MAF). You will rely on your experience in computer vision, signal processing, machine learning, and deep learning to extract insightful metadata from the video. You will create algorithms for multi-modal analysis of video. Additionally, you’ll ensure that your components are well-tested, production-ready, and performant at scale. The position is open in for placement in either Chicago or Washington, DC. We feature an innovative, informal, open atmosphere, and cultivate a start-up culture with the backing of a Fortune 50 company. To better serve our community, we believe the diversity of our team should reflect the diversity of our customers.Employees At All Levels Are Expected ToUnderstand our Operating Principles; make them the guidelines for how you do your jobOwn the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and servicesKnow your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiencesWin as a team - make big things happen by working together and being open to new ideasBe an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joininghuddles, making call backs and helping us elevate opportunities to do better for our customersDrive results and growthRespect and promote inclusion and diversityDo what's right for each other, our customers, investors and our communitiesCore ResponsibilitiesResearch and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. Consistent exercise of independent judgment and discretion in matters of significance. Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. Other duties and responsibilities as assigned. Desired QualificationsPhD degree in computer science, computer engineering, electrical engineering, mathematics, or a related technical field; or Master’s degree with 1-3 years related proven experience. Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. Strong programming and software skills, with Python experience preferred. Strong understanding of machine learning. Familiarity and experience with image processing and deep learning frameworks and tools, such as OpenCV, Keras, TensorFlow, PyTorch, or Caffe. Preferred SkillsThe preferred candidate will have the following skills and qualities:Has excellent interpersonal skills and can communicate effectively. Chart a solid research path given available requirements. Quickly understands entertainment media and its semantic and technical structure. Is innovative and can find unique solutions to problems. Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. Plans, organizes, and time-manages independently. Prioritizes and assesses the implications of decisions. Job SpecificationBachelor’s DegreeComputer Science, Engineering, Applied Mathematics, or StatisticsGenerally requires 5-8 years related experience.Comcast is an EOE/Veterans/Disabled/LGBT employer"", 'Research and develop analysis methods that extend the Media Analysis Framework, including video/image/audio processing and machine learning methods, to extract meaning and produce timestamped metadata from video content. Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. Work with other researchers, engineers, product managers, and business partners to rapidly prototype algorithms for proof-of-concept demonstrations. Collaborate closely with team members within and outside of research to advance the capabilities of the MAF system and to foster the team’s collective knowledge. Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. Consistent exercise of independent judgment and discretion in matters of significance. Regular, consistent and punctual attendance. Must be able to work nights and weekends and with variable schedules as necessary for project requirements. Other duties and responsibilities as assigned. ', 'Quickly understands entertainment media and its semantic and technical structure. ', 'Core Responsibilities', 'Has excellent interpersonal skills and can communicate effectively. ', 'Demonstrates excellent teamwork skills when interacting with research and engineering collaborators. ', 'Desired Qualifications', 'Plans, organizes, and time-manages independently. ', 'Drive results and growth', 'Business Unit', 'Generally requires 5-8 years related experience.', 'huddles, making call backs and helping us elevate opportunities to do better for our customers', 'Clearly communicate research discoveries and developed solutions to a variety of audiences through presentations. ', 'Employees At All Levels Are Expected To', 'Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences', 'Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services', 'Respect and promote inclusion and diversity', 'The position is open in for placement in either Chicago or Washington, DC.', 'Win as a team - make big things happen by working together and being open to new ideas', 'Job Specification', 'Develop and test software components that implement your analysis methods for integration into production systems. Work closely with the team to fit components into well-established workflows and systems. ', 'Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining', 'Understand our Operating Principles; make them the guidelines for how you do your job', 'Bachelor’s DegreeComputer Science, Engineering, Applied Mathematics, or StatisticsGenerally requires 5-8 years related experience.', ""Do what's right for each other, our customers, investors and our communities"", 'Practical and academic experience that includes signal processing, computer vision, and deep learning. Experience in video analysis, object detection/recognition, ad event/activity recognition is desired. ']",Not Applicable,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Data Engineer - Clinical Trials,CVS Health,"Woonsocket, RI",4 hours ago,Be among the first 25 applicants,"['', ' Healthcare space and clinical trial space A large scale Snowflake or Spark implementation Conduct continuous improvement on CRP while keeping up with the day-to-day build and operation tasks', 'Skill In', ' Work with a large cross-functional team developing product, including multiple digital scrum teams, IT project, legal and other partners', 'Preferred Qualifications', 'Knowledge Of', ' Implement the strategy and roadmap to establish and maintain a comprehensive patient database and design process and governance to manage data assets', ' A large scale Snowflake or Spark implementation', 'Education', ' Design and develop the Clinical Recruitment Platform (CRP)', ' Healthcare space and clinical trial space', ' Develop, test, iterate, deploy, and continually innovate and improve current product', ' Conduct continuous improvement on CRP while keeping up with the day-to-day build and operation tasks', ' Translate analytical problems into structured programs (in PySpark or Scala)', ' One of the following programming languages: PySpark, Scala, or Java', ' Translate analytical problems into structured programs (in PySpark or Scala) Design data models and solutions for analytical as well as reporting use cases', ' Following scripting languages: shell scripting, SQL (preferably Teradata and PL/SQL syntax)', ' Design data models and solutions for analytical as well as reporting use cases', ' MS preferred with coursework focused on advanced algorithms, mathematics in computing, data structures etc.', 'Business Overview', ' “Big data” technologies including Spark, Snowflake, Airflow, Kafka, Hbase, Pig, NoSQL databases, etc', ' “Big data” platforms including Hadoop (preferably Azure or AWS), Snowflake and Spark as well as experience with traditional RDBMS (e.g., Teradata, Oracle) “Big data” technologies including Spark, Snowflake, Airflow, Kafka, Hbase, Pig, NoSQL databases, etc One of the following programming languages: PySpark, Scala, or Java Following scripting languages: shell scripting, SQL (preferably Teradata and PL/SQL syntax)', ' Develop an in-depth knowledge of the end-to-end Recruitment process and design data flows between different portals and Clinical Recruitment Platform (CRP)', ' Design and develop the Clinical Recruitment Platform (CRP) Implement the strategy and roadmap to establish and maintain a comprehensive patient database and design process and governance to manage data assets Work with a large cross-functional team developing product, including multiple digital scrum teams, IT project, legal and other partners Develop an in-depth knowledge of the end-to-end Recruitment process and design data flows between different portals and Clinical Recruitment Platform (CRP) Develop, test, iterate, deploy, and continually innovate and improve current product', 'Required Qualifications', ' B.S. Computer Science, Engineering, Statistics, Physics, Math or related fields.', ' Data, master data and metadata related standards, processes and technology', 'Job Description', ' Frameworks for either Machine Learning or NLP (Scikit-Learn, SpaCy, Pytorch, Spark NLP) Designing and implementing scalable, distributed systems leveraging cloud computing technologies like Microsoft Azure Data, master data and metadata related standards, processes and technology', ' B.S. Computer Science, Engineering, Statistics, Physics, Math or related fields. MS preferred with coursework focused on advanced algorithms, mathematics in computing, data structures etc.', 'The Advisor Of Data Engineer Will', ' “Big data” platforms including Hadoop (preferably Azure or AWS), Snowflake and Spark as well as experience with traditional RDBMS (e.g., Teradata, Oracle)', ' Designing and implementing scalable, distributed systems leveraging cloud computing technologies like Microsoft Azure', 'Ability To', ' Frameworks for either Machine Learning or NLP (Scikit-Learn, SpaCy, Pytorch, Spark NLP)']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Research Scientist,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' 1+ of research or work experience in the job offered, or as a Research Scientist, Research Assistant, Software Engineer, or a related occupation.', "" Employer will accept a Master's degree or foreign equivalent in Statistics, Machine Learning, Computer Science, Mathematics, Physics, or a related field and three years of research or work experience in the job offered or a related occupation as equivalent to the PhD and one year of experience."", 'Preferred Qualifications', 'Company', 'Responsibilities', 'Basic Qualifications', "" PhD or equivalent Master's degree plus 4+ years of research experience in a quantitative filed Experience investigating the feasibility of applying scientific principals and concepts to business problems and products Ph.D. or foreign equivalent in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field 1+ of research or work experience in the job offered, or as a Research Scientist, Research Assistant, Software Engineer, or a related occupation. Employer will accept a Master's degree or foreign equivalent in Statistics, Machine Learning, Computer Science, Mathematics, Physics, or a related field and three years of research or work experience in the job offered or a related occupation as equivalent to the PhD and one year of experience. Must have at least one year of research or work experience in the following skill(s): programming with a mathematical programming language such as R, MATLAB, or SAS or major programming language such as Python, Java, C++, C#, or C Experience formulating and solving predictive modeling, machine learning, forecasting or statistical modeling problems."", 'Description', ' Ph.D. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field 2+ years of research or work experience in the job offered, or as a Research Scientist, Research Assistant, Software Engineer, or a related occupation. Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts', ' Experience formulating and solving predictive modeling, machine learning, forecasting or statistical modeling problems.', ' 2+ years of research or work experience in the job offered, or as a Research Scientist, Research Assistant, Software Engineer, or a related occupation.', ' Understand and mine the large amount of data, prototype and implement new learning algorithms and prediction techniques to improve forecast accuracy', ' Contribute to progress of the Amazon and broader research communities by producing publications', "" PhD or equivalent Master's degree plus 4+ years of research experience in a quantitative filed"", ' Ph.D. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field', ' Ph.D. or foreign equivalent in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field', ' Collaborate with product managers and engineering teams to design and implement software solutions for Amazon problems', ' Understand and mine the large amount of data, prototype and implement new learning algorithms and prediction techniques to improve forecast accuracy Collaborate with product managers and engineering teams to design and implement software solutions for Amazon problems Contribute to progress of the Amazon and broader research communities by producing publications', ' Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts', ' Experience investigating the feasibility of applying scientific principals and concepts to business problems and products', ' Must have at least one year of research or work experience in the following skill(s): programming with a mathematical programming language such as R, MATLAB, or SAS or major programming language such as Python, Java, C++, C#, or C']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
Machine Learning Engineer - Computer Vision,Optello,"Denver, CO",2 hours ago,Be among the first 25 applicants,"['', 'Salary:', 'Optello is proud to be an Equal Opportunity Employer', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : BB7-1608570 -- in the email subject line for your application to be considered.***', 'Strong knowledge of Algorithm Development and ability to put code into production', ' Certification / educational reimbursements', ' 100% work from home!', 'Build, integrate and extend code for prototype models', ' Tons of room for upward career growth', ' 401(k) and much more!', 'Develop, test, and update ML algorithms', 'Experience developing practical ML solutions', ' Industry Leading AI Software', 'You will be a key member of our development team, producing high-performance computer vision products for document verification, text segmentation and related OCR solutionsDevelop, test, and update ML algorithmsBuild, integrate and extend code for prototype models', 'Masters degree or higher, in computer science or related fieldExperience developing practical ML solutionsStrong knowledge of Algorithm Development and ability to put code into productionBONUS: Experience with AWS is highly preferred', ' Talented Technical Team', ' Medical, Dental, Vision', ' Industry Leading AI Software Talented Technical Team Tons of room for upward career growth', 'Location:', 'You will be a key member of our development team, producing high-performance computer vision products for document verification, text segmentation and related OCR solutions', 'Position:', 'Masters degree or higher, in computer science or related field', ' Competitive salaries (DOE) 100% work from home! Bonuses Vacation / PTO Certification / educational reimbursements Medical, Dental, Vision 401(k) and much more!', ' Bonuses', 'Email Your Resume In Word To', ' Competitive salaries (DOE)', 'BONUS: Experience with AWS is highly preferred', ' Vacation / PTO', 'Your Right to Work', 'AND SALARY']",Entry level,Full-time,Information Technology,Construction,2020-11-05 11:32:32
2021 BSMH Intern Program: HR - Data Science Intern,Bon Secours Mercy Health,"Cincinnati, OH",20 hours ago,Be among the first 25 applicants,"['', 'Professionalism & Integrity', 'Accepts personal responsibility', 'Delivers a high-quality work product ensuring its completeness and organization is logicalUses effective time management skills to complete project work within specified deadlinesPerforms thorough self-reviews of workMeets assigned deadlines while performing assigned tasksKeeps supervisor informed on a routine basis as to the status of various projects, particularly when a delay or problem arises', 'Technical Skills', 'Currently pursuing a degree in Data Analytics, Business Analytics, Mathematics, Data Science, or an Analytical/Mathematical related degree', 'Meets assigned deadlines while performing assigned tasks', 'Assist team with predictive analytics & forecasting projects', 'Scheduled Weekly Hours', 'Strong time management and organization skills', 'Requests challenging assignments to ensure continuous learning', 'Exhibits professional behavior, integrity and ethical behavior consistently', 'Delivers a high-quality work product ensuring its completeness and organization is logical', 'Hours: ', 'Qualifications', 'All applicants will receive consideration for employment without regard to race, color, national origin, religion, sex, sexual orientation, gender identity, age, genetic information, or protected veteran status, and will not be discriminated against on the basis of disability. If you’d like to view a copy of the affirmative action plan or policy statement for ', 'Displays positive attitude and work ethicAdheres to Mission and Mercy Health’s Core ValuesExhibits professional behavior, integrity and ethical behavior consistentlyAccepts personal responsibility', 'Basic working knowledge of Microsoft Office Suite', 'Demonstrates ability to work well with others and builds positive relationships with team membersRepresents own interests while working for the good of the team', 'Work with R/Python (Knowledge of R/Python programming language preferred)', 'Demonstrates ability to adjust communication style of the audience', 'Bon Secours Mercy Health!', 'Forecast monthly system wide turnover, based on historical data and present insights for different demographics', 'Comprehensive, affordable medical, dental and vision plans', 'Keeps supervisor informed on a routine basis as to the status of various projects, particularly when a delay or problem arises', 'Delivers communications, both oral and written, that are timely, clear and concise', 'Educational Assistance', 'Responsibilities', 'Applies effective listening skills', 'Develops understanding of projects and how tasks relate to the “big picture”', 'Junior/Senior/Graduate preferred', 'Displays positive attitude and work ethic', 'We’ll Also Reward Your Hard Work With', 'Ability to work effectively in a team environment and have strong rapport with the leaders and colleagues', 'Life insurance w/AD&D', 'Uses effective time management skills to complete project work within specified deadlines', 'Proficient in Microsoft Office suite – specifically Excel, Word, PowerPoint, Outlook', 'Work Shift', 'Basic programming skills', 'recruitment@mercy.com', 'Thank you for considering a career at ', 'Good communication (verbal, written, and listening)', 'Represents own interests while working for the good of the team', 'Takes initiative and is willing to attempt new tasks/responsibilities. Asks questions when unclear of a concept or ideaRequests challenging assignments to ensure continuous learningActively solicits feedback on performance', 'About Bon Secours Mercy Health', 'HR – Data Analytics Internship ', 'Location: ', 'Support statistical work for various survey analyses', 'Utilize Machine learning models and data visualization tools to make binary predictions', 'An employer-matched 403(b) for those who qualify', 'Ability to work independently', 'Work with our data scientist to support current projects', 'Familiarity with Python/R programming language', 'Data cleanup and modeling', 'Provide analytical insights for various HR programs (eg: Student Loan Forgiveness Program)', 'Adheres to Mission and Mercy Health’s Core Values', 'Comprehensive, affordable medical, dental and vision plansPrescription drug coverageFlexible spending accountsLife insurance w/AD&DAn employer-matched 403(b) for those who qualifyPaid time offEducational AssistanceAnd much more', 'Actively solicits feedback on performance', 'Paid time off', 'Dates: ', 'Strong interpersonal and presentations skills', 'Takes initiative and is willing to attempt new tasks/responsibilities. Asks questions when unclear of a concept or idea', 'Basic programming skillsBasic working knowledge of Microsoft Office SuiteDevelops understanding of projects and how tasks relate to the “big picture”Demonstrates ability to research, analyze and conclude on issuesAsks the right questions to garner an appropriate level of understanding', 'Communication', 'Focus on Quality & Workload Management', 'Delivers communications, both oral and written, that are timely, clear and conciseApplies effective listening skillsDemonstrates ability to adjust communication style of the audience', 'Performs thorough self-reviews of work', 'Flexible spending accounts', 'Currently pursuing a degree in Data Analytics, Business Analytics, Mathematics, Data Science, or an Analytical/Mathematical related degreeJunior/Senior/Graduate preferredFamiliarity with Python/R programming languageProficient in Microsoft Office suite – specifically Excel, Word, PowerPoint, OutlookGood communication (verbal, written, and listening)Strong interpersonal and presentations skillsSelf-motivated, capable of taking initiative, successfully handle and prioritize multiple competing priorities, and effectively manage deadlinesAbility to work effectively in a team environment and have strong rapport with the leaders and colleaguesAbility to work independentlyStrong analytical skillsStrong time management and organization skills', 'Accountabilities', 'Perform ad-hoc queries', 'Create decision trees, regressions, and random forests', 'Prescription drug coverage', ', which are Affirmative Action and Equal Opportunity Employers, please email recruitment@mercy.com. If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact The Talent Acquisition Team at ', 'Teamwork', 'Self-motivated, capable of taking initiative, successfully handle and prioritize multiple competing priorities, and effectively manage deadlines', 'Demonstrates ability to work well with others and builds positive relationships with team members', 'Personal Effectiveness', 'Department', 'Strong analytical skills', 'Demonstrates ability to research, analyze and conclude on issues', 'And much more', 'Other Information', 'Asks the right questions to garner an appropriate level of understanding', 'Data cleanup and modelingAssist team with predictive analytics & forecasting projectsSupport statistical work for various survey analysesWork with our data scientist to support current projectsCreate decision trees, regressions, and random forestsWork with R/Python (Knowledge of R/Python programming language preferred)Forecast monthly system wide turnover, based on historical data and present insights for different demographicsUtilize Machine learning models and data visualization tools to make binary predictionsProvide analytical insights for various HR programs (eg: Student Loan Forgiveness Program)Perform ad-hoc queries']",Not Applicable,Full-time,Education,"Health, Wellness and Fitness",2020-11-05 11:32:32
"Data Scientist, Cardiovascular modeling",N/A,"Cambridge, MA",21 hours ago,77 applicants,"['', 'We are seeking a Data Scientist who can drive our research into cardiovascular modeling. You will play an important part in the growing MindMics team of scientists, engineers, and clinicians. You will build models of cardiovascular function to be compared with precise, continuous measurements from human subjects, obtained utilizing our technology. You will also guide the design, execution, and interpretation of experiments to improve our unique monitoring systems. Finally, you will participate in clinical trials and collaborative research projects with our external partners in academia and industry.', 'Conduct independent research projects on non-routine analysis problems.', 'Demonstrate leadership and technical expertise in your field of research.', 'Advanced degree (M.A. or Ph.D.) in a relevant field (biology, medicine, data science)', 'Work with complex datasets combining device signals with patient information.', 'Work with complex datasets combining device signals with patient information.Conduct independent research projects on non-routine analysis problems.Collaborate cross-functionally with scientists, engineers, and clinicians.Demonstrate leadership and technical expertise in your field of research.Present your findings to internal and external audiences.Author internal and external reports and research publications.Collaborate with research teams with our external partner organizations.', 'Contact us if you are interested and would like to learn more.\xa0', 'Advanced degree (M.A. or Ph.D.) in a relevant field (biology, medicine, data science)or equivalent practical experience.Domain expertise with modeling the cardiovascular systemExpertise in machine learning, exploratory data analysis, and/or signal processing.Demonstrated ability to lead and execute scientific research projects.Ability to manage multiple projects and priorities simultaneously.Strong communication and collaboration skills.Eagerness to take on unexpected challenges in a dynamic environment.', 'Ability to manage multiple projects and priorities simultaneously.', 'Responsibilities', 'Domain expertise with modeling the cardiovascular system', 'Expertise in machine learning, exploratory data analysis, and/or signal processing.', 'Eagerness to take on unexpected challenges in a dynamic environment.', 'Demonstrated ability to lead and execute scientific research projects.', 'Strong communication and collaboration skills.', 'Qualifications', 'joseph.lehar@mindmics.com', 'Present your findings to internal and external audiences.', 'Collaborate cross-functionally with scientists, engineers, and clinicians.', 'or equivalent practical experience.', 'Collaborate with research teams with our external partner organizations.', 'MindMics, 90 Sherman St, Cambridge MA 02140', 'Author internal and external reports and research publications.', 'This is a ground floor opportunity with a very promising early-stage company.\xa0The upside potential for this position is huge.', 'Joseph Lehár, PhD, CSO']",Associate,Full-time,Analyst,Biotechnology,2020-11-05 11:32:32
"Senior Data Scientist, Risk and Fraud",Robinhood,"Menlo Park, CA",6 hours ago,Be among the first 25 applicants,"['', 'Risk & Fraud experience in fintech is a plus', ' Combining knowledge of several research domains to improve our understanding of different risks to Robinhood and help power decisions Designing new machine learning systems to power the fraud prevention and risk reduction efforts at Robinhood especially in product areas Build production grade models on large-scale datasets to measure effectiveness across products by leveraging statistical modeling, machine learning and data mining techniques. Collaborate with the rest of the data team and partner marketing, product, content, design teams to build data solutions and products to drive user and revenue growth.  Work with cross-functional teams to implement insights and analytical solutions to empower data-driven decision making. Problem solving skills and a can-do attitude to dive deep into data to solve business problems ', 'About The Company', 'Solid understanding of unsupervised learning, statistical analysis and machine learning algorithms for imbalanced datasets.', 'Your Day-to-day Will Involve', 'Feeling ready to give 100% to democratizing finance for all? We’d love to have you apply, even if you feel unsure about whether you meet every single requirement in this posting. At Robinhood, we’re looking for people invigorated by our mission, not just those who simply check off all the boxes.', 'Some Things We Consider Critical For This Role', 'At least 4 years of work experience, either in a research/ academic or commercial/ industry setting.', ' Graduate degree in a quantitative field such as mathematics, statistics, computer science, engineering or natural sciences (or equivalent research/work experience) Solid understanding of unsupervised learning, statistical analysis and machine learning algorithms for imbalanced datasets. Excellent programming skills, including expert level familiarity with either Python or R programming languages At least 4 years of work experience, either in a research/ academic or commercial/ industry setting. Risk & Fraud experience in fintech is a plus ', 'Combining knowledge of several research domains to improve our understanding of different risks to Robinhood and help power decisions', 'Passion for working and learning in a fast-growing company', ' Passion for working and learning in a fast-growing company ', 'Problem solving skills and a can-do attitude to dive deep into data to solve business problems', 'Graduate degree in a quantitative field such as mathematics, statistics, computer science, engineering or natural sciences (or equivalent research/work experience)', 'Work with cross-functional teams to implement insights and analytical solutions to empower data-driven decision making.', 'About The Role', 'Collaborate with the rest of the data team and partner marketing, product, content, design teams to build data solutions and products to drive user and revenue growth. ', 'Build production grade models on large-scale datasets to measure effectiveness across products by leveraging statistical modeling, machine learning and data mining techniques.', 'Designing new machine learning systems to power the fraud prevention and risk reduction efforts at Robinhood especially in product areas', 'Bonus Points', 'Excellent programming skills, including expert level familiarity with either Python or R programming languages']",Associate,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
"AI Research scientist: up to $350,000 base+equity",Apptronic Labs,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', 'Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Ideal candidates would be able to rapidly iterate on new ideas with engineers, potentially publish at top conferences and be able to write code.', 'Responsibilities:', 'We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'We are looking for people who have done research / published papers in one of the following areas: Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Candidates will need to have a PhD preferably in Artificial Intelligence or Machine Learning.\xa0', 'Job Description:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. We have also previously been founders and early employees at startups. We are backed by Eric Schmidt and Decibel Ventures with Series A funding of $18 million. We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'General Requirements:', 'Required Skills:', 'Responsible for coming up with new techniques in unsupervised learning, dataset augmentation and deep reinforcement learning that can be applied to automating various parts of the AI development workflow.']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Machine Learning Engineer - Computer Vision,Systems & Technology Research,"Woburn, MA",19 hours ago,40 applicants,"['', 'Some Other Relevant Skills You May Have', 'Experience with scientific software development', 'Collaborate with other STR engineers and leading researchers in the computer vision community to develop, adapt, extend and optimize state-of-the-art techniques for addressing new sensor exploitation applications.', 'Solve scene understanding problems where limited measured training data is available using techniques such as transfer learning and domain adaptation. ', 'Track record of applying computer vision and machine learning algorithms to scene understanding problems', 'Perform data analysis on experimental data and identify performance improvement strategies.', 'Experience with Python and C/C++ ', 'Interact with national security customers and users to determine and assess unmet needs and evolving requirements.', 'Description', 'Track record in written and oral communication to both technical and non-technical audiences ', 'The Role', 'BS, MS or PhD degree in Computer Science, Electrical Engineering, Applied Mathematics or related technical discipline', ' Experience with Python and C/C++  Track record in written and oral communication to both technical and non-technical audiences  ', 'Requirements', ' Design and implement innovative computer vision and deep learning algorithms for solving challenging scene understanding problems. Collaborate with other STR engineers and leading researchers in the computer vision community to develop, adapt, extend and optimize state-of-the-art techniques for addressing new sensor exploitation applications. Apply sensor exploitation solutions to a range of image modalities, such as: visible/infrared video from ground and aerial sensors, social media photographs, imaging radar, LIDAR or hyperspectral cameras. Solve scene understanding problems where limited measured training data is available using techniques such as transfer learning and domain adaptation.  Perform data analysis on experimental data and identify performance improvement strategies. Interact with national security customers and users to determine and assess unmet needs and evolving requirements. Transition algorithms to prototype and/or real-time systems demonstrations. Position may involve travel to customer meetings and/or data collections and experiments. ', 'Apply sensor exploitation solutions to a range of image modalities, such as: visible/infrared video from ground and aerial sensors, social media photographs, imaging radar, LIDAR or hyperspectral cameras.', 'Design and implement innovative computer vision and deep learning algorithms for solving challenging scene understanding problems.', 'Position may involve travel to customer meetings and/or data collections and experiments.', 'Who You Are', ' BS, MS or PhD degree in Computer Science, Electrical Engineering, Applied Mathematics or related technical discipline Track record of applying computer vision and machine learning algorithms to scene understanding problems Experience with scientific software development Motivated collaborator with internal and external teams ', 'Motivated collaborator with internal and external teams', 'Transition algorithms to prototype and/or real-time systems demonstrations.']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Data Scientist - CI Poly,Stanley Reid & Company,"Reston, VA",21 hours ago,Be among the first 25 applicants,"['', ' US citizenship plus current TS/SCI + CI Poly', 'Any Of The Following Is Beneficial', ' Experience with Matlab', ' Experience with SPSS, SAS, KNIME, RapidMiner, or Statistica Experience with Matlab Experience with SQL and Oracle Experience with Java, Pig, or Spark People-centric analytics (human behavior, user activity, risk ranking, psychology, security, CI, etc.) Supervised and unsupervised learning techniques (neural networks, regressions, clustering, segmentation, etc.)', ' People-centric analytics (human behavior, user activity, risk ranking, psychology, security, CI, etc.)', ' Experience with R/Shiny or Python', ' Experience with Java, Pig, or Spark', ' Supervised and unsupervised learning techniques (neural networks, regressions, clustering, segmentation, etc.)', "" Bachelor's Degree (MS or PhD preferred)"", ' Experience with Data Science, Statistics, Machine Learning, NLP, Predictive Analytics, or similar discipline', ' Experience with SQL and Oracle', ' Experience with SPSS, SAS, KNIME, RapidMiner, or Statistica', "" US citizenship plus current TS/SCI + CI Poly Bachelor's Degree (MS or PhD preferred) Experience with Data Science, Statistics, Machine Learning, NLP, Predictive Analytics, or similar discipline Experience with R/Shiny or Python""]",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Staff Data Scientist,ServiceNow,"Santa Clara, CA",9 hours ago,Be among the first 25 applicants,"['', 'Unstructured data (utterances, descriptions, documents, …)', 'Company', 'Collaborate day-to-day with an energetic team of like-minded data scientists, developers, product managers and quality engineers.Master new functional areas and take ownership of customer-critical features', 'Mentor and help grow the data science team', 'Bring intelligence to customer workflows by leveraging their individual data -', 'Strong background in statistics, probability, and machine learning', 'Solid software development skills and understanding of computer science fundamentalsStrong proficiency with Python scientific stack (scikit-learn, pandas, numpy, …)Experience with neural network-based NLP technologies (Transformers, BERT, etc.) desiredProficient in Java, SQL, source code control systems (git), and basic UNIX utilitiesStrong educational background (M.S.) in a quantitative discipline (Ph.D. preferred)', 'Structured data (workflow state evolution, database tables)Unstructured data (utterances, descriptions, documents, …)Adapting to their unique and complex workflowsAt Scale: 7000+ customers with a wide range of data volumes', 'Strong educational background (M.S.) in a quantitative discipline (Ph.D. preferred)', 'Experience with neural network-based NLP technologies (Transformers, BERT, etc.) desired', 'Co-pilot the expansion of machine learning into new products with our product management, internal operations teams and development teams', 'Providing technical leadership to data science teams', 'In order to be successful in this role, we need someone who has:', 'Experience evaluating and developing new machine learning algorithms', 'Solid software development skills and understanding of computer science fundamentals', 'Master new functional areas and take ownership of customer-critical features', 'Team ', 'At Scale: 7000+ customers with a wide range of data volumes', 'Staff Data ScientistKirkland, WA, Boston, Ma, Chicago, IL, Bay Area, Ca', 'Demonstrated ability to deploy machine learning solutionsProven track record solving industrial problems with dataExperience evaluating and developing new machine learning algorithmsProviding technical leadership to data science teams', 'Excellent written and oral communication skills', 'Role ', 'Ability to explain models in simple terms to a broader audience', 'Structured data (workflow state evolution, database tables)', 'Adapting to their unique and complex workflows', 'Collaborate day-to-day with an energetic team of like-minded data scientists, developers, product managers and quality engineers.', 'Strong proficiency with Python scientific stack (scikit-learn, pandas, numpy, …)', 'Demonstrated ability to deploy machine learning solutions', 'Proficient in Java, SQL, source code control systems (git), and basic UNIX utilities', 'In This Role, You Will', '6+ years’ experience in a commercial setting:', 'Proven track record solving industrial problems with data']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist, Advanced Analytics",GoHealth,"Chicago, IL",4 hours ago,161 applicants,"['', 'Familiarity with optimization techniques including linear optimization, nonlinear optimization and network optimization', 'Provide new insights through a combination of descriptive and diagnostic analytics', 'current and future', 'Frequently cited statistics show that women and underrepresented groups apply to jobs only if they meet 100% of the qualifications. GoHealth encourages you to break that statistic and to apply. No one ever meets 100% of the qualifications. We look forward to your application.', 'Medical, dental, vision, and life insurance benefits', ' Open vacation policy because work life balance is important 401k program with company match Employee Stock Purchase Program Medical, dental, vision, and life insurance benefits Paid maternity and paternity leave Professional growth opportunities Generous employee referral bonuses Employee Resource Groups Work from Home Stipend GoHealth is an Equal Opportunity Employer ', 'Benefits & Perks', 'Experience with Python packages NumPy, SciPy, pandas and scikit-learn', 'Understand GoHealth’s business processes, including the role each department plays in supporting the company’s ultimate goals', 'Experience with a data and analytics programming language such as Python, R, or MATLAB', 'Lead quantitative analyses, working with product management, partners, and data engineers to solve business problems', 'Responsibilities', 'Work from Home Stipend', 'Employee Resource Groups', '401k program with company match', 'Test hypotheses across departments using measurable, statistically methods to evaluate best performing strategies', 'Experience taking insights and turning them into models and products can create value', 'Familiarity with probabilistic modeling, including Poisson processes and renewal processes', 'Generous employee referral bonuses', 'Stay current with data analytics tools and techniques and methods for data science, statistics and optimization', 'Experience extracting and standardizing inconsistent data from different data sources', 'SQL experience in writing, editing and modifying complex, efficient SQL scripts', 'Paid maternity and paternity leave', ' employees by managing our business remotely. This is inclusive of interviewing, ', 'Skills & Experience', 'on-boarding', 'Mastery of statistics including regression, estimation and hypothesis testing', 'Employee Stock Purchase Program', ' the unprecedented situation of COVID-19, GoHealth has decided to protect our ', 'Open vacation policy because work life balance is important', ' 3+ years in Data Science or analytics, BS or BA degree in quantitative discipline such as Mathematics, Statistics, Operations Research, Computer Science, Economics or Engineering Mastery of statistics including regression, estimation and hypothesis testing Experience with a data and analytics programming language such as Python, R, or MATLAB Experience with Python packages NumPy, SciPy, pandas and scikit-learn Familiarity with probabilistic modeling, including Poisson processes and renewal processes Familiarity with optimization techniques including linear optimization, nonlinear optimization and network optimization SQL experience in writing, editing and modifying complex, efficient SQL scripts Experience implementing algorithms or models into a product Experience guiding decisions within a business context through a combination of descriptive and diagnostic analytics Experience taking insights and turning them into models and products can create value Experience extracting and standardizing inconsistent data from different data sources ', ' Understand GoHealth’s business processes, including the role each department plays in supporting the company’s ultimate goals Lead quantitative analyses, working with product management, partners, and data engineers to solve business problems Provide new insights through a combination of descriptive and diagnostic analytics Test hypotheses across departments using measurable, statistically methods to evaluate best performing strategies Stay current with data analytics tools and techniques and methods for data science, statistics and optimization Convey complex concepts to colleagues with varying degrees of analytical understanding ', 'Due to', 'Experience guiding decisions within a business context through a combination of descriptive and diagnostic analytics', "" and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities’ and the CDC."", '3+ years in Data Science or analytics, BS or BA degree in quantitative discipline such as Mathematics, Statistics, Operations Research, Computer Science, Economics or Engineering', 'Convey complex concepts to colleagues with varying degrees of analytical understanding', 'GoHealth is an Equal Opportunity Employer', 'Professional growth opportunities', 'Experience implementing algorithms or models into a product']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Machine Learning Engineer,Upstart,"San Mateo, CA",4 hours ago,Over 200 applicants,"['', 'Machine Learning Engineer ', 'Advanced degree in computer science, mathematics, statistics or related area of study', 'The Team', 'Experience optimizing models for memory and speed', ' Competitive compensation (base + bonus & equity) Comprehensive medical, dental, and vision coverage Personal development and technology & ergonomic budgets  Life insurance and disability benefits  Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams)  Generous vacation policy 401(k) retirement plan Catered lunches + snacks & drinks ', 'Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams) ', 'The Role', '401(k) retirement plan', 'Competitive compensation (base + bonus & equity)', '2+ years of professional experience as a data scientist or software engineer', 'Experience productionalizing, deploying, and training machine learning models (we use Python and sklearn, but experience in any language is valuable)', 'What We’re Looking For', 'Comprehensive medical, dental, and vision coverage', 'Knowledge of machine learning and statistics or a strong desire to learn', ' 2+ years of professional experience as a data scientist or software engineer Experience productionalizing, deploying, and training machine learning models (we use Python and sklearn, but experience in any language is valuable) Interest in helping other data scientists improve code quality in addition to conducting independent analyses Experience optimizing models for memory and speed Knowledge of machine learning and statistics or a strong desire to learn Advanced degree in computer science, mathematics, statistics or related area of study ', 'Life insurance and disability benefits ', 'Generous vacation policy', 'Interest in helping other data scientists improve code quality in addition to conducting independent analyses', 'Personal development and technology & ergonomic budgets ', 'Catered lunches + snacks & drinks', 'What You’ll Love']",Entry level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
"AI Research scientist: up to $350,000 base+equity",Scovios,"Seattle, WA",8 hours ago,Be among the first 25 applicants,"['', 'Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Ideal candidates would be able to rapidly iterate on new ideas with engineers, potentially publish at top conferences and be able to write code.', 'Responsibilities:', 'We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'We are looking for people who have done research / published papers in one of the following areas: Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Candidates will need to have a PhD preferably in Artificial Intelligence or Machine Learning.\xa0', 'Job Description:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. We have also previously been founders and early employees at startups. We are backed by Eric Schmidt and Decibel Ventures with Series A funding of $18 million. We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'General Requirements:', 'Required Skills:', 'Responsible for coming up with new techniques in unsupervised learning, dataset augmentation and deep reinforcement learning that can be applied to automating various parts of the AI development workflow.']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Senior Machine Learning Engineer,Tapjoy,"San Francisco, CA",11 hours ago,Be among the first 25 applicants,"['', 'Inform bidding strategy and data engineering architecture. ', 'Understand major recommendation systems approaches and corresponding algorithms. ', 'Experiment and improve machine learning models for the recommendation/ad optimization system. ', 'B.S./M.S., in Computer Science or similar applied technical field.', 'Strong understanding of Algorithms, Data Structures and Machine Learning / Data Mining', 'Responsibilities', 'Deep expertise in recommendation systems, classification models, class imbalance, and model calibration. ', 'Hands-on Machine Learning related industry projects.', ' Solid object-oriented programming skill (Scala or Java) and at least one scripting language such as Python/R. Packages: scikit-learn, TensorFlow.  Scaling GPU clusters to train deep neural networks. Experimental Design and statistical inference.  Deep expertise in recommendation systems, classification models, class imbalance, and model calibration.  Experience with BigQuery or PySpark or another modern method to access data.  Experience with deploying and monitoring real-time model endpoint in AWS SageMaker is a plus. ', 'Understanding of RDBMS, SQL and NoSQL alternatives', 'Understand various ad-optimization algorithms (CTR prediction, eCPM optimization, user targeting and segmentation, RTB optimization, Exploration/Exploitation Algos) ', 'Competencies', 'Packages: scikit-learn, TensorFlow. ', 'Understand major supervised learning and unsupervised learning algorithms (Artificial/Deep Neural Networks, Boosting algorithms, Random Forest, SVM, Naive Bayes, PCA, K-means variants, etc).', 'Scaling GPU clusters to train deep neural networks.', 'Position Title: ', ' B.S./M.S., in Computer Science or similar applied technical field. Hands-on Machine Learning related industry projects. Ability to work in a fast paced, test-driven collaborative and iterative programming environment. Understand major supervised learning and unsupervised learning algorithms (Artificial/Deep Neural Networks, Boosting algorithms, Random Forest, SVM, Naive Bayes, PCA, K-means variants, etc). Understand major recommendation systems approaches and corresponding algorithms.  Understand statistical hypothesis testing (ex. A/B testing) Strong understanding of Algorithms, Data Structures and Machine Learning / Data Mining Understanding of RDBMS, SQL and NoSQL alternatives ', 'Understand statistical hypothesis testing (ex. A/B testing)', 'Requirements', 'Ability to work in a fast paced, test-driven collaborative and iterative programming environment.', ' Experiment and improve machine learning models for the recommendation/ad optimization system.  Inform bidding strategy and data engineering architecture.  Understand various ad-optimization algorithms (CTR prediction, eCPM optimization, user targeting and segmentation, RTB optimization, Exploration/Exploitation Algos)  ', 'Experience with deploying and monitoring real-time model endpoint in AWS SageMaker is a plus.', 'Solid object-oriented programming skill (Scala or Java) and at least one scripting language such as Python/R.', 'Experimental Design and statistical inference. ', 'Experience with BigQuery or PySpark or another modern method to access data. ']",Associate,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
Cloud Data Engineer,Brunel,"Houston, TX",2 hours ago,Be among the first 25 applicants,"['Demonstrated experience in designing, deploying, and operating cloud-based data solutions supporting model- and machine learning-based products ', 'Defines and develops data solutions to meet product requirements using the latest and best cloud-based platforms ', 'Responsible for developing and deploying data solutions and structures using cloud-based platforms, in alignment with the companies shift towards more cloud-based technology solutions ', 'Relevant Cloud Certifications (i.e. Certified AWS Solutions Architect – Associate (Professional preferred), Developer, Database Specialty, Machine Learning Specialty, etc.)', 'Introduction', 'Experience Proficiency in R and/or SAS; additional knowledge of other statistical software (SPSS, RapidMiner, etc.) is helpful ', 'Interacts with the Asset to understand all data requirements to develop business insights and translates them into data structures and data model requirements to IT ', 'Experience working with large data sets, simulation/ optimization and distributed computing tools ', 'Responsibilities', 'Responsible for developing and deploying data solutions and structures using cloud-based platforms, in alignment with the companies shift towards more cloud-based technology solutions Apply strong expertise in machine-learning, data mining, and information retrieval to design, prototype, and build the next-generation analytics engines and services Understand business problems and designs end-to-end analytics use cases Conducts advanced statistical analysis to provide actionable insights, identify trends, and measure performance Defines and develops data solutions to meet product requirements using the latest and best cloud-based platforms Has an ability to work with senior technologists and Business leaders providing technical guidance related to data architecture, data models and meta data management Interacts with the Asset to understand all data requirements to develop business insights and translates them into data structures and data model requirements to IT Works closely with database teams on topics related to data requirements, cleanliness, accuracy etc. Creates and modifies computer programs to extract information from company databases ', 'Has an ability to work with senior technologists and Business leaders providing technical guidance related to data architecture, data models and meta data management ', 'Creates and modifies computer programs to extract information from company databases ', 'Responsibilities ', 'Requirements ', '5-7 years’ experience in a statistical and/or data science role ', 'Deep knowledge of machine learning, statistics, optimization or related field ', 'We’re hiring a Cloud Data Engineer for our client, a large mining company, to join their team. The Cloud Data Engineer’s primary responsibility is to define data lifecycle, including data models and data sources for analytics platform, gathering data from business and cleaning them in order to provide ready-to-work inputs for Data Scientists. ', 'Understand business problems and designs end-to-end analytics use cases ', 'Requirements', 'Experience in working with large datasets, relational databases (SQL), and distributed systems (Hadoop, Hive) ', 'Introduction ', 'Conducts advanced statistical analysis to provide actionable insights, identify trends, and measure performance ', 'Works closely with database teams on topics related to data requirements, cleanliness, accuracy etc. ', 'Advanced knowledge of statistical techniques, data mining, machine learning (regression, decision trees, clustering, random forests, generalized linear models, etc.) ', 'Attitude to thrive in a fun, fast-paced start-up like environment ', '\xa0 ', '5-7 years’ experience in a statistical and/or data science role Demonstrated experience in designing, deploying, and operating cloud-based data solutions supporting model- and machine learning-based products Deep knowledge of machine learning, statistics, optimization or related field Experience working with large data sets, simulation/ optimization and distributed computing tools Experience in working with large datasets, relational databases (SQL), and distributed systems (Hadoop, Hive) Experience Proficiency in R and/or SAS; additional knowledge of other statistical software (SPSS, RapidMiner, etc.) is helpful Advanced knowledge of statistical techniques, data mining, machine learning (regression, decision trees, clustering, random forests, generalized linear models, etc.) Attitude to thrive in a fun, fast-paced start-up like environment Relevant Cloud Certifications (i.e. Certified AWS Solutions Architect – Associate (Professional preferred), Developer, Database Specialty, Machine Learning Specialty, etc.)', 'Apply strong expertise in machine-learning, data mining, and information retrieval to design, prototype, and build the next-generation analytics engines and services ']",Mid-Senior level,Contract,Other,Mining & Metals,2020-11-05 11:32:32
Senior Principal Data Scientist [Dialogue Management/NLU]],LivePerson,"Seattle, WA",10 hours ago,Be among the first 25 applicants,"['Faceted unsupervised learning -- how can we inject knowledge into unsupervised tasks? How can we inject knowledge into clustering/similarity tasks to reflect facets we care about (intent) and orthogonalize irrelevant facets?', ""LivePerson was named to Fast Company's World’s most innovative companies of 2020 list for the Artificial Intelligence category. We offer top tier tech & data science colleagues, along with opportunities to push your own limits. We embrace invention and experimentation. You’ll have great benefits, flexible time off, plus snacks and drinks to keep your mind fresh and stomach full. Most importantly, you’ll have an ability to make an impact at work and at brands across the globe as we build the future with trusted Conversational AI together.\xa0"", 'You can operate in a fast paced, dynamic environmentYou can advance the SOTA in dialogue systems with experiments and code that are well-designed and well-implemented.You can build partnerships that move our business forwardYou see feedback or failure as motivation to learn and to growYou believe data-driven decision making is the normYou relate to our core principles (link) and want to work with Conversational AI experts', 'Learning NLP systems using self-supervision from unannotated dialogue - Leveraging latent structure within task-oriented dialogue data to solve classification and dialogue problems more accurately and label-efficiently.Faceted unsupervised learning -- how can we inject knowledge into unsupervised tasks? How can we inject knowledge into clustering/similarity tasks to reflect facets we care about (intent) and orthogonalize irrelevant facets?Lightly/distantly supervised dialog management ML systems - How can we utilize self-supervision and reinforcement learning to learn representations of conversational goals and policies from unlabelled historical conversations in a goal-oriented setting?Controllable natural language generation -- How can we build adaptable natural language generation systems that can be easily controlled/configured?', 'You will thrive here if: ', 'Demonstrated capacity to work closely with teammates in a highly collaborative environment, as well as providing strong individual contributions', 'Expertise in NLP techniques to solve problems in dialogue management: either direct experience in dialogue systems OR experience in reinforcement learning', 'You relate to our core principles (link) and want to work with Conversational AI experts', 'Work with one of the world’s largest goal-oriented conversational data sets to push the boundaries of computational linguistics and drive innovative new products at scale.', 'Preferred qualifications:', 'SOTA in dialogue system', '\xa0', 'In addition to a world-class data set, you’ll also have an at-scale population of expert data annotators (contact center agents) to help drive investigation and learning.', 'Learning NLP systems using self-supervision from unannotated dialogue - Leveraging latent structure within task-oriented dialogue data to solve classification and dialogue problems more accurately and label-efficiently.', 'Publish and present cutting-edge research derived from our conversational data', 'You can advance the SOTA in dialogue systems with experiments and code that are well-designed and well-implemented.', 'You believe data-driven decision making is the norm', 'All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.', 'Some areas of research of particular interest:', 'We are an innovative, intent-driven company that believes in building the future and we are looking for growth minded, unconventional thinkers, developers and builders to join the team.\xa0', 'Propose and execute research efforts that drive product strategy', 'You can build partnerships that move our business forward', 'Degree in Computational Linguistics, Computer Science, Statistics, or Mathematics', 'LivePerson is a transformational force in how brands and consumers communicate. With over 18,000 brands, including HSBC, Disney, Verizon, and Home Depot, we are on a mission to make life easier for people and brands everywhere through trusted Conversational AI. We believe in a future where conversations are the norm for getting your intentions fulfilled - whatever they are.\xa0\xa0', 'You can operate in a fast paced, dynamic environment', 'Record of publications in competitive journals/conferences in the field, such as EMNLP, ACL, ICLR, NIPS, NAACL.', 'Writing Python code that is efficient and clean in a Linux environment', 'Your qualifications are:', 'Develop state of the art approaches to unsupervised/semi-supervised problems in intent and dialog management.', 'Controllable natural language generation -- How can we build adaptable natural language generation systems that can be easily controlled/configured?', '3-5 years post-graduate experience in ML, specifically in NLU/NLP', 'Lightly/distantly supervised dialog management ML systems - How can we utilize self-supervision and reinforcement learning to learn representations of conversational goals and policies from unlabelled historical conversations in a goal-oriented setting?', 'Why you’ll love working here:', 'Proven track record of problem-solving, communication, and critical-thinking skills', 'Experience with Python packages for Machine Learning (Scikit-Learn), NLP (SpaCy), and Deep Learning (Pytorch)', 'You see feedback or failure as motivation to learn and to grow', 'At LivePerson, people from diverse backgrounds come together to do their best work and be their authentic selves. We are proud to be an equal opportunity employer. ', 'Degree in Computational Linguistics, Computer Science, Statistics, or Mathematics3-5 years post-graduate experience in ML, specifically in NLU/NLPExpertise in NLP techniques to solve problems in dialogue management: either direct experience in dialogue systems OR experience in reinforcement learningTrack record of applied research on NLP or related fields, e.g. NLU, NLG, ASR/TTS and/or experience with dialogue systemsWriting Python code that is efficient and clean in a Linux environmentExperience with Python packages for Machine Learning (Scikit-Learn), NLP (SpaCy), and Deep Learning (Pytorch)Proven track record of problem-solving, communication, and critical-thinking skillsDemonstrated capacity to work closely with teammates in a highly collaborative environment, as well as providing strong individual contributions', 'Why you’ll love working here:\xa0', 'In this role you will:', 'Track record of applied research on NLP or related fields, e.g. NLU, NLG, ASR/TTS and/or experience with dialogue systems', 'Work with one of the world’s largest goal-oriented conversational data sets to push the boundaries of computational linguistics and drive innovative new products at scale.In addition to a world-class data set, you’ll also have an at-scale population of expert data annotators (contact center agents) to help drive investigation and learning.Propose and execute research efforts that drive product strategyPublish and present cutting-edge research derived from our conversational dataApply cutting-edge methods of NLP/NLU to learn and derive value from one of the world’s largest goal-oriented conversational data sets.Develop state of the art approaches to unsupervised/semi-supervised problems in intent and dialog management.', 'Apply cutting-edge methods of NLP/NLU to learn and derive value from one of the world’s largest goal-oriented conversational data sets.']",Director,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Senior Data Engineer,Insight,"Detroit, MI",14 hours ago,Be among the first 25 applicants,"['', 'APPLY', 'We are looking for an experienced Senior Data Engineer ', 'Aggressively grow your skillset and expertise to meet emerging needs', 'Analysis Services (SSAS) and DAX', 'Scripting: PowerShell, Azure Automation', '5+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)1+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Fortune Top 100 Best Companies for Diversity', '30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizesMicrosoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOpsFortune Top 100 Best Companies for DiversityFortune Top 50 Best Workplaces in TechnologyWinner of several “Best Places to Work” awards30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Predictive Analytics: R, Azure Machine Learning ', 'Requisition Number: 78954 ', 'Prioritize, self-direct and execute at velocity', 'some', 'Fortune Top 50 Best Workplaces in Technology', 'Skill at translating requirements into clean, efficient, quality code ', 'Strong analytical and reasoning skills that result in clear technical execution', 'About Insight', 'Lead discussions with clients and recommend technical solutions for business cases', '1+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity', 'Winner of several “Best Places to Work” awards', 'Integration Services (SSIS)', 'Design and code modern solutions to tough data challenges leveraging the cloud and ', 'Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data Factory', 'Development Languages: .NET, Java or Scala', 'most', 'SQL Server', 'Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team', 'Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externally', 'Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Design and develop cutting-edge enterprise data solutions in a fast-paced environmentLead discussions with clients and recommend technical solutions for business casesDesign and code modern solutions to tough data challenges leveraging the cloud and Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externallyPrioritize, self-direct and execute at velocityAggressively grow your skillset and expertise to meet emerging needs', 'Reporting Tools: Power BI, Tableau, Qlik, SSRS ', 'SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizes', 'Azure Big Data Technologies: Azure Data Lake and Azure Data Lake Analytics', 'Design and develop cutting-edge enterprise data solutions in a fast-paced environment', 'What We Do', 'What We Look For', 'Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity5+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)1+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or ScalaStrong analytical and reasoning skills that result in clear technical executionSkill at translating requirements into clean, efficient, quality code Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team', 'Ready to join?', 'SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)1+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Big Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystem', 'What can Insight offer?', 'Microsoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOps']",Mid-Senior level,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Research Scientist,KLA,"Milpitas, CA",6 hours ago,58 applicants,"['', '  Experience in complex optical system modeling and noise analysis  Hands-on experience in high precision optical system setup, diagnosis, remote instrument control and data collection  Strong math and physics background and fast learner  Good programming skill using Matlab, Python or the like. Experience in high performance computing is a plus.  Experience with modeling packages such as Comsol, FDTD is desirable', ' Group/Division ', ' Strong math and physics background and fast learner', ' Hands-on experience in high precision optical system setup, diagnosis, remote instrument control and data collection', ' Experience with modeling packages such as Comsol, FDTD is desirable', ' Designing and conducting experiments, analyzing and presenting data to support theoretical analysis.', '  Analyzing optical systems to understand the impact of specifications/tolerances on performance and providing guidelines for system design.  Designing and conducting experiments, analyzing and presenting data to support theoretical analysis.  Collaborating with other team members and other divisions to solve technical problems and support product roadmap.', ' Good programming skill using Matlab, Python or the like. Experience in high performance computing is a plus.', 'We offer a competitive, family friendly total rewards package. We design our programs to reflect our commitment to an inclusive environment, while ensuring we provide benefits that meet the diverse needs of our employees. ', 'KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com to request accommodation.', 'Minimum Qualifications', ' Collaborating with other team members and other divisions to solve technical problems and support product roadmap.', ' Analyzing optical systems to understand the impact of specifications/tolerances on performance and providing guidelines for system design.', 'Company Overview', ' Experience in complex optical system modeling and noise analysis']",Associate,Full-time,Other,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Data Engineer - BS/MS,Procter & Gamble,"Cincinnati, OH",9 hours ago,Be among the first 25 applicants,"['', ' Support and collaborate with Data Scientists developing advanced machine learning and statistical models ', ' Strong data wrangling skills ', ' Familiarity with data privacy and data governance ', ' Overall G.P.A. of 3.0 or above on a 4.0 scale ', ' Familiarity with machine learning workflows (desirable) ', ' Experience with cloud services (AWS, Azure or GCP) ', 'Description', ' A BS or MS in Computer Science, Computer or Electrical Engineering, but we also consider other, similar engineering degree ', ' Experience with NoSQL databases ', ' Strong interpersonal communication and collaboration skills  History of working independently and effectively multi-tasking  Familiarity with machine learning workflows (desirable)  Have experience with sensors and IoT cloud architecture (desirable)  Familiarity with RESTful Application Programming Interface (API), containers and microservices  Familiarity with data privacy and data governance  Experience with NoSQL databases ', ' Hands on experience with relational databases and the use of SQL to extract and manipulate data ', ' Strong problem-solving skills paired with extensive experience programming (Python, Java, C++, etc...)  Strong data wrangling skills  Hands on experience with relational databases and the use of SQL to extract and manipulate data  Experience with cloud services (AWS, Azure or GCP) ', ' Familiarity with RESTful Application Programming Interface (API), containers and microservices ', ' Deliver optimal data solution architectures, automation and technology choices starting from experimentation through proof of concept and often through delivery ', 'Qualifications', ' Strong interpersonal communication and collaboration skills ', ' Develop and maintain scalable data pipelines that will ingest, transform, and distribute numerous data streams and batches in support of key R&D initiatives ', ' Have experience with sensors and IoT cloud architecture (desirable) ', ' History of working independently and effectively multi-tasking ', ' If you want to join us, you will need: ', 'We Are Also Looking For Someone Who Has', 'In this role you will:', ' Strong problem-solving skills paired with extensive experience programming (Python, Java, C++, etc...) ', ' Evaluate tools and develop pipelines to capture, integrate and clean data to support edge analytics solutions ', ' A BS or MS in Computer Science, Computer or Electrical Engineering, but we also consider other, similar engineering degree  Overall G.P.A. of 3.0 or above on a 4.0 scale ', ' Develop and maintain scalable data pipelines that will ingest, transform, and distribute numerous data streams and batches in support of key R&D initiatives  Support and collaborate with Data Scientists developing advanced machine learning and statistical models  Evaluate tools and develop pipelines to capture, integrate and clean data to support edge analytics solutions  Deliver optimal data solution architectures, automation and technology choices starting from experimentation through proof of concept and often through delivery ', 'The Ideal Candidate']",Not Applicable,Full-time,Research,Consumer Goods,2020-11-05 11:32:32
Data Architect,Zoom,"San Jose, CA",5 hours ago,Be among the first 25 applicants,"['', 'Firm believer of data driven decision making', 'In-depth understanding of database structure principles', 'Coordinate with Data Science and Business Systems teams to identify future needs and requirements', 'Provide Data knowledge leadership to the Data teams and Systems Architects Analyze current data designs to optimize and provide structural improvements to handle the growth of the business Provide insights and new data processes to help with predictive modelingExecute Product driven data projects from database to analysis to insights to presentationsHave thorough knowledge of Data warehousing designs and have experience in designing conceptual and logical data models and flowchartsCoordinate with Data Science and Business Systems teams to identify future needs and requirementsAggregate and correlate large disparaging data sets from all business divisions', 'Great organization skills with the ability to manage competing priorities', 'Aggregate and correlate large disparaging data sets from all business divisions', 'Responsibilities', 'Strong problem-solving skills', 'Enterprise SaaS experience preferred', 'Self-driven with the ability to work in a self-guided manner', 'Analyze current data designs to optimize and provide structural improvements to handle the growth of the business ', 'Have thorough knowledge of Data warehousing designs and have experience in designing conceptual and logical data models and flowcharts', 'Provide insights and new data processes to help with predictive modeling', 'Familiarity with data visualization tools (e.g. Tableau) ', 'Provide Data knowledge leadership to the Data teams and Systems Architects ', 'Requirements', 'Expertise in SQL and Data warehousing concepts', 'Proven analytical skills with attention to detail', 'Execute Product driven data projects from database to analysis to insights to presentations', 'Minimum 7+ years of experience as a Data Architect, Data Engineer, Data Scientist or similar role', 'Experience with AWS, Redshift or Snowflake', 'Minimum 7+ years of experience as a Data Architect, Data Engineer, Data Scientist or similar roleIn-depth understanding of database structure principlesExpertise in SQL and Data warehousing conceptsFamiliarity with data visualization tools (e.g. Tableau) Enterprise SaaS experience preferredExperience with AWS, Redshift or SnowflakeFirm believer of data driven decision makingGreat organization skills with the ability to manage competing prioritiesProven analytical skills with attention to detailSelf-driven with the ability to work in a self-guided mannerStrong problem-solving skills']",Not Applicable,Full-time,Business Development,Information Technology and Services,2020-11-05 11:32:32
Tableau Consultant,Accenture,"Seattle, WA",10 hours ago,Be among the first 25 applicants,"['', 'You know your way around other data visualization toolsets such as Qlikview or Spotfire ', 'Here’s What You Need: ', 'Minimum of 2 year’s experience designing or developing with Tableau, including dashboards, reports, and/or front-end visualizations ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', 'You’re familiar with Business Intelligence tools including Cognos, Business Objects, OBIEE, methodologies, and/or responsibilities ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'You’re no newbie to Data Platforms such as Teradata, IBM, TM1, Netezza, DataMirror, Oracle, Essbase, GoldenGate, EMS, Greenplum', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Experience with database development including Custom SQL design, PLSQL, and/or Data Modeling ', 'Accenture Overview', 'Bonus Points If:', 'Equal Employment Opportunity:', 'Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'You’ve had experience with, or exposure to custom data visualization frameworks such as d3.js ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Accenture is committed to providing veteran employment opportunities to our service men and women. ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'You’ve got experience of full life-cycle development in a BI or Analytics environment ', 'The Work:', 'You Are:', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Business Development,Information Technology and Services,2020-11-05 11:32:32
"Machine Learning Engineer (App Store), Apple Media Products Data Science",Apple,"Culver City, CA",12 hours ago,Be among the first 25 applicants,"['', 'Description', 'Key Qualifications', 'Education & Experience', 'Summary']",Not Applicable,Full-time,Engineering,Consumer Electronics,2020-11-05 11:32:32
Data Scientist (Polygraph Clearance),ManTech,"Chantilly, VA",7 hours ago,Be among the first 25 applicants,"['', 'Working with large, complex, and disparate data setsDesigning and implementing innovative ways to analyze and exploit the Sponsor’s data holdingsResearching and reporting on a wide variety of Sponsor inquiriesRaising proactive inquiries to the Sponsor based on observations and proposed data analysis/exploitationSolving difficult, non-routine problems by applying advanced analytical methodologies, and improving analytic methodologiesDeveloping custom searchesCommunicating and coordinating with internal and external partners as needed', 'Secure our Nation, Ignite your Future', 'Expertise with statistical data analysis (e.g. linear models, multivariate analysis, stochastic models, sampling methods)', 'Developing custom searches', 'Applied mathematics (e.g. probability and statistics, formal modeling, computational social sciences)', 'Demonstrated effectiveness in collecting information and accurately representing/visualizing it to non-technical third parties', 'Experience with and theoretical understanding of algorithms for classification, regression, clustering, and anomaly detection', 'Desired Experience, Skills & Technologies', 'Communicating and coordinating with internal and external partners as needed', 'Knowledge of relational databases, including SQL and large-scale distributed systems (e.g. Hadoop)', 'Bachelor of Science or equivalent and 12-15 years related experience, but will consider all levels of experience.', 'Researching and reporting on a wide variety of Sponsor inquiries', 'TS/SCI with Polygraph', 'Designing and implementing innovative ways to analyze and exploit the Sponsor’s data holdings', 'Previous investigative experience using a combination of technical and analytic skills', 'Required Experience, Skills, & Technologies', 'Raising proactive inquiries to the Sponsor based on observations and proposed data analysis/exploitation', 'Solving difficult, non-routine problems by applying advanced analytical methodologies, and improving analytic methodologies', 'Computer programming (e.g. programming languages, math/statistics packages, computer science, machine learning, scientific computing)', 'Applied mathematics (e.g. probability and statistics, formal modeling, computational social sciences)Computer programming (e.g. programming languages, math/statistics packages, computer science, machine learning, scientific computing)Ability to code or script in one or more general programming languageExperience with and theoretical understanding of algorithms for classification, regression, clustering, and anomaly detectionKnowledge of relational databases, including SQL and large-scale distributed systems (e.g. Hadoop)Expertise with statistical data analysis (e.g. linear models, multivariate analysis, stochastic models, sampling methods)Demonstrated effectiveness in collecting information and accurately representing/visualizing it to non-technical third partiesTS/SCI with PolygraphBachelor of Science or equivalent and 12-15 years related experience, but will consider all levels of experience.', 'Working with large, complex, and disparate data sets', 'Duties, Tasks & Responsibilities', 'Ability to code or script in one or more general programming language']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Security Researcher (remote),deepwatch,"Denver, CO",18 hours ago,Be among the first 25 applicants,"['', '10 Company Holidays', 'Bachelors, Masters, or PhD in Computer Science or related field', 'Conducts research using multiple data sources, evaluates collection, performs analysis and disseminates findings to customersFollow relevant trends surrounding practices involving cyber security analysisDrive, in partnership with Product Management, productionizing relevant security outcomes that are developed through research and analysis of emerging security threatsCommunicate key cyber security concepts and findings with deewatch leadership, operations, and customersInteract daily with the deepwatch Threat Operations team in support of ongoing threat intelligence analysis and collection plansApply expertise on threat actors, attack trends, and attack tactics, techniques, and procedures (TTPs)Collect and analyze information from various sources, including open source reports, information sharing partners, and cyber security vendorsSupport threat hunting by providing in-depth analysis of noteworthy incidents and brief leadership on findings through threat reports, blog posts, and white papers', 'A “purple team” mindset that takes into account the motivation of attackers and those defending enterprise systems and data', 'Experience in Security Operations environments with disparate technology stacks and data sets ', '401k retirement plan with employer match', 'Apply expertise on threat actors, attack trends, and attack tactics, techniques, and procedures (TTPs)', 'Deep technical expertise in all relevant areas including computer architecture, cloud services, network and application stack, and operating systems', 'Published research that is customer outcome focused (research is fun but we’re here for our customers)', 'Experience with Digital Forensics and Incident Response, including active response and reporting on breaches and intrusions by advanced threat actors', 'A highly collaborative environment with very bright minds and inquisitive thinking', 'Security Researcher', 'Company paid Life Insurance, Short Term Disability and Long Term Disability', 'Attractive referral bonus program', 'Significant annual allowance per employee for Professional Development', 'Responsibilities', 'Cybersecurity expertise with data sets, big data and data science', 'Metrics driven, data driven, and results oriented ', 'Description', 'Career paths and the opportunity to do cool and different things as our growth continues', 'deepwatch is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability status, marital status, sexual orientation, gender identity, genetic information, protected veteran status, or any other characteristic protected by law. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.', 'A highly collaborative environment with very bright minds and inquisitive thinkingAwesome benefits - we pay a significant portion of our employees’ medical and dental premiums (100% for the HDHP plan) and a very generous portion for dependentsFSA (medical and dependent) and HSA with employer contributionCompany paid Life Insurance, Short Term Disability and Long Term Disability401k retirement plan with employer matchPaid Time Off (PTO)10 Company HolidaysPaid time off for votingAs a fully remote company, we offer the responsible balancing of your time between work & lifeAll employees are paid a generous mobile phone and home internet allowanceApple productsAttractive referral bonus programCareer paths and the opportunity to do cool and different things as our growth continuesSignificant annual allowance per employee for Professional Development', 'Conducts research using multiple data sources, evaluates collection, performs analysis and disseminates findings to customers', 'Previous experience with Security Research and published code and findings in the security community', 'Required Experience, Skills and Knowledge', 'Paid Time Off (PTO)', 'Ability to present in to customers and leadership, translating deep technical into general understanding', 'Awesome benefits - we pay a significant portion of our employees’ medical and dental premiums (100% for the HDHP plan) and a very generous portion for dependents', 'deepwatch Offers', 'As a fully remote company, we offer the responsible balancing of your time between work & life', 'Drive, in partnership with Product Management, productionizing relevant security outcomes that are developed through research and analysis of emerging security threats', 'Support threat hunting by providing in-depth analysis of noteworthy incidents and brief leadership on findings through threat reports, blog posts, and white papers', 'Ability to conduct independent research on pressing cyber security issues', 'Requirements', 'FSA (medical and dependent) and HSA with employer contribution', 'Follow relevant trends surrounding practices involving cyber security analysis', 'Previous experience with Security Research and published code and findings in the security communityDeep technical expertise in all relevant areas including computer architecture, cloud services, network and application stack, and operating systemsWriting and analyzing code (Python, JavaScript, Go, etc)A “purple team” mindset that takes into account the motivation of attackers and those defending enterprise systems and dataPublished research that is customer outcome focused (research is fun but we’re here for our customers)Ability to present in to customers and leadership, translating deep technical into general understandingMetrics driven, data driven, and results oriented Cybersecurity expertise with data sets, big data and data scienceAbility to conduct independent research on pressing cyber security issuesExpansive knowledge in understanding and analyzing threat actor capabilities and methodologiesPreferred Experience, Skills and KnowledgeBachelors, Masters, or PhD in Computer Science or related fieldExperience with Digital Forensics and Incident Response, including active response and reporting on breaches and intrusions by advanced threat actorsExperience in Security Operations environments with disparate technology stacks and data sets ', 'Who We Are', 'Interact daily with the deepwatch Threat Operations team in support of ongoing threat intelligence analysis and collection plans', 'Equal Opportunity Employer', 'Apple products', 'Writing and analyzing code (Python, JavaScript, Go, etc)', 'Communicate key cyber security concepts and findings with deewatch leadership, operations, and customers', 'Expansive knowledge in understanding and analyzing threat actor capabilities and methodologies', 'Paid time off for voting', 'Preferred Experience, Skills and Knowledge', 'Collect and analyze information from various sources, including open source reports, information sharing partners, and cyber security vendors', 'All employees are paid a generous mobile phone and home internet allowance']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Tata Consultancy Services,"Georgia, NJ",20 hours ago,Be among the first 25 applicants,"['', ' Solid and professional communications skills, both verbal and written', ' Deep understanding of both relational and non-relational databases', ' Experience in designing and delivering complex pipelines and API development (preferably ETL logic) in Python', ' Experience in a Unix/Linux environment', ' Strong knowledge of Software Development Lifecycle (SDLC).', ' Operate in an enterprise-class Agile product development environment by demonstrating comfort with process and tools including IDE’s, compilers, debuggers, profilers, version control systems, code coverage tools, automated testing tools, and usability', ' Experience in SQL programming, hands on with Database like Google Cloud Big query', ' High energy, self-motivation, attention to detail, creativity, flexibility, and ability to work under pressure.', ' Job scheduling experience using Maestro/Jenkins is required', ' Working knowledge of source-code control using GitHub is required.', ' Flexibility to work additional hours on an as needed basis to meet deadlines and with onsite/offshore team.', ' Ability to work independently and multi-task to meet critical deadlines in a rapidly changing environment', ' Hands-on, self-directed design and development of highly-scalable, reliable, and performant pipelines to consume, integrate and analyze large volumes of complex data using a variety of best-in-class proprietary and open-source platforms and tools', ' Deliver high performance code into production cloud applications in a team environment', ' Unix familiarity and shell scripting experience']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer III,Apex Systems,"Menlo Park, CA",3 hours ago,Be among the first 25 applicants,"['', 'Skills', 'Location: Menlo Park, CA', 'Position: Data Engineer III ', 'Length: 6 Month Contract ']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Applied Researcher,eBay,"San Jose, CA",1 day ago,Be among the first 25 applicants,"['', '- Experience with Python or R, and Java or Scala.\xa0', 'We are looking for stellar applied researchers to join us and build the next generation of content understanding technologies in eBay search. If you enjoy the scale and technical complexity of NLP problems and want to be at the frontier of applied research in information retrieval in e-commerce, join now.', 'Basic Qualifications', '- Work through others as a technical leader to drive vision, define and standardize methodologies, establish processes, and operationalize machine learning solutions across teams and projects', 'eBay Inc. is an equal opportunity employer.\xa0 All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status.\xa0 If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com.\xa0 We will make every effort to respond to your request for disability assistance as soon as possible.', 'View our accessibility info', 'accessibility info', '- Experience in big data processing, e.g. Hadoop, SQL, Spark', '- Strong Industrial experience with one or more of the following: classification, regression, recommendation systems, targeting systems, ranking systems, fraud detection, online advertising, or related', '- Seek scientific solutions to multiple complex and ambiguous problems by crafting a technical vision and driving consensus across teams', 'This website uses cookies to enhance your experience. By continuing to browse the site, you agree to our\xa0use of cookies', '- Present key technical and novel research work in public forums and conferences', 'For more information see:', '- 2 or more related publications in quality conferences or journals', 'Looking to make an impact on the future of global commerce? Do you want to shape how millions of people buy, sell, and engage around the world?', '- Think through complex research problems, simplify where necessary, invent when needed, to drive a principled vision from thought to reality', '- Mentor junior team members', 'EEO is the Law Poster', 'Job Responsibilities', 'View our privacy policy', 'The Search Content, Item and Inventory Understanding team is part of the biggest organization that drives eBay’s world-wide impact. We innovate at the heart of ecommerce search, with the ambitious goal of redefining ecommerce search. We craft optimized experiences for buyers and sellers on eBay. We innovate rapidly in this space and there is no shortage of new challenges for motivated individuals.', '- 5-8 years (with PhD) or 8-12 years (with MS) of industrial experience in a related field', 'EEO is the Law Poster Supplement', '- MS or PhD in Computer Science, Statistics, Mathematics, or equivalent']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Senior HFT Researcher,Selby Jennings,"New York, NY",1 day ago,132 applicants,"['Tried and tested research approach ', 'Develop alpha research agenda for team members and spearhead strategy simulations PnL driven research through signal generation, exploring applications of machine learning and generating research ideas Developing production level code in C++ and Python ', '3+ years working on high frequency trading strategies Master’s or PhD in a quantitative field (Math, Physics, EE, Computer Science, Statistics, ect.) Tried and tested research approach A true technologist at heart and strong coding skills in C++ and/or Python', 'PnL driven research through signal generation, exploring applications of machine learning and generating research ideas ', '3+ years working on high frequency trading strategies ', 'A true technologist at heart and strong coding skills in C++ and/or Python', 'Developing production level code in C++ and Python ', 'Senior HFT Quantitative Researcher ', 'Master’s or PhD in a quantitative field (Math, Physics, EE, Computer Science, Statistics, ect.) ', 'Senior HFT Quantitative Researcher', 'Develop alpha research agenda for team members and spearhead strategy simulations ', 'Responsibilities: ', '\xa0 ', 'A boutique multi-manager fund in New York is looking to bring a Senior Quantitative Researcher with High Frequency Trading experience into the fund.  The greenfield initiative has received substantial backing from the fund and will allow you to engage in heavy PnL driven projects through cutting edge proprietary technology and in-depth research.  You will work alongside the head of the group, working on end to end strategy development and establishing the research agenda for junior members of the team.  This will offer you complete oversight of data sourcing, alpha signal generation/construction, strategy development and backtesting. ', 'Requirements: ']",Mid-Senior level,Full-time,Research,Financial Services,2020-11-05 11:32:32
Contract - Data Engineer - Python and Spark,CyberCoders,"San Francisco, CA",22 hours ago,Be among the first 25 applicants,"['', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Supportive Team and Management', ' Fun and Exciting Projects! Supportive Management! Great Pay!', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : TR4-1609653 -- in the email subject line for your application to be considered.***', 'Your Right to Work', 'Nice To Haves', ' Supportive Management!', ' Python and Spark Creating and maintaining data ingestion pipelines', 'Email Your Resume In Word To', ' Great Pay!', ' Competitive Pay', ' AWS Big Data technologies like Glue, S3, and RedShift', ' Flexibility', ' Python and Spark', ' Fun and Exciting Projects!', ' Creating and maintaining data ingestion pipelines', ' Competitive Pay Supportive Team and Management Flexibility']",Mid-Senior level,Full-time,Information Technology,Management Consulting,2020-11-05 11:32:32
"Machine Learning Engineer, 3+ Years Experience - Seattle",Snap Inc.,"Seattle, WA",5 hours ago,53 applicants,"['', ' Experience in solving open ambiguous problems from end to end ', ' Experience working with machine learning, ranking infrastructures, and system designs ', ' Strong understanding of machine learning approaches and algorithms  Ability to prioritize tasks and work independently  Excellent verbal and written communication skills, with high attention to detail  Experience collaborating with internal and external stakeholders at all levels of a company  Experience in solving open ambiguous problems from end to end  Possesses a desire to learn and help others ', ' 3+ years ML industry experience or 2+ years ML industry experience and MS and/or PhD in computer science or related field ', ' Create models which help drive value for users, advertisers, and our company ', ' Ability to proactively learn new concepts and apply them at work ', 'Minimum Qualifications', 'Preferred Qualifications', ' Experience with mobile apps and/or databases ', 'What You’ll Do', ' Create models which help drive value for users, advertisers, and our company  Evaluate the technical tradeoffs of every decision  Perform code reviews and ensure exceptional code quality  Build robust, lasting, and scalable products  Iterate quickly without compromising quality ', ' Excellent verbal and written communication skills, with high attention to detail ', ' Iterate quickly without compromising quality ', ' accommodations-ext@snap.com ', 'Knowledge, Skills & Abilities', 'Snapchat', ' Experience working with machine learning frameworks such as TensorFlow, Caffe2, PyTorch, Spark ML, scikit-learn, or related frameworks ', ' Perform code reviews and ensure exceptional code quality ', ' Ability to prioritize tasks and work independently ', 'Snap Engineering', ' Experience working with distributed systems ', ' Experience working with machine learning frameworks such as TensorFlow, Caffe2, PyTorch, Spark ML, scikit-learn, or related frameworks  Experience with mobile apps and/or databases  Experience working with distributed systems  M.S. degree and/or PhD in computer science or related field  Experience working with machine learning, ranking infrastructures, and system designs  Ability to proactively learn new concepts and apply them at work ', ' Strong understanding of machine learning approaches and algorithms ', ' Possesses a desire to learn and help others ', ' Evaluate the technical tradeoffs of every decision ', ' M.S. degree and/or PhD in computer science or related field ', ' our values', 'Our Benefits', ' Experience collaborating with internal and external stakeholders at all levels of a company ', ' BS/BA degree in technical field such as Computer Science, Mathematics, Statistics or equivalent years of experience ', ' BS/BA degree in technical field such as Computer Science, Mathematics, Statistics or equivalent years of experience  3+ years ML industry experience or 2+ years ML industry experience and MS and/or PhD in computer science or related field ', ' Build robust, lasting, and scalable products ']",Associate,Full-time,Engineering,Marketing and Advertising,2020-11-05 11:32:32
"Lead Machine Learning Engineer, Comment",TikTok,"Mountain View, CA",19 hours ago,Be among the first 25 applicants,"['', '• Great communication and teamwork skills;', '• Experience in at least one of the following areas: NLP, machine learning, and data mining;', ""In TikTok's Comment team, you’ll have the opportunity to build a modern machine learning system on our large-scale data. Our team is responsible for comment systems, content safety, and comment ranking to provide the best comment user experience for all TikTok users."", ""TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We believe individuals shouldn't be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are passionate about this and hope you are too."", 'Preferred:', '• Guide and mentor team members to reach their full potential.', '• Work with cross-functional teams to deliver improvements;', '• Track record of leveraging Machine Learning techniques to impact key company metrics;', '• Bachelor or above degree in computer science or a related technical discipline;', '• Drive all phases of comment related work, including comment system implementation, algorithm development, ML model development and iterations, model applications, and serving;', 'Qualifications', '• In-depth knowledge of natural language processing, deep neural networks, classification techniques, and embedding methods;', '• Leadership experience is a plus.', ""What You'll Do"", 'TikTok is committed to providing reasonable accommodations during our recruitment process. If you need assistance or an accommodation, please reach out to us at usrc@tiktok.com.', '• Passion about techniques and solving challenging problems.', '• Experience with 3+ years’ experience as a machine learning engineer;', 'TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo.', '• Experience working in the multi-language products;', '• Lead the comment projects to meet our safety goals and improve our user experience;']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Data Platform Engineer - Scientific Working Environment,Stitch Fix,"San Francisco, CA",18 hours ago,Be among the first 25 applicants,"['you have the ability to understand requirements in context to design solutions, rather than take them at face value.', 'We believe in autonomy & taking initiative', 'you will envision, design, build, and support services and tools for data scientists where ""self service"" is the goal.you enjoy building systems using a mix of Python and Go in an AWS-heavy environment.you will learn our scientific working environment holistically in order to design better tools.you take pride in communicating, documenting, supporting, and otherwise understanding scientists when needs arise and the world changes.', 'We have a smart, experienced leadership team that wants to do it right & is open to new ideas', 'We take what we do seriously. We don’t take ourselves seriously', 'We’re Excited About You Because…', 'At Stitch Fix, we’re about personal styling for everybody and we believe in both a service and a workplace where you can be your best, most authentic self. We’re the first fashion retailer to combine technology and data science with the human instinct of a Stylist to deliver a deeply personalized shopping experience. This novel juxtaposition attracts a highly diverse group of talented people who are both thinkers and doers. All of this results in a simple, powerful offering to our customers and a successful, growing business serving millions of men, women, and kids. We believe we are only scratching the surface on our opportunity, and we’re looking for incredible people like you to help us carry on that trend.', 'you have a ""bias to action"" and are not easily blocked by problems and difficulties. You naturally take ownership of projects and efforts.you have a diversity of software development experience rather than a single tool suite or paradigm. Experience and experience working in a data science environment is a plus.you have the ability to understand requirements in context to design solutions, rather than take them at face value.you are a good communicator and you enjoy working in a collaborative environment.you have experience working with AWS resources (familiarity with ECS and Docker is a plus)', 'you are a good communicator and you enjoy working in a collaborative environment.', 'you have experience working with AWS resources (familiarity with ECS and Docker is a plus)', 'We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same!', 'We are committed to our clients and connected through our vision of “Transforming the way people find what they love”', 'you will learn our scientific working environment holistically in order to design better tools.', 'We are a group of bright, kind and goal oriented people. You can be your authentic self here, and are empowered to encourage others to do the same!We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generationWe are a technologically and data-driven businessWe are committed to our clients and connected through our vision of “Transforming the way people find what they love”We love solving problems, thinking creatively and trying new thingsWe believe in autonomy & taking initiativeWe are challenged, developed and have meaningful impactWe take what we do seriously. We don’t take ourselves seriouslyWe have a smart, experienced leadership team that wants to do it right & is open to new ideasWe offer competitive compensation packages and comprehensive health benefitsYou will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day', 'We are currently starting the design of a “next generation” working environment, in which we are re-thinking and “re-platforming” most of our tools and services. We are looking for folks to help us form the vision and build this new world.', 'you enjoy building systems using a mix of Python and Go in an AWS-heavy environment.', 'We offer competitive compensation packages and comprehensive health benefits', 'About Stitch Fix', 'The Scientific Working Environment team is responsible for curating, designing, building, and supporting the day-to-day operating environment for our data scientists. We figure out what is needed and then carefully create tools and services and the best practices for using them. We believe that everything a scientist uses should be expertly crafted, with each feature having a deliberate purpose. This role is for an engineer who is excited about understanding scientists\' needs and can translate these needs into a vision of what should be built. This engineer should enjoy being ""full stack"" in the sense that they own a product from beginning to end by designing, constructing, integrating, testing, documenting, and supporting their creations.', ""Why you'll love working at Stitch Fix..."", ""Please Review Stitch Fix's Recruiting Privacy Policy Here"", 'We love solving problems, thinking creatively and trying new things', 'You will be proud to say that you work for Stitch Fix and will know that the work you do brings joy to our clients every day', 'We are challenged, developed and have meaningful impact', 'About The Team & Role', 'you will envision, design, build, and support services and tools for data scientists where ""self service"" is the goal.', 'you take pride in communicating, documenting, supporting, and otherwise understanding scientists when needs arise and the world changes.', 'you have a ""bias to action"" and are not easily blocked by problems and difficulties. You naturally take ownership of projects and efforts.', 'https://www.stitchfix.com/privacy/usrecruitingprivacy', 'We are a successful, fast-growing company at the forefront of tech and fashion, redefining retail for the next generation', 'you have a diversity of software development experience rather than a single tool suite or paradigm. Experience and experience working in a data science environment is a plus.', ""You're Excited About This Opportunity Because…"", 'We are a technologically and data-driven business']",Mid-Senior level,Full-time,Information Technology,Apparel & Fashion,2020-11-05 11:32:32
Principal Data Scientist-Prime Contract,ClearedJobs.Net,"Reston, VA",3 hours ago,Be among the first 25 applicants,"['', 'Red Arch Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, national origin, age, marital status, disability, or protected veteran status. Red Arch Solutions takes affirmative action in support of its policy to advance in employment individuals who are minorities, women, protected veterans and individuals with disabilities.', 'Qualifications', 'Experience working with users to help define their database use, data analytics, and the data user experience. ', 'Bachelors Degree + 8 years or Master Degree + 6 years of experienceExperience working with users to help define their database use, data analytics, and the data user experience. ', 'The CDF Data Warehouse will help the warfighter make informed decisions by supporting advanced AI/ML on all available data resources to provide advanced analytics capabilities.', 'TS/SCI with Poly is required for this position**Red Arch Solutions is a proven and effective small business integrator and consultant, recognized as a leading provider of IT development to the Federal Government. We offer excellent benefits, including 20 days PTO, 10 holidays, up to 10% 401k contribution, and reimbursement for tuition/certifications. Top of the line PPO Medical, Dental, Vision, and Short and Long-Term disability are also offered.Red Arch Solutions is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, color, religion, sex, sexual orientation, national origin, age, marital status, disability, or protected veteran status. Red Arch Solutions takes affirmative action in support of its policy to advance in employment individuals who are minorities, women, protected veterans and individuals with disabilities.', 'Bachelors Degree + 8 years or Master Degree + 6 years of experience']",Entry level,Contract,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Data Scientist Lead, Adobe Spark & CC Education",Adobe,"San Francisco, CA",6 hours ago,Be among the first 25 applicants,"['', 'Our Team ', 'Degree in a quantitative field like statistics, economics, applied math, operations research or engineering (advanced degrees are preferred) or equivalent practical experience6+ years of hands-on technical experience in a data science roleExperience exploring large amounts of information, extracting insights, and achieving real-world resultsAbility to dig-in, understand the data, and to use creative thinking and problem-solving skills are mustsHistory of deriving and communicating insights from data analyses to product and/or business leaders', 'Degree in a quantitative field like statistics, economics, applied math, operations research or engineering (advanced degrees are preferred) or equivalent practical experience', 'Prioritize and lead deep dives into Adobe Spark data to uncover new product and business opportunities, including a machine learning strategy and roadmap', 'Design, implement, and analyze A/B experiments to provide reports and impactful insights', 'Inspire the data science and product teams around experimentation and product insights', 'Ability to dig-in, understand the data, and to use creative thinking and problem-solving skills are musts', '6+ years of hands-on technical experience in a data science role', 'Prioritize and lead deep dives into Adobe Spark data to uncover new product and business opportunities, including a machine learning strategy and roadmapBuild and lead a high-performing team of data scientistsPartner with the product development teams and leadership to develop business strategy and product roadmaps based on analytical insightsDesign, implement, and analyze A/B experiments to provide reports and impactful insightsInspire the data science and product teams around experimentation and product insightsWork directly with the development teams on product instrumentation, product flow and data capture', 'History of deriving and communicating insights from data analyses to product and/or business leaders', 'Build and lead a high-performing team of data scientists', 'Our Company', 'Experience exploring large amounts of information, extracting insights, and achieving real-world results', 'Work directly with the development teams on product instrumentation, product flow and data capture', 'Partner with the product development teams and leadership to develop business strategy and product roadmaps based on analytical insights', 'What You Need To Succeed']",Mid-Senior level,Full-time,Other,Marketing and Advertising,2020-11-05 11:32:32
Tobacco Senior Researcher,Fors Marsh Group,"Arlington, VA",8 hours ago,Be among the first 25 applicants,"['', 'Oversee and guide preparation of research reports and presentation decks and other external communications summarizing research methods, findings and strategic implications for marketing strategies and advertising messaging.', 'Contribute subject matter expertise and thought leadership on tobacco prevention and cessation as well as campaign development and evaluationContribute to the planning, coordination, design, execution, and interpretation of social-psychological, social persuasion and/or behavior change studies across a variety of quantitative and qualitative methodologies.Oversee and guide preparation of research reports and presentation decks and other external communications summarizing research methods, findings and strategic implications for marketing strategies and advertising messaging.Oversee and guide the conduct of interviews, focus group discussions, and other methods to collect qualitative data.Oversee and guide the conduct of univariate and multivariate analyses; analyze and interpret results from descriptive and inferential quantitative analyses.Oversee and guide the analysis and interpretation of results from qualitative research studies (e.g., thematic analysis, NVIVO.)Interact with project team, including the FMG Research Director, FMG Research Advisors, Senior leadership and advertising agency/client teams on a day-to-day basis working under tight deadlines to fulfill requests.Lead and direct client and partner engagement, project meetings and presentations.Oversee and guide preparation of written proposals for research in response to RFPs.Lead, coach, and mentor junior- to mid-level researchers. ', 'Lead, coach, and mentor junior- to mid-level researchers. ', 'Minimum of twelve years of professional research experience required with at least three years of experience in a senior project role, preferably in a consulting organization.', 'Communications-related research and/or experience working with advertising agencies or marketing firms preferred', 'Oversee and guide the conduct of univariate and multivariate analyses; analyze and interpret results from descriptive and inferential quantitative analyses.', 'Proven publication record and thought leadership on tobacco prevention and cessation', 'Contribute subject matter expertise and thought leadership on tobacco prevention and cessation as well as campaign development and evaluation', 'Contribute to the planning, coordination, design, execution, and interpretation of social-psychological, social persuasion and/or behavior change studies across a variety of quantitative and qualitative methodologies.', 'Lead and direct client and partner engagement, project meetings and presentations.', 'A highly collegial and intellectually stimulating work environment', 'Oversee and guide preparation of written proposals for research in response to RFPs.', 'Demonstration of strong verbal and written communications skills and ability to produce high-quality, accurate deliverables and presentations.', 'High degree of team orientation, as well as ability to work independently under minimal supervision to effectively balance and manage personal workload.', 'Demonstrated experience managing complex client and/or stakeholder relationships and maintaining high satisfaction.', 'Highly competitive benefit/compensation package', 'Master’s degree in communication, marketing, social science, or related field. PhD preferred but not required.', 'Significant growth opportunities', 'Experience working with FDA, NCI, CDC, or other government entities on tobacco social science research strongly preferred', 'Experience with qualitative study design, data collection and analysis; experience with qualitative software (e.g., NVIVO) preferred. Formal moderation training (e.g., RIVA) a plus. ', 'Experience balancing multiple concurrent projects including management of project timelines, budget and scope in fast-paced environments working on tight deadlines.', 'Significant growth opportunitiesA highly collegial and intellectually stimulating work environmentOpportunities to participate in high quality research and influence decision making among government leadersHighly competitive benefit/compensation package', 'Experience successfully managing project budget and resources is required; doing so in time and materials contracts preferred.', 'Oversee and guide the analysis and interpretation of results from qualitative research studies (e.g., thematic analysis, NVIVO.)', 'Interact with project team, including the FMG Research Director, FMG Research Advisors, Senior leadership and advertising agency/client teams on a day-to-day basis working under tight deadlines to fulfill requests.', 'Applicants may be subject to a low-level government security investigation and must meet eligibility criteria for access to sensitive information.', 'Oversee and guide the conduct of interviews, focus group discussions, and other methods to collect qualitative data.', 'Quantitative proficiency and experience working with data in Microsoft Excel® and at least one statistical analysis software package (e.g., SPSS, STATA, SAS, R). Experience writing code/syntax preferred', 'Opportunities to participate in high quality research and influence decision making among government leaders', 'Master’s degree in communication, marketing, social science, or related field. PhD preferred but not required.Experience working with FDA, NCI, CDC, or other government entities on tobacco social science research strongly preferredMinimum of twelve years of professional research experience required with at least three years of experience in a senior project role, preferably in a consulting organization.Proven publication record and thought leadership on tobacco prevention and cessationQuantitative proficiency and experience working with data in Microsoft Excel® and at least one statistical analysis software package (e.g., SPSS, STATA, SAS, R). Experience writing code/syntax preferredExperience with qualitative study design, data collection and analysis; experience with qualitative software (e.g., NVIVO) preferred. Formal moderation training (e.g., RIVA) a plus. Communications-related research and/or experience working with advertising agencies or marketing firms preferredExperience balancing multiple concurrent projects including management of project timelines, budget and scope in fast-paced environments working on tight deadlines.Experience successfully managing project budget and resources is required; doing so in time and materials contracts preferred.High degree of team orientation, as well as ability to work independently under minimal supervision to effectively balance and manage personal workload.Demonstrated experience managing complex client and/or stakeholder relationships and maintaining high satisfaction.Demonstration of strong verbal and written communications skills and ability to produce high-quality, accurate deliverables and presentations.Applicants may be subject to a low-level government security investigation and must meet eligibility criteria for access to sensitive information.']",Associate,Full-time,Research,Marketing and Advertising,2020-11-05 11:32:32
Azure Data Engineer,Brooksource,Greater Chicago Area,22 hours ago,Be among the first 25 applicants,"['', 'Netezza experience ', 'Version Control (Git or equivalent) ', 'Working with existing Databricks Notebooks to optimize or address performance concerns ', 'Willingness to learn existing on-premise data management tools as required, such as Ab Initio ', '5 years data engineering experience ', 'Ab Initio experience', 'Skills Needed', 'Experience in regularly dealing with data in hundreds of Terabytes up to 1-2 Petabytes ', 'Responsibilities', 'Responsibilities ', 'Data Warehousing / Big Data Best Practices Understanding of how best to partition and organize data depending on the technology and use case Experience in regularly dealing with data in hundreds of Terabytes up to 1-2 Petabytes 5 years data engineering experience 2 years cloud platform experience Version Control (Git or equivalent) Data Integration Tools (Spark/Databricks or equivalent) Scripting (Linux/Unix Shell scripting or equivalent) Netezza experience Ab Initio experience', 'As the Data Engineer you will be responsible for creating and maintaining data pipelines between on-premise data center, Azure Data Lake Storage, and Azure Synapse database using Databricks and Apache Spark/Scala.\xa0 You will\xa0join a team responsible for managing a growing cloud-based data ecosystem consisting of a metadata driven data lake and databases that support real time analytics, extracts, and reporting.\xa0 This candidate needs to have a strong background in data engineering and should have a few years of experience on a major cloud platform such as Azure. ', 'Create new Databricks Notebooks or stand-alone Apache Spark/Scala code as needed ', '2 years cloud platform experience ', 'Working with existing Databricks Delta Lake tables to optimize for CDC performance using techniques ', 'Skills Needed ', 'Building and maintaining a data processing framework on Azure using Databricks Writing code in Apache Spark/Scala Working with existing Databricks Delta Lake tables to optimize for CDC performance using techniques Working with existing Databricks Notebooks to optimize or address performance concerns Create new Databricks Notebooks or stand-alone Apache Spark/Scala code as needed Willingness to learn existing on-premise data management tools as required, such as Ab Initio ', 'Data Warehousing / Big Data Best Practices ', 'Data Integration Tools (Spark/Databricks or equivalent) ', ' ', 'Building and maintaining a data processing framework on Azure using Databricks ', 'Understanding of how best to partition and organize data depending on the technology and use case ', 'Writing code in Apache Spark/Scala ', 'Scripting (Linux/Unix Shell scripting or equivalent) ']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Lafayette, LA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Quantitative UX Researcher,Creative Circle,"San Jose, CA",5 hours ago,Be among the first 25 applicants,"['', '2 years of experience in industry UXRA quantitative researchFluency in SQL. Mastery of R or PythonBS/BA degree in Computer Science, Human-Computer Interaction, Psychology, Statistics or a related field (MS preferred)Expertise in multivariate statistics and the design of experiments.', 'Fluency in SQL. Mastery of R or Python', 'Ideal Qualifications', 'Examine existing data and product designs to generate hypotheses and plans for high-impact research.', '2 years of experience in industry UXRA quantitative research', 'Support existing research initiatives, prioritize and drive research to quantify and improve the advertiser user experience.Support product development and design and provide confidence in decision making through thorough quantitative insightsDefine and measure quantitative UX goals and metrics in collaboration with Designers,Qualitative Researchers, Engineers and Program Managers.Examine existing data and product designs to generate hypotheses and plans for high-impact research.Develop code and statistical models to understand user experience.', 'Develop code and statistical models to understand user experience.', 'BS/BA degree in Computer Science, Human-Computer Interaction, Psychology, Statistics or a related field (MS preferred)', 'Expertise in multivariate statistics and the design of experiments.', 'Top Responsibilities', 'Support product development and design and provide confidence in decision making through thorough quantitative insights', 'Define and measure quantitative UX goals and metrics in collaboration with Designers,Qualitative Researchers, Engineers and Program Managers.', 'Support existing research initiatives, prioritize and drive research to quantify and improve the advertiser user experience.']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Remote Sr. Data Engineer (Python/GCP),Cypress HCM,"Austin, TX",23 hours ago,Be among the first 25 applicants,"['', 'Knowledge of Git, Jinja2, Docker(containerization), Bitbucket, and Bamboo ', 'Responsibilities:', 'Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud ', 'Preferred: ', 'Required', '*Must be able to work EST hours*', 'Requirements:', 'Google Cloud Certified - Professional Data Engineer certification would be a plus ', 'Strong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow or Google Composer) ', 'Strong communication & interpersonal skills ', 'Preferred:', 'Perform data integration related work for the company which includes Ad stack Tech integration, BI continuity and other data integration required for running our business Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery Develop and promote best practices in data engineering Develop real-time data processing applications using Google Cloud Be part of the on-call rotation supporting our SLA’s Participate in design and code reviews ', 'Develop real-time data processing applications using Google Cloud ', '5+ years of hands-on experience working in data engineering environment ', 'Advanced SQL programming skills - Ability to write complex SQL to perform common types of analysis and aggregations ', 'Familiar with version control systems (Git and Bitbucket) ', 'Requirements: ', 'Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery ', 'Familiar with Atlassian products Jira and Confluence ', 'Can-do attitude on problem-solving, quality and ability to execute ', 'Google Cloud Certified - Professional Data Engineer certification would be a plus Knowledge of Git, Jinja2, Docker(containerization), Bitbucket, and Bamboo Familiar with a NoSQL database such as MongoDB Familiar with version control systems (Git and Bitbucket) Familiar with Atlassian products Jira and Confluence Hands-on experience with Apache Airflow or Google Composer Knowledge of Application Programming Interfaces ', 'Required: ', ""Bachelor's degree in Computer Science or equivalent experience in a related field "", 'Be part of the on-call rotation supporting our SLA’s ', 'Develop and promote best practices in data engineering ', 'The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting. This engineer’s duty is to monitor the existing metrics, analyze data, and lead partnerships with other Data and Analytics teams in an effort to identify and implement systems and process improvements. This engineer also designs, architects, implements, and supports key datasets. ', 'Experience with Apache Airflow or Google Composer ', 'Perform data integration related work for the company which includes Ad stack Tech integration, BI continuity and other data integration required for running our business ', 'Strong proficiency in Python with an emphasis in building data pipelines ', 'Knowledge of Application Programming Interfaces ', 'Experience developing data solutions on GCP (airflow experience) ', 'Familiar with a NoSQL database such as MongoDB ', 'Hands-on experience with Apache Airflow or Google Composer ', ""Bachelor's degree in Computer Science or equivalent experience in a related field 5+ years of hands-on experience working in data engineering environment Strong proficiency in Python with an emphasis in building data pipelines Advanced SQL programming skills - Ability to write complex SQL to perform common types of analysis and aggregations Experience developing data solutions on GCP (airflow experience) Experience with Apache Airflow or Google Composer Can-do attitude on problem-solving, quality and ability to execute Strong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow or Google Composer) Strong communication & interpersonal skills "", 'Responsibilities: ', '\xa0 ', 'Participate in design and code reviews ']",Mid-Senior level,Contract,Engineering,Computer Software,2020-11-05 11:32:32
Senior Designer/Researcher (Remote Work Available),USAA,"Austin, TX",22 hours ago,Be among the first 25 applicants,"['', 'Preferred Requirements', 'not', 'Real Estate or Fintech domain knowledge and understanding of sales funnel and conversion optimization', 'Relocation', 'Excellent written and verbal communication skills, interpersonal skills, time management skills and strong attention to detail.', ""Identifies and manages existing and emerging risks that stem from business activities and the job role.Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.Follows written risk and compliance policies and procedures for business activities.Supports design team in defining business problems, design requirements, and demonstrate a solution's potential success for moderately complex projects.Co-facilitates a cross-functional understanding of business problems and potential design solutions using human-centered design sessions and group discussions to achieve actionable outcomes.Navigates multiple workstreams from discovery to implementation, balancing efforts, priorities, and partnerships for each.Guides the development and facilitation of human-centered research efforts, the synthesis of research findings and the generation of insights.Works autonomously to create holistic member experiences leveraging extensive knowledge of interaction design, visual design, and/or content design.Articulates ideas and solutions using a range of storytelling techniques to inspire and compel audiences to align on direction.Mentors developing designers across the Chief Design Office. Provides constructive day-to-day feedback and guidance to team members.Applies advanced understanding of human-centered and service design practices and leverages multiple methods to solve complex design problems.Stays abreast of current digital and mobile technology trends, in the area of application architecture with best practices within the digital development ecosystem"", 'Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.', 'Articulates ideas and solutions using a range of storytelling techniques to inspire and compel audiences to align on direction.', 'Demonstrated experience designing user interfaces for web and mobile applications (iOS, Android, etc.)', 'Guides the development and facilitation of human-centered research efforts, the synthesis of research findings and the generation of insights.', 'Highly organized, with the ability to work on multiple projects/task at once while managing a diverse group of employees.', 'Works autonomously to create holistic member experiences leveraging extensive knowledge of interaction design, visual design, and/or content design.', 'Follows written risk and compliance policies and procedures for business activities.', 'A portfolio that demonstrates extensive experience designing digital experiences for mobile and web-based applications.', 'Bachelor’s Degree or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree (10+ years of experience in lieu of degree).6 years of relevant, on-the-job experience in a Product Design, UX Design, Service Design or Design Research role delivering complex design systems for web and native applications.Highly organized, with the ability to work on multiple projects/task at once while managing a diverse group of employees.Extensive experience designing and supporting digital products inside an Agile environment using human-centered design principles, methods and problem-solving strategies.A portfolio that demonstrates extensive experience designing digital experiences for mobile and web-based applications.Demonstrated ability to work fluently in standard applications, including Sketch, InVision (or comparable prototyping tools), Adobe CC and Microsoft Office Suite.Advanced facilitation, collaboration and consensus-building skills, with extensive experience in presenting to cross-functional terms and Senior/Executive leaders.Excellent written and verbal communication skills, interpersonal skills, time management skills and strong attention to detail.Demonstrated advanced understanding of new technologies and best practices in website navigation, browsers, mobile patterns, information architecture and usability.Demonstrated experience designing user interfaces for web and mobile applications (iOS, Android, etc.)Demonstrates a strategic mindset by decomposing complex problems into a clear and achievable workstream requiring limited support and direction for decision making.', 'Extensive experience designing and supporting digital products inside an Agile environment using human-centered design principles, methods and problem-solving strategies.', 'Advanced facilitation, collaboration and consensus-building skills, with extensive experience in presenting to cross-functional terms and Senior/Executive leaders.', 'Demonstrated experience using behavioral and/or transactional data to help prioritize design efforts.', 'Mentors developing designers across the Chief Design Office. Provides constructive day-to-day feedback and guidance to team members.', '6 years of relevant, on-the-job experience in a Product Design, UX Design, Service Design or Design Research role delivering complex design systems for web and native applications.', 'Working knowledge of Accessibility principles and guidelines; experience creating inclusive designs.', ""Supports design team in defining business problems, design requirements, and demonstrate a solution's potential success for moderately complex projects."", 'BOUT USAA', 'About Usaa’s Chief Design Office', 'Experience working with internal design systems, component libraries, web application frameworks.', 'Identifies and manages existing and emerging risks that stem from business activities and the job role.', '3+ years of experience planning and conducting both qualitative and quantitative design research. Experience should include establishing recruitment criteria/screening, creating protocols/interview guides, conducting test/interview sessions, identifying top-level findings and documenting recommendations.Demonstrated experience using behavioral and/or transactional data to help prioritize design efforts.Experience working with internal design systems, component libraries, web application frameworks.Working knowledge of Accessibility principles and guidelines; experience creating inclusive designs.Real Estate or Fintech domain knowledge and understanding of sales funnel and conversion optimization', 'Bachelor’s Degree or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree (10+ years of experience in lieu of degree).', 'available', 'Co-facilitates a cross-functional understanding of business problems and potential design solutions using human-centered design sessions and group discussions to achieve actionable outcomes.', '3+ years of experience planning and conducting both qualitative and quantitative design research. Experience should include establishing recruitment criteria/screening, creating protocols/interview guides, conducting test/interview sessions, identifying top-level findings and documenting recommendations.', 'Demonstrates a strategic mindset by decomposing complex problems into a clear and achievable workstream requiring limited support and direction for decision making.', 'Stays abreast of current digital and mobile technology trends, in the area of application architecture with best practices within the digital development ecosystem', 'Demonstrated ability to work fluently in standard applications, including Sketch, InVision (or comparable prototyping tools), Adobe CC and Microsoft Office Suite.', 'Tasks', 'Minimum Requirements', 'Applies advanced understanding of human-centered and service design practices and leverages multiple methods to solve complex design problems.', 'Demonstrated advanced understanding of new technologies and best practices in website navigation, browsers, mobile patterns, information architecture and usability.', 'Navigates multiple workstreams from discovery to implementation, balancing efforts, priorities, and partnerships for each.']",Not Applicable,Full-time,Design,Financial Services,2020-11-05 11:32:32
Data Engineer,"Sage Intacct, Inc.","San Francisco, CA",21 hours ago,63 applicants,"['You may be a fit for this role if:', 'Responsibilities:', 'Working with ML Engineers and data scientists to refine and specify data products that satisfy business policies and requirements', 'Preferred Qualifications:', 'What it’s like to work here:', 'Ability to work independently and deliver results on-time', 'Designing, implementing, and operating pipelines that deliver data with measurable quality and SLOs', 'Basic Qualifications:', 'Advanced SQL skills either for DB management or analysis', 'Bachelor’s degree, preferably in a field that requires data management and manipulation (e.g. statistics, applied math, computer science, or a science field with direct statistics applications)', 'Every business on Earth must, in some way, do bookkeeping, accounting, and financial planning to operate. At the outset, these functions may seem like mundane facts-of-life in the process of running a business; however, the skill with which a company does them can have a profound impact not only on their business, but also the world. A poorly forecasted budget, could mean the abrupt end to the clinical trial of a potentially life-saving drug. On the other hand, a highly accurate hiring plan can lead to successful team growth that allows a company to design a brand-new material that helps reverse climate change.', 'You’re a deeply curious person.', 'Today, unfortunately, financial management and services are universally manual, tedious, and error prone. At the same time, these processes often follow welldefined rules, abide by industry standardization, and have become increasingly data-rich. Our team, within the Medium Segment Native Cloud Solutions at Sage, builds cloud-based AI-powered features and products that fundamentally change the way businesses operate.', 'Strong quantitative and analytical skills with minimum 4 years of experience with building data-intensive applications,familiarity with the scientific Python toolset: numpy, scipy, sklearn, etc.experience with one or more workflow management technology: airflow, argo, etc.Experience building and operating cloud infrastructure, preferably on AWS', 'familiarity with the scientific Python toolset: numpy, scipy, sklearn, etc.', 'Ability to communicate complex ideas to non-technical stakeholders and alternate between big-picture and implementation.', 'Fluent in data fundamentals: SQL, data management, and data manipulation using a procedural language', 'You’re comfortable with investigating open-ended problems and coming up with concrete approaches to solve them.', 'Excellent problem solving and critical thinking skills', 'You can wrangle data like a pro alligator wrestler and come out relatively unscathed.', 'Bachelor’s degree, preferably in a field that requires data management and manipulation (e.g. statistics, applied math, computer science, or a science field with direct statistics applications)Fluent in data fundamentals: SQL, data management, and data manipulation using a procedural languageStrong quantitative and analytical skills with minimum 4 years of experience with building data-intensive applications,familiarity with the scientific Python toolset: numpy, scipy, sklearn, etc.experience with one or more workflow management technology: airflow, argo, etc.Experience building and operating cloud infrastructure, preferably on AWSDeep understanding of relational as well as big data techniques and technologies (e.g. Postgres/mysql, spark, data warehousing (s3, Redshift, Snowflake, etc.))Ability to work independently and deliver results on-timeAbility to communicate complex ideas to non-technical stakeholders and alternate between big-picture and implementation.Excellent problem solving and critical thinking skills', 'Experience developing and operating machine learning pipelines with Kubeflow or Argo', 'You’re comfortable with investigating open-ended problems and coming up with concrete approaches to solve them.You’re a deeply curious person.You can wrangle data like a pro alligator wrestler and come out relatively unscathed.You often think about applications of machine learning in your personal life.', 'Working with our AI Infrastructure team to extend our capabilities , curate new data sets, and manage the data that drives our machine learning platform', 'familiarity with the scientific Python toolset: numpy, scipy, sklearn, etc.experience with one or more workflow management technology: airflow, argo, etc.Experience building and operating cloud infrastructure, preferably on AWS', 'We are looking for a Data Engineer to help us ship AI-powered products and services.', 'Experience building and operating cloud infrastructure, preferably on AWS', 'Informing our strategy for data governance, security, privacy, quality, and retention', 'Exploratory data analyses and investigations', 'Hands-on experience with one or more ML pipeline automation frameworks — MLFlow, Kubeflow, or TFX.', 'Designing, implementing, and operating pipelines that deliver data with measurable quality and SLOsCreating tools for establishing common data management patterns across our team and beyondWriting production-quality code to support our data pipelines and machine learning systemsInforming our strategy for data governance, security, privacy, quality, and retentionWorking with our AI Infrastructure team to extend our capabilities , curate new data sets, and manage the data that drives our machine learning platformWorking with ML Engineers and data scientists to refine and specify data products that satisfy business policies and requirementsExploratory data analyses and investigations', 'Deep understanding of relational as well as big data techniques and technologies (e.g. Postgres/mysql, spark, data warehousing (s3, Redshift, Snowflake, etc.))', 'You often think about applications of machine learning in your personal life.', 'Experience developing and operating machine learning pipelines with Kubeflow or ArgoHands-on experience with one or more ML pipeline automation frameworks — MLFlow, Kubeflow, or TFX.Advanced SQL skills either for DB management or analysisYou have deep experience with these things: data warehousing, schema management, timeseries datasets, data validation, synthetic data generation, serialization protocols, data privacy and security', 'experience with one or more workflow management technology: airflow, argo, etc.', 'Creating tools for establishing common data management patterns across our team and beyond', 'Writing production-quality code to support our data pipelines and machine learning systems', 'You will have an opportunity to work on a small and growing team in an environment where data engineering and ML are central to our success. The products we build are breaking new ground, and we have a focus on providing the best environment to allow you to do what you do best - solve problems, collaborate with your team, and push first class software. We promote an open diverse environment, encourage contributions to open-source software and invest heavily in our staff. Our team is talented, capable and inclusive. We know that great things can only be done with great teams and look forward to building and working with a great people.', 'You have deep experience with these things: data warehousing, schema management, timeseries datasets, data validation, synthetic data generation, serialization protocols, data privacy and security']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Data Engineer,Idexcel,"Sunnyvale, CA",3 hours ago,Over 200 applicants,"['', '• Experience with setting up and operating data pipelines using Python or SQL.', '• 3+ years relevant working with Redshift, SQL, Python, Airflow and AWS data technologies.', '• Capability to conduct performance analysis, troubleshooting and remediation.', 'Note: Local to CA candidates preferred, would be completely remote.', '\xa0', 'Job Title: Data Engineer', '• Bachelor’s degree in Computer Engineering, or related discipline.', '• Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. CICD).', '• 1+ years of experience working on AWS.', 'Duration: 6+ months', '• 3+ years of experience working with SQL.', 'Qualifications:', '• Understanding of data architecture concepts such as data modeling, metadata, workflow management, ETL/ELT, real-time streaming), data quality.', '• Exposure to open source and proprietary cloud data pipeline tools such as Airflow, and Glue.', 'Be part of Data Engineering team responsible for Data Analytics Platform servicing the business needs of the broader organization.', 'Description:', '• Experience working with relational databases.', '• Self-starter with the ability to work independently or as part of a project team.', '• Great written and verbal communication skills.', 'Location: Sunnyvale, CA/Remote']",Associate,Contract,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior User Researcher,Spotify,"New York, NY",7 hours ago,160 applicants,"['', 'Have proven experience in user research, with significant expertise in either exploratory qualitative research to identify needs and problems or workflow and task analysis (or both!).', 'What You’ll Do', 'Have proven experience in user research, with significant expertise in either exploratory qualitative research to identify needs and problems or workflow and task analysis (or both!).Hold a degree in Psychology, Human Computer Interaction, or a related field, and/or relevant professional experience.Comfortable with planning, prioritizing, conducting, analyzing and communicating research in a variety of contexts.Familiar with quantitative research methods, utilizing metrics and A/B tests, and able to synthesise quantitative data with qualitative data.Have strong interpersonal skills and can easily connect with your partners in product, tech, business and design.A dedicated advocate of a user-centred, evidence-based approach to product development, while balancing business needs.', 'Work closely with a cross-functional, geographically distributed team of data scientists, user researchers, product managers, designers and engineers across New York, Stockholm and London.', 'Apply rigorous analysis to understand and document complex workflows and processes.', 'Deliver compelling insights, stories and artefacts to help drive evidence-based product and design decisions.', 'Comfortable with planning, prioritizing, conducting, analyzing and communicating research in a variety of contexts.', 'Familiar with quantitative research methods, utilizing metrics and A/B tests, and able to synthesise quantitative data with qualitative data.', 'Develop and innovate on our mixed-methods user research practice and contribute to the wider Insights community at Spotify', 'A dedicated advocate of a user-centred, evidence-based approach to product development, while balancing business needs.', 'Have strong interpersonal skills and can easily connect with your partners in product, tech, business and design.', 'Define, plan, and conduct exploratory user research, including supporting the work of less experienced colleagues.', 'Hold a degree in Psychology, Human Computer Interaction, or a related field, and/or relevant professional experience.', ""Work from our offices in New York (With the current situation regarding COVID-19, this role will be remote until it's appropriate to work from the office)."", ""Work closely with a cross-functional, geographically distributed team of data scientists, user researchers, product managers, designers and engineers across New York, Stockholm and London.Define, plan, and conduct exploratory user research, including supporting the work of less experienced colleagues.Apply rigorous analysis to understand and document complex workflows and processes.Deliver compelling insights, stories and artefacts to help drive evidence-based product and design decisions.Develop and innovate on our mixed-methods user research practice and contribute to the wider Insights community at SpotifyWork from our offices in New York (With the current situation regarding COVID-19, this role will be remote until it's appropriate to work from the office)."", 'Who You Are']",Not Applicable,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
"Researcher II, North America",Riot Games,"Los Angeles, CA",22 minutes ago,31 applicants,"['', 'Our Perks', 'Proficient in many research methodologies, such as surveys, focus groups, ethnography, and labs, and apply research methodologies with a minimal amount of craft guidance', 'Construct, organize, and build studies and surveys designed to answer business, development, and usability questions and work with central research team to lead focus groups and share your results with other Rioters and leaders', 'Develop projects that improve our understanding of the gamer and Esports audience to both grow the audience and increase audience investment in our multiple IP', ' Develop projects that improve our understanding of the gamer and Esports audience to both grow the audience and increase audience investment in our multiple IP Create/socialize backlog for regional market research to understand gamer & esports fan preferences Advise regional leadership on market research spend/best practices, and need for scope of current tools and future tools to be developed Scope, support and socialize regional audience profiling, purchase/trial research, or additional company-wide research efforts Framework for understanding the interaction effects between player hours in games and player engagement in non-game experiences (Esports, IP/C products)  Construct, organize, and build studies and surveys designed to answer business, development, and usability questions and work with central research team to lead focus groups and share your results with other Rioters and leaders Develop relationships with product and regional insights teams ', 'Responsibilities', 'Create/socialize backlog for regional market research to understand gamer & esports fan preferences', 'Advise regional leadership on market research spend/best practices, and need for scope of current tools and future tools to be developed', 'Framework for understanding the interaction effects between player hours in games and player engagement in non-game experiences (Esports, IP/C products) ', 'Experience in the tech, gaming, consumer products or media/entertainment industry', ""It’s our policy to provide equal employment opportunity for all applicants and members of Riot Games, Inc. Riot Games makes reasonable accommodations for handicapped and disabled Rioters and does not unlawfully discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, handicap, veteran status, marital status, criminal history, or any other category protected by applicable federal and state law, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance relating to an applicant's criminal history (LAMC 189.00)."", 'Desired Qualifications', 'Experience creating presentations and convey complex or nuanced topics to creative audiences', 'Advanced degree', 'Hypothesis-driven experimentation skills with emphasis on qual/quant user research techniques and playtesting/labs. Familiarity with helping a team test, learn, and iterate', 'Researcher on the North America Regional & Oceania team', 'Develop relationships with product and regional insights teams', ' BA or BS in Psychology, Anthropology, Human-Computer Interaction, or a related social science discipline 4+ years of experience in user experience research, behavioral or cognitive research, or quantitative market research Proficient in many research methodologies, such as surveys, focus groups, ethnography, and labs, and apply research methodologies with a minimal amount of craft guidance Expertise in at least one quantitative method for understanding sentiment, needs, and survey preferences Hypothesis-driven experimentation skills with emphasis on qual/quant user research techniques and playtesting/labs. Familiarity with helping a team test, learn, and iterate Create applicable recommendations for brand/growth strategy Experience creating presentations and convey complex or nuanced topics to creative audiences ', 'Required Qualifications', 'Scope, support and socialize regional audience profiling, purchase/trial research, or additional company-wide research efforts', ' Advanced degree Experience in the tech, gaming, consumer products or media/entertainment industry ', 'Create applicable recommendations for brand/growth strategy', 'BA or BS in Psychology, Anthropology, Human-Computer Interaction, or a related social science discipline', 'Expertise in at least one quantitative method for understanding sentiment, needs, and survey preferences', '4+ years of experience in user experience research, behavioral or cognitive research, or quantitative market research']",Not Applicable,Full-time,Research,Computer Games,2020-11-05 11:32:32
Principal Research Scientist – Hematology,Novartis Institutes for BioMedical Research (NIBR),"Cambridge, MA",6 hours ago,Be among the first 25 applicants,"['', 'Division', ' Manage a team of associates', 'Work Location', 'Country', 'Functional Area', 'Company/Legal Entity', 'The Novartis Group of Companies are Equal Opportunity Employers and take pride in maintaining a diverse environment. We do not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status.', ' Ph.D. in Cellular or Molecular Biology or Immunology. Experience in hematology or Immunology is preferred together with 3 to 5 years’ experience in leading an innovative research team with a focus on Hematology research Preference will be given to candidates with experience leading hematology focused drug discovery efforts in a pharmaceutical or biotechnology research setting.', ' The candidate will have a proven record of accomplishment of driving and supporting multiple research projects, and contributions as an author to high-impact, peer-reviewed publications in the field He/she will conduct early research for genetic and non-genetic hematologic disorders Will possess excellent oral and written communication skills and an ability to thrive in a dynamic matrix research environment. Creative problem-solving skills; excellent analytical, communication and organizational skills.', 'Shift Work', ' Creative problem-solving skills; excellent analytical, communication and organizational skills.', ' Will assume a crucial role in developing novel therapeutic concepts and will contribute at all stages of a project, from inception, early project validation, optimization, candidate selection and through to early clinical development of novel medicines for patients with hematological disorders', ' Ph.D. in Cellular or Molecular Biology or Immunology. Experience in hematology or Immunology is preferred together with 3 to 5 years’ experience in leading an innovative research team with a focus on Hematology research', ' Will assume a crucial role in developing novel therapeutic concepts and will contribute at all stages of a project, from inception, early project validation, optimization, candidate selection and through to early clinical development of novel medicines for patients with hematological disorders Will work collaboratively with other specialists to develop project strategy, identify key drug discovery issues, propose and implement creative solutions, execute and guide teams to success and decision points. Propose and explore new research directions, projects, and/or new technologies. Self-motivation, ability to work independently, passion for working in an interdisciplinary, collaborative research environment Manage a team of associates', ' Will possess excellent oral and written communication skills and an ability to thrive in a dynamic matrix research environment.', ' Preference will be given to candidates with experience leading hematology focused drug discovery efforts in a pharmaceutical or biotechnology research setting.', 'Business Unit', ' Propose and explore new research directions, projects, and/or new technologies.', ' The candidate will have a proven record of accomplishment of driving and supporting multiple research projects, and contributions as an author to high-impact, peer-reviewed publications in the field', 'Job Description', 'Employment Type', ' Self-motivation, ability to work independently, passion for working in an interdisciplinary, collaborative research environment', ' Will work collaboratively with other specialists to develop project strategy, identify key drug discovery issues, propose and implement creative solutions, execute and guide teams to success and decision points.', 'Job Type', 'Minimum Requirements', 'EEO Statement', ' He/she will conduct early research for genetic and non-genetic hematologic disorders']",Associate,Full-time,Research,Pharmaceuticals,2020-11-05 11:32:32
"ML Engineer, NLP and Search, Public Sector - AWS Professional Services",Amazon Web Services (AWS),"Richmond, VA",6 hours ago,Be among the first 25 applicants,"['', ' 2+ years of experience with building ML infrastructure and data pipelines to train models', 'The Primary Responsibilities Of This Role Are To', ' 5+ years of industry experience in software development', ' Experience with Python, R, or other statistical software', 'Preferred Qualifications', 'Company', ' Strong communication and data presentation skills', ' Experience with common ML techniques such as pre-processing data, training, and evaluation of classification and regression models', 'Basic Qualifications', 'Description', ' Working knowledge of Natural Language Processing, search technologies such as Elasticsearch, or graph databases', ' Experience with ML libraries/frameworks such as Tensorflow, Keras, PyTorch, or AWS SageMaker', ' BS in computer science or related technical, math, or scientific field 2+ years of non-internship professional software development experience 2+ years of experience with building ML infrastructure and data pipelines to train models Experience with common ML techniques such as pre-processing data, training, and evaluation of classification and regression models Experience with Python, R, or other statistical software', ' User interface experience with Javascript or HTML', ' Interact with customers directly to understand their business problems, and assist them in the implementation of their ML ecosystem', ' Design data architectures and data lakes', ' Collaborate with our data scientists to create scalable ML solutions for business problems', ' Work closely with account team, research scientist teams, and product engineering teams to drive model implementations and new algorithms', ' Masters or PhD degree in computer science or related technical, math, or scientific field 5+ years of industry experience in software development 5+ years of experience with big data and scalable model training 5+ years of experience with ML in production Experience with ML libraries/frameworks such as Tensorflow, Keras, PyTorch, or AWS SageMaker Working knowledge of Natural Language Processing, search technologies such as Elasticsearch, or graph databases Experience with cloud computing on AWS User interface experience with Javascript or HTML Strong communication and data presentation skills', ' Analyze and extract relevant information from large amounts of data, providing hands-on data wrangling expertise', ' 5+ years of experience with ML in production', ' BS in computer science or related technical, math, or scientific field', ' Experience with cloud computing on AWS', ' 5+ years of experience with big data and scalable model training', ' 2+ years of non-internship professional software development experience', ' Provide expertise in the development of ETL solutions on AWS', ' Masters or PhD degree in computer science or related technical, math, or scientific field', ' Design data architectures and data lakes Provide expertise in the development of ETL solutions on AWS Collaborate with our data scientists to create scalable ML solutions for business problems Interact with customers directly to understand their business problems, and assist them in the implementation of their ML ecosystem Analyze and extract relevant information from large amounts of data, providing hands-on data wrangling expertise Work closely with account team, research scientist teams, and product engineering teams to drive model implementations and new algorithms']",Not Applicable,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Principal Data Engineer - Lead,Cognizant,"Riverwoods, IL",6 hours ago,Be among the first 25 applicants,"['', 'AWS EMR', 'Kafka', 'AWS', 'Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers.', 'Responsibilities', 'Spark', 'Strong teamwork skills', 'Provide system support as part of a support rotation with other team members.', 'Works with key stakeholders to design complex solutions and lead from inception to production', 'Develop real-time data ingestion and stream-analytic solutions leveraging technologies such as Kafka, Apache Spark, Python, AWS', 'Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.', 'Qualifications', 'About Cognizant', 'Cognizant will not be able to provide sponsorship for this role. Candidates have the option of working remotely.', 'Python', 'Snowflake', 'Develop data driven solutions utilizing current and next generation technologies to meet evolving business needs.', 'Strong desire and capability to automate everything.', 'Company Description', 'Ability to quickly identify an opportunity and recommend possible technical solutions.', 'Strong analytical and problem-solving skills', 'Develop data driven solutions utilizing current and next generation technologies to meet evolving business needs.Ability to quickly identify an opportunity and recommend possible technical solutions.Strong desire and capability to automate everything.Develop real-time data ingestion and stream-analytic solutions leveraging technologies such as Kafka, Apache Spark, Python, AWSCustom Data pipeline development (Cloud and locally hosted)Provide support for deployed data applications and analytical models by being a trusted advisor to Data Scientists and other data consumers by identifying data problems and guiding issue resolution with partner Data Engineers and source data providers.Provide subject matter expertise in the analysis, preparation of specifications and plans for the development of data processes.Ensure proper data governance policies are followed by implementing or validating Data Lineage, Quality checks, classification, etc.Works with key stakeholders to design complex solutions and lead from inception to productionProvide system support as part of a support rotation with other team members.', 'Provide subject matter expertise in the analysis, preparation of specifications and plans for the development of data processes.', 'AWSAWS EMRSparkPythonSnowflakeKafkaStrong teamwork skillsStrong analytical and problem-solving skills', 'Custom Data pipeline development (Cloud and locally hosted)']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr Staff UX Design Researcher,GE Healthcare,"Chicago, IL",22 hours ago,Be among the first 25 applicants,"['', 'Optionally, also lead design thinking / co-creation/ service design workshops that take stakeholders through the design thinking process to frame a project.', 'Flexibility in research approaches and strong, pragmatic bias for action, always trying to seek the most expedient path to get the insights needed without compromising on findings or integrity', 'As a senior researcher, you will:Provide leadership, research guidance and mentorship to team members; provide coaching on feedback gathering techniques; implement and evangelize best practices and the latest techniques, including Lean UX and use of analyticsFrame, scope, and lead execution of design research projectsLead / facilitate constructive design and research critiques; review research work; set standards for researchIdentify and share repeatable cross-product insights and findings; advocate for and ensure knowledge-share across researchers and team membersEstablish, refine and standardize existing research processes and approaches; ensure the right research is being optimally conducted at the right time, using the right mix of methods by productOversee a consolidated research backlog, roadmap and prioritiesManage the research repository, standardized candidate recruitment, vendors and costs; relentlessly aim to optimize and improve research processes for greater efficiency and less overheadBe the main voice of UX research within the UX team and the Digital organization: methods, benefits, planning, standards, outcomes', 'Legal authorization to work in the U.S. is required. GE may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills.Any offer of employment is conditioned upon the successful completion of a background investigation and drug screenMust be willing to travel for research activities in the futureMust be willing to work out of an office located in CHICAGO IL or WAUKESHA WI', 'Minimum of 10+ years professional experience', 'Extremely strong written and verbal communication skills', 'As a senior researcher, you will:', 'Frame reports, write-ups and insights in a way that inspires design teams to develop imaginative and appropriate solutions. Help to facilitate teams through analysis and synthesis of user research, helping to distill the most important insights and link them together in frameworks, principles, and implications for design. Design researchers must be confident about leading teams and users through a range of research analysis and synthesis processes.', 'Any offer of employment is conditioned upon the successful completion of a background investigation and drug screen', 'Oversee a consolidated research backlog, roadmap and priorities', 'Can create and communicate research artifacts, findings, reports, and recommendations with stakeholders in compelling ways: Executive summaries, reports, key findings and insights, case studies', 'Plan and conduct interview sessions with users and stakeholders, including executives.', 'Communicate design insights and opportunities throughout all phases of design process and product lifecycle, from concept to release. Utilize Compelling storytelling to deliver insights about people and behavior - verbally and visually - in a way that generates empathy, emotion, and engagement from the design team as well as engineering, product management, marketing and others.', 'Be the main voice of UX research within the UX team and the Digital organization: methods, benefits, planning, standards, outcomes', 'Desired Characteristics', 'If Discovery research is needed, structure user-centered research and work with a variety of teams through fieldwork to determine users physical, cognitive, social, emotional, and cultural needs. Research specialists must have proven experience in uncovering unmet user needs, and unpacking meaning from sometimes obscure and disparate findings.', 'High attention to detail', 'Awareness and enjoyment of using Lean research / informal testing methods earlier in the design process to obtain early insights, when possible', 'Leads and recommends both short- and long-term research activities, defining a vision for evolving research at GEHC', 'Research and evaluate emerging design, technology, and industry trends and competitive products; champion new ideas and approaches as appropriate.', 'Strongly Desired: Knowledge of FDA formative & summative usability testing and past medical device or healthcare research experience', 'Select and use appropriate user research methods to address UX and product research needs. Be equally comfortable with discovery research and concept and validation testing', 'Can evaluate and prioritize research priorities and backlog based on user, business and product criticality.', 'Sees patterns within industry issues. Demonstrates how UX provides solutions for internal/external customer challenges.', 'Exceedingly organized, proactive and self-motivated', 'Propose designs, features or changes to product solutions based on research and synthesis outcomes; influence change', 'Provide leadership, research guidance and mentorship to team members; provide coaching on feedback gathering techniques; implement and evangelize best practices and the latest techniques, including Lean UX and use of analytics', 'Leads and recommends both short- and long-term research activities, defining a vision for evolving research at GEHCExperience with conducting qualitative and quantitative research activities such as ethnographic studies and usability studies, including surveys (qualitative and quantitative) and overseeing the work of external research partners and agenciesCan create and communicate research artifacts, findings, reports, and recommendations with stakeholders in compelling ways: Executive summaries, reports, key findings and insights, case studiesHigh attention to detailExceedingly organized, proactive and self-motivatedExtremely strong written and verbal communication skillsDeep knowledge of research tools and methods from discovery to post-launch evaluation and survey, recruitment, acquisition tools and methodsFlexibility in research approaches and strong, pragmatic bias for action, always trying to seek the most expedient path to get the insights needed without compromising on findings or integrityAwareness and enjoyment of using Lean research / informal testing methods earlier in the design process to obtain early insights, when possibleStrongly Desired: Knowledge of FDA formative & summative usability testing and past medical device or healthcare research experienceDesired: knowledge of usage analytics and use of aggregate analytics data as a research sourceDesired but optional: design thinking / co-creation/ service design facilitation experience, takes various stakeholders through the design thinking process to frame a project.Creates, analyzes and can self-manage research projects independentlyCan evaluate and prioritize research priorities and backlog based on user, business and product criticality.Understands key principles of design thinking and research, what it is and why it is important. Explores all ideas, regardless of their source.', 'Manage the research repository, standardized candidate recruitment, vendors and costs; relentlessly aim to optimize and improve research processes for greater efficiency and less overhead', 'Run standardized distance, accessibility and metaphor evaluation tests for Edison Design System components', 'As An Individual Contributor, You May Be Asked To', 'Deep knowledge of research tools and methods from discovery to post-launch evaluation and survey, recruitment, acquisition tools and methods', 'Essential Responsibilities :', 'Legal authorization to work in the U.S. is required. GE may agree to sponsor an individual for an employment visa now or in the future if there is a shortage of individuals with particular skills.', 'Lead / facilitate constructive design and research critiques; review research work; set standards for research', 'Must be willing to work out of an office located in CHICAGO IL or WAUKESHA WI', 'Experience with conducting qualitative and quantitative research activities such as ethnographic studies and usability studies, including surveys (qualitative and quantitative) and overseeing the work of external research partners and agencies', 'Mine existing product usage analytics as a research source', 'Creates, analyzes and manages projects that provide direct business benefit. Demonstrates detailed knowledge of business operations and strategic direction, including merger & acquisition opportunities.Sees patterns within industry issues. Demonstrates how UX provides solutions for internal/external customer challenges.Uses root cause analysis to identify, correct and/or eliminate the causes of problems as well as the problem itself.', 'Frame, scope, and lead execution of design research projects', 'Identify and share repeatable cross-product insights and findings; advocate for and ensure knowledge-share across researchers and team members', 'Creates, analyzes and can self-manage research projects independently', 'Uses root cause analysis to identify, correct and/or eliminate the causes of problems as well as the problem itself.', 'Lead FDA-mandated formative & summative usability testing for healthcare products', 'Understands key principles of design thinking and research, what it is and why it is important. Explores all ideas, regardless of their source.', 'Job Description', 'Qualifications/Requirements', 'Relocation Assistance Provided: ', 'Desired: knowledge of usage analytics and use of aggregate analytics data as a research source', 'Creates, analyzes and manages projects that provide direct business benefit. Demonstrates detailed knowledge of business operations and strategic direction, including merger & acquisition opportunities.', 'Frame, scope, plan and lead execution of small and large research projects independently', 'Must be willing to travel for research activities in the future', 'Establish, refine and standardize existing research processes and approaches; ensure the right research is being optimally conducted at the right time, using the right mix of methods by product', 'Frame, scope, plan and lead execution of small and large research projects independentlyPropose designs, features or changes to product solutions based on research and synthesis outcomes; influence changeSelect and use appropriate user research methods to address UX and product research needs. Be equally comfortable with discovery research and concept and validation testingPlan and conduct interview sessions with users and stakeholders, including executives.Research and evaluate emerging design, technology, and industry trends and competitive products; champion new ideas and approaches as appropriate.If Discovery research is needed, structure user-centered research and work with a variety of teams through fieldwork to determine users physical, cognitive, social, emotional, and cultural needs. Research specialists must have proven experience in uncovering unmet user needs, and unpacking meaning from sometimes obscure and disparate findings.Frame reports, write-ups and insights in a way that inspires design teams to develop imaginative and appropriate solutions. Help to facilitate teams through analysis and synthesis of user research, helping to distill the most important insights and link them together in frameworks, principles, and implications for design. Design researchers must be confident about leading teams and users through a range of research analysis and synthesis processes.Communicate design insights and opportunities throughout all phases of design process and product lifecycle, from concept to release. Utilize Compelling storytelling to deliver insights about people and behavior - verbally and visually - in a way that generates empathy, emotion, and engagement from the design team as well as engineering, product management, marketing and others.Lead FDA-mandated formative & summative usability testing for healthcare productsRun standardized distance, accessibility and metaphor evaluation tests for Edison Design System componentsMine existing product usage analytics as a research sourceOptionally, also lead design thinking / co-creation/ service design workshops that take stakeholders through the design thinking process to frame a project.', 'Additional Eligibility Qualifications', 'Desired but optional: design thinking / co-creation/ service design facilitation experience, takes various stakeholders through the design thinking process to frame a project.', 'In This Role, You Will', 'Leadership and Personal Attributes', 'Bachelor’s Degree in Cognitive or Experimental Psychology, Human Computer Interaction, Human Factors; or in “STEAM” Majors (Science, Technology, Engineering, Arts and Math) is required; Master’s Degree preferredMinimum of 10+ years professional experience', 'Bachelor’s Degree in Cognitive or Experimental Psychology, Human Computer Interaction, Human Factors; or in “STEAM” Majors (Science, Technology, Engineering, Arts and Math) is required; Master’s Degree preferred', 'Eligibility Requirements']",Associate,Full-time,Information Technology,Hospital & Health Care,2020-11-05 11:32:32
"Data Engineer, Sr",Seattle Children's,"Seattle, WA",4 hours ago,29 applicants,"['', ' Experience in Healthcare or related industry', 'Work Status: Regular;', ' Demonstrated ability to achieve stretch goals in a highly innovative and fast-paced environment', 'Department: Enterprise Analytics;', 'The people who work at Seattle Children’s are members of a community that seeks to respect and celebrate all the qualities that make each of us unique. Each of us is empowered to be ourselves within this community, which cultivates and promotes equity, diversity, and inclusion at all levels. ', ' Experience wrting test cases and test scripts for data quality assurance', 'Work Status:', ' Experience utilizing Netezza, Datastage, BitBucket, JIRA, Confluence a plus', 'About Us', 'Department:', 'FTE/Hours per pay period:', 'Area of Interest: Information Technology;', ' Experience developing dimensional data model with any industry standard tool.', 'Shift:', ' Experience in SDLC process with requirements gathering, analysis, architecture, design, implementation, testing, deployment and technical support.', ' Continuous delivery and deployment automation for analytic solutions using tools like Bamboo', 'Hope. Care. Cure. These three simple words capture what we do at Seattle Children’s -- to help every child live the healthiest and most fulfilling life possible. Are you ready to engage with a mission-driven organization that is life-changing to many, and touches the hearts of all? #HOPECARECURE', 'FTE/Hours per pay period: 1.0 FTE (80 hours per bi-weekly pay periods);', ' Experience working in a complex data infrastructure environment', ' Build highly scalable, scaled-out architectures on large scale database platforms', 'Seattle Children’s is proud to be an Equal Opportunity Workplace and Affirmative Action Employer.', 'Job ID: 36471;', ' Experience productizing/automating predictive models that use R, SAS, Python, SPSS, etc.', 'Requirements', 'Required Credentials', ' Familiarity with test driven development methodology for analytic solutions', 'Preferred', ' Minimum of five (5) years technology industry or related experience, including items such as:', 'Area of Interest:', ' Experience creating stored procedures and functions', 'Overview', ' Five (5) years of experience in a data engineering role', ' Experience with any industry standard tool for Source Control and Project Management', ' API development', 'Area of Interest: Information Technology;FTE/Hours per pay period: 1.0 FTE (80 hours per bi-weekly pay periods);Work Status: Regular;Department: Enterprise Analytics;Shift: Day Shift;Job ID: 36471;', ' Extensive and in depth data pipeline development experience with industry standard data integration tools', ' N/A', 'Shift: Day Shift;', ' AGILE', ' Data visualization and/or dashboard development', 'Our community welcomes diverse experiences, backgrounds, and thoughts as this is what drives our spirit of inquiry and allows us to better connect with our increasingly diverse patients and families. Our organization recruits, employs, trains, compensates, and promotes without regard to race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. ', 'Our Commitment to Diversity', "" Bachelor's Degree in computer science or related field, or equivalent combination of education and experience/technical training that demonstrates analytical and technical competency"", 'Job ID:']",Associate,Full-time,Legal,Research,2020-11-05 11:32:32
"Senior Machine Learning Engineer, Homefeed Ranking",Pinterest,"San Francisco, CA",7 hours ago,Be among the first 25 applicants,"['', 'Work in a high-impact environment with quick experimentation and product launches', 'Passionate about recommendation systems and deep learning', 'What You’ll Do', '5+ years experience applying machine learning methods in settings like recommender systems, search, user modeling, image recognition, graph representation learning, natural language processing', ""Apply the latest advances in deep learning and machine learning to personalize Pinterest user's Homefeeds"", 'Develop new features to improve our user and pin understanding in our models', "" Apply the latest advances in deep learning and machine learning to personalize Pinterest user's Homefeeds Develop new features to improve our user and pin understanding in our models Impact 400M+ monthly active users by developing the next generation of discovery technologies Work in a high-impact environment with quick experimentation and product launches "", 'What We’re Looking For', ' Passionate about recommendation systems and deep learning 5+ years experience applying machine learning methods in settings like recommender systems, search, user modeling, image recognition, graph representation learning, natural language processing Experience building pipelines for large scale data processing', 'Impact 400M+ monthly active users by developing the next generation of discovery technologies', 'Experience building pipelines for large scale data processing', 'About Pinterest']",Mid-Senior level,Full-time,Information Technology,Internet,2020-11-05 11:32:32
"Senior UX Researcher, Enterprise Cloud",NVIDIA,"Santa Clara, CA",8 hours ago,Be among the first 25 applicants,"['', ' Identify the accurate participants for recruiting. ', "" Background in working on software product design and development and Bachelor's degree "", "" Experience working within an enterprise organization.  Background in working on software product design and development and Bachelor's degree  Ability to work across multiple tracks of work. "", ' Moderate one-on-one usability sessions. ', ' Develop quantitative surveys. ', ' Translate user insights into impactful recommendations for the overall design strategy and interaction. ', ' Match research methods to objectives. ', ' Craft research plans and execute exploratory, conceptual and strategic research. ', 'What We Need To See', ' Write a usability research screener and discussion guides. ', ' Conduct partner and client interviews. ', ' Extract insights about user behaviors from web instrumentation tools. ', "" 6+ years of experience working within an enterprise organization and Bachelor's degree "", ' Experience working within an enterprise organization. ', ' Ability to work across multiple tracks of work. ', ' Develop a well-crafted research plan with clear research objectives. ', ""What You'll Be Doing"", 'Ways To Stand Out From The Crowd', "" 6+ years of experience working within an enterprise organization and Bachelor's degree  Develop a well-crafted research plan with clear research objectives.  Match research methods to objectives.  Identify the accurate participants for recruiting.  Write a usability research screener and discussion guides.  Craft research plans and execute exploratory, conceptual and strategic research.  Conduct partner and client interviews.  Moderate one-on-one usability sessions.  Develop quantitative surveys.  Extract insights about user behaviors from web instrumentation tools.  Translate user insights into impactful recommendations for the overall design strategy and interaction. ""]",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
"Travel Medical Tech - $1,850 per week",NurseFly,"Healdsburg, CA",24 hours ago,Be among the first 25 applicants,"['', ' 401(k) and Flex Spending', ' Refer a friend and earn extra cash!', 'Specialty: Medical TechDiscipline: Allied Health ProfessionalStart Date: 11/09/2020Duration: 13 weeks40.00 hours per weekShift: 8 hours, daysEmployment Type: Travel', '40.00 hours per week', 'Medical Tech', '13 weeks', 'About The Company', 'Allied Health Professional', 'Preferred Qualifications', 'Duration: 13 weeks', 'Discipline: Allied Health Professional', 'Facility Location', '11/09/2020', '  Competitive pay rates  Medical, Dental, Vision  401(k) and Flex Spending  Life Insurance  Accident and Short-term Disability Coverage  Free Continuing Education  Free Private Housing  Refer a friend and earn extra cash! ', 'Travel', ' Free Continuing Education', ' Life Insurance', ' Competitive pay rates', ' Medical, Dental, Vision', 'About Club Staffing', 'Job Description & Requirements', '8 hours, days', 'Required Qualifications', 'Start Date: 11/09/2020', ' Accident and Short-term Disability Coverage', 'Job Benefits', ' Free Private Housing', 'Employment Type: Travel', 'Shift: 8 hours, days', 'Specialty: Medical Tech']",Not Applicable,Part-time,Other,Staffing and Recruiting,2020-11-05 11:32:32
Data Scientist - 100% Remote Available,Wiley Job Network,"Macdona, TX",15 hours ago,Be among the first 25 applicants,"['', 'Preferred Requirements', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree."", 'Relocation', 'Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions.', 'Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.', 'Works with IT to research architecture for new products, services, and features.', ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization."", 'Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.', 'Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.', 'Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.', 'Develops algorithms and supporting code such that research efforts are based on the highest quality data.', 'Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required.', 'Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.', ""Master's degree in Computer Science, Applied Mathematics, Quantitative Economics, Statistics, or related field. 6 additional years of related experience beyond the minimum required may be substituted in lieu of a degree.4 or more years of related experience and accountability for complex tasks and/or projects required.Proficient knowledge of the function/discipline and demonstrated application of knowledge, skills and abilities towards work products required.Proficient level of business acumen in the areas of the business operations, industry practices and emerging trends required."", 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.', '4 or more years of related experience and accountability for complex tasks and/or projects required.', ""Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation."", ""Partners with other analysts across the organization to fully define business problems and research questions; Supports SME's on cross functional matrixed teams to solve highly complex work critical to the organization.Integrates and extracts relevant information from large amounts of both structured and unstructured data (internal and external) to enable analytical solutions.Conducts advanced analytics leveraging predictive modeling, machine learning, simulation, optimization and other techniques to deliver insights or develop analytical solutions to achieve business objectives.Supports Subject Matter Experts (SME's) on efforts to develop scalable, efficient, automated solutions for large scale data analyses, model development, model validation and model implementation.Works with IT to research architecture for new products, services, and features.Develops algorithms and supporting code such that research efforts are based on the highest quality data.Translates complex analytical and technical concepts to non-technical employees to enable understanding and drive informed business decisions."", 'available', 'Minimum Requirements', 'Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).', 'PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).', 'Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).Hands-on experience developing products that utilize advanced machine learning techniques like deep learning in areas such as computer vision, Natural Language Processing (NLP), sensor data from the Internet of Things (IoT), and recommender systems; along with transitioning those solutions from the development environment into the production environment for full-time use.PhD in Computer Science, Applied Mathematics, Quantitative Economics, Operations Research, Statistics, or related field with coursework in advanced Machine Learning techniques (Natural Language Processing, Deep Neural Networks, etc).Fluent in deep learning frameworks and libraries (TensorFlow, Keras, PyTorch, etc).Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).Experience in reinforcement learning, knowledge graphs and graph databases, Generative Adversarial Networks (GANs), semi-supervised learning, multi-task learning is a plus.Experience in publishing at top ML, computer vision, NLP, or AI conferences and/or contributing to ML/AI-related open source projects and/or converting ML/AI papers into code is a plus.', 'Highly skilled in handling Big Data (Hadoop, Hive, Spark, Kafka, etc).', 'Proven ability to enrich (add new information to) data, advise on appropriate course(s) of action to take based on results, summarize complex technical analysis for non-technical executive audiences, succinctly present visualizations of high dimensional data, and explain & justify the results of the analysis conducted.', 'Highly competent at data wrangling and data engineering in SQL and SAS as well as advanced machine learning (ML) techniques using Python; comfortable in cloud computing environments (Azure, GCP, AWS).']",Entry level,Full-time,Engineering,Higher Education,2020-11-05 11:32:32
Senior Data Scientist,Microsoft,"Atlanta, GA",3 hours ago,Be among the first 25 applicants,"['', 'Actively participate in AI innovation and establish thought leadership via publications/patents and presence in industry/academic conferences', 'Experience with deep learning applied to areas such as NLP and computer visionExperience with deploying ML models on cloud technologies such as AzurePhD in a quantitative field (engineering, computer science, statistics etc.) with relevant coursework in Data Science, Machine Learning, Statistics & Deep LearningAbility to program in an object-oriented language (such as C# or C++)', '3+ years of professional experience in a technical role in the areas of supervised & unsupervised machine learning3+ years of implementing and successfully deploying ML solutions at scale for real-world problemsProficiency in Python, and/or other statistics/ML tools.Moderate coding skills with specific experience in data wrangling & exploration. SQL or similar required.Bachelors/Masters degree with relevant coursework toward Data Science, Statistics, Machine Learning, and Deep Learning', 'Required', 'Ability to program in an object-oriented language (such as C# or C++)', 'PhD in a quantitative field (engineering, computer science, statistics etc.) with relevant coursework in Data Science, Machine Learning, Statistics & Deep Learning', 'Moderate coding skills with specific experience in data wrangling & exploration. SQL or similar required.', 'Responsibilities', 'Bachelors/Masters degree with relevant coursework toward Data Science, Statistics, Machine Learning, and Deep Learning', 'Proficiency in Python, and/or other statistics/ML tools.', 'Architect and implement ML systems to protect our customers', 'rovide technical leadership to our team by reviewing problem sets, proposing prediction models, and reviewing experiments and models.', 'Identify performant features and models and make them universally accessible to our team and partners across Microsoft.', '3+ years of professional experience in a technical role in the areas of supervised & unsupervised machine learning', '3+ years of implementing and successfully deploying ML solutions at scale for real-world problems', 'Experience with deep learning applied to areas such as NLP and computer vision', 'Preferred', 'Monitor and analyze protection data to uncover gaps', 'Experience with deploying ML models on cloud technologies such as Azure', 'Monitor and analyze protection data to uncover gapsIdentify performant features and models and make them universally accessible to our team and partners across Microsoft.Architect and implement ML systems to protect our customersrovide technical leadership to our team by reviewing problem sets, proposing prediction models, and reviewing experiments and models.Actively participate in AI innovation and establish thought leadership via publications/patents and presence in industry/academic conferences']",Not Applicable,Full-time,Other,Computer Hardware,2020-11-05 11:32:32
Senior Data Scientist,CVS Health,Greater Boston,3 hours ago,Over 200 applicants,"['', 'Position Summary :', '-  You will monitor and bug fix solutions', '-  3+ years’ experience – Experience with Big Data and Machine Learning in cloud environment (Azure/Databricks experience strongly)', 'MS of PhD in Electrical or Computer Engineering, Computer Science, Physics, Mathematics or related engineering or information sciences discipline and in lieu of a MS, a BS and 4+ years of experience will be considered.', '-  You will provide technical expertise in building and maintaining artificial intelligence product in cloud environment', '-  3+ years’ experience - Computer Science, Programming skills', 'We strive to promote and sustain a culture of diversity, inclusion and belonging every day. CVS Health is an equal opportunity and affirmative action employer.  We do not discriminate in recruiting, hiring or promotion based on race, ethnicity, sex/gender, sexual orientation, gender identity or expression, age, disability or protected veteran status or on any other basis or characteristic prohibited by applicable federal, state, or local law. We proudly support and encourage people with military experience (active, veterans, reservists and National Guard) as well as military spouses to apply for CVS Health job opportunities', '-  Experience with Natural Language Processing (NLP)', '-  Experience in retail or loyalty programs preferred', '-  You will build scalable solutions as part of artificial intelligence pipeline', '-  You will collaborate with IT/Engineering to ensure proposed solutions are implemented/supported', '-  3+ years’ experience – Expert programming skills in at least two of the following: Python, R, Scala, Spark or Java. Strong preference for Python/Spark/Keras', '-  You will build Machine Learning pipelines and train models', '-  3+ years’ experience - Probability and Statistics', 'Preferred Qualifications :', 'Business Overview :', '-  3+ years’ experience - in model selection and sampling', '-  You will work in code notebooks', '-  Deep knowledge base in Machine Learning and in- depth expertise in applying automated solutions in Decision Optimization/Workflow processes. ', '-  You will build & validate models', '-  3+ years’ experience - Data Modeling and Evaluation', ' ', '-  2+ years’ experience – Building Machine Learning pipeline ( data ingestion, feature engineering, modeling including ensemble methods, predicting, explaining, deploying and diagnosing over fitting )', 'Education :', '-  1+ years’ experience - deep learning and neural nets (strong preference for experience with Keras)', '-  You will monitor & retrain models', 'Required Qualifications :', '-  2+ years’ experience - in applying supervised, unsupervised and semi-supervised learning techniques', 'At CVS Health, we are joined in a common purpose: helping people on their path to better health.  We are working to transform health care through innovations that make quality care more accessible, easier to use, less expensive and patient-focused. Working together and organizing around the individual, we are pioneering a new approach to total health that puts people at the heart.', '-  You will ensure implemented solutions within production meet design requirement']",Mid-Senior level,Full-time,Analyst,Hospital & Health Care,2020-11-05 11:32:32
Applied Scientist,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Conducting and coordinating process development leading to improved and streamlined processes for model development. Strong customer focus is essential', ' Working closely with Product Managers to expand depth of our product insights with data, create a variety of experiments, and determine the highest-impact projects to include in planning roadmaps', 'Preferred Qualifications', ' Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve search matching and ranking problems, including filtering, new content indexing, and apply document understanding', 'Company', ' Work well in a fast-moving team environment and effectively deliver technical implementations having complex dependencies and requirements.', 'Basic Qualifications', ' Proficiency in model development, model validation and model implementation.', 'Description', ' Being a cultural leader that ensures teams are collecting, understanding, and using data to inform every decision that impacts our customers', ' Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve search matching and ranking problems, including filtering, new content indexing, and apply document understanding Conducting and coordinating process development leading to improved and streamlined processes for model development. Strong customer focus is essential Working closely with Product Managers to expand depth of our product insights with data, create a variety of experiments, and determine the highest-impact projects to include in planning roadmaps Providing technical and scientific guidance to your team members Communicating effectively with senior management as well as with colleagues from science, engineering, and business backgrounds Being a cultural leader that ensures teams are collecting, understanding, and using data to inform every decision that impacts our customers', ' Proven track in leading, mentoring, and growing teams of scientists', ' Significant peer reviewed scientific contributions in premier journals and conferences', ' 7+ years of hands-on experience applying theoretical models in an applied environment', ' Hands on experience with scripting languages such as Python, Perl', ' 7+ years of hands-on experience applying theoretical models in an applied environment Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, deep learning, Natural Language Processing, recommendation systems, dialogue systems, informational retrieval Significant peer reviewed scientific contributions in premier journals and conferences Proven track in leading, mentoring, and growing teams of scientists Experience with digital media, online advertising or retail Proven ability to work effectively in a cross-functional team Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts', ' Communicating effectively with senior management as well as with colleagues from science, engineering, and business backgrounds', ' At least 2+ years hands on experience programming in R, Java, C#, C++ or other similar programming languages', ' Providing technical and scientific guidance to your team members', ' PHD/MS. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field At least 5+ years of hands-on experience in predictive modeling and analysis Proficiency in model development, model validation and model implementation. At least 2+ years hands on experience programming in R, Java, C#, C++ or other similar programming languages Hands on experience with scripting languages such as Python, Perl Work well in a fast-moving team environment and effectively deliver technical implementations having complex dependencies and requirements.', ' Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, deep learning, Natural Language Processing, recommendation systems, dialogue systems, informational retrieval', ' Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts', 'Responsibilities Include', ' Experience with digital media, online advertising or retail', ' Proven ability to work effectively in a cross-functional team', ' At least 5+ years of hands-on experience in predictive modeling and analysis', ' PHD/MS. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
"AI Research scientist: up to $350,000 base+equity",Apptronic Labs,"Austin, Texas Metropolitan Area",6 hours ago,Be among the first 25 applicants,"['', 'Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Ideal candidates would be able to rapidly iterate on new ideas with engineers, potentially publish at top conferences and be able to write code.', 'Responsibilities:', 'We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'We are looking for people who have done research / published papers in one of the following areas: Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Candidates will need to have a PhD preferably in Artificial Intelligence or Machine Learning.\xa0', 'Job Description:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. We have also previously been founders and early employees at startups. We are backed by Eric Schmidt and Decibel Ventures with Series A funding of $18 million. We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'General Requirements:', 'Required Skills:', 'Responsible for coming up with new techniques in unsupervised learning, dataset augmentation and deep reinforcement learning that can be applied to automating various parts of the AI development workflow.']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Data Scientist(Healthcare Exp a Plus!),Optello,"Washington, DC",2 hours ago,Be among the first 25 applicants,"['', 'Multiple Years Experience With The Following', ' Data efficiency', ' Apply statistical means and methods to be able to use data more efficiently, ideally in a SaaS environment Structure data sets Apply advanced statistical modeling to create relational models between data', 'Optello is proud to be an Equal Opportunity Employer', ' Apply statistical means and methods to be able to use data more efficiently, ideally in a SaaS environment', ' Relational models', ' Statistical Modeling', 'Email Your Resume In Word To', ' Data structuring', ' Relational Database', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : CD3-1608080 -- in the email subject line for your application to be considered.***', ' Apply advanced statistical modeling to create relational models between data', 'Your Right to Work', ' Structure data sets', ' Data structuring Statistical Modeling Relational models Relational Database Data efficiency']",Entry level,Full-time,Engineering,Construction,2020-11-05 11:32:32
Data Scientist Online Course,N/A,"Essex, VT",13 hours ago,Be among the first 25 applicants,"['', 'Different scripting languages necessary for this role, including Java, Python, Javascript, Ruby, and using the command line interface.', 'Big data topics including data architecture as well as techniques and tools for analysis, streaming and visualization.', 'Various platform technologies, including Windows and Linux, and virtualization.', 'Data and data structures, as well as relational and non-relational data types.']",Entry level,Part-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Senior Data Scientist, Machine Learning",GoHealth,"Chicago, IL",20 hours ago,Be among the first 25 applicants,"['', 'Medical, dental, vision, and life insurance benefits', ' Open vacation policy because work life balance is important 401k program with company match Employee Stock Purchase Program Medical, dental, vision, and life insurance benefits Paid maternity and paternity leave Professional growth opportunities Generous employee referral bonuses Employee Resource Groups Work from Home Stipend GoHealth is an Equal Opportunity Employer ', 'Benefits And Perks', 'Expertise in applying common machine learning algorithms such as Linear Regression, Random Forests, XGBoost.', 'Proficient in Python and related libraries, such as Pandas, Numpy, Scikit-Learn, TensorFlow, Pytorch', 'Responsibilities', 'Stay current with leading edge systems, methods, and best practices for data science and analytics; and introduce technology and process changes across the organization', ""Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities’ and the CDC."", 'Lead quantitative analyses with product management, partners, and data engineers in solving problems', 'Work from Home Stipend', 'Employee Resource Groups', '401k program with company match', "" Master's in Statistics, Mathematics, Computer Science, or related quantitative field 5+ years of experience demonstrating trajectory of professional growth in software engineering, data science, or data engineering Proficient in Python and related libraries, such as Pandas, Numpy, Scikit-Learn, TensorFlow, Pytorch Expertise in applying common machine learning algorithms such as Linear Regression, Random Forests, XGBoost. Experience deploying real-time prediction models. Experience working with Scrum and other Agile methodologies, and Version control systems such as Git or Bitbucket "", ""Collaborate on improvements to team operations and delivery on GoHealth's goals"", 'Generous employee referral bonuses', 'Experience working with Scrum and other Agile methodologies, and Version control systems such as Git or Bitbucket', 'Find new ways to combine data that do not naturally mesh together', 'Frequently cited statistics show that women and underrepresented groups apply to jobs only if they meet 100% of the qualifications. GoHealth encourages you to break that statistic and to apply. No one ever meets 100% of the qualifications. We look forward to your application. ', 'Conduct business and technical presentations to our teams', 'Skills And Experience', 'Paid maternity and paternity leave', '5+ years of experience demonstrating trajectory of professional growth in software engineering, data science, or data engineering', ""Master's in Statistics, Mathematics, Computer Science, or related quantitative field"", "" Lead quantitative analyses with product management, partners, and data engineers in solving problems Conduct business and technical presentations to our teams Find new ways to combine data that do not naturally mesh together Stay current with leading edge systems, methods, and best practices for data science and analytics; and introduce technology and process changes across the organization Improve the collaboration around actual performance and forecast to directly improve our actions Collaborate on improvements to team operations and delivery on GoHealth's goals "", 'Experience deploying real-time prediction models.', 'Employee Stock Purchase Program', 'Open vacation policy because work life balance is important', 'GoHealth is an Equal Opportunity Employer', 'Professional growth opportunities', 'Improve the collaboration around actual performance and forecast to directly improve our actions']",Associate,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
"AI Research scientist: up to $350,000 base+equity",Scovios,"Austin, Texas Metropolitan Area",8 hours ago,Be among the first 25 applicants,"['', 'Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Ideal candidates would be able to rapidly iterate on new ideas with engineers, potentially publish at top conferences and be able to write code.', 'Responsibilities:', 'We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'We are looking for people who have done research / published papers in one of the following areas: Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Candidates will need to have a PhD preferably in Artificial Intelligence or Machine Learning.\xa0', 'Job Description:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. We have also previously been founders and early employees at startups. We are backed by Eric Schmidt and Decibel Ventures with Series A funding of $18 million. We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'General Requirements:', 'Required Skills:', 'Responsible for coming up with new techniques in unsupervised learning, dataset augmentation and deep reinforcement learning that can be applied to automating various parts of the AI development workflow.']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Quantitative User Experience Researcher,Robinhood,"Menlo Park, CA",6 hours ago,Be among the first 25 applicants,"['', ' Proactively and independently identifying high-impact questions from a product or business perspective Answering those questions with a strong command of quantitative methods – especially by using behavioral data analysis and advanced survey methodology Planning and leading research end to end, including strategic and evaluative research Developing data dashboards that are actionable for researchers, designers, PMs, and other stakeholders Representing the voice of the user throughout the product development process, working closely with data scientists, PMs, designers, engineers, and leadership Clearly communicating your research insights for teams to translate research findings to product and business impact Contributing to the development of a data-driven understanding of Robinhood users and potential users ', 'About The Company', 'Proactively and independently identifying high-impact questions from a product or business perspective', 'Answering those questions with a strong command of quantitative methods – especially by using behavioral data analysis and advanced survey methodology', 'R and/or Python', 'Your Day-to-day Will Involve', 'Quantitative survey methodology training and experience including MaxDiff and Conjoint techniques', 'Developing data dashboards that are actionable for researchers, designers, PMs, and other stakeholders', '4-8+ years of quantitative research experience; it can either be industry-only, or a combination of industry experience and academic research', ' SQL (advanced queries) R and/or Python Quantitative survey methodology training and experience including MaxDiff and Conjoint techniques 4-8+ years of quantitative research experience; it can either be industry-only, or a combination of industry experience and academic research Master’s or Ph.D. in Data Science, Marketing Science, Human-Computer Interaction, Statistics, Psychology, Sociology, Behavioral Economics, Political Science, or similar Record of applying your research skills to create product and business impact Strong work ethic, excellent organization and communication skills Love and care for your craft ', 'Planning and leading research end to end, including strategic and evaluative research', 'Passion for working and learning in a fast-growing company', ' Passion for working and learning in a fast-growing company ', 'Record of applying your research skills to create product and business impact', 'Strong work ethic, excellent organization and communication skills', 'Master’s or Ph.D. in Data Science, Marketing Science, Human-Computer Interaction, Statistics, Psychology, Sociology, Behavioral Economics, Political Science, or similar', 'About The Role', 'Love and care for your craft', 'Contributing to the development of a data-driven understanding of Robinhood users and potential users', 'Clearly communicating your research insights for teams to translate research findings to product and business impact', 'SQL (advanced queries)', 'Some Things We Consider Critical For This Role', 'Representing the voice of the user throughout the product development process, working closely with data scientists, PMs, designers, engineers, and leadership', 'Bonus Points']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer,Insight,"Columbus, OH",14 hours ago,Be among the first 25 applicants,"['', 'APPLY', 'We are looking for an experienced Senior Data Engineer ', 'Aggressively grow your skillset and expertise to meet emerging needs', 'Analysis Services (SSAS) and DAX', 'Scripting: PowerShell, Azure Automation', '5+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)1+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Fortune Top 100 Best Companies for Diversity', '30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizesMicrosoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOpsFortune Top 100 Best Companies for DiversityFortune Top 50 Best Workplaces in TechnologyWinner of several “Best Places to Work” awards30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Predictive Analytics: R, Azure Machine Learning ', 'Prioritize, self-direct and execute at velocity', 'some', 'Fortune Top 50 Best Workplaces in Technology', 'Skill at translating requirements into clean, efficient, quality code ', 'Strong analytical and reasoning skills that result in clear technical execution', 'About Insight', 'Lead discussions with clients and recommend technical solutions for business cases', '1+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity', 'Winner of several “Best Places to Work” awards', 'Integration Services (SSIS)', 'Design and code modern solutions to tough data challenges leveraging the cloud and ', 'Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data Factory', 'Development Languages: .NET, Java or Scala', 'most', 'SQL Server', 'Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team', 'Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externally', 'Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Design and develop cutting-edge enterprise data solutions in a fast-paced environmentLead discussions with clients and recommend technical solutions for business casesDesign and code modern solutions to tough data challenges leveraging the cloud and Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externallyPrioritize, self-direct and execute at velocityAggressively grow your skillset and expertise to meet emerging needs', 'Reporting Tools: Power BI, Tableau, Qlik, SSRS ', 'SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizes', 'Azure Big Data Technologies: Azure Data Lake and Azure Data Lake Analytics', 'Design and develop cutting-edge enterprise data solutions in a fast-paced environment', 'What We Do', 'What We Look For', 'Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity5+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)1+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or ScalaStrong analytical and reasoning skills that result in clear technical executionSkill at translating requirements into clean, efficient, quality code Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team', 'Requisition Number: 78955 ', 'Ready to join?', 'SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)1+ year of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Big Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystem', 'What can Insight offer?', 'Microsoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOps']",Mid-Senior level,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
PhD Data Engineer,Procter & Gamble,"Cincinnati, OH",9 hours ago,Be among the first 25 applicants,"['', ' Support and collaborate with Data Scientists developing advanced machine learning and statistical models. ', ' History of working independently and effectively multi-tasking. ', ' Familiarity with RESTful APIs, containers and microservices. ', 'Description', ' A PhD in Computer Science, Computer or Electrical Engineering or a related field. ', ' Strong interpersonal communication and collaboration skills. ', 'Experience with cloud services (AWS, Azure or GCP).', ' Strong data wrangling skills. ', 'Qualifications', ' Strong interpersonal communication and collaboration skills.  History of working independently and effectively multi-tasking.  Familiarity with machine learning workflows (desirable).  Have experience with sensors and IoT cloud architecture (desirable).  Familiarity with RESTful APIs, containers and microservices.  Familiarity with data privacy and data governance.  Experience with NoSQL databases. ', ' Have experience with sensors and IoT cloud architecture (desirable). ', ' Familiarity with machine learning workflows (desirable). ', ' Strong problem-solving skills paired with extensive experience programming (Python, Java, C++, etc). ', ' Develop and maintain scalable data pipelines that will ingest, transform, and distribute numerous data streams and batches in support of key R&D initiatives.  Support and collaborate with Data Scientists developing advanced machine learning and statistical models.  Evaluate tools and develop pipelines to capture, integrate and clean data to support edge analytics solutions.  Deliver optimal data solution architectures, automation and technology choices starting from experimentation through proof of concept and often through delivery. ', ' Develop and maintain scalable data pipelines that will ingest, transform, and distribute numerous data streams and batches in support of key R&D initiatives. ', ' Familiarity with data privacy and data governance. ', ' Experience with NoSQL databases. ', ' Deliver optimal data solution architectures, automation and technology choices starting from experimentation through proof of concept and often through delivery. ', ' A PhD in Computer Science, Computer or Electrical Engineering or a related field.  Strong problem-solving skills paired with extensive experience programming (Python, Java, C++, etc).  Strong data wrangling skills.  Hands on experience with relational databases and the use of SQL to extract and manipulate data. Experience with cloud services (AWS, Azure or GCP).', 'The Ideal Candidate', ' Hands on experience with relational databases and the use of SQL to extract and manipulate data. ', ' Evaluate tools and develop pipelines to capture, integrate and clean data to support edge analytics solutions. ']",Not Applicable,Full-time,Research,Consumer Goods,2020-11-05 11:32:32
Tableau Consultant,Accenture,"Denver, CO",10 hours ago,Be among the first 25 applicants,"['', 'You know your way around other data visualization toolsets such as Qlikview or Spotfire ', 'Here’s What You Need: ', 'Minimum of 2 year’s experience designing or developing with Tableau, including dashboards, reports, and/or front-end visualizations ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', 'You’re familiar with Business Intelligence tools including Cognos, Business Objects, OBIEE, methodologies, and/or responsibilities ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'You’re no newbie to Data Platforms such as Teradata, IBM, TM1, Netezza, DataMirror, Oracle, Essbase, GoldenGate, EMS, Greenplum', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Experience with database development including Custom SQL design, PLSQL, and/or Data Modeling ', 'Accenture Overview', 'Bonus Points If:', 'Equal Employment Opportunity:', 'Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'You’ve had experience with, or exposure to custom data visualization frameworks such as d3.js ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Accenture is committed to providing veteran employment opportunities to our service men and women. ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'You’ve got experience of full life-cycle development in a BI or Analytics environment ', 'The Work:', 'You Are:', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Business Development,Information Technology and Services,2020-11-05 11:32:32
"Senior Data Scientist, Ad Platforms-Data Insights",Apple,"Cupertino, CA",5 hours ago,63 applicants,"['', 'Description', 'Key Qualifications', 'Education & Experience', 'Summary']",Not Applicable,Full-time,Other,Consumer Electronics,2020-11-05 11:32:32
Staff Research Scientist,Upstart,"San Mateo, CA",4 hours ago,Be among the first 25 applicants,"['', 'Full-stack expertise with all steps of the modeling process from ideation to productionalizing code; OR deep expertise in either statistical modeling or machine learning', 'Strong sense of intellectual curiosity balanced with humility, drive and teamwork', 'Programming skills in Python and/or R', 'The Team', 'Enthusiasm for and alignment with Upstart’s mission and values', ' Competitive compensation (base + bonus & equity) Comprehensive medical, dental, and vision coverage Personal development and technology & ergonomic budgets  Life insurance and disability benefits  Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams)  Generous vacation policy 401(k) retirement plan Catered lunches + snacks & drinks ', 'Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams) ', 'The Role', '401(k) retirement plan', '5+ years relevant experience with detailed understanding of building good technical solutions; ability to convert ideas into testable hypotheses and/or next steps', 'Competitive compensation (base + bonus & equity)', 'What You’ll Love', 'What We’re Looking For', 'Numerically-savvy and smart with ability to operate at a speedy pace', 'Comprehensive medical, dental, and vision coverage', 'Life insurance and disability benefits ', 'Generous vacation policy', "" Strong academic credentials with a master's degree in computer science, statistics, mathematics, or other quantitative areas of study; Ph.D. preferred 5+ years relevant experience with detailed understanding of building good technical solutions; ability to convert ideas into testable hypotheses and/or next steps Programming skills in Python and/or R Full-stack expertise with all steps of the modeling process from ideation to productionalizing code; OR deep expertise in either statistical modeling or machine learning Knowledge of machine learning, pipelines and engineering architecture helpful Interest in growing in technical and/or people leadership is a plus Enthusiasm for and alignment with Upstart’s mission and values Strong sense of intellectual curiosity balanced with humility, drive and teamwork Numerically-savvy and smart with ability to operate at a speedy pace "", 'Knowledge of machine learning, pipelines and engineering architecture helpful', 'Personal development and technology & ergonomic budgets ', 'Catered lunches + snacks & drinks', 'Interest in growing in technical and/or people leadership is a plus', ""Strong academic credentials with a master's degree in computer science, statistics, mathematics, or other quantitative areas of study; Ph.D. preferred""]",Associate,Full-time,Other,Computer Software,2020-11-05 11:32:32
Sonar Algorithm Researcher,Systems & Technology Research,"Woburn, MA",19 hours ago,Be among the first 25 applicants,"['', 'Participate in preparation of proposals, plans and schedules. ', 'Algorithm development for sonar detection and tracking algorithms (beamforming, spectral estimation, detection processing)', 'Active Security Clearance at the Secret or Top Secret (TS) level', ' Interest and aptitude for working on large, complex technical projects and teams Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects Scientific curiosity and creativity Knowledge of one or more of the following topic areas: Signal processing  Tracking Estimation Control Marine robotics Cooperative navigation   Active Security Clearance at the Secret or Top Secret (TS) level ', 'Interest and aptitude for working on large, complex technical projects and teams', 'Description', 'Marine robotics', 'Tracking', 'Strong scientific programming skills in MATLAB, Python, and/or C/C++', 'Estimation', 'Desired Qualifications', 'Developing and implementing algorithms using at-sea collected data and iterate to improve performance', 'Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects', 'US Citizenship with the ability to obtain a Security Clearance', 'Cooperative navigation', 'Participate in at-sea data collections including experiment design and analysis of collected data', 'Scientific curiosity and creativity', 'Requirements', 'PhD or MS degree with research experience in underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field', 'Required Qualifications', 'Control', ' Algorithm development for sonar detection and tracking algorithms (beamforming, spectral estimation, detection processing) Developing and implementing algorithms using at-sea collected data and iterate to improve performance Participate in at-sea data collections including experiment design and analysis of collected data Participate in preparation of proposals, plans and schedules.  ', 'Responsibilities Include', ' Signal processing  Tracking Estimation Control Marine robotics Cooperative navigation ', 'Knowledge of one or more of the following topic areas: Signal processing  Tracking Estimation Control Marine robotics Cooperative navigation  ', 'Algorithm Research Engineer', ' US Citizenship with the ability to obtain a Security Clearance PhD or MS degree with research experience in underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field Strong scientific programming skills in MATLAB, Python, and/or C/C++ ', 'Signal processing ']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Contract - Data Engineer - Python and Spark,CyberCoders,"San Francisco, CA",22 hours ago,Be among the first 25 applicants,"['', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Supportive Team and Management', ' Fun and Exciting Projects! Supportive Management! Great Pay!', 'Your Right to Work', ' Supportive Management!', 'Nice To Haves', ' Great Pay!', ' Python and Spark Creating and maintaining data ingestion pipelines', 'Email Your Resume In Word To', ' Competitive Pay', ' AWS Big Data technologies like Glue, S3, and RedShift', ' Flexibility', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : TR4-1608331 -- in the email subject line for your application to be considered.***', ' Python and Spark', ' Fun and Exciting Projects!', ' Creating and maintaining data ingestion pipelines', ' Competitive Pay Supportive Team and Management Flexibility']",Mid-Senior level,Full-time,Information Technology,Management Consulting,2020-11-05 11:32:32
"Senior Researcher, Tobacco",Fors Marsh Group,"Arlington, VA",4 hours ago,Be among the first 25 applicants,"['', 'FMG is seeking an experienced, intelligent and motivated scientist for our Health Communication Research Team, to lead and manage a range of research projects in support of health communication research related to tobacco prevention and cessation.', 'Oversee and guide preparation of research reports and presentation decks and other external communications summarizing research methods, findings and strategic implications for marketing strategies and advertising messaging.', 'Quantitative proficiency\xa0and experience working with data in Microsoft Excel® and at least one statistical analysis software package (e.g., SPSS, STATA, SAS, R). Experience writing code/syntax preferred', 'We Offer:', 'Master’s degree in communication, marketing, social science, or related field. PhD preferred but not required.Experience working with FDA, NCI, CDC, or other government entities on tobacco social science research strongly preferredMinimum of twelve years of professional research experience required with at least three years of experience in a senior project role, preferably in a consulting organization.Proven publication record and thought leadership on tobacco prevention and cessationQuantitative proficiency\xa0and experience working with data in Microsoft Excel® and at least one statistical analysis software package (e.g., SPSS, STATA, SAS, R). Experience writing code/syntax preferredExperience with qualitative study design, data collection and analysis; experience with qualitative software (e.g., NVIVO) preferred. Formal moderation training (e.g., RIVA) a plus.\xa0Communications-related research and/or experience working with advertising agencies or marketing firms preferredExperience balancing multiple concurrent projects including management of project timelines, budget and scope in fast-paced environments working on tight deadlines.Experience successfully managing project budget and resources is required; doing so in time and materials contracts preferred.High degree of team orientation, as well as ability to work independently under minimal supervision to effectively balance and manage personal workload.Demonstrated experience managing complex client and/or stakeholder relationships and maintaining high satisfaction.Demonstration of strong verbal and written communications skills and ability to produce high-quality, accurate deliverables and presentations.Applicants may be subject to a low-level government security investigation and must meet eligibility criteria for access to sensitive information.', 'Minimum of twelve years of professional research experience required with at least three years of experience in a senior project role, preferably in a consulting organization.', 'Successful individuals in this role will thrive in a fast-paced deadline-driven and highly collaborative environment. Additionally, comfort with ambiguous and evolving nature of projects is a central component of this role.\xa0', 'Communications-related research and/or experience working with advertising agencies or marketing firms preferred', 'Oversee and guide the conduct of univariate and multivariate analyses; analyze and interpret results from descriptive and inferential quantitative analyses.', 'Specific duties include providing the above technical expertise, team management (workplan development and management, delegating work across a team, setting clear expectations of quality, providing clear feedback, coaching, and mentoring to foster growth and development among researchers), budget management, developing and overseeing quality control including review and approval of deliverables, managing client relationships and assisting senior leadership in determining the overall approach to a project. The individual should be equally comfortable with delegating tasks and implementing directly.', 'Selected individuals will work in a senior research role providing subject matter expertise on tobacco regulatory social science and tobacco-related communications, overseeing multiple research studies using various methodologies (e.g., focus group discussions, in-depth interviews, cognitive testing, surveys, segmentation, secondary data analysis, literature reviews, environmental scans, eye tracking, and facial expression tracking) and audiences (e.g. youth, young adults, racial/ethnic minorities, sexual and gender minorities, people who use tobacco products who wish to quit) to inform marketing, communication, and regulations. The Individual will function as a SME, project manager, and supervisor.', 'Contribute subject matter expertise and thought leadership on tobacco prevention and cessation as well as campaign development and evaluation', 'Contribute to the planning, coordination, design, execution, and interpretation of social-psychological, social persuasion and/or behavior change studies across a variety of quantitative and qualitative methodologies.', 'Lead and direct client and partner engagement, project meetings and presentations.', 'Proven publication record and thought leadership on tobacco prevention and cessation', 'A highly collegial and intellectually stimulating work environment', 'Oversee and guide preparation of written proposals for research in response to RFPs.', 'Demonstration of strong verbal and written communications skills and ability to produce high-quality, accurate deliverables and presentations.', 'Responsibilities include:', 'High degree of team orientation, as well as ability to work independently under minimal supervision to effectively balance and manage personal workload.', 'Demonstrated experience managing complex client and/or stakeholder relationships and maintaining high satisfaction.', 'Highly competitive benefit/compensation package', 'Master’s degree in communication, marketing, social science, or related field. PhD preferred but not required.', 'Significant growth opportunities', 'Contribute subject matter expertise and thought leadership on tobacco prevention and cessation as well as campaign development and evaluationContribute to the planning, coordination, design, execution, and interpretation of social-psychological, social persuasion and/or behavior change studies across a variety of quantitative and qualitative methodologies.Oversee and guide preparation of research reports and presentation decks and other external communications summarizing research methods, findings and strategic implications for marketing strategies and advertising messaging.Oversee and guide the conduct of interviews, focus group discussions, and other methods to collect qualitative data.Oversee and guide the conduct of univariate and multivariate analyses; analyze and interpret results from descriptive and inferential quantitative analyses.Oversee and guide the analysis and interpretation of results from qualitative research studies (e.g., thematic analysis, NVIVO.)Interact with project team, including the FMG Research Director, FMG Research Advisors, Senior leadership and advertising agency/client teams on a day-to-day basis working under tight deadlines to fulfill requests.Lead and direct client and partner engagement, project meetings and presentations.Oversee and guide preparation of written proposals for research in response to RFPs.Lead, coach, and mentor junior- to mid-level researchers.\xa0', 'Qualifications:', 'Experience working with FDA, NCI, CDC, or other government entities on tobacco social science research strongly preferred', 'Experience balancing multiple concurrent projects including management of project timelines, budget and scope in fast-paced environments working on tight deadlines.', 'Significant growth opportunitiesA highly collegial and intellectually stimulating work environmentOpportunities to participate in high quality research and influence decision making among government leadersHighly competitive benefit/compensation package', 'Lead, coach, and mentor junior- to mid-level researchers.\xa0', 'Experience successfully managing project budget and resources is required; doing so in time and materials contracts preferred.', 'Oversee and guide the analysis and interpretation of results from qualitative research studies (e.g., thematic analysis, NVIVO.)', 'Interact with project team, including the FMG Research Director, FMG Research Advisors, Senior leadership and advertising agency/client teams on a day-to-day basis working under tight deadlines to fulfill requests.', 'At Fors Marsh Group (FMG), we combine the power of science and strategy to improve people’s lives. Each day, we work with institutions and organizations that seek to disrupt markets, understand and influence behavior, drive action on a national scale, and create positive impact. Our approach extends far beyond our client portfolio—as a certified B Corporation and a 2020 Greenbook Top 50 Market Research Company, we make a difference in our community through corporate-sponsored employee volunteer programs and pro bono partnerships with values-aligned nonprofits. Most importantly, as a 2019 Washington Post Top Workplace, we are committed to putting people first and foster a culture that reflects that commitment. We are proud to be an equal opportunity employer, and we celebrate diversity and inclusivity as the foundation of a healthy, successful, and innovative work environment. Join us, and together we can work to ensure a better tomorrow.\xa0', 'Experience with qualitative study design, data collection and analysis; experience with qualitative software (e.g., NVIVO) preferred. Formal moderation training (e.g., RIVA) a plus.\xa0', 'Oversee and guide the conduct of interviews, focus group discussions, and other methods to collect qualitative data.', 'Applicants may be subject to a low-level government security investigation and must meet eligibility criteria for access to sensitive information.', 'Opportunities to participate in high quality research and influence decision making among government leaders']",Not Applicable,Full-time,Research,Research,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"New York, NY",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Remote Sr. Data Engineer (Python/GCP),Cypress HCM,San Francisco Bay Area,23 hours ago,Be among the first 25 applicants,"['', 'Knowledge of Git, Jinja2, Docker(containerization), Bitbucket, and Bamboo ', 'Responsibilities:', 'Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud ', 'Preferred: ', 'Required', '*Must be able to work EST hours*', 'Requirements:', 'Google Cloud Certified - Professional Data Engineer certification would be a plus ', 'Strong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow or Google Composer) ', 'Strong communication & interpersonal skills ', 'Preferred:', 'Perform data integration related work for the company which includes Ad stack Tech integration, BI continuity and other data integration required for running our business Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery Develop and promote best practices in data engineering Develop real-time data processing applications using Google Cloud Be part of the on-call rotation supporting our SLA’s Participate in design and code reviews ', 'Develop real-time data processing applications using Google Cloud ', '5+ years of hands-on experience working in data engineering environment ', 'Advanced SQL programming skills - Ability to write complex SQL to perform common types of analysis and aggregations ', 'Familiar with version control systems (Git and Bitbucket) ', 'Requirements: ', 'Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery ', 'Familiar with Atlassian products Jira and Confluence ', 'Can-do attitude on problem-solving, quality and ability to execute ', 'Google Cloud Certified - Professional Data Engineer certification would be a plus Knowledge of Git, Jinja2, Docker(containerization), Bitbucket, and Bamboo Familiar with a NoSQL database such as MongoDB Familiar with version control systems (Git and Bitbucket) Familiar with Atlassian products Jira and Confluence Hands-on experience with Apache Airflow or Google Composer Knowledge of Application Programming Interfaces ', 'Required: ', ""Bachelor's degree in Computer Science or equivalent experience in a related field "", 'Be part of the on-call rotation supporting our SLA’s ', 'Develop and promote best practices in data engineering ', 'The role of the Senior Data Engineer is responsible for building and maintaining optimized and highly available data pipelines that facilitate deeper analysis and reporting. This engineer’s duty is to monitor the existing metrics, analyze data, and lead partnerships with other Data and Analytics teams in an effort to identify and implement systems and process improvements. This engineer also designs, architects, implements, and supports key datasets. ', 'Experience with Apache Airflow or Google Composer ', 'Perform data integration related work for the company which includes Ad stack Tech integration, BI continuity and other data integration required for running our business ', 'Strong proficiency in Python with an emphasis in building data pipelines ', 'Knowledge of Application Programming Interfaces ', 'Experience developing data solutions on GCP (airflow experience) ', 'Familiar with a NoSQL database such as MongoDB ', 'Hands-on experience with Apache Airflow or Google Composer ', ""Bachelor's degree in Computer Science or equivalent experience in a related field 5+ years of hands-on experience working in data engineering environment Strong proficiency in Python with an emphasis in building data pipelines Advanced SQL programming skills - Ability to write complex SQL to perform common types of analysis and aggregations Experience developing data solutions on GCP (airflow experience) Experience with Apache Airflow or Google Composer Can-do attitude on problem-solving, quality and ability to execute Strong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow or Google Composer) Strong communication & interpersonal skills "", 'Responsibilities: ', '\xa0 ', 'Participate in design and code reviews ']",Mid-Senior level,Contract,Engineering,Computer Software,2020-11-05 11:32:32
Senior Designer/Researcher (Remote Work Available),USAA,"San Antonio, TX",22 hours ago,Be among the first 25 applicants,"['', 'Preferred Requirements', 'not', 'Real Estate or Fintech domain knowledge and understanding of sales funnel and conversion optimization', 'Relocation', 'Excellent written and verbal communication skills, interpersonal skills, time management skills and strong attention to detail.', ""Identifies and manages existing and emerging risks that stem from business activities and the job role.Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.Follows written risk and compliance policies and procedures for business activities.Supports design team in defining business problems, design requirements, and demonstrate a solution's potential success for moderately complex projects.Co-facilitates a cross-functional understanding of business problems and potential design solutions using human-centered design sessions and group discussions to achieve actionable outcomes.Navigates multiple workstreams from discovery to implementation, balancing efforts, priorities, and partnerships for each.Guides the development and facilitation of human-centered research efforts, the synthesis of research findings and the generation of insights.Works autonomously to create holistic member experiences leveraging extensive knowledge of interaction design, visual design, and/or content design.Articulates ideas and solutions using a range of storytelling techniques to inspire and compel audiences to align on direction.Mentors developing designers across the Chief Design Office. Provides constructive day-to-day feedback and guidance to team members.Applies advanced understanding of human-centered and service design practices and leverages multiple methods to solve complex design problems.Stays abreast of current digital and mobile technology trends, in the area of application architecture with best practices within the digital development ecosystem"", 'Ensures risks associated with business activities are effectively identified, measured, monitored, and controlled.', 'Articulates ideas and solutions using a range of storytelling techniques to inspire and compel audiences to align on direction.', 'Demonstrated experience designing user interfaces for web and mobile applications (iOS, Android, etc.)', 'Guides the development and facilitation of human-centered research efforts, the synthesis of research findings and the generation of insights.', 'Highly organized, with the ability to work on multiple projects/task at once while managing a diverse group of employees.', 'Works autonomously to create holistic member experiences leveraging extensive knowledge of interaction design, visual design, and/or content design.', 'Follows written risk and compliance policies and procedures for business activities.', 'A portfolio that demonstrates extensive experience designing digital experiences for mobile and web-based applications.', 'Bachelor’s Degree or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree (10+ years of experience in lieu of degree).6 years of relevant, on-the-job experience in a Product Design, UX Design, Service Design or Design Research role delivering complex design systems for web and native applications.Highly organized, with the ability to work on multiple projects/task at once while managing a diverse group of employees.Extensive experience designing and supporting digital products inside an Agile environment using human-centered design principles, methods and problem-solving strategies.A portfolio that demonstrates extensive experience designing digital experiences for mobile and web-based applications.Demonstrated ability to work fluently in standard applications, including Sketch, InVision (or comparable prototyping tools), Adobe CC and Microsoft Office Suite.Advanced facilitation, collaboration and consensus-building skills, with extensive experience in presenting to cross-functional terms and Senior/Executive leaders.Excellent written and verbal communication skills, interpersonal skills, time management skills and strong attention to detail.Demonstrated advanced understanding of new technologies and best practices in website navigation, browsers, mobile patterns, information architecture and usability.Demonstrated experience designing user interfaces for web and mobile applications (iOS, Android, etc.)Demonstrates a strategic mindset by decomposing complex problems into a clear and achievable workstream requiring limited support and direction for decision making.', 'Extensive experience designing and supporting digital products inside an Agile environment using human-centered design principles, methods and problem-solving strategies.', 'Advanced facilitation, collaboration and consensus-building skills, with extensive experience in presenting to cross-functional terms and Senior/Executive leaders.', 'Demonstrated experience using behavioral and/or transactional data to help prioritize design efforts.', 'Mentors developing designers across the Chief Design Office. Provides constructive day-to-day feedback and guidance to team members.', '6 years of relevant, on-the-job experience in a Product Design, UX Design, Service Design or Design Research role delivering complex design systems for web and native applications.', 'Working knowledge of Accessibility principles and guidelines; experience creating inclusive designs.', ""Supports design team in defining business problems, design requirements, and demonstrate a solution's potential success for moderately complex projects."", 'BOUT USAA', 'About Usaa’s Chief Design Office', 'Experience working with internal design systems, component libraries, web application frameworks.', 'Identifies and manages existing and emerging risks that stem from business activities and the job role.', '3+ years of experience planning and conducting both qualitative and quantitative design research. Experience should include establishing recruitment criteria/screening, creating protocols/interview guides, conducting test/interview sessions, identifying top-level findings and documenting recommendations.Demonstrated experience using behavioral and/or transactional data to help prioritize design efforts.Experience working with internal design systems, component libraries, web application frameworks.Working knowledge of Accessibility principles and guidelines; experience creating inclusive designs.Real Estate or Fintech domain knowledge and understanding of sales funnel and conversion optimization', 'Bachelor’s Degree or 4 additional years of related experience beyond the minimum required may be substituted in lieu of a degree (10+ years of experience in lieu of degree).', 'available', 'Co-facilitates a cross-functional understanding of business problems and potential design solutions using human-centered design sessions and group discussions to achieve actionable outcomes.', '3+ years of experience planning and conducting both qualitative and quantitative design research. Experience should include establishing recruitment criteria/screening, creating protocols/interview guides, conducting test/interview sessions, identifying top-level findings and documenting recommendations.', 'Demonstrates a strategic mindset by decomposing complex problems into a clear and achievable workstream requiring limited support and direction for decision making.', 'Stays abreast of current digital and mobile technology trends, in the area of application architecture with best practices within the digital development ecosystem', 'Demonstrated ability to work fluently in standard applications, including Sketch, InVision (or comparable prototyping tools), Adobe CC and Microsoft Office Suite.', 'Tasks', 'Minimum Requirements', 'Applies advanced understanding of human-centered and service design practices and leverages multiple methods to solve complex design problems.', 'Demonstrated advanced understanding of new technologies and best practices in website navigation, browsers, mobile patterns, information architecture and usability.', 'Navigates multiple workstreams from discovery to implementation, balancing efforts, priorities, and partnerships for each.']",Not Applicable,Full-time,Design,Financial Services,2020-11-05 11:32:32
Senior Principal Data Scientist [Dialogue Management/Conversational AI],LivePerson,Greater Seattle Area,10 hours ago,44 applicants,"['Faceted unsupervised learning -- how can we inject knowledge into unsupervised tasks? How can we inject knowledge into clustering/similarity tasks to reflect facets we care about (intent) and orthogonalize irrelevant facets?', ""LivePerson was named to Fast Company's World’s most innovative companies of 2020 list for the Artificial Intelligence category. We offer top tier tech & data science colleagues, along with opportunities to push your own limits. We embrace invention and experimentation. You’ll have great benefits, flexible time off, plus snacks and drinks to keep your mind fresh and stomach full. Most importantly, you’ll have an ability to make an impact at work and at brands across the globe as we build the future with trusted Conversational AI together.\xa0"", 'You can operate in a fast paced, dynamic environmentYou can advance the SOTA in dialogue systems with experiments and code that are well-designed and well-implemented.You can build partnerships that move our business forwardYou see feedback or failure as motivation to learn and to growYou believe data-driven decision making is the normYou relate to our core principles (link) and want to work with Conversational AI experts', 'Learning NLP systems using self-supervision from unannotated dialogue - Leveraging latent structure within task-oriented dialogue data to solve classification and dialogue problems more accurately and label-efficiently.Faceted unsupervised learning -- how can we inject knowledge into unsupervised tasks? How can we inject knowledge into clustering/similarity tasks to reflect facets we care about (intent) and orthogonalize irrelevant facets?Lightly/distantly supervised dialog management ML systems - How can we utilize self-supervision and reinforcement learning to learn representations of conversational goals and policies from unlabelled historical conversations in a goal-oriented setting?Controllable natural language generation -- How can we build adaptable natural language generation systems that can be easily controlled/configured?', 'You will thrive here if: ', 'Demonstrated capacity to work closely with teammates in a highly collaborative environment, as well as providing strong individual contributions', 'Expertise in NLP techniques to solve problems in dialogue management: either direct experience in dialogue systems OR experience in reinforcement learning', 'You relate to our core principles (link) and want to work with Conversational AI experts', 'Work with one of the world’s largest goal-oriented conversational data sets to push the boundaries of computational linguistics and drive innovative new products at scale.', 'Preferred qualifications:', '\xa0', 'In addition to a world-class data set, you’ll also have an at-scale population of expert data annotators (contact center agents) to help drive investigation and learning.', 'Learning NLP systems using self-supervision from unannotated dialogue - Leveraging latent structure within task-oriented dialogue data to solve classification and dialogue problems more accurately and label-efficiently.', 'Publish and present cutting-edge research derived from our conversational data', 'You can advance the SOTA in dialogue systems with experiments and code that are well-designed and well-implemented.', 'You believe data-driven decision making is the norm', 'All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.', 'Some areas of research of particular interest:', 'We are an innovative, intent-driven company that believes in building the future and we are looking for growth minded, unconventional thinkers, developers and builders to join the team.\xa0', 'Propose and execute research efforts that drive product strategy', 'You can build partnerships that move our business forward', 'Degree in Computational Linguistics, Computer Science, Statistics, or Mathematics', 'LivePerson is a transformational force in how brands and consumers communicate. With over 18,000 brands, including HSBC, Disney, Verizon, and Home Depot, we are on a mission to make life easier for people and brands everywhere through trusted Conversational AI. We believe in a future where conversations are the norm for getting your intentions fulfilled - whatever they are.\xa0\xa0', 'You can operate in a fast paced, dynamic environment', 'Record of publications in competitive journals/conferences in the field, such as EMNLP, ACL, ICLR, NIPS, NAACL.', 'Writing Python code that is efficient and clean in a Linux environment', 'Your qualifications are:', 'Develop state of the art approaches to unsupervised/semi-supervised problems in intent and dialog management.', 'Controllable natural language generation -- How can we build adaptable natural language generation systems that can be easily controlled/configured?', '3-5 years post-graduate experience in ML, specifically in NLU/NLP', 'Lightly/distantly supervised dialog management ML systems - How can we utilize self-supervision and reinforcement learning to learn representations of conversational goals and policies from unlabelled historical conversations in a goal-oriented setting?', 'Why you’ll love working here:', 'Proven track record of problem-solving, communication, and critical-thinking skills', 'Experience with Python packages for Machine Learning (Scikit-Learn), NLP (SpaCy), and Deep Learning (Pytorch)', 'You see feedback or failure as motivation to learn and to grow', 'At LivePerson, people from diverse backgrounds come together to do their best work and be their authentic selves. We are proud to be an equal opportunity employer. ', 'Degree in Computational Linguistics, Computer Science, Statistics, or Mathematics3-5 years post-graduate experience in ML, specifically in NLU/NLPExpertise in NLP techniques to solve problems in dialogue management: either direct experience in dialogue systems OR experience in reinforcement learningTrack record of applied research on NLP or related fields, e.g. NLU, NLG, ASR/TTS and/or experience with dialogue systemsWriting Python code that is efficient and clean in a Linux environmentExperience with Python packages for Machine Learning (Scikit-Learn), NLP (SpaCy), and Deep Learning (Pytorch)Proven track record of problem-solving, communication, and critical-thinking skillsDemonstrated capacity to work closely with teammates in a highly collaborative environment, as well as providing strong individual contributions', 'Why you’ll love working here:\xa0', 'In this role you will:', 'Track record of applied research on NLP or related fields, e.g. NLU, NLG, ASR/TTS and/or experience with dialogue systems', 'Work with one of the world’s largest goal-oriented conversational data sets to push the boundaries of computational linguistics and drive innovative new products at scale.In addition to a world-class data set, you’ll also have an at-scale population of expert data annotators (contact center agents) to help drive investigation and learning.Propose and execute research efforts that drive product strategyPublish and present cutting-edge research derived from our conversational dataApply cutting-edge methods of NLP/NLU to learn and derive value from one of the world’s largest goal-oriented conversational data sets.Develop state of the art approaches to unsupervised/semi-supervised problems in intent and dialog management.', 'Apply cutting-edge methods of NLP/NLU to learn and derive value from one of the world’s largest goal-oriented conversational data sets.']",Director,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
UX Researcher,Creative Circle,"San Jose, CA",6 hours ago,Be among the first 25 applicants,"['', 'BA/BS in Computer Science, Human-Computer Interaction, Cognitive Science,Experimental Psychology, Anthropology, Information Science with 2 years of equivalent practical experience. OR Masters degree with internship.Experienced at survey design and analysis (descriptive statistics only).', 'BA/BS in Computer Science, Human-Computer Interaction, Cognitive Science,', 'Experienced at survey design and analysis (descriptive statistics only).', 'Ideal Qualifications', 'Support ongoing UX research work. Survey design, analysis, writing detailed reports.Work with other researchers, designers, product managers, engineers in a fast-paced, rapidly changing environment.Understand and incorporate complex technical and business requirements into research.', 'Understand and incorporate complex technical and business requirements into research.', 'Work with other researchers, designers, product managers, engineers in a fast-paced, rapidly changing environment.', 'Support ongoing UX research work. Survey design, analysis, writing detailed reports.', 'Top Responsibilities', 'Experimental Psychology, Anthropology, Information Science with 2 years of equivalent practical experience. OR Masters degree with internship.']",Associate,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
Research Scientist (electro-optical systems),KLA,"Milpitas, CA",6 hours ago,Be among the first 25 applicants,"['', ' Group/Division ', 'Qualifications', 'We offer a competitive, family friendly total rewards package. We design our programs to reflect our commitment to an inclusive environment, while ensuring we provide benefits that meet the diverse needs of our employees. ', 'KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com to request accommodation.', 'Minimum Qualifications', 'Company Overview']",Mid-Senior level,Full-time,Other,Electrical/Electronic Manufacturing,2020-11-05 11:32:32
Lead UX Researcher,ServiceNow,"San Diego, CA",21 hours ago,Be among the first 25 applicants,"['', 'Experience working with Enterprise IT software (e.g., ServiceNow, Microsoft, Oracle, Salesforce, PeopleSoft), ideally a background in Application Platform as a Service (PaaS) or Software as a Service (SaaS) applications.Expertise in one or more of the following product spaces: IT Security Management, IT Operations Management, Security Operations, HR Service Delivery, Customer Service Management (CSM), or Finance & Legal.Awareness of Mobile and web application design experience across various platforms (iOS, Android, Windows) including demonstrating an understanding of responsive web design.Advanced degree in the Human-Computer Interaction, Human Factors, Cognitive Psychology, or other related degrees.', 'Work directly with external vendors to procure research sample, research reports, and partner on research projects as needed.', 'Analyze and synthesize data in order to generate strategic and tactical insights with actionable recommendations that drive product improvements, innovations, and customer experience improvements.', 'Knowledge of user interface design principles, usability evaluation techniques, perception, cognition, task analysis, experimental design and fundamental knowledge of statistics to best inform useful and usable recommendations.', 'Experience facilitating workshops', 'Advanced degree in the Human-Computer Interaction, Human Factors, Cognitive Psychology, or other related degrees.', 'We provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.', 'Work collaboratively inside a cross-functional team, effectively integrating your research into the product definition and design phases.', 'Experience working with Enterprise IT software (e.g., ServiceNow, Microsoft, Oracle, Salesforce, PeopleSoft), ideally a background in Application Platform as a Service (PaaS) or Software as a Service (SaaS) applications.', 'Up to 20% annually', 'Influence architectural design tasks such as user flows, information architecture definition, wireframing, etc. with the aim of communicating design opportunities to the broader Design and Product teams.', 'Execute various types of primary research and analysis, from early discovery, usage and needs, through product design validation.', 'Expertise in one or more of the following enterprise product spaces: IT Security Management, IT Operations Management, Security Operations, HR Service Delivery, Customer Service Management (CSM), or Finance & Legal', 'Expertise in one or more of the following product spaces: IT Security Management, IT Operations Management, Security Operations, HR Service Delivery, Customer Service Management (CSM), or Finance & Legal.', '7+ years of direct experience or equivalent combination of education and experience in user experience, product, customer, or academic research. Preferably for product development purposes.Proven history of independently defining, planning and executing research strategies including defining objectives, goals, timelines and ability to select the appropriate methodology for the project. This includes developing sample plans and designing data collection instruments.Advanced knowledge of several data collection methods (either qualitative or quantitative) and fundamental knowledge of mixed methods.Can quickly understand customer needs, taking the initiative to interact with customers, managing expectations, responding to their requests, and communicating feedback in a simple, clear, and concise manner.Demonstrates confidence in the data collection process which is evidenced by the ability to naturally engage users and in the aptitude to respond with insightful follow-up questions which increases richness of research data.Knowledge of user interface design principles, usability evaluation techniques, perception, cognition, task analysis, experimental design and fundamental knowledge of statistics to best inform useful and usable recommendations.Exceptional written and oral communication abilities. Can prepare reports of findings, illustrating research data graphically and translating complex findings into written text. Experience working with and presenting research results to executive leadership (C-Level, director level).Willing to be proactive and take initiative to learn about ServiceNow products and customers.Ability to work independently on complex projects requiring frequent problem solving and critical thinking.', 'Staff (Lead) UX Researcher', 'Prepare reports of findings, create PowerPoint and Excel reports, explaining methods used and insights learned, and presenting research results to key stakeholders and leadership (C-Level, director level).', 'Willing to be proactive and take initiative to learn about ServiceNow products and customers.', 'Collaborate on feature definition and user story creation as needed.', 'Proven history of independently defining, planning and executing research strategies including defining objectives, goals, timelines and ability to select the appropriate methodology for the project. This includes developing sample plans and designing data collection instruments.', 'The Ideal Candidate Will Have The Following', 'Apply appropriate research techniques and methods for the specific project. Methods such as individual customer interviews, focus groups, diary studies, journey mapping, user flows, information architecture definition, wireframing and others to aid in the formulation of insights that improve product functionality and user experience.', 'An inspiring portfolio representing the process you follow to build Insanely Great ExperiencesDemonstration of any accessible projects you have builtWe provide competitive compensation, generous benefits and a professional atmosphere. This is a very collaborative and inclusive work environment where individuals strong on aptitude and attitude will have an opportunity to grow their professional careers through working with some of the most advanced technology and talented developers in the business.', 'Experience facilitating workshopsExpertise in one or more of the following enterprise product spaces: IT Security Management, IT Operations Management, Security Operations, HR Service Delivery, Customer Service Management (CSM), or Finance & LegalExperience in compliance to WCAG 2.0/2.1 AA guidelines', 'In order to be successful in this role, we need someone who has:', 'What we would love to see from you before or during an interview:', '7+ years of direct experience or equivalent combination of education and experience in user experience, product, customer, or academic research. Preferably for product development purposes.', 'Advanced knowledge of several data collection methods (either qualitative or quantitative) and fundamental knowledge of mixed methods.', 'Text analysis and coding of open-end responses which might include product feature requests, problem reports, discussion forums, and community discussions.', ""Represent the needs of ServiceNow customers or partners and their end users associated with ServiceNow's products, competing products, or future concepts.Collaborate with key stakeholders including designers, other researchers, and product managers to identify objectives, goals, timelines and research execution plan.Work directly with external vendors to procure research sample, research reports, and partner on research projects as needed.Execute various types of primary research and analysis, from early discovery, usage and needs, through product design validation.Apply appropriate research techniques and methods for the specific project. Methods such as individual customer interviews, focus groups, diary studies, journey mapping, user flows, information architecture definition, wireframing and others to aid in the formulation of insights that improve product functionality and user experience.Develop strategic research plans including discussion guides, contingency plans and other instruments from rough outline to the final version.Partner closely with Product Management to influence product strategy and roadmaps with validated user research findings.Collaborate on feature definition and user story creation as needed.Work collaboratively inside a cross-functional team, effectively integrating your research into the product definition and design phases.Influence architectural design tasks such as user flows, information architecture definition, wireframing, etc. with the aim of communicating design opportunities to the broader Design and Product teams.Text analysis and coding of open-end responses which might include product feature requests, problem reports, discussion forums, and community discussions.Analyze and synthesize data in order to generate strategic and tactical insights with actionable recommendations that drive product improvements, innovations, and customer experience improvements.Prepare reports of findings, create PowerPoint and Excel reports, explaining methods used and insights learned, and presenting research results to key stakeholders and leadership (C-Level, director level)."", 'Exceptional written and oral communication abilities. Can prepare reports of findings, illustrating research data graphically and translating complex findings into written text. Experience working with and presenting research results to executive leadership (C-Level, director level).', 'Ability to work independently on complex projects requiring frequent problem solving and critical thinking.', 'Can quickly understand customer needs, taking the initiative to interact with customers, managing expectations, responding to their requests, and communicating feedback in a simple, clear, and concise manner.', 'Partner closely with Product Management to influence product strategy and roadmaps with validated user research findings.', 'Develop strategic research plans including discussion guides, contingency plans and other instruments from rough outline to the final version.', 'Experience in compliance to WCAG 2.0/2.1 AA guidelines', 'What You Get To Do In This Role', 'Demonstration of any accessible projects you have built', ""Represent the needs of ServiceNow customers or partners and their end users associated with ServiceNow's products, competing products, or future concepts."", 'Awareness of Mobile and web application design experience across various platforms (iOS, Android, Windows) including demonstrating an understanding of responsive web design.', 'An inspiring portfolio representing the process you follow to build Insanely Great Experiences', 'Demonstrates confidence in the data collection process which is evidenced by the ability to naturally engage users and in the aptitude to respond with insightful follow-up questions which increases richness of research data.', 'Bonus Points', 'Travel:', 'Collaborate with key stakeholders including designers, other researchers, and product managers to identify objectives, goals, timelines and research execution plan.']",Associate,Full-time,Design,Information Technology and Services,2020-11-05 11:32:32
Data Engineer II,Amazon Web Services (AWS),"Seattle, WA",4 hours ago,82 applicants,"['', ' Identify, extract, and transform both structured and unstructured data collected from internal tools and systems', ' Promote best practices in creating storage solutions, persistence layers and presentation models', ' Ability to present metrics in a web rich environment using D3 (or C3)', ' Identify, extract, and transform both structured and unstructured data collected from internal tools and systems Promote best practices in creating storage solutions, persistence layers and presentation models Communicate with customers to ensure data is correctly understood and actionable Communicate with software teams and tool developers to expand and improve data collection Work with AWS leadership to present key findings from analyses to stakeholders Provide input on how best to measure the impact and progress of ongoing efforts', 'Preferred Qualifications', 'Company', ' Comfortable working in a Linux environment', 'Basic Qualifications', 'Description', ' Communicate with software teams and tool developers to expand and improve data collection', ' Meets/exceeds Amazon’s leadership principles requirements for this role.', "" Meets/Exceeds Amazon's leadership principles requirements for this role"", ' Committed to getting things done, and balance and prioritize multiple requests with high attention to detail.', ' Communicate with customers to ensure data is correctly understood and actionable', "" Meets/Exceeds Amazon's functional/technical depth and complexity for this role"", ' Demonstrated ability to influence and develop productive working relationships with resources and dependent teams', ' Experience with Spark (or Pandas)', "" Comfortable working in a Linux environment Proficient in Python development Experience with Spark (or Pandas) Experience with Flask and designing APIs Experience with Javascript (ideally familiar with frameworks such as Vue, React, or Angular) Ability to present metrics in a web rich environment using D3 (or C3) Committed to getting things done, and balance and prioritize multiple requests with high attention to detail. Experience developing with AWS services (S3, EMR, Lambda, Glue, Athena, SNS, Cloudwatch, Redshift, Aurora/RDS) Knowledge of workflow management systems, like luigi, oozie, or custom made ones Writing code as part of a team, with code reviews, testing, deployment and documentation Demonstrated ability to influence and develop productive working relationships with resources and dependent teams Excellent verbal/written communication & data presentation skills, including ability to succinctly summarize key findings and effectively communicate with both business and technical teams. Meets/Exceeds Amazon's leadership principles requirements for this role Meets/Exceeds Amazon's functional/technical depth and complexity for this role Meets/exceeds Amazon’s leadership principles requirements for this role."", ' Bachelor’s Degree in Computer Science, Information Systems, Mathematics, Statistics, Finance, Business, related field or equivalent working experience', ' Writing code as part of a team, with code reviews, testing, deployment and documentation', ' Experience with Flask and designing APIs', ' 2+ Experience in using SQL to articulate data in a database or data warehouse and be able to use a major programming (e.g. Java/C) and/or a scripting language (Perl, Unix shell) to process data for modeling', ' Bachelor’s Degree in Computer Science, Information Systems, Mathematics, Statistics, Finance, Business, related field or equivalent working experience 2+ Experience in using SQL to articulate data in a database or data warehouse and be able to use a major programming (e.g. Java/C) and/or a scripting language (Perl, Unix shell) to process data for modeling', ' Work with AWS leadership to present key findings from analyses to stakeholders', ' Experience developing with AWS services (S3, EMR, Lambda, Glue, Athena, SNS, Cloudwatch, Redshift, Aurora/RDS)', ' Excellent verbal/written communication & data presentation skills, including ability to succinctly summarize key findings and effectively communicate with both business and technical teams.', 'Key Responsibilities', ' Knowledge of workflow management systems, like luigi, oozie, or custom made ones', ' Provide input on how best to measure the impact and progress of ongoing efforts', ' Experience with Javascript (ideally familiar with frameworks such as Vue, React, or Angular)', ' Proficient in Python development']",Mid-Senior level,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
Senior Applied Researcher - Search Content,eBay,"San Jose, CA",17 hours ago,Be among the first 25 applicants,"['', '- Experience with Python or R, and Java or Scala.\xa0', 'We are looking for stellar applied researchers to join us and build the next generation of content understanding technologies in eBay search. If you enjoy the scale and technical complexity of NLP problems and want to be at the frontier of applied research in information retrieval in e-commerce, join now.', 'Basic Qualifications', '- Work through others as a technical leader to drive vision, define and standardize methodologies, establish processes, and operationalize machine learning solutions across teams and projects', 'eBay Inc. is an equal opportunity employer.\xa0 All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status.\xa0 If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com.\xa0 We will make every effort to respond to your request for disability assistance as soon as possible.', 'View our accessibility info', 'accessibility info', '- Experience in big data processing, e.g. Hadoop, SQL, Spark', '- Strong Industrial experience with one or more of the following: classification, regression, recommendation systems, targeting systems, ranking systems, fraud detection, online advertising, or related', '- Seek scientific solutions to multiple complex and ambiguous problems by crafting a technical vision and driving consensus across teams', 'This website uses cookies to enhance your experience. By continuing to browse the site, you agree to our\xa0use of cookies', '- Present key technical and novel research work in public forums and conferences', 'For more information see:', '- 2 or more related publications in quality conferences or journals', 'Looking to make an impact on the future of global commerce? Do you want to shape how millions of people buy, sell, and engage around the world?', '- Think through complex research problems, simplify where necessary, invent when needed, to drive a principled vision from thought to reality', '- Mentor junior team members', 'EEO is the Law Poster', 'Job Responsibilities', 'View our privacy policy', 'The Search Content, Item and Inventory Understanding team is part of the biggest organization that drives eBay’s world-wide impact. We innovate at the heart of ecommerce search, with the ambitious goal of redefining ecommerce search. We craft optimized experiences for buyers and sellers on eBay. We innovate rapidly in this space and there is no shortage of new challenges for motivated individuals.', '- 5-8 years (with PhD) or 8-12 years (with MS) of industrial experience in a related field', 'EEO is the Law Poster Supplement', '- MS or PhD in Computer Science, Statistics, Mathematics, or equivalent']",Mid-Senior level,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Sr. Python / AWS Developer - AI,Cognizant,"Chicago, IL",5 hours ago,Be among the first 25 applicants,"['', 'Create and maintain optimal data pipeline architecture, Assemble large, sophisticated data sets that meet functional / non-functional business requirements.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Cognizant is an Equal Opportunity Employer M/F/D/V', 'Responsibilities', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big data’ technologies.', '1+ Years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra. ', 'Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', 'Create and maintain optimal data pipeline architecture, Assemble large, sophisticated data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big data’ technologies.Build analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency and other key business performance metrics.Work with partners including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Build analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency and other key business performance metrics.', '1+ years of experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift ', '3+ years of experience (Mid-level) Strong Programming experience with object-oriented/object function scripting languages: Python/Scala, Spark.', 'Qualifications', 'Experience with stream-processing systems: Storm, Spark-Streaming, etc. (Nice to have) ', '3+ years of experience (Mid-level) Experience with big data tools: Hadoop, Apache Spark, Kafka, etc ', 'About Cognizant', 'Company Description', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.', 'Work with partners including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.', 'Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.3+ years of experience (Mid-level) Strong Programming experience with object-oriented/object function scripting languages: Python/Scala, Spark.3+ years of experience (Mid-level) Experience with big data tools: Hadoop, Apache Spark, Kafka, etc 1+ years of experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift Experience with stream-processing systems: Storm, Spark-Streaming, etc. (Nice to have) 1+ Years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra. ']",Associate,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Senior CNO Researcher,ManTech,"Hanover, MD",7 hours ago,Be among the first 25 applicants,"['', 'Secure our Nation, Ignite your Future', 'Understanding of network protocols (TCP/IP stacks, wire level protocols, RF communications, BGP, routing protocols, or others)', 'Experience using reverse engineering tools such as IDA Pro, Binary Ninja, or Ghidra', 'Performs applied research and development to analyze, design, and identify desired programmatic behaviors.', 'Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.', 'Preferred Qualifications', 'Experience using debuggers such as gdb, WinDbg, OllyDbg', 'Needs to occasionally move about inside the office to access file cabinets, office machinery, etc.', 'Basic Qualifications', 'Must be able to remain in a stationary position 50%.', 'Experience reading and/or writing assembly (x86, x64, ARM, MIPS, SPARC, 68k, PPC, or others)', 'Minimum of two years’ experience in technology/tools specific to the target platforms.', 'Security Clearance Requirements', 'Understanding of exploit mitigations such as DEP and ASLR', 'May be asked to move Audio/Visual or Computer equipment', 'Requires Bachelor’s degree or equivalent and five to seven years of related experience.', 'Requires Bachelor’s degree or equivalent and five to seven years of related experience.Minimum of two years’ experience in technology/tools specific to the target platforms.', 'Frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations.', 'Often positions self to maintain computers in the lab, including under the desks and in the server closet.', 'Must be able to remain in a stationary position 50%.Needs to occasionally move about inside the office to access file cabinets, office machinery, etc.Constantly operates a computer and other office productivity machinery, such as a calculator, copy machine and computer printer.Often positions self to maintain computers in the lab, including under the desks and in the server closet.Frequently communicates with co-workers, management and customers, which may involve delivering presentations. Must be able to exchange accurate information in these situations.May be asked to move Audio/Visual or Computer equipment', 'Provides daily guidance to other CNO Researchers on similar projects. Expert reverse engineering skills in hardware or software for the purpose of understanding and/or vulnerability discovery (e.g. heap sprays, ROP gadgets, DEP, ASLR, or CFG defeats).', 'Expert knowledge of programming languages such as C, Assembly, and Python.', 'Designs, develops, documents, tests and debugs applications software and systems that contain logical and mathematical solutions. Determines system capabilities based upon output requirements, input data acquisition, and programming.', 'Responsibilities Include, But Are Not Limited To', 'TS/SCI with Polygraph', 'Experience performing software vulnerability research', 'Experience with modern source control (e.g., git, Atlassian, or similar)', 'Developed specialized knowledge in at least one technology area (e.g. Windows, Linux, UNIX, Mobile, Network devices). Contributes to the completion of milestones associated with specific projects. Provides solutions to a variety of complex technical problems.', 'Performs applied research and development to analyze, design, and identify desired programmatic behaviors.Designs, develops, documents, tests and debugs applications software and systems that contain logical and mathematical solutions. Determines system capabilities based upon output requirements, input data acquisition, and programming.Ensures software standards are met. Independently performs static and dynamic analysis applying research tools such as disassemblers, debuggers, and fuzzers.Provides daily guidance to other CNO Researchers on similar projects. Expert reverse engineering skills in hardware or software for the purpose of understanding and/or vulnerability discovery (e.g. heap sprays, ROP gadgets, DEP, ASLR, or CFG defeats).Expert knowledge of programming languages such as C, Assembly, and Python.Developed specialized knowledge in at least one technology area (e.g. Windows, Linux, UNIX, Mobile, Network devices). Contributes to the completion of milestones associated with specific projects. Provides solutions to a variety of complex technical problems.', 'Understanding of low-level OS internals', 'Ensures software standards are met. Independently performs static and dynamic analysis applying research tools such as disassemblers, debuggers, and fuzzers.', 'Experience developing device drivers', 'Physical Requirements', 'Experience performing software vulnerability researchUnderstanding of low-level OS internalsExperience reading and/or writing assembly (x86, x64, ARM, MIPS, SPARC, 68k, PPC, or others)Understanding of network protocols (TCP/IP stacks, wire level protocols, RF communications, BGP, routing protocols, or others)Understanding of exploit mitigations such as DEP and ASLRExperience using reverse engineering tools such as IDA Pro, Binary Ninja, or GhidraExperience using debuggers such as gdb, WinDbg, OllyDbgExperience developing device driversExperience with modern source control (e.g., git, Atlassian, or similar)', ' Senior CNO Researcher ']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer - Information Security,Riot Games,"Los Angeles, CA",47 minutes ago,Be among the first 25 applicants,"['', 'Experience with ELK', 'Our Perks', 'Work with Analysts to determine and implement the best practices for data retention and storage', 'Responsibilities', 'Experience with systems for data processing (Spark, Flink, Hadoop, Airflow) and storage (S3, Kafka, ElasticSearch, Dynamo, MySQL, or Postgres)', ' Experience with systems for data processing (Spark, Flink, Hadoop, Airflow) and storage (S3, Kafka, ElasticSearch, Dynamo, MySQL, or Postgres) Experience with ELK Experience reading and optimizing data schema queries for content and performance Experience working in agile project management methodologies (Scrum, Kanban) ', 'Senior Data Engineer', 'Work with engineers on the team to manage infrastructure for moving and processing large-scale data', 'Design and promote standards for security operations data telemetry and processing', '2+ years experience with open source ETL frameworks such as Airflow, Luigi, or similar', 'Experience reading and optimizing data schema queries for content and performance', 'Experience working in agile project management methodologies (Scrum, Kanban)', '2+ years experience with Spark or Hadoop', '4+ years experience with Python and SQL', ""It’s our policy to provide equal employment opportunity for all applicants and members of Riot Games, Inc. Riot Games makes reasonable accommodations for handicapped and disabled Rioters and does not unlawfully discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, handicap, veteran status, marital status, criminal history, or any other category protected by applicable federal and state law, including the City of Los Angeles’ Fair Chance Initiative for Hiring Ordinance relating to an applicant's criminal history (LAMC 189.00)."", ' Create and promote a technical design and architectural vision for security operations data systems and tooling Work with engineers on the team to manage infrastructure for moving and processing large-scale data Improve log flows efficiency through data processing to reduce the cost of analysis and storage Convert log flows from Logstash to Elastic Common Schema Work with Analysts to determine and implement the best practices for data retention and storage Design and promote standards for security operations data telemetry and processing Help engineers across the team select data technologies for their development needs Be the face of data best-practices to engineers on the team around the product by advocating for data considerations early in the product life cycle and educating teammates on how to get the most out of Riot data ecosystem. ', 'Desired Qualifications', 'Bachelor’s degree in Computer Science or related field', 'Help engineers across the team select data technologies for their development needs', 'Required Qualifications', 'Be the face of data best-practices to engineers on the team around the product by advocating for data considerations early in the product life cycle and educating teammates on how to get the most out of Riot data ecosystem.', 'Create and promote a technical design and architectural vision for security operations data systems and tooling', ' 2+ years experience working with data systems 2+ years experience with data warehousing, processing, pipelines, infrastructure, and query patterns 2+ years experience with Spark or Hadoop 2+ years experience with open source ETL frameworks such as Airflow, Luigi, or similar 4+ years experience with Python and SQL Bachelor’s degree in Computer Science or related field ', 'Convert log flows from Logstash to Elastic Common Schema', '2+ years experience working with data systems', 'Improve log flows efficiency through data processing to reduce the cost of analysis and storage', '2+ years experience with data warehousing, processing, pipelines, infrastructure, and query patterns']",Not Applicable,Full-time,Information Technology,Computer Games,2020-11-05 11:32:32
Radiative Properties - Postdoctoral Researcher,ClearedJobs.Net,"Livermore, CA",8 hours ago,Be among the first 25 applicants,"['', 'Join us and make YOUR mark on the World!', ' Conduct research on atomic physics, radiative properties of hot, dense matter, inertial confinement fusion, high energy density physics, x-ray source development or laboratory astrophysics.', ' Publish research results in peer-reviewed scientific or technical journals and present results at external conferences, seminars and/or technical meetings.', ' Guide the design and performance of experiments and conduct new experiments.', '2020 Best Places to ', ' Design, develop, calibrate, and deploy x-ray spectrometers and x-ray spectroscopic techniques for the purpose of studying the physics of high-temperature plasmas and radiative processes.', ' Experience with experimental spectroscopy including calibration, instrument design and fielding, data unfolding.', 'About Us', ' Experience with performing experience at large facilities such as Z, OMEGA,', ' Perform other duties as assigned.', 'Pre-Employment Drug Test:', 'Desired Qualifications', ' Experience working on a research team with individuals from diverse technical backgrounds, as well as function as an independent researcher with a high level of attention to details.', 'Security Clearance: ', ' Proficient verbal and written communication skills necessary to work in a multidisciplinary team environment, author technical and scientific reports and publications and deliver scientific presentations.', 'Qualifications', ' Experience with analyzing x-ray or optical images.', ' Documented publication record in peer-reviewed literature and /or experience presenting research results to a large audience.', 'Note: ', 'Essential Duties', ' Experience in using spectral analysis codes to understand measured optical or x-ray spectra.', ' Ability to perform independent research, find innovative solutions and produce significant accomplishments to complex scientific and technical problems.', 'Work by Glassdoor!']",Entry level,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Data Science Intern,Pinterest,"San Francisco, CA",7 hours ago,27 applicants,"['', ' Dive into the code base on your very first day Work on high impact projects and help build the future of Pinterest Collaborate with engineers across our organization to build new features from scratch Continually grow both professionally and personally through various learning and development opportunities ', ' Currently pursuing a degree in a quantitative field Preferred candidates are pursuing advanced degrees in statistics, math, economics, applied sciences, or computer science Experience using Python or R; SQL a plus Excellent communication skills and the ability to tell a complete narrative using data to a variety of audiences Ability to connect data analysis to real business problems, in order to impact business performance Must be graduating December 2021 or later', 'What You’ll Do', 'Continually grow both professionally and personally through various learning and development opportunities', 'Experience using Python or R; SQL a plus', 'Work on high impact projects and help build the future of Pinterest', 'Dive into the code base on your very first day', 'Excellent communication skills and the ability to tell a complete narrative using data to a variety of audiences', 'Currently pursuing a degree in a quantitative field', 'Collaborate with engineers across our organization to build new features from scratch', 'What We’re Looking For', 'Preferred candidates are pursuing advanced degrees in statistics, math, economics, applied sciences, or computer science', 'Ability to connect data analysis to real business problems, in order to impact business performance', 'Must be graduating December 2021 or later', 'About Pinterest']",Internship,Internship,Other,Internet,2020-11-05 11:32:32
"Travel Medical Tech - $1,850 per week",NurseFly,"Healdsburg, CA",24 hours ago,Be among the first 25 applicants,"['', ' 401(k) and Flex Spending', ' Refer a friend and earn extra cash!', 'Specialty: Medical TechDiscipline: Allied Health ProfessionalStart Date: 11/09/2020Duration: 13 weeks40.00 hours per weekShift: 8 hours, daysEmployment Type: Travel', '40.00 hours per week', 'Medical Tech', '13 weeks', 'About The Company', 'Allied Health Professional', 'Preferred Qualifications', 'Duration: 13 weeks', 'About Med Travelers', 'Discipline: Allied Health Professional', 'Facility Location', '11/09/2020', '  Competitive pay rates  Medical, Dental, Vision  401(k) and Flex Spending  Life Insurance  Accident and Short-term Disability Coverage  Free Continuing Education  Free Private Housing  Refer a friend and earn extra cash! ', 'Travel', ' Free Continuing Education', ' Life Insurance', ' Competitive pay rates', ' Medical, Dental, Vision', '8 hours, days', 'Job Description & Requirements', 'Required Qualifications', 'Start Date: 11/09/2020', ' Accident and Short-term Disability Coverage', 'Job Benefits', ' Free Private Housing', 'Employment Type: Travel', 'Shift: 8 hours, days', 'Specialty: Medical Tech']",Not Applicable,Temporary,Other,Staffing and Recruiting,2020-11-05 11:32:32
Senior Data Scientist,Microsoft,"Redmond, WA",3 hours ago,Be among the first 25 applicants,"['', '5+ years’ hands-on experience with one or more statistical software like R, Python, SAS, etc.\u202f', '5+ years’ experience with statistical, ML or data mining algorithms for real world problems.\u202f', 'Advanced data visualization experience', 'Bachelors, M.S or Ph.D. in Computer Science, Data Science, Economics/Econometrics, Statistics, Operations Research, or a similar quantitative field\u202f\u202fSolid foundation understanding of core data science concepts, statistical modeling, machine learning algorithms and experimental design\u202f5+ years’ experience with statistical, ML or data mining algorithms for real world problems.\u202f5+ years’ hands on experience with advanced ML techniques for classification, regression, recommendations, or pattern recognition. 5+ years’ hands-on experience with one or more statistical software like R, Python, SAS, etc.\u202f5+ years’ hands-on experience with one or more query languages like SQL3+ years’ experience with developing and operationalizing product metrics', 'Responsibilities', 'Able to coach and mentor other data scientists for technical and product skills. Enables others to deliver high quality deliverables with increased throughput.', 'Experience working on devices or subscription business', '3+ years’ experience with developing and operationalizing product metrics', '5+ years’ hands on experience with advanced ML techniques for classification, regression, recommendations, or pattern recognition. ', 'Partner with PM, engineering, research and other data scientists to formulate data-driven answers to business and decision-making problems, applying a wide variety of analytical and modeling techniques ', 'Software development in one or more language like C#', 'Software development in one or more language like C#Experience working on devices or subscription businessAdvanced data visualization experience', 'Solid foundation understanding of core data science concepts, statistical modeling, machine learning algorithms and experimental design\u202f', 'Qualifications', 'Applies (or develops if necessary) tools and pipelines to efficiently collect, clean, and prepare massive volumes of data for analysis.\u202f', 'Applying appropriate statistical and machine learning techniques to generate insights', 'Validates, monitors, and drives continuous improvement to methods, and proposes enhancements to data sources that improve usability and results.\u202f\u202f', 'Partner with PM, engineering, research and other data scientists to formulate data-driven answers to business and decision-making problems, applying a wide variety of analytical and modeling techniques Applies (or develops if necessary) tools and pipelines to efficiently collect, clean, and prepare massive volumes of data for analysis.\u202fApplying appropriate statistical and machine learning techniques to generate insightsPresent findings and recommendations to key decision makers at various management levelsValidates, monitors, and drives continuous improvement to methods, and proposes enhancements to data sources that improve usability and results.\u202f\u202fAble to coach and mentor other data scientists for technical and product skills. Enables others to deliver high quality deliverables with increased throughput.', 'Bachelors, M.S or Ph.D. in Computer Science, Data Science, Economics/Econometrics, Statistics, Operations Research, or a similar quantitative field\u202f\u202f', '5+ years’ hands-on experience with one or more query languages like SQL', 'Present findings and recommendations to key decision makers at various management levels']",Not Applicable,Full-time,Other,Computer Hardware,2020-11-05 11:32:32
Data Engineer/Analyst - HEDIS Data,CVS Health,"Phoenix, AZ",4 hours ago,Be among the first 25 applicants,"['', 'Fundamental Components', 'exposure to XML', 'Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.', 'Percent Of Travel Required', 'Builds data marts and data models to support Data Science and other internal customers.', 'Key data contact to assigned health plans2-3 yrs experience with SQL and HEDIS data extract builds working knowledge of HEDIS supplemental data, it use, and extract creationWrites ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processing.NCQA HEDIS specification core knowledge preferred Collaborates with data science team to transform data and integrate algorithms and models into automated processes.exposure to XMLBuilds data marts and data models to support Data Science and other internal customers.Experiments with available tools and advises on new tools in order to determine optimal solution given the requirements dictated by the model/use case.Develops large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs.Experience with HEDIS engines preferred', 'Background Experience', 'Education', 'working knowledge of HEDIS supplemental data, it use, and extract creation', 'Experience with HEDIS engines preferred', 'Writes ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processing.', '2-3 yrs experience with SQL and HEDIS data extract builds ', 'Experiments with available tools and advises on new tools in order to determine optimal solution given the requirements dictated by the model/use case.', 'Business Overview', 'Job Description', 'Collaborates with data science team to transform data and integrate algorithms and models into automated processes.', 'NCQA HEDIS specification core knowledge preferred ', 'Key data contact to assigned health plans', 'We Provide Primary Support To 16 Medicaid Health Plans, Including Analytics, Data Submission, NCQA And State Medicaid HEDIS Submissions Key Job Components Are']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Scientist,Amazon,"Seattle, WA",4 hours ago,148 applicants,"['', ' 3+ years of experience working in data science in a consumer product company, managing Machine Learning Scientists, Data Scientists, Research Scientists, Applied Scientists, and/or Economists', ' Experience using a scripting language for managing large datasets', 'Preferred Qualifications', 'Company', ' Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes', 'Basic Qualifications', 'Description', ' A PhD in a quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)', 'The Key Strategic Objectives For This Role Include', ' Automating feedback loops for algorithms in production.', ' Helping to build production systems that take inputs from multiple models and make decisions in real time.', ' Utilizing Amazon systems and tools to effectively work with terabytes of data.', ' Understanding drivers, impacts, and key influences on Pricing dynamics.', ' Ability to quickly adapt to changing priorities and generate innovative solutions in an extremely fast-paced environment', ' Understanding drivers, impacts, and key influences on Pricing dynamics. Optimizing Pricing to improve the customer experience and grow Amazon’s business. Drive actions at scale to provide low prices and increased selection for customers using scientifically-based methods and decision making frameworks. Helping to build production systems that take inputs from multiple models and make decisions in real time. Automating feedback loops for algorithms in production. Utilizing Amazon systems and tools to effectively work with terabytes of data.', ' Functional knowledge of AWS platforms such as S3, Glue, Athena, Sagemaker.', ' Advanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar Databases', ' Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts.', ' Masters in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent) 3+ years of experience working in data science in a consumer product company, managing Machine Learning Scientists, Data Scientists, Research Scientists, Applied Scientists, and/or Economists Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes Experience using a scripting language for managing large datasets Ability to quickly adapt to changing priorities and generate innovative solutions in an extremely fast-paced environment Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts.', ' Optimizing Pricing to improve the customer experience and grow Amazon’s business.', ' A PhD in a quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent) Skilled with Java, C++, or other programming language, as well as with R, SAS, MATLAB, Python or similar scripting language Advanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar Databases Functional knowledge of AWS platforms such as S3, Glue, Athena, Sagemaker. Experience leading cross-functional projects and effectively communicating with both business and technical teams', ' Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives', ' Experience leading cross-functional projects and effectively communicating with both business and technical teams', ' Skilled with Java, C++, or other programming language, as well as with R, SAS, MATLAB, Python or similar scripting language', ' Drive actions at scale to provide low prices and increased selection for customers using scientifically-based methods and decision making frameworks.', ' Masters in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)']",Not Applicable,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
"Machine Learning Engineer: up to $250,000 base+equity",Apptronic Labs,"San Francisco, CA",7 hours ago,Be among the first 25 applicants,"['', 'Responsibilities:', 'Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher level abstractions for various common AI/ML techniques.', 'Candidates will need to have a BS or MS from top notch CS programs with industry experience. We are looking for machine learning software engineers who have experience building at least one of the following: ML/AI models which are in production New neural network algorithms based on research papers Low level performance optimization of deep learning systems Machine learning platforms', 'Company Description:', 'Job Description:', 'General Requirements:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. They have also previously been founders and early employees at startups. We raised $18 million in Series A from Decibel Ventures and Eric Schmidt. We are looking for talented machine learning software engineers, systems software engineers and research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Machine Learning Engineer - R&D | Facial Recognition,Optello,"Calabasas, CA",2 hours ago,Be among the first 25 applicants,"['', ' Experience with regression testing', 'Optello is proud to be an Equal Opportunity Employer', ' Small, close-knit team', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : BL1-1585288 -- in the email subject line for your application to be considered.***', ' Work cross-organizationally with multiple teams / individuals', ' 401(K)', ' EQUITY', ' Assist in our product technology development Design and implement integration and testing Help to develop techniques and strategies to ensure system dynamics are performing optimally, and to ensure client deliverables are being met Work cross-organizationally with multiple teams / individuals', ' Experience with facial recognition algorithms or machine learning', "" Bachelor's, Master's, or PhD in relevant field of study"", ' Experience with LiDAR', ' Competitive base salary EQUITY Medical, Dental, and Vision 401(K) PTO Small, close-knit team Brilliant leadership team We are one of the leaders in our field of study Great office location! Great company culture Much more!', 'HUGE Bonus Points If You Have The Following', ' Help to develop techniques and strategies to ensure system dynamics are performing optimally, and to ensure client deliverables are being met', ' Small, diverse, and BRILLIANT team of scientists, engineers, and PhDs!', ' Experience with profiling and benchmarking', ' Competitive base salary', ' Great office location!', ' Experience with LiDAR Experience with C/C++ or Matlab programming Experience with embedded systems', ' Great company culture', ' HUGE opportunities for growth! Small, diverse, and BRILLIANT team of scientists, engineers, and PhDs! Highly lucrative area of study and development!', ' Experience with embedded systems', ' Brilliant leadership team', ' Much more!', ' 5+ years of experience working in R&D or Machine Learning field', ' HUGE opportunities for growth!', ' Design and implement integration and testing', ' Experience with Python or Shell scripting', 'Email Your Resume In Word To', ' Assist in our product technology development', ' We are one of the leaders in our field of study', ' Medical, Dental, and Vision', ' Highly lucrative area of study and development!', ' Experience with C/C++ or Matlab programming', ' PTO', 'Your Right to Work', "" Bachelor's, Master's, or PhD in relevant field of study 5+ years of experience working in R&D or Machine Learning field Experience with Python or Shell scripting Experience with facial recognition algorithms or machine learning Experience with profiling and benchmarking Experience with regression testing""]",Entry level,Full-time,Information Technology,Construction,2020-11-05 11:32:32
Data Analyst (Scientist and Engineer Level 3),N/A,"Hurlburt Field, FL",16 hours ago,Be among the first 25 applicants,"['', 'Computer programming skills and experience working with MATLAB are required.', 'Reviews technical specifications and system design documents. Attends test planning meetings, technical interchange meetings, and system design reviews. ', 'Proficiency in the use of Microsoft Office applications including Excel is required.', ""U.S. Citizenship is required.Active Secret Clearance is required Bachelor's degree in applicable discipline and 3 - 10 years of related experience.Six years of applicable technical experience may be substituted for the BS degree (total 9 years) or four years’ experience with an Associate’s Degree (total 7 years).This skill level typically performs all functional duties independently.Must be a self-motivated expert able to take responsibility for identifying, organizing, coordinating, and executing necessary tasks to the successful accomplishment of assigned duties.Must be able to work as part of an integrated test team.Must be able to effectively communicate orally and possess technical writing skill.Proficiency in the use of Microsoft Office applications including Excel is required.Computer programming skills and experience working with MATLAB are required."", ""Bachelor's degree in applicable discipline and 3 - 10 years of related experience.Six years of applicable technical experience may be substituted for the BS degree (total 9 years) or four years’ experience with an Associate’s Degree (total 7 years)."", 'Responsibilities', 'Manages databases and analytic functions to ensure robust, secure, and responsive data control capability. Develops, maintains, and manages data tools to support the helicopter test teams.', 'Test support includes recommendation of system performance requirements, development of test objectives, development of test methods and detailed test procedures, development of specification datarequirements, identification of instrumentation and test support equipment requirements, development of data collection forms and logs, coordination with test support agencies and ranges, and other test and evaluation (T&E) planning tasks. ', 'Writes technical reports to address test results and findings.Provides technical advice and assistance to military test directors.', 'Must be able to effectively communicate orally and possess technical writing skill.', 'Activities include participation in test execution, data collection and reduction, data analysis, assessing systems effectiveness, and test reporting.', 'U.S. Citizenship is required.', 'Active Secret Clearance is required ', 'Incorporates scientific principles and methods in test planning and execution.Works with Test Engineers to create required data products for test reporting.', 'Must be able to work as part of an integrated test team.', 'Supports the HH-60W Combat Rescue Helicopter (CRH) and MH-139 Strategic Defense Helicopter (SDH) developmental test & evaluation (DT&E) programs within the guidelines established in Government approved test procedures, method of test (MOT), and go or no-go criteria. Activities include participation in test execution, data collection and reduction, data analysis, assessing systems effectiveness, and test reporting.Test support includes recommendation of system performance requirements, development of test objectives, development of test methods and detailed test procedures, development of specification datarequirements, identification of instrumentation and test support equipment requirements, development of data collection forms and logs, coordination with test support agencies and ranges, and other test and evaluation (T&E) planning tasks. Reviews technical specifications and system design documents. Attends test planning meetings, technical interchange meetings, and system design reviews. Manages databases and analytic functions to ensure robust, secure, and responsive data control capability. Develops, maintains, and manages data tools to support the helicopter test teams.Incorporates scientific principles and methods in test planning and execution.Works with Test Engineers to create required data products for test reporting.Writes technical reports to address test results and findings.Provides technical advice and assistance to military test directors.Travels to offsite locations as required and other duties as assigned.', 'Supports the HH-60W Combat Rescue Helicopter (CRH) and MH-139 Strategic Defense Helicopter (SDH) developmental test & evaluation (DT&E) programs within the guidelines established in Government approved test procedures, method of test (MOT), and go or no-go criteria. ', 'Travels to offsite locations as required and other duties as assigned.', 'This skill level typically performs all functional duties independently.Must be a self-motivated expert able to take responsibility for identifying, organizing, coordinating, and executing necessary tasks to the successful accomplishment of assigned duties.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Machine Learning Engineer: up to $250,000 base+equity",Scovios,"San Francisco, CA",9 hours ago,Be among the first 25 applicants,"['', 'Responsibilities:', 'Responsible for implementing various algorithms to do automated feature extraction and dataset augmentation, optimizing runtimes of neural network algorithms and building higher level abstractions for various common AI/ML techniques.', 'Candidates will need to have a BS or MS from top notch CS programs with industry experience. We are looking for machine learning software engineers who have experience building at least one of the following: ML/AI models which are in production New neural network algorithms based on research papers Low level performance optimization of deep learning systems Machine learning platforms', 'Company Description:', 'Job Description:', 'General Requirements:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. They have also previously been founders and early employees at startups. We raised $18 million in Series A from Decibel Ventures and Eric Schmidt. We are looking for talented machine learning software engineers, systems software engineers and research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Principal Data Engineer,Insight,"Columbus, OH",14 hours ago,Be among the first 25 applicants,"['', 'APPLY', 'Aggressively grow your skillset and expertise to meet emerging needs', 'Analysis Services (SSAS) and DAX', 'Scripting: PowerShell, Azure Automation', 'Fortune Top 100 Best Companies for Diversity', '30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizesMicrosoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOpsFortune Top 100 Best Companies for DiversityFortune Top 50 Best Workplaces in TechnologyWinner of several “Best Places to Work” awards30+ years in business, 11,000+ teammates worldwide, and $7.7 billion in revenue in 2019', 'Predictive Analytics: R, Azure Machine Learning ', 'Prioritize, self-direct and execute at velocity', 'some', 'Fortune Top 50 Best Workplaces in Technology', 'Skill at translating requirements into clean, efficient, quality code ', 'Strong analytical and reasoning skills that result in clear technical execution', 'About Insight', '5+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)2+ years of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Lead discussions with clients and recommend technical solutions for business cases', 'Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity', 'Winner of several “Best Places to Work” awards', 'Integration Services (SSIS)', 'Big Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystem', 'Design and code modern solutions to tough data challenges leveraging the cloud and ', '2+ years of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data Factory', 'Development Languages: .NET, Java or Scala', 'most', 'SQL Server', 'Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team', 'Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externally', 'Requisition Number: 78956 ', 'Design and develop cutting-edge enterprise data solutions in a fast-paced environmentLead discussions with clients and recommend technical solutions for business casesDesign and code modern solutions to tough data challenges leveraging the cloud and Lead and collaborate with sharp, passionate teammates, provide feedback on others’ work, and encourage innovation and best practices internally and externallyPrioritize, self-direct and execute at velocityAggressively grow your skillset and expertise to meet emerging needs', 'Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)', 'SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)2+ years of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or Scala', 'Reporting Tools: Power BI, Tableau, Qlik, SSRS ', 'Global provider of Intelligent Technology Solutions™ for organizations of all sizes', 'Azure Big Data Technologies: Azure Data Lake and Azure Data Lake Analytics', 'Design and develop cutting-edge enterprise data solutions in a fast-paced environment', 'What We Do', 'What We Look For', 'Ready to join?', 'We are looking for an experienced Principal Data Engineer ', 'Demonstrated communication skills with both technical and non-technical stakeholders; Active listening, critical thinking, presentation skills, coaching, empathy, dependability, creativity5+ years of experience working with data and data analytics development, preferably within the Microsoft data platform and an excellent grasp of most of following technologies:SQL ServerAnalysis Services (SSAS) and DAXReporting Tools: Power BI, Tableau, Qlik, SSRS Integration Services (SSIS)2+ years of experience in some of the following:Azure: Azure SQL Database, Azure SQL Data Warehouse and Azure Data FactoryAzure Big Data Technologies: Azure Data Lake and Azure Data Lake AnalyticsBig Data Technologies: Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystemPredictive Analytics: R, Azure Machine Learning Scripting: PowerShell, Azure AutomationDevelopment Languages: .NET, Java or ScalaStrong analytical and reasoning skills that result in clear technical executionSkill at translating requirements into clean, efficient, quality code Eagerness to learn new tools and technologies, and passion to deliver quality solutions both individually and as part of a team', 'What can Insight offer?', 'Microsoft Global Partner of the Year for AI, IoT, Open Source Solutions, Mobile Apps, & Modern Desktop; Microsoft US Partner of the Year for DevOps']",Mid-Senior level,Full-time,Information Technology,Marketing and Advertising,2020-11-05 11:32:32
User Experience Researcher,Robinhood,"Menlo Park, CA",6 hours ago,Be among the first 25 applicants,"['', 'Planning and leading research end to end, including strategic, foundational, iterative, and evaluative research', 'About The Company', 'Proactively and independently identifying high-impact questions from a product or business perspective', ' 6-8+ years of qualitative research experience; it can either be industry-only, or a combination of industry experience and academic research Masters or PhD Degree in Human-Computer Interaction, Psychology, Behavioral Economics, Anthropology, Sociology, or similar Record of applying your research skills to create product and business impact Strong work ethic, excellent organization and communication skills Love and care for your craft ', 'Your Day-to-day Will Involve', 'Contributing to the development of a data-driven understanding of Robinhood users and potential users ', 'Passion for working and learning in a fast-growing company', ' Passion for working and learning in a fast-growing company ', 'Record of applying your research skills to create product and business impact', 'Representing the voice of the user throughout the whole product development process, working closely with PMs, designers, engineers, and leadership', ' Proactively and independently identifying high-impact questions from a product or business perspective Answering those questions with a strong command of qualitative and quantitative methods – especially survey development and related data analysis Planning and leading research end to end, including strategic, foundational, iterative, and evaluative research Representing the voice of the user throughout the whole product development process, working closely with PMs, designers, engineers, and leadership Clearly communicating your research insights for teams to translate research findings to product and business impact Contributing to the development of a data-driven understanding of Robinhood users and potential users  ', 'Bonus Points', 'Strong work ethic, excellent organization and communication skills', 'About The Role', 'Answering those questions with a strong command of qualitative and quantitative methods – especially survey development and related data analysis', 'Clearly communicating your research insights for teams to translate research findings to product and business impact', '6-8+ years of qualitative research experience; it can either be industry-only, or a combination of industry experience and academic research', 'Some Things We Consider Critical For This Role', 'Love and care for your craft', 'Masters or PhD Degree in Human-Computer Interaction, Psychology, Behavioral Economics, Anthropology, Sociology, or similar']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Tableau Consultant,Accenture,"Phoenix, AZ",10 hours ago,Be among the first 25 applicants,"['', 'You know your way around other data visualization toolsets such as Qlikview or Spotfire ', 'Here’s What You Need: ', 'Minimum of 2 year’s experience designing or developing with Tableau, including dashboards, reports, and/or front-end visualizations ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', 'You’re familiar with Business Intelligence tools including Cognos, Business Objects, OBIEE, methodologies, and/or responsibilities ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'You’re no newbie to Data Platforms such as Teradata, IBM, TM1, Netezza, DataMirror, Oracle, Essbase, GoldenGate, EMS, Greenplum', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Experience with database development including Custom SQL design, PLSQL, and/or Data Modeling ', 'Accenture Overview', 'Bonus Points If:', 'Equal Employment Opportunity:', 'Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'You’ve had experience with, or exposure to custom data visualization frameworks such as d3.js ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Accenture is committed to providing veteran employment opportunities to our service men and women. ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'You’ve got experience of full life-cycle development in a BI or Analytics environment ', 'The Work:', 'You Are:', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Business Development,Information Technology and Services,2020-11-05 11:32:32
Staff Research Scientist,Upstart,"Columbus, OH",5 hours ago,Be among the first 25 applicants,"['', 'Full-stack expertise with all steps of the modeling process from ideation to productionalizing code; OR deep expertise in either statistical modeling or machine learning', 'Strong sense of intellectual curiosity balanced with humility, drive and teamwork', 'Programming skills in Python and/or R', 'The Team', 'Enthusiasm for and alignment with Upstart’s mission and values', ' Competitive compensation (base + bonus & equity) Comprehensive medical, dental, and vision coverage Personal development and technology & ergonomic budgets  Life insurance and disability benefits  Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams)  Generous vacation policy 401(k) retirement plan Catered lunches + snacks & drinks ', 'Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams) ', 'The Role', '401(k) retirement plan', '5+ years relevant experience with detailed understanding of building good technical solutions; ability to convert ideas into testable hypotheses and/or next steps', 'Competitive compensation (base + bonus & equity)', 'What You’ll Love', 'What We’re Looking For', 'Numerically-savvy and smart with ability to operate at a speedy pace', 'Comprehensive medical, dental, and vision coverage', 'Life insurance and disability benefits ', 'Generous vacation policy', "" Strong academic credentials with a master's degree in computer science, statistics, mathematics, or other quantitative areas of study; Ph.D. preferred 5+ years relevant experience with detailed understanding of building good technical solutions; ability to convert ideas into testable hypotheses and/or next steps Programming skills in Python and/or R Full-stack expertise with all steps of the modeling process from ideation to productionalizing code; OR deep expertise in either statistical modeling or machine learning Knowledge of machine learning, pipelines and engineering architecture helpful Interest in growing in technical and/or people leadership is a plus Enthusiasm for and alignment with Upstart’s mission and values Strong sense of intellectual curiosity balanced with humility, drive and teamwork Numerically-savvy and smart with ability to operate at a speedy pace "", 'Knowledge of machine learning, pipelines and engineering architecture helpful', 'Personal development and technology & ergonomic budgets ', 'Catered lunches + snacks & drinks', 'Interest in growing in technical and/or people leadership is a plus', ""Strong academic credentials with a master's degree in computer science, statistics, mathematics, or other quantitative areas of study; Ph.D. preferred""]",Associate,Full-time,Other,Computer Software,2020-11-05 11:32:32
Sonar Algorithm Researcher,Systems & Technology Research,"Dayton, OH",19 hours ago,Be among the first 25 applicants,"['', 'Participate in preparation of proposals, plans and schedules. ', 'Algorithm development for sonar detection and tracking algorithms (beamforming, spectral estimation, detection processing)', 'Active Security Clearance at the Secret or Top Secret (TS) level', ' Interest and aptitude for working on large, complex technical projects and teams Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects Scientific curiosity and creativity Knowledge of one or more of the following topic areas: Signal processing  Tracking Estimation Control Marine robotics Cooperative navigation   Active Security Clearance at the Secret or Top Secret (TS) level ', 'Interest and aptitude for working on large, complex technical projects and teams', 'Description', 'Marine robotics', 'Tracking', 'Strong scientific programming skills in MATLAB, Python, and/or C/C++', 'Estimation', 'Desired Qualifications', 'Developing and implementing algorithms using at-sea collected data and iterate to improve performance', 'Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects', 'US Citizenship with the ability to obtain a Security Clearance', 'Cooperative navigation', 'Participate in at-sea data collections including experiment design and analysis of collected data', 'Scientific curiosity and creativity', 'Requirements', 'PhD or MS degree with research experience in underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field', 'Required Qualifications', 'Control', ' Algorithm development for sonar detection and tracking algorithms (beamforming, spectral estimation, detection processing) Developing and implementing algorithms using at-sea collected data and iterate to improve performance Participate in at-sea data collections including experiment design and analysis of collected data Participate in preparation of proposals, plans and schedules.  ', 'Responsibilities Include', ' Signal processing  Tracking Estimation Control Marine robotics Cooperative navigation ', 'Knowledge of one or more of the following topic areas: Signal processing  Tracking Estimation Control Marine robotics Cooperative navigation  ', 'Algorithm Research Engineer', ' US Citizenship with the ability to obtain a Security Clearance PhD or MS degree with research experience in underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field Strong scientific programming skills in MATLAB, Python, and/or C/C++ ', 'Signal processing ']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Machine Learning Engineer - Segmentation and Depth Estimation (TDG),Apple,"Cupertino, CA",6 hours ago,98 applicants,"['', 'Description', 'Key Qualifications', 'Education & Experience', 'Summary']",Not Applicable,Full-time,Engineering,Consumer Electronics,2020-11-05 11:32:32
Senior Data Scientist - Geneticist (REMOTE),CyberCoders,"South San Francisco, CA",22 hours ago,Be among the first 25 applicants,"['', 'You will lead the development of cutting edge statistical approaches and workflows to analyze large-scale human cohorts with genetic and multi-dimensional, multi-modality phenotypic data. These will be obtained from public sources, as well as private datasets generated in-house and obtained through our collaborations', 'Hands on experience with...', 'Genetic association testing (eQTL mapping, GWAS, EWAS, PheWAS, etc.) or post-association analysis using summary statistics (fine mapping, colocalization, LD score regression, meta-analysis, etc.)', 'Applied multivariate statistics; experience working with statistical models for complex datasets, effectively measuring goodness of fit and estimating confidence', ""Very high job security with the late stage startup environment, yet still able to 'pave the way' for the future of the company"", 'Competitive market compensation (base, bonus, equity, generous benefits)', 'Industry-renown professionals leading the company', 'You will also work closely with a cross-functional team of life scientists, bioengineers and machine learning scientists to integrate human level data with our high-throughput in-house in vitro genomic and phenotypic data to identify therapeutic targets and develop drugs that have high efficacy and low toxicity', 'Mining modern, large-scale genetic databases (e.g. ExAC/gnomAD, UK Biobank, UK10K, EBI GWAS Catalog, 1KG, etc.)', ""$240,000,000 + in funding to date within the last 2 yearsFast growing, late stage startup with opportunity for cross-functional learningVery high job security with the late stage startup environment, yet still able to 'pave the way' for the future of the companyIndustry-renown professionals leading the companyOpportunity for growthCompetitive market compensation (base, bonus, equity, generous benefits)"", 'Ph.D. in statistics, genetics, computational biology, or similarDemonstrated ability to use and develop cutting edge methods for analyzing human genetic dataHands on experience with...Genetic association testing (eQTL mapping, GWAS, EWAS, PheWAS, etc.) or post-association analysis using summary statistics (fine mapping, colocalization, LD score regression, meta-analysis, etc.)Mining modern, large-scale genetic databases (e.g. ExAC/gnomAD, UK Biobank, UK10K, EBI GWAS Catalog, 1KG, etc.)Applied multivariate statistics; experience working with statistical models for complex datasets, effectively measuring goodness of fit and estimating confidenceProficiency in working with large-scale datasets in Python; R, C, C++ a huge plus', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', 'Opportunity for growth', '$240,000,000 + in funding to date within the last 2 years', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : SJ7-1607942 -- in the email subject line for your application to be considered.***', 'Ph.D. in statistics, genetics, computational biology, or similar', 'Demonstrated ability to use and develop cutting edge methods for analyzing human genetic data', 'Email Your Resume In Word To', 'Proficiency in working with large-scale datasets in Python; R, C, C++ a huge plus', 'Your Right to Work', 'Fast growing, late stage startup with opportunity for cross-functional learning']",Internship,Full-time,Other,Biotechnology,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"New Orleans, LA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Big Data Engineer,Cypress HCM,"Sunnyvale, CA",17 hours ago,Be among the first 25 applicants,"['Desired skills and experience', 'Experience with Data Warehouse design, ETL (Extract, Transform, Load), architecting efficient software solutions ', 'Responsibilities', 'Experience in engineering large-scale distributed systems in a production environment ', 'Working experience with Hadoop projects/infrastructure ', 'Sr. Big Data Engineer ', 'Desired skills and experience ', 'Ensuring best practices that can be adopted in Big Data stack and share across teams and BUs. ', 'Responsibilities ', 'Job Description:', 'Experience in the Big Data space (Hadoop Stack like Spark, HDFS, Pig, Hive, etc.) ', 'Knowledge of data modeling for both data warehousing and Big Data ', 'Experience with an OO programming language like Java a bonus', 'Designing, integrating and documenting technical components for seamless data extraction and analysis on our big data platform. ', 'Experience with at least one scripting language (Shell, Python, Perl etc.) a bonus ', 'Performing all of the necessary data transformations to populate data into a warehouse table structure that is optimized for reporting. ', 'Sr. Big Data Engineer', 'Ability to write, analyze, and debug SQL queries ', ' ', 'Working in a team environment, interacting with multiple groups on a daily basis (very strong communication skills). ', 'Contributing at a senior-level to the Big data and data warehouse design and data preparation by implementing a solid, robust, extensible design that supports key business flows. ', '2+ years of relevant work experience in data ', 'Experience working extensively in multi-petabyte data environment ', 'Job Description:\xa0 \xa0 \xa0 \xa0 \xa0 \xa0 \xa0  ', 'The Big Data Engineering team is responsible for building and maintaining the state-of-the-art ETL pipelines that makes this data available and accessible to the entire company to make data driven decisions. The team works closely with Data scientists, Product Managers, Executives and other key parts of the business across the globe to understand their data requirements and build appropriate solutions or platforms that meet or exceed those needs. ', '\xa0 ', 'Establishing efficient design and programming patterns for engineers as well as for non-technical individuals ']",Associate,Contract,Writing/Editing,Internet,2020-11-05 11:32:32
Data Engineer II,LivePerson,"New York, NY",5 hours ago,101 applicants,"['', ' Stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc. ', '  Stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.   Advanced working SQL knowledge and experience working with relational databases, query authoring as well as working familiarity with a broad range of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytical skills related to working with unstructured or “dirty” datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Demonstrated ability to work closely with teammates in a highly collaborative environment and simultaneously be a self-starter with strong individual contributions.  ', 'Code repository and deployment pipelines - GIT and Docker, Kubernetes, Puppet', ' Data pipeline and workflow management tools: AWS Glue, Luigi, Airflow, etc. Code repository and deployment pipelines - GIT and Docker, Kubernetes, Puppet Relational SQL and NoSQL databases. Bigdata Hadoop ecosystem: Hadoop, HBase, Spark, Kafka, Hive, Presto etc.  AWS-based cloud services: API Gateway, Lambda, Load Balancer, DynamoDB, Glue etc. ', 'AWS-based cloud services: API Gateway, Lambda, Load Balancer, DynamoDB, Glue etc.', 'Professional qualifications:', 'Work with stakeholders, including the Executive, Product, Data, and Finance teams, to understand requirements and business impact and support related data infrastructures.', 'Strong analytical skills related to working with unstructured or “dirty” datasets.', 'Experience using the following software/tools:', '2+ years of experience in development of Microservices, RESTful API, backend systems', 'You relate to our core principles (link) and want to work with Conversational AI experts', 'Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.', 'Assemble large, complex data sets that meet a broad range of business requirements.', 'Identify, design, and implement internal process improvements, including automating manual processes, optimizing data flows, and re-designing infrastructure for greater scalability.', '2+ years of experience in public / private cloud', 'Why You’ll Love Working Here', 'Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.', 'You believe data-driven decision making is the norm', 'All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.', 'Bigdata Hadoop ecosystem: Hadoop, HBase, Spark, Kafka, Hive, Presto etc. ', 'You can build partnerships that move our business forward', ' Stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.  ', 'You can operate in a fast paced, dynamic environment', 'Advanced working SQL knowledge and experience working with relational databases, query authoring as well as working familiarity with a broad range of databases.', 'Graduate degree in Computer Science, Statistics, or another quantitative field.', 'Your qualifications are:', ' 3+ years of experience in a Data Engineer role working with databases, SQL, ETL 2+ years of experience in public / private cloud 2+ years of experience in development of Microservices, RESTful API, backend systems Graduate degree in Computer Science, Statistics, or another quantitative field. Experience using the following software/tools: ', 'You see feedback or failure as motivation to learn and to grow ', 'You Will Thrive Here If', 'You build code that is simple, understandable, and clean ', 'Create and maintain optimal data pipeline architecture.', 'Relational SQL and NoSQL databases.', ' Create and maintain optimal data pipeline architecture. Assemble large, complex data sets that meet a broad range of business requirements. Identify, design, and implement internal process improvements, including automating manual processes, optimizing data flows, and re-designing infrastructure for greater scalability. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS-based ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics. Work with stakeholders, including the Executive, Product, Data, and Finance teams, to understand requirements and business impact and support related data infrastructures. ', '  Stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.   Advanced working SQL knowledge and experience working with relational databases, query authoring as well as working familiarity with a broad range of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytical skills related to working with unstructured or “dirty” datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Demonstrated ability to work closely with teammates in a highly collaborative environment and simultaneously be a self-starter with strong individual contributions. ', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS-based ‘big data’ technologies.', 'Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.', ' You can operate in a fast paced, dynamic environment You can build partnerships that move our business forward You build code that is simple, understandable, and clean  You see feedback or failure as motivation to learn and to grow  You believe data-driven decision making is the norm You relate to our core principles (link) and want to work with Conversational AI experts ', 'Demonstrated ability to work closely with teammates in a highly collaborative environment and simultaneously be a self-starter with strong individual contributions.', 'Stream-processing systems: Storm, Spark-Streaming, etc.', '   Stream-processing systems: Storm, Spark-Streaming, etc. Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.   Advanced working SQL knowledge and experience working with relational databases, query authoring as well as working familiarity with a broad range of databases. Experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong analytical skills related to working with unstructured or “dirty” datasets. Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores. Demonstrated ability to work closely with teammates in a highly collaborative environment and simultaneously be a self-starter with strong individual contributions.   ', 'At LivePerson, people from diverse backgrounds come together to do their best work and be their authentic selves. We are proud to be an equal opportunity employer. ', '3+ years of experience in a Data Engineer role working with databases, SQL, ETL', 'In This Role, You Will', 'Data pipeline and workflow management tools: AWS Glue, Luigi, Airflow, etc.', 'Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.', 'Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Senior Machine Learning Engineer, Public Sector - AWS Professional Services",Amazon Web Services (AWS),"Richmond, VA",6 hours ago,Be among the first 25 applicants,"['', ' Work closely with account team, research scientist teams and product engineering teams to drive model implementations and new algorithms', ' Experience in using Python, R or Matlab or other statistical/machine learning software', ' Analyze and extract relevant information from large amounts of historical data — provide hands-on data wrangling expertise', 'The Primary Responsibilities Of This Role Are To', 'BASIC QUALIFICATIONS', ' The motivation to achieve results in a fast-paced environment.', ' Design data architectures and data lakes Provide expertise in the development of ETL solutions on AWS Use ML tools, such as Amazon SageMaker Ground Truth (GT) to annotate data. Work with Professional Services on designing workflow and user interface for GT annotation. Collaborate with our data scientists to create scalable ML solutions for business problems Interact with customer directly to understand the business problem, help and aid them in implementation of their ML ecosystem Analyze and extract relevant information from large amounts of historical data — provide hands-on data wrangling expertise Work closely with account team, research scientist teams and product engineering teams to drive model implementations and new algorithms This position can have periods of up to 10% travel.', ' Knowledge of ETL tools and databases (both SQL-based, NoSQL)', 'Preferred Qualifications', 'PREFERRED QUALIFICATIONS', 'Company', ' Strong communication and data presentation skills', 'Basic Qualifications', 'Description', ' Use ML tools, such as Amazon SageMaker Ground Truth (GT) to annotate data. Work with Professional Services on designing workflow and user interface for GT annotation.', ' This position can have periods of up to 10% travel.', ' This position requires that the candidate selected be a U.S. citizen and be willing to maintain a TS security clearance', ' Comfortable working in a fast paced, highly collaborative, dynamic work environment', ' 1+ year of public cloud computing experience in AWS', ' Masters or PhD degree in computer science, or related technical, math, or scientific field Working knowledge of deep learning, machine learning and statistics. User interface experience with Javascript, HTML Model deployment experience using C++ Knowledge of ETL tools and databases (both SQL-based, NoSQL) Experience in using Python, R or Matlab or other statistical/machine learning software Strong communication and data presentation skills The motivation to achieve results in a fast-paced environment. Comfortable working in a fast paced, highly collaborative, dynamic work environment This position requires that the candidate selected be a U.S. citizen and be willing to maintain a TS security clearance', ' Design data architectures and data lakes', ' 3+ year of experience with data engineering, ETL, and data wrangling', ' User interface experience with Javascript, HTML', ' Collaborate with our data scientists to create scalable ML solutions for business problems', ' BS in computer science, or related technical, math, or scientific field', ' Masters or PhD degree in computer science, or related technical, math, or scientific field', ' 5+ years of relevant experience in building large scale enterprise IT systems', ' Model deployment experience using C++', ' Interact with customer directly to understand the business problem, help and aid them in implementation of their ML ecosystem', ' BS in computer science, or related technical, math, or scientific field 5+ years of relevant experience in building large scale enterprise IT systems 3+ year of experience with data engineering, ETL, and data wrangling 1+ year of public cloud computing experience in AWS', ' Provide expertise in the development of ETL solutions on AWS', ' Working knowledge of deep learning, machine learning and statistics.']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Senior AWS Data Engineer,Cognizant,Greater Chicago Area,18 hours ago,61 applicants,"[':', 'Position Qualifications: ', 'Cognizant’s AIA practice takes insights that are buried in data, and provides businesses a clear way to transform how they source, interpret and consume their information. ', 'Position Qualifications', 'AWS Data Engineer – Full Time', 'Location: Peoria, Illinois', 'Data stores such as Redshift and Snowflake ', '\xa0', 'Deploying and maintaining software using public clouds such as AWS. 5+ Years experience designing, developing, deploying and maintaining software at scale using Java and Spark Developing software applications using relational and NoSQL databases. Experience writing in ETL in AWS using S3, EMR and EC2 or AWS GLUE Data stores such as Redshift and Snowflake Debugging and maintaining software in Linux or UNIX platforms. Must demonstrate solid knowledge of data structures and algorithms. ', '*You must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.* ', 'Developing software applications using relational and NoSQL databases. ', 'Location: Peoria, Illinois ', 'Debugging and maintaining software in Linux or UNIX platforms. ', 'By decoding customer needs, preferences, and behaviors, our clients can understand exactly what services, products, and experiences their consumers need. ', 'AWS Data Engineer – Full Time ', 'Cognizant is looking for AWS Data Engineer to join our Artificial Intelligence and Analytics practice (AIA)..  As an experienced Developer, you will analyze the existing architecture for gaps in addressing business needs. You are a thought leader-comfortable challenging the status quo to enhance our current services and technologies. ', '5+ Years experience designing, developing, deploying and maintaining software at scale using Java and Spark ', 'About AI & Analytics: ', 'Experience writing in ETL in AWS using S3, EMR and EC2 or AWS GLUE ', '\xa0 ', 'Must demonstrate solid knowledge of data structures and algorithms. ', 'Deploying and maintaining software using public clouds such as AWS. ', 'About AI & Analytics']",Mid-Senior level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
Principal Data Scientist,Microsoft,"Redmond, WA",20 hours ago,Be among the first 25 applicants,"['', 'Bachelors or advanced degree in Computer Science or similar field3+ years experience coding in C++, C#, Java, python or equivalent5+ years of research scientist, data scientist and/or ML engineering experience3+ years of experience in large-scale data analytics', 'Be a champion and role model of ML engineering excellence.', 'not required', 'Responsibilities', 'Cutting-edge knowledge and hands-on experience in developing end-to-end commercial scale deep learning systems3+ years of experience with optimization of commercial scale Search or Recommendation systems3+ years experience with experimentation and shipping user experience features on commercial scale Search or Recommendation systemsMasters or PhD in computer science or equivalent', '3+ years of experience with optimization of commercial scale Search or Recommendation systems', 'Qualifications', '3+ years experience with experimentation and shipping user experience features on commercial scale Search or Recommendation systems', '3+ years experience coding in C++, C#, Java, python or equivalent', 'Masters or PhD in computer science or equivalent', 'Innovations in ML system architecture/functionalities for high scalability and efficiency.', 'ML modeling innovations in NLP, ranking and recommendation domains.', 'Lead opportunity analysis, project proposals, design, implementation and execution across a variety of ML projects to ship product improvements.ML modeling innovations in NLP, ranking and recommendation domains.Innovations in ML system architecture/functionalities for high scalability and efficiency.Be a champion and role model of ML engineering excellence.', 'Lead opportunity analysis, project proposals, design, implementation and execution across a variety of ML projects to ship product improvements.', 'Cutting-edge knowledge and hands-on experience in developing end-to-end commercial scale deep learning systems', '5+ years of research scientist, data scientist and/or ML engineering experience', 'Bachelors or advanced degree in Computer Science or similar field', '3+ years of experience in large-scale data analytics']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Applied Scientist,Amazon,"East Palo Alto, CA",6 hours ago,Be among the first 25 applicants,"['', ' PhD degree in computer science, operations research, statistics, engineering, or mathematics 3+ years of experience in the field with a proven track record Experience with fast prototyping Experience with object oriented languages and efficient low level coding Experience with data mining or machine learning applications Strong publication record at top conferences and journals', 'Description', ' Scientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field.', ' Strong publication record at top conferences and journals', ' Excellent written and verbal communication skills.', ' Experience working effectively with software engineering teams', ' 3+ years of experience in the field with a proven track record', ' Experience with fast prototyping', 'Preferred Qualifications', ' Experience with data mining or machine learning applications', ' Experience working effectively with software engineering teams Excellent written and verbal communication skills. Scientific thinking and the ability to invent, a track record of thought leadership and contributions that have advanced the field.', 'Company', ' Experience with object oriented languages and efficient low level coding', ' PhD degree in computer science, operations research, statistics, engineering, or mathematics', 'Basic Qualifications']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
"AI Research scientist: up to $350,000 base+equity",Apptronic Labs,"San Francisco, CA",6 hours ago,Be among the first 25 applicants,"['', 'Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Ideal candidates would be able to rapidly iterate on new ideas with engineers, potentially publish at top conferences and be able to write code.', 'Responsibilities:', 'We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'We are looking for people who have done research / published papers in one of the following areas: Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Candidates will need to have a PhD preferably in Artificial Intelligence or Machine Learning.\xa0', 'Job Description:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. We have also previously been founders and early employees at startups. We are backed by Eric Schmidt and Decibel Ventures with Series A funding of $18 million. We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'General Requirements:', 'Required Skills:', 'Responsible for coming up with new techniques in unsupervised learning, dataset augmentation and deep reinforcement learning that can be applied to automating various parts of the AI development workflow.']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Senior Data Engineer,CVS Health,"Moon, PA",4 hours ago,Be among the first 25 applicants,"['', 'Job Description', 'Fundamental Components', 'Education', 'Business Overview', 'Percent Of Travel Required', 'Background Experience']",Associate,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"AI Research scientist: up to $350,000 base+equity",Scovios,"San Francisco, CA",9 hours ago,Be among the first 25 applicants,"['', 'Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Ideal candidates would be able to rapidly iterate on new ideas with engineers, potentially publish at top conferences and be able to write code.', 'Responsibilities:', 'We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'We are looking for people who have done research / published papers in one of the following areas: Unsupervised Learning Generative Modeling Deep Neural Networks Deep Reinforcement Learning Generative Adversarial Networks Causal Reasoning\xa0', 'Candidates will need to have a PhD preferably in Artificial Intelligence or Machine Learning.\xa0', 'Job Description:', 'We are a stealth startup building a cutting edge cloud AI service. Our founders have a wealth of experience working on various ground-breaking products including self driving cars, AWS AI services, GMail, Google Docs and flash storage systems. We have also previously been founders and early employees at startups. We are backed by Eric Schmidt and Decibel Ventures with Series A funding of $18 million. We are looking for talented research scientists to be part of the founding team. You will help build the product that applies unsupervised learning to model the world and automatically creates and manages production grade AI systems. As an initial member of the founding team, you get to own a significant chunk of the company, shape its culture and work on state-of-the-art science and technology.', 'General Requirements:', 'Required Skills:', 'Responsible for coming up with new techniques in unsupervised learning, dataset augmentation and deep reinforcement learning that can be applied to automating various parts of the AI development workflow.']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Senior Data Scientist - Saint Petersburg,N/A,"Petersburg, PA",13 hours ago,Be among the first 25 applicants,[],Associate,Full-time,Other,Information Technology and Services,2020-11-05 11:32:32
Algorithms Researcher - Command and Control,Systems & Technology Research,"Woburn, MA",19 hours ago,Be among the first 25 applicants,"['', 'Explain design rationale and report on performance improvements', 'MS in Mathematics, Computer Science, Operations Research, Electrical Engineering or related discipline.', 'Analyze sensors, weapons, platforms, and communications systems to develop mathematical models for predicting performance and future behaviors', 'Description', 'Demonstrated skill in communicating technical content to diverse teammates', 'Experience utilizing Objected Oriented Programming principles', 'Background in at least one of: machine learning for predictive analytics, reinforcement learning, approximate dynamic programming, constraint satisfaction, combinatorial optimization.', ' MS in Mathematics, Computer Science, Operations Research, Electrical Engineering or related discipline. Background in at least one of: machine learning for predictive analytics, reinforcement learning, approximate dynamic programming, constraint satisfaction, combinatorial optimization. Demonstrated skill in communicating technical content to diverse teammates Experience with at least one of: Java, Python, C/C++ ', 'Experience with at least one of: Java, Python, C/C++', ' Active Security Clearance Ph.D. in one of the disciplines above Experience utilizing Objected Oriented Programming principles Experience with DoD mission-level modeling and simulation environments, such as NGTS or AFSIM Experience with military systems analysis or survivability analysis ', 'The Role', 'Ph.D. in one of the disciplines above', 'Active Security Clearance', 'Experience with military systems analysis or survivability analysis', 'Requirements', 'Even Better', 'U.S. Citizen with the ability to obtain a Security Clearance', 'Who You Are', 'Implement, analyze, and improve prototype algorithms', 'Work as a member of an Agile/Scrum software team', 'Experience with DoD mission-level modeling and simulation environments, such as NGTS or AFSIM', 'Design algorithms to support real-time decision-making', ' Work as a member of an Agile/Scrum software team Analyze sensors, weapons, platforms, and communications systems to develop mathematical models for predicting performance and future behaviors Design algorithms to support real-time decision-making Implement, analyze, and improve prototype algorithms Explain design rationale and report on performance improvements ']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Mid-Level Data Engineer,Optello,"San Mateo, CA",2 hours ago,Be among the first 25 applicants,"['', ' Build upon existing data service architecture to support internal and external applications', ' Catered breakfast and lunch each week', 'Optello is proud to be an Equal Opportunity Employer', 'POST-COVID', ' Salesforce integration experience', ' Pet-friendly office', ' Build scalable pipelines capable of processing massive amounts of data', ' Generous PTO', 'Requirements:', ' Catered breakfast and lunch each week Fully stocked snacks Pet-friendly office Childcare assistance', ' RESTful API and server-side API integration experience', 'DURING COVID', ' 7+ years of Python programming experience', 'Job Title:', 'Job Location:', ' Strong verbal and written communication experience', ' Competitive starting salary', ' Experience with Cassandra databases Additional NoSQL database experience Experience with Maria databases Salesforce integration experience', 'Bonus Skills', ' 401k + match', ' Competitive starting salary Amazing healthcare benefits 401k + match Generous PTO Equipment provided Stipend for workspace', ' Additional NoSQL database experience', ' Design and implement process improvements, automate manual processes, and redesign infrastructure', ' Fully stocked snacks', ' Build scalable pipelines capable of processing massive amounts of data Build upon existing data service architecture to support internal and external applications Work supporting ETL pipelines, real time streams, and data warehouses Design and implement process improvements, automate manual processes, and redesign infrastructure Build upon on the infrastructure required to optimize the extraction, transformation, and loading of data using Java, Python, SQL Working in a remote setting with virtual team meetings on a regular basis Collaborate with business intelligence and analytics teams to optimize Tableau report queries', ' 10+ years of Java programming experience 7+ years of Python programming experience 7+ years of SQL database experience Strong verbal and written communication experience RESTful API and server-side API integration experience', ' Amazing healthcare benefits', ' Childcare assistance', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : TB10-1597390 -- in the email subject line for your application to be considered.***', ' Work supporting ETL pipelines, real time streams, and data warehouses', ' Experience with Cassandra databases', ' Stipend for workspace', ' 7+ years of SQL database experience', 'Job Duration:', ' Collaborate with business intelligence and analytics teams to optimize Tableau report queries', ' Equipment provided', 'Must Have Skills', 'Email Your Resume In Word To', ' Working in a remote setting with virtual team meetings on a regular basis', ' Experience with Maria databases', 'NOTE:', ' 10+ years of Java programming experience', 'Your Right to Work', ' Build upon on the infrastructure required to optimize the extraction, transformation, and loading of data using Java, Python, SQL']",Entry level,Full-time,Information Technology,Construction,2020-11-05 11:32:32
Marketing Researcher,Robinhood,"Menlo Park, CA",4 hours ago,162 applicants,"['', 'About The Company', ' Proactively and independently identifying high-impact research questions Planning and leading research projects end-to-end, including strategic, foundational, iterative, and evaluative research to achieve our marketing objectives Collaborating with marketing to identify key users and define relevant questions around user needs, attitudes, and engagement Answering those questions with a strong command of qualitative and quantitative methods – especially survey development and related data analysis Integrating alternate data sources (primary and secondary research, campaign analytics, attribution metrics, etc.) to inform and support research Translating research insights into actions and recommendations that will drive brand sentiment, communications, marketing strategy, user acquisition, retention, and engagement Contributing to the development of a data-driven understanding of Robinhood users and potential users  ', '6-8+ years of qualitative/quantitative research experience; it can either be industry-only, or a combination of industry experience and academic research', 'Your Day-to-day Will Involve', 'Contributing to the development of a data-driven understanding of Robinhood users and potential users ', 'Knowledge of brand and advertising research, including marketing effectiveness', 'Passion for working and learning in a fast-growing company', 'Translating research insights into actions and recommendations that will drive brand sentiment, communications, marketing strategy, user acquisition, retention, and engagement', ' 6-8+ years of qualitative/quantitative research experience; it can either be industry-only, or a combination of industry experience and academic research Masters or PhD Degree in Human-Computer Interaction, Psychology, Behavioral Economics, Anthropology, Sociology, or similar Record of applying your research skills to create product and business impact Knowledge of brand and advertising research, including marketing effectiveness Experience directing agencies/vendors Strong work ethic, excellent organization and communication skills Love and care for your craft ', ' Passion for working and learning in a fast-growing company ', 'Record of applying your research skills to create product and business impact', 'Collaborating with marketing to identify key users and define relevant questions around user needs, attitudes, and engagement', 'Bonus Points', 'Strong work ethic, excellent organization and communication skills', 'About The Role', 'Answering those questions with a strong command of qualitative and quantitative methods – especially survey development and related data analysis', 'Experience directing agencies/vendors', 'Planning and leading research projects end-to-end, including strategic, foundational, iterative, and evaluative research to achieve our marketing objectives', 'Integrating alternate data sources (primary and secondary research, campaign analytics, attribution metrics, etc.) to inform and support research', 'Some Things We Consider Critical For This Role', 'Love and care for your craft', 'Masters or PhD Degree in Human-Computer Interaction, Psychology, Behavioral Economics, Anthropology, Sociology, or similar', 'Proactively and independently identifying high-impact research questions']",Associate,Full-time,Marketing,Information Technology and Services,2020-11-05 11:32:32
"AI/ML - Siri Data Engineer, Siri Search, Knowledge & Platform",Apple,"Seattle, WA",13 hours ago,Be among the first 25 applicants,"['', 'Description', 'Key Qualifications', 'Education & Experience', 'Summary', 'Additional Requirements']",Not Applicable,Full-time,Information Technology,Consumer Electronics,2020-11-05 11:32:32
Sr. Data Engineer (REMOTE),CyberCoders,"Houston, TX",6 hours ago,Be among the first 25 applicants,"['', ' Continue to advance the backend platform', ' Python', ' Create solutions to to problems that arise when working with very large sets of data', ' MS or Advanced Degree is a PLUS', ' Work with the team to expand our platform and have a future mindset with design and architecture.', "" Bachelor's degree in Computer science, Engineering, Mathematics or Informatics"", "" Bachelor's degree in Computer science, Engineering, Mathematics or Informatics 5+ years of Data Engineering experience ETL design, implementation and maintenance Experience in the data warehouse space Python Familiarity with tools for analysis of large datasets Data visualization skills (R, and Tableau) is a PLUS MS or Advanced Degree is a PLUS"", 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Work in a team environment where you will be designing, building and maintaining the overall data pipeline', ' Flexible PTO', ' Room to grow with a growing startup', ' Work hand in hand with leadership', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JS21-1610259 -- in the email subject line for your application to be considered.***', ' Data visualization skills (R, and Tableau) is a PLUS', ' 5+ years of Data Engineering experience', ' Experience in the data warehouse space', ' Competitive Salary', 'Email Your Resume In Word To', ' Competitive Salary Flexible PTO Room to grow with a growing startup Work hand in hand with leadership', ' Create data systems that ensure the efficiency and quality of our data platform.', ' Scale ETL and large processing systems to organize large sets of data', ' ETL design, implementation and maintenance', 'Your Right to Work', ' Familiarity with tools for analysis of large datasets', ' Create data systems that ensure the efficiency and quality of our data platform. Create solutions to to problems that arise when working with very large sets of data Continue to advance the backend platform Scale ETL and large processing systems to organize large sets of data Work with the team to expand our platform and have a future mindset with design and architecture. Work in a team environment where you will be designing, building and maintaining the overall data pipeline']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Burlington, VT",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Remote Sr. Data Engineer (Python/GCP),Cypress HCM,"New York, NY",18 hours ago,Be among the first 25 applicants,"['', 'Strong proficiency in Python with an emphasis in building data pipelines', 'Google Cloud Certified - Professional Data Engineer certification would be a plus', 'Can-do attitude on problem-solving, quality and ability to execute', 'Required', 'Requirements:', 'Design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud', 'Familiar with a NoSQL database such as MongoDB', 'Knowledge of Git, Jinja2, Docker(containerization), Bitbucket, and Bamboo', 'Responsibilities', 'Be part of the on-call rotation supporting our SLA’s', 'Strong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow or Google Composer)', 'Advanced SQL programming skills - Ability to write complex SQL to perform common types of analysis and aggregations ', 'Familiar with Atlassian products Jira and Confluence', ""Bachelor's degree in Computer Science or equivalent experience in a related field"", 'Perform data integration related work for the company which includes Ad stack Tech integration, BI continuity and other data integration required for running our businessDesign and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloudIdentify, design and implement internal process improvements by automating manual processes and optimizing data deliveryDevelop and promote best practices in data engineeringDevelop real-time data processing applications using Google CloudBe part of the on-call rotation supporting our SLA’sParticipate in design and code reviews', 'Data Engineer', 'Identify, design and implement internal process improvements by automating manual processes and optimizing data delivery', 'Participate in design and code reviews', 'Google Cloud Certified - Professional Data Engineer certification would be a plusKnowledge of Git, Jinja2, Docker(containerization), Bitbucket, and BambooFamiliar with a NoSQL database such as MongoDBFamiliar with version control systems (Git and Bitbucket)Familiar with Atlassian products Jira and ConfluenceHands-on experience with Apache Airflow or Google ComposerKnowledge of Application Programming Interfaces', 'Develop and promote best practices in data engineering', ""Bachelor's degree in Computer Science or equivalent experience in a related field5+ years of hands-on experience working in data engineering environmentStrong proficiency in Python with an emphasis in building data pipelinesAdvanced SQL programming skills - Ability to write complex SQL to perform common types of analysis and aggregations Experience developing data solutions on GCP (airflow experience)Experience with Apache Airflow or Google ComposerCan-do attitude on problem-solving, quality and ability to executeStrong experience in authoring, scheduling, and monitoring of workflows (Apache Airflow or Google Composer)Strong communication & interpersonal skills"", 'Familiar with version control systems (Git and Bitbucket)', 'Experience with Apache Airflow or Google Composer', 'Preferred', '5+ years of hands-on experience working in data engineering environment', 'Strong communication & interpersonal skills', 'Sr. ', 'Knowledge of Application Programming Interfaces', 'Hands-on experience with Apache Airflow or Google Composer', 'Experience developing data solutions on GCP (airflow experience)', 'Perform data integration related work for the company which includes Ad stack Tech integration, BI continuity and other data integration required for running our business', 'Develop real-time data processing applications using Google Cloud']",Mid-Senior level,Contract,Engineering,Online Media,2020-11-05 11:32:32
Hadoop Consultant,Accenture,"San Francisco, CA",10 hours ago,Be among the first 25 applicants,"['', 'Here’s What You Need: ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.', 'You’ve got experience of full life-cycle development ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Accenture Overview', 'R Studio ', 'Bonus Points If:', 'Jenkins, Chef, Puppet ', ' You Are:', 'Scala, Spark ', 'Minimum of 4 years’ hands-on technical experience implementing Big Data solutions using Hadoop ecosystem ', 'Equal Employment Opportunity:', 'You’re familiar with designing ingestion, low-latency, visualization clusters to sustain data loads ', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'You can configure and support API and Open Source integrations ', 'You have delivered Big Data solutions in the cloud with AWS or Azure or Google Cloud ', 'Amazon S3 ', 'Relational and Non-relations Databases (No-SQL) ', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'You have experience administering Hadoop or other Data Science and Analytics platforms using the technologies above [LC1] ', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Kafka-based streaming services ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'The Work:', 'Experience in developing solutions using any of the following: ', 'You’re no newbie when it comes to working in a DevOps environment ', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Consulting,Information Technology and Services,2020-11-05 11:32:32
Data Engineer II,Amazon Web Services (AWS),"Seattle, WA",4 hours ago,43 applicants,"['', ' Identify, extract, and transform both structured and unstructured data collected from internal tools and systems', ' Promote best practices in creating storage solutions, persistence layers and presentation models', ' Bachelor’s Degree in Computer Science, Information Systems, Mathematics, Statistics, Finance, Business, related field or equivalent working experience 2+ years of experience in data infrastructure management Proficiency in SQL and one common data pipeline language like Python/Java/Scala.', ' Identify, extract, and transform both structured and unstructured data collected from internal tools and systems Promote best practices in creating storage solutions, persistence layers and presentation models Communicate with customers to ensure data is correctly understood and actionable Communicate with software teams and tool developers to expand and improve data collection Work with AWS leadership to present key findings from analyses to stakeholders Provide input on how best to measure the impact and progress of ongoing efforts', 'Preferred Qualifications', 'Company', 'Basic Qualifications', 'Description', ' Communicate with software teams and tool developers to expand and improve data collection', "" Meets/Exceeds Amazon's leadership principles requirements for this role"", ' Excellent verbal/written communication & data presentation skills, including ability to succinctly summarize key findings and effectively communicate with both business and technical teams', ' Proficiency in SQL and one common data pipeline language like Python/Java/Scala.', ' Communicate with customers to ensure data is correctly understood and actionable', ' Experience in working with data visualization (QuickSight or Tableau)', "" Meets/Exceeds Amazon's functional/technical depth and complexity for this role"", ' Demonstrated ability to influence and develop productive working relationships with resources and dependent teams', ' Bachelor’s Degree in Computer Science, Information Systems, Mathematics, Statistics, Finance, Business, related field or equivalent working experience', ' 2+ years of experience in data infrastructure management', ' Work with AWS leadership to present key findings from analyses to stakeholders', "" Experience in design and optimization of data-processing systems using AWS services (S3, EMR, Lambda, Glue, Athena, SNS, CloudWatch, Redshift, Aurora/RDS) Experience in working with data visualization (QuickSight or Tableau) Demonstrated ability to influence and develop productive working relationships with resources and dependent teams Excellent verbal/written communication & data presentation skills, including ability to succinctly summarize key findings and effectively communicate with both business and technical teams Meets/Exceeds Amazon's leadership principles requirements for this role Meets/Exceeds Amazon's functional/technical depth and complexity for this role"", 'Key Responsibilities', ' Experience in design and optimization of data-processing systems using AWS services (S3, EMR, Lambda, Glue, Athena, SNS, CloudWatch, Redshift, Aurora/RDS)', ' Provide input on how best to measure the impact and progress of ongoing efforts']",Mid-Senior level,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
Azure Data Engineer,Cognizant,"Deerfield, IL",18 hours ago,42 applicants,"['', '2-3 years of experience working on Data bricks, Azure Data Factory, Azure Functions, Azure data explorer and other Azure data solutions ecosystems (Mandatory)', 'Propose and develop data solutions to enable effective decision-making, specifically by addressing the enterprise integration requirements', 'Work directly with Business leadership and Application SMEs to understand the requirement and analyzing the source to fulfill the requirement. ', 'Good understanding of data oriented projects for integration and analytics is must.', '2-3 years of experience working on Data bricks, Azure Data Factory, Azure Functions, Azure data explorer and other Azure data solutions ecosystems (Mandatory)2-3 years of experience working on Spark SQL, Hive SQL, USQL, Kusto Query. (Mandatory).2-3 years of experience working on Spark, Scala and Python. (Mandatory)2-3 years of experience working on ADLS, Cosmos DB, Cassandra DB, Mongo DB, Azure Synapse, Azure SQL Server.2-3 years of experience building 2-3 Experience on creating the frameworks towards building the data pipelines. (Mandatory)Must have experience on configure the data streams between Event Hub and Azure Service Bus with other integration systems such as Data Bricks etc., (Mandatory)Must have experience working with Onshore / Offshore model. (Mandatory)Azure Fundamentals Certification (AZ-900) and Azure Data Solution (DP-200 & DP-201) (Preferred).2-3 years of experience working on JAVA or other object oriented programming (Preferred).Extensive experience working on Big data technologies such has Hive, Pig and Map Reduce are preferred.Experience work with structured and unstructured data are must. Good understanding of data oriented projects for integration and analytics is must.Domain: Retail/Supply chain/Pharmacy (Preferred)', 'Propose and develop data solutions to enable effective decision-making, specifically by addressing the enterprise integration requirementsProficient in creating optimized data ingestion and integration pipelinesExperience building integration solutions for variety of data sources including Relational DB Tables, Files, Real Time Streaming Data and Unstructured Data Possess data modelling skills. Build conceptual and logical models based on the functional flow of business in a scalable mode.Analyze the data quality, data governance, compliance and other legal requirements on data storage; address all the required non-business but operational requirements during the design and build of data pipelines. Evaluate and define functional requirements for DW solutionsWork directly with Business leadership and Application SMEs to understand the requirement and analyzing the source to fulfill the requirement. Identify avenues on cost savings either by using in-house Cognizant accelerators or by building re-usable frameworks across the projects.Expert and Key point of contact between the data analyst, data scientists, and the business/application teams.', '2-3 years of experience working on ADLS, Cosmos DB, Cassandra DB, Mongo DB, Azure Synapse, Azure SQL Server.', 'Must have experience on configure the data streams between Event Hub and Azure Service Bus with other integration systems such as Data Bricks etc., (Mandatory)', ""Please note, this role is not able to offer visa transfer or sponsorship now or in the future*Practice - AIA - Artificial Intelligence and AnalyticsThe AIA Practice leads all initiatives surrounding incorporating AI into Customer Intelligence, Operations Intelligence, Product Intelligence, and Fraud InsightsLocationDeerfield IL – Work will be onsite post COVID and remote to startDuties & ResponsibilitiesPropose and develop data solutions to enable effective decision-making, specifically by addressing the enterprise integration requirementsProficient in creating optimized data ingestion and integration pipelinesExperience building integration solutions for variety of data sources including Relational DB Tables, Files, Real Time Streaming Data and Unstructured Data Possess data modelling skills. Build conceptual and logical models based on the functional flow of business in a scalable mode.Analyze the data quality, data governance, compliance and other legal requirements on data storage; address all the required non-business but operational requirements during the design and build of data pipelines. Evaluate and define functional requirements for DW solutionsWork directly with Business leadership and Application SMEs to understand the requirement and analyzing the source to fulfill the requirement. Identify avenues on cost savings either by using in-house Cognizant accelerators or by building re-usable frameworks across the projects.Expert and Key point of contact between the data analyst, data scientists, and the business/application teams.Qualifications2-3 years of experience working on Data bricks, Azure Data Factory, Azure Functions, Azure data explorer and other Azure data solutions ecosystems (Mandatory)2-3 years of experience working on Spark SQL, Hive SQL, USQL, Kusto Query. (Mandatory).2-3 years of experience working on Spark, Scala and Python. (Mandatory)2-3 years of experience working on ADLS, Cosmos DB, Cassandra DB, Mongo DB, Azure Synapse, Azure SQL Server.2-3 years of experience building 2-3 Experience on creating the frameworks towards building the data pipelines. (Mandatory)Must have experience on configure the data streams between Event Hub and Azure Service Bus with other integration systems such as Data Bricks etc., (Mandatory)Must have experience working with Onshore / Offshore model. (Mandatory)Azure Fundamentals Certification (AZ-900) and Azure Data Solution (DP-200 & DP-201) (Preferred).2-3 years of experience working on JAVA or other object oriented programming (Preferred).Extensive experience working on Big data technologies such has Hive, Pig and Map Reduce are preferred.Experience work with structured and unstructured data are must. Good understanding of data oriented projects for integration and analytics is must.Domain: Retail/Supply chain/Pharmacy (Preferred)We pride ourselves on the talent we are able to attract to our organization. We not only hire the best, but continuously strive to provide our associates with opportunities to work with innovative solutions and technologies, with premier clients across the globe. Our diverse backgrounds offer different perspectives and new ways of thinking. It encourages lively discussions, inspires thought leadership, and helps us build better solutions for our clients. We want someone who thrives in this setting and is inspired to craft meaningful solutions through true collaboration.Cognizant is committed to veteran and military communities. Cognizant is a military friendly employer and is a coalition member of the Veteran Jobs Mission. Our business resource group Veterans Network assists our military associates in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence.IND123#CBEmployee Status : Full Time EmployeeShift : Day JobTravel : NoJob Posting : Oct 29 2020About CognizantCognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 194 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @USJobsCognizant.Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.Cognizant is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law.If you have a disability that requires a reasonable accommodation to search for a job opening or submit an application, please email CareersNA2@cognizant.com with your request and contact information."", '2-3 years of experience working on Spark SQL, Hive SQL, USQL, Kusto Query. (Mandatory).', 'Domain: Retail/Supply chain/Pharmacy (Preferred)', 'Location', '2-3 years of experience working on Spark, Scala and Python. (Mandatory)', 'Proficient in creating optimized data ingestion and integration pipelines', 'Azure Data Engineer – Full Time', 'Extensive experience working on Big data technologies such has Hive, Pig and Map Reduce are preferred.', '2-3 years of experience building ', 'Qualifications', 'Evaluate and define functional requirements for DW solutions', 'Analyze the data quality, data governance, compliance and other legal requirements on data storage; address all the required non-business but operational requirements during the design and build of data pipelines. ', '2-3 years of experience working on JAVA or other object oriented programming (Preferred).', 'About Cognizant', 'Experience work with structured and unstructured data are must. ', 'Duties & Responsibilities', 'Must have experience working with Onshore / Offshore model. (Mandatory)', '2-3 Experience on creating the frameworks towards building the data pipelines. (Mandatory)', 'Expert and Key point of contact between the data analyst, data scientists, and the business/application teams.', 'Azure Fundamentals Certification (AZ-900) and Azure Data Solution (DP-200 & DP-201) (Preferred).', 'Experience building integration solutions for variety of data sources including Relational DB Tables, Files, Real Time Streaming Data and Unstructured Data ', 'Identify avenues on cost savings either by using in-house Cognizant accelerators or by building re-usable frameworks across the projects.', 'Practice - AIA - Artificial Intelligence and Analytics', 'Possess data modelling skills. Build conceptual and logical models based on the functional flow of business in a scalable mode.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data & Applied Scientist Manager,Microsoft,United States,21 hours ago,Be among the first 25 applicants,"['', 'Experience leading a diverse team of greater than 10 people, providing coaching and performance management. ', 'Supervise the creation and implementation of new reporting and analyses: data integrity, test design, analysis, validation, and documentation.', 'Minimum of 10 years of related work experience. ', 'Design analytics solutions and reports to measure program impact, identify trends and anomalies, and influence marketing program investments', 'Demonstrated ability to engage with and influence Business Leadership teams in order to drive alignment', 'About The Team', 'Proven ability to solve complex quantitative business challenges; experience in the development of web analytics, anomaly detection or multi-touch attribution is a plus.', 'Ability to work cross-functionally, building and maintaining trust with internal stakeholders', 'Learn and understand a broad range of data resources and know when, how, and which to use and which not to at any given time.Design analytics solutions and reports to measure program impact, identify trends and anomalies, and influence marketing program investmentsOwn the delivery of the reporting and insights on a regular cadence to the stakeholders and senior leadership teamsUnderstanding and proactively communicating factors affecting channel performance to stakeholders by partnering with business leaders, other analysts and data engineering teams.Ensuring insights are both actionable and measurable and you should be able to build these insights and hypothesis with awareness of practical implementation and implications for the businessPartnering with our Digital Analytics and Data Engineering teams to ensure robust and accurate data capture and continuous improvement of data available for both analytics and the wider businessDeveloping and defining analytical vision, strategy and roadmap for the business area, coordinating with leaders to ensure alignment with business goalsSupervise the creation and implementation of new reporting and analyses: data integrity, test design, analysis, validation, and documentation.Be a “doer” as well as a leader - be a data and analytics expert that your team can turn to for inspiration and hands-on guidance. Be able to produce individual analytics work products as needed while continuing to manage the work of the team.Demonstrated ability to engage with and influence Business Leadership teams in order to drive alignmentKnowledge sharing through presentations at regional, channel and business wide events, as well as building relationships with analytics teams across the group.', 'Responsibilities', 'Learn and understand a broad range of data resources and know when, how, and which to use and which not to at any given time.', 'Partnering with our Digital Analytics and Data Engineering teams to ensure robust and accurate data capture and continuous improvement of data available for both analytics and the wider business', 'Be a “doer” as well as a leader - be a data and analytics expert that your team can turn to for inspiration and hands-on guidance. Be able to produce individual analytics work products as needed while continuing to manage the work of the team.', 'Understanding and proactively communicating factors affecting channel performance to stakeholders by partnering with business leaders, other analysts and data engineering teams.', 'Minimum of 10 years of related work experience. Demonstrated ability to manage large scale projects or programs including work prioritization, planning, and coordinationExperience leading a diverse team of greater than 10 people, providing coaching and performance management. Solid communication and data presentation skills, experience analyzing data and communicating the results to senior business leadersAbility to work cross-functionally, building and maintaining trust with internal stakeholdersSolid SQL skills are a requirement - hands on use of big data in large projects using Power BI, Azure, Data Bricks, Presto or SparkProven experience of using R (or similar tools) to structure, transform and visualize big dataSolid understanding of online marketing, preferably in a past or current role, with experience of Search Engine Marketing, Revenue Optimization requiredProven ability to solve complex quantitative business challenges; experience in the development of web analytics, anomaly detection or multi-touch attribution is a plus.Bachelor’s degree or higher in an analytical area such as Computer Science, Management information Systems, Mathematics, Statistics, Engineering or similar field preferred', 'Solid understanding of online marketing, preferably in a past or current role, with experience of Search Engine Marketing, Revenue Optimization required', 'Solid communication and data presentation skills, experience analyzing data and communicating the results to senior business leaders', 'Demonstrated ability to manage large scale projects or programs including work prioritization, planning, and coordination', 'Own the delivery of the reporting and insights on a regular cadence to the stakeholders and senior leadership teams', ' Freedom - Microsoft values everyone’s talent and skillset and provides the freedom to explore and enhance them.', 'Qualifications', 'Developing and defining analytical vision, strategy and roadmap for the business area, coordinating with leaders to ensure alignment with business goals', 'Ensuring insights are both actionable and measurable and you should be able to build these insights and hypothesis with awareness of practical implementation and implications for the business', ' Reach - Microsoft’s resources and scale empowers employees to utilize their skills for lasting impact.', 'Knowledge sharing through presentations at regional, channel and business wide events, as well as building relationships with analytics teams across the group.', 'Bachelor’s degree or higher in an analytical area such as Computer Science, Management information Systems, Mathematics, Statistics, Engineering or similar field preferred', 'Proven experience of using R (or similar tools) to structure, transform and visualize big data', 'Solid SQL skills are a requirement - hands on use of big data in large projects using Power BI, Azure, Data Bricks, Presto or Spark', ' Inspiration - inspiration can be found through our products and how they can improve our customers’ lives.', 'About The You']",Not Applicable,Full-time,Other,Computer Hardware,2020-11-05 11:32:32
Senior Data Scientist,Amazon,"Carolina, NC",6 hours ago,Be among the first 25 applicants,"['', ' Proficiency in model development, model validation and model implementation', ' Implement statistical and machine learning methods to solve complex business problems', ' Proficiency working with R or Python', ' Practical experience with big-data processing libraries, eg. Apache Spark, Apache Beam, Hive, Apache Pig, Hadoop or similar', ' Research new ways to improve predictive and explanatory models', 'Preferred Qualifications', 'Company', ' Extensive knowledge and practical experience in several of the following areas: machine learning, time-series, statistics, deep learning, recommendation systems. Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data. Practical experience with big-data processing libraries, eg. Apache Spark, Apache Beam, Hive, Apache Pig, Hadoop or similar', 'Basic Qualifications', 'Description', ' Directly contribute to the design and development of automated prediction systems and ML infrastructure', ' Experience leading, mentoring, and growing teams of scientists', ' Collaborate with other researchers, software developers, and business leaders to define the scientific roadmap for this team', ' Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data.', "" Bachelor or Master's degree in Statistics, Applied Mathematics, Operation Research, Economics or a related quantitative field 5+ years of hands-on experience in predictive modeling and machine learning Proficiency in model development, model validation and model implementation Proficiency working with R or Python Experience leading, mentoring, and growing teams of scientists"", ' Extensive knowledge and practical experience in several of the following areas: machine learning, time-series, statistics, deep learning, recommendation systems.', ' 5+ years of hands-on experience in predictive modeling and machine learning', 'Key Responsibilities', ' Build models that can detect supply chain defects and explain variance to the optimal state', ' Implement statistical and machine learning methods to solve complex business problems Research new ways to improve predictive and explanatory models Directly contribute to the design and development of automated prediction systems and ML infrastructure Build models that can detect supply chain defects and explain variance to the optimal state Collaborate with other researchers, software developers, and business leaders to define the scientific roadmap for this team', "" Bachelor or Master's degree in Statistics, Applied Mathematics, Operation Research, Economics or a related quantitative field""]",Mid-Senior level,Full-time,Other,Computer Software,2020-11-05 11:32:32
Senior Data Scientist,Apptronic Labs,"San Francisco, CA",5 hours ago,Over 200 applicants,"['', 'Ability to adapt quickly and constructively to changes\xa0', 'Background in cybersecurity or fraud\xa0', 'Responsibilities:', 'Participate in security conference to increase awareness on online fraud and abuse', 'Develop POC as needed and help draft the engineering design to be handed over to the dev team\xa0', 'Effective oral and written communication to peers, leadership, and both technical and non-technical audiences\xa0', 'Solid understanding of the world wide web ecosystem, including protocols (HTTP, DNS), coding (HTML, JS, CSS), issues around privacy…\xa0', 'Occasional travel to customer site as necessary\xa0', 'Follow evolution of privacy features introduced by browser vendors, assess possible impact for the product and propose necessary adjustment as needed.\xa0', ""Example of this includes: user-agent deprecation and transition to client-hints Google privacy sandbox and privacy budget proposal, Safari's intelligent tracking prevention, Firefox enhanced tracking prevention\xa0"", 'Work with the technical product manager team to review requirement and expected outcomes\xa0', 'Startup Experience', 'Nice to haves:', 'Evaluate accuracy of detection methods and propose enhancements as needed\xa0', 'Ability to code, experiment and fail fast\xa0', 'Proven track record of successful application of ML to resolve hard problems\xa0', 'Company Description:', 'The product platform organization is responsible for the overall fraud and abuse protection product strategy. The focus of the team is to define the product requirements, research the best way to defend against the threat vectors and architect the product to meet the following key requirements: Detection: Detect automated and human fraud / abuse through various methods with high accuracy. The detection must be tightly integrated with the challenge framework so as to adopt the most effective response strategy depending on the risk associated with the request session. The challenge framework is managed by Matt Ford’s Product Challenge organization. Visibility: provide a set of dashboard and reports to customers, partner and our support team to allow them to visualize and analyze the fraud activity detected by the product Serviceability: provide customers the ability tune the detection and response strategy based on the risk score. Also provide customers the ability to craft custom logic to meet their own requirements. The product platform consists of technical product managers and the product research team. The product research team is responsible for coming up with different ways to process data collected on a session in order to differentiate bot from human traffic but also detect human fraud within the human traffic. The team may use different techniques including but not limited to statistical model, unsupervised learning, supervised learning, deep learning, whichever model is the most effective to meet the accuracy requirements.', 'Job Description:', 'A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience\xa0', 'A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience\xa03+ years of industry experience in predictive modeling, data science and analysis\xa0Previous experience in a ML or data scientist role and a track record of building ML or DL models\xa0Ability to code, experiment and fail fast\xa0Proven track record of successful application of ML to resolve hard problems\xa0Solid understanding of the world wide web ecosystem, including protocols (HTTP, DNS), coding (HTML, JS, CSS), issues around privacy…\xa0Effective oral and written communication to peers, leadership, and both technical and non-technical audiences\xa0Ability to adapt quickly and constructively to changes\xa0A breadth of technical aptitude to talk shop to our engineers Ambitious, accountable, and be a self-starter', ""Work with the technical product manager team to review requirement and expected outcomes\xa0Research and develop new ML models as necessary to meet agreed upon product requirements and goals\xa0Develop POC as needed and help draft the engineering design to be handed over to the dev team\xa0Evaluate accuracy of detection methods and propose enhancements as needed\xa0Research newer internet protocol that could provide additional signals that may be relevant to improve detection for example HTTP/2 or HTTP/3\xa0Research product workflow change or features that will improve detection and ensure optimal user experience\xa0Follow evolution of privacy features introduced by browser vendors, assess possible impact for the product and propose necessary adjustment as needed.\xa0Example of this includes: user-agent deprecation and transition to client-hints Google privacy sandbox and privacy budget proposal, Safari's intelligent tracking prevention, Firefox enhanced tracking prevention\xa0Get involved in customers calls on occasion to discuss future product directions\xa0Work with the Customer Success team to assist as needed with complex escalation, training on new detection methods and best practices for effectively defending against attacks\xa0Occasional travel to customer site as necessary\xa0Participate in security conference to increase awareness on online fraud and abuse"", 'We also offer flexible PTO and some WFH opportunities as needed.', 'Research newer internet protocol that could provide additional signals that may be relevant to improve detection for example HTTP/2 or HTTP/3\xa0', 'Get involved in customers calls on occasion to discuss future product directions\xa0', 'Benefits:', 'Competitive salary, equity, and a robust benefits package includes top-notch medical, dental, vision, life insurance, 401k, commuter benefits and we cover 95% of the cost of employee benefits and 65% of the cost of dependent care coverage!\xa0', 'Experience working in the web security space is a plus (fraud, bot management, abuse, web application firewall)\xa0Background in cybersecurity or fraud\xa0Startup Experience', 'Work with the Customer Success team to assist as needed with complex escalation, training on new detection methods and best practices for effectively defending against attacks\xa0', 'General Requirements:', 'Required Skills: Machine Learning, Data Science, Deep Learning, Data Modeling, HTTP, DNS, HTML, JavaScript, JS, CSS, Python, R, SQL', 'A breadth of technical aptitude to talk shop to our engineers Ambitious, accountable, and be a self-starter', 'Research product workflow change or features that will improve detection and ensure optimal user experience\xa0', 'Research and develop new ML models as necessary to meet agreed upon product requirements and goals\xa0', 'Experience working in the web security space is a plus (fraud, bot management, abuse, web application firewall)\xa0', 'Previous experience in a ML or data scientist role and a track record of building ML or DL models\xa0', '3+ years of industry experience in predictive modeling, data science and analysis\xa0', 'We are a fast-growing startup that is disrupting the fraud industry by putting the control back into the hands of digital businesses with an innovative approach that bankrupts the underlying business model of fraudsters. Our fraud and abuse prevention platform combines real-time intelligence, rich analytics and adaptive step-up challenges to progressively diminish the profitability of attacks while adapting to evolving attack patterns. We offer the only fraud solution with a 100% SLA guarantee. The world’s largest brands trust us to protect their customer journey while delivering unrivaled customer experience.', 'Competitive salary, equity, and a robust benefits package includes top-notch medical, dental, vision, life insurance, 401k, commuter benefits and we cover 95% of the cost of employee benefits and 65% of the cost of dependent care coverage!\xa0We also offer flexible PTO and some WFH opportunities as needed.']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Data Engineer - Front Store Personalization,CVS Health,"Woonsocket, RI",4 hours ago,Be among the first 25 applicants,"['', 'Job Description', 'Education', 'Business Overview', 'Required Qualifications', 'Preferred Qualifications']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer - Remote,N/A,"South Kent, CT",16 hours ago,Be among the first 25 applicants,"['', '2nd Nov, 2020 Reference', 'Permanent Date Posted']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Engineer (REMOTE),Optello,"Houston, TX",2 hours ago,Be among the first 25 applicants,"['', ' Continue to advance the backend platform', 'Optello is proud to be an Equal Opportunity Employer', ' Python', ' Create solutions to to problems that arise when working with very large sets of data', ' MS or Advanced Degree is a PLUS', ' Work with the team to expand our platform and have a future mindset with design and architecture.', "" Bachelor's degree in Computer science, Engineering, Mathematics or Informatics"", "" Bachelor's degree in Computer science, Engineering, Mathematics or Informatics 5+ years of Data Engineering experience ETL design, implementation and maintenance Experience in the data warehouse space Python Familiarity with tools for analysis of large datasets Data visualization skills (R, and Tableau) is a PLUS MS or Advanced Degree is a PLUS"", ' Work in a team environment where you will be designing, building and maintaining the overall data pipeline', ' Flexible PTO', ' Room to grow with a growing startup', ' Work hand in hand with leadership', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JS21-1610259 -- in the email subject line for your application to be considered.***', ' Data visualization skills (R, and Tableau) is a PLUS', ' 5+ years of Data Engineering experience', ' Experience in the data warehouse space', ' Competitive Salary', 'Email Your Resume In Word To', ' Competitive Salary Flexible PTO Room to grow with a growing startup Work hand in hand with leadership', ' Create data systems that ensure the efficiency and quality of our data platform.', ' Scale ETL and large processing systems to organize large sets of data', ' ETL design, implementation and maintenance', 'Your Right to Work', ' Familiarity with tools for analysis of large datasets', ' Create data systems that ensure the efficiency and quality of our data platform. Create solutions to to problems that arise when working with very large sets of data Continue to advance the backend platform Scale ETL and large processing systems to organize large sets of data Work with the team to expand our platform and have a future mindset with design and architecture. Work in a team environment where you will be designing, building and maintaining the overall data pipeline']",Associate,Full-time,Information Technology,Construction,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Omaha, NE",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Scientist-100% REMOTE (Local candidates preferred),CyberCoders,"Alexandria, VA",22 hours ago,Be among the first 25 applicants,"['', 'Transportation benefits & cell phone reimbursement', 'Collaborate with the product team, executives, & other stakeholders to define whats possible', 'Nice to have: experience with Spark or other big data framework', 'Nice to have: Ph.D. in a math-related field', 'Experience working with Python & associated ecosystem', 'Deliver work on a cadence within an agile framework', 'Great medical, dental & vision Insurance packages', 'Lead definition and implementation of descriptive and predictive models across a variety of marketing tech functional areasCollaborate with the product team, executives, & other stakeholders to define whats possibleDeliver output of the highest quality, including code, models, & documentationContribute to the development of data pipelinesDeliver work on a cadence within an agile framework', 'Contribute to the development of data pipelines', 'Casual dress all day, every day', 'Recognition and reward for outstanding performance', 'Collaborative and creative atmosphere, with inspired leadership', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', 'Competitive 401K with company match to plan for the long term', 'Experience working with SQL', 'MS in a math-related field', 'Competitive salary with high bonus potential', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : SW3-1605571 -- in the email subject line for your application to be considered.***', 'MS in a math-related field5+ years of experience in data scienceExperience working with SQLExperience working with Python & associated ecosystemNice to have: Ph.D. in a math-related fieldNice to have: experience with Spark or other big data frameworkNice to have: Exposure to ad tech concepts & terminology', '5+ years of experience in data science', 'Unlimited paid-time-off', 'Nice to have: Exposure to ad tech concepts & terminology', 'Lead definition and implementation of descriptive and predictive models across a variety of marketing tech functional areas', 'Competitive salary with high bonus potentialCollaborative and creative atmosphere, with inspired leadershipCareer advancement opportunitiesRecognition and reward for outstanding performanceGreat medical, dental & vision Insurance packagesCompetitive 401K with company match to plan for the long termUnlimited paid-time-offTransportation benefits & cell phone reimbursementCasual dress all day, every day', 'Email Your Resume In Word To', 'Deliver output of the highest quality, including code, models, & documentation', 'Your Right to Work', 'Career advancement opportunities']",Mid-Senior level,Full-time,Information Technology,Broadcast Media,2020-11-05 11:32:32
Underwater Acoustics Researcher,Systems & Technology Research,"Dayton, OH",19 hours ago,Be among the first 25 applicants,"['', 'Active Security Clearance at the Secret or Top Secret (TS) level', 'PhD or MS degree with research experience in physical oceanography, underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field', 'Description', 'Strong scientific programming skills in MATLAB, Python, and/or C/C++', ' Physics and statistics based underwater acoustic propagation modeling and simulation Develop models for acoustics sources and receivers to model system performance Participate in at-sea data collections including experiment design and analysis of collected data ', 'Desired Qualifications', 'Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects', 'Physics and statistics based underwater acoustic propagation modeling and simulation', 'US Citizenship with the ability to obtain a Security Clearance', 'Participate in at-sea data collections including experiment design and analysis of collected data', 'Scientific curiosity and creativity', 'Requirements', 'Familiarity with various acoustic propagation modeling software (KRAKEN, OASIS, BELLHOP)', 'Interest and aptitude for working complex technical projects', 'Responsibilities Include', 'Knowledge of one or more of the following topic areas: underwater acoustic propagation or communications modeling, ocean modeling, statistics', 'Develop models for acoustics sources and receivers to model system performance', 'Demonstrated understanding of underwater acoustics and sonar sensor technologies', ' US Citizenship with the ability to obtain a Security Clearance PhD or MS degree with research experience in physical oceanography, underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field Demonstrated understanding of underwater acoustics and sonar sensor technologies Strong scientific programming skills in MATLAB, Python, and/or C/C++ Familiarity with various acoustic propagation modeling software (KRAKEN, OASIS, BELLHOP) Interest and aptitude for working complex technical projects Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects Scientific curiosity and creativity Knowledge of one or more of the following topic areas: underwater acoustic propagation or communications modeling, ocean modeling, statistics ']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Hadoop Consultant,Accenture,"Seattle, WA",10 hours ago,Be among the first 25 applicants,"['', 'Here’s What You Need: ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.', 'You’ve got experience of full life-cycle development ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Accenture Overview', 'R Studio ', 'Bonus Points If:', 'Jenkins, Chef, Puppet ', ' You Are:', 'Scala, Spark ', 'Minimum of 4 years’ hands-on technical experience implementing Big Data solutions using Hadoop ecosystem ', 'Equal Employment Opportunity:', 'You’re familiar with designing ingestion, low-latency, visualization clusters to sustain data loads ', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'You can configure and support API and Open Source integrations ', 'You have delivered Big Data solutions in the cloud with AWS or Azure or Google Cloud ', 'Amazon S3 ', 'Relational and Non-relations Databases (No-SQL) ', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'You have experience administering Hadoop or other Data Science and Analytics platforms using the technologies above [LC1] ', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Kafka-based streaming services ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'The Work:', 'Experience in developing solutions using any of the following: ', 'You’re no newbie when it comes to working in a DevOps environment ', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Consulting,Information Technology and Services,2020-11-05 11:32:32
Sr Data Engineer,Cypress HCM,"San Diego, CA",1 day ago,31 applicants,"['Significant experience with Spark, Kafka, Nifi, and other streaming data tools ', 'Responsibilities:', 'Build integrated and automated data pipelines using the Hadoop Ecosystem (Spark, Kafka, Hive, Yarn, Oozie) \xa0 ', 'Extensive experience working with the Apache Hadoop Ecosystem \xa0 ', 'Bachelor’s Degree in Computer Science or related ', 'Bachelor’s Degree in Computer Science or related Extensive experience working with the Apache Hadoop Ecosystem \xa0 Working experience with MS SQL Server or other RDBMS \xa0 Significant experience with Spark, Kafka, Nifi, and other streaming data tools Strong knowledge of the Hadoop Ecosystem including HDFS, MapReduce, Sqoop, Yarn, Hive, and Oozie Solid understanding of T-SQL and ETL programming including SQL Server Integration Services (SSIS) \xa0 Extensive knowledge of common data warehousing technologies and techniques', 'Mentor and coach junior engineers, software developers, and data analysts \xa0 \xa0 \xa0 ', 'Process documentation and data flow diagramming \xa0 ', 'Participate in the research, design, and testing of next generation data engine platforms ', 'Requirements: ', 'Participate in the full software development lifecycle (requirements, design, code, unit test, deployment, sustaining) Develop and manage steaming data pipelines used for training and developing machine learning models Participate in the research, design, and testing of next generation data engine platforms Develop and guide long-term strategy for data pipelines and persistent data storage Evaluate and recommend database infrastructure and tools including cloud technologies\xa0 Build integrated and automated data pipelines using the Hadoop Ecosystem (Spark, Kafka, Hive, Yarn, Oozie) \xa0 Develop efficient and effective T-SQL to extract, transform, and load data from source systems Process documentation and data flow diagramming \xa0 Mentor and coach junior engineers, software developers, and data analysts \xa0 \xa0 \xa0 ', 'Extensive knowledge of common data warehousing technologies and techniques', 'Develop and manage steaming data pipelines used for training and developing machine learning models ', 'Strong knowledge of the Hadoop Ecosystem including HDFS, MapReduce, Sqoop, Yarn, Hive, and Oozie ', 'Evaluate and recommend database infrastructure and tools including cloud technologies\xa0 ', 'Requirements', 'Participate in the full software development lifecycle (requirements, design, code, unit test, deployment, sustaining) ', 'Develop efficient and effective T-SQL to extract, transform, and load data from source systems ', ' ', 'Working experience with MS SQL Server or other RDBMS \xa0 ', 'Solid understanding of T-SQL and ETL programming including SQL Server Integration Services (SSIS) \xa0 ', 'Develop and guide long-term strategy for data pipelines and persistent data storage ', 'Responsibilities: ']",Mid-Senior level,Full-time,Engineering,Computer Software,2020-11-05 11:32:32
Apple Music - Senior Software Data Engineer,Apple,"New York, NY",13 hours ago,Be among the first 25 applicants,"['', 'Description', 'Key Qualifications', 'Education & Experience', 'Summary']",Not Applicable,Full-time,Information Technology,Consumer Electronics,2020-11-05 11:32:32
Hadoop Developer,Cognizant,"Wilmington, DE",5 hours ago,Be among the first 25 applicants,"['', ' 1+ years of experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift', 'Create and maintain optimal data pipeline architecture, Assemble large, sophisticated data sets that meet functional / non-functional business requirements.', 'You must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.', 'Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', 'Responsibilities', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big data’ technologies.', ' VA / DE / Dallas, TX', ' Experience with stream-processing systems: Storm, Spark-Streaming, etc. (Nice to have)', ' Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.', 'Create and maintain optimal data pipeline architecture, Assemble large, sophisticated data sets that meet functional / non-functional business requirements.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘Big data’ technologies.Build analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency and other key business performance metrics.Work with partners including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.', ' 1+ Years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra. Cognizant will not be able to provide sponsorship for this role. Candidates have the option of working remotely.', ' 3+ years of experience (Mid-level) Experience with big data tools: Hadoop, Apache Spark, Kafka, etc', 'Build analytics tools that utilize the data pipeline to deliver impactful insights into customer acquisition, operational efficiency and other key business performance metrics.', 'Qualifications', 'About Cognizant', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.', ' 3+ years of experience (Mid-level) Strong Programming experience with object-oriented/object function scripting languages: Python/Scala, Spark.', 'Work with partners including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.']",Entry level,Full-time,Engineering,Information Technology and Services,2020-11-05 11:32:32
"Sr. Data Engineer, AWS Specialized Sales Org",Amazon Web Services (AWS),"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Strong problem-solving skills with the ability to navigate highly complex and ambiguous situations', ' Analyze source systems, define underlying data sources and transformation requirements, design suitable data models, and document design specifications', ' Demonstrate passion for quality and productivity by use of efficient development techniques', ' Bachelor’s degree or higher in an engineering or technical field such as Computer Science, Mathematics, Statistics, Engineering or similar', ' Apply your knowledge of technology options to design and build systems that meet business needs', "" Master's degree in an engineering or technical field such as Computer Science, Physics, Mathematics, Statistics, or Engineering"", 'Preferred Qualifications', ' Experience leading design and development of open data platforms using AWS technologies', 'Company', ' Strong interpersonal skills and the ability to work effectively across teams', ' 5+ years of building ETL systems', 'Basic Qualifications', ' Experience hiring and developing the best direct reports', 'Description', ' Play a leading role in architecture design and implementation of next generation BI solutions', ' Great communication skills - ability to think creatively and adapt the message to the audience, providing information to technical and non-technical stakeholders alike', ' Proficiency in shell scripting', ' Bachelor’s degree or higher in an engineering or technical field such as Computer Science, Mathematics, Statistics, Engineering or similar Advanced knowledge of SQL 5+ years of building ETL systems Proficiency in shell scripting Experience writing Python code Experience managing competing priorities simultaneously and driving projects to completion Great communication skills - ability to think creatively and adapt the message to the audience, providing information to technical and non-technical stakeholders alike', ' Apply your knowledge of technology options to design and build systems that meet business needs Analyze source systems, define underlying data sources and transformation requirements, design suitable data models, and document design specifications Play a leading role in architecture design and implementation of next generation BI solutions Demonstrate passion for quality and productivity by use of efficient development techniques Effectively communicate with stakeholder teams If interested, manage a team of more junior Data Engineers', "" Master's degree in an engineering or technical field such as Computer Science, Physics, Mathematics, Statistics, or Engineering Strong interpersonal skills and the ability to work effectively across teams Experience hiring and developing the best direct reports Experience leading design and development of open data platforms using AWS technologies Experience with AWS cloud technologies such as Elastic Map Reduce (EMR), Kinesis, Athena Strong problem-solving skills with the ability to navigate highly complex and ambiguous situations A self-starter who loves data and who enjoys spotting the trends in it"", ' Experience writing Python code', 'Key Responsibilities Include', ' If interested, manage a team of more junior Data Engineers', ' Experience managing competing priorities simultaneously and driving projects to completion', ' Experience with AWS cloud technologies such as Elastic Map Reduce (EMR), Kinesis, Athena', ' Effectively communicate with stakeholder teams', ' Advanced knowledge of SQL', ' A self-starter who loves data and who enjoys spotting the trends in it']",Mid-Senior level,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
Data & Applied Scientist Manager,Microsoft,"Redmond, WA",21 hours ago,Be among the first 25 applicants,"['', 'Experience leading a diverse team of greater than 10 people, providing coaching and performance management. ', 'Supervise the creation and implementation of new reporting and analyses: data integrity, test design, analysis, validation, and documentation.', 'Minimum of 10 years of related work experience. ', 'Design analytics solutions and reports to measure program impact, identify trends and anomalies, and influence marketing program investments', 'Demonstrated ability to engage with and influence Business Leadership teams in order to drive alignment', 'About The Team', 'Proven ability to solve complex quantitative business challenges; experience in the development of web analytics, anomaly detection or multi-touch attribution is a plus.', 'Ability to work cross-functionally, building and maintaining trust with internal stakeholders', 'Learn and understand a broad range of data resources and know when, how, and which to use and which not to at any given time.Design analytics solutions and reports to measure program impact, identify trends and anomalies, and influence marketing program investmentsOwn the delivery of the reporting and insights on a regular cadence to the stakeholders and senior leadership teamsUnderstanding and proactively communicating factors affecting channel performance to stakeholders by partnering with business leaders, other analysts and data engineering teams.Ensuring insights are both actionable and measurable and you should be able to build these insights and hypothesis with awareness of practical implementation and implications for the businessPartnering with our Digital Analytics and Data Engineering teams to ensure robust and accurate data capture and continuous improvement of data available for both analytics and the wider businessDeveloping and defining analytical vision, strategy and roadmap for the business area, coordinating with leaders to ensure alignment with business goalsSupervise the creation and implementation of new reporting and analyses: data integrity, test design, analysis, validation, and documentation.Be a “doer” as well as a leader - be a data and analytics expert that your team can turn to for inspiration and hands-on guidance. Be able to produce individual analytics work products as needed while continuing to manage the work of the team.Demonstrated ability to engage with and influence Business Leadership teams in order to drive alignmentKnowledge sharing through presentations at regional, channel and business wide events, as well as building relationships with analytics teams across the group.', 'Responsibilities', 'Learn and understand a broad range of data resources and know when, how, and which to use and which not to at any given time.', 'Partnering with our Digital Analytics and Data Engineering teams to ensure robust and accurate data capture and continuous improvement of data available for both analytics and the wider business', 'Be a “doer” as well as a leader - be a data and analytics expert that your team can turn to for inspiration and hands-on guidance. Be able to produce individual analytics work products as needed while continuing to manage the work of the team.', 'Understanding and proactively communicating factors affecting channel performance to stakeholders by partnering with business leaders, other analysts and data engineering teams.', 'Minimum of 10 years of related work experience. Demonstrated ability to manage large scale projects or programs including work prioritization, planning, and coordinationExperience leading a diverse team of greater than 10 people, providing coaching and performance management. Solid communication and data presentation skills, experience analyzing data and communicating the results to senior business leadersAbility to work cross-functionally, building and maintaining trust with internal stakeholdersSolid SQL skills are a requirement - hands on use of big data in large projects using Power BI, Azure, Data Bricks, Presto or SparkProven experience of using R (or similar tools) to structure, transform and visualize big dataSolid understanding of online marketing, preferably in a past or current role, with experience of Search Engine Marketing, Revenue Optimization requiredProven ability to solve complex quantitative business challenges; experience in the development of web analytics, anomaly detection or multi-touch attribution is a plus.Bachelor’s degree or higher in an analytical area such as Computer Science, Management information Systems, Mathematics, Statistics, Engineering or similar field preferred', 'Solid understanding of online marketing, preferably in a past or current role, with experience of Search Engine Marketing, Revenue Optimization required', 'Solid communication and data presentation skills, experience analyzing data and communicating the results to senior business leaders', 'Demonstrated ability to manage large scale projects or programs including work prioritization, planning, and coordination', 'Own the delivery of the reporting and insights on a regular cadence to the stakeholders and senior leadership teams', ' Freedom - Microsoft values everyone’s talent and skillset and provides the freedom to explore and enhance them.', 'Qualifications', 'Developing and defining analytical vision, strategy and roadmap for the business area, coordinating with leaders to ensure alignment with business goals', 'Ensuring insights are both actionable and measurable and you should be able to build these insights and hypothesis with awareness of practical implementation and implications for the business', ' Reach - Microsoft’s resources and scale empowers employees to utilize their skills for lasting impact.', 'Knowledge sharing through presentations at regional, channel and business wide events, as well as building relationships with analytics teams across the group.', 'Bachelor’s degree or higher in an analytical area such as Computer Science, Management information Systems, Mathematics, Statistics, Engineering or similar field preferred', 'Proven experience of using R (or similar tools) to structure, transform and visualize big data', 'Solid SQL skills are a requirement - hands on use of big data in large projects using Power BI, Azure, Data Bricks, Presto or Spark', ' Inspiration - inspiration can be found through our products and how they can improve our customers’ lives.', 'About The You']",Not Applicable,Full-time,Other,Computer Hardware,2020-11-05 11:32:32
Senior Research Scientist,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Excellent written and verbal communication skills with technical and business teams; ability to speak at a level appropriate for the audience. The ideal candidate can present business cases and document the models and analysis and present the results in order to influence important decisions', ' Create prototypes and simulations to test devised solutions', ' Mentor team members for their career development and growth', ' Ability to distill problem definitions, models, and constraints from informal business requirements; and to deal with ambiguity and competing objectives', ' Demonstrated use of modeling and mathematical optimization techniques tailored to meet real life problems through a record of achievements in industrial and/or academic environments', ' Interact with engineering, operations, science and business teams to develop an understanding and domain knowledge of processes, system structures, and business requirements Apply domain knowledge and business judgment to identify opportunities and quantify the impact aligning research direction to business requirements and make the right judgment on research project prioritization Develop scalable mathematical models to derive optimal or near-optimal solutions to existing and new supply chain challenges Create prototypes and simulations to test devised solutions Advocate technical solutions to business stakeholders, engineering teams, as well as executive-level decision makers Work closely with engineers to integrate prototypes into production system Create policy evaluation methods to track the actual performance of devised solutions in production systems, identify areas with potential for improvement and work with internal teams to improve the solution with new features Mentor team members for their career development and growth Present business cases and document models, analyses, and their results in order to influence important decisions', ' Hands-on experience in building end-to-end mathematical models and prototyping Deep expertise in stochastic and deterministic optimization techniques and simulation Experience in inventory optimization Experience in common predictive analytic methods Expert in one or proficient in more than one major programming language (Mosel, AMPL, Python, C/C++/Java, SSJ, Matlab, Arena, etc.) A working knowledge of linear and non-linear optimization methods accompanied by expertise in the use of OR tools (e.g. CPLEX, Gurobi, XPRESS). Expertise in prototyping with applications of efficient large-scale data analysis in a complicated system Experience and/or academic research in area of online retail and competition with brick and mortar stores; mechanism design and coordination/contracting within supply chains; or Pricing and Revenue Management', ' Expertise in prototyping with applications of efficient large-scale data analysis in a complicated system', 'Preferred Qualifications', ' Create policy evaluation methods to track the actual performance of devised solutions in production systems, identify areas with potential for improvement and work with internal teams to improve the solution with new features', 'Company', ' A working knowledge of linear and non-linear optimization methods accompanied by expertise in the use of OR tools (e.g. CPLEX, Gurobi, XPRESS).', 'Responsibilities', ' Experience in common predictive analytic methods', 'Basic Qualifications', 'Description', ' Ability to quantify improvement in business areas resulting from optimization techniques through use of business analytics and/or statistical modeling', ' Apply domain knowledge and business judgment to identify opportunities and quantify the impact aligning research direction to business requirements and make the right judgment on research project prioritization', ' Ph.D. in Operations Research, Operations Management, Engineering, Computer Science, Applied Mathematics, or a related quantitative field', ' Develop scalable mathematical models to derive optimal or near-optimal solutions to existing and new supply chain challenges', ' Deep expertise in stochastic and deterministic optimization techniques and simulation', ' Ph.D. in Operations Research, Operations Management, Engineering, Computer Science, Applied Mathematics, or a related quantitative field 5+ years of relevant industrial research experience in supply chain management, inventory management, operations management, simulation or a closely related field 2+ years hands-on experience in a high level programming language (Python, Perl, Scala, Java, C#, C++ or other similar language) Ability to distill problem definitions, models, and constraints from informal business requirements; and to deal with ambiguity and competing objectives Ability to quantify improvement in business areas resulting from optimization techniques through use of business analytics and/or statistical modeling Demonstrated use of modeling and mathematical optimization techniques tailored to meet real life problems through a record of achievements in industrial and/or academic environments Excellent written and verbal communication skills with technical and business teams; ability to speak at a level appropriate for the audience. The ideal candidate can present business cases and document the models and analysis and present the results in order to influence important decisions', ' 2+ years hands-on experience in a high level programming language (Python, Perl, Scala, Java, C#, C++ or other similar language)', ' 5+ years of relevant industrial research experience in supply chain management, inventory management, operations management, simulation or a closely related field', ' Hands-on experience in building end-to-end mathematical models and prototyping', ' Expert in one or proficient in more than one major programming language (Mosel, AMPL, Python, C/C++/Java, SSJ, Matlab, Arena, etc.)', ' Advocate technical solutions to business stakeholders, engineering teams, as well as executive-level decision makers', ' Present business cases and document models, analyses, and their results in order to influence important decisions', ' Work closely with engineers to integrate prototypes into production system', ' Experience in inventory optimization', ' Experience and/or academic research in area of online retail and competition with brick and mortar stores; mechanism design and coordination/contracting within supply chains; or Pricing and Revenue Management', ' Interact with engineering, operations, science and business teams to develop an understanding and domain knowledge of processes, system structures, and business requirements']",Mid-Senior level,Full-time,Research,Computer Software,2020-11-05 11:32:32
Senior Data Scientist,Apptronic Labs,"San Francisco, CA",5 hours ago,89 applicants,"['', 'Ability to adapt quickly and constructively to changes\xa0', 'Background in cybersecurity or fraud\xa0', 'Responsibilities:', 'Participate in security conference to increase awareness on online fraud and abuse', 'Develop POC as needed and help draft the engineering design to be handed over to the dev team\xa0', 'Effective oral and written communication to peers, leadership, and both technical and non-technical audiences\xa0', 'Solid understanding of the world wide web ecosystem, including protocols (HTTP, DNS), coding (HTML, JS, CSS), issues around privacy…\xa0', 'Occasional travel to customer site as necessary\xa0', 'Follow evolution of privacy features introduced by browser vendors, assess possible impact for the product and propose necessary adjustment as needed.\xa0', ""Example of this includes: user-agent deprecation and transition to client-hints Google privacy sandbox and privacy budget proposal, Safari's intelligent tracking prevention, Firefox enhanced tracking prevention\xa0"", 'Work with the technical product manager team to review requirement and expected outcomes\xa0', 'Startup Experience', 'Nice to haves:', 'Evaluate accuracy of detection methods and propose enhancements as needed\xa0', 'Ability to code, experiment and fail fast\xa0', 'Proven track record of successful application of ML to resolve hard problems\xa0', 'Company Description:', 'The product platform organization is responsible for the overall fraud and abuse protection product strategy. The focus of the team is to define the product requirements, research the best way to defend against the threat vectors and architect the product to meet the following key requirements: Detection: Detect automated and human fraud / abuse through various methods with high accuracy. The detection must be tightly integrated with the challenge framework so as to adopt the most effective response strategy depending on the risk associated with the request session. The challenge framework is managed by Matt Ford’s Product Challenge organization. Visibility: provide a set of dashboard and reports to customers, partner and our support team to allow them to visualize and analyze the fraud activity detected by the product Serviceability: provide customers the ability tune the detection and response strategy based on the risk score. Also provide customers the ability to craft custom logic to meet their own requirements. The product platform consists of technical product managers and the product research team. The product research team is responsible for coming up with different ways to process data collected on a session in order to differentiate bot from human traffic but also detect human fraud within the human traffic. The team may use different techniques including but not limited to statistical model, unsupervised learning, supervised learning, deep learning, whichever model is the most effective to meet the accuracy requirements.', 'Job Description:', 'A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience\xa0', 'A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience\xa03+ years of industry experience in predictive modeling, data science and analysis\xa0Previous experience in a ML or data scientist role and a track record of building ML or DL models\xa0Ability to code, experiment and fail fast\xa0Proven track record of successful application of ML to resolve hard problems\xa0Solid understanding of the world wide web ecosystem, including protocols (HTTP, DNS), coding (HTML, JS, CSS), issues around privacy…\xa0Effective oral and written communication to peers, leadership, and both technical and non-technical audiences\xa0Ability to adapt quickly and constructively to changes\xa0A breadth of technical aptitude to talk shop to our engineers Ambitious, accountable, and be a self-starter', ""Work with the technical product manager team to review requirement and expected outcomes\xa0Research and develop new ML models as necessary to meet agreed upon product requirements and goals\xa0Develop POC as needed and help draft the engineering design to be handed over to the dev team\xa0Evaluate accuracy of detection methods and propose enhancements as needed\xa0Research newer internet protocol that could provide additional signals that may be relevant to improve detection for example HTTP/2 or HTTP/3\xa0Research product workflow change or features that will improve detection and ensure optimal user experience\xa0Follow evolution of privacy features introduced by browser vendors, assess possible impact for the product and propose necessary adjustment as needed.\xa0Example of this includes: user-agent deprecation and transition to client-hints Google privacy sandbox and privacy budget proposal, Safari's intelligent tracking prevention, Firefox enhanced tracking prevention\xa0Get involved in customers calls on occasion to discuss future product directions\xa0Work with the Customer Success team to assist as needed with complex escalation, training on new detection methods and best practices for effectively defending against attacks\xa0Occasional travel to customer site as necessary\xa0Participate in security conference to increase awareness on online fraud and abuse"", 'We also offer flexible PTO and some WFH opportunities as needed.', 'Research newer internet protocol that could provide additional signals that may be relevant to improve detection for example HTTP/2 or HTTP/3\xa0', 'Get involved in customers calls on occasion to discuss future product directions\xa0', 'Benefits:', 'Competitive salary, equity, and a robust benefits package includes top-notch medical, dental, vision, life insurance, 401k, commuter benefits and we cover 95% of the cost of employee benefits and 65% of the cost of dependent care coverage!\xa0', 'Experience working in the web security space is a plus (fraud, bot management, abuse, web application firewall)\xa0Background in cybersecurity or fraud\xa0Startup Experience', 'Work with the Customer Success team to assist as needed with complex escalation, training on new detection methods and best practices for effectively defending against attacks\xa0', 'General Requirements:', 'Required Skills: Machine Learning, Data Science, Deep Learning, Data Modeling, HTTP, DNS, HTML, JavaScript, JS, CSS, Python, R, SQL', 'A breadth of technical aptitude to talk shop to our engineers Ambitious, accountable, and be a self-starter', 'Research product workflow change or features that will improve detection and ensure optimal user experience\xa0', 'Research and develop new ML models as necessary to meet agreed upon product requirements and goals\xa0', 'Experience working in the web security space is a plus (fraud, bot management, abuse, web application firewall)\xa0', 'Previous experience in a ML or data scientist role and a track record of building ML or DL models\xa0', '3+ years of industry experience in predictive modeling, data science and analysis\xa0', 'We are a fast-growing startup that is disrupting the fraud industry by putting the control back into the hands of digital businesses with an innovative approach that bankrupts the underlying business model of fraudsters. Our fraud and abuse prevention platform combines real-time intelligence, rich analytics and adaptive step-up challenges to progressively diminish the profitability of attacks while adapting to evolving attack patterns. We offer the only fraud solution with a 100% SLA guarantee. The world’s largest brands trust us to protect their customer journey while delivering unrivaled customer experience.', 'Competitive salary, equity, and a robust benefits package includes top-notch medical, dental, vision, life insurance, 401k, commuter benefits and we cover 95% of the cost of employee benefits and 65% of the cost of dependent care coverage!\xa0We also offer flexible PTO and some WFH opportunities as needed.']",Mid-Senior level,Full-time,Engineering,Internet,2020-11-05 11:32:32
Data Engineer with DataBricks Exp,N/A,Miami-Fort Lauderdale Area,17 hours ago,Be among the first 25 applicants,"['', 'Must have an expert in DATABRICKS and be willing to take an online coding challenge on DATABRICKS', 'Azure SQL Managed Instance is a plus\xa0', 'Note: 100% REMOTE, Our client is looking for consultants who are authorized to work for client. No visa sponser', 'AZURE SYNAPSE\xa0', 'ETL Developer', 'SQL', 'Job Description:']",Mid-Senior level,Contract,Information Technology,Hospital & Health Care,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Virginia Beach, VA",8 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Associate Scientist,CyberCoders,"San Diego, CA",22 hours ago,Be among the first 25 applicants,"['', ' Vacation/PTO Medical Dental Vision 401k Stock options Gym', ' Cell Culture', ' Transfection', ' Assay Development', ' Characterization of hit/lead candidates in vitro (qPCR, western blot, ELISA, functional assays)', ' Assay development', ' Stock options', ' Gym', ' Vacation/PTO', ' qPCR', ' Medical', ' 401k', ' Vision', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Cell line development and characterization', ' Assay Development Cell Culture Transfection qPCR nucleic acids Ophthalmology', ' Dental', ' nucleic acids', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : AB12-1606163 -- in the email subject line for your application to be considered.***', ' Data analysis and presentation', 'Email Your Resume In Word To', ' Ophthalmology', ' Assay development Cell line development and characterization Characterization of hit/lead candidates in vitro (qPCR, western blot, ELISA, functional assays) Mechanism of action study design and conception Data analysis and presentation', ' Mechanism of action study design and conception', 'Your Right to Work']",Mid-Senior level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
"Data Engineer - TS Clearance , Security+ Java",Optello,"Washington, DC",2 hours ago,Be among the first 25 applicants,"['', ' Data Migration', ' Clear path for advancement', ' Small team environment with security of larger company Great benefits Clear path for advancement', 'Optello is proud to be an Equal Opportunity Employer', ' Rest', ' Develop and test Java software plugins for HCP family of products Develop and test components using TCP/IP, RSS, SMTP, ODBC/SQL, HTTP/REST, XML, JSON Communicate with technical and non-technical members of the project team Enterprise object storage solutions (e.g., S3, HCP, Centera) Data migrations Data Analytics solution development GUI development and programming Experience in troubleshooting, maintaining, and developing data-driven applications for enterprise environments Experience with development and management of Linux based OSs Experience with XML and JSON Experience with APIs for SharePoint, MS Exchange or MS Work Folder', ' Develop and test components using TCP/IP, RSS, SMTP, ODBC/SQL, HTTP/REST, XML, JSON', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : KT4-1604882 -- in the email subject line for your application to be considered.***', ' Communication Skills', ' Must possess a TS/SCI clearance or currently have a TS with the ability to upgrade', ' Data migrations', ' Security+ Certification (must be completed prior to start)', ' Willingness to work a flexible schedule and travel 15-30%', 'Technical Overview', ' Experience in troubleshooting, maintaining, and developing data-driven applications for enterprise environments', ' Communicate with technical and non-technical members of the project team', ' Small team environment with security of larger company', ' Enterprise object storage solutions (e.g., S3, HCP, Centera)', ' Must possess a TS/SCI clearance or currently have a TS with the ability to upgrade Willingness to work a flexible schedule and travel 15-30% Security+ Certification (must be completed prior to start) Experience with Pentaho and/or Hitachi Content Intelligence a strong plus', ' Experience with Pentaho and/or Hitachi Content Intelligence a strong plus', ' Java', ' GUI development and programming', ' Experience with XML and JSON', ' Security+ Certification', ' Great benefits', ' Data Analytics solution development', ' HCP', ' Centera Java Security+ Certification Data Migration Rest Linux HCP S3 Communication Skills Presentation Skills', 'Email Your Resume In Word To', ' Presentation Skills', ' S3', ' Experience with development and management of Linux based OSs', ' Experience with APIs for SharePoint, MS Exchange or MS Work Folder', ' Centera', ' Linux', ' Develop and test Java software plugins for HCP family of products', 'Your Right to Work']",Entry level,Full-time,Information Technology,Construction,2020-11-05 11:32:32
Hadoop Consultant,Accenture,"Denver, CO",10 hours ago,Be among the first 25 applicants,"['', 'Here’s What You Need: ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.', 'You’ve got experience of full life-cycle development ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Accenture Overview', 'R Studio ', 'Bonus Points If:', 'Jenkins, Chef, Puppet ', ' You Are:', 'Scala, Spark ', 'Minimum of 4 years’ hands-on technical experience implementing Big Data solutions using Hadoop ecosystem ', 'Equal Employment Opportunity:', 'You’re familiar with designing ingestion, low-latency, visualization clusters to sustain data loads ', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'You can configure and support API and Open Source integrations ', 'You have delivered Big Data solutions in the cloud with AWS or Azure or Google Cloud ', 'Amazon S3 ', 'Relational and Non-relations Databases (No-SQL) ', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'You have experience administering Hadoop or other Data Science and Analytics platforms using the technologies above [LC1] ', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Kafka-based streaming services ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'The Work:', 'Experience in developing solutions using any of the following: ', 'You’re no newbie when it comes to working in a DevOps environment ', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Consulting,Information Technology and Services,2020-11-05 11:32:32
Underwater Acoustics Researcher,Systems & Technology Research,"Arlington, VA",19 hours ago,Be among the first 25 applicants,"['', ' Familiarity with various acoustic propagation modeling software (KRAKEN, OASIS, BELLHOP) Interest and aptitude for working on large, complex technical projects Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects Scientific curiosity and creativity Knowledge of one or more of the following topic areas: underwater acoustic propagation or communications modeling, ocean modeling, statistics Active Security Clearance at the Secret or Top Secret (TS) level ', 'Active Security Clearance at the Secret or Top Secret (TS) level', 'PhD or MS degree with research experience in physical oceanography, underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field', 'Description', 'Strong scientific programming skills in MATLAB, Python, and/or C/C++', ' Physics and statistics based underwater acoustic propagation modeling and simulation Develop models for acoustics sources and receivers to model system performance Participate in at-sea data collections including experiment design and analysis of collected data ', 'Desired Qualifications', 'Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects', 'Physics and statistics based underwater acoustic propagation modeling and simulation', 'US Citizenship with the ability to obtain a Security Clearance', 'Participate in at-sea data collections including experiment design and analysis of collected data', 'Scientific curiosity and creativity', 'Requirements', 'Familiarity with various acoustic propagation modeling software (KRAKEN, OASIS, BELLHOP)', 'Interest and aptitude for working on large, complex technical projects', 'Responsibilities Include', 'Knowledge of one or more of the following topic areas: underwater acoustic propagation or communications modeling, ocean modeling, statistics', 'Develop models for acoustics sources and receivers to model system performance', 'Demonstrated understanding of underwater acoustics and sonar sensor technologies', ' US Citizenship with the ability to obtain a Security Clearance PhD or MS degree with research experience in physical oceanography, underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field Demonstrated understanding of underwater acoustics and sonar sensor technologies Strong scientific programming skills in MATLAB, Python, and/or C/C++ ']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Manager - Big Data Engineering - Wallet & Apple Pay - SCV,Apple,"Cupertino, CA",5 hours ago,90 applicants,"['', 'Description', 'Key Qualifications', 'Education & Experience', 'Summary']",Not Applicable,Full-time,Information Technology,Consumer Electronics,2020-11-05 11:32:32
"Senior Software Engineer, AWS SageMaker Core Platform",Amazon Web Services (AWS),"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Build fundamental primitives in the cloud for enabling data scientists workflows.', ' Machine learning knowledge and experience. Experience building tools for data scientists and developers. Experience building complex software systems that have been successfully delivered to customers. Experience with highly distributed, multi-tenant systems with clear state-full/state-less boundaries. Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Ability to take a project from scoping requirements through actual launch of the project. Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs. Deep hands-on technical expertise in: large scale systems engineering and/or full-stack development.', ' Experience with highly distributed, multi-tenant systems with clear state-full/state-less boundaries.', ' Deep hands-on technical expertise in: large scale systems engineering and/or full-stack development.', ' 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design', ' Experience building complex software systems that have been successfully delivered to customers.', ' Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.', ' Develop in multiple layers of the stack including distributed workflows, high throughput data planes, linux networking, and system security.', 'Preferred Qualifications', 'Company', "" You'll be well supported with by a group with deep technical chops, including multiple senior and principal engineers."", 'Engineers On This Team Get To', 'Basic Qualifications', ' Strong analytical abilities and problem solving', ' Experience building tools for data scientists and developers.', 'Description', ' Ability to take a project from scoping requirements through actual launch of the project.', ' Proficiency in, at least, one modern programming language such as Java, Go, Python, Scala, C++, C#.', ' Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.', ' Serve as technical lead on complex projects using best practice engineering standards, and hire/mentor junior development engineers', "" Assist in gathering and analyzing business and functional requirements, and translate requirements into technical specifications for robust, scalable, supportable solutions that work well within the overall system architecture. Engage with customers and other AWS partners Serve as technical lead on complex projects using best practice engineering standards, and hire/mentor junior development engineers You'll be well supported with by a group with deep technical chops, including multiple senior and principal engineers."", ' Develop in multiple layers of the stack including distributed workflows, high throughput data planes, linux networking, and system security. Build fundamental primitives in the cloud for enabling data scientists workflows. Develop/maintain operational rigor for a fast-growing AWS service.', ' Bachelor’s Degree in Computer Science or related field or equivalent work experience', ' 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems', ' 4+ years of professional software development experience 3+ years of programming experience with at least one modern language such as Java, C++, or C# including object-oriented design 2+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems Bachelor’s Degree in Computer Science or related field or equivalent work experience Strong computer science fundamentals - data structures, algorithms design, complexity analysis, operating systems etc. Object-oriented design proficiency Strong analytical abilities and problem solving Strong inclination towards building high quality systems by testing mercilessly. Strong sense of ownership and willing to own end to end systems. Proficiency in, at least, one modern programming language such as Java, Go, Python, Scala, C++, C#.', ' Assist in gathering and analyzing business and functional requirements, and translate requirements into technical specifications for robust, scalable, supportable solutions that work well within the overall system architecture.', ' Strong sense of ownership and willing to own end to end systems.', ' Machine learning knowledge and experience.', ' 4+ years of professional software development experience', 'Key Responsibilities', ' Strong inclination towards building high quality systems by testing mercilessly.', ' Develop/maintain operational rigor for a fast-growing AWS service.', ' Strong computer science fundamentals - data structures, algorithms design, complexity analysis, operating systems etc.', ' Engage with customers and other AWS partners', ' Object-oriented design proficiency']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
Sustainability Science Researcher,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Manage sustainability-related research projects through all stages: ideation, modeling, data collection, data analysis, data visualization, and reporting; Develop tools and methods to harvest and continuously update data to provide sustainability insights at scale. Respond to time critical questions from multiple business teams; Professionally communicate to senior business leaders. Work closely with software engineering teams to drive real-time model implementations and new feature creations. Lead the early investigative / inception phase of strategic sustainability initiatives and effectively influence, negotiate, and communicate with stakeholders to enable hand off of those projects for implementation.', ' Professionally communicate to senior business leaders.', ' Strong written and verbal communication skills; PhD in a highly quantitative or related field. Experience with LCA data sources and commercially available tools. Experience building scalable analytics, models, and applications. Experience with AWS features (S3, Redshift) is a plus. Ability to write well-structured, easily maintainable, and well-documented code and desire to improve by iterating on code through peer review. Experience working with big, messy datasets and deriving inferences from them. Broad experience applying data-driven decision making across multiple industries. Strong drive to question the status quo and learn new topics and skills. Published a peer-reviewed LCA study or report (e.g. thesis/dissertation, journal article, Environmental Product Declaration (EPD), etc.)', 'Preferred Qualifications', 'Company', 'Basic Qualifications', 'Description', ' Respond to time critical questions from multiple business teams;', ' 5+ years conducting sustainability research and/or driving sustainability improvements;', ' Published a peer-reviewed LCA study or report (e.g. thesis/dissertation, journal article, Environmental Product Declaration (EPD), etc.)', ' Strong drive to question the status quo and learn new topics and skills.', ' Manage sustainability-related research projects through all stages: ideation, modeling, data collection, data analysis, data visualization, and reporting;', ' Lead the early investigative / inception phase of strategic sustainability initiatives and effectively influence, negotiate, and communicate with stakeholders to enable hand off of those projects for implementation.', ' Experience building scalable analytics, models, and applications.', 'The Role', ' Ability to write well-structured, easily maintainable, and well-documented code and desire to improve by iterating on code through peer review.', ' Develop tools and methods to harvest and continuously update data to provide sustainability insights at scale.', ' Experience with sustainability footprinting and/or Life Cycle Assessment (LCA);', ' Strong written and verbal communication skills;', ' Coding experience in Python, R, or similar;', ' Experience working with big, messy datasets and deriving inferences from them.', ' Work closely with software engineering teams to drive real-time model implementations and new feature creations.', ' Experience with AWS features (S3, Redshift) is a plus.', ' 5+ years conducting sustainability research and/or driving sustainability improvements; Experience with sustainability footprinting and/or Life Cycle Assessment (LCA); Coding experience in Python, R, or similar; Master’s degree in environmental science or engineering, industrial ecology, industrial or mechanical engineering, or related fields; Competence in statistical analysis, databases and mathematical modeling.', ' Competence in statistical analysis, databases and mathematical modeling.', 'Key Responsibilities', ' Experience with LCA data sources and commercially available tools.', ' Broad experience applying data-driven decision making across multiple industries.', ' PhD in a highly quantitative or related field.', ' Master’s degree in environmental science or engineering, industrial ecology, industrial or mechanical engineering, or related fields;']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Ann Arbor, MI",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect - Data & AI - CTJ,Microsoft,"Chevy Chase, MD",3 hours ago,Be among the first 25 applicants,"['', 'The technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends required', 'General awareness of Data Governance and Stewardship processes', 'Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud services', 'QualificationsProfessionalExperience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) requiredTechnicalEnterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'General awareness of Machine Learning / Data Science and model operationalization processes', 'Knowledge of Azure cloud services', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desired', 'Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)', 'Responsibilities', ""Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platformBe an Azure Platform evangelist with customers, partners and external communities"", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications required', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,', 'Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.', 'Machine Learning, including Azure ML Services / ML Flow', ""QualificationsProfessionalExperience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) requiredTechnicalEnterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processesThe technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends requiredCompetitive Landscape: Knowledge of enterprise public cloud platforms and related industry/marketplace preferredPartners: Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferredEducationBachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial IntelligenceExperiencesPrior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud servicesGeneral Knowledge of competitive cloud services desired"", 'Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'Breadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. required', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'NoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)', 'Be an Azure Platform evangelist with customers, partners and external communities', 'Advanced Analytics, including Azure Data Bricks', 'Qualifications', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence"", 'Visualization tools, including PowerBI, and/or Tableau', 'Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment', 'Professional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence', 'General Knowledge of competitive cloud services desired', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systems', 'Key Responsibilities Include', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners."", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'Artificial Intelligence, including Azure Cognitive Services', 'Experiences', 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Data Analyst (Scientist and Engineer Level 3) with Security Clearance - Duke Field AFS,N/A,"Hurlburt Field, FL",19 hours ago,Be among the first 25 applicants,"['Active Secret Clearance is required', 'Writes technical reports to address test results and findings.Provides technical advice and assistance to military test directors.', 'Must be able to effectively communicate orally and possess technical writing skill.', 'Experience with the principles of Design of Experiments is desirable. Employee Referral Code: ER2 Our EEO policy: Bevilacqua Research Corporation is an equal opportunity employer Minorities/Females/Disabled/Veterans and VEVRAA federal contractor. We recruit, employ, train, compensate, and promote without regard to race, color, religion, sex, national origin or any other basis protected by applicable federal, state or local law.', 'Activities include participation in test execution, data collection and reduction, data analysis, assessing systems effectiveness, and test reporting.', 'Incorporates scientific principles and methods in test planning and execution.Works with Test Engineers to create required data products for test reporting.', 'Proficiency in the use of Microsoft Office applications including Excel is required.', 'Must be able to work as part of an integrated test team.', 'Familiarity with US Air Force test and evaluation processes is highly desirable.', 'Travels to offsite locations as required and other duties as assigned. Minimum Requirements:', ""Bachelor's degree in applicable discipline and 3 - 10 years of related experience.Six years of applicable technical experience may be substituted for the BS degree (total 9 years) or four years' experience with an Associate's Degree (total 7 years)."", 'This skill level typically performs all functional duties independently.Must be a self-motivated expert able to take responsibility for identifying, organizing, coordinating, and executing necessary tasks to the successful accomplishment of assigned duties.', 'Reviews technical specifications and system design documents. Attends test planning meetings, technical interchange meetings, and system design reviews.', 'U.S. Citizenship is required.', 'Computer programming skills and experience working with MATLAB are required. Desired Experience:', 'Test support includes recommendation of system performance requirements, development of test objectives, development of test methods and detailed test procedures, development of specification datarequirements, identification of instrumentation and test support equipment requirements, development of data collection forms and logs, coordination with test support agencies and ranges, and other test and evaluation (T&E) planning tasks.', 'Supports the HH-60W Combat Rescue Helicopter (CRH) and MH-139 Strategic Defense Helicopter (SDH) developmental test & evaluation (DT&E) programs within the guidelines established in Government approved test procedures, method of test (MOT), and go or no-go criteria.', 'Manages databases and analytic functions to ensure robust, secure, and responsive data control capability. Develops, maintains, and manages data tools to support the helicopter test teams.']",Entry level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Research Scientist - ADC Bioconjugation,CyberCoders,"San Diego, CA",22 hours ago,Be among the first 25 applicants,"['', ' Supporting preclinical development of targeted agents for cancer therapy', 'Your Right to Work', ' Antibody drug conjugates (ADCs)', 'Email Your Resume In Word To', 'Experience With The Following', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JG9-1607897 -- in the email subject line for your application to be considered.***', ' Bioconjugation', ' Analytical Chemistry', ' Antibody drug conjugates (ADCs) Bioconjugation Analytical Chemistry Optimzation of antibody drug conjugations', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Optimzation of antibody drug conjugations']",Entry level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Hadoop Consultant,Accenture,"Phoenix, AZ",10 hours ago,Be among the first 25 applicants,"['', 'Here’s What You Need: ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.', 'You’ve got experience of full life-cycle development ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Accenture Overview', 'R Studio ', 'Bonus Points If:', 'Jenkins, Chef, Puppet ', ' You Are:', 'Scala, Spark ', 'Minimum of 4 years’ hands-on technical experience implementing Big Data solutions using Hadoop ecosystem ', 'Equal Employment Opportunity:', 'You’re familiar with designing ingestion, low-latency, visualization clusters to sustain data loads ', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'You can configure and support API and Open Source integrations ', 'You have delivered Big Data solutions in the cloud with AWS or Azure or Google Cloud ', 'Amazon S3 ', 'Relational and Non-relations Databases (No-SQL) ', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'You have experience administering Hadoop or other Data Science and Analytics platforms using the technologies above [LC1] ', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Kafka-based streaming services ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'The Work:', 'Experience in developing solutions using any of the following: ', 'You’re no newbie when it comes to working in a DevOps environment ', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Consulting,Information Technology and Services,2020-11-05 11:32:32
Underwater Acoustics Researcher,Systems & Technology Research,"Woburn, MA",19 hours ago,Be among the first 25 applicants,"['', ' Familiarity with various acoustic propagation modeling software (KRAKEN, OASIS, BELLHOP) Interest and aptitude for working on large, complex technical projects Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects Scientific curiosity and creativity Knowledge of one or more of the following topic areas: underwater acoustic propagation or communications modeling, ocean modeling, statistics Active Security Clearance at the Secret or Top Secret (TS) level ', 'Active Security Clearance at the Secret or Top Secret (TS) level', 'PhD or MS degree with research experience in physical oceanography, underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field', 'Description', 'Strong scientific programming skills in MATLAB, Python, and/or C/C++', ' Physics and statistics based underwater acoustic propagation modeling and simulation Develop models for acoustics sources and receivers to model system performance Participate in at-sea data collections including experiment design and analysis of collected data ', 'Desired Qualifications', 'Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects', 'Physics and statistics based underwater acoustic propagation modeling and simulation', 'US Citizenship with the ability to obtain a Security Clearance', 'Participate in at-sea data collections including experiment design and analysis of collected data', 'Scientific curiosity and creativity', 'Requirements', 'Familiarity with various acoustic propagation modeling software (KRAKEN, OASIS, BELLHOP)', 'Interest and aptitude for working on large, complex technical projects', 'Responsibilities Include', 'Knowledge of one or more of the following topic areas: underwater acoustic propagation or communications modeling, ocean modeling, statistics', 'Develop models for acoustics sources and receivers to model system performance', 'Demonstrated understanding of underwater acoustics and sonar sensor technologies', ' US Citizenship with the ability to obtain a Security Clearance PhD or MS degree with research experience in physical oceanography, underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field Demonstrated understanding of underwater acoustics and sonar sensor technologies Strong scientific programming skills in MATLAB, Python, and/or C/C++ ']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
"Research Scientist, NLU Analytics",Amazon,"Cambridge, MA",6 hours ago,56 applicants,"['', ' Knowledge of various machine learning techniques and key parameters that affect their performance', ' Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc.', ' Ability to think creatively and solve problems', ' Work with engineers to develop efficient data querying infrastructure for both offline and online use cases', ' Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, and transformation.', ' 3+ years of experience with various machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance', ' Master’s degree or PhD in a relevant field (Computer Science, Computer or Electrical Engineering, Mathematics, Physics, Statistics or a related field)', ' Build and release predictive models for retention and engagement using large datasets of user conversational behaviors and system performance to recommend and track the impact of feature improvements over time', 'Preferred Qualifications', ' Build and release predictive models for retention and engagement using large datasets of user conversational behaviors and system performance to recommend and track the impact of feature improvements over time Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, and transformation. Collaborate with colleagues from science, engineering and business backgrounds. Present proposals and results to partner teams in a clear manner backed by data and coupled with actionable conclusions Define ML based techniques for sampling, judgment monitoring, A/B testing and efficient evaluations Work with engineers to develop efficient data querying infrastructure for both offline and online use cases', 'Company', 'Basic Qualifications', ' Strong attention to detail and exceptional level of organization', 'Description', ' Experience in Perl, Python, or another scripting language; command line usage', ' Master’s degree or PhD in a relevant field (Computer Science, Computer or Electrical Engineering, Mathematics, Physics, Statistics or a related field) Experience diving into data to discover hidden patterns and of conducting error/deviation analysis Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. Strong attention to detail and exceptional level of organization Proven ability to achieve results in a fast paced, highly collaborative, dynamic work environment Ability to think creatively and solve problems', ' Proven ability to achieve results in a fast paced, highly collaborative, dynamic work environment', ' Bachelor’s degree in a relevant field, such as Computer Science or Applied Statistics 3+ years of experience with various machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance Experience in Perl, Python, or another scripting language; command line usage Experience analyzing data to identify patterns and conducting error/deviation analysis Knowledge of various machine learning techniques and key parameters that affect their performance Understanding of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc.', ' Collaborate with colleagues from science, engineering and business backgrounds.', ' Present proposals and results to partner teams in a clear manner backed by data and coupled with actionable conclusions', ' Define ML based techniques for sampling, judgment monitoring, A/B testing and efficient evaluations', ' Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations', 'You Will', ' Experience diving into data to discover hidden patterns and of conducting error/deviation analysis', ' Experience analyzing data to identify patterns and conducting error/deviation analysis', ' Bachelor’s degree in a relevant field, such as Computer Science or Applied Statistics']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Jackson County, MO",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect - Data & AI - CTJ,Microsoft,"Chevy Chase, MD",3 hours ago,Be among the first 25 applicants,"['', 'The technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends required', 'General awareness of Data Governance and Stewardship processes', 'Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud services', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'General awareness of Machine Learning / Data Science and model operationalization processes', 'Knowledge of Azure cloud services', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desired', 'Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)', 'Responsibilities', ""Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platformBe an Azure Platform evangelist with customers, partners and external communities"", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications required', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,', 'Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.', 'Machine Learning, including Azure ML Services / ML Flow', 'Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'Breadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. required', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'NoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)', 'Be an Azure Platform evangelist with customers, partners and external communities', 'Advanced Analytics, including Azure Data Bricks', 'Qualifications', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence"", 'Visualization tools, including PowerBI, and/or Tableau', 'Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment', 'Professional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence', 'General Knowledge of competitive cloud services desired', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systems', 'Key Responsibilities Include', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners."", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'Artificial Intelligence, including Azure Cognitive Services', 'Experiences', 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Scientist - Neurodegenerative Disease/Alzheimer's,CyberCoders,"Atherton, CA",6 hours ago,Be among the first 25 applicants,"['', ' Data analysis and experimental record keeping', ' We are a cutting edge biotech company that is developing new immunotherapy antibody drugs Our platform has had unparalleled success Our employees are our greatest asset and we know it!', ' Work interdepartmentally to screen and validate antibody candidates', "" PhD or Master's Degree Experience in neuroscience, neurodegenerative diseases and/or Alzheimer's Track record in biochemical, molecular and cellular biology methods Background in animal models of neurodegenerative diseases"", ' Our platform has had unparalleled success', ' Help to develop antibody therapeutics for Alzheimers Disease and other neurodegenerative diseases Design and execute experiments Data analysis and experimental record keeping Work interdepartmentally to screen and validate antibody candidates', "" PhD or Master's Degree"", 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Track record in biochemical, molecular and cellular biology methods', ' Background in animal models of neurodegenerative diseases', "" Experience in neuroscience, neurodegenerative diseases and/or Alzheimer's"", ' Help to develop antibody therapeutics for Alzheimers Disease and other neurodegenerative diseases', ' We are a cutting edge biotech company that is developing new immunotherapy antibody drugs', 'Email Your Resume In Word To', ' Our employees are our greatest asset and we know it!', ' Design and execute experiments', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : ML-1610221 -- in the email subject line for your application to be considered.***', 'Your Right to Work']",Entry level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Underwater Acoustics Researcher,Systems & Technology Research,"Woburn, MA",19 hours ago,Be among the first 25 applicants,"['', 'Active Security Clearance at the Secret or Top Secret (TS) level', 'PhD or MS degree with research experience in physical oceanography, underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field', 'Description', 'Strong scientific programming skills in MATLAB, Python, and/or C/C++', ' Physics and statistics based underwater acoustic propagation modeling and simulation Develop models for acoustics sources and receivers to model system performance Participate in at-sea data collections including experiment design and analysis of collected data ', 'Desired Qualifications', 'Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects', 'Physics and statistics based underwater acoustic propagation modeling and simulation', 'US Citizenship with the ability to obtain a Security Clearance', 'Participate in at-sea data collections including experiment design and analysis of collected data', 'Scientific curiosity and creativity', 'Requirements', 'Familiarity with various acoustic propagation modeling software (KRAKEN, OASIS, BELLHOP)', 'Interest and aptitude for working complex technical projects', 'Responsibilities Include', 'Knowledge of one or more of the following topic areas: underwater acoustic propagation or communications modeling, ocean modeling, statistics', 'Develop models for acoustics sources and receivers to model system performance', 'Demonstrated understanding of underwater acoustics and sonar sensor technologies', ' US Citizenship with the ability to obtain a Security Clearance PhD or MS degree with research experience in physical oceanography, underwater acoustics, electrical engineering, mechanical engineering, physics, applied mathematics or related field Demonstrated understanding of underwater acoustics and sonar sensor technologies Strong scientific programming skills in MATLAB, Python, and/or C/C++ Familiarity with various acoustic propagation modeling software (KRAKEN, OASIS, BELLHOP) Interest and aptitude for working complex technical projects Ability to interact with technical and non-technical customers and external teammates to understand their technical issues, frame potential solutions and develop collaborative projects Scientific curiosity and creativity Knowledge of one or more of the following topic areas: underwater acoustic propagation or communications modeling, ocean modeling, statistics ']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Hadoop Consultant,Accenture,"Los Angeles, CA",10 hours ago,Be among the first 25 applicants,"['', 'Here’s What You Need: ', 'Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.', 'You’ve got experience of full life-cycle development ', 'Answer client’s business questions by dissecting their data, using measurement techniques, drafting KPIs, and building reports and dashboards. ', ' Important Information:', 'Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture. ', 'Generate requirements for application designs while pinpointing the best type of visualization to meet your client’s needs. ', 'Build and test functional prototypes for BI, data discovery, and analytics solutions. ', 'Accenture Overview', 'R Studio ', 'Bonus Points If:', 'Jenkins, Chef, Puppet ', ' You Are:', 'Scala, Spark ', 'Minimum of 4 years’ hands-on technical experience implementing Big Data solutions using Hadoop ecosystem ', 'Equal Employment Opportunity:', 'You’re familiar with designing ingestion, low-latency, visualization clusters to sustain data loads ', 'Build dashboard automation processes, and pull together and deliver presentations based on your findings. ', 'Run data and dashboard quality assurance throughout the design phase in collaboration with your team. ', 'All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.', 'You can configure and support API and Open Source integrations ', 'You have delivered Big Data solutions in the cloud with AWS or Azure or Google Cloud ', 'Amazon S3 ', 'Relational and Non-relations Databases (No-SQL) ', 'A Bachelor’s degree, or an Associate’s degree and 6 additional years of experience, or 12 additional years of experience', 'You have experience administering Hadoop or other Data Science and Analytics platforms using the technologies above [LC1] ', 'Work together with IT Architects, BI analysts, database developers, application developers, and functional practitioners, as well as with clients/partners.', 'Kafka-based streaming services ', 'Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. ', 'Collaborate with clients and team members on data visualizations using tools such as Tableau, Qlik, IBM Cognos, Plotly, and Kibana, per clients’ needs. ', 'Data Business Group', 'The Work:', 'Experience in developing solutions using any of the following: ', 'You’re no newbie when it comes to working in a DevOps environment ', 'We Are:', 'It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve clients, our employees must be able to travel when needed. This role requires 100% flexibility to travel and work onsite with clients (typically Monday through Thursday).']",Associate,Full-time,Consulting,Information Technology and Services,2020-11-05 11:32:32
Sr Applied Scientist,Amazon,"Tempe, AZ",6 hours ago,Be among the first 25 applicants,"['', ' Masters in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent) 6+ years of experience working in data science in a consumer product company 3+ years of experience managing Machine Learning Scientists, Data Scientists, Research Scientists, Applied Scientists, and/or Economists Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes Experience hiring and leading experienced scientists as well as a successful record of developing junior members to a successful career track Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts.', ' Experience hiring and leading experienced scientists as well as a successful record of developing junior members to a successful career track', ' 6+ years of experience working in data science in a consumer product company', 'Preferred Qualifications', 'Company', ' Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes', 'Basic Qualifications', 'Description', ' A PhD in a quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)', 'Position Responsibilities', ' A PhD in a quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent) 10+ years of experience working in data science in a consumer product company Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, NLP, deep learning, recommendation systems, dialogue systems, information retrieval Skilled with Java, C++, or other programming language, as well as with R, SAS, MATLAB, Python or similar scripting language Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes', ' Participate in the design, development, evaluation, deployment and updating of data-driven models and analytical solutions for written language applications', ' Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts.', ' Participate in the design, development, evaluation, deployment and updating of data-driven models and analytical solutions for written language applications Research and implement novel ML and statistical approaches which add value to Amazon Lead and Mentor junior engineers and scientists Develop and/or apply statistical modelling methods (e.g. deep neural networks), optimizations, and other ML techniques to different applications in written language engineering', ' 10+ years of experience working in data science in a consumer product company', ' Research and implement novel ML and statistical approaches which add value to Amazon', ' Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives', ' 3+ years of experience managing Machine Learning Scientists, Data Scientists, Research Scientists, Applied Scientists, and/or Economists', ' Skilled with Java, C++, or other programming language, as well as with R, SAS, MATLAB, Python or similar scripting language', ' Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, NLP, deep learning, recommendation systems, dialogue systems, information retrieval', ' Develop and/or apply statistical modelling methods (e.g. deep neural networks), optimizations, and other ML techniques to different applications in written language engineering', ' Lead and Mentor junior engineers and scientists', ' Masters in quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)']",Mid-Senior level,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Jackson, MS",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect - Data & AI - CTJ,Microsoft,"Reston, VA",3 hours ago,Be among the first 25 applicants,"['', 'The technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends required', 'General awareness of Data Governance and Stewardship processes', 'Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud services', 'QualificationsProfessionalExperience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) requiredTechnicalEnterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'General awareness of Machine Learning / Data Science and model operationalization processes', 'Knowledge of Azure cloud services', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desired', 'Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)', 'Responsibilities', ""Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platformBe an Azure Platform evangelist with customers, partners and external communities"", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications required', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,', 'Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.', 'Machine Learning, including Azure ML Services / ML Flow', ""QualificationsProfessionalExperience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) requiredTechnicalEnterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processesThe technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends requiredCompetitive Landscape: Knowledge of enterprise public cloud platforms and related industry/marketplace preferredPartners: Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferredEducationBachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial IntelligenceExperiencesPrior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud servicesGeneral Knowledge of competitive cloud services desired"", 'Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'Breadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. required', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'NoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)', 'Be an Azure Platform evangelist with customers, partners and external communities', 'Advanced Analytics, including Azure Data Bricks', 'Qualifications', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence"", 'Visualization tools, including PowerBI, and/or Tableau', 'Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment', 'Professional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence', 'General Knowledge of competitive cloud services desired', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systems', 'Key Responsibilities Include', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners."", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'Artificial Intelligence, including Azure Cognitive Services', 'Experiences', 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Research Scientist - ADC Bioconjugation,CyberCoders,"San Diego, CA",22 hours ago,Be among the first 25 applicants,"['', ' Supporting preclinical development of targeted agents for cancer therapy', 'Your Right to Work', ' Antibody drug conjugates (ADCs)', 'Email Your Resume In Word To', 'Experience With The Following', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : JG9-1609769 -- in the email subject line for your application to be considered.***', ' Bioconjugation', ' Analytical Chemistry', ' Antibody drug conjugates (ADCs) Bioconjugation Analytical Chemistry Optimzation of antibody drug conjugations', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', ' Optimzation of antibody drug conjugations']",Entry level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Senior Vulnerability Researcher,Systems & Technology Research,"Woburn, MA",19 hours ago,Be among the first 25 applicants,"['', 'Working in small research teams to develop innovative cybersecurity solutions', 'Exploit development', 'Active Security Clearance at the Secret or Top Secret (TS) level', 'Embedded systems or firmware analysis', 'Protocol analysis', '10+ years of relevant experience', 'JTAG debugging, firmware flashing or extraction', 'Description', 'Working in small research teams to reverse engineer and identify vulnerabilities in complex software, firmware, and/or hardware targets', 'Knowledge of binary file structures and formats', 'Senior Vulnerability Researcher', ' Working in small research teams to reverse engineer and identify vulnerabilities in complex software, firmware, and/or hardware targets Performing vulnerability research (VR), exploit development, and vulnerability mitigation on a variety of challenging targets ranging from Windows/Linux binaries to embedded firmware on non-traditional information systems Working in small research teams to develop innovative cybersecurity solutions Documenting, demonstrating, and presenting research ', 'Experience performing static/dynamic/symbolic program analysis', 'Documenting, demonstrating, and presenting research', 'Duties Will Include But Are Not Limited To', 'Performing vulnerability research (VR), exploit development, and vulnerability mitigation on a variety of challenging targets ranging from Windows/Linux binaries to embedded firmware on non-traditional information systems', 'Proficiency in one or more programming languages: C/C++, Python, etc.', 'Operating system internals including memory/process/thread management', 'Penetration testing or system hacking', 'Experience performing VR using tools such as IDA, Binary Ninja, or Ghidra', 'Vulnerability research and analysis', 'Requirements', ' Active Security Clearance at the Secret or Top Secret (TS) level Reverse engineering Knowledge of anti-reverse engineering techniques Operating system internals including memory/process/thread management Implant or software patch development Protocol analysis Knowledge of binary file structures and formats Embedded systems or firmware analysis JTAG debugging, firmware flashing or extraction Assembly Languages (x86, ARM, etc.) ', 'Knowledge of anti-reverse engineering techniques', 'US Citizen with the ability to obtain a Security Clearance', 'Implant or software patch development', 'Reverse engineering', ' US Citizen with the ability to obtain a Security Clearance BS, MS or PhD in Computer Science, Computer Engineering, Cybersecurity or related field (or equivalent) 10+ years of relevant experience Experience performing VR using tools such as IDA, Binary Ninja, or Ghidra Experience performing static/dynamic/symbolic program analysis Vulnerability research and analysis Penetration testing or system hacking Proficiency in one or more programming languages: C/C++, Python, etc. Exploit development ', 'BS, MS or PhD in Computer Science, Computer Engineering, Cybersecurity or related field (or equivalent)', 'Desired Skills And Experience', 'Assembly Languages (x86, ARM, etc.)']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Senior Applied Scientist,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Conducting and coordinating process development leading to improved and streamlined processes for model development. Strong customer focus is essential', ' Working closely with Product Managers to expand depth of our product insights with data, create a variety of experiments, and determine the highest-impact projects to include in planning roadmaps', ' PhD. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field 7+ years of hands-on experience applying theoretical models in an applied environment Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, deep learning, Natural Language Processing, recommendation systems, dialogue systems, informational retrieval Significant peer reviewed scientific contributions in premier journals and conferences Proven track in leading, mentoring, and growing teams of scientists Experience with digital media, online advertising or retail Proven ability to work effectively in a cross-functional team Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts', 'Preferred Qualifications', ' Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve search matching and ranking problems, including filtering, new content indexing, and apply document understanding', 'Company', ' PhD. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field', ' Work well in a fast-moving team environment and effectively deliver technical implementations having complex dependencies and requirements.', ' MSc. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field At least 5+ years of hands-on experience in predictive modeling and analysis Proficiency in model development, model validation and model implementation. At least 2+ years hands on experience programming in R, Java, C#, C++ or other similar programming languages Hands on experience with scripting languages such as Python, Perl Work well in a fast-moving team environment and effectively deliver technical implementations having complex dependencies and requirements.', 'Basic Qualifications', ' Proficiency in model development, model validation and model implementation.', 'Description', ' Being a cultural leader that ensures teams are collecting, understanding, and using data to inform every decision that impacts our customers', ' Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve search matching and ranking problems, including filtering, new content indexing, and apply document understanding Conducting and coordinating process development leading to improved and streamlined processes for model development. Strong customer focus is essential Working closely with Product Managers to expand depth of our product insights with data, create a variety of experiments, and determine the highest-impact projects to include in planning roadmaps Providing technical and scientific guidance to your team members Communicating effectively with senior management as well as with colleagues from science, engineering, and business backgrounds Being a cultural leader that ensures teams are collecting, understanding, and using data to inform every decision that impacts our customers', ' Proven track in leading, mentoring, and growing teams of scientists', ' Significant peer reviewed scientific contributions in premier journals and conferences', ' 7+ years of hands-on experience applying theoretical models in an applied environment', ' Hands on experience with scripting languages such as Python, Perl', ' MSc. in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field', ' Communicating effectively with senior management as well as with colleagues from science, engineering, and business backgrounds', ' At least 2+ years hands on experience programming in R, Java, C#, C++ or other similar programming languages', ' Providing technical and scientific guidance to your team members', ' Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, deep learning, Natural Language Processing, recommendation systems, dialogue systems, informational retrieval', ' Superior verbal and written communication and presentation skills, ability to convey rigorous mathematical concepts and considerations to non-experts', 'Responsibilities Include', ' Experience with digital media, online advertising or retail', ' Proven ability to work effectively in a cross-functional team', ' At least 5+ years of hands-on experience in predictive modeling and analysis']",Mid-Senior level,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Hartford, CT",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect - Data & AI - CTJ,Microsoft,"Washington, DC",3 hours ago,Be among the first 25 applicants,"['', 'The technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends required', 'General awareness of Data Governance and Stewardship processes', 'Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud services', 'QualificationsProfessionalExperience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) requiredTechnicalEnterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'General awareness of Machine Learning / Data Science and model operationalization processes', 'Knowledge of Azure cloud services', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desired', 'Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)', 'Responsibilities', ""Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platformBe an Azure Platform evangelist with customers, partners and external communities"", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications required', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,', 'Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.', 'Machine Learning, including Azure ML Services / ML Flow', ""QualificationsProfessionalExperience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) requiredTechnicalEnterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processesThe technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends requiredCompetitive Landscape: Knowledge of enterprise public cloud platforms and related industry/marketplace preferredPartners: Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferredEducationBachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial IntelligenceExperiencesPrior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud servicesGeneral Knowledge of competitive cloud services desired"", 'Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'Breadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. required', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'NoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)', 'Be an Azure Platform evangelist with customers, partners and external communities', 'Advanced Analytics, including Azure Data Bricks', 'Qualifications', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence"", 'Visualization tools, including PowerBI, and/or Tableau', 'Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment', 'Professional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence', 'General Knowledge of competitive cloud services desired', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systems', 'Key Responsibilities Include', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners."", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'Artificial Intelligence, including Azure Cognitive Services', 'Experiences', 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Scientist - Neurodegenerative Disease/Alzheimer's,CyberCoders,"Atherton, CA",22 hours ago,Be among the first 25 applicants,"['', ' Data analysis and experimental record keeping', ' We are a cutting edge biotech company that is developing new immunotherapy antibody drugs Our platform has had unparalleled success Our employees are our greatest asset and we know it!', ' Work interdepartmentally to screen and validate antibody candidates', "" PhD or Master's Degree Experience in neuroscience, neurodegenerative diseases and/or Alzheimer's Track record in biochemical, molecular and cellular biology methods Background in animal models of neurodegenerative diseases"", ' Our platform has had unparalleled success', ' Help to develop antibody therapeutics for Alzheimers Disease and other neurodegenerative diseases Design and execute experiments Data analysis and experimental record keeping Work interdepartmentally to screen and validate antibody candidates', "" PhD or Master's Degree"", 'CyberCoders, Inc is proud to be an Equal Opportunity Employer', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : ML-1608431 -- in the email subject line for your application to be considered.***', ' Track record in biochemical, molecular and cellular biology methods', ' Background in animal models of neurodegenerative diseases', "" Experience in neuroscience, neurodegenerative diseases and/or Alzheimer's"", ' Help to develop antibody therapeutics for Alzheimers Disease and other neurodegenerative diseases', ' We are a cutting edge biotech company that is developing new immunotherapy antibody drugs', 'Email Your Resume In Word To', ' Our employees are our greatest asset and we know it!', ' Design and execute experiments', 'Your Right to Work']",Entry level,Full-time,Research,Biotechnology,2020-11-05 11:32:32
Senior Vulnerability Researcher,Systems & Technology Research,"Arlington, VA",19 hours ago,Be among the first 25 applicants,"['', 'Working in small research teams to develop innovative cybersecurity solutions', 'Exploit development', 'Active Security Clearance at the Secret or Top Secret (TS) level', 'Embedded systems or firmware analysis', 'Protocol analysis', '10+ years of relevant experience', 'JTAG debugging, firmware flashing or extraction', 'Description', 'Working in small research teams to reverse engineer and identify vulnerabilities in complex software, firmware, and/or hardware targets', 'Knowledge of binary file structures and formats', 'Senior Vulnerability Researcher', ' Working in small research teams to reverse engineer and identify vulnerabilities in complex software, firmware, and/or hardware targets Performing vulnerability research (VR), exploit development, and vulnerability mitigation on a variety of challenging targets ranging from Windows/Linux binaries to embedded firmware on non-traditional information systems Working in small research teams to develop innovative cybersecurity solutions Documenting, demonstrating, and presenting research ', 'Experience performing static/dynamic/symbolic program analysis', 'Documenting, demonstrating, and presenting research', 'Duties Will Include But Are Not Limited To', 'Performing vulnerability research (VR), exploit development, and vulnerability mitigation on a variety of challenging targets ranging from Windows/Linux binaries to embedded firmware on non-traditional information systems', 'Proficiency in one or more programming languages: C/C++, Python, etc.', 'Operating system internals including memory/process/thread management', 'Penetration testing or system hacking', 'Experience performing VR using tools such as IDA, Binary Ninja, or Ghidra', 'Vulnerability research and analysis', 'Requirements', ' Active Security Clearance at the Secret or Top Secret (TS) level Reverse engineering Knowledge of anti-reverse engineering techniques Operating system internals including memory/process/thread management Implant or software patch development Protocol analysis Knowledge of binary file structures and formats Embedded systems or firmware analysis JTAG debugging, firmware flashing or extraction Assembly Languages (x86, ARM, etc.) ', 'Knowledge of anti-reverse engineering techniques', 'US Citizen with the ability to obtain a Security Clearance', 'Implant or software patch development', 'Reverse engineering', ' US Citizen with the ability to obtain a Security Clearance BS, MS or PhD in Computer Science, Computer Engineering, Cybersecurity or related field (or equivalent) 10+ years of relevant experience Experience performing VR using tools such as IDA, Binary Ninja, or Ghidra Experience performing static/dynamic/symbolic program analysis Vulnerability research and analysis Penetration testing or system hacking Proficiency in one or more programming languages: C/C++, Python, etc. Exploit development ', 'BS, MS or PhD in Computer Science, Computer Engineering, Cybersecurity or related field (or equivalent)', 'Desired Skills And Experience', 'Assembly Languages (x86, ARM, etc.)']",Associate,Full-time,Research,Information Technology and Services,2020-11-05 11:32:32
Sr. Research Scientist,Amazon,"Glendale, CA",6 hours ago,Be among the first 25 applicants,"['', ' Superior communication and data presentation skills Demonstrated ability to lead research projects and identify fruitful research directions Demonstrated ability to work on cross-functional teams Experience with applying scientific principles', 'Description', ' Depth and breadth in state-of-the-art approaches in science', ' 2+ years of relevant academic research or industry experience', ' Demonstrated ability to lead research projects and identify fruitful research directions', ' Scientific mindset and the ability to invent', ' Experience with applying scientific principles', ' MS or PhD in computer science, engineering, statistics, machine learning, operations research, mathematics, or in another highly quantitative field Depth and breadth in state-of-the-art approaches in science 2+ years of relevant academic research or industry experience Scientific mindset and the ability to invent Excellent creative problem solving skills Ability to design and develop system prototypes in simulation Superior communication and data presentation skills Effective working in a team environment', ' MS or PhD in computer science, engineering, statistics, machine learning, operations research, mathematics, or in another highly quantitative field', ' Effective working in a team environment', ' Demonstrated ability to work on cross-functional teams', 'Preferred Qualifications', ' Excellent creative problem solving skills', 'Company', ' Ability to design and develop system prototypes in simulation', ' Superior communication and data presentation skills', 'Basic Qualifications']",Mid-Senior level,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Boston, MA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect - Data & AI - CTJ,Microsoft,"Washington, DC",3 hours ago,Be among the first 25 applicants,"['', 'The technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends required', 'General awareness of Data Governance and Stewardship processes', 'Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud services', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'General awareness of Machine Learning / Data Science and model operationalization processes', 'Knowledge of Azure cloud services', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desired', 'Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)', 'Responsibilities', ""Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platformBe an Azure Platform evangelist with customers, partners and external communities"", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications required', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,', 'Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.', 'Machine Learning, including Azure ML Services / ML Flow', 'Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'Breadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. required', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'NoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)', 'Be an Azure Platform evangelist with customers, partners and external communities', 'Advanced Analytics, including Azure Data Bricks', 'Qualifications', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence"", 'Visualization tools, including PowerBI, and/or Tableau', 'Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment', 'Professional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence', 'General Knowledge of competitive cloud services desired', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systems', 'Key Responsibilities Include', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners."", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'Artificial Intelligence, including Azure Cognitive Services', 'Experiences', 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Data Engineer - Azure Guru,CyberCoders,"Lake Forest, CA",22 hours ago,Be among the first 25 applicants,"['', 'Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : NG-1599292 -- in the email subject line for your application to be considered.***', 'Extensive Azure Cloud Services REQUIRED For Production', 'Your Right to Work', 'Email Your Resume In Word To', 'CyberCoders, Inc is proud to be an Equal Opportunity Employer']",Mid-Senior level,Full-time,Engineering,Consumer Goods,2020-11-05 11:32:32
Operations Analyst,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Ability to quickly adapt to changing priorities and generate innovative solutions in an innovative and fast-paced environment Demonstrated ability to frame complex analytical problems, pull data, and extract insights that led to tangible business results Proven written and verbal communication skill Willingness to roll up the sleeves and do whatever is necessary to meet team goals and deadlines Challenge the status quo and ask the hard questions to ensure investment of time and resources is warranted MBA or Master’s degree in Economics, Finance, Statistics, Math or BusinessCompany - Amazon.com Services LLCJob ID: A1329287', 'Core Responsibilities And Capabilities', ' Help business customers define and prioritize work items for execution Work backwards from your end-customer to define, design, and execute each work item with an emphasis on improved metrics, productivity and defect reduction Update and maintain multiple dashboards and data sources to feed automated reporting to the extended team Translate data into actionable insights for stakeholders while proactively identifing new areas of opportunity to drive further improvements', 'Preferred Qualifications', ' Proven written and verbal communication skill', 'Company', ' Meets/exceeds Amazon’s functional/technical depth and complexity for this role', 'Basic Qualifications', ' Demonstrated ability to frame complex analytical problems, pull data, and extract insights that led to tangible business results', 'Description', ' Update and maintain multiple dashboards and data sources to feed automated reporting to the extended team', ' Willingness to roll up the sleeves and do whatever is necessary to meet team goals and deadlines', ' Ability to quickly adapt to changing priorities and generate innovative solutions in an innovative and fast-paced environment', ' Help business customers define and prioritize work items for execution', ' Challenge the status quo and ask the hard questions to ensure investment of time and resources is warranted', ' Translate data into actionable insights for stakeholders while proactively identifing new areas of opportunity to drive further improvements', ' 3+ years experience writing SQL code or Python with intermediate complexity', ' Work backwards from your end-customer to define, design, and execute each work item with an emphasis on improved metrics, productivity and defect reduction', ' Experience in developing business models and metrics to address business critical issues in a time-sensitive environment', ' MBA or Master’s degree in Economics, Finance, Statistics, Math or Business', "" Bachelor's degree in Math, Finance, Statistics, Engineering or related discipline"", ' Strong attention to detail, excellent organizational skills, and ability to manage multiple projects and responsibilities', "" Bachelor's degree in Math, Finance, Statistics, Engineering or related discipline 4+ years experience as an Operations analyst, Business analyst, Data scientist or similar job function, including 3+ years of relevant experience with data mining, SQL, building reporting, and modeling 3+ years experience writing SQL code or Python with intermediate complexity Experience in developing business models and metrics to address business critical issues in a time-sensitive environment Strong attention to detail, excellent organizational skills, and ability to manage multiple projects and responsibilities Meets/exceeds Amazon’s functional/technical depth and complexity for this role"", ' 4+ years experience as an Operations analyst, Business analyst, Data scientist or similar job function, including 3+ years of relevant experience with data mining, SQL, building reporting, and modeling']",Not Applicable,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Sioux Falls, SD",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect - Data & AI - CTJ,Microsoft,"Reston, VA",3 hours ago,Be among the first 25 applicants,"['', 'The technical aptitude, enthusiasm and desire to adapt to change, learn new technologies and understand relevant industry and cloud trends required', 'General awareness of Data Governance and Stewardship processes', 'Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desiredKnowledge of Azure cloud services', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'General awareness of Machine Learning / Data Science and model operationalization processes', 'Knowledge of Azure cloud services', 'Prior work experience in a Consulting/Architecture position within a software engineering and/or professional services company such as Amazon, VMware, Google, IBM, Oracle, or similar desired', 'Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platform', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)', 'Responsibilities', ""Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners.Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,Maintain technical skills and knowledge, keeping up to date with market trends and competitive insights; collaborate and share with the technical community while educate customers on Azure platformBe an Azure Platform evangelist with customers, partners and external communities"", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications required', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on Microsoft Azure platform,', 'Understand customers’ overall data estate, IT and business priorities and success measures to design implementation architectures and solutions.', 'Machine Learning, including Azure ML Services / ML Flow', 'Apply technical knowledge to architect solutions that meet business and IT needs, create Data Platform, AA/AI roadmaps, and ensure long term technical viability of new deployments, infusing key analytics technologies where appropriate (e.g. Azure ML, Database Platforms, Big Data, Data Lake, Azure Databricks, Azure Synapse, etc.)', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'Breadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. required', 'Enterprise-scale technical experience with cloud and hybrid infrastructures, architecture designs including scalability, security and resiliency, database migrations, and cloud technology management. requiredBreadth of technical experience and knowledge, with depth / Subject Matter Expertise (SME) in the following Data Platform Cloud solutions and/or data estate workloads required:', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systemsNoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)Big Data platforms including SQL DW (Synapse), Snowflake, Redshift, Spark (EMR/HDInsight)Advanced Analytics, including Azure Data BricksVisualization tools, including PowerBI, and/or TableauMachine Learning, including Azure ML Services / ML FlowArtificial Intelligence, including Azure Cognitive ServicesGeneral awareness of Data Governance and Stewardship processesGeneral awareness of Machine Learning / Data Science and model operationalization processes', 'NoSQL Databases including Azure Cosmos DB, and OSS Databases (Cassandra, Mongo etc)', 'Be an Azure Platform evangelist with customers, partners and external communities', 'Advanced Analytics, including Azure Data Bricks', 'Qualifications', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredProfessional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence"", 'Visualization tools, including PowerBI, and/or Tableau', 'Ensure that solution exhibits high levels of performance, security, scalability, maintainability, appropriate reusability and reliability upon deployment', 'Professional Cloud Certification in one or more of the following technologies preferred: Cloud, Database, Big Data, BI, Data Science, Machine Learning, Artificial Intelligence', 'General Knowledge of competitive cloud services desired', 'SQL platforms including SQL Server (Database/Analysis Services), Azure SQL DB, OSS Databases (PostgreSQL), ETL/ELT systems', 'Key Responsibilities Include', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners."", 'Experience. 5+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of cloud based applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'Artificial Intelligence, including Azure Cognitive Services', 'Experiences', 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
"Quantum Research Scientist, Test and Measurement",Amazon,"Glendale, CA",6 hours ago,Be among the first 25 applicants,"['', 'RF test equipment and circuit analysis', ' Experience with four of the following:', ' Excellent skills in problem solving, organization, and communication', ' Curiosity/capability to research and learn new techniques or technical topics as needed', 'Low-noise measurement analysis and techniques', 'Preferred Qualifications', ' Experience in multi-qubit calibration and testing', 'Company', 'Setup of highly structured automated data taking and analysis', 'Basic Qualifications', 'Description', ' Thrives in a collaborative environment', ' Comfortable working in a diverse group and contributing to an inclusive culture', ' Strong command of the basic toolset for analyzing superconducting circuits (circuit Lagrangians and Hamiltonians, canonical quantization, etc.)', ' Depth and breadth in experimental test and measurement techniques', 'Troubleshooting and operation/construction of cryogenic hardware', ' Proficient in a scientific programming environment (one or more of Julia, Python, Mathematica, MATLAB)', ' Familiarity with a variety of quantum computing architectures and algorithms', 'Nanofabrication of chip scale devices', ' Experience working closely with scientists and engineers having a wide range of technical skill levels', 'Construction of high-performance test setups', ' Experience in testing superconducting microwave/RF circuits Strong command of the basic toolset for analyzing superconducting circuits (circuit Lagrangians and Hamiltonians, canonical quantization, etc.) Experience in multi-qubit calibration and testing Experience in gate optimization and system identification Familiarity with a variety of quantum computing architectures and algorithms', ' PhD in physics, applied physics, or electrical engineering Depth and breadth in experimental test and measurement techniques Proficient in a scientific programming environment (one or more of Julia, Python, Mathematica, MATLAB) Excellent skills in problem solving, organization, and communication Thrives in a collaborative environment Curiosity/capability to research and learn new techniques or technical topics as needed Comfortable working in a diverse group and contributing to an inclusive culture Experience working closely with scientists and engineers having a wide range of technical skill levels Experience with four of the following:Low-noise measurement analysis and techniquesRF test equipment and circuit analysisConstruction of high-performance test setupsTroubleshooting and operation/construction of cryogenic hardwareSetup of highly structured automated data taking and analysisNanofabrication of chip scale devicesDesign and layout of chip scale devices', ' PhD in physics, applied physics, or electrical engineering', ' Experience in gate optimization and system identification', ' Experience in testing superconducting microwave/RF circuits', 'Design and layout of chip scale devices']",Not Applicable,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Portland, ME",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Customer Success Account Manager,Microsoft,"San Francisco, CA",3 hours ago,Be among the first 25 applicants,"['', 'Travel required: 0-30%', 'Collaboration and Communication - Proven track record of driving decisions collaboratively, resolving conflicts, and ensuring follow-through with verbal and written communication. Strong presentation skills with a high degree of comfort with both large and small audiences and various levels of management (Senior Executives, IT management, Database administrators and Data Scientist).', 'Technical', 'Partner with your customer and Account Team to prioritize and plan customer engagements and programs across cloud and on-premise workloads. ', ""Experience - 5+ years of success in complex technical engagement management and/or program management required. Prior work experience in a Program Manager or Engagement Manager position focused on Cloud and software/services solution preferred. Leadership - This role requires strong communication skills, as well as displaying executive presence and confidence in varying levels of customer situations. The CSAM must show leadership in teams comprised of Microsoft, Partner and customer resources who may be engaged in the delivery of complex solutions for overall customer success.Relationship Building - Proven track record of building relationships with senior customer executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solutions/engagements required.Program Management - Excellent skills in planning for a portfolio of engagements, cross-group collaboration, resource orchestration, communications, analytical capabilities, and attention to detail required.Collaboration and Communication - Proven track record of driving decisions collaboratively, resolving conflicts, and ensuring follow-through with verbal and written communication. Strong presentation skills with a high degree of comfort with both large and small audiences and various levels of management (Senior Executives, IT management, Database administrators and Data Scientist).Technical - Experience with cloud and hybrid infrastructures, architecture designs, and migrations preferred. Knowledge of market trends and competitive insights preferred. Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferred. Education - Bachelor’s degree or equivalent work experience. Bachelor's degree in Computer Science, Information Technology, Engineering or related field preferred. Certification(s) in the following preferred: "", 'Responsibilities', 'Fulfill Support contract obligations by driving quality planning and delivery of Support services to realize customer business outcomes and overall experience with Microsoft solutions. ', 'Education', 'Leadership', 'Fulfill Support contract obligations by driving quality planning and delivery of Support services to realize customer business outcomes and overall experience with Microsoft solutions. Partner with your customer and Account Team to prioritize and plan customer engagements and programs across cloud and on-premise workloads. Define outcomes to improve the health, performance, and business capabilities of the prioritized workloads to drive customer value realization. Orchestration, customer sponsor management, and stakeholder communication of prioritized engagements and programs. Track, escalate, and plan for the remediation of technical blockers and provide engineering feedback to further our product and solutions as appropriate. ', 'Relationship Building - Proven track record of building relationships with senior customer executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solutions/engagements required.', 'Program Management', 'Leadership - This role requires strong communication skills, as well as displaying executive presence and confidence in varying levels of customer situations. The CSAM must show leadership in teams comprised of Microsoft, Partner and customer resources who may be engaged in the delivery of complex solutions for overall customer success.', 'Qualifications', 'Track, escalate, and plan for the remediation of technical blockers and provide engineering feedback to further our product and solutions as appropriate. ', 'Experience', ""Education - Bachelor’s degree or equivalent work experience. Bachelor's degree in Computer Science, Information Technology, Engineering or related field preferred. Certification(s) in the following preferred: "", 'Relationship Building ', 'Technical - Experience with cloud and hybrid infrastructures, architecture designs, and migrations preferred. Knowledge of market trends and competitive insights preferred. Understanding of partner ecosystems and the ability to leverage partner solutions to solve customer needs preferred. ', 'Experience - 5+ years of success in complex technical engagement management and/or program management required. Prior work experience in a Program Manager or Engagement Manager position focused on Cloud and software/services solution preferred. ', 'Key Accountabilities Include', 'Orchestration, customer sponsor management, and stakeholder communication of prioritized engagements and programs. ', 'Collaboration and Communication', 'Program Management - Excellent skills in planning for a portfolio of engagements, cross-group collaboration, resource orchestration, communications, analytical capabilities, and attention to detail required.', 'Define outcomes to improve the health, performance, and business capabilities of the prioritized workloads to drive customer value realization. ']",Not Applicable,Full-time,Sales,Computer Hardware,2020-11-05 11:32:32
Data Engineer,Amazon,"Boston, MA",6 hours ago,Be among the first 25 applicants,"['', ' Write Extract-Transform-Load (ETL) jobs and Spark/Hadoop jobs to calculate business metrics', ' Proficiency with search technologies (Elasticsearch and the Elastic stack)', ' Detailed knowledge of data warehouse technical architecture, infrastructure components, ETL and reporting/analytic tools and environments', 'Preferred Qualifications', ' 3+ years of experience as a Data Engineer or in a similar role', 'Company', ' Design, implement, and automate deployment of our distributed system for collecting and processing log events from multiple sources Design data schema and operate internal data warehouses and SQL/NoSQL database systems Write Extract-Transform-Load (ETL) jobs and Spark/Hadoop jobs to calculate business metrics Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions Monitor and troubleshoot operational or data issues in the data pipelines Drive architectural plans and implementation for future data storage, reporting, and analytic solutions', 'Basic Qualifications', ' Demonstrated experience delivering actionable insights for a consumer business', ' Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc)', 'Description', ' Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions', ' 2+ years of experience in implementing big data processing technology: Hadoop, Apache Spark, etc.', ' Graduate degree in Computer Science, Mathematics, Statistics, Finance, related technical field', ' Monitor and troubleshoot operational or data issues in the data pipelines', ' Experience with data modeling, data warehousing, and building ETL pipelines', ' Experience with AWS technologies including Redshift, RDS, S3, EMR', ' Graduate degree in Computer Science, Mathematics, Statistics, Finance, related technical field Strong ability to effectively communicate with both business and technical teams Demonstrated experience delivering actionable insights for a consumer business Proficiency with search technologies (Elasticsearch and the Elastic stack) Coding proficiency in at least one modern programming language (Python, Ruby, Java, etc) Experience with AWS technologies including Redshift, RDS, S3, EMR', "" 3+ years of experience as a Data Engineer or in a similar role Experience with data modeling, data warehousing, and building ETL pipelines Experience in SQL Bachelor's degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience 3+ years of relevant work experience in analytics, data engineering, business intelligence or related field, and 3+ years professional experience 2+ years of experience in implementing big data processing technology: Hadoop, Apache Spark, etc. Experience using SQL queries, experience in writing and optimizing SQL queries in a business environment with large-scale, complex datasets Detailed knowledge of data warehouse technical architecture, infrastructure components, ETL and reporting/analytic tools and environments Experience in data visualization software (Tableau/Qlikview) or open-source project"", "" Bachelor's degree in Computer Science, Mathematics, Statistics, Finance, related technical field, or equivalent work experience"", ' Design, implement, and automate deployment of our distributed system for collecting and processing log events from multiple sources', ' Drive architectural plans and implementation for future data storage, reporting, and analytic solutions', ' Strong ability to effectively communicate with both business and technical teams', ' Experience in SQL', 'Key Responsibilities', ' 3+ years of relevant work experience in analytics, data engineering, business intelligence or related field, and 3+ years professional experience', ' Experience in data visualization software (Tableau/Qlikview) or open-source project', ' Design data schema and operate internal data warehouses and SQL/NoSQL database systems', ' Experience using SQL queries, experience in writing and optimizing SQL queries in a business environment with large-scale, complex datasets']",Not Applicable,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Nashville, TN",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect (Infrastructure) - CTJ,Microsoft,"Reston, VA",3 hours ago,Be among the first 25 applicants,"['', 'Join us and be one who helps to empower the US government! ', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'Microsoft Federal ', ', plus the ', 'Apply technical knowledge and customer insights to create a modernization roadmap. Architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, while orchestrating key resources and infusing key Infrastructure technologies (e.g. Windows and Linux IaaS, Security, Networking, etc.), and Application Development and DevOps technologies (e.g. App Service, containers, serverless, cloud native, etc.) as appropriate', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners"", 'Responsibilities', 'Education', 'inspiration', '. When you combine that with your own ', ' and support to make your ideas happen, you can make a huge ', 'Professional', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'reach', ""Understand customers' overall applications portfolio, IT and business priorities and success measures to design implementation architectures and solutions (Microsoft and 3rd party solutions)"", 'Be an Azure Platform evangelist with customers, partners and external communities', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on the Microsoft Azure platform', 'Qualifications', 'Experiences', 'Experience. 10+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of highly distributed applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Microsoft Federal delivers a single unified organization centered around our customer: ', 'empowering our teams', 'Be the Voice of the Customer; Share insights and best practices, and connect with Engineering teams to remove key blockers', 'Maintain technical skills and knowledge of market trends and competitive insights; collaborate and share with the technical community', 'Certification in one of the following technologies preferred: Cloud, mobile, web application development, cloud-native application architecture (i.e. containers, microservices, API management), modern software development techniques like DevOps and CI/CD tool chains (i.e. Jenkins, Spinnaker, Azure developer services, GitHub) and container orchestration systems (i.e. Docker, Kubernetes, Cloud Foundry, Azure Kubernetes Service, GitHub).', 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'That’s incredible ', 'Ensure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deployment', 'Experience. 10+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of highly distributed applications required', 'freedom', 'Key responsibilities include: Azure Secret Cloud', ""Understand customers' overall applications portfolio, IT and business priorities and success measures to design implementation architectures and solutions (Microsoft and 3rd party solutions)Apply technical knowledge and customer insights to create a modernization roadmap. Architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, while orchestrating key resources and infusing key Infrastructure technologies (e.g. Windows and Linux IaaS, Security, Networking, etc.), and Application Development and DevOps technologies (e.g. App Service, containers, serverless, cloud native, etc.) as appropriateEnsure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe the Voice of the Customer; Share insights and best practices, and connect with Engineering teams to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partnersCollaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on the Microsoft Azure platformMaintain technical skills and knowledge of market trends and competitive insights; collaborate and share with the technical communityBe an Azure Platform evangelist with customers, partners and external communities"", ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredCertification in one of the following technologies preferred: Cloud, mobile, web application development, cloud-native application architecture (i.e. containers, microservices, API management), modern software development techniques like DevOps and CI/CD tool chains (i.e. Jenkins, Spinnaker, Azure developer services, GitHub) and container orchestration systems (i.e. Docker, Kubernetes, Cloud Foundry, Azure Kubernetes Service, GitHub)."", 'impact.']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Sr. Data Scientist - Finance Operations,Amazon,"Arlington, VA",6 hours ago,Be among the first 25 applicants,"['', ' Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, NLP, deep learning, recommendation systems, dialogue systems, information retrieval, XGBoost, LightGBM, ElasticNet.', ' Automating feedback loops for algorithms in production', 'Preferred Qualifications', ' Fluency in a scripting or computing language (e.g. Python, Scala, C++, Java, etc.)', 'Company', ' Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes', 'Basic Qualifications', 'Description', ' A PhD in a quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent)', 'The Key Strategic Objectives For This Role Include', ' Understanding drivers, impacts, and key influences on cash application operations for a large-scale Amazon business Optimizing automated cash application technology to improve the customer experience and increase operational productivity Helping to build production systems that take inputs from multiple models and make decisions in real time Automating feedback loops for algorithms in production Utilizing Amazon systems and tools to effectively work with terabytes of data', ' 4+ years of relevant working experience in an analytical and model building role involving data extraction, analysis, statistical modeling, and communication', ' 4+ years of experience with data querying languages (e.g. SQL, Hadoop/Hive)', ' Experience working with high volume operational processes and partnering with front line operators', ' Functional knowledge of AWS platforms such as S3, Glue, Athena, Sagemaker.', ' Utilizing Amazon systems and tools to effectively work with terabytes of data', ' Advanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar Databases', ' Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data from different product groups and business functions', ' 8+ years of experience working in data science in a consumer product company', ' Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts.', ' Helping to build production systems that take inputs from multiple models and make decisions in real time', ' Optimizing automated cash application technology to improve the customer experience and increase operational productivity', ' Masters in quantitative field (Computer Science, Mathematics, Machine Learning, Decision Science, Statistics, or equivalent) Fluency in a scripting or computing language (e.g. Python, Scala, C++, Java, etc.) 4+ years of relevant working experience in an analytical and model building role involving data extraction, analysis, statistical modeling, and communication 4+ years of experience with data querying languages (e.g. SQL, Hadoop/Hive) Experience processing, filtering, and presenting large quantities (Millions to Billions of rows) of data from different product groups and business functions Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts. Experience working with high volume operational processes and partnering with front line operators', ' Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives', ' Skilled with Java, C++, or other programming language, as well as with R, SAS, MATLAB, Python or similar scripting language', ' Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, NLP, deep learning, recommendation systems, dialogue systems, information retrieval', ' Understanding drivers, impacts, and key influences on cash application operations for a large-scale Amazon business', ' Masters in quantitative field (Computer Science, Mathematics, Machine Learning, Decision Science, Statistics, or equivalent)', ' A PhD in a quantitative field (Computer Science, Mathematics, Machine Learning, AI, Statistics, or equivalent) 8+ years of experience working in data science in a consumer product company Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, NLP, deep learning, recommendation systems, dialogue systems, information retrieval, XGBoost, LightGBM, ElasticNet. Skilled with Java, C++, or other programming language, as well as with R, SAS, MATLAB, Python or similar scripting language Functional knowledge of AWS platforms such as S3, Glue, Athena, Sagemaker. Ability to distill informal customer requirements into problem definitions, dealing with ambiguity and competing objectives Extensive knowledge and practical experience in several of the following areas: machine learning, statistics, NLP, deep learning, recommendation systems, dialogue systems, information retrieval Advanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar Databases Ability to manage and quantify improvement in customer experience or value for the business resulting from research outcomes']",Mid-Senior level,Full-time,Other,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Seattle, WA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect (Infrastructure) - CTJ,Microsoft,"Reston, VA",3 hours ago,Be among the first 25 applicants,"['', 'Join us and be one who helps to empower the US government! ', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'Microsoft Federal ', ', plus the ', 'Apply technical knowledge and customer insights to create a modernization roadmap. Architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, while orchestrating key resources and infusing key Infrastructure technologies (e.g. Windows and Linux IaaS, Security, Networking, etc.), and Application Development and DevOps technologies (e.g. App Service, containers, serverless, cloud native, etc.) as appropriate', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners"", 'Responsibilities', 'Education', 'Maintain technical skills and knowledge of market trends and competitive insights; collaborate and share with the technical community ', ""Understand customers' overall applications portfolio, IT and business priorities and success measures to design implementation architectures and solutions (Microsoft and 3rd party solutions) "", 'inspiration', '. When you combine that with your own ', ' and support to make your ideas happen, you can make a huge ', 'Professional', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'reach', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on the Microsoft Azure platform', 'Qualifications', 'Experience. 10+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of highly distributed applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Be an Azure Platform evangelist with customers, partners and external communities ', 'Microsoft Federal delivers a single unified organization centered around our customer: ', 'empowering our teams', 'Be the Voice of the Customer; Share insights and best practices, and connect with Engineering teams to remove key blockers', 'Certification in one of the following technologies preferred: Cloud, mobile, web application development, cloud-native application architecture (i.e. containers, microservices, API management), modern software development techniques like DevOps and CI/CD tool chains (i.e. Jenkins, Spinnaker, Azure developer services, GitHub) and container orchestration systems (i.e. Docker, Kubernetes, Cloud Foundry, Azure Kubernetes Service, GitHub).', 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'That’s incredible ', 'Ensure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deployment', 'Experience. 10+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of highly distributed applications required', 'freedom', 'Key responsibilities include: Azure Secret Cloud', 'Experiences', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredCertification in one of the following technologies preferred: Cloud, mobile, web application development, cloud-native application architecture (i.e. containers, microservices, API management), modern software development techniques like DevOps and CI/CD tool chains (i.e. Jenkins, Spinnaker, Azure developer services, GitHub) and container orchestration systems (i.e. Docker, Kubernetes, Cloud Foundry, Azure Kubernetes Service, GitHub)."", ""Understand customers' overall applications portfolio, IT and business priorities and success measures to design implementation architectures and solutions (Microsoft and 3rd party solutions) Apply technical knowledge and customer insights to create a modernization roadmap. Architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, while orchestrating key resources and infusing key Infrastructure technologies (e.g. Windows and Linux IaaS, Security, Networking, etc.), and Application Development and DevOps technologies (e.g. App Service, containers, serverless, cloud native, etc.) as appropriateEnsure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe the Voice of the Customer; Share insights and best practices, and connect with Engineering teams to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partnersCollaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on the Microsoft Azure platformMaintain technical skills and knowledge of market trends and competitive insights; collaborate and share with the technical community Be an Azure Platform evangelist with customers, partners and external communities "", 'impact.']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
Senior Principal Research Scientist,Amazon,"Seattle, WA",4 hours ago,Be among the first 25 applicants,"['', ' Work with Scholars and others on the Core AI team to consult with internal partner teams on candidate opportunities to assess potential for impact based on advanced scientific methods', ' Develop new scientific approaches and mathematical formalisms to deploy in real-world applications', ' Thought leader; sought after for research expertise to apply to real-world systems at scale.', ' Work with Scholars and others on the Core AI team to consult with internal partner teams on candidate opportunities to assess potential for impact based on advanced scientific methods Participate and/or drive ideation, exploration, and feasibility analysis of Core-AI-sponsored innovations. Develop new scientific approaches and mathematical formalisms to deploy in real-world applications', 'Preferred Qualifications', 'Company', ' Phd in Statistics, Operations Research, or related discipline', 'Responsibilities', ' The candidate will work on problems driven by client needs in areas such as supply-chain modeling, forecasting, pricing, resource allocation, and personalization. The work will include the development of new mathematical and algorithmic ideas.', 'Basic Qualifications', ' Can successfully sell ideas to an executive-level decision making', 'Description', "" A successful candidate will work closely with Amazon's Scholar Residency Program - a program consisting of world-class academic scientists and researchers collaborating with internal partner teams to facilitate the delivery of Scholar-led science into engineering systems."", ' 10+ years of combined academic research and industry experience with track record of innovation', "" A successful candidate will work closely with Amazon's Scholar Residency Program - a program consisting of world-class academic scientists and researchers collaborating with internal partner teams to facilitate the delivery of Scholar-led science into engineering systems. The candidate will work on problems driven by client needs in areas such as supply-chain modeling, forecasting, pricing, resource allocation, and personalization. The work will include the development of new mathematical and algorithmic ideas."", ' Phd in Statistics, Operations Research, or related discipline 10+ years of combined academic research and industry experience with track record of innovation Strong publication record in top-tier journals and conference presentations Excellent communication, writing and presentation skills', ' Strong publication record in top-tier journals and conference presentations', ' Participate and/or drive ideation, exploration, and feasibility analysis of Core-AI-sponsored innovations.', ' Excellent communication, writing and presentation skills', ' Strong theoretical and applied foundations in statistics and OR Thought leader; sought after for research expertise to apply to real-world systems at scale. Can successfully sell ideas to an executive-level decision making Experience mentoring/training scientists on complex technical and scientific issues Experience in deploying scalable solutions to complex problems, from defining the problem, implementing the solution, and launching the new product successfully', ' Experience in deploying scalable solutions to complex problems, from defining the problem, implementing the solution, and launching the new product successfully', ' Strong theoretical and applied foundations in statistics and OR', ' Experience mentoring/training scientists on complex technical and scientific issues']",Director,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Manchester, NH",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect (App Dev) - CTJ,Microsoft,"Reston, VA",3 hours ago,Be among the first 25 applicants,"['', ' 10+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of highly distributed applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Join us and be one who helps to empower the US government! ', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'Microsoft Federal ', 'Apply technical knowledge and customer insights to create a modernization roadmap. Architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, while orchestrating key resources and infusing key Infrastructure technologies (e.g. Windows and Linux IaaS, Security, Networking, etc.), and Application Development and DevOps technologies (e.g. App Service, containers, serverless, cloud native, etc.) as appropriate', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners"", 'Responsibilities', 'impact.', 'Education', 'Maintain technical skills and knowledge of market trends and competitive insights; collaborate and share with the technical community ', ""Understand customers' overall applications portfolio, IT and business priorities and success measures to design implementation architectures and solutions (Microsoft and 3rd party solutions) "", 'inspiration', 'Professional', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'reach', ""Understand customers' overall applications portfolio, IT and business priorities and success measures to design implementation architectures and solutions (Microsoft and 3rd party solutions) Apply technical knowledge and customer insights to create a modernization roadmap. Architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, while orchestrating key resources and infusing key Infrastructure technologies (e.g. Windows and Linux IaaS, Security, Networking, etc.), and Application Development and DevOps technologies (e.g. App Service, containers, serverless, cloud native, etc.) as appropriateEnsure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe the Voice of the Customer; Share insights and best practices, and connect with Engineering teams to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partnersCollaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on the Microsoft Azure platformMaintain technical skills and knowledge of market trends and competitive insights; collaborate and share with the technical community Be an Azure Platform evangelist with customers, partners and external communities"", 'Be an Azure Platform evangelist with customers, partners and external communities', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on the Microsoft Azure platform', ' 10+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of highly distributed applications required', 'Qualifications', 'Microsoft Federal delivers a single unified organization centered around our customer: ', 'empowering our teams', 'That’s incredible reach. When you combine that with your own inspiration, plus the freedom and support to make your ideas happen, you can make a huge impact.', 'Be the Voice of the Customer; Share insights and best practices, and connect with Engineering teams to remove key blockers', 'Certification in one of the following technologies preferred: Cloud, mobile, web application development, cloud-native application architecture (i.e. containers, microservices, API management), modern software development techniques like DevOps and CI/CD tool chains (i.e. Jenkins, Spinnaker, Azure developer services, GitHub) and container orchestration systems (i.e. Docker, Kubernetes, Cloud Foundry, Azure Kubernetes Service, GitHub).', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'Ensure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deployment', 'freedom', 'Key responsibilities include: Azure Secret Cloud', 'Experiences', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredCertification in one of the following technologies preferred: Cloud, mobile, web application development, cloud-native application architecture (i.e. containers, microservices, API management), modern software development techniques like DevOps and CI/CD tool chains (i.e. Jenkins, Spinnaker, Azure developer services, GitHub) and container orchestration systems (i.e. Docker, Kubernetes, Cloud Foundry, Azure Kubernetes Service, GitHub)."", 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
ES Tech - Data Engineer,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Experience building ETL on Mulesoft.', ' 2+ years of experience in scripting languages like Python etc.', ' 3+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.', 'Preferred Qualifications', 'Company', ' Build and deliver high quality data architecture to support business analyst, data scientists, and customer reporting needs.', 'Basic Qualifications', 'Description', ' Experience with Big Data Technologies.', ' Experience with AWS services including S3, Redshift, EMR and Kinesis. Ability to work independently and problem solve with little to no direction. Impeccable customer service focus with a demonstrated desire to exceed expectations. Attention to detail; you prioritize multiple tasks simultaneously without sacrificing the ability to dive deep. Mulesoft certification a plus.', ' Drive the collection of new data and the refinement of existing data sources to continually improve data quality and implement business logic using efficient transformations.', ' 2+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.', ' Build robust and scalable data integration (ETL) pipelines using SQL, Python and Mulesoft. Build and deliver high quality data architecture to support business analyst, data scientists, and customer reporting needs. Interface with other technology teams to extract, transform, and load data from a wide variety of data sources. Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers. Design and development ETL mappings within data integration tool primarily for Salesforce applications. Drive the collection of new data and the refinement of existing data sources to continually improve data quality and implement business logic using efficient transformations.', ' Ability to work independently and problem solve with little to no direction.', ' Build robust and scalable data integration (ETL) pipelines using SQL and Python. Experience with Big Data Technologies. 2+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets. 2+ years of experience in scripting languages like Python etc. 3+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets. Experience building ETL on Mulesoft.', ' Mulesoft certification a plus.', ' Design and development ETL mappings within data integration tool primarily for Salesforce applications.', 'Responsibilities Include', ' Interface with other technology teams to extract, transform, and load data from a wide variety of data sources.', ' Impeccable customer service focus with a demonstrated desire to exceed expectations.', ' Experience with AWS services including S3, Redshift, EMR and Kinesis.', ' Build robust and scalable data integration (ETL) pipelines using SQL, Python and Mulesoft.', ' Build robust and scalable data integration (ETL) pipelines using SQL and Python.', ' Attention to detail; you prioritize multiple tasks simultaneously without sacrificing the ability to dive deep.', ' Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers.']",Not Applicable,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Columbus, OH",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Cloud Solution Architect (App Dev) - CTJ,Microsoft,"Reston, VA",3 hours ago,Be among the first 25 applicants,"['', ' 10+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of highly distributed applications requiredRelationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. requiredProblem Solving. Ability to solve customer problems through cloud technologies requiredCollaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', 'Join us and be one who helps to empower the US government! ', 'Problem Solving. Ability to solve customer problems through cloud technologies required', 'Microsoft Federal ', 'Apply technical knowledge and customer insights to create a modernization roadmap. Architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, while orchestrating key resources and infusing key Infrastructure technologies (e.g. Windows and Linux IaaS, Security, Networking, etc.), and Application Development and DevOps technologies (e.g. App Service, containers, serverless, cloud native, etc.) as appropriate', 'Collaboration and Communication. Acknowledged for driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills. Ability to orchestrate, lead, and influence virtual teams, ensuring successful implementation of customer projects. Presentation skills with a high degree of comfort with both large and small audiences (Senior Executives, IT management, Database administrators and Data Scientist) required', ""Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners"", 'Responsibilities', 'impact.', 'Education', 'Maintain technical skills and knowledge of market trends and competitive insights; collaborate and share with the technical community ', ""Understand customers' overall applications portfolio, IT and business priorities and success measures to design implementation architectures and solutions (Microsoft and 3rd party solutions) "", 'inspiration', 'Professional', 'Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates', 'reach', ""Understand customers' overall applications portfolio, IT and business priorities and success measures to design implementation architectures and solutions (Microsoft and 3rd party solutions) Apply technical knowledge and customer insights to create a modernization roadmap. Architect solutions to meet business and IT needs, ensuring technical viability of new projects and successful deployments, while orchestrating key resources and infusing key Infrastructure technologies (e.g. Windows and Linux IaaS, Security, Networking, etc.), and Application Development and DevOps technologies (e.g. App Service, containers, serverless, cloud native, etc.) as appropriateEnsure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deploymentDevelop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocatesBe the Voice of the Customer; Share insights and best practices, and connect with Engineering teams to remove key blockersAssess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partnersCollaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on the Microsoft Azure platformMaintain technical skills and knowledge of market trends and competitive insights; collaborate and share with the technical community Be an Azure Platform evangelist with customers, partners and external communities"", 'Be an Azure Platform evangelist with customers, partners and external communities', 'Collaborate with other Cloud Solution Architects in developing complex end-to-end Enterprise solutions on the Microsoft Azure platform', ' 10+ years of success in consultative/complex technical sales and deployment projects, architecture, design, implementation, and/or support of highly distributed applications required', 'Qualifications', 'Microsoft Federal delivers a single unified organization centered around our customer: ', 'empowering our teams', 'That’s incredible reach. When you combine that with your own inspiration, plus the freedom and support to make your ideas happen, you can make a huge impact.', 'Be the Voice of the Customer; Share insights and best practices, and connect with Engineering teams to remove key blockers', 'Certification in one of the following technologies preferred: Cloud, mobile, web application development, cloud-native application architecture (i.e. containers, microservices, API management), modern software development techniques like DevOps and CI/CD tool chains (i.e. Jenkins, Spinnaker, Azure developer services, GitHub) and container orchestration systems (i.e. Docker, Kubernetes, Cloud Foundry, Azure Kubernetes Service, GitHub).', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferred"", 'Ensure all solutions exhibit high levels of performance, security, scalability, maintainability, and appropriate reusability and reliability upon deployment', 'freedom', 'Key responsibilities include: Azure Secret Cloud', 'Experiences', ""Bachelor's degree in Computer Science, Information Technology, Engineer or related field preferredCertification in one of the following technologies preferred: Cloud, mobile, web application development, cloud-native application architecture (i.e. containers, microservices, API management), modern software development techniques like DevOps and CI/CD tool chains (i.e. Jenkins, Spinnaker, Azure developer services, GitHub) and container orchestration systems (i.e. Docker, Kubernetes, Cloud Foundry, Azure Kubernetes Service, GitHub)."", 'Relationship Building. Proven track record of building deep technical relationships with senior IT executives in large or highly strategic accounts. Experience in managing various stakeholder relationships to get consensus on solution/projects. required']",Not Applicable,Full-time,Engineering,Computer Hardware,2020-11-05 11:32:32
"Senior Data Scientist, WW Ops Analytics",Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Presenting research results to our internal research community.', 'Preferred Qualifications', ' Collaborating with our dedicated product, data engineering, and software development teams to create production implementations for large-scale data analysis.', 'Company', ' Experience working on problems of a financial nature', 'Basic Qualifications', 'Description', ' Leveraging the largest repository of supply chain data to ever exist to develop models to forecast, classify, and detect anomalous costs.', "" Bachelor's Degree 5+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab) 4+ years working as a Data Scientist"", ' Deep understanding of supply chains and their cost drivers Experience working on problems of a financial nature', 'Here In WW Ops Analytics Our Data Scientists Raise The Bar On Our Ability To Fulfill Promises To Customers At Greater Convenience, Speed, And Value Through', ' 5+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)', ' Deep understanding of supply chains and their cost drivers', ' Working with technical and non-technical customers across every step of data science project life cycle.', ' Developing an understanding of key business metrics / KPIs and providing clear, compelling analysis that shapes the direction of our business.', "" Bachelor's Degree"", ' Leading training and informational sessions on our science and capabilities.', ' Leveraging the largest repository of supply chain data to ever exist to develop models to forecast, classify, and detect anomalous costs. Working with technical and non-technical customers across every step of data science project life cycle. Collaborating with our dedicated product, data engineering, and software development teams to create production implementations for large-scale data analysis. Developing an understanding of key business metrics / KPIs and providing clear, compelling analysis that shapes the direction of our business. Presenting research results to our internal research community. Leading training and informational sessions on our science and capabilities.', ' 4+ years working as a Data Scientist']",Mid-Senior level,Full-time,Other,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Cincinnati, OH",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Operations Research Scientist,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Familiarity with transportation/logistics concepts - forecasting, planning, optimization, and logistics - gained through work experience or graduate level education', 'Duties Include', ' Partnering closely with many groups such as operations, IT, retail, and finance teams to support various business initiatives', ' Graduate degree in operations research, statistics, engineering, mathematics, or computer science and 7+ years of related work experience OR PhD and 5+ years of related work experience', 'Preferred Qualifications', ' Technical aptitude and familiarity with the design and use of complex logistics software systems', 'Company', ' PhD highly desired', 'Basic Qualifications', 'Description', ' Effectively communicating with senior management as well as with colleagues from computer science, operations research and business backgrounds', ' Owning the strategic planning and project management for initiatives including long-term forecasting, optimization, and process improvement', ' Ability to code with an object oriented language', ' Excellent written and verbal communication skills', ' Experience working effectively with software engineering teams', ' Ability to develop system prototypes', ' Experience with mathematical libraries like CPLEX, XPRESS, and SAS', ' Exposure to scripting languages, relational databases and Linux', ' PhD highly desired Project management experience desired for working on cross-functional projects Software development experience Exposure to scripting languages, relational databases and Linux Familiarity with transportation/logistics concepts - forecasting, planning, optimization, and logistics - gained through work experience or graduate level education Technical aptitude and familiarity with the design and use of complex logistics software systems Experience working effectively with software engineering teams Excellent written and verbal communication skills', ' Utilizing code (Java, C++ or another object oriented language) for modeling (optimization, simulation, statistical)', ' Graduate degree in operations research, statistics, engineering, mathematics, or computer science and 7+ years of related work experience OR PhD and 5+ years of related work experience Ability to code with an object oriented language Ability to develop system prototypes Experience with mathematical libraries like CPLEX, XPRESS, and SAS', ' Providing business analysis using mathematical modeling tools to answer important questions', ' Software development experience', ' Owning the strategic planning and project management for initiatives including long-term forecasting, optimization, and process improvement Providing business analysis using mathematical modeling tools to answer important questions Utilizing code (Java, C++ or another object oriented language) for modeling (optimization, simulation, statistical) Partnering closely with many groups such as operations, IT, retail, and finance teams to support various business initiatives Effectively communicating with senior management as well as with colleagues from computer science, operations research and business backgrounds', ' Project management experience desired for working on cross-functional projects']",Mid-Senior level,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"San Francisco, CA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Business Intelligence Engineer,Amazon,"Austin, TX",4 hours ago,Over 200 applicants,"['', 'As Part Of The The Business VOC Team You Will', ' Experience using AWS technologies such as Redshift, S3, EC2, EMR and data pipelines', 'Preferred Qualifications', ' 5+ years in relevant experience as data scientist, data engineer, software engineer, business intelligence engineer, or equivalent. Strong fundamentals in problem-solving, algorithm design and complexity analysis.Masters Proficiency with a scripting language (Java, Python, or R) Experience in data mining, SQL, ETL, etc. and using databases in a business environment with large-scale, complex datasets. Master’s degree in BI, Finance, Engineering, Statistics, Computer Science, Mathematics, Finance or related field required.', 'Company', "" Answer critical business questions using data - Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations Establish KPI's and highlight opportunities - Report key insight trends, using statistical rigor to simplify and inform the larger team of noteworthy story lines that impact the business. Build best-in-class datasets - Scope, build and own technical data warehouse processes using a broad range of Amazon's data resources to help the business scale. Automate reporting and BI - Build automated data solutions and dashboards to enable your team to self-service 80% of data needs, allowing you to focus on answering hard and ambiguous problems. Build analytical models - Perform analytics across multiple data sources, building models that are both scalable and extensible to business needs. Contribute to NLP and ML - Become proficient in best-in-class natural language processing (NLP) standards and contribute to ML improvements. Be a trusted partner - Collaborate with software engineering, product management, marketing and UX as a leader of quantitative analysis and where you develop solutions that utilize the highest standards of analytical rigor and data integrity."", 'Basic Qualifications', ' Contribute to NLP and ML - Become proficient in best-in-class natural language processing (NLP) standards and contribute to ML improvements.', ' Answer critical business questions using data - Identify, develop, manage, and execute analyses to uncover areas of opportunity and present written business recommendations', 'Description', "" Establish KPI's and highlight opportunities - Report key insight trends, using statistical rigor to simplify and inform the larger team of noteworthy story lines that impact the business."", ' Master’s degree in BI, Finance, Engineering, Statistics, Computer Science, Mathematics, Finance or related field required.', ' Strong fundamentals in problem-solving, algorithm design and complexity analysis.Masters', ' Proficiency with a scripting language (Java, Python, or R)', "" Build best-in-class datasets - Scope, build and own technical data warehouse processes using a broad range of Amazon's data resources to help the business scale."", ' Build analytical models - Perform analytics across multiple data sources, building models that are both scalable and extensible to business needs.', ' A desire to work in a collaborative, intellectually curious environment', "" Bachelor's degree in Business Administration, Finance, Computer Information Systems, Engineering, Operations Research, Mathematics or other business/analytical disciplines or equivalent experience"", ' Proficiency with data querying or modeling technique with SQL', ' Automate reporting and BI - Build automated data solutions and dashboards to enable your team to self-service 80% of data needs, allowing you to focus on answering hard and ambiguous problems.', "" 3+ years of relevant experience as a data engineer, business analyst, product analyst, data scientist, software engineer, business intelligence engineer, or equivalent. Proficiency with data querying or modeling technique with SQL Experience using AWS technologies such as Redshift, S3, EC2, EMR and data pipelines Bachelor's degree in Business Administration, Finance, Computer Information Systems, Engineering, Operations Research, Mathematics or other business/analytical disciplines or equivalent experience A desire to work in a collaborative, intellectually curious environment"", ' 3+ years of relevant experience as a data engineer, business analyst, product analyst, data scientist, software engineer, business intelligence engineer, or equivalent.', ' Be a trusted partner - Collaborate with software engineering, product management, marketing and UX as a leader of quantitative analysis and where you develop solutions that utilize the highest standards of analytical rigor and data integrity.', ' Experience in data mining, SQL, ETL, etc. and using databases in a business environment with large-scale, complex datasets.', ' 5+ years in relevant experience as data scientist, data engineer, software engineer, business intelligence engineer, or equivalent.']",Not Applicable,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Minneapolis, MN",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Experience with building high-performance, highly-available and scalable data systems', ' BS/MS in Computer Science or equivalent industry experience', ' Are you excited about working directly to empower users? Love to get your hands dirty and solve challenging technical issues?', ' Love to get your hands dirty and solve challenging technical issues?', 'Preferred Qualifications', ' 3+ years of experience as a Data Engineer or in a similar role', 'Company', 'Basic Qualifications', 'Description', ' BS/MS in Computer Science or equivalent industry experience Experience in functional/programming languages such as , Spark, Scala and Java Knowledge of distributed systems as it pertains to data storage and computing Deep knowledge of various AWS big data technologies Experience successfully mentoring junior data and software engineers', ' Willingness to dive deep, experiment rapidly and get things done', ' Are you excited about working directly to empower users?', ' Experience successfully mentoring junior data and software engineers', ' Knowledge of distributed systems as it pertains to data storage and computing', "" 3+ years of experience as a Data Engineer or in a similar role Experience with data modeling, data warehousing, and building ETL pipelines Experience in SQL Bachelor's degree in Computer Science, Software Engineering, or a related engineering discipline 3+ years’ full-time experience in software design and development Proficiency with at least one Object Oriented language (e.g. Java, Scala) Experience with building high-performance, highly-available and scalable data systems Willingness to dive deep, experiment rapidly and get things done Ability to communicate clearly and concisely with technical and non-technical customers in order to understand ambiguous problems and articulate technical designs and solutions to complex problem Agile methodologies, coding standards, code reviews, source control management, build processes, testing, and operations"", ' Agile methodologies, coding standards, code reviews, source control management, build processes, testing, and operations', ' Experience with data modeling, data warehousing, and building ETL pipelines', ' 3+ years’ full-time experience in software design and development', ' Experience in functional/programming languages such as , Spark, Scala and Java', ' Proficiency with at least one Object Oriented language (e.g. Java, Scala)', ' Deep knowledge of various AWS big data technologies', ' Ability to communicate clearly and concisely with technical and non-technical customers in order to understand ambiguous problems and articulate technical designs and solutions to complex problem', ' Experience in SQL', "" Bachelor's degree in Computer Science, Software Engineering, or a related engineering discipline""]",Not Applicable,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Raleigh, NC",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Machine Learning Applied Scientist - Technical Leader,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' At least 4 years of experience with, at least, one model programming language such as Java, Python, Scala, C++.', ' Run A/B experiments, gather data, and perform statistical analysis.', ' M.S. or Ph.D. in Computer Science, Information Retrieval, Machine Learning, Statistics, Applied Mathematics, Natural Language Processing, or related discipline.', ' Ph.D. in quantitative field with a strong Machine Learning background. Experience in building large-scale machine-learning models for online recommendation, ads ranking, personalization, or search, etc. Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, Lucene/SOLR or Storm/Samza.', 'Preferred Qualifications', ' This role combines science leadership, organizational ability, technical strength, product focus and business understanding. In the immediate term, this role requires (a) addressing principles of allocation function and pricing in ad marketplace auctions, (b) developing efficient algorithms for multi-objective optimization and AI control methods to find operating points for the ad marketplace auctions and to evolve them, and (c) develop science talent around machine learning, Economics and optimization for WW Advertising.', ' 3+ years of experience of building machine learning models for business application', 'Company', ' Build machine learning models and utilize data analysis to deliver scalable solutions to business problems.', ' Influence customer facing shopping experiences to helping suppliers grow their retail business and the auction dynamics that leverage native advertising, this role will be powering the engine of one the fastest growing businesses at Amazon.', ' Research new machine learning approaches.', 'Basic Qualifications', 'Description', ' Work closely with software engineers on detailed requirements, technical designs and implementation of end-to-end solutions in production', ' Breadth and depth knowledge of machine learning algorithms and best practices.', ' Establish scalable, efficient, automated processes for large-scale data analysis, machine-learning model development, model validation and serving.', ' Experience in building large-scale machine-learning models for online recommendation, ads ranking, personalization, or search, etc.', ' You will invent new shopper and advertiser experiences, and accelerate the pace of Machine Learning and Optimization.', ' You will invent new shopper and advertiser experiences, and accelerate the pace of Machine Learning and Optimization. Influence customer facing shopping experiences to helping suppliers grow their retail business and the auction dynamics that leverage native advertising, this role will be powering the engine of one the fastest growing businesses at Amazon. Define a long-term science vision for our ad marketplace, driven fundamentally from the needs of our customers, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams. This role combines science leadership, organizational ability, technical strength, product focus and business understanding. In the immediate term, this role requires (a) addressing principles of allocation function and pricing in ad marketplace auctions, (b) developing efficient algorithms for multi-objective optimization and AI control methods to find operating points for the ad marketplace auctions and to evolve them, and (c) develop science talent around machine learning, Economics and optimization for WW Advertising.', 'Why You Love This Opportunity', ' Experience programming in Java, C++, Python or related language', ' Define a long-term science vision for our ad marketplace, driven fundamentally from the needs of our customers, translating that direction into specific plans for research and applied scientists, as well as engineering and product teams.', 'Impact And Career Growth', ' Ph.D. in quantitative field with a strong Machine Learning background.', ' Build machine learning models and utilize data analysis to deliver scalable solutions to business problems. Run A/B experiments, gather data, and perform statistical analysis. Establish scalable, efficient, automated processes for large-scale data analysis, machine-learning model development, model validation and serving. Work closely with software engineers on detailed requirements, technical designs and implementation of end-to-end solutions in production Research new machine learning approaches.', ' At least 4 years of experience with computer science fundamentals in object-oriented design, data structures, algorithm design, problem solving, and complexity analysis.', ' PhD degree with 4 years of applied research experience or a Masters degree and 6+ years of experience of applied research experience', ' Experience with Big Data technologies such as AWS, Hadoop, Spark, Pig, Hive, Lucene/SOLR or Storm/Samza.', ' PhD degree with 4 years of applied research experience or a Masters degree and 6+ years of experience of applied research experience 3+ years of experience of building machine learning models for business application Experience programming in Java, C++, Python or related language M.S. or Ph.D. in Computer Science, Information Retrieval, Machine Learning, Statistics, Applied Mathematics, Natural Language Processing, or related discipline. Breadth and depth knowledge of machine learning algorithms and best practices. At least 4 years of hands-on experience in building Machine Learning solutions to solve real-world problems. At least 4 years of experience with computer science fundamentals in object-oriented design, data structures, algorithm design, problem solving, and complexity analysis. At least 4 years of experience with, at least, one model programming language such as Java, Python, Scala, C++.', ' At least 4 years of hands-on experience in building Machine Learning solutions to solve real-world problems.', 'As An Applied Scientist In Machine Learning, You Will']",Mid-Senior level,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Portland, OR",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Salt Lake City, UT",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Data Engineer, Alexa",Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' Participate in strategic & tactical planning discussions, including annual budget processes', ' Communicating verbally and in writing to business customers and leadership team with various levels of technical knowledge, educating them about our systems, as well as sharing insights and recommendations', ' Proficiency in at least one modern programming language such as Python, Perl, Ruby, Java, etc', 'Preferred Qualifications', ' Proven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams Demonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, marketing, finance, and operations Knowledge of Advanced SQL and a programming language (Python, R, or others) Experience with data visualization using Tableau or similar tools', ' Interface with business customers and team scientists and engineers to gather data and metrics requirements', ' 3+ years of experience as a Data Engineer or in a similar role', 'Company', ' Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.)', 'Responsibilities', 'Basic Qualifications', 'Description', ' Experience gathering business requirements, using industry standard business intelligence tool(s) to extract data, formulate metrics and build reports', ' Manage and optimize team AWS resources', ' Experience with large-scale data warehousing and analytics tools, including AWS technologies like Redshift, S3, and EC2', ' 6+ years of years of relevant work experience in analytics, data engineering, business intelligence, market research or related field', ' Experience with data modeling, data warehousing, and building ETL pipelines', ' Experience using SQL, ETL and databases in a business environment with large-scale, complex datasets', ' Bachelor’s degree in Computer Science, MIS, Mathematics, Statistics, Finance, related technical field, or equivalent work experience.', ' Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL', ' Experience with data visualization using Tableau or similar tools', ' Proven track record of successful communication of analytical outcomes through written communication, including an ability to effectively communicate with both business and technical teams', ' 3+ years of experience as a Data Engineer or in a similar role Experience with data modeling, data warehousing, and building ETL pipelines Experience in SQL Bachelor’s degree in Computer Science, MIS, Mathematics, Statistics, Finance, related technical field, or equivalent work experience. 6+ years of years of relevant work experience in analytics, data engineering, business intelligence, market research or related field Experience gathering business requirements, using industry standard business intelligence tool(s) to extract data, formulate metrics and build reports Experience using SQL, ETL and databases in a business environment with large-scale, complex datasets Experience with large-scale data warehousing and analytics tools, including AWS technologies like Redshift, S3, and EC2 Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.) Proficiency in at least one modern programming language such as Python, Perl, Ruby, Java, etc Knowledge of UNIX shell scripting Experience architecting large scale BI solutions', ' Interface with business customers and team scientists and engineers to gather data and metrics requirements Collaborate with data and software engineers to implement the design of our data architecture and to automate and scale statistical analyses developed by scientists on the team Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL Own the design, development, and maintenance of datasets to drive key business decisions Manage and optimize team AWS resources Participate in strategic & tactical planning discussions, including annual budget processes Created automated alarming and dashboarding to monitor data integrity. Communicating verbally and in writing to business customers and leadership team with various levels of technical knowledge, educating them about our systems, as well as sharing insights and recommendations', ' Collaborate with data and software engineers to implement the design of our data architecture and to automate and scale statistical analyses developed by scientists on the team', ' Experience in SQL', ' Demonstrated ability to coordinate projects across functional teams, including engineering, IT, product management, marketing, finance, and operations', ' Own the design, development, and maintenance of datasets to drive key business decisions', ' Created automated alarming and dashboarding to monitor data integrity.', ' Knowledge of UNIX shell scripting', ' Knowledge of Advanced SQL and a programming language (Python, R, or others)', ' Experience architecting large scale BI solutions']",Not Applicable,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Irvine, CA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Amazon,"Seattle, WA",4 hours ago,45 applicants,"['', ' Write ETL to consolidate and relate petabytes of data owned by disparate teams', ' Participate in design reviews for new tooling and services Capture and share best practices with service teams Teach service team engineers how to test for data quality issues', ' Work with systems engineers and data scientists to design and build a analytics platform and data lake to support compute heavy data science, dashboarding, and web-facing production tooling. (You get to tell us what this should look like!)', 'Preferred Qualifications', 'Company', ' Participate in design reviews for new tooling and services', 'Basic Qualifications', ' Bachelors degree in software engineering or a relevant quantitative discipline', ' Work with systems engineers and data scientists to design and build a analytics platform and data lake to support compute heavy data science, dashboarding, and web-facing production tooling. (You get to tell us what this should look like!) Write ETL to consolidate and relate petabytes of data owned by disparate teams Implement best practice data quality assurance mechanisms', 'Description', 'Within The Compute Services Organization You Will', ' 5+ years of work experience with ETL, Data Modeling, and Data Architecture.', ' 1+ years experience working with distributed computing and associated technologies such as Spark, EMR, etc.', ' Capture and share best practices with service teams', ' 2+ years development experience in python or similar scripting language for automation', ' 3+ years of work experience with ETL, Data Modeling, and Data Architecture with hundreds of terabytes of data', ' Implement best practice data quality assurance mechanisms', 'Roles And Responsibilities', ' 2+ years experience working with core AWS data and analytics services. Understand of the applicability, limitations, and trade offs between a wide set of AWS database and analytics technologies.', ' 5+ years of work experience with ETL, Data Modeling, and Data Architecture. Experience or familiarity with newer AWS data and analytics tools such as AWS Lake Formation, Sagemaker Expert-level skills in writing and optimizing SQL', ' Experience or familiarity with newer AWS data and analytics tools such as AWS Lake Formation, Sagemaker', ' 2+ years experience with Redshift. Tangible experience working with Redshift Spectrum, AWS Glue, DynamoDB, and S3', ' Bachelors degree in software engineering or a relevant quantitative discipline 2+ years development experience in python or similar scripting language for automation 3+ years of work experience with ETL, Data Modeling, and Data Architecture with hundreds of terabytes of data 2+ years experience working with core AWS data and analytics services. Understand of the applicability, limitations, and trade offs between a wide set of AWS database and analytics technologies. 1+ years experience working with distributed computing and associated technologies such as Spark, EMR, etc. 2+ years experience with Redshift. Tangible experience working with Redshift Spectrum, AWS Glue, DynamoDB, and S3', ' Expert-level skills in writing and optimizing SQL', ' Teach service team engineers how to test for data quality issues']",Not Applicable,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Baton Rouge, LA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Data Engineer - Analytics,Amazon,"Boulder, CO",6 hours ago,Be among the first 25 applicants,"['', ' Proven track record of successful communication of data infrastructure, data models, and data engineering solutions through written communication, including an ability to effectively communicate with both business and technical teams', 'Description', ' 5+ years of experience as a Data Engineer or in a similar role Experience with data modeling, data warehousing, and building ETL pipelines Experience in SQL Experience with AWS technologies stack including DynamoDB, RDS, S3, EMR or similar solutions build around Hive/Spark etc Proven track record of successful communication of data infrastructure, data models, and data engineering solutions through written communication, including an ability to effectively communicate with both business and technical teams', ' Experience in SQL', ' Familiarity with statistical models and data mining algorithms', ' Experience with AWS technologies stack including DynamoDB, RDS, S3, EMR or similar solutions build around Hive/Spark etc', ' Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', ' Experience providing technical leadership and mentoring other engineers for best practices on data engineering Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations Familiarity with statistical models and data mining algorithms', ' Experience providing technical leadership and mentoring other engineers for best practices on data engineering', 'Preferred Qualifications', ' 5+ years of experience as a Data Engineer or in a similar role', 'Company', ' Experience with data modeling, data warehousing, and building ETL pipelines', 'Basic Qualifications']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Tulsa, OK",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Data Engineer,Amazon,"Seattle, WA",4 hours ago,116 applicants,"['', ' Experience in BI projects converting business needs to data warehousing and reporting solutions', 'Description', ' 2 plus years of relevant experience Exposure to Big Data Ecosystem and hands-on knowledge on hadoop, hive, pig, spark Exposure to AWS Ecosystem with hands-on knowledge of data products and services Hands-on in writing and optimizing advanced SQL queries Experience in BI projects converting business needs to data warehousing and reporting solutions', ' Exposure to AWS Ecosystem with hands-on knowledge of data products and services', ' 2 plus years of relevant experience', ' Ability to interact, communicate, present and influence within multiple levels of the organization', ' Strong scripting abilities', ' Exposure to Big Data Ecosystem and hands-on knowledge on hadoop, hive, pig, spark', ' Strong scripting abilities Strong in any programming languages such as , Ability to interact, communicate, present and influence within multiple levels of the organization Excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions', 'Preferred Qualifications', ' Excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions', ' Strong in any programming languages such as ,', 'Company', ' Hands-on in writing and optimizing advanced SQL queries', 'Basic Qualifications']",Not Applicable,Full-time,Strategy/Planning,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Little Rock, AR",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior Machine Learning Applied Scientist - Video Shopping,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', 'Major Responsibilities', ' Extensive experience applying theoretical models in an applied environment.', ' Analyze and extract information from large amounts of videos to help moderate and optimize search across videos', 'Preferred Qualifications', ' 3+ years of experience of building machine learning models for business application', 'Company', ' Significant peer reviewed scientific contributions in relevant field.', 'Basic Qualifications', ' Experience with defining organizational research and development practices in an industry setting.', 'Description', ' Work closely with software engineering teams to drive real-time model implementations and new feature creations', ' Proficiency in, at least, one modern programming language such as C, C++, Java, or Perl', ' Computer Science fundamentals in data structures, algorithm design, problem solving, and complexity analysis', ' Experience programming in Java, C++, Python or related language', ' Proven track record of delivering production-ready code with superior user experience.', ' Use statistical and machine learning techniques to create scalable solutions for video analysis and content moderation problems', ' Experience with Python, R, MATLAB or similar scripting languages.', ' PhD degree with 4 years of applied research experience or a Masters degree and 6+ years of experience of applied research experience 3+ years of experience of building machine learning models for business application Experience programming in Java, C++, Python or related language MS in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field 4+ years professional experience in predictive modeling and analysis Computer Science fundamentals in data structures, algorithm design, problem solving, and complexity analysis Proficiency in, at least, one modern programming language such as C, C++, Java, or Perl Experience with Python, R, MATLAB or similar scripting languages.', ' Use statistical and machine learning techniques to create scalable solutions for video analysis and content moderation problems Analyze and extract information from large amounts of videos to help moderate and optimize search across videos Work closely with software engineering teams to drive real-time model implementations and new feature creations Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation Demonstrated ability to drive adoption of best practices across organizations. Proven track record of delivering production-ready code with superior user experience.', ' Strong personal interest in learning, researching, and creating new technologies with high commercial impact.', ' Demonstrated ability to drive adoption of best practices across organizations.', ' 4+ years professional experience in predictive modeling and analysis', ' PhD in Mathematics, Statistics, Machine Learning, or a related quantitative field', ' PhD in Mathematics, Statistics, Machine Learning, or a related quantitative field Significant peer reviewed scientific contributions in relevant field. Extensive experience applying theoretical models in an applied environment. Strong fundamentals in problem solving, algorithm design and complexity analysis. Strong personal interest in learning, researching, and creating new technologies with high commercial impact. Experience with defining organizational research and development practices in an industry setting. Experience with AWS technologies', ' Establish scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation', ' PhD degree with 4 years of applied research experience or a Masters degree and 6+ years of experience of applied research experience', ' Strong fundamentals in problem solving, algorithm design and complexity analysis.', ' Experience with AWS technologies', ' MS in Computer Science, Machine Learning, Operational Research, Statistics or a related quantitative field']",Mid-Senior level,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Denver, CO",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
BIE / Data Engineer,Amazon,"Seattle, WA",23 hours ago,93 applicants,"['', '3+ years working in hands on environment with the above', 'BASIC QUALIFICATIONS', 'Hire Velocity is an Amazon Partner.', '· Experience in data visualization platforms', '· 5+ years of experience in a business analyst/data analyst/statistical analyst role', '· Experience with SQL', 'PREFERRED QUALIFICATIONS', 'At WW Operations (WWOps) Talent Strategy, we use data to drive all our decision making. The Talent Strategy team acts as an internal provider of new strategy solutions, using quantitative approaches to uncover insight to drive changes and inform decisions. As a Business Analyst, you will work on a team transforming massive, complex data into quantifiable relationships, trends and actionable insights. We are looking for a strong problem-solver, who is skilled using quantitative methods to get things done.', 'Data Warehousing ', 'Supply chain', 'Officlal Online Job Description:', 'Position: Permanent, full-time opportunity in the Seattle, WA area', '· Understanding of data warehousing and data modeling', 'Nice to Haves: ', 'People analytics background ', 'Data Visualization (however, there are three other BIE’s on the team who already have this covered) ', '· Experience with data visualization using Tableau, Quicksight, or similar tools', '· 5+ years of experience conducting analysis and data mining', '· 6+ years of relevant experience in a business analyst, data analyst or statistical analyst role', 'The ideal Business Intelligence Engineer, Talent Strategy candidate will be a blend of BIE and Data Engineer: ', '· Experience implementing processes and providing support for core HR solutions', 'Hire Velocity is an Amazon Partner. I am supporting a Senior Technical Recruiter at Amazon in Seattle.', 'Communication – excellent oral and written communication skills ', '· Proficient extracting and processing data using SQL', 'SQL & ETL (how to set up pipelines and direct querying) ', '· Excellent communication (verbal, written, and data presentation) skills for interactions with both business and technical teams', '· Advanced technical or business degree (MS or MBA)', '3+ years of experience as an analyst or engineer in the data/BI space', 'In this role, you will scope and execute analyses to formulate conclusions and recommendations to be presented to leaders about talent and organization related opportunities. You will be responsible for producing insights that will help shape effective strategies to better meet business needs, often working from scratch create first-generation analyses and insights. You will collaborate closely with partners across the organization to design metrics, test hypotheses, predict outcomes and determine solutions.', 'Stats background ', 'Position:', ' ', 'Must Haves: ', '· Ability to deal with ambiguity and competing objectives in a fast-paced environment', 'Python, R - scripting (15-20% of job) ', ""· Bachelor's degree in Business, Engineering, Statistics, Computer Science, Mathematics or related field"", 'This role requires a significant understanding of data mining and analytical techniques. You will be expected to deliver at a high level against ambiguous problems with minimal technical supervision. The successful candidate will have strong technical and analytical capabilities, business acumen, effective communication skills, and the ability to work effectively with cross-functional teams in a fast paced environment.', 'Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.', '· 3+ years of experience as an analyst or engineer in the data/BI space']",Mid-Senior level,Full-time,Information Technology,Internet,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"St Louis, MO",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Principal Scientist - Amazon Alexa,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', 'Description', ' Excellent written and spoken communication skills', ' Experience working effectively with science, data processing, and software engineering teams', ' Entrepreneurial spirit combined with strong architectural and problem solving skills', ' Graduate degree (MS or PhD) in Electrical Engineering, Computer Sciences, or Mathematics with at least 7 years of related work experience Domain expertise in acoustic and/or language modeling for speech recognition, familiarity with deep learning for speech recognition Familiarity with machine learning techniques, scientific thinking, and the ability to invent Familiarity with programming languages such as C/C++ and Python', ' Strong publication record', ' Strong software design and development skills', ' Graduate degree (MS or PhD) in Electrical Engineering, Computer Sciences, or Mathematics with at least 7 years of related work experience', 'Preferred Qualifications', ' Familiarity with programming languages such as C/C++ and Python', ' Familiarity with machine learning techniques, scientific thinking, and the ability to invent', ' PhD with specialization in speech recognition and machine learning Strong publication record Strong software design and development skills Experience working effectively with science, data processing, and software engineering teams Proven track record of innovation and advancing the state of the art Entrepreneurial spirit combined with strong architectural and problem solving skills Excellent written and spoken communication skills', 'Company', ' PhD with specialization in speech recognition and machine learning', ' Domain expertise in acoustic and/or language modeling for speech recognition, familiarity with deep learning for speech recognition', ' Proven track record of innovation and advancing the state of the art', 'Basic Qualifications']",Director,Full-time,Research,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Las Vegas, NV",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Sr. Data Engineer,Amazon,"Seattle, WA",5 hours ago,27 applicants,"['', "" Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets Proficient in R, Python or any other scripting language for statistical computing. Demonstrated ability to manage and prioritize workload and roadmaps Self-driven with ability to deliver on ambiguous projects with incomplete or unstructured data. Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.) Knowledge of data management fundamentals and data storage principles Knowledge of distributed systems as it pertains to data storage and computing Hands-on experience and advanced knowledge of SQL Basic knowledge of UNIX shell scripting"", ' Passion for building great notification experiences which directly impacts our customers', ' Manage AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etc', ' Collaborate with data scientists, BIEs and BAs to deliver high quality data architecture and pipelines.', ' Basic knowledge of UNIX shell scripting', 'Preferred Qualifications', ' Knowledge of data management fundamentals and data storage principles', ' Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.)', 'Company', ' Contribute to the architecture, design and implementation of next generation BI solutions.', 'Basic Qualifications', ' 5+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems Analyst in a company with large, complex data sources.', 'Description', ' Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets', ' Knowledge of distributed systems as it pertains to data storage and computing', ' Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy', ' Experience providing technical leadership and mentoring other engineers for best practices on data engineering', ' 5+ years of experience as a Data Engineer, BI Engineer, Business/Financial Analyst or Systems Analyst in a company with large, complex data sources. Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets Experience working with AWS big data technologies (EMR, Redshift, S3, Glue, Kinesis and Lambda for serverless ETL) Demonstrated strength in data modeling, ETL development, and data warehousing Experience using business intelligence reporting tools (Quicksight, Power BI, Tableau, Cognos, etc.) Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy Experience providing technical leadership and mentoring other engineers for best practices on data engineering Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations Mindset and analytical skills to towards continuous improvement and have an edge to always research on latest technologies Passion for building great notification experiences which directly impacts our customers', "" Bachelor's degree in computer science, engineering, mathematics, or a related technical discipline"", ' Experience using business intelligence reporting tools (Quicksight, Power BI, Tableau, Cognos, etc.)', ' Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations', ' Experience working with AWS big data technologies (EMR, Redshift, S3, Glue, Kinesis and Lambda for serverless ETL)', ' Make large and/or complex data more accessible, understandable and usable by implementing advanced BI dashboards and applications.', ' 5+ years of industry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets', ' Contribute to the architecture, design and implementation of next generation BI solutions. Manage AWS resources including EC2, RDS, Redshift, Kinesis, EMR, Lambda etc Collaborate with data scientists, BIEs and BAs to deliver high quality data architecture and pipelines. Interface with other technology teams to extract, transform, and load data from a wide variety of data sources. Make large and/or complex data more accessible, understandable and usable by implementing advanced BI dashboards and applications. Own the design, development, and maintenance of metrics, reports, analyses, dashboards, etc. to drive key business decisions. Provide clear communication for recommended actions.', ' Own the design, development, and maintenance of metrics, reports, analyses, dashboards, etc. to drive key business decisions.', ' Demonstrated ability to manage and prioritize workload and roadmaps', ' Interface with other technology teams to extract, transform, and load data from a wide variety of data sources.', ' Provide clear communication for recommended actions.', ' Demonstrated strength in data modeling, ETL development, and data warehousing', ' Hands-on experience and advanced knowledge of SQL', ' Mindset and analytical skills to towards continuous improvement and have an edge to always research on latest technologies', ' Self-driven with ability to deliver on ambiguous projects with incomplete or unstructured data.', ' Proficient in R, Python or any other scripting language for statistical computing.']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Chicago, IL",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Senior User Experience Researcher - Delivery Experience,Amazon,"Seattle, WA",6 hours ago,Be among the first 25 applicants,"['', ' MS in Human Factors, HCDE, or Cognitive Psychology or related discipline', ' Retail/E-commerce research experience in a global context', 'Preferred Qualifications', ' The ability to manage ambiguity, work autonomously and multi-task in a fast paced environment', 'Company', ' Ability to meet ambitious deadlines and deliver high-quality work on schedule, including quickly turning around study plans and reports', 'Basic Qualifications', 'Description', ' 7+ years of proven success leading user research projects with demonstrated impact', ' A BS or equivalent degree in psychology, cognitive science, Human Factors, HCI, HCD etc.', ' Eagerness to continually learn, grow and improve the craft of research.', ' Hands-on experience with: lab-based user testing, remote testing, iterative prototype testing, concept testing, ethnographic research, longitudinal research (e.g. diary studies), benchmarking, international research, survey design and usage of multiple methods within a study', ' End-to-end experience with all aspects of research (study design, recruiting, moderation, analysis, reporting)', ' Experience conducting research on mobile platforms', ' Exceptional behavioral data-collection and analysis skills, (e.g., designing, conducting, and analyzing all kinds of user data.) The ability to manage ambiguity, work autonomously and multi-task in a fast paced environment Ability to meet ambitious deadlines and deliver high-quality work on schedule, including quickly turning around study plans and reports Excellent communication, presentation, interpersonal and analytical skills; the ability to communicate complex concepts clearly and persuasively across different audiences and varying levels of the organization Eagerness to continually learn, grow and improve the craft of research. Demonstrated passion for solving problems A BS or equivalent degree in psychology, cognitive science, Human Factors, HCI, HCD etc. MS in Human Factors, HCDE, or Cognitive Psychology or related discipline Retail/E-commerce research experience in a global context', ' Demonstrated passion for solving problems', ' 7+ years of proven success leading user research projects with demonstrated impact A strong portfolio demonstrating and showcasing how your work has the impacted the product/experience, and the ability to extract actionable insights from qualitative data End-to-end experience with all aspects of research (study design, recruiting, moderation, analysis, reporting) Experience conducting research on mobile platforms Hands-on experience with: lab-based user testing, remote testing, iterative prototype testing, concept testing, ethnographic research, longitudinal research (e.g. diary studies), benchmarking, international research, survey design and usage of multiple methods within a study', ' Excellent communication, presentation, interpersonal and analytical skills; the ability to communicate complex concepts clearly and persuasively across different audiences and varying levels of the organization', ' A strong portfolio demonstrating and showcasing how your work has the impacted the product/experience, and the ability to extract actionable insights from qualitative data', ' Exceptional behavioral data-collection and analysis skills, (e.g., designing, conducting, and analyzing all kinds of user data.)']",Mid-Senior level,Full-time,Art/Creative,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Jersey City, NJ",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"Senior Frontend Engineer, Amazon SageMaker",Amazon,"Palo Alto, CA",7 hours ago,Be among the first 25 applicants,"['', "" Work closely with senior engineers, UX designers, and product managers to develop friendly UI experiences. Work closely with engineers to architect and develop the best technical design. Develop/maintain operational rigor for the frontend of a fast-growing AWS service. Develop the engineers of an existing “two pizza” scrum team. Collaborate with other SageMaker SDE's for features that cut across SageMaker. Engage with customers and other AWS partners. Help with hiring."", "" Experience building tools for data scientists or developers. Attuned design sense so can collaborate with UX designers and hold a high bar with “backend” SDE's. Experience with with CI/CD in a frontend context. Experience establishing and leveraging web analytics. Machine learning knowledge and experience. Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations. Ability to take a project from scoping requirements through actual launch of the project. Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs. Deep hands-on technical expertise in full-stack development."", ' The SageMaker Management Console (https://console.aws.amazon.com/sagemaker )', ' Develop the engineers of an existing “two pizza” scrum team.', ' Bachelor’s Degree in Computer Science or related field.', "" Bachelor’s Degree in Computer Science or related field. Equivalent experience to a Bachelor's degree based on 3 years of work experience for every 1 year of education 5+ years professional experience in software development. Experience with modern programming languages (Java, C#, Python) and open-source technologies. Experience with web/mobile technologies (e.g., JavaScript/TypeScript, NodeJS, React, WebPack, HTTP mechanics/performance)."", "" Custom UI/widgets for AWS ML's Notebook authoring and data scientist IDE experience"", ' Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.', 'Preferred Qualifications', 'Company', "" Collaborate with other SageMaker SDE's for features that cut across SageMaker."", ' Experience with modern programming languages (Java, C#, Python) and open-source technologies.', ' Work closely with senior engineers, UX designers, and product managers to develop friendly UI experiences.', 'Basic Qualifications', 'Description', ' Ability to take a project from scoping requirements through actual launch of the project.', ' Engage with customers and other AWS partners.', ' Experience with web/mobile technologies (e.g., JavaScript/TypeScript, NodeJS, React, WebPack, HTTP mechanics/performance).', ' Knowledge of professional software engineering practices & best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.', ' Work closely with engineers to architect and develop the best technical design.', ' Deep hands-on technical expertise in full-stack development.', "" Attuned design sense so can collaborate with UX designers and hold a high bar with “backend” SDE's."", "" Equivalent experience to a Bachelor's degree based on 3 years of work experience for every 1 year of education"", ' 5+ years professional experience in software development.', ' Help with hiring.', ' Develop/maintain operational rigor for the frontend of a fast-growing AWS service.', ' Experience building tools for data scientists or developers.', ' Experience with with CI/CD in a frontend context.', ' Machine learning knowledge and experience.', 'Key Responsibilities', ' Experience establishing and leveraging web analytics.']",Mid-Senior level,Full-time,Information Technology,Computer Software,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"San Diego, CA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"National City, CA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Louisville, KY",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Cheyenne, WY",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Allentown, PA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Cleveland, OH",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Charlotte, NC",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Bloomington, IL",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Los Angeles, CA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Phoenix, AZ",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Des Moines, IA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Oklahoma City, OK",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Birmingham, AL",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Boise, ID",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Lafayette, LA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Lafayette, LA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Livonia, MI",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Detroit, MI",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Atlanta, GA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Charleston, WV",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Pittsburgh, PA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Houston, TX",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Grand Rapids, MI",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Fargo, ND",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Memphis, TN",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Buffalo, NY",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Virginia Beach, VA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Baton Rouge, LA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Indianapolis, IN",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Providence, RI",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Madison, WI",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"San Antonio, TX",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Fairfax, VA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"New Orleans, LA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Albuquerque, NM",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Kansas City, KS",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Little Rock, AR",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Charleston, SC",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Milwaukee, WI",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Orlando, FL",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Manchester, NH",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Tampa, FL",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Sioux Falls, SD",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Sioux Falls, SD",13 hours ago,Be among the first 25 applicants,[],Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Columbia, SC",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Memphis, TN",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Billings, MT",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Tulsa, OK",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Philadelphia, PA",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Cheyenne, WY",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Raleigh, NC",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Portland, ME",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Boise, ID",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Birmingham, AL",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Salt Lake City, UT",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Baltimore, MD",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Billings, MT",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Dallas, TX",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Burlington, VT",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Bloomington, IL",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Cincinnati, OH",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Albuquerque, NM",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Allentown, PA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Louisville, KY",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Jackson, MS",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Washington, DC",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Atlanta, GA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Atlanta, GA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Jackson County, MO",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Charleston, SC",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Miami, FL",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Houston, TX",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Houston, TX",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Nashville, TN",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Fargo, ND",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Dallas, TX",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Pittsburgh, PA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Denver, CO",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Portland, OR",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Hartford, CT",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Des Moines, IA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"St Louis, MO",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Charlotte, NC",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Tampa, FL",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Detroit, MI",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Ann Arbor, MI",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Austin, TX",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Jersey City, NJ",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Indianapolis, IN",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Boston, MA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"San Antonio, TX",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Chicago, IL",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Kansas City, KS",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Providence, RI",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Milwaukee, WI",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Cleveland, OH",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Grand Rapids, MI",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Phoenix, AZ",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Orlando, FL",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"National City, CA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"San Diego, CA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Minneapolis, MN",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
"ETL Talend Data Engineer, Java a+",Perficient,"Wilmington, DE",13 hours ago,Be among the first 25 applicants,"['', 'Talend Data Engineer', ' Configure and setup Talend environments. ', ' Future technology leaders- dynamic individuals energized by fast paced personal and professional growth. ', ' Translate business requirements to technical specifications and coded data pipelines. ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments. ', 'Responsibilities', ' Need help finding the right job? ', ' Deploy data processing jobs to production ', ' Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design. ', ' Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', ' Work with stakeholders to identify and document requirements. ', ' Disclaimer: ', 'Options', ' Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments. ', ' Troubleshoot data pipelines ', ' Experience with Snowflake, Redshift, or Azure Synapse strongly desired. ', ' Create / CodeTalend data pipelines for a state of the art analytics applications.  Deploy data processing jobs to production  Configure and setup Talend environments.  Work with stakeholders to identify and document requirements.  Configure and schedule data pipelines  Translate business requirements to technical specifications and coded data pipelines.  Troubleshoot data pipelines ', ' Knowledge and experience in developing software using agile methodologies. ', ' Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers. ', ' Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases. ', 'Qualifications', ' Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence. ', ' Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major. ', ' Experience with working in AWS, Azure, and/or Google Cloud environments. ', ' Skilled problem solvers with the desire and proven ability to create innovative solutions. ', 'Talend Data Engineer in their market leading Data Solutions team', ' Proficient in authoring, editing and presenting technical documents. ', ' Passionate coders with 3-5 years of application development experience with Talend.  Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production  Experience with Snowflake, Redshift, or Azure Synapse strongly desired.  Expert knowledge of developing with Talend Cloud.  Knowledge of data formats and ETL and ELT processes in a Hadoop environment including Hive, Parquet, MapReduce, YARN, HBase and other NoSQL databases.  Experience in dealing with structured, semi-structured and unstructured data in batch and real-time environments.  Experience with working in AWS, Azure, and/or Google Cloud environments.  Familiarity with DevOps and CI/CD as well as Agile tools and processes including Git, Jenkins, Jira and Confluence.  Client facing or consulting experience highly preferred.  Skilled problem solvers with the desire and proven ability to create innovative solutions.  Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.  Future technology leaders- dynamic individuals energized by fast paced personal and professional growth.  Phenomenal communicators who can explain and present concepts to technical and non-technical audiences alike, including high level decision makers.  Bachelor’s Degree in MIS, Computer Science, Math, Engineering or comparable major.  Solid foundation in Computer Science, with strong competencies in data structures, algorithms and software design.  Knowledge and experience in developing software using agile methodologies.  Proficient in authoring, editing and presenting technical documents.  Ability to communicate effectively via multiple channels (verbal, written, etc.) with technical and non-technical staff. ', 'Overview', ' Client facing or consulting experience highly preferred. ', ' Passionate coders with 3-5 years of application development experience with Talend. ', ' Proficiency with Talend Open Data Studio or Talend Big Data is a must. Must have worked on projects that have resulted in code being deployed to production ', 'More About Perficient', ' Create / CodeTalend data pipelines for a state of the art analytics applications. ', ' Expert knowledge of developing with Talend Cloud. ', ' Are you legally authorized to work in the United States?', ' Configure and schedule data pipelines ']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Las Vegas, NV",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Columbia, SC",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"New York, NY",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Irvine, CA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Irvine, CA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Seattle, WA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Seattle, WA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Baltimore, MD",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Philadelphia, PA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Madison, WI",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Columbus, OH",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Oklahoma City, OK",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Los Angeles, CA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"San Francisco, CA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Miami, FL",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Fairfax, VA",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Wilmington, DE",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
Azure Data Engineer,Perficient,"Washington, DC",13 hours ago,Be among the first 25 applicants,"['', ' Experience with Agile/Scrum methodology ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB ', ' Ability to conduct/lead oral status/technical interchange meetings with clients ', 'Azure Data Engineer ', ' Strong experience with Azure Databricks is critical ', ' Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form ', ' Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing ', ' Provide guidance on data governance, security, and privacy ', ' Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework ', 'Job Overview', ' Will you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?', ' Self-sufficient, high integrity, more than just competent ', ' Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions ', 'Responsibilities', ' Serve as a technical leader and mentor ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total) ', ' Need help finding the right job? ', ' Ensure that proper processes are followed on the project, be familiar with industry best practices ', ' Experience with IaaS and PaaS capabilities on cloud platforms ', ' Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling ', ' 5+ years of solution delivery experience and a Bachelor of Computer Science, MIS or equivalent degree; without a degree, three additional years of relevant professional experience (8+ years in total)  3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services  Applicable knowledge of principles summarized in the Microsoft Cloud Adoption Framework  Experience developing software architectures and key software components  Experience with IaaS and PaaS capabilities on cloud platforms  Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms  Working knowledge of Azure Monitor, Application Insights, Cost Management or equivalent tooling  Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse  Strong experience with Azure Databricks is critical  Experience with Agile/Scrum methodology  Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise  Able to communicate and present complex issues with preciseness, assurance and confidence  Passion for technology and a high technical aptitude  Self-sufficient, high integrity, more than just competent  Demonstrates the use of consulting skills including: questioning, listening, ideas development, permission and rapport, and influencing  Ability to conduct/lead oral status/technical interchange meetings with clients  Owns and produces customer documentation. Ability to translate technical details into concise and easy to understand written form  Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Passion for technology and a high technical aptitude ', ' Disclaimer: ', ' Able to communicate and present complex issues with preciseness, assurance and confidence ', 'Options', ' Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements ', ' Understanding of data services including CosmosDB, Azure SQL Database, Data Lake, Databricks, Data Factory, Synapse ', ' Contribute knowledge, tools and positivity to the greater Perficient culture and community ', 'Qualifications', ' Sufficient depth and breadth of technical knowledge to be individually responsible for the design and scope of deliverables within a field of expertise ', ' Communicate across client’s community – consistently viewed as adding value ', ' Provide technical leadership for on-premises assessment, economic forecast and modernization strategy ', 'Overview', ' Ability to translate requirements from client meetings into requirements documents and proposal presentations ', ' Support data migrations from SQL and open source repositories into modern Azure data services ', ' 3+ years delivering solutions on the Microsoft Azure platform with a special emphasis on data solutions and services ', 'More About Perficient', ' Support IaaS and data migrations and PaaS modernizations ', ' Implement modern data solutions with Azure Data Factory, Data Lake, Data Bricks, SQL data warehouse, and Cosmos DB  Provide guidance on data governance, security, and privacy  Support IaaS and data migrations and PaaS modernizations  Support data migrations from SQL and open source repositories into modern Azure data services  Craft high-quality Visio documents to communicate thoroughness of vision for system architecture topology, component design, networking and security of proposed solutions  Ensure that proper processes are followed on the project, be familiar with industry best practices  Understand a broad spectrum of technology in order to provide detailed technical design which meets customer requirements  Provide technical leadership for on-premises assessment, economic forecast and modernization strategy  Communicate across client’s community – consistently viewed as adding value  Contribute knowledge, tools and positivity to the greater Perficient culture and community  Serve as a technical leader and mentor ', ' Experience developing software architectures and key software components ', ' Hands-on experience with Kubernetes, AKS, OpenShift or ARO container platforms ', ' Are you legally authorized to work in the United States?']",Mid-Senior level,Full-time,Information Technology,Information Technology and Services,2020-11-05 11:32:32
